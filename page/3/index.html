<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="人一己千">
<meta property="og:type" content="website">
<meta property="og:title" content="Weekly Review">
<meta property="og:url" content="http://www.linzehui.me/page/3/index.html">
<meta property="og:site_name" content="Weekly Review">
<meta property="og:description" content="人一己千">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Weekly Review">
<meta name="twitter:description" content="人一己千">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.linzehui.me/page/3/"/>





  <title>Weekly Review</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Weekly Review</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/23/代码相关/代码记录13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/23/代码相关/代码记录13/" itemprop="url">代码片段记录13</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-23T09:42:30+08:00">
                2018-12-23
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-23T09:44:04+08:00">
                2018-12-23
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-flatten-list"><a href="#1️⃣-flatten-list" class="headerlink" title="1️⃣[flatten list]"></a>1️⃣[flatten list]</h3><p>对二维list进行展开。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list2d = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>], [<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"><span class="comment"># ①</span></span><br><span class="line">flatten = [l <span class="keyword">for</span> list <span class="keyword">in</span> list2d <span class="keyword">for</span> l <span class="keyword">in</span> list]</span><br><span class="line"><span class="comment"># ②</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">merged = list(itertools.chain(*list2d))</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">merged = list(itertools.chain.from_iterable(list2d))</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/23/碎片知识/每周碎片知识16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/23/碎片知识/每周碎片知识16/" itemprop="url">每周碎片知识16</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-23T09:09:14+08:00">
                2018-12-23
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-29T18:48:42+08:00">
                2018-12-29
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-Softmax"><a href="#1️⃣-Softmax" class="headerlink" title="1️⃣[Softmax]"></a>1️⃣[Softmax]</h3><p>在使用softmax的时候，要非常注意softmax的行为。应尽量控制softmax前元素的规模，否则容易出现one-hot的情况，导致训练困难。<br><img src="/images/15455275366030.jpg" width="70%" height="50%"></p>
<p>同时，对全-inf做softmax是未定义的，因此也会出现问题：<br><img src="/images/15455278529550.jpg" width="40%" height="50%"></p>
<hr>
<h3 id="2️⃣-slice"><a href="#2️⃣-slice" class="headerlink" title="2️⃣[slice]"></a>2️⃣[slice]</h3><p>在对tensor或array操作时，如果需要取某维的slice：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">a[:,<span class="number">1</span>:<span class="number">3</span>]  <span class="comment"># 取第1列到第2列的slice</span></span><br><span class="line">a[:][<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># wrong，获得的是第1行到第2行的slice</span></span><br></pre></td></tr></table></figure>
<p>原因是，<code>a[:][1:3]</code>是先做<code>a[:]</code>操作，获得了全部元素，然后再做<code>[1:3]</code>操作，也即获得第1行到第2行的元素。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/16/代码相关/代码记录12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/16/代码相关/代码记录12/" itemprop="url">代码片段记录12</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-16T10:59:30+08:00">
                2018-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-16T11:01:18+08:00">
                2018-12-16
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-CUDA-time"><a href="#1️⃣-CUDA-time" class="headerlink" title="1️⃣[CUDA time]"></a>1️⃣[CUDA time]</h3><p>正确测试代码在cuda运行时间。需要加上<code>torch.cuda.synchronize()</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line">b = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">M = torch.bmm(a, b.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"bmm"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">local_a = a.unsqueeze(<span class="number">2</span>)</span><br><span class="line">local_b = b.unsqueeze(<span class="number">1</span>)</span><br><span class="line">N = (local_a*local_b).sum(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"element-wise"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"output difference (should be 0)"</span>, (N - M).abs().max())</span><br><span class="line">print(<span class="string">"In single precision this can fail because of the size of the tensors."</span>)</span><br><span class="line">print(<span class="string">"Using double should always work"</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/16/碎片知识/每周碎片知识15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/16/碎片知识/每周碎片知识15/" itemprop="url">每周碎片知识15</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-16T10:55:14+08:00">
                2018-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-18T18:18:09+08:00">
                2018-12-18
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-Pytorch"><a href="#1️⃣-Pytorch" class="headerlink" title="1️⃣[Pytorch]"></a>1️⃣[Pytorch]</h3><p>在0.41的pytorch中，bernoulli的速度会比随机sample的速度慢很多；<br>在1.0中修复了该bug，但速度上还是随机sample快一点点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Pytorch0.41</span><br><span class="line">Bernoulli  0.430371046066</span><br><span class="line">sample  0.24411702156</span><br><span class="line"></span><br><span class="line"># Pytorch1.0</span><br><span class="line">Bernoulli  0.256921529</span><br><span class="line">sample  0.25317035184</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下二者等价</span></span><br><span class="line">mask = Bernoulli(gamma).sample(x.size()) <span class="comment"># slow</span></span><br><span class="line">mask = (torch.rand_like(x)&lt;gamma).float() <span class="comment"># faster</span></span><br></pre></td></tr></table></figure>
<p>Reference:<br><a href="https://github.com/pytorch/pytorch/issues/6940" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/6940</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/16/论文/每周论文9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/16/论文/每周论文9/" itemprop="url">每周论文9</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-16T10:43:30+08:00">
                2018-12-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-16T11:14:52+08:00">
                2018-12-16
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1️⃣-Sentence-State-LSTM-for-Text-Representation"><a href="#1️⃣-Sentence-State-LSTM-for-Text-Representation" class="headerlink" title="1️⃣[Sentence-State LSTM for Text Representation]"></a>1️⃣[Sentence-State LSTM for Text Representation]</h2><p>提出一种新型的encode句子的方法。有点类似gather-distribute的想法。</p>
<p><img src="/images/15449283844319.jpg" width="45%" height="50%"></p>
<p>每个时间步t所有的h一起更新。更新方式是与其左右的点进行交互，同时与一个global representation进行交互。这样即考虑了local的信息也考虑了global的信息。每次更新都增加了信息交互，从3gram到5gram再到7gram…</p>
<p>具体来说：<br>①如何求$h_i$<br><img src="/images/15449285619763.jpg" width="45%" height="50%"></p>
<p>从公式可以看出，对于一个特定的$h_i$，同时考虑左右两点，以及global信息$g$，以及输入$x$。</p>
<p>②如何求g<br><img src="/images/15449286595709.jpg" width="50%" height="50%"></p>
<p>通过average同时考虑所有的词，同时考虑自己上一个状态。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/09/碎片知识/Python中的+=操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/09/碎片知识/Python中的+=操作/" itemprop="url">Python中的+=操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-09T20:14:11+08:00">
                2018-12-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-09T20:35:29+08:00">
                2018-12-09
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>前几日在写一段Pytorch代码时，又一次遇到了in-place操作的问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output+=pos  <span class="comment"># pos是不可更新的tensor，output是可更新的tensor</span></span><br></pre></td></tr></table></figure>
<p>程序报错：“one of the variables needed for gradient computation has been modified by an inplace operation”。</p>
<p>无意中将代码改成<code>output=output+pos</code>，程序就不会报错了。</p>
<p>在查阅了相关资料后，将我的思考整理下来。</p>
<p>在Python中，<code>i=i+1</code>和<code>i+=1</code>是不同的，如果被操作数没有部署 ’<strong>iadd</strong>‘方法，则<code>i=i+1</code>和<code>i+=1</code>是等价的，’+=‘并不会产生in-place操作；当被操作数有部署该方法且正确部署，则是会产生in-place操作的。当没有in-place操作时，<code>i=i+1</code>表示对i重分配，也即i指向了另一个空间而不是原来的空间。</p>
<p>所以，这样的例子就能解释清楚了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    a = a + <span class="number">1</span></span><br><span class="line"><span class="comment"># A并没有被改变</span></span><br><span class="line">B = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">    b += <span class="number">1</span></span><br><span class="line"><span class="comment"># B被改变了</span></span><br></pre></td></tr></table></figure>
<p>在Pytorch中，也有部署’<strong>iadd</strong>()‘操作，所以对于<code>output+=pos</code>，output内部的值被改变了，也即在计算图中引入了环，在反向求导时则会出错。</p>
<p>因此，在Pytorch中，应当避免in-place的操作。</p>
<p>Reference:<br><a href="https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop" target="_blank" rel="noopener">https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/09/论文/每周论文8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/09/论文/每周论文8/" itemprop="url">每周论文8</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-09T09:57:30+08:00">
                2018-12-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-16T11:08:16+08:00">
                2018-12-16
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1️⃣-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding"><a href="#1️⃣-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding" class="headerlink" title="1️⃣[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]"></a>1️⃣[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]</h2><p>提出了两种attention机制，即 multi-dimentional attention和directional self-attention，在此基础上提出有向自注意力网络（directional self-attention network)</p>
<h3 id="Multi-dimensional-Attention"><a href="#Multi-dimensional-Attention" class="headerlink" title="Multi-dimensional Attention"></a>Multi-dimensional Attention</h3><p>与传统的方法不同的是，对于每个词对，attention出来的不是标量而是向量。<br><img src="/images/15443239891184.jpg" width="60%" height="50%"></p>
<p>计算公式：<br><img src="/images/15443240335179.jpg" width="40%" height="50%"></p>
<p>$f$的维度与$q$相同，每一维代表的是$x_i$在该维对$q$的重要性。也即feature-wise的attention。因此对于$q$而言，其获得的加权求和向量为：<br><img src="/images/15443241367138.jpg" width="55%" height="50%"></p>
<p>使用feature-wise的attention能够解决一次多义的问题，因为能够计算每一维的重要性，在不同的context下有不同的重要性。</p>
<p>将其应用于self-attention中，有两种变体：<br>①token2token<br><img src="/images/15443242128118.jpg" width="58%" height="50%"></p>
<p><img src="/images/15443242249947.jpg" width="20%" height="50%"></p>
<p>因此x在交互完有：<br><img src="/images/15443242733208.jpg" width="35%" height="50%"></p>
<p>②source2token<br><img src="/images/15443243090328.jpg" width="40%" height="50%"></p>
<p>也即$x_i$没有和其他元素有交互。<br>可用作获得sentence encoding：<br><img src="/images/15443243968731.jpg" width="20%" height="50%"></p>
<h3 id="Directional-Self-Attention"><a href="#Directional-Self-Attention" class="headerlink" title="Directional Self-Attention"></a>Directional Self-Attention</h3><p>使用mask达到有向性这一目的：<strong>通过mask矩阵将位置/方向编码进attention，解决时序丢失问题</strong>。<br>首先将x过一层获得新的h表示：<br><img src="/images/15443244421489.jpg" width="27%" height="50%"></p>
<p>接着使用token2token求attention，这里为了减少参数作了一定改动，将W换成c，tanh替换σ。<br><img src="/images/15443245099821.jpg" width="53%" height="50%"></p>
<p>$\textbf{1}$是全1的向量。M就是mask矩阵，代表i与j是否连通，Mask矩阵有：<br><img src="/images/15443248745747.jpg" width="28%" height="50%"></p>
<p><img src="/images/15443248908199.jpg" width="31%" height="50%"></p>
<p>也即：<br><img src="/images/15443249388350.jpg" width="50%" height="50%"></p>
<p>首先mask掉自己，第二：分别mask掉forward和backward，类似biLSTM，只和前面或后面的交互。</p>
<h3 id="Directional-Self-Attention-Network"><a href="#Directional-Self-Attention-Network" class="headerlink" title="Directional Self-Attention Network"></a>Directional Self-Attention Network</h3><p>在上述两个方法的基础上，此时已获得了上下文相关的$s_i$，再引入fusion gate：<br><img src="/images/15443250617220.jpg" width="45%" height="50%"></p>
<p>整个流程：<br><img src="/images/15443250338890.jpg" width="50%" height="50%"></p>
<p>将前向和反向的表示拼接起来，获得最终的表示$[u^{fw};u^{bw}]$：<br><img src="/images/15443251919096.jpg" width="50%" height="50%"></p>
<p>对于所获得的每一个表示，通过source2token，获得最终的句子表示。</p>
<p>这一点论文也提到了，非常类似bi-LSTM。</p>
<hr>
<h2 id="2️⃣-Targeted-Dropout"><a href="#2️⃣-Targeted-Dropout" class="headerlink" title="2️⃣[Targeted Dropout]"></a>2️⃣[Targeted Dropout]</h2><p>一种网络剪枝方法，想法简单易实现。<br>简单说，在每次更新时对最不重要的weight或者unit进行随机dropout。</p>
<h3 id="Targeted-Dropout"><a href="#Targeted-Dropout" class="headerlink" title="Targeted Dropout"></a>Targeted Dropout</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>给定输入X，权重W，输出Y M为dropout的mask矩阵。<br>unit dropout：<br><img src="/images/15443218016315.jpg" width="22%" height="50%"></p>
<p>weight dropout：<br><img src="/images/15443218315803.jpg" width="22%" height="50%"></p>
<p>也即drop掉的是layer之间的connection。</p>
<h4 id="Magnitude-based-pruning"><a href="#Magnitude-based-pruning" class="headerlink" title="Magnitude-based pruning"></a>Magnitude-based pruning</h4><p>剪枝通常对权重最小的进行剪枝，也即保留topk个最大的权重。</p>
<p>Unit pruning：直接剪掉的是一整列，也即一个unit<br><img src="/images/15443218793541.jpg" width="43%" height="50%"></p>
<p>Weight pruning：对W的每个元素进行剪枝。注意是对每行的topk进行保留<br><img src="/images/15443219325533.jpg" width="58%" height="50%"></p>
<p>可以理解成对一个unit来说，保留最高的k个connection。</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>结合dropout和剪枝。<br>主要思想：首先选择N-k最不重要的element，由于我们希望这些low-value的元素有机会在训练过程中变得重要，因此我们对这些element进行随机dropout。</p>
<p>引入targeting proportion γ和drop probability α，亦即：选择最低的γ|θ|个weight，再根据α进行dropout。<br>这样做的结果是：减少重要的子网络对不重要的子网络的依赖。</p>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><p>①dropout的intuition：减少unit之间的相互适应。when dropout is applied to a unit, the remaining network can no longer depend on that unit’s contribution to the function and must learn to propagate that unit’s information through a more reliable channel。<br>也可以理解成：使得unit之间的交互信息达到最大，在失去某个unit的时候影响不会那么大。</p>
<p>②targeted dropout intuition：the important subnetwork is completely separated from the unimportant one。假设一个网络由两个不相交的子网络组成，每个都能输出正确的结果，总的网络是这两个网络的平均。我们通过对不重要的子网络进行dropout（也即往子网络里加noise，会破坏该子网络的输出，由于重要的子网络已经能够输出正确的结果，因此为了减少损失，我们需要减少不重要网络的输出到0，也即kill掉该子网络，并且加强这两个网络的分离。（为什么不直接舍弃呢？因为是在训练过程中，有可能会有变化）<br>这个解释还是没完全懂。</p>
<hr>
<h2 id="3️⃣-A2-Nets-Double-Attention-Networks"><a href="#3️⃣-A2-Nets-Double-Attention-Networks" class="headerlink" title="3️⃣[A2-Nets: Double Attention Networks]"></a>3️⃣[A2-Nets: Double Attention Networks]</h2><p>发表于NIPS2018，个人认为很有启发。提出一种新的attention机制，基于“收集-分发”的思想，能够让CNN获得更大的感受野。</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>CNN本身主要是捕获局部特征与关系，但对于长距离之间的关系只能通过堆叠多几层才能实现。但这样需要更高的计算量，且容易过拟合；同时，远处的特征实际上是来自好几层的延迟，导致推理的困难。</p>
<p>通过将feature收集起来，然后分发下去，使得feature之间有交互，让CNN获得更大的感受野，能够捕获长距离的特征。</p>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><p><img src="/images/15443223814542.jpg" width="80%" height="50%"></p>
<p>也即：<br><img src="/images/15443224194279.jpg" width="34%" height="50%"></p>
<p>X是所有输入，$v_i是$local feature。</p>
<h4 id="The-First-Attention-Step-Feature-Gathering"><a href="#The-First-Attention-Step-Feature-Gathering" class="headerlink" title="The First Attention Step: Feature Gathering"></a>The First Attention Step: Feature Gathering</h4><p>对于两个feature map A,B，有：<br><img src="/images/15443225280678.jpg" width="40%" height="50%"></p>
<p>其中：<br><img src="/images/15443226145868.jpg" width="35%" height="50%"></p>
<p><img src="/images/15443226262919.jpg" width="35%" height="50%"></p>
<p>如果A、B都来自同一个X，将B归一化softmax，就类似transformer的attention。其中上式的最右边是外积的形式。</p>
<p>我们将G拆分成向量形式：<br><img src="/images/15443226708983.jpg" width="33%" height="50%"><br>同时将B重写成行向量形式，则有：<br><img src="/images/15443227241595.jpg" width="22%" height="50%"></p>
<p>则会有：<br><img src="/images/15443227868015.jpg" width="28%" height="50%"></p>
<p>上式让我们有一个新的理解角度：G实际上就是 a bag of visual primitives。每个$g_i$是所有local feature加权求和，其中$b_i$是求和的weight。</p>
<p>因此我们对B做softmax，保证权重为1：<br><img src="/images/15443228682403.jpg" width="28%" height="50%"></p>
<h4 id="The-Second-Attention-Step-Feature-Distribution"><a href="#The-Second-Attention-Step-Feature-Distribution" class="headerlink" title="The Second Attention Step: Feature Distribution"></a>The Second Attention Step: Feature Distribution</h4><p>在获得了全局的feature G后，现在根据local feature去获取全局feature的部分，这通过一个权重控制，也即$v_i$（local feature)的每一维作为权重。可以不将local feature $v_i$归一化，但归一化能更好地converge。</p>
<h4 id="The-Double-Attention-Block"><a href="#The-Double-Attention-Block" class="headerlink" title="The Double Attention Block"></a>The Double Attention Block</h4><p>最终得到double attention block：<br><img src="/images/15443230115907.jpg" width="68%" height="50%"></p>
<p>整个流程：<br><img src="/images/15443230641691.jpg" width="80%" height="50%"></p>
<p>所以其实是有三个convolution layer。</p>
<p>上式还可以写成：<br><img src="/images/15443232642402.jpg" width="70%" height="50%"><br>数学上等价，但计算上差很多。第一个式子会有更低的复杂度。</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>虽然用了attention，但这里和Transformer还是有非常大的区别的。Transformer每个元素都和其他元素有交互，通过直接的计算得到权重。而这边的权重由feature本身来决定。并没有直接的交互。</p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/09/碎片知识/每周碎片知识14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/09/碎片知识/每周碎片知识14/" itemprop="url">每周碎片知识14</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-09T09:41:14+08:00">
                2018-12-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-09T09:55:28+08:00">
                2018-12-09
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-Pytorch"><a href="#1️⃣-Pytorch" class="headerlink" title="1️⃣[Pytorch]"></a>1️⃣[Pytorch]</h3><p>Pytorch的tensor和Tensor是有区别的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor(<span class="number">2</span>)  <span class="comment"># 是标量，size为[]</span></span><br><span class="line">b = torch.Tensor(<span class="number">2</span>)  <span class="comment"># 是向量，size为[2]</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/09/诗词&句/每周诗词17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/09/诗词&句/每周诗词17/" itemprop="url">每周诗词17</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-09T09:38:14+08:00">
                2018-12-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-09T09:39:18+08:00">
                2018-12-09
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣虞美人"><a href="#1️⃣虞美人" class="headerlink" title="1️⃣虞美人"></a>1️⃣虞美人</h3><p>[宋] 叶梦得<br>落花已作风前舞，又送黄昏雨。晓来庭院半残红，惟有游丝，千丈袅晴空。<br>殷勤花下同携手，更尽杯中酒。美人不用敛蛾眉，<strong>我亦多情，无奈酒阑时</strong>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2018/12/02/碎片知识/每周碎片知识13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/02/碎片知识/每周碎片知识13/" itemprop="url">每周碎片知识13</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-02T15:32:14+08:00">
                2018-12-02
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-12-02T11:34:20+08:00">
                2018-12-02
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣-attention"><a href="#1️⃣-attention" class="headerlink" title="1️⃣[attention]"></a>1️⃣[attention]</h3><p>所有attention的总结：<br><img src="/images/15437180657954.jpg" width="70%" height="50%"><br><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention!</a></p>
<hr>
<h3 id="2️⃣-Pytorch"><a href="#2️⃣-Pytorch" class="headerlink" title="2️⃣[Pytorch]"></a>2️⃣[Pytorch]</h3><p>①torch.no_grad能够显著减少内存使用，model.eval不能。因为eval不会关闭历史追踪。</p>
<blockquote>
<p>model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval model instead of training mode.<br>torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).</p>
</blockquote>
<p>Reference:<br><a href="https://discuss.pytorch.org/t/does-model-eval-with-torch-set-grad-enabled-is-train-have-the-same-effect-for-grad-history/17183/3" target="_blank" rel="noopener">Does model.eval() &amp; with torch.set_grad_enabled(is_train) have the same effect for grad history?</a></p>
<p><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615" target="_blank" rel="noopener">‘model.eval()’ vs ‘with torch.no_grad()’</a></p>
<p>②torch.full(…) returns a tensor filled with value.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg"
                alt="林泽辉" />
            
              <p class="site-author-name" itemprop="name">林泽辉</p>
              <p class="site-description motion-element" itemprop="description">人一己千</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">128</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">150</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">林泽辉</span>

  
</div>






  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
