<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†29</title>
    <url>/2019/10/27/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8629/</url>
    <content><![CDATA[<h3 id="æ¡ä»¶æ•°"><a href="#æ¡ä»¶æ•°" class="headerlink" title="[æ¡ä»¶æ•°]"></a>[æ¡ä»¶æ•°]</h3><p>ä¸€ç‚¹æ¨æµ‹ï¼šåœ¨ä½¿ç”¨fairseqæ—¶ï¼Œå³ä½¿ä½¿ç”¨é»˜è®¤çš„è¶…å‚ä»¥åŠè®­ç»ƒæ–¹æ³•ï¼Œéƒ½æœ‰ä¸€å®šæœºä¼šå‡ºç°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°nançš„é—®é¢˜ã€‚è¿™é‡Œæ¨æµ‹æˆ–è®¸æ˜¯å’Œæ¡ä»¶æ•°ï¼ˆcondition number)ç›¸å…³ã€‚</p>
<p>condition numberï¼šè‹¥çŸ©é˜µçš„condition numberå¤§ï¼Œåˆ™ä¸å…¶ç›¸ä¹˜çš„å‘é‡åšä¸€ç‚¹å˜åŒ–ä¼šå¯¼è‡´ç›¸ä¹˜çš„ç»“æœå˜åŒ–å¾ˆå¤§ã€‚æ‰€ä»¥å¦‚æœå±‚æ•°è¶Šå¤šï¼Œç†è®ºä¸Šå¯èƒ½ä¼šå¯¼è‡´åé¢çš„çŸ©é˜µçš„condition numberè¶Šæ¥è¶Šå¤§ï¼Œè€Œå‘é‡å¯¹åº”æ¯å±‚çš„è¾“å…¥ï¼Œé‚£ä¹ˆéšç€å±‚æ•°çš„åŠ æ·±ï¼Œæ¨¡å‹è¾“å…¥çš„ä¸€ç‚¹æ‰°åŠ¨ä¼šéšç€å±‚æ•°çš„å¢åŠ ï¼Œscaleé€æ¸å¢å¤§ï¼Œæœ€ç»ˆå¯èƒ½å¯¼è‡´nanï¼ˆinfinityï¼‰ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆtransformerå¯èƒ½ä¼šå¶å°”nançš„é—®é¢˜ã€‚ï¼ˆæ„Ÿè°¢éƒ­åšçš„ç§‘æ™®ğŸ˜¬ï¼‰</p>
<hr>
<h3 id="attentionæ–°è§’åº¦"><a href="#attentionæ–°è§’åº¦" class="headerlink" title="[attentionæ–°è§’åº¦]"></a>[attentionæ–°è§’åº¦]</h3><p>attentionå¯ä»¥ç†è§£æˆæ˜¯äºŒç»´çš„äº’åŠ¨ï¼š$q_i$ä¸$k_j$ä¹‹é—´çš„äº’åŠ¨ï¼Œä¹Ÿå³ä»äºŒç»´çš„è§’åº¦å»çœ‹ï¼ŒçŸ©é˜µçš„æ¯æ ¼éƒ½æ˜¯ç”±iä¸jç‹¬ç«‹æ§åˆ¶çš„ã€‚è€ŒLSTMå¯ä»¥çœ‹æˆæ˜¯ä¸¤ä¸ªä¸€ç»´çš„å åŠ ï¼Œinput gateæ§åˆ¶è¾“å…¥çš„å¤šå°‘ï¼Œä¹Ÿå³ä¸Šä¸€å±‚èƒ½è¿›å…¥å¤šå°‘ä¿¡æ¯ï¼Œoutput gateåˆ™æ§åˆ¶è¾“å‡ºçš„å¤šå°‘ï¼Œä¹Ÿå³ä¸‹ä¸€å±‚æœ€å¤šèƒ½æ¥å—å¤šå°‘ã€‚ä»äºŒç»´çš„è§’åº¦å°±æ˜¯ï¼Œä¸€ä¸ªgateæ§åˆ¶çš„æ•´è¡Œï¼Œå¦ä¸€ä¸ªgateæ§åˆ¶çš„æ•´åˆ—ã€‚ï¼ˆæ„Ÿè°¢éƒ­åšç§‘æ™®ï¼Œéƒ­åštqlğŸ˜¬ï¼‰</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>attention</tag>
        <tag>æ¡ä»¶æ•°</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡33</title>
    <url>/2019/10/27/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8733/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Toward Controlled Generation of Text</li>
<li>Style Transfer in Text: Exploration and Evaluation</li>
<li>Unsupervised Text Style Transfer using Language Models as Discriminators</li>
<li>Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</li>
<li>Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer</li>
<li>Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis</li>
<li>SHAPED: Shared-Private Encoder-Decoder for Text Style Adaptation</li>
<li>Style Transfer Through Back-Translation</li>
<li>Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer</li>
<li>Disentangled Representation Learning for Non-Parallel Text Style Transfer</li>
</ol>
<h2 id="Toward-Controlled-Generation-of-Text"><a href="#Toward-Controlled-Generation-of-Text" class="headerlink" title="[Toward Controlled Generation of Text]"></a>[Toward Controlled Generation of Text]</h2><p>VAE+GANç”¨ä»¥ç”Ÿæˆå¯æ§åˆ¶æ–‡æœ¬ã€‚</p>
<p><img src="/images/15721482835511.jpg" width="60%" height="50%"></p>
<p>ä¸ºäº†ç”Ÿæˆå¯æ§åˆ¶æ–¹å‘çš„æ–‡æœ¬ï¼Œå…¶æ€æƒ³æ˜¯å¸Œæœ›èƒ½å¤Ÿè®©æ¨¡å‹å­¦ä¼šç”Ÿæˆdisentangled latent representationï¼Œå°†å†…å®¹å’Œæ§åˆ¶å˜é‡åˆ†ç¦»å¼€ï¼Œå…·ä½“æ˜¯é€šè¿‡GANæ¥å®ç°çš„ã€‚</p>
<p>ç®€å•æ¥è¯´ï¼Œç»™å®š$x$ï¼Œè¦æ±‚encoderèƒ½å¤Ÿç”Ÿæˆdisentangled latent representationï¼Œä¹Ÿå³æ§åˆ¶å˜é‡$c$å’Œå†…å®¹$z$çš„åˆ†ç¦»ã€‚åœ¨ç»™å®šç‰¹å®šçš„æ§åˆ¶å˜é‡$c$ï¼Œé€šè¿‡generatorç”Ÿæˆå¯¹åº”çš„$\hat{x}$ï¼Œè¦æ±‚$\hat{x}$èƒ½å¤Ÿéª—è¿‡discriminatorï¼Œä½¿å¾—discriminatorè®¤ä¸º$\hat{x}$æ˜¯å±äºç»™å®šçš„ç‰¹å®šæ§åˆ¶å˜é‡$c$ï¼›åŒæ—¶$\hat{x}$ä¼šé‡æ–°è¾“å…¥åˆ°encoderä¸­ä»¥æœŸæœ›èƒ½å¤Ÿæ‹Ÿåˆ$z$ï¼Œè¿™æ ·èƒ½å¤Ÿä¿è¯$z$ä¸$c$çš„è§£è€¦ã€‚</p>
<hr>
<h2 id="Style-Transfer-in-Text-Exploration-and-Evaluation"><a href="#Style-Transfer-in-Text-Exploration-and-Evaluation" class="headerlink" title="[Style Transfer in Text: Exploration and Evaluation]"></a>[Style Transfer in Text: Exploration and Evaluation]</h2><p>ä¸¤ä¸ªè´¡çŒ®ï¼šæå‡ºä¸€ç§æ–°çš„style transferçš„æ¨¡å‹ï¼›æå‡ºæ–°çš„è¯„ä»·æŒ‡æ ‡ã€‚</p>
<h3 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><p><img src="/images/15721769663657.jpg" width="80%" height="50%"></p>
<p>æœ¬æ–‡æå‡ºä¸¤ä¸ªæ¨¡å‹ï¼Œ ä¸€ç§æ˜¯multi-decoderçš„ï¼Œå¦ä¸€ç§æ˜¯åŸºäºstyle-embeddingçš„ã€‚encoderç«¯éƒ½æ˜¯ä¸€æ ·ï¼Œé€šè¿‡discriminatoræ¥è·å¾—style-independent content $c$ã€‚å¯¹äºmulti-decoderè€Œè¨€ï¼Œä¸åŒstyleæœ‰ä¸åŒçš„decoderï¼›è€Œåœ¨style-embeddingä¸­ï¼Œåˆ™æ˜¯é€šè¿‡åœ¨å†…å®¹åé¢catä¸€ä¸ªstyleçš„embeddingä½œä¸ºè¾“å…¥ä¼ ç»™decoderã€‚</p>
<h3 id="è¯„ä»·æŒ‡æ ‡"><a href="#è¯„ä»·æŒ‡æ ‡" class="headerlink" title="è¯„ä»·æŒ‡æ ‡"></a>è¯„ä»·æŒ‡æ ‡</h3><p>åœ¨è¯„ä»·æŒ‡æ ‡ä¸­ï¼Œæå‡ºä¸¤ä¸ªæ–¹é¢ï¼šTransfer Strengthå’Œcontent preservationã€‚</p>
<p>Transfer Strengthï¼šæŒ‡çš„æ˜¯è½¬æ¢æˆåŠŸçš„èƒ½åŠ›ï¼Œä¹Ÿå³ç”¨ä¸€ä¸ªåˆ†ç±»å™¨åˆ¤æ–­ç”Ÿæˆçš„å¥å­å’Œæºå¥å­æ˜¯å¦æ˜¯ä¸åŒçš„styleï¼›</p>
<p>content preservationï¼šè®¡ç®—ä¸¤ä¸ªå¥å­çš„embeddingç„¶åç®—ä»–ä»¬ä¹‹é—´çš„cosè·ç¦»ã€‚å…·ä½“å…¬å¼ï¼š</p>
<p>$\begin{aligned} v_{\min }[i] &amp;=\min \left\{w_{1}[i], \ldots w_{n}[i]\right\} \\ v_{\operatorname{mean}}[i] &amp;=\operatorname{mean}\left\{w_{1}[i], \ldots w_{n}[i]\right\} \\ v_{\max }[i] &amp;=\max \left\{w_{1}[i], \ldots w_{n}[i]\right\} \\ v &amp;=\left[v_{\min }, v_{\operatorname{mean}}, v_{\max }\right] \\ \operatorname{score} &amp;=\frac{v_{s}^{\top} v_{t}}{\left|v_{s}\right| \cdot\left|v_{t}\right|} \\ \text {score}_{t o t a l} &amp;=\sum_{i=1}^{M_{t e s t}} s c o r e_{i} \end{aligned}$</p>
<hr>
<h2 id="Unsupervised-Text-Style-Transfer-using-Language-Models-as-Discriminators"><a href="#Unsupervised-Text-Style-Transfer-using-Language-Models-as-Discriminators" class="headerlink" title="[Unsupervised Text Style Transfer using Language Models as Discriminators]"></a>[Unsupervised Text Style Transfer using Language Models as Discriminators]</h2><p>æœ¬æ–‡çš„äº®ç‚¹æ˜¯åˆ©ç”¨è¯­è¨€æ¨¡å‹æ¥æ›¿ä»£åˆ†ç±»å™¨ä½œä¸ºdiscriminatorã€‚</p>
<p>ä¸ºä»€ä¹ˆé€‰æ‹©language modelè€Œä¸æ˜¯åˆ†ç±»å™¨ï¼š<br>è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè·å¾—æ›´ç›´æ¥çš„ä¿¡å·ï¼Œæ˜¯token-levelè€Œä¸æ˜¯sentence-levelçš„ï¼Œèƒ½å¤Ÿé’ˆå¯¹è¯è¿›è¡Œè®¡ç®—lossï¼›åŒæ—¶è¿˜èƒ½å¤Ÿæä¾›æ•´ä½“çš„scoreï¼ˆpplï¼‰ã€‚</p>
<p>æ¨¡å‹æ•´ä½“åšæ³•ï¼š</p>
<p><img src="/images/15721791494071.jpg" width="80%" height="50%"></p>
<p>lossç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šreconstruction losså’Œtransferred lossã€‚reconstruction losså°±æ˜¯åœ¨encodeä¸ºä¸€ä¸ªstyle-independent representationåå†ç»™å®šåŒä¸€ä¸ªstyleçš„æƒ…å†µä¸‹ï¼Œæ¢å¤å›åŸå…ˆçš„xï¼›ç¬¬äºŒæ˜¯åœ¨ç»™å®šä¸åŒstyleçš„æƒ…å†µä¸‹generatorç”Ÿæˆçš„$\tilde{x}$çš„lossã€‚</p>
<p>transferred losså…·ä½“åšæ³•ï¼š</p>
<p><img src="/images/15721793478258.jpg" width="80%" height="50%"></p>
<p>ç¬¬ä¸€ï¼Œåœ¨è¿™é‡Œä½¿ç”¨continuous approximationï¼Œä¹Ÿå³ä½¿ç”¨çš„æ˜¯æ¦‚ç‡åˆ†å¸ƒè€Œä¸æ˜¯one-hotä½œä¸ºä¸‹ä¸€æ¬¡çš„è¾“å…¥ï¼Œå…·ä½“æ¥è¯´æ˜¯gumbel softmaxï¼›ç¬¬äºŒï¼Œè¯¥åˆ†å¸ƒä¸ä»…ä¼ å…¥åˆ°generatorä½œä¸ºä¸‹ä¸€æ¬¡çš„é¢„æµ‹ï¼ŒåŒæ—¶è¿˜ä¼ å…¥åˆ°è¯­è¨€æ¨¡å‹ï¼Œç”Ÿæˆçš„æ¦‚ç‡åˆ†å¸ƒä¸generatorçš„æ¦‚ç‡è®¡ç®—cross entropyä½œä¸ºlossã€‚</p>
<p>å®éªŒçš„ä¸€äº›å°trickï¼šlanguage modelæ›´å€¾å‘äºçŸ­å¥å­ï¼Œå› æ­¤å°†lossæŒ‰ç…§é•¿åº¦å½’ä¸€åŒ–ï¼ŒåŒæ—¶å›ºå®š$\tilde{x}$ä¸xçš„é•¿åº¦ä¸€è‡´ã€‚</p>
<p>æ€»ç»“ï¼šè¡Œæ–‡éå¸¸æµç•…ï¼Œè€Œä¸”ä¹Ÿæœ‰äº®ç‚¹ï¼Œç¡®å®ç”¨language modelæ›´è‡ªç„¶ã€‚</p>
<hr>
<h2 id="Unpaired-Sentiment-to-Sentiment-Translation-A-Cycled-Reinforcement-Learning-Approach"><a href="#Unpaired-Sentiment-to-Sentiment-Translation-A-Cycled-Reinforcement-Learning-Approach" class="headerlink" title="[Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach]"></a>[Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach]</h2><p>é€šè¿‡ä¸¤ä¸ªæ¨¡å—neutralizationå’Œemotionalizationç”Ÿæˆä¸åŒæƒ…æ„Ÿææ€§çš„å¥å­ï¼Œå‰è€…å°†å¥å­æ˜ å°„æˆæ²¡æœ‰æƒ…æ„Ÿçš„ä¸­æ€§å¥å­ï¼Œåè€…å°†ä¸­æ€§å¥å­æ˜ å°„æˆä¸åŒæƒ…æ„Ÿææ€§çš„å¥å­ã€‚åŒæ—¶é€šè¿‡RLçš„rewardå¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚</p>
<p><img src="/images/15721795128794.jpg" width="45%" height="50%"></p>
<p>ç¬¬ä¸€ï¼Œneutralizationæ¨¡å—é€šè¿‡ä¸€ä¸ªåˆ†ç±»å™¨çš„attention weightåˆ¤æ–­å“ªäº›è¯æ˜¯æœ‰æƒ…æ„Ÿææ€§çš„ï¼Œç„¶ååˆ æ‰ï¼›<br>ç¬¬äºŒï¼Œemotionalizationæ¨¡å—å°†åˆ æ‰è¯çš„å¥å­è¿‡ä¸€ä¸ªåŒå‘çš„LSTMï¼Œç„¶åè·å¾—ä¸€ä¸ªè¡¨ç¤ºæ•´ä¸ªå¥å­çš„è¡¨ç¤ºï¼Œè¾“å…¥åˆ°decoderä¸­ï¼Œå…¶ä¸­åˆ†åˆ«æœ‰ç”Ÿæˆæ­£å‘æƒ…æ„Ÿå’Œè´Ÿå‘æƒ…æ„Ÿçš„decoderã€‚<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸¤ä¸ªæ¨¡å—é€šè¿‡cycled RLè®­ç»ƒã€‚å…¶ä¸­rewardæœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯ç”Ÿæˆçš„å¥å­æ˜¯å¦ä¸æ‰€ç‰¹å®šçš„æƒ…æ„Ÿç›¸åŒï¼Œè¿™é€šè¿‡ä¸€ä¸ªé¢„è®­ç»ƒçš„åˆ†ç±»å™¨åˆ¤æ–­ï¼Œç¬¬äºŒåˆ™æ˜¯é€šè¿‡BLEUè¯„åˆ¤å†…å®¹ä¿ç•™çš„æƒ…å†µã€‚</p>
<p>ç»†èŠ‚ï¼š<br>â‘ å…·ä½“æ¥è¯´ï¼Œneutralizationæ¨¡å—çš„åšæ³•æ˜¯å…ˆé¢„è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œç„¶åä¸€ä¸ªå¥å­è¿‡ä¸€ä¸ªå•å‘çš„LSTMï¼Œæ‰€æœ‰hidden stateä¸æœ€åä¸€ä¸ªhidden stateï¼ˆè®¤ä¸ºæ˜¯ä¿ç•™äº†å¥å­çš„æ‰€æœ‰ä¿¡æ¯ï¼‰è®¡ç®—attention weightï¼Œå¤§äºå¹³å‡å€¼çš„attentionæ‰€å¯¹åº”çš„è¯å°±è¢«è®¤ä¸ºæ˜¯æƒ…æ„Ÿææ€§çš„è¯ã€‚<br>â‘¡neutralizationæ¨¡å—å’Œemotionalizationæ¨¡å—éƒ½æå‰ä¸è®­ç»ƒå¥½äº†ã€‚</p>
<p>æœ€ç»ˆçš„ç®—æ³•ï¼š</p>
<p><img src="/images/15721795998974.jpg" width="50%" height="50%"></p>
<hr>
<h2 id="Delete-Retrieve-Generate-A-Simple-Approach-to-Sentiment-and-Style-Transfer"><a href="#Delete-Retrieve-Generate-A-Simple-Approach-to-Sentiment-and-Style-Transfer" class="headerlink" title="[Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer]"></a>[Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer]</h2><p>style transferç›¸å…³ã€‚ä¸‰æ­¥èµ°ï¼šåˆ é™¤å…³é”®è¯ï¼›æŠ½å–å¯¹ç«‹styleå¥å­ï¼›ä»¥åŠç”Ÿæˆæ–°å¥å­ã€‚å¤§è‡´æ€è·¯æ˜¯å…ˆæŠ½å–ææ€§è¯ï¼Œç„¶åé€šè¿‡æ›¿æ¢æˆ–ç”Ÿæˆçš„æ–¹å¼å¾—åˆ°æ–°çš„å¥å­ã€‚</p>
<p><img src="/images/15721796925697.jpg" width="45%" height="50%"></p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p><img src="/images/15721797724438.jpg" width="70%" height="50%"></p>
<h4 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h4><p>é¦–å…ˆåˆ é™¤ï¼šè¯†åˆ«å‡ºè¾“å…¥ä¸­ä¸styleç›¸å…³çš„è¯ï¼Œåšæ³•æ˜¯ç›¸å¯¹é¢‘ç‡ï¼š</p>
<script type="math/tex; mode=display">s(u, v)=\frac{\operatorname{count}\left(u, \mathcal{D}_{v}\right)+\lambda}{\left(\sum_{v^{\prime} \in \mathcal{V}, v^{\prime} \neq v} \operatorname{count}\left(u, \mathcal{D}_{v^{\prime}}\right)\right)+\lambda}</script><p>ä¹Ÿå³å¦‚æœä¸€ä¸ªè¯åœ¨è¯¥styleçš„é¢‘ç‡å¯¹æ¯”åœ¨å¦ä¸€ä¸ªstyleçš„æ•°æ®çš„é¢‘ç‡é«˜äºä¸€ä¸ªé˜ˆå€¼åˆ™è®¤ä¸ºæ˜¯ä¸styleç›¸å…³çš„ã€‚</p>
<h4 id="Retrieve"><a href="#Retrieve" class="headerlink" title="Retrieve"></a>Retrieve</h4><p>è®°$a\left(x, v^{\mathrm{src}}\right)$ä¸ºåˆ é™¤æ‰çš„è¯çš„é›†åˆï¼Œä¹Ÿå³attribute markersã€‚å°†è¿™äº›è¯åˆ æ‰åçš„å¥å­ä¸º$c\left(x, v^{\mathrm{src}}\right)$ã€‚</p>
<p>åˆ©ç”¨$c\left(x, v^{\mathrm{src}}\right)$åœ¨target styleçš„æ•°æ®é›†ä¸Šæ‰¾ç±»ä¼¼çš„å¥å­ä½œä¸ºå‚è€ƒï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">x^{\mathrm{tgt}}=\underset{x^{\prime} \in \mathcal{D}_{v^{\mathrm{tgt}}}}{\operatorname{argmin}} d\left(c\left(x, v^{\mathrm{src}}\right), c\left(x^{\prime}, v^{\mathrm{tgt}}\right)\right)</script><p>$d$ä¹Ÿå³è®¡ç®—è·ç¦»çš„å‡½æ•°ã€‚</p>
<h4 id="Generate"><a href="#Generate" class="headerlink" title="Generate"></a>Generate</h4><p>æœ¬æ–‡æå‡ºå››ç§æ–¹æ³•</p>
<p>â‘ RETRIEVE ONLYï¼šç›´æ¥æŠŠå‰æ–‡æŠ½å–çš„å‚è€ƒå¥å­å½“åšè¾“å‡ºã€‚</p>
<p>â‘¡TEMPLATE BASEDï¼šç›´æ¥æ‹¿å‚è€ƒçš„å¥å­æ‰¾åˆ°ä»–çš„attribute markerç›´æ¥å¡«åˆ°å¯¹åº”ç©ºæ ¼ã€‚</p>
<p>â‘¢DELETE ONLYï¼šå°†å¥å­è¿‡RNNï¼Œè·å¾—ä¸€ä¸ªå•ä¸€çš„å¥å­å‘é‡ï¼Œè®¾ç½®å¯å­¦ä¹ çš„style embeddingï¼Œå°†ç›®æ ‡styleçš„embedding catåˆ°è¯¥å¥å­å‘é‡ä¸­ï¼Œç„¶åè¾“å…¥åˆ°å¦ä¸€ä¸ªRNNä¸­ç”Ÿæˆç›®æ ‡å¥å­ã€‚</p>
<p>â‘£DELETE AND RETRIEVEï¼šç±»ä¼¼ä¸Šé¢çš„ï¼Œä½†æ˜¯æ˜¯åˆ©ç”¨å‚è€ƒå¥å­çš„attribute markersè¿‡ä¸€ä¸ªRNNæå–ä¸€ä¸ªå‘é‡ï¼Œcatåˆ°æºå¥å­çš„å¥å­å‘é‡ï¼Œè¾“å…¥åˆ°å¦ä¸€ä¸ªRNNä¸­ç”Ÿæˆç›®æ ‡å¥å­ã€‚ç›¸æ¯”ä¸Šé¢çš„æ›´æœ‰æŒ‡å‘æ€§ã€‚</p>
<p>å…¶ä»–ç»†èŠ‚ï¼š<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ˜¯åˆ©ç”¨reconstructionæ¥åšçš„ã€‚</p>
<hr>
<h2 id="Progressive-Self-Supervised-Attention-Learning-for-Aspect-Level-Sentiment-Analysis"><a href="#Progressive-Self-Supervised-Attention-Learning-for-Aspect-Level-Sentiment-Analysis" class="headerlink" title="[Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis]"></a>[Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis]</h2><p>Motivationï¼šæ¨¡å‹å¸¸å¸¸èƒ½å¤Ÿè¯†åˆ«å‡ºé¢‘ç‡é«˜çš„æƒ…æ„Ÿææ€§è¯ï¼Œè€Œå¯¹é¢‘ç‡ä½çš„æƒ…æ„Ÿææ€§è¯åˆ™æ˜¯underfitçš„ã€‚è¿™é‡Œé€šè¿‡å¾ªç¯maskæ‰ææ€§çš„è¯ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè®­ç»ƒåˆ°é¢‘ç‡ä½çš„ææ€§è¯ã€‚å…·ä½“åšæ³•æ˜¯é€šè¿‡attentionçš„ç›‘ç£ä¿¡å·ã€‚</p>
<p>å…·ä½“åšæ³•ï¼šé€šè¿‡ä¸æ–­mask attention weightæœ€å¤§çš„è¯ï¼Œè§‚å¯Ÿåˆ†ç±»æ˜¯å¦å‡ºé”™ã€‚å¦‚æœå‡ºé”™ï¼Œåˆ™è¯´æ˜è¯¥è¯æ˜¯misleadingï¼Œæ¨¡å‹åº”è¯¥å‡å°è¯¥è¯çš„weightï¼›å¦‚æœåˆ†ç±»æ­£ç¡®ï¼Œè¯´æ˜è¯¥è¯åº”è¯¥åˆ†é…å¤§çš„weightï¼Œè®°ä¸ºactiveçš„è¯ã€‚é€šè¿‡æå–active å’Œmisleadingçš„è¯ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»™äºˆç›‘ç£ä¿¡å·/æ­£åˆ™åŒ–ï¼ˆattention weightçš„æ”¾å¤§æˆ–ç¼©å°ï¼‰ï¼Œè¿™æ ·èƒ½å¤Ÿè®©æ¨¡å‹æŒ–æ˜å‡ºé¢‘ç‡è¾ƒä½çš„è¯çš„æƒ…æ„Ÿææ€§è€Œä¸æ˜¯overfitåˆ°å¸¸ç”¨è¯çš„ææ€§ã€‚</p>
<p><img src="/images/15721805892169.jpg" width="80%" height="50%"></p>
<p><img src="/images/15721806118504.jpg" width="80%" height="50%"></p>
<hr>
<h2 id="SHAPED-Shared-Private-Encoder-Decoder-for-Text-Style-Adaptation"><a href="#SHAPED-Shared-Private-Encoder-Decoder-for-Text-Style-Adaptation" class="headerlink" title="[SHAPED: Shared-Private Encoder-Decoder for Text Style Adaptation]"></a>[SHAPED: Shared-Private Encoder-Decoder for Text Style Adaptation]</h2><p>é‡‡ç”¨äº†shard-privateçš„æ€æƒ³ã€‚share encoderç¼–ç ä¸styleæ— å…³çš„ç‰¹æ€§ï¼›privateåˆ™ç¼–ç styleç›¸å…³çš„ç‰¹æ€§ã€‚</p>
<p><img src="/images/15721806660683.jpg" width="50%" height="50%"></p>
<hr>
<h2 id="Style-Transfer-Through-Back-Translation"><a href="#Style-Transfer-Through-Back-Translation" class="headerlink" title="[Style Transfer Through Back-Translation]"></a>[Style Transfer Through Back-Translation]</h2><p>é€šè¿‡back translationä»¥å»é™¤style-specificçš„ä¿¡æ¯ã€‚åŸºäºå‡è®¾ï¼šé€šè¿‡back translationæ‰€è·å¾—latent representationæœ‰æ›´å°‘çš„style-specificä¿¡æ¯ã€‚</p>
<p><img src="/images/15721807128106.jpg" width="80%" height="50%"></p>
<p><img src="/images/15721807318957.jpg" width="70%" height="50%"></p>
<p>æœ‰ä¸¤ä¸ªlossï¼šä¸€ä¸ªæ˜¯reconstructionçš„lossï¼Œå¦ä¸€ä¸ªåˆ™æ˜¯discriminatorçš„lossã€‚è¿™é‡Œæœ‰ä¸¤ä¸ªdecoderã€‚</p>
<hr>
<h2 id="Fighting-Offensive-Language-on-Social-Media-with-Unsupervised-Text-Style-Transfer"><a href="#Fighting-Offensive-Language-on-Social-Media-with-Unsupervised-Text-Style-Transfer" class="headerlink" title="[Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer]"></a>[Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer]</h2><p>style transferç›¸å…³ã€‚</p>
<p><img src="/images/15721807750198.jpg" width="80%" height="50%"></p>
<p>lossï¼šä¸€ä¸ªreconstruction lossï¼Œä¹Ÿå³encoderçš„styleä¸decoderçš„styleä¸€è‡´ï¼›å¦‚æœä¸ä¸€è‡´ï¼Œåˆ™å†å°†è¯¥å¥å­é‡æ–°ä¼ å›åˆ°encoder decoderï¼Œå¹¶æä¾›åŸæ¥çš„styleå¹¶é‡æ–°ç”Ÿæˆå›å»ã€‚ç„¶åå°±æ˜¯discriminatorçš„lossäº†ã€‚</p>
<p>æ„Ÿè§‰å…¶å®æ²¡å•¥åˆ›æ–°ï¼ŒåŸºæœ¬ä¸Šéƒ½æ˜¯åˆ«äººåšè¿‡çš„ã€‚å”¯ä¸€çš„è´¡çŒ®å°±æ˜¯æäº†æ•°æ®é›†å§ã€‚</p>
<hr>
<h2 id="Disentangled-Representation-Learning-for-Non-Parallel-Text-Style-Transfer"><a href="#Disentangled-Representation-Learning-for-Non-Parallel-Text-Style-Transfer" class="headerlink" title="[Disentangled Representation Learning for Non-Parallel Text Style Transfer]"></a>[Disentangled Representation Learning for Non-Parallel Text Style Transfer]</h2><p>style transferç›¸å…³ã€‚ä»æ›´å¥½åˆ†ç¦»styleå’Œcontentçš„è§’åº¦å‡ºå‘è®¾è®¡äº†å‡ ä¸ªlossã€‚è¿™ç¯‡æŒºæœ‰å¯å‘æ€§çš„ã€‚</p>
<p>å…¶åšæ³•æ˜¯äººå·¥å°†latent representationåˆ†æˆä¸¤å—ï¼Œä¹Ÿå³ä¸åŒçš„å‘é‡ã€‚åœ¨inferenceæ—¶ï¼Œç›´æ¥å°†styleå¯¹åº”çš„å‘é‡æ›¿æ¢æˆå¦ä¸€ä¸ªstyleçš„å‘é‡å°±èƒ½åšåˆ°é£æ ¼è½¬æ¢ã€‚</p>
<p><img src="/images/15721809468995.jpg" width="50%" height="50%"></p>
<p>è®ºæ–‡æå‡ºäº†å‡ ä¸ªlossï¼š</p>
<p>â‘ autoencoding lossï¼Œä¹Ÿå³reconstructionçš„lossï¼Œä¸€ä¸ªencoderç”Ÿæˆlatent representationï¼Œç„¶ådecoderåˆ©ç”¨è¯¥latent representationé‡æ–°æ¢å¤åŸæ¥çš„å¥å­ã€‚</p>
<p>â‘¡Style-Oriented Lossesï¼šä¿è¯style spaceæœ‰styleä¿¡æ¯è€Œcontent spaceæ²¡æœ‰styleçš„ä¿¡æ¯ã€‚</p>
<p>â‘¢Content-Oriented Lossesï¼šä¿è¯content spaceæœ‰contentä¿¡æ¯è€Œstyle spaceæ²¡æœ‰contentçš„ä¿¡æ¯ã€‚</p>
<h3 id="Style-Oriented-Losses"><a href="#Style-Oriented-Losses" class="headerlink" title="Style-Oriented Losses"></a>Style-Oriented Losses</h3><h4 id="Multi-Task-Loss-for-Style"><a href="#Multi-Task-Loss-for-Style" class="headerlink" title="Multi-Task Loss for Style"></a>Multi-Task Loss for Style</h4><p>è®°$\boldsymbol{s}$ä¸ºstyleçš„representationï¼›$\boldsymbol{c}$ä»£è¡¨contentçš„representationã€‚</p>
<p>$\boldsymbol{y}_{s}=\operatorname{softmax}\left(W_{\operatorname{mul}(\mathrm{s})} \boldsymbol{s}+\boldsymbol{b}_{\mathrm{mul}(\mathrm{s})}\right)$</p>
<p>$J_{\mathrm{mul(s)}}\left(\boldsymbol{\theta}_{\mathrm{E}} ; \boldsymbol{\theta}_{\mathrm{mul}(\mathrm{s})}\right)=-\sum_{l \in \text { labels }} t_{s}(l) \log y_{s}(l)$</p>
<p>ä¹Ÿå³è®©åˆ†ç±»å™¨èƒ½å¤Ÿé€šè¿‡$\mathrm{s}$è¯†åˆ«å‡ºè¯¥latent representationçš„styleã€‚</p>
<h4 id="Adversarial-Loss-for-Style"><a href="#Adversarial-Loss-for-Style" class="headerlink" title="Adversarial Loss for Style"></a>Adversarial Loss for Style</h4><p>ä¸Šè¿°lossåªèƒ½ä¿è¯style spaceæœ‰styleçš„ä¿¡æ¯ï¼Œä¸èƒ½ä¿è¯contentæ²¡æœ‰styleä¿¡æ¯ã€‚</p>
<p>å› æ­¤ï¼š</p>
<p>$\boldsymbol{y}_{s}=\operatorname{softmax}\left(W_{\mathrm{dis}(\mathrm{s})} \boldsymbol{c}+\boldsymbol{b}_{\mathrm{dis}(\mathrm{s})}\right)$</p>
<p>$J_{\mathrm{dis}(\mathrm{s})}\left(\boldsymbol{\theta}_{\mathrm{dis}(\mathrm{s})}\right)=-\sum_{l \in \mathrm{labels}} t_{c}(l) \log y_{s}(l)$</p>
<p>ä¸ºäº†èƒ½å¤Ÿè®©æ¢¯åº¦ä¼ åˆ°åˆ°autoencoderï¼Œåˆ™autoencoderæœ€å¤§åŒ–ï¼š</p>
<script type="math/tex; mode=display">J_{\mathrm{adv}(\mathrm{s})}\left(\boldsymbol{\theta}_{\mathrm{E}}\right)=\mathcal{H}\left(\boldsymbol{y}_{s} | \boldsymbol{c} ; \boldsymbol{\theta}_{\mathrm{dis}(\mathrm{s})}\right)</script><p>å½“é¢„æµ‹çš„æ ‡ç­¾$\boldsymbol{y}_{s}$æ˜¯uniformçš„æ—¶å€™ï¼Œç›®æ ‡æœ€å¤§ï¼Œä¹Ÿå³å¸Œæœ›contentä¸­å…³äºstyleçš„å†…å®¹å°½é‡å°‘ï¼Œä½¿å¾—discriminatoræ— æ³•é€šè¿‡$\boldsymbol{c}$è¯†åˆ«å‡ºå¥å­çš„styleã€‚</p>
<h3 id="Content-Oriented-Losses"><a href="#Content-Oriented-Losses" class="headerlink" title="Content-Oriented Losses"></a>Content-Oriented Losses</h3><p>è¯¥losså¸Œæœ›contentçš„å†…å®¹ä¸ä¼šæ¸—é€åˆ°style spaceä¸­ã€‚åšæ³•æ˜¯å‘Šè¯‰æ¨¡å‹ï¼Œåº”å¦‚ä½•æ­£ç¡®ç¼–ç contentï¼Œä¹Ÿå³è¦å‘Šè¯‰æ¨¡å‹ï¼Œcontentåˆ°åº•æŒ‡çš„æ˜¯ä»€ä¹ˆã€‚</p>
<p>æœ¬æ–‡ç”¨äº†BoWçš„featureä½œä¸ºå¼•å¯¼æ¨¡å‹encodeçš„è¾…åŠ©ã€‚<br>BoWï¼šå¯¹äºä¸€ä¸ªå¥å­æœ‰Nä¸ªè¯çš„ï¼Œåˆ™è¯w*çš„BoWæ¦‚ç‡ä¸º$t_{c}\left(w_{}\right)=\frac{\sum_{i=1}^{N} \mathbb{I}\left\{w_{i}=w_{}\right\}}{N}$ã€‚æ³¨æ„è¿™é‡Œåªè€ƒè™‘content wordï¼Œä¹Ÿå³å»æ‰äº†åœç”¨è¯å’Œæƒ…æ„Ÿè¯ï¼ˆå¼•å…¥äº†å¤–éƒ¨è¯å…¸ï¼‰ã€‚</p>
<p>å› æ­¤æ‹Ÿåˆè¯¥encodingï¼š</p>
<p>$\boldsymbol{y}_{c}=\operatorname{softmax}\left(W_{\mathrm{mul}(\mathrm{c})} \boldsymbol{c}+\boldsymbol{b}_{\mathrm{mulc}}\right)$</p>
<p>$J_{\mathrm{mul(c)}}\left(\boldsymbol{\theta}_{\mathrm{E}} ; \boldsymbol{\theta}_{\mathrm{mul}(\mathrm{c})}\right)=-\sum_{w \in \text { vocab }} t_{c}(w) \log y_{c}(w)$</p>
<p>åŒæ ·ï¼Œå¸Œæœ›style spaceæ²¡æœ‰è¿™æ ·çš„ä¿¡æ¯ï¼š</p>
<p>$\begin{aligned} \boldsymbol{y}_{c}=&amp; \operatorname{softmax}\left(W_{\mathrm{dis}(\mathrm{c})}^{\top} \boldsymbol{s}+\boldsymbol{b}_{\mathrm{dis}(\mathrm{c})}\right) \\ J_{\mathrm{dis}(\mathrm{c})}\left(\boldsymbol{\theta}_{\mathrm{dis}(\mathrm{c})}\right) &amp;=-\sum_{w \in \text { vocab }} t_{c}(w) \log y_{c}(w) \\ J_{\mathrm{adv}(\mathrm{c})}\left(\boldsymbol{\theta}_{\mathrm{E}}\right) &amp;=\mathcal{H}\left(\boldsymbol{y}_{c} | \boldsymbol{s} ; \boldsymbol{\theta}_{\mathrm{dis}(\mathrm{c})}\right) \end{aligned}$</p>
<h3 id="å…¶ä»–ç»†èŠ‚"><a href="#å…¶ä»–ç»†èŠ‚" class="headerlink" title="å…¶ä»–ç»†èŠ‚"></a>å…¶ä»–ç»†èŠ‚</h3><p>â‘ å½“inferenceæ—¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥å°†styleçš„éƒ¨åˆ†æ›¿æ¢æˆå¦ä¸€ä¸ªstyleçš„latent representationï¼Œå…¶ä¸­å¦ä¸€ä¸ªstyleçš„latent representationæ˜¯è¿™æ ·å–å¾—çš„ï¼š</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{s}}=\frac{\sum_{i \in \text { target style }} \boldsymbol{s}_{i}}{\# \text { target style samples }}</script><p>ä¹Ÿå³å°†è®­ç»ƒé›†çš„æ‰€æœ‰ç›®æ ‡styleçš„såšä¸€ä¸ªå¹³å‡ã€‚</p>
<p>â‘¡åœ¨å®ç°ä¸­ï¼Œæ˜¯å°†hidden stateåˆ†åˆ«è¿‡ä¸¤ä¸ªå…¨è¿æ¥ä»¥è·å¾—è¿™ä¸¤ä¸ªlatent representationï¼Œæ¯”å¦‚hidden stateä¸º256ç»´ï¼Œè¿‡ä¸¤ä¸ªå…¨è¿æ¥è·å¾—sä¸º8ç»´ï¼Œcontentä¸º128ç»´ã€‚ç„¶ååœ¨decodeçš„æ—¶å€™å°†è¿™ä¸¤ä¸ªè¡¨ç¤ºæ‹¼èµ·æ¥$\boldsymbol{h}=[\boldsymbol{s}, \boldsymbol{c}]$ä¼ å…¥åˆ°decoderã€‚</p>
<p>â‘¢é€šè¿‡é™ç»´å¯ä»¥çœ‹åˆ°ç¡®å®åˆ†ç¦»å¾—ä¸é”™ï¼š</p>
<p><img src="/images/15721820144438.jpg" width="50%" height="50%"></p>
<hr>
<h2 id="æœ¬å‘¨è®ºæ–‡å°ç»“"><a href="#æœ¬å‘¨è®ºæ–‡å°ç»“" class="headerlink" title="[æœ¬å‘¨è®ºæ–‡å°ç»“]"></a>[æœ¬å‘¨è®ºæ–‡å°ç»“]</h2><p>æœ¬å‘¨çœ‹çš„åŸºæœ¬ä¸Šæ˜¯style transferçš„è®ºæ–‡ï¼Œå¤§æ¦‚ç®—æ˜¯å…¥é—¨äº†ã€‚æœ‰å‡ ç¯‡æ¯”è¾ƒäº®çœ¼çš„å¤–ï¼Œå…¶ä»–çš„ä¼¼ä¹noveltyéƒ½ä¸æ˜¯å¾ˆå¥½ã€‚ç”Ÿç—…äº†å¯¼è‡´è¿›åº¦æœ‰äº›æ…¢ï¼Œå¸Œæœ›ä¸‹å‘¨èƒ½åŸºæœ¬ä¸Šçœ‹å®Œstyle transferç»å…¸çš„è®ºæ–‡ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>style transfer</tag>
        <tag>åˆ†ç±»</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºhexoæ— æ³•æœç´¢çš„è¯¦ç»†è§£å†³æ–¹æ¡ˆ</title>
    <url>/2019/10/27/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%85%B3%E4%BA%8Ehexo%E6%97%A0%E6%B3%95%E6%90%9C%E7%B4%A2%E7%9A%84%E8%AF%A6%E7%BB%86%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>é‡åˆ°hexoæ— æ³•æœç´¢çš„é—®é¢˜å·²ç»å¥½é•¿æ—¶é—´äº†ï¼Œæ¯æ¬¡ç‚¹å‡»æœç´¢éƒ½ä¼šä¸€ç›´æ˜¾ç¤ºåŠ è½½çš„åœˆåœˆã€‚</p>
<p><img src="/images/15721451404498.png" width="50%" height="50%"><br>ï¼ˆå€Ÿç”¨å…¶ä»–åšå®¢[1]çš„ä¸€å¼ å›¾ï¼Œä¹‹å‰å¿˜äº†æˆªå›¾äº†ï¼‰</p>
<p>æœäº†ä¸€ä¸‹ç½‘ä¸Šçš„è§£å†³æ–¹æ¡ˆï¼Œå¤§æ¦‚æ˜ç™½äº†é—®é¢˜å‡ºåœ¨å“ªé‡Œï¼Œä½†æ˜¯å› ä¸ºç½‘ä¸Šçš„æ•™ç¨‹å¤šæœ‰äº›ç®€ç•¥ï¼Œä¹Ÿé¢‡èŠ±äº†ä¸€äº›åŠŸå¤«æ‰æœ€ç»ˆè§£å†³äº†è¯¥é—®é¢˜ã€‚å› æ­¤åœ¨è¿™é‡Œè¯¦ç»†è®°å½•ä¸€æ­¥ä¸€æ­¥å¦‚ä½•æ’é™¤é”™è¯¯ï¼Œæˆ–è®¸èƒ½å¤Ÿå¸®åŠ©æœ‰åŒæ ·é—®é¢˜çš„äººã€‚</p>
<h3 id="é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ"><a href="#é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ" class="headerlink" title="é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ"></a>é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ</h3><p>æ€»çš„æ¥è¯´ï¼Œé‡åˆ°ä»¥ä¸Šé•¿æ—¶é—´åŠ è½½çš„å¤§æ¦‚ç‡æ˜¯ç¼–ç ï¼ˆencoding)é—®é¢˜ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œè¦ä¿è¯æ­£ç¡®å®‰è£…äº†local searchçš„åŒ…ä»¥åŠåœ¨é…ç½®æ–‡ä»¶æ­£ç¡®æ‰“å¼€äº†æœç´¢åŠŸèƒ½ï¼ˆè¯¦ç»†è§ç½‘ä¸Šå…¶ä»–æ•™ç¨‹ï¼Œå¦‚[3]çš„ç¬¬ä¸€éƒ¨åˆ†ï¼‰ã€‚</p>
<p>å½“ä¿è¯äº†æ­£ç¡®é…ç½®çš„æƒ…å†µä¸‹ï¼Œè¿˜å‡ºç°è¯¥é—®é¢˜ã€‚é¦–å…ˆåœ¨Chromeä¸­è¿›å…¥search.xmlã€‚å…·ä½“ä¹Ÿå³è¿›å…¥ä½ ä¸ªäººçš„ç½‘ç«™çš„search.xmlé¡µé¢ www.yoursite.com/search.xml ã€‚è¯¥é¡µé¢æ˜¯æ”¯æŒæœç´¢åŠŸèƒ½çš„å…³é”®ã€‚</p>
<p><img src="/images/15721456793555.jpg" width="70%" height="50%"></p>
<p>è¿›å…¥åˆ°xmlæ–‡ä»¶åå‘ç°è¯¥é¡µé¢å­˜åœ¨é”™è¯¯ã€‚ä»é”™è¯¯æç¤ºå¯ä»¥çœ‹åˆ°æ˜¯ç¼–ç é”™è¯¯ã€‚</p>
<p>æ¥ä¸‹æ¥å³é”®è¿›å…¥inspectï¼š</p>
<p><img src="/images/15721458451242.jpg" width="80%" height="50%"></p>
<p>è¿›å…¥åˆ°å®¡æŸ¥ç•Œé¢ï¼š</p>
<p><img src="/images/15721458811230.jpg" width="90%" height="50%"></p>
<p>é€‰æ‹©Networké€‰é¡¹å¡ï¼š</p>
<p><img src="/images/15721459320994.jpg" width="90%" height="50%"></p>
<p>æ­¤æ—¶éœ€è¦é‡æ–°åˆ·æ–°é¡µé¢æ‰èƒ½è·å¾—è¿”å›åŒ…ã€‚æŒ‰åˆ·æ–°æŒ‰é’®æˆ–è€…command+Rã€‚ç‚¹æŒ‰search.xmlï¼Œæ­¤æ—¶è¿›å…¥é¡µé¢ï¼š</p>
<p><img src="/images/15721459875362.jpg" width="90%" height="50%"></p>
<p>æ³¨æ„æœ€å¼€å§‹çš„æ—¶å€™é”™è¯¯æç¤ºå‘Šè¯‰æˆ‘ä»¬åœ¨ç¬¬å‡ è¡Œæœ‰é”™è¯¯ï¼š</p>
<p><img src="/images/15721460622123.jpg" width="90%" height="50%"></p>
<p>æ‰€ä»¥æˆ‘ä»¬åœ¨â‘¡å¤„å®šä½åˆ°æ”¹è¡Œï¼Œå¯èƒ½è¯¥è¡Œå†…å®¹å¾ˆé•¿å¾ˆé•¿ï¼Œè€å¿ƒä¸€ç‚¹çœ‹è¿‡å»ï¼Œæ‰¾åˆ°çº¢è‰²ç‚¹ï¼ŒæŠŠé¼ æ ‡ç§»ä¸Šå»å¯ä»¥çœ‹åˆ°ï¼š</p>
<p><img src="/images/15721461320868.jpg" width="30%" height="50%"></p>
<p>é‚£ä¹ˆè¿™æ—¶å€™å°±å¯ä»¥é€šè¿‡æœç´¢å®šä½åˆ°è¿™ç¯‡åšæ–‡äº†ã€‚æ³¨æ„è¦ç”¨sublime/vscodeæ‰“å¼€è¯¥åšæ–‡ï¼Œå…¶ä»–æ™®é€šçš„ç¼–è¾‘å™¨å¯èƒ½æ²¡åŠæ³•çœ‹åˆ°è¯¥å­—ç¬¦ã€‚</p>
<p><img src="/images/15721462218733.jpg" width="40%" height="50%"></p>
<p>å¯ä»¥çœ‹åˆ°ä¸çŸ¥é“ä¸ºä»€ä¹ˆåœ¨è¿™é‡Œå¼•å…¥äº†ä¸¤ä¸ªç‰¹æ®Šå­—ç¬¦ã€‚</p>
<p>æ­¤æ—¶ç”¨sublimeæ‰“å¼€æ‰€æœ‰åšå®¢æ‰€å­˜çš„æ–‡ä»¶å¤¹ï¼ˆæˆ‘çš„æ˜¯_postï¼‰ï¼Œç„¶åå…¨å±€æ›¿æ¢è¯¥ç‰¹æ®Šå­—ç¬¦ä¸ºç©ºå°±å¯ä»¥äº†ã€‚æ³¨æ„åˆ°æ›¿æ¢æ—¶æœç´¢çš„ç›®æ ‡æ˜¯<0x10>å­—ç¬¦ï¼Œè€Œè¯¥å­—ç¬¦æ˜¯ä¸€ä¸ªå•å­—ç¬¦ï¼Œè€Œä¸æ˜¯ç”±&lt; 0 x 1 0 &gt;ç»„æˆçš„ã€‚æ‰€ä»¥å¦‚æœç›´æ¥ç”¨é”®ç›˜è¾“å…¥è¿›å»æ˜¯æ²¡ç”¨çš„ï¼Œåªèƒ½ç›´æ¥å¤åˆ¶è¯¥å­—ç¬¦ã€‚</0x10></p>
<p>å…¨å±€æ›¿æ¢ï¼š</p>
<p><img src="/images/15721464581229.jpg" width="80%" height="50%"></p>
<p>è‡³äºä¸ºå•¥ä¼šå¼•å…¥è¿™ä¸ªç¬¦å·ï¼Œæ€€ç–‘æ˜¯å¤åˆ¶å…¶ä»–æ–‡æ¡£çš„æ—¶å€™ä¸å°å¿ƒå¼•å…¥çš„ã€‚</p>
<p>å‘ç°åˆ æ‰äº†è¿™ä¸ªè¿˜ä¸å¤Ÿï¼Œåº”è¯¥æ¥è¯´è¿˜æœ‰å…¶ä»–çš„ã€‚æ¯”å¦‚æˆ‘åˆ å®Œå†çœ‹ï¼Œè¿˜æœ‰ï¼š</p>
<p><img src="/images/15721464959511.jpg" width="80%" height="50%"></p>
<p>å®šä½åˆ°å…·ä½“ä½ç½®ï¼š</p>
<p><img src="/images/15721465152031.jpg" width="30%" height="50%"></p>
<p>æ²¡å¾—åŠæ³•ï¼Œåªèƒ½ä¸€ä¸ªä¸€ä¸ªåˆ äº†ï¼Œç›´åˆ°search.xmlä¸å†å‡ºç°é”™è¯¯ï¼š</p>
<p><img src="/images/15721465322486.jpg" width="90%" height="50%"></p>
<p>æœ€ç»ˆï¼Œæœç´¢æ¡†ç»ˆäºå¯ä»¥è°ƒå‡ºäº†ï¼š</p>
<p><img src="/images/15721465579024.jpg" width="60%" height="50%"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://www.itfanr.cc/2017/11/24/resolve-hexo-blog-search-exception/" target="_blank" rel="noopener">https://www.itfanr.cc/2017/11/24/resolve-hexo-blog-search-exception/</a><br>[2] <a href="https://juejin.im/post/5c85c5b7e51d45576e3cc9a5" target="_blank" rel="noopener">https://juejin.im/post/5c85c5b7e51d45576e3cc9a5</a><br>[3] <a href="https://www.sqlsec.com/2017/12/hexosearch.html" target="_blank" rel="noopener">https://www.sqlsec.com/2017/12/hexosearch.html</a></p>
]]></content>
      <tags>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>hexo</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡32</title>
    <url>/2019/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8732/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Incremental Parsing with the Perceptron Algorithm</li>
<li>Iterative Dual Domain Adaptation for Neural Machine Translation</li>
<li>Classical Structured Prediction Losses for Sequence to Sequence Learning</li>
<li>Learning as Search Optimization: Approximate Large Margin Methods for Structured Prediction</li>
<li>Professor Forcing: A New Algorithm for Training Recurrent Networks</li>
<li>Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation</li>
<li>Style Transfer from Non-Parallel Text by Cross-Alignment</li>
</ol>
<h2 id="Incremental-Parsing-with-the-Perceptron-Algorithm"><a href="#Incremental-Parsing-with-the-Perceptron-Algorithm" class="headerlink" title="[Incremental Parsing with the Perceptron Algorithm]"></a>[Incremental Parsing with the Perceptron Algorithm]</h2><p>æ—©æœŸearly updateçš„è®ºæ–‡ã€‚åœ¨seq2seq/structured learningä»»åŠ¡ä¸­ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å½“é‡åˆ°ä¸æ˜¯golden truthæ—¶å€™å°±æå‰åœæ­¢ï¼Œç›´æ¥æ›´æ–°å‚æ•°ã€‚</p>
<p><img src="/images/15715350372832.jpg" width="70%" height="50%"></p>
<hr>
<h2 id="Iterative-Dual-Domain-Adaptation-for-Neural-Machine-Translation"><a href="#Iterative-Dual-Domain-Adaptation-for-Neural-Machine-Translation" class="headerlink" title="[Iterative Dual Domain Adaptation for Neural Machine Translation]"></a>[Iterative Dual Domain Adaptation for Neural Machine Translation]</h2><p>è®¨è®ºäº†ä¸€ç§domain adaptationçš„åšæ³•ã€‚ä¸ä¼ ç»Ÿdomain adaptationåœ¨out domainè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œåœ¨in domainæ•°æ®ä¸Šfine-tuneå¾—åˆ°æœ€ç»ˆçš„æ¨¡å‹ä¸åŒï¼Œæœ¬æ–‡çš„åšæ³•æ˜¯ï¼šåœ¨in domainå’Œout domainä¹‹é—´æ¥å›è¿ç§»ï¼ŒåŒæ—¶è¿˜ä¿ç•™è¿‡å»é˜¶æ®µçš„æœ€ä¼˜æ¨¡å‹ï¼Œé‡‡ç”¨knowledge distillationæå–æœ‰ç”¨ä¿¡æ¯ä»¥å¸®åŠ©å½“å‰æ¨¡å‹çš„è®­ç»ƒã€‚æ¥å›è¿ç§»çš„motivationæ˜¯èƒ½æ›´å¥½ä¿ç•™<strong>domain-shared</strong>çš„çŸ¥è¯†ã€‚</p>
<p><img src="/images/15715351353551.jpg" width="80%" height="50%"></p>
<p><img src="/images/15715351517163.jpg" width="90%" height="50%"></p>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¸ä»…è¦æœ€å°åŒ–è®­ç»ƒé›†çš„è¯¯å·®ï¼ŒåŒæ—¶è¿˜è¦æ‹Ÿåˆä¸Šä¸ªbestæ¨¡å‹çš„è¾“å‡ºã€‚</p>
<script type="math/tex; mode=display">\begin{aligned} \mathcal{L}_{i n}^{(k)}=& \sum_{(\mathbf{x}, \mathbf{y}) \in D_{i n}}\left[-(1-\lambda) \cdot \log P\left(\mathbf{y} | \mathbf{x} ; \theta_{i n}^{(k)}\right)+\right.\\ &\left.\lambda \cdot \operatorname{KL}\left(P\left(\mathbf{y} | \mathbf{x} ; \theta_{i n}^{(k)}\right) \| P\left(\mathbf{y} | \mathbf{x} ; \theta_{i n}^{*}\right)\right)\right] \end{aligned}</script><hr>
<h2 id="Classical-Structured-Prediction-Losses-for-Sequence-to-Sequence-Learning"><a href="#Classical-Structured-Prediction-Losses-for-Sequence-to-Sequence-Learning" class="headerlink" title="[Classical Structured Prediction Losses for Sequence to Sequence Learning]"></a>[Classical Structured Prediction Losses for Sequence to Sequence Learning]</h2><p>æ·±å…¥æ¢è®¨äº†å„ç§ç»å…¸structured learningçš„lossåœ¨NN-basedçš„ç”Ÿæˆä»»åŠ¡ä¸‹çš„æ•ˆæœã€‚ç»“è®ºæ˜¯ä¼ ç»Ÿçš„è¿™äº›lossä»ç„¶å…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚</p>
<p>è®ºæ–‡ä¸€å…±æåˆ°å‡ ç§lossï¼š</p>
<p><img src="/images/15715353551772.jpg" width="80%" height="50%"></p>
<p>$\mathbf{x}$æ˜¯source sentenceï¼›$\mathbf{u}$æ˜¯æ¨¡å‹ç”Ÿæˆçš„å¥å­ï¼›$\mathbf{t}$æ˜¯referenceã€‚</p>
<p>å…¬å¼1æ˜¯æ™®é€šçš„teacher forcingçš„lossï¼›å…¬å¼2æ˜¯label smoothingä¹‹åçš„lossã€‚<br>å…¬å¼3æ˜¯sentence-levelçš„lossï¼Œå…¶ä¸­$\mathbf{u}^*$æ˜¯æŒ‡ä¸referenceè®¡ç®—åæœ€é«˜çš„candidateã€‚å…¬å¼çš„æ„æ€ä¹Ÿå³æœ€å¤§åŒ–$\mathbf{u}^*$çš„æ¦‚ç‡è€Œæœ€å°åŒ–å…¶ä»–çš„æ¦‚ç‡ï¼Œæˆ–è€…è¯´å¸Œæœ›è¯¥$\mathbf{u}^*$ä¸å…¶ä»–candidateä¹‹é—´æœ‰è¾ƒå¤§å·®å¼‚marginã€‚</p>
<p>å…¬å¼4çš„costæ˜¯$\operatorname{cost}(\mathbf{t}, \mathbf{u})=1-\mathrm{BLEU}(\mathbf{t}, \mathbf{u})$ï¼›ä¹Ÿå³æœ€å°åŒ–é‚£äº›bleuå°çš„ã€‚ç›¸å¯¹å…¬å¼3è€Œè¨€ï¼Œèƒ½å¤Ÿæé«˜å¤šä¸ªcostå°çš„candidateçš„æ¦‚ç‡ï¼Œè€Œå…¬å¼3åªèƒ½focusåœ¨ä¸€ä¸ªsequenceã€‚</p>
<p>å…¬å¼5å¼ºè¿«modelä¸­æœ€é«˜åˆ†æ•°ï¼ˆä¹Ÿå³æ¦‚ç‡æœ€é«˜çš„ï¼‰$\hat{\mathbf{u}}$ä¸å®é™…ä¸Šå’Œreferenceç›¸ä¼¼åº¦æœ€é«˜çš„$\mathbf{u}^*$ä¹‹é—´è¦æœ‰marginã€‚</p>
<p>å…¬å¼6æ˜¯å¯¹5çš„æ”¹è¿›ï¼Œå¸Œæœ›èƒ½å¤Ÿfocusåˆ°å¤šä¸ªcandidateã€‚</p>
<p>å…¬å¼7æ˜¯å¯¹seqNLLçš„æ”¹è¿›ï¼Œç›´è§‚ä¸Šæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿæ ¹æ®costçš„å¤§å°å»æ”¾å¤§æˆ–ç¼©å°lossã€‚</p>
<p>è®ºæ–‡è¿˜æåˆ°å°†token-levelå’Œsequence-levelçš„ç»“åˆæ–¹æ³•ï¼š</p>
<p>â‘ weighted</p>
<p>$\mathcal{L}_{\text {Weighted }}=\alpha \mathcal{L}_{\text {TokLS }}+(1-\alpha) \mathcal{L}_{\text {Risk }}$</p>
<p>â‘¡å…ˆç”¨token-level pretrainï¼Œç„¶åç”¨sequence-level fine-tune</p>
<p>$\mathcal{L}_{\text {constrained }}=\left\{\begin{array}{ll}{\mathcal{L}_{\text {Risk }}} &amp; {\mathcal{L}_{\text {TokLs }} \leq \mathcal{L}_{\text {TokLS }}^{b}} \\ {\mathcal{L}_{\text {TokLs }}} &amp; {\text { otherwise }}\end{array}\right.$</p>
<p>å®éªŒçš„å‡ ä¸ªç»“è®ºï¼š</p>
<p>â‘ sequence-levelçš„lossæ¯”æ‰€æœ‰çš„token-levelçš„lossæ›´å¥½ï¼š</p>
<p><img src="/images/15715358862970.jpg" width="40%" height="50%"></p>
<p>â‘¡sequence-levelå’Œtoken-levelç»“åˆçš„lossä¼šæ¯”å•ç‹¬ç”¨æ›´å¥½ï¼š</p>
<p><img src="/images/15715359137599.jpg" width="40%" height="50%"><br>å…¶ä¸­weightedçš„ä¼šconstrainedçš„æ›´å¥½ã€‚</p>
<p>â‘¢å¯¹äºpretrainå†fine-tuneçš„æ–¹æ³•ï¼Œå¯¹æ¯”ä½¿ç”¨label-smoothingå’Œä¸ä½¿ç”¨LSçš„æ¨¡å‹ä½œä¸ºåˆå§‹åŒ–ï¼Œä½¿ç”¨LSçš„æ¨¡å‹åœ¨åˆå§‹é˜¶æ®µperformanceæ›´é«˜ï¼›åŒæ—¶åœ¨fine-tuneåçš„æå‡ä¹Ÿæ›´å¤§ã€‚</p>
<p><img src="/images/15715359541812.jpg" width="40%" height="50%"></p>
<p>â‘£åœ¨ç”Ÿæˆcandidateè¿‡ç¨‹ä¸­æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯beam searchï¼Œå¦ä¸€ç§æ˜¯sampleã€‚beam searchçš„è¡¨ç°æ€»æ˜¯æ›´å¥½</p>
<p><img src="/images/15715359771917.jpg" width="50%" height="50%"></p>
<p>â‘¤Riskä¸BSOçš„å¯¹æ¯”ï¼šRiskæ›´ä¼˜ã€‚</p>
<p><img src="/images/15715360031714.jpg" width="40%" height="50%"></p>
<hr>
<h2 id="Learning-as-Search-Optimization-Approximate-Large-Margin-Methods-for-Structured-Prediction"><a href="#Learning-as-Search-Optimization-Approximate-Large-Margin-Methods-for-Structured-Prediction" class="headerlink" title="[Learning as Search Optimization: Approximate Large Margin Methods for Structured Prediction]"></a>[Learning as Search Optimization: Approximate Large Margin Methods for Structured Prediction]</h2><p>BSOçš„æ—©æœŸç‰ˆæœ¬ã€‚</p>
<p>åŸºæœ¬æ€æƒ³æ˜¯ï¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¦‚æœé‡åˆ°æ­£ç¡®çš„yä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œåˆ™æ›´æ–°å‚æ•°ï¼Œæ›´æ–°æ–¹æ³•æ˜¯æ­£ç¡®çš„å’Œé”™è¯¯çš„ç›¸å‡ï¼ŒåŒæ—¶æ¸…ç©ºqueueï¼Œé‡æ–°æ’å…¥æ­£ç¡®çš„yå†ç»§ç»­ç”Ÿæˆã€‚</p>
<p><img src="/images/15715360816007.jpg" width="60%" height="50%"></p>
<p>å‚æ•°æ›´æ–°ï¼š</p>
<script type="math/tex; mode=display">\Delta=\sum_{n \in s i b s} \frac{\mathbf{\Phi}(x, n)}{|s i b s|}-\sum_{n \in n o d e s} \frac{\mathbf{\Phi}(x, n)}{|n o d e s|}</script><hr>
<h2 id="Professor-Forcing-A-New-Algorithm-for-Training-Recurrent-Networks"><a href="#Professor-Forcing-A-New-Algorithm-for-Training-Recurrent-Networks" class="headerlink" title="[Professor Forcing: A New Algorithm for Training Recurrent Networks]"></a>[Professor Forcing: A New Algorithm for Training Recurrent Networks]</h2><p>é€šè¿‡GANè®­ç»ƒRNNã€‚å…·ä½“æ“ä½œæ˜¯åˆ©ç”¨GANå¼ºè¿«æ¨¡å‹å‡å°‘ teacher forcingå’Œself-generated è¡Œä¸ºçš„å·®å¼‚ã€‚è¿™æ ·å¯ä»¥ç¼“è§£exposure biasï¼ŒåŒæ—¶è¿˜èƒ½å¤Ÿå¸®åŠ©æ¨¡å‹å»ºæ¨¡é•¿ç¨‹ä¾èµ–ã€‚</p>
<p><img src="/images/15715365606455.jpg" width="70%" height="50%"></p>
<p>å…·ä½“åšæ³•ï¼šä¸€ä¸ªRNNè·‘teacher forcingä»¥åŠfree runningç”Ÿæˆä¸¤ä¸ªå¥å­ï¼Œå¦ä¸€ä¸ªåŒå‘RNNå°†ç”Ÿæˆå‡ºæ¥çš„å¥å­/hidden stateï¼Œè¿‡ä¸€éRNNå°†hidden stateæ‹¼èµ·æ¥ä½œä¸ºè¾“å‡ºä¼ å…¥åˆ°discriminatorã€‚</p>
<hr>
<h2 id="Style-Transformer-Unpaired-Text-Style-Transfer-without-Disentangled-Latent-Representation"><a href="#Style-Transformer-Unpaired-Text-Style-Transfer-without-Disentangled-Latent-Representation" class="headerlink" title="[Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation]"></a>[Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation]</h2><p>æå‡ºä¸€ç§style transferçš„æ–¹æ³•ã€‚å»æ‰latent variableï¼Œç›´æ¥ç”¨transformerå»ºæ¨¡ã€‚åŒæ—¶åœ¨è®­ç»ƒæ–¹æ³•ä¸Šä¹Ÿæœ‰åˆ›æ–°ã€‚</p>
<p>ä¼ ç»Ÿæ–¹æ³•ï¼šencoder-decoderç»“æ„ã€‚encoderå°†æ–‡æœ¬æ˜ å°„ä¸ºstyle-independentçš„latent representationï¼›decoderé€šè¿‡è¯¥representationåŠ ä¸Šä¸€ä¸ªstyle variableç”Ÿæˆç›®æ ‡sequenceã€‚è¿™äº›æ–¹æ³•éƒ½ä¸“æ³¨äºå¦‚ä½•åœ¨éšç©ºé—´åˆ†ç¦»style-independentå†…å®¹å’Œstyleæœ¬èº«ã€‚</p>
<p>ä½†è¿™ç§æ–¹æ³•æœ‰å‡ ä¸ªé—®é¢˜ï¼š<br>éš¾ä»¥åˆ¤æ–­åˆ†ç¦»çš„æƒ…å†µï¼›è¿™ç§åˆ†ç¦»ä¼¼ä¹æ²¡æœ‰å¿…è¦ï¼Œå› ä¸ºdecoderå¯ä»¥é€šè¿‡ç›´æ¥overwriteråŸå…ˆçš„styleä»æœªåˆ†ç¦»çš„latent representationä¸­ç”Ÿæˆæƒ³è¦çš„styleï¼Œï¼›å‘é‡è¡¨ç¤ºçš„limited capacityï¼Œå¹¶ä¸èƒ½å¾ˆå¥½ä¿å­˜ä¸°å¯Œçš„ä¿¡æ¯ï¼›æ‰€æœ‰ç°å­˜çš„æ–¹æ³•éƒ½å‡è®¾è¾“å…¥å¥å­é€šè¿‡ä¸€ä¸ªå›ºå®šå¤§å°çš„latent vector encodeï¼Œæ²¡åŠæ³•ç›´æ¥ç”¨attentionï¼›ç°å­˜çš„æ–¹æ³•éƒ½é‡‡ç”¨RNNï¼Œéš¾ä»¥æ•è·åˆ°é•¿ç¨‹ä¾èµ–ã€‚</p>
<p>æœ¬æ–‡ç›´æ¥å¯¹å¥å­å»ºæ¨¡è€Œä¸é‡‡ç”¨latent representationçš„æ–¹æ¡ˆï¼›ç›´æ¥ä½¿ç”¨transformerè§£å†³é•¿ç¨‹ä¾èµ–é—®é¢˜ï¼›åœ¨è®­ç»ƒæ–¹æ³•ä¸Šä¹Ÿæœ‰æ‰€åˆ›æ–°ã€‚</p>
<p>ä¼ ç»Ÿæ–¹æ³•ä¸æœ¬æ–‡æå‡ºçš„æ–¹æ³•çš„å¯¹æ¯”ï¼šä¼ ç»Ÿæ–¹æ³•æ˜¯åœ¨encodeæ—¶å°†ç”Ÿæˆçš„vectoråˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯contentä¸€ä¸ªæ˜¯styleï¼Œç„¶åé€šè¿‡æ›¿æ¢styleï¼Œå†ç”¨decodeå»ç”Ÿæˆyï¼›è€Œåœ¨transformeræ˜¯ç›´æ¥åœ¨å¥å­å‰é¢æ’å…¥ä¸€ä¸ªstyleçš„è¡¨ç¤ºã€‚</p>
<p><img src="/images/15715367458802.jpg" width="50%" height="50%"></p>
<p>Notation:<br>è®°$\left\{\mathcal{D}_{i}\right\}_{i=1}^{K}$ä¸ºæ‹¥æœ‰Kä¸ªstyleçš„æ•°æ®é›†ï¼›å…¶ä¸­$\mathbf{s}^{(i)}$ä¸ºç¬¬iä¸ªstyleï¼›åˆ™style transferçš„å®šä¹‰ï¼šç»™å®šä»»æ„ä¸€ä¸ªå¥å­$\mathbf{x}$ï¼Œä»¥åŠä¸€ä¸ªæƒ³è¦çš„style $\widehat{\mathbf{s}} \in\left\{\mathbf{s}^{(i)}\right\}_{i=1}^{K}$ï¼Œèƒ½å¤Ÿç”Ÿæˆæ–°çš„$\hat{\mathbf{x}}$ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿å­˜æ›´å¤šçš„$\mathbf{x}$çš„ä¿¡æ¯ã€‚è®°$f_{\theta}(\mathbf{x}, \mathbf{s})$ä¸ºæ˜ å°„å‡½æ•°ï¼Œå°†$\mathbf{x}$æ˜ å°„æˆ$\mathbf{s}$çš„$\hat{\mathbf{x}}$ã€‚</p>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p>åœ¨style transformerä¸­ï¼Œencoderå°†$\mathbf{x}=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$ encodeæˆ$\mathbf{z}=\left(z_{1}, z_{2}, \ldots, z_{n}\right)$ï¼Œè€Œdecoderåˆ™é€šè¿‡autoregressiveçš„æ–¹å¼ç”Ÿæˆ$\mathbf{y}=\left(y_{1}, y_{2}, \dots, y_{n}\right)$ã€‚å½¢å¼åŒ–ä¸ºï¼š</p>
<script type="math/tex; mode=display">p_{\theta}(\mathbf{y} | \mathbf{x})=\prod_{t=1}^{m} p_{\theta}\left(y_{t} | \mathbf{z}, y_{1}, \ldots, y_{t-1}\right)</script><p>ä¸ºäº†ä¿è¯æœ‰style controlï¼Œåœ¨è¾“å…¥å‰é¢æ·»åŠ ä¸€ä¸ªstyleçš„embeddingã€‚</p>
<p>ç”±äºä¸å­˜åœ¨å¹³è¡Œè¯­æ–™ï¼Œå› æ­¤é€šè¿‡discriminatoræ¥åšç›‘ç£ã€‚ä¹Ÿå³ç”¨discriminatoræ¥åˆ¤æ–­æºå¥å­çš„styleå’Œç”Ÿæˆå¥å­çš„styleçš„ä¸åŒã€‚è¯¥discriminatorä¹Ÿæ˜¯ä¸€ä¸ªtransformer encoderï¼Œå°è¯•å­¦ä¼šåˆ†è¾¨ä¸åŒstyleçš„å¥å­ï¼Œè€Œç”Ÿæˆå™¨åˆ™å°è¯•å»æœ€å¤§åŒ–discriminatorå¯¹æ‰€åœ¨styleçš„åˆ¤åˆ«æ¦‚ç‡ã€‚</p>
<p>æœ¬æ–‡æå‡ºäº†ä¸¤ç§discriminatorï¼š<br>â‘ conditional discriminatorï¼šæ¯æ¬¡è¾“å…¥$\mathbf{x}$å’Œ$\mathbf{s}$ï¼Œåˆ¤åˆ«å™¨$d_{\phi}(\mathbf{x}, \mathbf{s})$è¦æ±‚å›ç­”$\mathbf{x}$å’Œæ˜¯ä¸æ˜¯å¯¹åº”$\mathbf{s}$çš„styleã€‚</p>
<p>â‘¡Multi-class Discriminatorï¼š<br>åªè¾“å…¥$\mathbf{x}$ï¼Œåˆ¤åˆ«å™¨$d_{\phi}(\mathbf{x})$è¦æ±‚å›ç­”æ˜¯å“ªä¸ªstyleã€‚</p>
<h4 id="è®­ç»ƒæ–¹æ³•"><a href="#è®­ç»ƒæ–¹æ³•" class="headerlink" title="è®­ç»ƒæ–¹æ³•"></a>è®­ç»ƒæ–¹æ³•</h4><h5 id="Discriminator-Learning"><a href="#Discriminator-Learning" class="headerlink" title="Discriminator Learning"></a>Discriminator Learning</h5><p>ä¸»è¦æ˜¯è®­ç»ƒè¾¨åˆ«åŸå§‹è¾“å…¥$\mathbf{x}$ä»¥åŠreconstructedçš„è¾“å…¥$\mathbf{y}$å’Œ$\widehat{\mathbf{y}}=f_{\theta}(\mathbf{x}, \widehat{\mathbf{s}})$ä¹‹é—´çš„å·®å¼‚ã€‚å…¶ä¸­$\widehat{\mathbf{y}}$æ˜¯$\mathbf{x}$åŠ ä¸Šå¦ä¸€ä¸ªä¸åŒçš„styleæ‰€ç”Ÿæˆçš„å¥å­ã€‚è€Œreconstructed $\mathbf{y}$åˆ™æ˜¯åœ¨è¾“å…¥$\mathbf{x}$ä»¥åŠç›¸å¯¹åº”çš„styleçš„æƒ…å†µä¸‹é‡å»ºç›¸åŒstyleçš„å¥å­ã€‚</p>
<p>Discriminator Learningçš„ç®—æ³•ï¼š</p>
<p><img src="/images/15715377655239.jpg" width="60%" height="50%"></p>
<h5 id="Style-Transformer-Learning"><a href="#Style-Transformer-Learning" class="headerlink" title="Style Transformer Learning"></a>Style Transformer Learning</h5><p>ä¸åŒcaseçš„$f_{\theta}(\mathbf{x}, \widehat{\mathbf{s}})$æœ‰ä¸åŒç®—æ³•ã€‚ä¸€å…±æœ‰ä¸¤ç§caseï¼Œ$\mathbf{s}=\widehat{\mathbf{s}}$ or $\mathbf{s} \neq \widehat{\mathbf{s}}$</p>
<p>å¦‚æœ$\mathbf{s}=\widehat{\mathbf{s}}$ï¼Œä¹Ÿå³è¾“å…¥çš„styleå’Œ$\mathbf{x}$åŸå…ˆçš„styleæ˜¯ä¸€è‡´çš„ï¼Œåˆ™æˆ‘ä»¬å¸Œæœ›style transformerèƒ½å¤Ÿé‡å»ºè¯¥å¥å­ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}_{self}(\theta)=-p_{\theta}(\mathbf{y}=\mathbf{x} | \mathbf{x}, \mathbf{s})</script><p>å¦‚æœ$\mathbf{s} \neq \widehat{\mathbf{s}}$ï¼Œåˆ™æœ‰ä¸¤ä¸ªlossï¼š</p>
<p>â‘ Cycle Reconstructionï¼šå¸Œæœ›æ¨¡å‹å°½å¯èƒ½ä¿å­˜åŸå§‹è¾“å…¥$\mathbf{x}$çš„ä¿¡æ¯ï¼Œé‚£ä¹ˆå°†ç”Ÿæˆçš„$\widehat{\mathbf{y}}$é‡æ–°è¾“å…¥è¿›æ¨¡å‹ä¸­ï¼Œä¸”ç»™å®š$\mathbf{x}$çš„styleï¼Œå¸Œæœ›èƒ½å¤Ÿé‡å»ºå›åŸå…ˆçš„$\mathbf{x}$ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}_{c y c l e}(\theta)=-p_{\theta}\left(\mathbf{y}=\mathbf{x} | f_{\theta}(\mathbf{x}, \widehat{\mathbf{s}}), \mathbf{s}\right)</script><p>â‘¡Style Controllingï¼šå¦‚æœä»…ä»…æ˜¯ä¸Šé¢çš„æ–¹æ³•ï¼Œé‚£ä¹ˆæ¨¡å‹å°±ä¼šå­¦ä¼šç›´æ¥å°†è¾“å…¥copyåˆ°è¾“å‡ºå°±èƒ½å°†lossé™å¾—å¾ˆä½ï¼Œä¸ºäº†é˜²æ­¢è¿™ä¸ªé—®é¢˜ï¼Œåˆ™å°†$\widehat{\mathbf{y}}$è¾“å…¥åˆ°discriminatorä»¥å¸Œæœ›æœ€å¤§åŒ–$\widehat{\mathbf{s}}$çš„æ¦‚ç‡ã€‚</p>
<p>æ€»çš„æ¥è¯´ï¼š<br><img src="/images/15715381498182.jpg" width="60%" height="50%"></p>
<p>å°†algorithm1å’Œalgorithm2ç»“åˆåˆ™æœ‰æ€»çš„ç®—æ³•ï¼š</p>
<p><img src="/images/15715383038673.jpg" width="60%" height="50%"></p>
<hr>
<h2 id="Style-Transfer-from-Non-Parallel-Text-by-Cross-Alignment"><a href="#Style-Transfer-from-Non-Parallel-Text-by-Cross-Alignment" class="headerlink" title="[Style Transfer from Non-Parallel Text by Cross-Alignment]"></a>[Style Transfer from Non-Parallel Text by Cross-Alignment]</h2><p>style transferçš„ä¸€ä¸ªæ–¹æ³•ã€‚å…¶ä¸­å¿ƒæ€æƒ³æ˜¯å¸Œæœ›èƒ½å¤Ÿå°†å†…å®¹å’Œstyleåˆ†ç¦»å¼€æ¥ã€‚å…¶å…·ä½“åšæ³•æ˜¯å°†ä¸€ä¸ªå¥å­å’Œå…¶styleçš„indicatorä½œä¸ºè¾“å…¥è¾“ç»™encoderï¼Œæ˜ å°„åˆ°ä¸€ä¸ªstyle-independentçš„content representationï¼›æ¥ç€å°†è¯¥è¡¨ç¤ºä¼ å…¥åˆ°ä¸€ä¸ªstyle-dependentçš„decoderç”Ÿæˆå¥å­ã€‚</p>
<p>å¦‚å›¾æœ‰å››ç§å¯èƒ½ï¼šåœ¨æ˜ å°„åˆ°zåï¼Œå¦‚æœä¸original styleç»‘å®šï¼Œåˆ™å¸Œæœ›èƒ½å¤Ÿé‡å»ºï¼›å¦‚æœä¸ä¸åŒstyleç»‘å®šï¼Œåˆ™å¸Œæœ›èƒ½åœ¨åˆ†å¸ƒä¸Šæœ‰å°½å¯èƒ½alignï¼ˆé€šè¿‡GANçš„æ€æƒ³å®ç°ï¼‰ã€‚</p>
<p><img src="/images/15715384140483.jpg" width="70%" height="50%"></p>
<h3 id="Aligned-auto-encoder"><a href="#Aligned-auto-encoder" class="headerlink" title="Aligned auto-encoder"></a>Aligned auto-encoder</h3><p>å…¶å®å°±æ˜¯é‡å»ºã€‚</p>
<script type="math/tex; mode=display">\begin{aligned} \boldsymbol{\theta}^{*} &=\underset{\boldsymbol{\theta}}{\arg \min } \mathcal{L}_{\text {rec }}\left(\boldsymbol{\theta}_{E}, \boldsymbol{\theta}_{G}\right) \\ \text { s.t. } E\left(\boldsymbol{x}_{1}, \boldsymbol{y}_{1}\right) & \stackrel{\mathrm{d}}{=} E\left(\boldsymbol{x}_{2}, \boldsymbol{y}_{2}\right) \quad \boldsymbol{x}_{1} \sim \boldsymbol{X}_{1}, \boldsymbol{x}_{2} \sim \boldsymbol{X}_{2} \end{aligned}</script><p>åŒæ—¶ï¼Œä¸ºäº†ä½¿zå°½é‡æ˜¯style-independentçš„ï¼Œä½¿ç”¨ä¸€ä¸ªGANæ¥ç›‘ç£ã€‚</p>
<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{adv}}\left(\boldsymbol{\theta}_{E}, \boldsymbol{\theta}_{D}\right)=\mathbb{E}_{\boldsymbol{x}_{1} \sim \boldsymbol{X}_{1}}\left[-\log D\left(E\left(\boldsymbol{x}_{1}, \boldsymbol{y}_{1}\right)\right)\right]+\mathbb{E}_{\boldsymbol{x}_{2} \sim \boldsymbol{X}_{2}}\left[-\log \left(1-D\left(E\left(\boldsymbol{x}_{2}, \boldsymbol{y}_{2}\right)\right)\right)\right]</script><p>å…¶å®zçš„å½¢å¼æ˜¯RNNçš„æœ€åä¸€ä¸ªstateã€‚</p>
<p>æœ€ç»ˆçš„lossåˆ™ä¸ºï¼š<br>$\min _{E, G} \max _{D} \mathcal{L}_{\mathrm{rec}}-\lambda \mathcal{L}_{\mathrm{adv}}$</p>
<h3 id="Cross-aligned-auto-encoder"><a href="#Cross-aligned-auto-encoder" class="headerlink" title="Cross-aligned auto-encoder"></a>Cross-aligned auto-encoder</h3><p>å¸Œæœ›åœ¨é£æ ¼è½¬æ¢åçš„å¥å­èƒ½å¤Ÿä¸æ‰€è½¬æ¢çš„é£æ ¼çš„å¥å­çš„<strong>åˆ†å¸ƒ</strong>ä¸€è‡´ã€‚</p>
<p><img src="/images/15715386888191.jpg" width="70%" height="50%"></p>
<p>é‡‡ç”¨çš„æ˜¯professor forcingçš„åšæ³•ï¼š<br>å¦‚å›¾ï¼Œencoderåœ¨ç”Ÿæˆä¸¤ä¸ªä¸åŒå¥å­çš„è¡¨ç¤ºåï¼Œä¸åŒä¸€é£æ ¼yç»‘å®šä½œä¸ºdecoderçš„åˆå§‹è¾“å…¥ï¼Œå¯¹äºå¥å­å’Œé£æ ¼ç›¸åŒçš„æƒ…å†µï¼ˆä¸ŠåŠéƒ¨åˆ†ï¼‰ï¼Œåˆ™ä½¿ç”¨teacher forcingï¼Œå¯¹äºå¥å­å’Œé£æ ¼ä¸åŒçš„æƒ…å†µä¸‹ï¼ˆä¸‹åŠéƒ¨åˆ†ï¼‰åˆ™ä½¿ç”¨self-fedçš„æ–¹å¼ç”Ÿæˆtransferred sentenceï¼Œå°†æ‰€æœ‰çš„hidden stateæ”¶é›†èµ·æ¥ç”¨discriminatoråšåˆ¤åˆ«ï¼Œæ¨¡å‹å¸Œæœ›èƒ½å¤Ÿç”Ÿæˆçš„hidden stateèƒ½å¤Ÿå°½é‡è®©discriminatoråˆ†è¾¨ä¸å‡ºæ¥ï¼Œä¹Ÿå³å¯¹äºä¸åŒçš„å†…å®¹zï¼Œåœ¨ç»™å®šåŒä¸€ä¸ªé£æ ¼çš„æƒ…å†µä¸‹ï¼Œå…¶è¡¨ç¤ºæ¥è¿‘ï¼Œä¹Ÿå³åˆ†å¸ƒæ¥è¿‘ï¼‰ã€‚</p>
<p>æœ€ç»ˆçš„ç®—æ³•ï¼š</p>
<p><img src="/images/15715387985967.jpg" width="90%" height="50%"></p>
<hr>
<h2 id="æœ¬å‘¨è®ºæ–‡å°ç»“"><a href="#æœ¬å‘¨è®ºæ–‡å°ç»“" class="headerlink" title="[æœ¬å‘¨è®ºæ–‡å°ç»“]"></a>[æœ¬å‘¨è®ºæ–‡å°ç»“]</h2><p>ä¼¼ä¹æœ‰ä¸€æ®µæ—¶é—´æ²¡æœ‰æ›´æ–°äº†ã€‚åŸæœ¬çš„æ‰“ç®—æ˜¯ç»§ç»­åšä¸€äº›ç¿»è¯‘ç›¸å…³çš„å·¥ä½œï¼Œä½†ä¼¼ä¹ç”±äºèµ„æºé™åˆ¶æ²¡æ³•åšäº†ã€‚å¤§æ¦‚æ¥ä¸‹æ¥ä¸€æ®µæ—¶é—´ä¼šä¸“æ³¨äºstyle transferã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>structured learning</tag>
        <tag>domain adaptation</tag>
        <tag>style transfer</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯39</title>
    <url>/2019/10/20/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D39/</url>
    <content><![CDATA[<h3 id="çœ¼å„¿åªšÂ·ä¸­å…ƒå¤œæœ‰æ„Ÿ"><a href="#çœ¼å„¿åªšÂ·ä¸­å…ƒå¤œæœ‰æ„Ÿ" class="headerlink" title="çœ¼å„¿åªšÂ·ä¸­å…ƒå¤œæœ‰æ„Ÿ"></a>çœ¼å„¿åªšÂ·ä¸­å…ƒå¤œæœ‰æ„Ÿ</h3><p>[æ¸…] çº³å…°æ€§å¾·<br>æ‰‹å†™é¦™å°é‡‘å­—ç»ï¼ŒæƒŸæ„¿ç»“æ¥ç”Ÿã€‚è²èŠ±æ¼è½¬ï¼Œæ¨æéœ²æ»´ï¼Œæƒ³é‰´å¾®è¯šã€‚<br>æ¬²çŸ¥å¥‰å€©ç¥ä¼¤æï¼Œå‡­è¯‰ä¸ç§‹æ“ã€‚<strong>è¥¿é£ä¸ç®¡ï¼Œä¸€æ± èæ°´ï¼Œå‡ ç‚¹è·ç¯ã€‚</strong></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä½³å¥åˆ†äº«5</title>
    <url>/2019/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB5/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>â€œé‚£ä¸€å¤©æˆ‘äºŒåä¸€å²ï¼Œåœ¨æˆ‘ä¸€ç”Ÿçš„é»„é‡‘æ—¶ä»£ã€‚æˆ‘æœ‰å¥½å¤šå¥¢æœ›ã€‚æˆ‘æƒ³çˆ±ï¼Œæƒ³åƒï¼Œè¿˜æƒ³åœ¨ä¸€ç¬é—´å˜æˆå¤©ä¸ŠåŠæ˜åŠæš—çš„äº‘ã€‚åæ¥æˆ‘æ‰çŸ¥é“ï¼Œç”Ÿæ´»å°±æ˜¯ä¸ªç¼“æ…¢å—é”¤çš„è¿‡ç¨‹ï¼Œäººä¸€å¤©å¤©è€ä¸‹å»ï¼Œå¥¢æœ›ä¹Ÿä¸€å¤©å¤©æ¶ˆå¤±ï¼Œæœ€åå˜å¾—åƒæŒ¨äº†é”¤çš„ç‰›ä¸€æ ·ã€‚å¯æ˜¯æˆ‘è¿‡äºŒåä¸€å²ç”Ÿæ—¥æ—¶æ²¡æœ‰é¢„è§åˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘è§‰å¾—è‡ªå·±ä¼šæ°¸è¿œç”ŸçŒ›ä¸‹å»ï¼Œä»€ä¹ˆä¹Ÿé”¤ä¸äº†æˆ‘ã€‚â€   â€”ã€Šé»„é‡‘æ—¶ä»£ã€‹</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡31</title>
    <url>/2019/09/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8731/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Quantifying Exposure Bias for Neural Language Generation</li>
<li>Sequence-to-Sequence Learning as Beam-Search Optimization</li>
<li>Learning to Stop in Structured Prediction for Neural Machine Translation</li>
<li>Scheduled Sampling for Transformers</li>
<li>Parallel Scheduled Sampling</li>
</ol>
<h2 id="Quantifying-Exposure-Bias-for-Neural-Language-Generation"><a href="#Quantifying-Exposure-Bias-for-Neural-Language-Generation" class="headerlink" title="[Quantifying Exposure Bias for Neural Language Generation]"></a>[Quantifying Exposure Bias for Neural Language Generation]</h2><p>è®¨è®ºäº†exposure biasåœ¨ç”Ÿæˆä»»åŠ¡ä¸Šçš„å½±å“å¤§å°ã€‚ç»“è®ºæ˜¯å½±å“è¾ƒå°ã€‚<br>å…¶å…·ä½“æ–¹æ³•æ˜¯â‘ äººå·¥è¯„æµ‹ï¼Œåœ¨ç»™å®šç›¸åŒå‰ç¼€ä¸‹ï¼Œæ¨¡å‹æ˜¯å¦èƒ½ç”Ÿæˆåˆç†çš„å¥å­ã€‚<br>â‘¡å®šé‡åˆ†æï¼Œé€šè¿‡å®šä¹‰æŒ‡æ ‡ï¼Œåˆ†åˆ«è®¡ç®—æ¨¡å‹åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚</p>
<hr>
<h2 id="Sequence-to-Sequence-Learning-as-Beam-Search-Optimization"><a href="#Sequence-to-Sequence-Learning-as-Beam-Search-Optimization" class="headerlink" title="[Sequence-to-Sequence Learning as Beam-Search Optimization]"></a>[Sequence-to-Sequence Learning as Beam-Search Optimization]</h2><p>ç»å…¸è®ºæ–‡ã€‚å†™å¾—æ¯”è¾ƒå¥½çš„ç¬”è®°ï¼š<a href="https://zhuanlan.zhihu.com/p/29969582" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29969582</a></p>
<p>æœ¬æ–‡ç›®çš„æ˜¯ç¼“è§£ä¼ ç»Ÿæœºå™¨ç¿»è¯‘è®­ç»ƒæ–¹æ³•çš„å‡ ä¸ªé—®é¢˜ã€‚</p>
<h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><p>ä¼ ç»Ÿæœºå™¨ç¿»è¯‘è®­ç»ƒæ–¹æ³•ä¸€èˆ¬é‡‡ç”¨teacher forcingã€‚å…·ä½“è€Œè¨€æœ‰ä»¥ä¸‹ä¸‰ä¸ªé—®é¢˜ï¼š</p>
<ol>
<li>Exposure Biasï¼šè®­ç»ƒä½¿ç”¨ground truthä½œä¸ºè¾“å…¥ï¼Œè€Œåœ¨æµ‹è¯•æœŸé—´ä½¿ç”¨ä¸Šä¸€é˜¶æ®µçš„predictionä½œä¸ºè¾“å…¥ï¼Œé”™è¯¯ä¼šè¿…é€Ÿç´¯ç§¯</li>
<li>Loss-Evaluation Mismatchï¼šè®­ç»ƒä½¿ç”¨word-levelçš„lossè€Œåœ¨æµ‹è¯•æœŸé—´ä½¿ç”¨BLEUä½œä¸ºæŒ‡æ ‡</li>
<li>label biasï¼šword probabilities at each time-step are locally normalized, guaranteeing that successors of incorrect histories receive the same mass as do the successors of the true history</li>
</ol>
<h3 id="Beam-Search-Optimization"><a href="#Beam-Search-Optimization" class="headerlink" title="Beam Search Optimization"></a>Beam Search Optimization</h3><p>ç®€å•è°ˆè°ˆä¸»è¦åšæ³•ï¼š</p>
<ol>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¹Ÿä½¿ç”¨beam search</li>
<li>è¿™é‡Œçš„beam searchä¸ä¼ ç»Ÿçš„beam searchä¸åŒï¼Œæ¯ä¸€æ­¥ä¸ä½¿ç”¨normalized probabilityï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨raw scoreã€‚ä¹Ÿå³ï¼Œå»æ‰softmaxå±‚ã€‚æ¯ä¸€ç»´ä»£è¡¨çš„æ„ä¹‰ä¸å†æ˜¯æ¦‚ç‡ï¼Œè€Œæ˜¯åœ¨ç»™å®š$w_{1 : t-1}$ä¸‹ï¼Œç”Ÿæˆ$w_t$çš„åˆ†æ•°ï¼Œä¹Ÿå³ï¼š$f\left(w_{t}, h_{t-1}, x\right)$ã€‚</li>
<li>Search-Based Lossï¼šè®¡ç®—lossä¸å†æ˜¯word-levelçš„CrossEntropyï¼Œè€Œæ˜¯åœ¨æŸä¸ªæ—¶é—´æ­¥tå½“ground truthæ‰å‡ºbeam sizeçš„çª—å£æ—¶æ‰ä¼šè®¡ç®—lossã€‚ä¸‹é¢ä¼šè®²ä¸€ä¸‹å…·ä½“æ€ä¹ˆåšçš„</li>
<li>å¼•å…¥sentence-level costï¼Œå…·ä½“ä¹Ÿå³å½“ground truthæ‰å‡ºbeam sizeçš„çª—å£æ—¶ä¼šè®¡ç®—ground truthä¸beam searchçª—å£å†…åˆ†æ•°æœ€ä½çš„å¥å­çš„å‰ç¼€çš„BLEUï¼Œå¦‚æœä¸¤ä¸ªå‰ç¼€å¾ˆç›¸ä¼¼ï¼Œåˆ™è¯¥losså°±ä¼šå°ä¸€äº›ï¼Œå¦åˆ™ä¼šå¤§ä¸€äº›ã€‚ä¹Ÿå³åœ¨lossçš„å‰é¢åŠ äº†ä¸€ä¸ªscaleï¼Œèƒ½å¤ŸåŠ¨æ€æ”¾å¤§æˆ–ç¼©å°lossã€‚</li>
</ol>
<h2 id="å…·ä½“æ“ä½œ"><a href="#å…·ä½“æ“ä½œ" class="headerlink" title="å…·ä½“æ“ä½œ"></a>å…·ä½“æ“ä½œ</h2><p><img src="/images/15697458311045.jpg" width="60%" height="50%"></p>
<p>å¦‚å›¾ï¼Œé»„è‰²çš„æ˜¯ground truthã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨beam searchç”Ÿæˆï¼Œå½“ground truthåœ¨beam sizeå†…ï¼Œåˆ™ä¸è®¡ç®—lossï¼Œç»§ç»­ç”Ÿæˆä¸‹å»ï¼›å½“ground truthæ‰å‡ºbeam sizeäº†ï¼Œå¦‚å›¾ç¬¬4ä¸ªstepï¼Œåˆ™è®¡ç®—ground truthæ‰€å¯¹åº”çš„åˆ†æ•°å’Œbeam sizeå†…åˆ†æ•°æœ€å°çš„å·®è·çš„lossï¼Œå…¶ç›®çš„æ˜¯å¸Œæœ›èƒ½å¤Ÿè®©æ¨¡å‹å°†ground truthæ’è¿›beam sizeï¼Œè®¡ç®—lossçš„æ–¹æ³•æ˜¯ï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}(f)=
\quad \sum_{t=1}^{T} \Delta\left(\hat{y}_{1 : t}^{(K)}\right)\left[1-f\left(y_{t}, \boldsymbol{h}_{t-1}\right)+f\left(\hat{y}_{t}^{(K)}, \hat{\boldsymbol{h}}_{t-1}^{(K)}\right)\right]</script><p>å…¶ä¸­$\Delta$æ‰€ä»£è¡¨çš„æ˜¯ä¸¤ä¸ª$y$æ‰€å¯¹åº”çš„å‰ç¼€çš„åŒ¹é…ç¨‹åº¦ï¼Œç”¨ä»¥ç¼©æ”¾lossçš„å¤§å°ï¼Œæ¯”å¦‚å¯ä»¥å°†$\Delta$è®¾ä¸º1-BLEUã€‚</p>
<p>å½“ground truthæ‰å‡ºbeam sizeæ—¶ï¼Œæ˜¾ç„¶ä¸èƒ½å†ç”¨æ¨¡å‹ç”Ÿæˆçš„è¯å»é¢„æµ‹æ¥ä¸‹æ¥çš„è¯ï¼Œå› æ­¤åœ¨step=4æ—¶ç”¨ground truthç»§ç»­ç”Ÿæˆä¸‹å»ï¼Œç›´åˆ°å†æ¬¡å‡ºç°æ‰å‡ºbeam sizeçš„æƒ…å†µã€‚</p>
<p>æ³¨æ„åˆ°åœ¨t&lt;Næ—¶ï¼Œground truthä¸€ç›´æ˜¯ä¸beam sizeå†…çš„æœ€åä¸€ä¸ªè¯è¿›è¡Œæ¯”è¾ƒçš„ï¼Œä½†åœ¨æœ€åä¸€ä¸ªstepå¸Œæœ›æ¨¡å‹èƒ½å¤Ÿå°†ground truthæ’åœ¨ç¬¬ä¸€ä½ï¼Œå› æ­¤åœ¨t=Næ—¶æ˜¯ä¸beam sizeçš„ç¬¬ä¸€ä½è¿›è¡Œæ¯”è¾ƒã€‚</p>
<p>å› æ­¤æœ€åçš„ç®—æ³•åˆ™æ˜¯ï¼š</p>
<p><img src="/images/15697463856127.jpg" width="50%" height="50%"></p>
<h3 id="ä¸€ç‚¹æ€è€ƒ"><a href="#ä¸€ç‚¹æ€è€ƒ" class="headerlink" title="ä¸€ç‚¹æ€è€ƒ"></a>ä¸€ç‚¹æ€è€ƒ</h3><p>BSOæ‘’å¼ƒäº†ä¼ ç»Ÿçš„word-levelçš„lossï¼Œå¼•å…¥sentence-level costï¼Œèƒ½å¤Ÿç¼“è§£Loss-Evaluation Mismatchçš„é—®é¢˜ï¼›åŒæ—¶è®­ç»ƒå’Œæµ‹è¯•éƒ½ä½¿ç”¨äº†beam searchï¼Œä¹Ÿå³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±æ¥è§¦äº†è‡ªå·±çš„predictionï¼Œè¿™æ ·å°±ç¼“è§£äº†exposure biasçš„é—®é¢˜ï¼›è®ºæ–‡ä¸­è¿˜æåˆ°ç”¨raw scoreè€Œä¸æ˜¯normalized probabilityå¯ä»¥è§£å†³label biasçš„é—®é¢˜ã€‚ç¡®å®è¿™ä¸ªç®—æ³•å¾ˆç²¾å¦™ã€‚</p>
<p>ä½†ä¼¼ä¹ä»ç„¶æœ‰ä¸€ç‚¹é—®é¢˜ã€‚ç¬¬ä¸€ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„losséå¸¸sparseï¼Œå¯èƒ½éš¾ä»¥è®­ç»ƒæ”¶æ•›ï¼›ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®ºæ–‡çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨teacher forcingå…ˆé¢„è®­ç»ƒä¸€ä¸ªæ ‡å‡†çš„æ¨¡å‹ï¼Œä¹Ÿå³BSOæ˜¯æ²¡åŠæ³•learn from scratchï¼›åŒæ—¶è¯¥æ–¹æ³•å…·æœ‰åºåˆ—æ€§ï¼Œå› æ­¤å¯èƒ½éš¾ä»¥åº”ç”¨äºTransformerè¿™æ ·çš„æ¨¡å‹ä¸Šã€‚</p>
<hr>
<h2 id="Learning-to-Stop-in-Structured-Prediction-for-Neural-Machine-Translation"><a href="#Learning-to-Stop-in-Structured-Prediction-for-Neural-Machine-Translation" class="headerlink" title="[Learning to Stop in Structured Prediction for Neural Machine Translation]"></a>[Learning to Stop in Structured Prediction for Neural Machine Translation]</h2><p>é’ˆå¯¹BSOè¿›è¡Œäº†ä¸€å®šçš„æ”¹è¿›ã€‚</p>
<p>â‘ BSOåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å€¾å‘äºç”Ÿæˆæ›´é•¿çš„å¥å­ï¼Œå› ä¸ºæ˜¯ä½¿ç”¨raw scoreä½œä¸ºbeam searchçš„å¥å­æ‰“åˆ†ï¼Œå› æ­¤ç”Ÿæˆè¶Šé•¿çš„å¥å­åˆ†æ•°å¯èƒ½è¶Šé«˜ï¼›<br>    æ”¹è¿›ï¼šåœ¨raw scoreå¤–é¢å¥—ä¸€å±‚sigmoid</p>
<p>â‘¡ä¸ºäº†é¼“åŠ±æ¨¡å‹ç”Ÿæˆå’Œground truthç±»ä¼¼çš„é•¿åº¦ï¼Œå¯¹ææ—©åœæ­¢çš„å¥å­è¿›è¡Œæƒ©ç½šï¼Œä¹Ÿå³å¯¹åœ¨ground truthä¹‹å‰å°±ç”Ÿæˆeosçš„æƒ…å†µè®¡ç®—lossï¼š</p>
<p>$\begin{aligned} \mathbb{L}^{\mathrm{s}}=&amp; \sum_{t=1}^{|\mathbf{y}|} \sum_{j=1}^{b} \mathbb{1}\left(\hat{y}_{t}^{j}=&lt;\langle\mathrm{eos}\rangle\right) \cdot Q\left(\hat{y}_{t}^{j}, \hat{y}_{t}^{b+1}\right) \\ Q\left(\hat{y}_{t}^{j}, \hat{y}_{t}^{b+1}\right)=&amp;\left(g_{\mathbf{x}}\left(\hat{y}_{t}^{j} | \hat{\mathbf{y}}_{&lt;t}^{j}\right)-g_{\mathbf{x}}\left(\hat{y}_{t}^{b+1} | \hat{\mathbf{y}}_{&lt;t}^{b+1}\right)\right)^{+} \end{aligned}$</p>
<p>å›¾ä¾‹ï¼š</p>
<p><img src="/images/15698111591417.jpg" width="50%" height="50%"></p>
<hr>
<h2 id="Scheduled-Sampling-for-Transformers"><a href="#Scheduled-Sampling-for-Transformers" class="headerlink" title="[Scheduled Sampling for Transformers]"></a>[Scheduled Sampling for Transformers]</h2><p>è®¨è®ºäº†scheduled samplingå¦‚ä½•åº”ç”¨äºtransformerã€‚<br>å…¶åšæ³•éå¸¸ç›´è§‚ï¼Œé¦–å…ˆå°†goldenä¼ å…¥è·å¾—é¢„æµ‹ç„¶åå°†é¢„æµ‹å’Œgoldenæ··åˆå†ä¼ å…¥ä¸€æ¬¡decoderã€‚æ²¡å•¥æ–°çš„åœ°æ–¹</p>
<p><img src="/images/15698112346426.jpg" width="80%" height="50%"></p>
<hr>
<h2 id="Parallel-Scheduled-Sampling"><a href="#Parallel-Scheduled-Sampling" class="headerlink" title="[Parallel Scheduled Sampling]"></a>[Parallel Scheduled Sampling]</h2><p>å°è¯•ç¼“è§£scheduled samplingçš„åºåˆ—æ€§çš„ç‰¹ç‚¹ã€‚å…¶å®å°±æ˜¯é’ˆå¯¹transformerè¿™ç§å¹¶è¡Œæ€§çš„æå‡ºæ–°çš„scheduled samplingã€‚åšäº†ä¸€ç‚¹å°åˆ›æ–°ã€‚</p>
<p>å…·ä½“åšæ³•æ˜¯ï¼šå…ˆç”¨ground truthè·å¾—predictionï¼Œç„¶åç”¨predictionå’Œground truthæ··åˆï¼Œå¾ªç¯å‡ æ¬¡ï¼Œå…¶ä¸­æ··åˆçš„æ–¹æ³•æ˜¯ï¼Œæ¯ä¸ªå¾ªç¯éƒ½ä¼šå°†ä¸€ä¸ªå‰ç¼€ä»goldenæ¢æˆpredictionï¼Œå…¶ä»–çš„è¯ç”¨æ¦‚ç‡sampleã€‚è¿™æ ·åˆ°æœ€åå°±å…¨æ˜¯predictionäº†ã€‚</p>
<p><img src="/images/15698113062324.jpg" width="80%" height="50%"></p>
<p>ç®—æ³•ï¼š</p>
<p><img src="/images/15698124950344.jpg" width="70%" height="50%"></p>
<p>å¼•å…¥äº†recurrentä»¥åŠä¸åŒçš„æ›¿æ¢æ–¹å¼ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>exposure bias</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯38</title>
    <url>/2019/09/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D38/</url>
    <content><![CDATA[<h3 id="èµ å­Ÿæµ©ç„¶"><a href="#èµ å­Ÿæµ©ç„¶" class="headerlink" title="èµ å­Ÿæµ©ç„¶"></a>èµ å­Ÿæµ©ç„¶</h3><p>[å”] æç™½<br>å¾çˆ±å­Ÿå¤«å­ï¼Œé£æµå¤©ä¸‹é—»ã€‚<br>çº¢é¢œå¼ƒè½©å†•ï¼Œç™½é¦–å§æ¾äº‘ã€‚<br>é†‰æœˆé¢‘ä¸­åœ£ï¼Œè¿·èŠ±ä¸äº‹å›ã€‚<br><strong>é«˜å±±å®‰å¯ä»°ï¼Œå¾’æ­¤æ–æ¸…èŠ¬ã€‚</strong></p>
<p>ä¸­åœ£ï¼šâ€œä¸­åœ£äººâ€çš„ç®€ç§°ï¼Œå³é†‰é…’ã€‚æ›¹é­æ—¶å¾é‚ˆå–œæ¬¢å–é…’ï¼Œç§°é…’æ¸…è€…ä¸ºâ€œåœ£äººâ€ï¼Œé…’æµŠè€…ä¸ºè´¤äººã€‚ä¸­ï¼šè¯»å»å£°ï¼ŒåŠ¨è¯ï¼Œâ€œä¸­æš‘â€ã€â€œä¸­æ¯’â€ä¹‹â€œä¸­â€ï¼Œæ­¤ä¸ºé¥®æ¸…é…’è€Œé†‰ï¼Œæ•…æ›°ä¸­åœ£ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯37</title>
    <url>/2019/09/22/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D37/</url>
    <content><![CDATA[<h3 id="åœ¨ç‹±å’è‰"><a href="#åœ¨ç‹±å’è‰" class="headerlink" title="åœ¨ç‹±å’è‰"></a>åœ¨ç‹±å’è‰</h3><p>[å”] éª†å®¾ç‹<br>è¥¿é™†è‰å£°å”±ï¼Œå—å† å®¢æ€ä¾µã€‚<br><strong>é‚£å ªç„é¬“å½±ï¼Œæ¥å¯¹ç™½å¤´åŸ</strong>ã€‚<br>éœ²é‡é£éš¾è¿›ï¼Œé£å¤šå“æ˜“æ²‰ã€‚<br>æ— äººä¿¡é«˜æ´ï¼Œè°ä¸ºè¡¨äºˆå¿ƒã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†28</title>
    <url>/2019/09/15/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8628/</url>
    <content><![CDATA[<h3 id="Pytorch"><a href="#Pytorch" class="headerlink" title="[Pytorch]"></a>[Pytorch]</h3><p>â‘ torch.index_selectè™½ç„¶ç›¸æ¯”åŸtensoré‡æ–°åˆ†é…äº†ç©ºé—´ï¼Œä½†ä»¥å›¾çš„å½¢å¼ä¿å­˜ï¼Œå› æ­¤ä»ç„¶å¯ä»¥æ¢¯åº¦å›ä¼ ã€‚</p>
<p>â‘¡CUDA error: device-side assert trigger<br>Assertion <code>srcIndex &lt; srcSelectDimSize</code> failed</p>
<p>å½“é‡åˆ°ä»¥ä¸ŠæŠ¥é”™æ—¶ï¼Œå¯ä»¥å°è¯•å°†deviceæ”¹æˆCPUä»¥è·å¾—æ›´å…·ä½“çš„æŠ¥é”™ä¿¡æ¯ï¼›å¦‚æœæ²¡åŠæ³•åœ¨CPUä¸Šè·‘çš„è¯ï¼Œåˆ™å¯ä»¥<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CUDA_LAUNCH_BLOCKING=<span class="number">1</span> python script.py args</span><br></pre></td></tr></table></figure></p>
<p>æ¥è·å¾—å…·ä½“é”™è¯¯ä¿¡æ¯ã€‚</p>
<p>é‡åˆ°ä»¥ä¸Šé—®é¢˜çš„ä¸€ç§å¯èƒ½æ€§å°±æ˜¯å–embeddingçš„æ—¶å€™indexè¶…è¿‡æœ€å¤§èŒƒå›´äº†ã€‚</p>
<p><a href="https://discuss.pytorch.org/t/solved-assertion-srcindex-srcselectdimsize-failed-on-gpu-for-torch-cat/1804/9" target="_blank" rel="noopener">https://discuss.pytorch.org/t/solved-assertion-srcindex-srcselectdimsize-failed-on-gpu-for-torch-cat/1804/9</a><br><a href="https://discuss.pytorch.org/t/what-the-error-means-runtimeerror-device-side-assert-triggered/3249" target="_blank" rel="noopener">https://discuss.pytorch.org/t/what-the-error-means-runtimeerror-device-side-assert-triggered/3249</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡30</title>
    <url>/2019/09/15/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8730/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Constant-Time Machine Translation with Conditional Masked Language Models</li>
<li>Learning a Multitask Curriculum for Neural Machine Translation</li>
</ol>
<h2 id="Constant-Time-Machine-Translation-with-Conditional-Masked-Language-Models"><a href="#Constant-Time-Machine-Translation-with-Conditional-Masked-Language-Models" class="headerlink" title="[Constant-Time Machine Translation with Conditional Masked Language Models]"></a>[Constant-Time Machine Translation with Conditional Masked Language Models]</h2><p>æå‡ºä¸€ç§æ–°çš„non-autoregressiveçš„NMTï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆä¸€æ¬¡æ€§é¢„æµ‹æ‰€æœ‰targetï¼Œç„¶åå¾ªç¯maskæ‰ä½confidentçš„è¯å¹¶é‡é¢„æµ‹ï¼Œé‡å¤è¯¥è¿‡ç¨‹ï¼›åœ¨decodeé˜¶æ®µï¼Œæ¯ä¸ªtokenèƒ½å¤Ÿçœ‹åˆ°ä¸¤è¾¹çš„tokenã€‚</p>
<p>ç»“æ„ï¼š<br>ä¸ä¼ ç»Ÿçš„encoder-decoderä¸€æ ·ï¼Œåªæ˜¯åœ¨decodeç«¯æ²¡æœ‰maskæ‰æœªæ¥çš„è¯ï¼›<br>åœ¨è®­ç»ƒé˜¶æ®µï¼Œæœ‰ä¸¤ä¸ªlossï¼Œä¸€ä¸ªæ˜¯é¢„æµ‹target sequenceçš„é•¿åº¦ï¼Œå…·ä½“æ˜¯åœ¨encoderç«¯å‰é¢æ’å…¥ç‰¹æ®Šçš„LEHGTHç¬¦å·ï¼Œå¹¶ç”¨è¯¥ç¬¦å·é¢„æµ‹targetçš„é•¿åº¦ï¼›ç¬¬äºŒæ˜¯éšæœºmaskæ‰ä¸€äº›tokenï¼Œé¢„æµ‹è¢«maskæ‰çš„è¯çš„lossã€‚</p>
<h3 id="mask-predict"><a href="#mask-predict" class="headerlink" title="mask-predict"></a>mask-predict</h3><p>ç»™å®štarget sequenceçš„é•¿åº¦$N$ï¼Œå®šä¹‰$(y_1 , . . . , y_N )$æ˜¯å¥å­çš„tokenï¼›è€Œ$(p_1 , . . . , p_N )$æ˜¯ç›¸å¯¹åº”çš„æ¦‚ç‡ã€‚è®¾å®šä¸€ä¸ªé¢„å®šä¹‰çš„å¾ªç¯æ¬¡æ•°$T$ï¼Œåœ¨æ¯ä¸ªè®­ç»ƒä¸­åšmask&amp;predictçš„æ“ä½œã€‚å…·ä½“æ¥è¯´ï¼šé¦–å…ˆmaskæ‰æ‰€æœ‰çš„è¯ï¼Œåˆ©ç”¨encoderçš„è¾“å…¥é¢„æµ‹æ‰€æœ‰çš„è¯ï¼Œæ¯ä¸ªè¯éƒ½ä¼šæœ‰ä¸€ä¸ªæ¦‚ç‡ï¼Œåœ¨ä¹‹åçš„å¾ªç¯ä¸­ï¼Œmaskæ‰é‚£äº›æ¦‚ç‡ä½çš„è¯ï¼Œå¹¶åˆ©ç”¨encoderçš„è¾“å…¥å’Œå·²è§‚å¯Ÿåˆ°çš„targeté‡æ–°é¢„æµ‹ï¼›æ¯ä¸ªå¾ªç¯ä¸­è¢«maskæ‰çš„è¯çš„ä¸ªæ•°éšç€å¾ªç¯æ¬¡æ•°çš„å¢åŠ è€Œå‡å°ã€‚é¢„æµ‹å®Œåpä¼šæ›´æ–°ã€‚</p>
<p>å…·ä½“å…¬å¼ï¼š</p>
<script type="math/tex; mode=display">n=N \cdot \frac{T-t}{T}</script><script type="math/tex; mode=display">Y_{\operatorname{mask}}^{(t)}=\arg \min _{i}\left(p_{i}, n\right)</script><script type="math/tex; mode=display">Y_{o b s}^{(t)}=Y \backslash Y_{m a s k}^{(t)}</script><script type="math/tex; mode=display">P\left(y | X, Y_{o b s}\right)</script><p>ä¾‹å­ï¼š</p>
<p><img src="/images/15685140449224.jpg" width="70%" height="50%"></p>
<p>åœ¨inferenceçš„æ—¶å€™ï¼Œè¿˜å¯ä»¥åŒæ—¶é€‰æ‹©å¤šä¸ªlengthï¼Œä¸€èµ·ç”Ÿæˆå¥å­ï¼Œç±»ä¼¼beam searchï¼Œæœ€åé€‰æ‹©å¹³å‡æ¦‚ç‡æœ€é«˜çš„å¥å­ã€‚</p>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>å‡ ä¸ªç»“è®ºï¼š<br>å¤šä¸ªå¾ªç¯æ˜¯æœ‰å¿…è¦çš„ï¼šå› ä¸ºä¸€å¼€å§‹ä¼šæœ‰token repetitionçš„ç°è±¡ï¼Œå› ä¸ºç”Ÿæˆæ˜¯åŸºäºä¸€ä¸ªå‡è®¾ï¼šmaskçš„tokenä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤é¢å¯¹åŒæ ·çš„observationå¯èƒ½ç”Ÿæˆå‡ºä¸€æ ·çš„tokenï¼ˆmulti-modalityï¼‰ã€‚å¾ªç¯mask-predictå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>æ›´å¤§çš„iterationèƒ½å¤Ÿå¸®åŠ©é•¿å¥å­æå‡è¡¨ç°ï¼›</p>
<p>æ›´å¤šçš„length candidateèƒ½å¤Ÿä¸€å®šç¨‹åº¦ä¸Šæå‡è¡¨ç°ï¼Œç±»ä¼¼beam search</p>
<h3 id="æƒ³æ³•"><a href="#æƒ³æ³•" class="headerlink" title="æƒ³æ³•"></a>æƒ³æ³•</h3><p>å¦‚æœåªæœ‰ä¸€ä¸ªiterationï¼Œé‚£ä¹ˆå°±æ˜¯å®Œå…¨çš„non-autoregressiveï¼›å¦‚æœä¸maskæ‰low confidentçš„tokenï¼Œé‚£ä¹ˆå°±ç±»ä¼¼Attending to Future Tokens for Bidirectional Sequence Generationã€‚ç›¸å¯¹äºAttending to Future Tokens for Bidirectional Sequence Generationï¼Œå‡å°ç”Ÿæˆçš„èŒƒå›´/é•¿åº¦ï¼Œé¢„æµ‹çš„æ˜¯å‡ ä¸ªè¯è€Œä¸æ˜¯ä¸€æ•´ä¸ªå¥å­ï¼Œä¸”æœ‰æŒ‡å‘æ€§ï¼ˆlow confidentï¼‰ï¼Œä¸”å¼•å…¥iterationçš„æ¦‚å¿µï¼Œå°±æ˜¯æœ¬ç¯‡è®ºæ–‡ã€‚</p>
<hr>
<h2 id="Learning-a-Multitask-Curriculum-for-Neural-Machine-Translation"><a href="#Learning-a-Multitask-Curriculum-for-Neural-Machine-Translation" class="headerlink" title="[Learning a Multitask Curriculum for Neural Machine Translation]"></a>[Learning a Multitask Curriculum for Neural Machine Translation]</h2><p>å°è¯•å­¦åˆ°ä¸€ä¸ªcurriculum strategyï¼Œä½¿å¾—å­¦å¾—çš„æ¨¡å‹èƒ½å¤Ÿåœ¨<strong>å¤šä»»åŠ¡/domain</strong>ä¸Šéƒ½è¡¨ç°å¥½ã€‚</p>
<p>å…¶å…·ä½“åšæ³•æ˜¯ï¼šæ¯ä¸ªsampleéƒ½èµ‹äºˆå¤šä¸ªscoreï¼Œå…¶ä¸­æ¯ä¸ªscoreä»£è¡¨è¯¥sampleå¯¹æŸä¸ªtaskçš„ä½œç”¨å¤§å°ï¼Œé€šè¿‡ä¸€ä¸ªå¯å­¦ä¹ çš„weightå°†å¤šä¸ªscoreçº¿æ€§åŠ æƒå¾—åˆ°ï¼Œè¯¥weighté€šè¿‡è´å¶æ–¯ä¼˜åŒ–æ›´æ–°ã€‚</p>
<p>ä¼ ç»ŸCLéƒ½æ˜¯focusåˆ°ä¸€ä¸ªfinal taskï¼Œè€Œåœ¨æœ¬æ–‡å¸Œæœ›èƒ½å¤Ÿåœ¨å¤šä¸ªtaskéƒ½æœ‰å¥½çš„è¡¨ç°ã€‚</p>
<p><img src="/images/15685163220835.jpg" width="50%" height="50%"></p>
<p>å¦‚å›¾ï¼Œæ¯ä¸ªsampleéƒ½æœ‰ä¸‰ä¸ªåˆ†æ•°ï¼Œåˆ†åˆ«ä»£è¡¨å¯¹ä¸‰ä¸ªä»»åŠ¡çš„è´¡çŒ®ç¨‹åº¦ã€‚ï¼ˆ2ï¼‰ï¼ˆ3ï¼‰ï¼ˆ4ï¼‰éƒ½æ˜¯focusåˆ°ä¸€ä¸ªä»»åŠ¡ï¼Œä»è´¡çŒ®ä½çš„å¼€å§‹è®­ï¼Œé€æ¸è½¬æ¢æˆè´¡çŒ®é«˜çš„è®­ï¼Œæœ€ç»ˆå¯¹ä¸€ä¸ªç‰¹å®šçš„ä»»åŠ¡è¡¨ç°å¥½ã€‚è€Œï¼ˆ5ï¼‰åˆ™æ˜¯å¸Œæœ›èƒ½å¤Ÿå¯¹ä¸‰ä¸ªä»»åŠ¡éƒ½è¡¨ç°å¥½ã€‚</p>
<p>è®°sampleå¯¹ç¬¬nä¸ªtaskçš„è´¡çŒ®ç¨‹åº¦$\phi^{(n)}\left(x, y ; \theta^{(n)}, m_{f}^{(n)}\right)$ï¼Œåˆ™ä¸€ä¸ªsampleå¯¹åº”ä¸€ä¸ªscoreçš„vectorï¼š$\Phi(x, y)=\left[\phi_{0}(x, y), \ldots, \phi_{M-1}(x, y)\right]$ã€‚è®¾weight $W=\left[w_{0}, \dots, w_{M-1}\right]$ï¼Œåˆ™çº¿æ€§åŠ æƒå¾—åˆ°ï¼š</p>
<script type="math/tex; mode=display">\varphi(x, y)=W \cdot \Phi(x, y)</script><p>æ ¹æ®è¯¥scoreæ’åˆ—ï¼Œåˆ©ç”¨CLæ¥è®­ç»ƒã€‚<br>æˆ‘ä»¬å¸Œæœ›è·å¾—ä¸€ä¸ªWï¼Œä½¿å¾—ï¼š</p>
<script type="math/tex; mode=display">W^{*}=\arg \max _{W} \mathcal{P}\left(\widehat{\mathcal{C}}(W) ; m_{f}^{(0)}, \ldots, m_{f}^{(N)}\right)</script><p>é€šè¿‡åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æœ€ç»ˆè¡¨ç°æ¥ä½œä¸ºè¯„åˆ¤æ ‡å‡†ï¼Œå¹¶åˆ©ç”¨è´å¶æ–¯æ¥åšä¼˜åŒ–ã€‚</p>
<p><img src="/images/15685165429041.jpg" width="60%" height="50%"></p>
<p><img src="/images/15685167625469.jpg" width="60%" height="50%"></p>
<p>Curriculum Learning strategyï¼š<br>å…·ä½“çš„curriculum learning strategyåœ¨è¿™é‡Œç±»ä¼¼domain adaptationã€‚è®¾ä¸€ä¸ªdecaying functionï¼Œ$\lambda(t)=0.5^{t / H}$ã€‚Hæ˜¯è¶…å‚ï¼Œtæ˜¯æ—¶é—´æ­¥ï¼ŒÎ»åˆ™ä»£è¡¨äº†æ¨¡å‹æ‰€ç”¨åˆ°çš„æ•°æ®çš„æ¯”ä¾‹ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œæ¯”ä¾‹è¶Šæ¥è¶Šå°ï¼Œä¹Ÿå³ä½¿ç”¨çš„æ•°æ®ä¸taskè¶Šæ¥è¶Šç›¸å…³ã€‚</p>
<p>éš¾åº¦çš„å®šä¹‰ï¼š<br>â‘ NLM domain relevance features</p>
<script type="math/tex; mode=display">d(x)=\frac{\log P_{\mathrm{domain}}(x)-\log P_{\mathrm{general}}(x)}{|x|}</script><p>â‘¡NMT quality features</p>
<script type="math/tex; mode=display">q(x, y)=\frac{\log P_{\text {clean }}(y | x)-\log P_{\text {noisy }}(y | x)}{|y|}</script><p>å…¶å®å°±æ˜¯è®­ç»ƒä¸¤ä¸ªä¸åŒæ•°æ®ä¸Šçš„æ¨¡å‹ï¼ˆç¿»è¯‘æˆ–è€…è¯­è¨€æ¨¡å‹ï¼‰ç„¶åå°†ä¸€ä¸ªsampleä¸¢è¿›å»è®¡ç®—å¾—åˆ°åˆ†æ•°ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>Machine Translation</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯36</title>
    <url>/2019/09/15/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D36/</url>
    <content><![CDATA[<h3 id="è¾‹å·é—²å±…èµ è£´ç§€æ‰è¿ª"><a href="#è¾‹å·é—²å±…èµ è£´ç§€æ‰è¿ª" class="headerlink" title="è¾‹å·é—²å±…èµ è£´ç§€æ‰è¿ª"></a>è¾‹å·é—²å±…èµ è£´ç§€æ‰è¿ª</h3><p>[å”] ç‹ç»´<br>å¯’å±±è½¬è‹ç¿ ï¼Œç§‹æ°´æ—¥æ½ºæ¹²ã€‚<br>å€šæ–æŸ´é—¨å¤–ï¼Œä¸´é£å¬æš®è‰ã€‚<br>æ¸¡å¤´é¦€è½æ—¥ï¼Œå¢Ÿé‡Œä¸Šå­¤çƒŸã€‚<br><strong>å¤å€¼æ¥èˆ†é†‰ï¼Œç‹‚æ­Œäº”æŸ³å‰ã€‚</strong></p>
<hr>
<h3 id="ç»ˆå—åˆ«ä¸š"><a href="#ç»ˆå—åˆ«ä¸š" class="headerlink" title="ç»ˆå—åˆ«ä¸š"></a>ç»ˆå—åˆ«ä¸š</h3><p>[å”] ç‹ç»´<br>ä¸­å²é¢‡å¥½é“ï¼Œæ™©å®¶å—å±±é™²ã€‚<br><strong>å…´æ¥æ¯ç‹¬å¾€ï¼Œèƒœäº‹ç©ºè‡ªçŸ¥</strong>ã€‚<br><strong>è¡Œåˆ°æ°´ç©·å¤„ï¼Œåçœ‹äº‘èµ·æ—¶</strong>ã€‚<br>å¶ç„¶å€¼æ—åŸï¼Œè°ˆç¬‘æ— è¿˜æœŸã€‚</p>
<hr>
<h3 id="çœ‹æ¢…ç»å¥äº”é¦–"><a href="#çœ‹æ¢…ç»å¥äº”é¦–" class="headerlink" title="çœ‹æ¢…ç»å¥äº”é¦–"></a>çœ‹æ¢…ç»å¥äº”é¦–</h3><p>[å®‹] é™†æ¸¸<br>è€å­èˆæ—¶ä¸é¡»æ‹ï¼Œæ¢…èŠ±ä¹±æ’ä¹Œå·¾é¦™ã€‚<br><strong>æ¨½å‰ä½œå‰§è«ç›¸ç¬‘ï¼Œæˆ‘æ­»è¯¸å›æ€æ­¤ç‹‚</strong>ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯35</title>
    <url>/2019/09/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D35/</url>
    <content><![CDATA[<h3 id="ç™»é‡‘é™µå‡¤å‡°å°"><a href="#ç™»é‡‘é™µå‡¤å‡°å°" class="headerlink" title="ç™»é‡‘é™µå‡¤å‡°å°"></a>ç™»é‡‘é™µå‡¤å‡°å°</h3><p>[å”] æç™½<br>å‡¤å‡°å°ä¸Šå‡¤å‡°æ¸¸ï¼Œå‡¤å»å°ç©ºæ±Ÿè‡ªæµã€‚<br><strong>å´å®«èŠ±è‰åŸ‹å¹½å¾„ï¼Œæ™‹ä»£è¡£å† æˆå¤ä¸˜ã€‚</strong><br>ä¸‰å±±åŠè½é’å¤©å¤–ï¼ŒäºŒæ°´ä¸­åˆ†ç™½é¹­æ´²ã€‚<br>æ€»ä¸ºæµ®äº‘èƒ½è”½æ—¥ï¼Œé•¿å®‰ä¸è§ä½¿äººæ„ã€‚</p>
<hr>
<h3 id="æ‘¸é±¼å„¿"><a href="#æ‘¸é±¼å„¿" class="headerlink" title="æ‘¸é±¼å„¿"></a>æ‘¸é±¼å„¿</h3><p>[å®‹] è¾›å¼ƒç–¾<br>æ›´èƒ½æ¶ˆã€å‡ ç•ªé£é›¨ï¼ŒåŒ†åŒ†æ˜¥åˆå½’å»ã€‚æƒœæ˜¥é•¿æ€•èŠ±å¼€æ—©ï¼Œä½•å†µè½çº¢æ— æ•°ã€‚æ˜¥ä¸”ä½ï¼Œè§è¯´é“ã€å¤©æ¶¯èŠ³è‰æ— å½’è·¯ã€‚æ€¨æ˜¥ä¸è¯­ã€‚ç®—åªæœ‰æ®·å‹¤ã€ç”»æªè››ç½‘ï¼Œå°½æ—¥æƒ¹é£çµ®ã€‚<br>é•¿é—¨äº‹ï¼Œå‡†æ‹Ÿä½³æœŸåˆè¯¯ã€‚è›¾çœ‰æ›¾æœ‰äººå¦¬ï¼Œåƒé‡‘çºµä¹°ç›¸å¦‚èµ‹ï¼Œè„‰è„‰æ­¤æƒ…è°è¯‰ï¼Ÿå›è«èˆï¼Œ<strong>å›ä¸è§ã€ç‰ç¯é£ç‡•çš†å°˜åœŸ</strong>ï¼é—²æ„æœ€è‹¦ï¼Œ<strong>ä¼‘å»å€šå±æ ï¼Œæ–œé˜³æ­£åœ¨ï¼ŒçƒŸæŸ³æ–­è‚ å¤„</strong>ã€‚</p>
<p>å¦¬ï¼ˆdÃ¹ï¼‰ï¼šåŒâ€œå¦’â€</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡29</title>
    <url>/2019/09/01/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8729/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks</li>
<li>A Simple Theoretical Model of Importance for Summarization</li>
<li>Attending to Future Tokens for Bidirectional Sequence Generation</li>
<li>Sequence Generation: From Both Sides to the Middle</li>
</ol>
<h2 id="Repeat-before-Forgetting-Spaced-Repetition-for-Efficient-and-Effective-Training-of-Neural-Networks"><a href="#Repeat-before-Forgetting-Spaced-Repetition-for-Efficient-and-Effective-Training-of-Neural-Networks" class="headerlink" title="[Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks]"></a>[Repeat before Forgetting: Spaced Repetition for Efficient and Effective Training of Neural Networks]</h2><p>æå‡ºä¸€ç§åŸºäºæ ¸å¯†åº¦ä¼°è®¡çš„è®­ç»ƒç¥ç»ç½‘ç»œçš„schedulerã€‚</p>
<p>è®ºæ–‡é¦–å…ˆä»å®éªŒä¸Šè®ºè¯äº†ç¥ç»ç½‘ç»œä¸äººç±»è®¤çŸ¥çš„ç›¸ä¼¼æ€§ã€‚æ¥ç€åŸºäºæ­¤æå‡ºæ–°çš„è®­ç»ƒç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚</p>
<h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><p>äººç±»åœ¨è®°å¿†æ–°çŸ¥è¯†æ—¶ï¼Œéœ€è¦ä¸æ–­é‡å¤ï¼Œè€Œé‡å¤çš„é—´éš”æ—¶é—´éšç€é‡å¤æ¬¡æ•°è€Œé€æ¸æ‰©å¤§ã€‚ï¼ˆé—å¿˜æ›²çº¿ï¼‰ã€‚åŒæ—¶å­¦ä¹ è¿‡ç¨‹è¿˜å’Œè¯¥çŸ¥è¯†çš„éš¾åº¦ä¸äººç±»è®°å¿†çš„å¼ºåº¦ç›¸å…³ã€‚æ”¾åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œå°±æœ‰ï¼š</p>
<script type="math/tex; mode=display">\operatorname{Pr}(r e c a l l)=\exp \left(-\frac{\text {difficulty} \times \text {delay}}{\text {strength}}\right)</script><p>å…¶ä¸­recallå°±æ˜¯åˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚</p>
<p>å› æ­¤æœ¬æ–‡åŸºäºä»¥ä¸Šä¸‰ä¸ªå˜é‡æå‡ºä¸€ç§åŸºäºé—´éš”é‡å¤è®­ç»ƒç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚<br>å®é™…ä¸Šæœ¬è´¨å°±æ˜¯ï¼Œåœ¨å¿«è¦é—å¿˜ä¹‹å‰é‡æ–°è¿‡ä¸€éè¿™ä¸ªsampleã€‚é€šè¿‡é¢„ä¼°çš„æ–¹æ³•å»è·å¾—delayçš„æ—¶é—´ã€‚</p>
<p>åœ¨æ­¤ä¹‹å‰çš„å·¥ä½œï¼š</p>
<p><img src="/images/15673013678116.jpg" width="50%" height="50%"></p>
<p>å¤§æ¦‚åšæ³•æ˜¯ï¼Œè®¾å®šå‡ ä¸ªé˜Ÿåˆ—ï¼Œå¦‚æœå½“å‰çš„sampleé¢„æµ‹å¯¹äº†ï¼Œå°±å°†è¯¥sample pushåˆ°åä¸€ä¸ªé˜Ÿåˆ—ï¼Œå¦åˆ™å°±å°†å…¶pushåˆ°å‰ä¸€ä¸ªé˜Ÿåˆ—æˆ–ç¬¬ä¸€ä¸ªé˜Ÿåˆ—ã€‚è¶Šåé¢çš„é˜Ÿåˆ—è¢«reviewçš„é—´éš”è¶Šé•¿ã€‚ç›¸å½“äºè®¤ä¸ºè¶Šåé¢çš„è¶Šç®€å•ï¼Œéœ€è¦è¢«è®­ç»ƒåˆ°çš„æ¬¡æ•°è¶Šå°‘ã€‚</p>
<p>ä½†è¿™é‡Œçš„é—´éš”æ˜¯æ‰‹åŠ¨è®¾å®šçš„ï¼ˆ2çš„kæ¬¡æ–¹ï¼‰ï¼Œå¹¶ä¸æ˜¯å¾ˆå‡†ã€‚æœ¬æ–‡æå‡ºçš„å°±æ˜¯åŠ¨æ€è®¾å®šè¿™æ ·ä¸€ä¸ªé—´éš”ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>è®¾$x_{i}=\frac{d_{i} \times t_{i}}{s_{e}}$</p>
<p>dæ˜¯è¯¥sampleçš„lossï¼Œtæ˜¯è¿˜æœ‰å‡ ä¸ªepochè¢«reviewåˆ°ï¼›såˆ™æ˜¯åœ¨validation dataä¸Šçš„performanceã€‚</p>
<p>xæ˜¯ä¸åŒæ ¸å‡½æ•°çš„å˜é‡ï¼š</p>
<p>$f_{g a u}(x, \tau)=\exp \left(-\tau x^{2}\right)$</p>
<p>$f_{l a p}(x, \tau)=\exp (-\tau x)$</p>
<p>$f_{l i n}(x, \tau)=\left\{\begin{array}{ll}{1-\tau x} &amp; {x&lt;\frac{1}{\tau}} \\ {0} &amp; {\text { otherwise }}\end{array}\right.$</p>
<p>$f_{\sec }(x, \tau)=\frac{2}{\exp \left(-\tau x^{2}\right)+\exp \left(\tau x^{2}\right)}$</p>
<p>ç­‰ç­‰ã€‚</p>
<p>ä¸åŒæ ¸å‡½æ•°çš„æ›²çº¿ï¼š</p>
<p><img src="/images/15673016101025.jpg" width="40%" height="50%"></p>
<p>æˆ‘ä»¬ç”¨æ ¸å‡½æ•°æ¥é¢„ä¼°ä¸€ä¸ªæ ·æœ¬è¢«reviewçš„é—´éš”ã€‚</p>
<p><img src="/images/15673017081202.jpg" width="50%" height="50%"></p>
<p>å¦‚æœtå°äºç­‰äº1ï¼Œåˆ™é€‰åšå½“å‰çš„è®­ç»ƒæ•°æ®ã€‚ä¸€å¼€å§‹å¤§å®¶éƒ½æ˜¯1ã€‚å…¶ä»–æœªè¢«é€‰ä¸­çš„è®°å½•åœ¨delayed batché‡Œã€‚<br>åœ¨è®­ç»ƒå®Œä¸€ä¸ªepochåï¼Œè·å¾—validä¸Šçš„accuracyã€‚é€šè¿‡validationæ¥é¢„ä¼°å½“å‰çš„$\tau$ï¼š</p>
<script type="math/tex; mode=display">\hat{\tau}=\arg \min _{\tau}\left(f\left(x_{j}, \tau\right)-a_{j}\right)^{2}, \forall h_{j} \in \mathbf{V}, a_{j} \geq \eta</script><p>å…¶ä¸­$a$æ˜¯accuracyã€‚<br>æ¥ç€åˆ©ç”¨è¿™ä¸ª$\tau$å»é¢„ä¼°å½“å‰è®­ç»ƒæ•°æ®çš„delay $t$ã€‚<br>æœ€åå°†delay batchçš„tå‡1ï¼Œå› ä¸ºå·²ç»è®­ç»ƒè¿‡äº†ä¸€ä¸ªepochäº†ã€‚</p>
<p>å®é™…ä¸Šå°±ç›¸å½“äºåˆ©ç”¨å¯†åº¦æ ¸å‡½æ•°å»åŠ¨æ€é¢„ä¼°å‚æ•°tã€‚</p>
<hr>
<h2 id="A-Simple-Theoretical-Model-of-Importance-for-Summarization"><a href="#A-Simple-Theoretical-Model-of-Importance-for-Summarization" class="headerlink" title="[A Simple Theoretical Model of Importance for Summarization]"></a>[A Simple Theoretical Model of Importance for Summarization]</h2><p>æå‡ºsummaryä»»åŠ¡çš„å‡ ä¸ªæŒ‡æ ‡ï¼ŒRedundancy, Relevance, and Informativenessï¼Œä»¥åŠç»Ÿä¸€è¿™ä¸‰ä¸ªæŒ‡æ ‡çš„Importanceã€‚æœ¬æ–‡è´¡çŒ®æ˜¯å°†ä¿¡æ¯è®ºå¼•å…¥ï¼Œå¹¶è¯æ˜å…¶ä»–è¿‡å»çš„å·¥ä½œå¯ä»¥æ”¾åœ¨è¿™ä¸ªæ¡†æ¶ä¸‹ã€‚</p>
<p>è®°semantic unitä½œä¸ºåŸºæœ¬å•ä½ï¼Œ$\Omega$æ˜¯æ‰€æœ‰semantic unitçš„é›†åˆï¼Œ$X$æ˜¯æ–‡æœ¬ã€‚$\mathbb{P}_{X}\left(\omega_{i}\right)$åˆ™æ˜¯æ–‡æœ¬$X$å‡ºç°è¯¥unitçš„æ¦‚ç‡ã€‚</p>
<p>$D$æ˜¯source documentï¼›$S$æ˜¯candidate summaryã€‚</p>
<h3 id="Redundancy"><a href="#Redundancy" class="headerlink" title="Redundancy"></a>Redundancy</h3><p>$S$çš„äº¤å‰ç†µï¼š</p>
<script type="math/tex; mode=display">H(S)=-\sum_{\omega_{i}} \mathbb{P}_{S}\left(\omega_{i}\right) \cdot \log \left(\mathbb{P}_{S}\left(\omega_{i}\right)\right)</script><p>å¼•å…¥redundancyï¼š</p>
<script type="math/tex; mode=display">\operatorname{Red}(S)=H_{\max }-H(S)</script><p>å¯ä»¥ç®€å†™ä¸ºï¼š$\operatorname{Red}(S)=-H(S)$</p>
<p>å½“æ‰€æœ‰çš„semantic unitçš„æ¦‚ç‡ç›¸åŒæ—¶ï¼Œredundancyæœ€å¤§ã€‚å› ä¸ºè¿™æ ·å°±æ²¡æœ‰ä»€ä¹ˆæœ‰ç”¨çš„ä¿¡æ¯äº†ã€‚</p>
<h3 id="Relevance"><a href="#Relevance" class="headerlink" title="Relevance"></a>Relevance</h3><script type="math/tex; mode=display">\operatorname{Rel}(S, D)=\sum_{\omega_{i}} \mathbb{P}_{S}\left(\omega_{i}\right) \cdot \log \left(\mathbb{P}_{D}\left(\omega_{i}\right)\right)</script><p>è¡¡é‡$S$ä¸$D$çš„å…³è”åº¦ã€‚</p>
<p>A summary with a low expected surprise produces a low uncertainty about what were the original sourcesã€‚summaryç›¸å½“äºå¯¹æºæ–‡æ¡£çš„æœ‰æŸå‹ç¼©ï¼Œå› æ­¤åº”å°½å¯èƒ½å‡å°è¯¥æŸå¤±ã€‚</p>
<p>relevanceä¸redundancyçš„è”ç³»ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} K L(S| | D) &=C E(S, D)-H(S) \\-K L(S| | D) &=\operatorname{Rel}(S, D)-\operatorname{Red}(S) \end{aligned}</script><p>KL divergence is the information loss incurred by using D as an approximation of S (i.e., the uncertainty about D arising from observing S instead of D). <strong>A summarizer that minimizes the KL divergence minimizes Redundancy while maximizing Relevance.</strong></p>
<h3 id="Informativeness"><a href="#Informativeness" class="headerlink" title="Informativeness"></a>Informativeness</h3><p>relevanceå¿½ç•¥äº†å¤–éƒ¨çŸ¥è¯†ã€‚å°†å¤–éƒ¨çŸ¥è¯†å¼•å…¥ï¼Œa summary is informative if it induces, for a user, a great change in her knowledge about the world.</p>
<script type="math/tex; mode=display">\operatorname{Inf}(S, K)=-\sum_{\omega_{i}} \mathbb{P}_{S}\left(\omega_{i}\right) \cdot \log \left(\mathbb{P}_{K}\left(\omega_{i}\right)\right)</script><p>å…¶ä¸­$K$æ˜¯background knowledgeã€‚</p>
<p>for Informativeness, the cross-entropy between S and K should be high because we measure the amount of new information induced by the summary in our knowledge.</p>
<h3 id="Importance"><a href="#Importance" class="headerlink" title="Importance"></a>Importance</h3><p>å…¶å®å°±æ˜¯å°†relevanceä¸informativenessç»“åˆèµ·æ¥ã€‚</p>
<script type="math/tex; mode=display">\begin{aligned} \mathbb{P}_{\frac{D}{K}}\left(\omega_{i}\right) &=\frac{1}{C} \cdot \frac{d_{i}^{\alpha}}{k_{i}^{\beta}} \\ C &=\sum_{i} \frac{d_{i}^{\alpha}}{k_{i}^{\beta}}, \alpha, \beta \in \mathbb{R}^{+} \end{aligned}</script><hr>
<h2 id="Attending-to-Future-Tokens-for-Bidirectional-Sequence-Generation"><a href="#Attending-to-Future-Tokens-for-Bidirectional-Sequence-Generation" class="headerlink" title="[Attending to Future Tokens for Bidirectional Sequence Generation]"></a>[Attending to Future Tokens for Bidirectional Sequence Generation]</h2><p>åŸºäºbertçš„æ€æƒ³ï¼Œå¼•å…¥åŒå‘çš„åºåˆ—ç”Ÿæˆï¼Œä¹Ÿå³ç”Ÿæˆçš„è¿‡ç¨‹ä¸­å¯ä»¥çœ‹åˆ°å·¦å³ä¸¤è¾¹ã€‚</p>
<p>åŸºæœ¬åšæ³•æ˜¯ï¼šé¦–å…ˆå°†xä¸yæ‹¼èµ·æ¥ï¼Œç„¶åå°†yç”¨placeholderæ›¿ä»£ï¼Œè¿‡transformer encoderå»uncoverè¿™äº›placeholderã€‚</p>
<p><img src="/images/15673034453669.jpg" width="80%" height="50%"></p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åœ¨è®­ç»ƒæ—¶å€™ï¼Œå¼•å…¥Placeholder Replacement Strategyï¼Œé‡‡ç”¨ä¼¯åŠªåˆ©åˆ†å¸ƒæˆ–é«˜æ–¯åˆ†å¸ƒéšæœºå°†éƒ¨åˆ†çš„è¯ç”¨placeholderæ›¿ä»£ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å°†å…¶recoverã€‚</p>
<p>åœ¨ç”Ÿæˆæ—¶ï¼Œæœ‰å‡ ç§æ–¹æ¡ˆï¼š</p>
<p>One-step greedyï¼š ç›´æ¥åŒæ—¶å°†æ‰€æœ‰çš„placeholderä¸€æ¬¡æ€§recoverã€‚<br>Highest probabilityï¼šä¸€æ­¥ä¸€æ­¥æ¥ï¼Œæ¯æ¬¡uncoveræ¦‚ç‡æœ€å¤§çš„é‚£ä¸ªtokenã€‚<br>Lowest entropyï¼š é€‰æ‹©ç†µæœ€å°çš„ï¼Œè¿™ä»£è¡¨äº†å…¶ä¸ç¡®å®šæ€§æœ€å°ã€‚<br>Left-to-rightï¼šå°±æ˜¯ä»å·¦åˆ°å³ï¼Œä½†æœªæ¥çš„placeholderä¹Ÿä¼šattendåˆ°ã€‚</p>
<h3 id="ä¸€ç‚¹æ€è€ƒ"><a href="#ä¸€ç‚¹æ€è€ƒ" class="headerlink" title="ä¸€ç‚¹æ€è€ƒ"></a>ä¸€ç‚¹æ€è€ƒ</h3><p>è¿™å®é™…ä¸Šå°±æœ‰ç‚¹åƒä»»æ„é¡ºåºçš„åºåˆ—ç”Ÿæˆã€‚ä½†ä¼¼ä¹è®¾è®¡æœ‰äº›ç²—ç³™ï¼Œä¸”å®éªŒæ²¡æœ‰åœ¨ç¿»è¯‘ä¸Šè·‘ï¼Œå¯èƒ½æ˜¯åœ¨ç¿»è¯‘ä¸Šæ²¡æœ‰æ•ˆæœã€‚ä¸”è®ºæ–‡ä¼¼ä¹æ²¡æœ‰æåˆ°å¦‚ä½•åŠ position encodingã€‚<br>æ€»ä½“æ€æƒ³è¿˜æ˜¯æ¯”è¾ƒæ¸…æ™°çš„ï¼Œå¦‚æœç”¨äºç¿»è¯‘è®¾è®¡å¾—åº”è¯¥æ›´ç²¾å·§ä¸€äº›ã€‚å¦å¤–ä¸€ä¸ªé—®é¢˜æ˜¯åœæ­¢æ¡ä»¶æ˜¯ä»€ä¹ˆè®ºæ–‡ä¼¼ä¹ä¹Ÿæ²¡æåˆ°ï¼Œå¤§æ¦‚ä¹Ÿæ˜¯å½“ç”Ÿæˆåˆ°EOSå°±åœæ­¢å§ã€‚placeholderçš„ä¸ªæ•°æ˜¯æ€ä¹ˆç¡®å®šçš„ï¼Ÿonly placeholder tokens up to some pre-determined maximum sequence lengthã€‚</p>
<hr>
<h2 id="Sequence-Generation-From-Both-Sides-to-the-Middle"><a href="#Sequence-Generation-From-Both-Sides-to-the-Middle" class="headerlink" title="[Sequence Generation: From Both Sides to the Middle]"></a>[Sequence Generation: From Both Sides to the Middle]</h2><p>æå‡ºä»å·¦åˆ°å³å’Œä»å³åˆ°å·¦çš„åŒæ—¶decodingã€‚æ›´å¤šçš„ç®—æ˜¯æ¨¡å‹ä¸Šçš„åˆ›æ–°å§ï¼Œä½†æ„Ÿè§‰æ²¡æœ‰ä»€ä¹ˆinsightã€‚</p>
<p>ä¸ºä»€ä¹ˆè¦ä»ä¸¤ç«¯åˆ°ä¸­é—´ï¼š<br>inferenceçš„æ—¶å€™èƒ½åŠ é€Ÿï¼›èƒ½å¤Ÿattendåˆ°æœªæ¥çš„è¯ï¼Œç¼“è§£under-translationï¼›</p>
<h3 id="æ–¹æ³•-2"><a href="#æ–¹æ³•-2" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15673038459325.jpg" width="50%" height="50%"></p>
<p>åœ¨decodeç«¯ï¼Œå…ˆforwardä¸backwardè‡ªè¡Œåšattentionï¼ˆintraï¼‰ï¼Œç„¶åäºŒè€…å†åšäº¤äº’ï¼ˆinterï¼‰ã€‚</p>
<p><img src="/images/15673038731825.jpg" width="60%" height="50%"></p>
<h3 id="ä¸€ç‚¹æ€è€ƒ-1"><a href="#ä¸€ç‚¹æ€è€ƒ-1" class="headerlink" title="ä¸€ç‚¹æ€è€ƒ"></a>ä¸€ç‚¹æ€è€ƒ</h3><p>ä»ä¸¤ç«¯åˆ°ä¸­é—´çš„æƒ³æ³•ä¸é”™ï¼Œè¿‡å»åº”è¯¥ä¹Ÿæœ‰è®ºæ–‡åšè¿‡è¿™æ ·çš„å°è¯•ã€‚ä½†æœ¬æ–‡æœ‰ç‚¹åƒä¸¤å¹´å‰çš„è®ºæ–‡ï¼Œä»æ¨¡å‹çš„ç»“æ„å…¥æ‰‹ï¼Œæ”¹æ”¹æ¨¡å‹è·‘è·‘å®éªŒå°±å‘å‡ºæ¥ï¼Œæœ‰ç‚¹åƒå®éªŒæŠ¥å‘Šã€‚å¹¶æ²¡æœ‰æä¾›ä¸€äº›æ›´æœ‰ä»·å€¼çš„insightï¼Œéš¾ä»¥followã€‚åŒæ—¶ï¼Œæœ¬æ–‡ä¹Ÿæ²¡æœ‰æpositionåº”è¯¥å¦‚ä½•åŠ ï¼Ÿè¿™ç‚¹æˆ–è®¸å¾ˆå…³é”®ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>Summary</tag>
        <tag>Sequence Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•19</title>
    <url>/2019/08/18/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9519/</url>
    <content><![CDATA[<h3 id="Pythonè·å¾—listä¸­topkçš„index"><a href="#Pythonè·å¾—listä¸­topkçš„index" class="headerlink" title="[Pythonè·å¾—listä¸­topkçš„index]"></a>[Pythonè·å¾—listä¸­topkçš„index]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">9</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">9</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ind = np.argpartition(a, <span class="number">-4</span>)[<span class="number">-4</span>:]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ind</span><br><span class="line">array([<span class="number">1</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[ind]</span><br><span class="line">array([<span class="number">4</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ³¨æ„æ˜¯æ²¡æœ‰æ’å¥½åºçš„ï¼Œæ•ˆç‡æ›´é«˜</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸‹é¢çš„æ˜¯æ’å¥½åºçš„</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: arr = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: arr.argsort()[<span class="number">-3</span>:][::<span class="number">-1</span>]</span><br><span class="line">Out[<span class="number">3</span>]: array([<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯34</title>
    <url>/2019/08/18/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D34/</url>
    <content><![CDATA[<h3 id="èµ°é©¬å·è¡Œå¥‰é€å°å¤§å¤«å‡ºå¸ˆè¥¿å¾"><a href="#èµ°é©¬å·è¡Œå¥‰é€å°å¤§å¤«å‡ºå¸ˆè¥¿å¾" class="headerlink" title="èµ°é©¬å·è¡Œå¥‰é€å°å¤§å¤«å‡ºå¸ˆè¥¿å¾"></a>èµ°é©¬å·è¡Œå¥‰é€å°å¤§å¤«å‡ºå¸ˆè¥¿å¾</h3><p>[å”] å²‘å‚<br>å›ä¸è§èµ°é©¬å·è¡Œé›ªæµ·è¾¹ï¼Œå¹³æ²™è½è½é»„å…¥å¤©ã€‚<br>è½®å°ä¹æœˆé£å¤œå¼ï¼Œä¸€å·ç¢çŸ³å¤§å¦‚æ–—ï¼Œéšé£æ»¡åœ°çŸ³ä¹±èµ°ã€‚<br>åŒˆå¥´è‰é»„é©¬æ­£è‚¥ï¼Œé‡‘å±±è¥¿è§çƒŸå°˜é£ï¼Œæ±‰å®¶å¤§å°†è¥¿å‡ºå¸ˆã€‚<br>å°†å†›é‡‘ç”²å¤œä¸è„±ï¼ŒåŠå¤œå†›è¡Œæˆˆç›¸æ‹¨ï¼Œé£å¤´å¦‚åˆ€é¢å¦‚å‰²ã€‚<br>é©¬æ¯›å¸¦é›ªæ±—æ°”è’¸ï¼Œäº”èŠ±è¿é’±æ—‹ä½œå†°ï¼Œå¹•ä¸­è‰æª„ç šæ°´å‡ã€‚<br>è™éª‘é—»ä¹‹åº”èƒ†æ…‘ï¼Œæ–™çŸ¥çŸ­å…µä¸æ•¢æ¥ï¼Œè½¦å¸ˆè¥¿é—¨ä¼«çŒ®æ·ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡28</title>
    <url>/2019/08/17/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8728/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Easy Questions First? A Case Study on Curriculum Learning for Question Answering</li>
<li>Bridging the Gap between Training and Inference for Neural Machine Translation</li>
<li>Improving Multi-step Prediction of Learned Time Series Models</li>
<li>Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</li>
<li>SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS</li>
<li>Minimum Risk Training for Neural Machine Translation</li>
<li>Greedy Search with Probabilistic N-gram Matching for Neural Machine Translation</li>
<li>Insertion Transformer: Flexible Sequence Generation via Insertion Operations</li>
</ol>
<h2 id="Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering"><a href="#Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering" class="headerlink" title="[Easy Questions First? A Case Study on Curriculum Learning for Question Answering]"></a>[Easy Questions First? A Case Study on Curriculum Learning for Question Answering]</h2><p>æå‡ºåœ¨QAä¸­å¼•å…¥CLï¼Œä½†å®é™…ä¸Šå…¶æœ¬è´¨ä¸æ˜¯CLè€Œæ›´åƒæ˜¯SPLã€‚</p>
<p>QAä»»åŠ¡æˆ‘ä¸æ„Ÿå…´è¶£ï¼Œåªè®¨è®ºCLã€‚</p>
<p>å…¶åŸºæœ¬åšæ³•æ˜¯ï¼šæ¯æ¬¡ä»å‰©ä¸‹æœªè¢«é€‰æ‹©çš„æ•°æ®ä¸­é€‰æ‹©å¯¹äºå½“å‰æ¨¡å‹æœ€ç®€å•çš„sampleï¼Œå¹¶å®šä¹‰äº†ä¸€ç³»åˆ—çš„æŒ‡æ ‡å»è¡¡é‡éš¾æ˜“ç¨‹åº¦ï¼Œè¿™ç›¸å½“äºæ˜¯<strong>åŠ¨æ€</strong>åœ¨é€‰æ‹©sampleï¼Œæ ¹æ®å½“å‰çš„æ¨¡å‹èƒ½åŠ›å»é€‰æ‹©æœ€å®¹æ˜“å­¦çš„sampleï¼Œä»æ•´ä¸ªè¿‡ç¨‹æ¥çœ‹ï¼Œç¡®å®æ˜¯ä»ç®€å•åˆ°éš¾ï¼Œä¸”è¾¾åˆ°äº†åŠ¨æ€é€‰æ‹©çš„ç›®çš„ï¼Œå¹¶ä¸”ä¸åƒSPLé‚£æ ·ä¼šç›´æ¥ä¸¢å¼ƒsampleï¼Œæ•ˆç‡ï¼ˆæˆ–è®¸ï¼‰ä¼šæ›´é«˜ã€‚</p>
<p>å…·ä½“åšæ³•ï¼š<br>æ¯æ¬¡ä»å‰©ä½™sampleé›†åˆå†…é€‰æ‹©æœ€ç®€å•çš„sample $q_{i} \in Q \backslash Q_{0}$ã€‚</p>
<p>æœ‰å‡ ç§æŒ‡æ ‡è¡¡é‡å¯¹äºå½“å‰æ¨¡å‹çš„éš¾æ˜“ç¨‹åº¦ï¼š<br>â‘ Greedy Optimal: has the minimum expected effect on the model<br>Change in Objective causes the smallest increase in the objective.<br>â‘¡Mini-max minimizes the regularized expected risk when including the question with the answer candidate a ij that yields the maximum error.<br>â‘¢Expected Change in Objective the minimum expected effect on the model<br>â‘£Change in Objective-Expected Change in Objective the minimum value of the difference between the change in objective and the expected change in objective<br>â‘¤Correctly Answered is answered by the model M with the minimum cost</p>
<p>åŒæ—¶ï¼Œå¸Œæœ›æ¯æ¬¡é€‰çš„batchï¼Œå°½é‡diverseï¼Œé€šè¿‡feature spaceçš„å¤¹è§’å»è¡¡é‡ã€‚</p>
<p>è¿™ä¸ªæ€æƒ³è¿˜æŒºæœ‰æ„æ€çš„ï¼Œä½†æ¯æ¬¡é€‰æ‹©sampleéƒ½è¦é‡æ–°è®¡ç®—ä¸€éï¼Œä¼šä¸ä¼šå¤æ‚åº¦è¿‡é«˜ï¼Ÿ</p>
<hr>
<h2 id="Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation"><a href="#Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation" class="headerlink" title="[Bridging the Gap between Training and Inference for Neural Machine Translation]"></a>[Bridging the Gap between Training and Inference for Neural Machine Translation]</h2><p>è¿™æ˜¯ACL19çš„best paperã€‚</p>
<p>æœ¬æ–‡ä¸»è¦çš„ç›®æ ‡æ˜¯ç¼“è§£exposure biasçš„é—®é¢˜ï¼Œä¹Ÿå³è®­ç»ƒä½¿ç”¨ground truthè€Œinferenceä½¿ç”¨predicted wordsæ‰€é€ æˆçš„ä¸ä¸€è‡´ã€‚ä¸»è¦æ€è·¯æ˜¯ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä»predicted wordå’Œground truth é‡‡æ ·ä½œä¸ºæ¥ä¸‹æ¥çš„ä¸Šä¸‹æ–‡ã€‚</p>
<p>å½“å‰è¿™ç§discrepancyçš„é—®é¢˜å°±æ˜¯<strong>è¿‡åº¦çº æ­£ï¼ˆovercorrectionï¼‰</strong>ï¼Œåªè¦æ¨¡å‹ç”Ÿæˆäº†ä¸€ä¸ªå’Œground truthä¸ä¸€æ ·çš„ï¼Œå°±ä¼šè¢«ç«‹å³çº æ­£ï¼Œä½†å®é™…ä¸Šç¿»è¯‘å¯ä»¥æœ‰å¥½å‡ ç§åˆç†çš„å€™é€‰ï¼Œå¹¶ä¸æ˜¯å’Œground truthä¸ä¸€æ ·å°±é”™è¯¯ï¼›åŒæ—¶åœ¨è®­ç»ƒæ—¶æœ‰ç›‘ç£ï¼Œè€Œåœ¨inferenceæ²¡æœ‰ä¿¡å·ç›‘ç£ï¼Œpredicted wordåœ¨ä¸åŒé˜¶æ®µæ˜¯ä»ä¸åŒçš„åˆ†å¸ƒè·å–çš„ï¼Œä¹Ÿå³data distribution vs model distributionï¼Œè¿™å°±æ˜¯exposure biaså¸¦æ¥çš„é—®é¢˜ã€‚</p>
<p>è®ºæ–‡ä¸¾äº†ä¸€ä¸ªä¾‹å­ï¼š<br><img src="/images/15660513298758.jpg" width="40%" height="50%"></p>
<p>â‘ å‡å¦‚æ¨¡å‹ç”Ÿæˆäº†ç¬¬ä¸‰ä¸ªè¯ä¸ºabideï¼Œä¸ºäº†å’Œground truthç›¸ä¸€è‡´ï¼Œæ¨¡å‹ä¼šå¼ºåˆ¶è®©ç¬¬å››ä¸ªè¯ç”Ÿæˆwithï¼Œç„¶åwithä½œä¸ºè¾“å…¥å»ç”Ÿæˆthe ruleï¼Œä½†å®é™…ä¸Šæ•´å¥æ˜¯é”™è¯¯çš„ã€‚å¦‚cand1å°±æ˜¯è¿‡åº¦çŸ«æ­£ï¼ˆovercorrectionï¼‰<br>â‘¡å‡è®¾æ¨¡å‹ç”Ÿæˆå¯¹äº†byï¼Œä½†ä¹Ÿå¯èƒ½å› ä¸ºè¾“å…¥äº†byè€Œäº§ç”Ÿäº†é”™è¯¯çš„â€™the lawâ€™ï¼Œå‡è®¾ä¸€ç§æƒ…å½¢ï¼Œæ¨¡å‹è®°ä½äº†withåé¢ä¸€å®šè·Ÿthe ruleï¼Œä¸ºäº†èƒ½å¤Ÿç”Ÿæˆcand3çš„ï¼Œæˆ‘ä»¬åº”å°† withä½œä¸ºè¾“å…¥è€Œä¸æ˜¯byï¼Œå³ä½¿æˆ‘ä»¬ç”Ÿæˆäº†byã€‚ç§°è¿™ç§åšæ³•ä¸º overcorrection recoveryã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å› æ­¤æœ¬æ–‡çš„åšæ³•å°±æ˜¯å°†é¢„æµ‹çš„è¯ï¼ˆoracleï¼‰å’Œgolden åœ¨è®­ç»ƒçš„æ—¶å€™éšæœºsampleä½œä¸ºè¾“å…¥ã€‚åœ¨ä¸€å¼€å§‹æ¨¡å‹è¿˜æ²¡æœ‰æ”¶æ•›çš„æ—¶å€™ï¼Œä¸»è¦æ˜¯goldenï¼Œè€Œåœ¨åæœŸåˆ™å¢åŠ oracleçš„æ¯”ä¾‹ã€‚</p>
<p><img src="/images/15660514154749.jpg" width="50%" height="50%"></p>
<p>è¿™æ ·æ¨¡å‹å°±èƒ½å¤Ÿhandleåœ¨inferenceå‡ºç°çš„æƒ…å†µï¼Œä¹Ÿå³æ²¡æœ‰golden truthçš„è¾…åŠ©ï¼ŒåŒæ—¶å¯ä»¥å‡å°è®­ç»ƒå’Œæµ‹è¯•ä¹‹é—´çš„gapã€‚</p>
<p>æœ‰ä¸¤ç§æ–¹æ³•è·å¾—oracle wordï¼Œä¸€ç§æ˜¯word levelçš„ä¸€ç§æ˜¯sentence levelçš„ã€‚</p>
<h4 id="Oracle-word-selection"><a href="#Oracle-word-selection" class="headerlink" title="Oracle word selection"></a>Oracle word selection</h4><h5 id="word-level"><a href="#word-level" class="headerlink" title="word level"></a>word level</h5><p>ä¹Ÿå³greedyçš„æ–¹æ³•ï¼Œæ¯æ¬¡é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è¯ä½œä¸ºoracle</p>
<p><img src="/images/15660518415062.jpg" width="50%" height="50%"></p>
<p>ä¸ºäº†è·å–æ›´ä¸ºé²æ£’çš„oracleï¼Œå¼•å…¥äº†gumbel noiseï¼Œè¿™æ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ã€‚</p>
<script type="math/tex; mode=display">
\begin{aligned} \eta=&-\log (-\log u) \\ \tilde{o}_{j-1} &=\left(o_{j-1}+\eta\right) / \tau \\ \tilde{P}_{j-1} &=\operatorname{softmax}\left(\tilde{o}_{j-1}\right) \end{aligned}</script><p>å½“$\tau$è¶‹äº0ï¼Œåˆ™é€¼è¿‘argmaxï¼Œè‹¥è¶‹äºâˆåˆ™é€¼è¿‘å‡åŒ€é‡‡æ ·ã€‚</p>
<p><img src="/images/15660519181632.jpg" width="60%" height="50%"></p>
<p>å› æ­¤æœ€ç»ˆï¼š</p>
<script type="math/tex; mode=display">y_{j-1}^{\text {oracle }}=y_{j-1}^{\mathrm{WO}}=\operatorname{argmax}\left(\tilde{P}_{j-1}\right)</script><h5 id="sentence-level"><a href="#sentence-level" class="headerlink" title="sentence level"></a>sentence level</h5><p>å¦ä¸€ç§åˆ™æ˜¯æ‰©å¤§åŒ¹é…çš„èŒƒå›´ï¼Œå…è®¸æ›´çµæ´»çš„é€‰æ‹©ï¼Œä¹Ÿå³å…ˆé€šè¿‡beam searchè®©æ¨¡å‹ç”Ÿæˆä¸€ä¸ªæ¦‚ç‡æœ€é«˜çš„å¥å­ï¼Œå°†è¯¥å¥å­çš„è¯ä¸ground truthä¸€ä¸€å¯¹åº”ï¼Œåœ¨ç”ŸæˆæœŸé—´ä¹Ÿå¯ä»¥å¼•å…¥gumbel noiseã€‚ä¸€ä¸€å¯¹åº”çš„è¯å°±å¯ä»¥éšæœºé‡‡æ ·äº†ã€‚</p>
<p>ä½†è¯¥åšæ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿå³å¯èƒ½ç”Ÿæˆçš„å¥å­é•¿åº¦å¯èƒ½å’Œground truthä¸å¯¹åº”ï¼Œå› æ­¤è¿™é‡Œå¼•å…¥<strong>force decoding</strong>çš„åšæ³•å¼ºåˆ¶å¯¹åº”ã€‚</p>
<p><strong>force decoding</strong></p>
<p>â‘ å½“ç”Ÿæˆåˆ°ç¬¬jä¸ªstepæ—¶top firstçš„æ¦‚ç‡æ˜¯EOSï¼Œæ­¤æ—¶$j \leqslant\left|\mathbf{y}^{*}\right|$ï¼Œé‚£ä¹ˆé¿å¼€EOSï¼Œé€‰æ‹©top secondæ¦‚ç‡çš„è¯ï¼Œä½¿å…¶èƒ½å¤Ÿç»§ç»­ç”Ÿæˆä¸‹å»ã€‚</p>
<p>â‘¡å½“ç”Ÿæˆåˆ°$\left\{\left|\mathbf{y}^{*}\right|+1\right\}$ä¸ªæ—¶è¿˜æ²¡ç”Ÿæˆåˆ°EOSï¼Œåˆ™ç›´æ¥é€‰æ‹©EOSä½œä¸ºç»“å°¾ï¼Œå¼ºåˆ¶åœæ­¢ã€‚</p>
<h4 id="Sampling-with-Decay"><a href="#Sampling-with-Decay" class="headerlink" title="Sampling with Decay"></a>Sampling with Decay</h4><p>å¦ä¸€ä¸ªå°±æ˜¯åœ¨æ¨¡å‹ä¸åŒé˜¶æ®µsampleçš„æ¦‚ç‡åº”è¯¥æ˜¯ä¸åŒçš„ï¼Œåœ¨è¿™é‡Œ</p>
<script type="math/tex; mode=display">p=\frac{\mu}{\mu+\exp (e / \mu)}</script><p>eæ˜¯epochæ•°ã€‚</p>
<h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p><img src="/images/15660521569189.jpg" width="80%" height="50%"></p>
<p>å®éªŒè¡¨æ˜èƒ½å¤Ÿæœ‰æ›´å¥½çš„æ•ˆæœï¼Œä¸”æ›´å¿«é€Ÿæ”¶æ•›ï¼Œåªçœ‹trainingå¯ä»¥å‘ç°ï¼Œæ²¡æœ‰baselineé‚£ä¹ˆå®¹æ˜“overfittingã€‚</p>
<p><img src="/images/15660521805452.jpg" width="50%" height="50%"></p>
<p><img src="/images/15660521942211.jpg" width="50%" height="50%"></p>
<p>å¯¹äºé•¿åº¦è¶Šé•¿çš„æå‡è¶Šå¤§ï¼Œè¯´æ˜exposure biasåœ¨é•¿å¥å­è¡¨ç°æ›´æ˜æ˜¾ã€‚</p>
<p><img src="/images/15660522167431.jpg" width="40%" height="50%"></p>
<p>åœ¨ä¸åŒæ•°æ®é›†å’Œä¸åŒæ¨¡å‹ä¸Šéƒ½æœ‰æå‡ï¼š</p>
<p><img src="/images/15660522455047.jpg" width="40%" height="50%"></p>
<h3 id="ä¸€ç‚¹æ€è€ƒ"><a href="#ä¸€ç‚¹æ€è€ƒ" class="headerlink" title="ä¸€ç‚¹æ€è€ƒ"></a>ä¸€ç‚¹æ€è€ƒ</h3><p>æœ¬ç¯‡å¾ˆæ¸…æ™°æ˜“æ‡‚ï¼Œç»“æ„ä¹Ÿå¾ˆå¥½ï¼ŒåŒæ—¶ä¸¾çš„ä¾‹å­ä¹Ÿéå¸¸å®¹æ˜“è®©äººç†è§£ã€‚å†è€…å®éªŒæ•ˆæœä¹Ÿå¾ˆå¥½ï¼Œåšäº†å¾ˆå¤šåˆ†æã€‚è¿™ä¸ªæ–¹å‘å¯ä»¥å¤šå…³æ³¨å…³æ³¨ï¼Œå› ä¸ºè¿˜æœ‰æŒºå¤šå¯åšçš„ã€‚</p>
<p>æˆ‘ä»¬å‡è®¾è®©trainingä¹Ÿå®Œå…¨ç”¨predictedæ˜¯ä¸€ä¸ªæç«¯ï¼Œå®Œå…¨ç”¨ground truthæ˜¯å¦ä¸€ä¸ªæç«¯ï¼Œåœ¨æ­¤äºŒè€…ä¹‹é—´çš„å°±æ˜¯è¿™ç§sampleæ–¹å¼ã€‚</p>
<p>ä½†ä¼¼ä¹ä»ç„¶æœ‰æœªè§£å†³çš„é—®é¢˜ï¼Œä¹Ÿå³target wordå§‹ç»ˆæ˜¯ground truthï¼Œè¿™ç§æ–¹æ³•å¥½åƒè¿˜æ˜¯æ²¡èƒ½è§£å†³overcorrectionçš„é—®é¢˜ã€‚</p>
<hr>
<h2 id="Improving-Multi-step-Prediction-of-Learned-Time-Series-Models"><a href="#Improving-Multi-step-Prediction-of-Learned-Time-Series-Models" class="headerlink" title="[Improving Multi-step Prediction of Learned Time Series Models]"></a>[Improving Multi-step Prediction of Learned Time Series Models]</h2><p>è®¨è®ºå¦‚ä½•åœ¨æ—¶åºæ¨¡å‹ä¸‹è§£å†³é”™è¯¯ç´¯ç§¯çš„é—®é¢˜ï¼ˆåœ¨ç¿»è¯‘ä¸­å°±æ˜¯exposure biasï¼‰ï¼Œè¯¥é—®é¢˜çš„æœ¬è´¨å°±æ˜¯train-testçš„iidå‡è®¾è¢«æ‰“ç ´ã€‚æœ¬æ–‡çš„åšæ³•å°±æ˜¯å°†predictionä¸training dataç»“åˆå½¢æˆæ–°çš„æ•°æ®é›†ï¼Œä¹Ÿå³ç›¸å½“äºç”¨æ­£ç¡®çš„æ•°æ®å¯¹predictionè¿›è¡Œä¿®æ­£ã€‚å¹¶ä¸”ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥ç®—æ³•çš„é«˜æ•ˆæ€§ã€‚</p>
<p>ç¤ºä¾‹å›¾å¾ˆæ¸…æ¥šï¼š<br><img src="/images/15660523604587.jpg" width="40%" height="50%"></p>
<p>å›¾aæ˜¯åœ¨è®­ç»ƒå®Œä¸€ä¸ªæ¨¡å‹ååšçš„é¢„æµ‹ä¸çœŸå®æ•°æ®çš„å¯¹æ¯”ï¼›å›¾bæ˜¯å°†é¢„æµ‹çš„åºåˆ—ä¸æ­£ç¡®çš„åºåˆ—ç»“åˆå½¢æˆæ–°çš„åºåˆ—ï¼Œé‡æ–°è®­æ–°æ¨¡å‹ã€‚å…¶å®å°±ç›¸å½“äºç”¨æ­£ç¡®æ•°æ®åšäº†ä¿®æ­£ã€‚</p>
<p>å› æ­¤ç®—æ³•å°±æœ‰ï¼š</p>
<p><img src="/images/15660523930825.jpg" width="50%" height="50%"></p>
<p>ç®—æ³•è¿‡ç¨‹æ¸…æ™°æ˜äº†ã€‚åœ¨è®­ç»ƒå¤šä¸ªæ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œæ•°æ®ä¼šè¶Šæ¥è¶Šå¤šï¼Œæœ‰recurrentçš„æ„Ÿè§‰ã€‚å…¶å®è¿™ä¸ªæ–¹æ³•çš„æœ¬è´¨ä¸Šä¹Ÿæ˜¯åœ¨ground truthå’Œoracleä¸Šè¿›è¡Œsamplingï¼Œå› ä¸ºæ•°æ®Dé‡Œé¢æ··æ‚äº†ground truthæˆ–oracleã€‚</p>
<hr>
<h2 id="Scheduled-Sampling-for-Sequence-Prediction-with-Recurrent-Neural-Networks"><a href="#Scheduled-Sampling-for-Sequence-Prediction-with-Recurrent-Neural-Networks" class="headerlink" title="[Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks]"></a>[Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks]</h2><p>åœ¨sequence predictionçš„é—®é¢˜ä¸Šï¼Œæå‡ºschedule samplingçš„æ–¹å¼ç¼“è§£exposure biasçš„é—®é¢˜ã€‚exposure biasæ˜¯æŒ‡è®­ç»ƒä½¿ç”¨teacher forceï¼Œå®Œå…¨ç”¨ç›‘ç£ä¿¡æ¯ï¼Œè€ŒinferenceæœŸé—´å®Œå…¨ç”¨predicted wordï¼Œé”™è¯¯å¯èƒ½ä¼šè¢«æ”¾å¤§ã€‚</p>
<p>å…¶åšæ³•æ˜¯ï¼šåœ¨è®­ç»ƒæœŸé—´ï¼ŒæŒ‰æ¦‚ç‡è¾“å…¥golden truthæˆ–è€…predicted wordï¼Œè¯¥æ¦‚ç‡é€šè¿‡æŸç§scheduleæ¥æ§åˆ¶ã€‚è¿™é‡Œçš„åšæ³•å°±æ˜¯åœ¨è®­ç»ƒæœŸé—´æ¦‚ç‡é‡‡æ ·è¾“å…¥predicted wordï¼Œè®©æ¨¡å‹è‡ªå·±å»å­¦ä¹ å¦‚ä½•è§£å†³inferenceå¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚</p>
<p><img src="/images/15660525698952.jpg" width="40%" height="50%"></p>
<p>è€Œscheduleåˆ™æ˜¯ï¼š</p>
<p><img src="/images/15660525988009.jpg" width="40%" height="50%"></p>
<p>æœªè§£å†³çš„é—®é¢˜ï¼štarget wordä»ç„¶æ˜¯golden truthã€‚samplingè¿™ç±»æ€è·¯éƒ½ä¼šæœ‰è¿™ä¸ªé—®é¢˜ã€‚</p>
<hr>
<h2 id="SEQUENCE-LEVEL-TRAINING-WITH-RECURRENT-NEURAL-NETWORKS"><a href="#SEQUENCE-LEVEL-TRAINING-WITH-RECURRENT-NEURAL-NETWORKS" class="headerlink" title="[SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS]"></a>[SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS]</h2><p>æœ¬æ–‡æ„åœ¨è§£å†³ç¿»è¯‘ä¸­å­˜åœ¨çš„exposure biasä»¥åŠæµ‹è¯•é˜¶æ®µçš„æŒ‡æ ‡å’Œè®­ç»ƒæŒ‡æ ‡ä¸åŒçš„é—®é¢˜ã€‚</p>
<p>å…¶åšæ³•æ˜¯ï¼šæå‡ºä¸€ç§åŸºäºRLçš„ç®—æ³•ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ··åˆäº†RLå’Œæ™®é€šè®­ç»ƒæ–¹æ³•ï¼Œæ—¢èƒ½ä¼˜åŒ–word levelçš„lossåˆèƒ½ç›´æ¥ä¼˜åŒ–sentence levelçš„bleuã€‚åŒæ—¶è¯¥æ–¹æ³•è¿˜è§£å†³äº†RLåœ¨random initä¸Šéš¾ä»¥æ‹Ÿåˆè¶…å¤§çš„search spaceçš„é—®é¢˜ï¼Œå› ä¸ºä½¿ç”¨äº†é¢„è®­ç»ƒçš„å‚æ•°ã€‚</p>
<p>æ¥ä¸‹æ¥ä»‹ç»å‡ ä¸ªç›¸å…³çš„æ¨¡å‹ã€‚</p>
<h3 id="WORD-LEVEL-TRAINING"><a href="#WORD-LEVEL-TRAINING" class="headerlink" title="WORD-LEVEL TRAINING"></a>WORD-LEVEL TRAINING</h3><h4 id="CROSS-ENTROPY-TRAINING-XENT"><a href="#CROSS-ENTROPY-TRAINING-XENT" class="headerlink" title="CROSS ENTROPY TRAINING (XENT)"></a>CROSS ENTROPY TRAINING (XENT)</h4><p>ä¹Ÿå³æ™®é€šçš„è®­ç»ƒæ–¹å¼ï¼Œæ¯æ¬¡è¾“å…¥golden truthï¼Œç„¶åä¼˜åŒ–loss<br>è¿™æ˜¯è¯¥æ¨¡å‹åœ¨è®­ç»ƒä¸inferenceæ—¶çš„ç¤ºæ„å›¾ï¼š</p>
<p><img src="/images/15660527119463.jpg" width="80%" height="50%"></p>
<p>ä¸»è¦é—®é¢˜ï¼šâ‘ exposure bias  â‘¡è®­ç»ƒæŒ‡æ ‡æ˜¯word levelçš„è€Œæµ‹è¯•æŒ‡æ ‡åˆ™æ˜¯sentence levelçš„ï¼Œé€ æˆè®­ç»ƒæ²¡æ³•ç›´æ¥ä¼˜åŒ–æµ‹è¯•çš„æŒ‡æ ‡ã€‚</p>
<h4 id="DATA-AS-DEMONSTRATOR-DAD"><a href="#DATA-AS-DEMONSTRATOR-DAD" class="headerlink" title="DATA AS DEMONSTRATOR (DAD)"></a>DATA AS DEMONSTRATOR (DAD)</h4><p>æ··åˆoracleä¸ground truthï¼š</p>
<p><img src="/images/15660527382516.jpg" width="90%" height="50%"></p>
<p>ä¸€ä¸ªé—®é¢˜åœ¨äºï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥tï¼Œtarget labelæ€»æ˜¯ground truthè€Œä¸ç®¡è¾“å…¥æ˜¯oracleæˆ–è€…ground truthã€‚è¿™æ ·å¯èƒ½å°±ä¼šé€ æˆä¸å¯¹é½çš„é—®é¢˜ï¼Œæ¯”å¦‚ï¼š<br>æ­£ç¡®çš„ç¿»è¯‘æ˜¯â€œI took a long walkâ€ï¼Œæ¨¡å‹ç›®å‰ç¿»è¯‘åˆ°â€œI took a walkâ€ï¼Œè€Œåœ¨æ¥ä¸‹æ¥æ¨¡å‹ä¼šå¼ºåˆ¶å†ç¿»è¯‘ä¸€æ¬¡wark<br>å¦ä¸€ä¸ªé—®é¢˜åœ¨äºï¼Œæ¢¯åº¦å›ä¼ æ²¡æœ‰åˆ°oracleï¼Œä¹Ÿå³oracleè™½ç„¶æ˜¯ç”±æ¨¡å‹ç”Ÿæˆçš„ï¼Œä½†gradientçš„å¾…é‡å’Œground truthæ˜¯ä¸€æ ·çš„ï¼Œä¸”ä»ç„¶å±€é™äºword-levelã€‚</p>
<h4 id="END-TO-END-BACKPROP-E2E"><a href="#END-TO-END-BACKPROP-E2E" class="headerlink" title="END-TO-END BACKPROP (E2E)"></a>END-TO-END BACKPROP (E2E)</h4><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¹Ÿä½¿ç”¨oracleè€Œä¸æ˜¯ground truthã€‚</p>
<p>åœ¨æ¯ä¸ªæ—¶é—´æ­¥tä¸Šï¼Œæˆ‘ä»¬é€‰æ‹©top kä¸ªé¢„æµ‹çš„è¯ä½œä¸ºä¸‹ä¸€ä¸ªè¾“å…¥è€Œä¸æ˜¯ground truthã€‚å…·ä½“çš„åšæ³•æ˜¯å°†softmaxè¿‡åçš„distributionè¿‡ä¸€ä¸ªk-max layerï¼Œå°†å…¶ä»–çš„éƒ½è®¾ä¸º0ï¼Œç„¶åå†renormalizeä½¿å…¶å’Œä¸º1ï¼Œæ­¤æ—¶æˆ‘ä»¬æœ‰ï¼š</p>
<script type="math/tex; mode=display">\left\{i_{t+1, j}, v_{t+1, j}\right\}_{j=1, \ldots, k}=\mathrm{k}-\max p_{\theta}\left(w_{t+1} | w_{t}, h_{t}\right)</script><p>å…¶ä¸­iæ˜¯indexï¼Œvæ˜¯å¯¹åº”çš„scoreï¼Œä¹Ÿä½œä¸ºå…¶weightï¼Œç”¨äºæ¢¯åº¦å›ä¼ ã€‚</p>
<p><img src="/images/15660528416693.jpg" width="90%" height="50%"></p>
<p>åœ¨å®é™…å®ç°ä¸­ï¼Œä¸€å¼€å§‹è¿˜æ˜¯ç”¨ground truthçš„ï¼Œç›´åˆ°è®­ç»ƒåæœŸæ‰ä½¿ç”¨top-kçš„ç­–ç•¥ã€‚</p>
<p>è¯¥æ–¹æ³•ç¡®å®è§£å†³äº†training-inferenceçš„discrepancyï¼Œä½†ä»ç„¶è¿˜æ˜¯word-levelçš„ã€‚</p>
<h3 id="SEQUENCE-LEVEL-TRAINING"><a href="#SEQUENCE-LEVEL-TRAINING" class="headerlink" title="SEQUENCE LEVEL TRAINING"></a>SEQUENCE LEVEL TRAINING</h3><p>ä½¿ç”¨RLç›´æ¥å¯¹bleuè¿›è¡Œä¼˜åŒ–ã€‚RNNæ˜¯agentï¼Œactionæ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œagentçš„å‚æ•°å°±æ˜¯policyï¼Œåœ¨é¢„æµ‹å®Œè¯¥å¥å­åï¼ŒBLEUå°±æ˜¯rewardã€‚</p>
<p>ç”±äºRLéš¾ä»¥ä»random initå»æ‹Ÿåˆå¤§æœç´¢ç©ºé—´ï¼Œå› æ­¤æ˜¯å…ˆé€šè¿‡æ™®é€šçš„è®­ç»ƒRNNï¼Œç„¶åç”¨è¯¥å‚æ•°å»ä½œä¸ºinitå»è®­ç»ƒæ¥ä¸‹æ¥çš„RLã€‚</p>
<p>ç¬¬äºŒå°±æ˜¯ï¼Œä¸ºäº†è®­ç»ƒçš„ç¨³å®šï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å¼•å…¥oracleï¼ˆRLéƒ¨åˆ†ï¼‰ã€‚åœ¨å‰$(T-\Delta)$ä¸ªstepç”¨æ™®é€šçš„XENTï¼Œç„¶åæ¥ä¸‹æ¥çš„$\Delta$ä¸ªstepä½¿ç”¨RLå»ç”Ÿæˆã€‚é€æ¸å¢å¤§$\Delta$ç›´åˆ°æ•´ä¸ªè®­ç»ƒéƒ½æ˜¯ç”±RLç”Ÿæˆçš„:</p>
<p><img src="/images/15660530021248.jpg" width="90%" height="50%"></p>
<p>å› æ­¤MIXERçš„ç®—æ³•å¦‚ä¸‹ï¼š</p>
<p><img src="/images/15660530338643.jpg" width="80%" height="50%"></p>
<p>æ€»ç»“ä¸€ä¸‹å‡ ä¸ªç®—æ³•ï¼š</p>
<p><img src="/images/15660530482870.jpg" width="80%" height="50%"></p>
<h3 id="ä¸€ç‚¹æƒ³æ³•"><a href="#ä¸€ç‚¹æƒ³æ³•" class="headerlink" title="ä¸€ç‚¹æƒ³æ³•"></a>ä¸€ç‚¹æƒ³æ³•</h3><p>ä¼¼ä¹è¦çœŸæ­£è§£å†³ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•çš„ä¸¤ä¸ªé—®é¢˜ï¼Œå°±åªèƒ½é€šè¿‡ç›´æ¥ä¼˜åŒ–test evaluation metricæ¥åšåˆ°ï¼Œè€Œåƒç›´æ¥é’ˆå¯¹è§£å†³exposure biasçš„æ–¹æ³•ï¼ˆscheduled samplingç­‰ï¼‰éƒ½æ²¡åŠæ³•çœŸæ­£è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚</p>
<hr>
<h2 id="Minimum-Risk-Training-for-Neural-Machine-Translation"><a href="#Minimum-Risk-Training-for-Neural-Machine-Translation" class="headerlink" title="[Minimum Risk Training for Neural Machine Translation]"></a>[Minimum Risk Training for Neural Machine Translation]</h2><p>åœ¨ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œç›´æ¥é€šè¿‡ä¼˜åŒ–evaluation metricå¦‚bleuè€Œä¸æ˜¯word-levelçš„lossæ¥æå‡è¡¨ç°ã€‚</p>
<p>æˆ‘ä»¬æ™®é€šçš„æ–¹æ³•æ˜¯é€šè¿‡ä¼˜åŒ–è¯çº§åˆ«çš„lossï¼Œä¹Ÿå³MLEï¼ˆmaximum likelihood estimationï¼‰ï¼Œæ¯ä¸ªstepçš„é¢„æµ‹å’Œgolden truthè®¡ç®—cross entropyç„¶åç´¯åŠ ã€‚ä½†è¿™ä¸ªæ–¹æ³•çš„ä¸¤ä¸ªåŠ£åŠ¿ï¼šexposure bias å’Œ loss functionåªå®šä¹‰åœ¨è¯çº§åˆ«è€Œä¸æ˜¯å¥å­çº§åˆ«ï¼Œè€Œåœ¨æµ‹è¯•é˜¶æ®µåˆ™æ˜¯ç”¨bleuè¿™ç§å¥å­çº§åˆ«çš„metricæ¥è¯„æµ‹ã€‚</p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>è®°$\left\langle\mathbf{x}^{(s)}, \mathbf{y}^{(s)}\right\rangle$æ˜¯sentence-pairï¼ŒåŒæ—¶æœ‰$\Delta\left(\mathbf{y}, \mathbf{y}^{(s)}\right)$ä½œä¸ºpredictionä¸golden truthä¹‹é—´çš„å·®è·ï¼Œè¿™æ˜¯ä¸å¯å¯¼çš„ã€‚</p>
<p>å®šä¹‰expected lossï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned} \mathcal{R}(\boldsymbol{\theta}) &=\sum_{s=1}^{S} \mathbb{E}_{\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}}\left[\Delta\left(\mathbf{y}, \mathbf{y}^{(s)}\right)\right] \\ &=\sum_{s=1}^{S} \sum_{\mathbf{y} \in \mathcal{Y}\left(\mathbf{x}^{(s)}\right)} P\left(\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}\right) \Delta\left(\mathbf{y}, \mathbf{y}^{(s)}\right) \end{aligned}</script><p>å…¶ä¸­$\mathcal{Y}\left(\mathbf{x}^{(s)}\right)$æ˜¯æ‰€æœ‰çš„å¯èƒ½çš„candidateï¼ŒPå°±æ˜¯ç”Ÿæˆè¯¥candidateçš„æ¦‚ç‡ã€‚</p>
<p>å› æ­¤æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯ï¼š</p>
<script type="math/tex; mode=display">\hat{\boldsymbol{\theta}}_{\mathrm{MRT}}=\underset{\boldsymbol{\theta}}{\operatorname{argmin}}\{\mathcal{R}(\boldsymbol{\theta})\}</script><p>ä¹Ÿå³ï¼Œå¸Œæœ›ç”Ÿæˆå‡ºæ¥å¥å­ä¸­çš„ä¸golden truthçš„å·®è·æœ€å°çš„æ¦‚ç‡æœ€å¤§ã€‚</p>
<p>ä¸€ä¸ªå¾ˆæ¸…æ™°çš„ä¾‹å­ï¼š</p>
<p><img src="/images/15660534305129.jpg" width="80%" height="50%"></p>
<p>å³è¾¹å››åˆ—æ˜¯å››ä¸ªä¸åŒçš„æ¨¡å‹ï¼Œy1ï¼Œy2ä¸y3æ˜¯ä¸‰ä¸ªä¸åŒçš„candidateï¼Œå…¶ä¸­y1ä¸yæœ€æ¥è¿‘ï¼Œè€Œy2æœ€è¿œã€‚ç¬¬å››åˆ—ç”Ÿæˆy1çš„æ¦‚ç‡æœ€é«˜ï¼Œy2æœ€ä½ï¼Œå› æ­¤å¯ä»¥çœ‹åˆ°å…¶é£é™©æœŸæœ›æœ€å°ã€‚ä¹Ÿå³æˆ‘ä»¬çš„ç›®æ ‡æ€»æ˜¯å¸Œæœ›æœ€å¤§æ¦‚ç‡ç”Ÿæˆä¸golden truthæœ€æ¥è¿‘çš„æ ·æœ¬ã€‚</p>
<p>ï¼ˆè¿™é‡Œå°±æœ‰ç‚¹åƒRLäº†ï¼Œç”Ÿæˆäº†å‡ ä¸ªepisodeï¼Œå¸Œæœ›rewardæœ€å¤§çš„episodeå‡ºç°çš„å¯èƒ½æ€§æ›´å¤§ã€‚è€Œæ™®é€šçš„è®­ç»ƒæ–¹æ³•åˆ™æ˜¯åœ¨æ¯æ­¥éƒ½ä¼˜åŒ–ã€‚ï¼‰</p>
<p>åœ¨å®é™…ä¸­ï¼Œç”±äºä¸å¯èƒ½éå†æ‰€æœ‰çš„æƒ…å†µï¼Œå› æ­¤åªé€‰æ‹©ä¸€ä¸ªcandidate subsetï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} \tilde{\mathcal{R}}(\boldsymbol{\theta}) &=\sum_{s=1}^{S} \mathbb{E}_{\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}, \alpha}\left[\Delta\left(\mathbf{y}, \mathbf{y}^{(s)}\right)\right] \\ &=\sum_{s=1}^{S} \sum_{\mathbf{y} \in \mathcal{S}\left(\mathbf{x}^{(s)}\right)} Q\left(\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}, \alpha\right) \Delta\left(\mathbf{y}, \mathbf{y}^{(s)}\right) \end{aligned}</script><p>å…¶ä¸­$\mathcal{S}\left(\mathbf{x}^{(s)}\right) \subset \mathcal{Y}\left(\mathbf{x}^{(s)}\right)$ï¼Œä¸”$Q$æ˜¯subsetçš„distributionï¼Œä¿è¯å’Œä¸º1ã€‚</p>
<script type="math/tex; mode=display">Q\left(\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}, \alpha\right)=\frac{P\left(\mathbf{y} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}\right)^{\alpha}}{\sum_{\mathbf{y}^{\prime} \in \mathcal{S}\left(\mathbf{x}^{(s)}\right)} P\left(\mathbf{y}^{\prime} | \mathbf{x}^{(s)} ; \boldsymbol{\theta}\right)^{\alpha}}</script><p>å…¶ä¸­$Î±$æ§åˆ¶$Q$çš„sharpç¨‹åº¦ã€‚</p>
<p>è€Œsample subsetçš„æ–¹å¼ï¼š</p>
<p><img src="/images/15660535677759.jpg" width="90%" height="50%"></p>
<p>æœ‰ç‚¹åƒbeam-searchçš„probabilistic sampling ç‰ˆã€‚å®éªŒè®¾k=100ã€‚</p>
<h3 id="æƒ³æ³•"><a href="#æƒ³æ³•" class="headerlink" title="æƒ³æ³•"></a>æƒ³æ³•</h3><p>æœ¬æ–‡çš„MRTåœ¨SMTä¸Šæœ‰ä½¿ç”¨è¿‡ã€‚æ€è·¯æœ‰ç‚¹åƒRLï¼Œè®ºæ–‡ä¸­ä¹Ÿæœ‰æåˆ°è¿™ç‚¹ï¼Œåœ¨æ€è·¯ä¸Šä¸MIXERç›¸è¿‘ã€‚ä¸”trainingä¸testçš„è¡Œä¸ºä¸€è‡´ï¼ˆæ²¡æœ‰exposure biasçš„é—®é¢˜ï¼‰ï¼Œä¹Ÿç›´æ¥ä¼˜åŒ–äº†sentence-levelçš„æŒ‡æ ‡ï¼Œä¸€æ¬¡è§£å†³äº†ä¸¤ä¸ªé—®é¢˜ã€‚</p>
<hr>
<h2 id="Greedy-Search-with-Probabilistic-N-gram-Matching-for-Neural-Machine-Translation"><a href="#Greedy-Search-with-Probabilistic-N-gram-Matching-for-Neural-Machine-Translation" class="headerlink" title="[Greedy Search with Probabilistic N-gram Matching for Neural Machine Translation]"></a>[Greedy Search with Probabilistic N-gram Matching for Neural Machine Translation]</h2><p>å¼•å…¥å¯å¯¼çš„sentence levelçš„è¯„ä»·æŒ‡æ ‡ï¼ŒåŒæ—¶åœ¨æ­¤åŸºç¡€ä¸Šè®­ç»ƒè¿‡ç¨‹ä¹Ÿä½¿ç”¨greedy searchè€Œä¸æ˜¯teacher forcingï¼Œèƒ½å¤Ÿç¼“è§£ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•å¸¦æ¥çš„ exposure biaså’Œword-level losså¸¦æ¥çš„training-testä¹‹é—´çš„æŒ‡æ ‡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</p>
<h3 id="ä¼ ç»Ÿåšæ³•"><a href="#ä¼ ç»Ÿåšæ³•" class="headerlink" title="ä¼ ç»Ÿåšæ³•"></a>ä¼ ç»Ÿåšæ³•</h3><script type="math/tex; mode=display">P(\hat{\boldsymbol{y}} | \boldsymbol{x})=\prod_{j=1}^{T} p\left(\hat{y}_{j} | \hat{\boldsymbol{y}}_{<j}, \boldsymbol{x}, \theta\right)</script><script type="math/tex; mode=display">\boldsymbol{\theta}=\arg \max _{\theta}\{\mathcal{L}(\theta)\}</script><script type="math/tex; mode=display">\mathcal{L}(\theta)=\sum_{m=1}^{M} \sum_{j=1}^{l^{m}} \log \left(p\left(\hat{y}_{j}^{m} | \hat{\boldsymbol{y}}_{<j}^{m}, \boldsymbol{x}^{m}, \theta\right)\right)</script><h3 id="è®ºæ–‡åšæ³•"><a href="#è®ºæ–‡åšæ³•" class="headerlink" title="è®ºæ–‡åšæ³•"></a>è®ºæ–‡åšæ³•</h3><p>å¥å­çº§åˆ«çš„evaluation metricsï¼Œæ¯”å¦‚BLEUæ˜¯åŸºäºn-gramçš„åŒ¹é…çš„ã€‚è®°$y$å’Œ$\hat{y}$æ˜¯predictionå’Œground truthï¼Œé•¿åº¦åˆ†åˆ«ä¸º$T$å’Œ$Tâ€™$ã€‚</p>
<p>è®°n-gram $\boldsymbol{g}=\left(g_{1}, \ldots, g_{n}\right)$ï¼Œåˆ™åœ¨$y$ä¸­è®¡ç®—ngramçš„countä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathrm{C}_{\boldsymbol{y}}(\boldsymbol{g})=\sum_{t=0}^{T-n} \prod_{i=1}^{n} 1\left\{g_{i}=y_{t+i}\right\}</script><p>åœ¨$y$ä¸$\hat{y}$ä¹‹é—´çš„countåˆ™ä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathbf{C}_{\boldsymbol{y}}^{\hat{y}}(\boldsymbol{g})=\min \left(\mathbf{C}_{\boldsymbol{y}}(\boldsymbol{g}), \mathbf{C}_{\hat{\boldsymbol{y}}}(\boldsymbol{g})\right)</script><p>precisionå’Œrecallåˆ™ä¸ºï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} p_{n} &=\frac{\sum_{\boldsymbol{g} \in \boldsymbol{y}} \mathbf{C}_{\boldsymbol{y}}^{\hat{y}}(\boldsymbol{g})}{\sum_{\boldsymbol{g} \in \boldsymbol{y}} \mathbf{C}_{\boldsymbol{y}}(\boldsymbol{g})} \\ r_{n} &=\frac{\sum_{\boldsymbol{g} \in \boldsymbol{y}} \mathbf{C}_{\boldsymbol{y}}^{\hat{y}}(\boldsymbol{g})}{\sum_{\boldsymbol{g} \in \hat{\boldsymbol{y}}} \mathbf{C}_{\hat{\boldsymbol{y}}}(\boldsymbol{g})} \end{aligned}</script><p>è€ŒBLEUçš„è®¡ç®—æ–¹æ³•ä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathrm{BLEU}=\mathrm{BP} \cdot \exp \left(\sum_{n=1}^{N} w_{n} \log p_{n}\right)</script><p>BPä¸ºbrevity penaltyï¼Œ$w_n$æ˜¯n-gramçš„weightã€‚</p>
<p>ä¸Šè¿°å…¬å¼ï¼Œå¯ä»¥çœ‹åˆ°å°†æ‰€æœ‰çš„è¾“å‡ºçš„è¯ä¸€è§†åŒä»ï¼Œä½†å®é™…ä¸Šåœ¨è¾“å‡ºçš„ä¸åŒçš„è¯æ˜¯æœ‰ä¸åŒçš„æ¦‚ç‡çš„ï¼Œå› æ­¤åº”è¯¥å¯¹n-gram countæœ‰æ›´ç²¾ç»†çš„æè¿°ï¼Œä¹Ÿå³å°†é¢„æµ‹çš„æ¦‚ç‡ä¹Ÿå¼•å…¥ï¼š</p>
<script type="math/tex; mode=display">\widetilde{\mathbf{C}}_{\boldsymbol{y}}(\boldsymbol{g})=\sum_{t=0}^{T-n} \prod_{i=1}^{n} 1\left\{g_{i}=y_{t+i}\right\} \cdot p\left(y_{t+i} | \boldsymbol{y}_{<t+i}, \boldsymbol{x}, \theta\right)</script><p>å› æ­¤bleuä¹Ÿæ›´æ–°ä¸ºï¼š</p>
<script type="math/tex; mode=display">\widetilde{\mathbf{C}}_{\boldsymbol{y}}^{\hat{\boldsymbol{y}}}(\boldsymbol{g})=\min \left(\widetilde{\mathbf{C}}_{\boldsymbol{y}}(\boldsymbol{g}), \mathbf{C}_{\hat{\boldsymbol{y}}}(\boldsymbol{g})\right)</script><script type="math/tex; mode=display">\tilde{p}_{n}=\frac{\sum_{\boldsymbol{g} \in \boldsymbol{y}} \widetilde{\mathbf{C}}_{\boldsymbol{y}}^{\hat{y}}(\boldsymbol{g})}{\sum_{\boldsymbol{g} \in \boldsymbol{y}} \widetilde{\mathbf{C}}_{\boldsymbol{y}}(\boldsymbol{g})}</script><script type="math/tex; mode=display">\mathrm{P}-\mathrm{BLEU}=\mathrm{BP} \cdot \exp \left(\sum_{n=1}^{N} w_{n} \log \tilde{p}_{n}\right)</script><p>æœ€ç»ˆçš„loss functionä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}(\theta)=-\sum_{m=1}^{M} \mathcal{P}\left(\boldsymbol{y}^{m}, \hat{\boldsymbol{y}}^{m}\right)</script><p>ç¤ºæ„å›¾ï¼š</p>
<p><img src="/images/15660541121139.jpg" width="80%" height="50%"></p>
<p>åœ¨è¿™é‡Œï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ä¹Ÿä½¿ç”¨äº†greedy searchè€Œä¸æ˜¯teacher forcingã€‚ä¸”æœ¬æ–‡æ˜¯ä½¿ç”¨baselineåœ¨probabilistic lossä¸Šfine-tuneçš„ï¼Œå› ä¸ºæ¨¡å‹ä¸€å¼€å§‹çš„èƒ½åŠ›å¾ˆå¼±ï¼Œä¸è¶³ä»¥ç¿»è¯‘æœ‰æ„ä¹‰çš„å¥å­ï¼Œæ²¡æ³•è®­ã€‚</p>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>ä½œè€…åšäº†ä¸€ä¸ªå®éªŒæ¢ç©¶æ˜¯exposure biasçš„ç¼“è§£è¿˜æ˜¯é‡‡ç”¨äº†sentence-levelçš„losså¸¦æ¥çš„æå‡ï¼Ÿ</p>
<p><img src="/images/15660541846618.jpg" width="50%" height="50%"></p>
<p>ä½œè€…å‘ç°äºŒè€…éƒ½æœ‰å¸¦æ¥æå‡ï¼Œä¸ç¼“è§£exposure biasï¼ˆä¹Ÿå³ä½¿ç”¨äº†teacher forcingï¼‰èƒ½æå‡0.5ï¼Œè€Œä½¿ç”¨greedy searchåˆ™å¸¦æ¥BLEUå€¼1ä¸ªç‚¹çš„æå‡ã€‚</p>
<h3 id="æƒ³æ³•-1"><a href="#æƒ³æ³•-1" class="headerlink" title="æƒ³æ³•"></a>æƒ³æ³•</h3><p>ç”¨äº†æ•´ä½“çš„æŒ‡æ ‡ä¸”ç”¨äº†greedy searchï¼Œä¹Ÿå°±ç¼“è§£äº†ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•çš„ä¸¤ä¸ªå¼Šç«¯ã€‚ä½†è¿™ä¸ªæ–¹æ³•æ˜¾ç„¶æ²¡æ³•ä»å¤´è®­ï¼Œå› æ­¤éœ€è¦fine-tuneï¼Œä½†fine-tuneæ˜¯åŸºäºåŸå…ˆçš„æ¨¡å‹è¡Œä¸ºè¿›è¡Œæ”¹å˜ï¼Œæ˜¯å¦å¯èƒ½å‡ºç°å·²ç»å¡åœ¨minimalä¸Šçš„æƒ…å†µï¼Ÿå¦‚æœèƒ½å¤Ÿæ‰¾åˆ°ä¸€ä¸ªæ–¹æ³•ä»å¤´è®­ï¼Œå¯èƒ½ä¼šæ›´å¥½ï¼Ÿ</p>
<hr>
<h2 id="Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations"><a href="#Insertion-Transformer-Flexible-Sequence-Generation-via-Insertion-Operations" class="headerlink" title="[Insertion Transformer: Flexible Sequence Generation via Insertion Operations]"></a>[Insertion Transformer: Flexible Sequence Generation via Insertion Operations]</h2><p>æå‡ºä¸€ç§æ–°çš„éƒ¨åˆ†è‡ªå›å½’çš„æ–‡æœ¬ç”Ÿæˆæ–¹å¼ï¼ŒåŸºäºæ’å…¥æ“ä½œï¼Œæ¯æ¬¡ç”Ÿæˆçš„è¯æ’å…¥åˆ°æ–‡æœ¬ä»»æ„ä½ç½®ã€‚åŒæ—¶ï¼Œä¸ä»…èƒ½å¤Ÿæ¯æ¬¡ç”Ÿæˆä¸€ä¸ªè¯ï¼Œè¿˜èƒ½å¤ŸåŒæ—¶ç”Ÿæˆå¤šä¸ªè¯æ’å…¥åˆ°ä¸åŒä½ç½®ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<p><img src="/images/15660543170148.jpg" width="90%" height="50%"></p>
<p>åœ¨æ¯ä¸ªiteration tï¼Œæ¨¡å‹ä¼šäº§ç”Ÿä¸€ä¸ªè”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œå…³äºé¢„æµ‹çš„contentå’Œæ’å…¥ä½ç½®l $l \in\left[0,\left|\hat{y}_{t}\right|\right]$ã€‚</p>
<h3 id="Insertion-Transformer-Model"><a href="#Insertion-Transformer-Model" class="headerlink" title="Insertion Transformer Model"></a>Insertion Transformer Model</h3><p>ä¸transformer decoderä¸åŒçš„åœ°æ–¹ï¼š<br>â‘ å»æ‰äº†maskï¼Œæ‰€æœ‰ä½ç½®éƒ½èƒ½å¤Ÿattendåˆ°å¯¹æ–¹ã€‚<br>â‘¡æ ‡å‡†transformerç”Ÿæˆnä¸ªå‘é‡è¡¨ç¤ºï¼Œå°†æœ€åä¸€ä¸ªè¡¨ç¤ºç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè€Œåœ¨è¿™é‡Œéœ€è¦ç”Ÿæˆn+1ä¸ªè¡¨ç¤ºï¼Œä¹Ÿå³slot representationï¼Œæ¯ä¸¤ä¸ªè¯ä¹‹é—´å…±n-1ä¸ªè¡¨ç¤ºï¼ŒåŠ ä¸Šå¼€å¤´ä¸ç»“å°¾ä¸¤ä¸ªã€‚é€šè¿‡åŠ å‰åä¸¤ä¸ªç‰¹æ®Šçš„æ ‡è®°ç¬¦ï¼Œè¿‡transformeråè·å¾—n+2ä¸ªå‘é‡ï¼Œå¹¶å°†æ¯ä¸¤ä¸ªç›¸é‚»çš„å‘é‡æ‹¼èµ·æ¥è·å¾—n+1ä¸ªå‘é‡ã€‚</p>
<h4 id="Model-Variants"><a href="#Model-Variants" class="headerlink" title="Model Variants"></a>Model Variants</h4><p>æ¨¡å‹æœ‰ä¸¤ä¸ªå˜ä½“ï¼Œä¸€ä¸ªæ˜¯ç›´æ¥å»ºæ¨¡è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œå¦ä¸€ä¸ªåˆ™æ˜¯æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚</p>
<p>è®°$H \in \mathbb{R}^{(T+1) \times h}$ä¸ºslot representationï¼ŒTæ˜¯å½“å‰çš„ç”Ÿæˆå¥å­çš„é•¿åº¦ï¼Œ$W \in \mathbb{R}^{h \times|\mathcal{C}|}$åˆ™æ˜¯softmaxçš„æ˜ å°„çŸ©é˜µã€‚</p>
<p>å› æ­¤å¯ä»¥ç›´æ¥å»ºæ¨¡è”åˆæ¦‚ç‡åˆ†å¸ƒï¼š</p>
<script type="math/tex; mode=display">p(c, l)=\operatorname{softmax}(\text {flatten}(H W))</script><p>å…ˆè®¡ç®—$HW$ç„¶åå±•å¼€è¿‡softmaxï¼Œæœ€å¤§çš„å€¼å¯¹åº”å…¶vocabçš„ä½ç½®ä»¥åŠç›¸åº”çš„slotçš„ä½ç½®ã€‚</p>
<p>å¦ä¸€ç§æ–¹æ³•åˆ™æ˜¯é€šè¿‡è®¡ç®—æ¡ä»¶æ¦‚ç‡ï¼š</p>
<script type="math/tex; mode=display">p(c, l)=p(c | l) p(l)</script><p>å…¶ä¸­$p(c | l)=\operatorname{softmax}\left(h_{l} W\right)$ï¼Œè€Œ$p(l)=\operatorname{softmax}(H q)$ï¼Œ$q$æ˜¯å¯å­¦ä¹ çš„å‚æ•°ã€‚</p>
<p>å¦å¤–ï¼Œä¸ºäº†å¢åŠ slotä¹‹é—´çš„ä¿¡æ¯äº¤æµï¼Œå¯é€šè¿‡max-poolingè·å¾—ä¸Šä¸‹æ–‡çš„å‘é‡$g$ï¼Œå†é€šè¿‡å¯å­¦ä¹ çš„$V$ç”Ÿæˆä¸€ä¸ªå…±äº«çš„biasç”¨äºè®¡ç®—æ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} g &=\operatorname{maxpool}(H) \\ b &=g V \\ B &=\operatorname{repmat}(b,[T+1,1]) \\ p(c, l) &=\operatorname{softmax}(H W+B) \end{aligned}</script><h3 id="Training-and-Loss-Functions"><a href="#Training-and-Loss-Functions" class="headerlink" title="Training and Loss Functions"></a>Training and Loss Functions</h3><p>æœ‰ä¸¤ç§é¡ºåºï¼Œä¸€ç§æ˜¯ä»å·¦åˆ°å³ï¼Œå¦ä¸€ç§åˆ™æ˜¯å¹³è¡¡äºŒå‰æ ‘çš„å½¢å¼ã€‚</p>
<h4 id="Left-to-Right"><a href="#Left-to-Right" class="headerlink" title="Left-to-Right"></a>Left-to-Right</h4><p>ç»™å®šè®­ç»ƒæ ·æœ¬$(x, y)$ï¼Œå…ˆéšæœºsample é•¿åº¦$k \sim$ Uniform $([0,|y|])$ï¼Œå¹¶ä¸”å‡å®šå·²ç»ç”Ÿæˆäº†å·¦è¾¹kä¸ªè¯ï¼Œ$\hat{y}=\left(y_{1}, \dots, y_{k}\right)$ï¼Œç›®æ ‡åˆ™æ˜¯maximize location l=kçš„æ¦‚ç‡ï¼š</p>
<script type="math/tex; mode=display">\operatorname{loss}(x, \hat{y})=-\log p\left(y_{k+1}, k | x, \hat{y}\right)</script><h4 id="Balanced-Binary-Tree"><a href="#Balanced-Binary-Tree" class="headerlink" title="Balanced Binary Tree"></a>Balanced Binary Tree</h4><p>æˆ‘ä»¬å¸Œæœ›æœ€ä¸­å¿ƒçš„è¯å…ˆç”Ÿæˆï¼Œç„¶åå·¦å³ä¸¤ç«¯çš„ä¸­å¿ƒè¯ï¼Œç„¶åå·¦å³ä¸¤ç«¯çš„å·¦å³ä¸¤ç«¯çš„ä¸­å¿ƒè¯ï¼Œåƒä¸€æ£µæ ‘é‚£æ ·ã€‚<br>å¦‚ï¼š$[ ] \rightarrow[D] \rightarrow[B, D, F] \rightarrow[A, B, C, D, E, F, G]$</p>
<p>ä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®çš„ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿä¼˜å…ˆå¼ºè°ƒä¸­å¿ƒé™„è¿‘çš„è¯ã€‚</p>
<p>ç»™å®š$(x, y)$ï¼Œé¦–å…ˆsample $y$çš„å­é›†ï¼Œä¸ºäº†ä¿è¯ä¸åŒé•¿åº¦è¢«sampleåˆ°çš„æ¦‚ç‡æ˜¯ä¸€è‡´çš„ï¼Œå…ˆsampleé•¿åº¦$k$ï¼Œç„¶åéšæœºä»$y$ä¸­sample $k$ä¸ªè¯ï¼Œ$k$ä¸ªè¯çš„å‘ˆç°é¡ºåºæ˜¯ä¸$y$å†…ä¸€è‡´çš„ã€‚</p>
<p>å¯¹äºk+1ä¸ªslotè€Œè¨€ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—è¿™k+1ä¸ªslotçš„lossã€‚è®°$\left(y_{i_{l}}, y_{i_{l}+1}, \dots, y_{j_{l}}\right)$ä¸ºå½“å‰å°šæœªç”Ÿæˆçš„ä½ç½®çš„target wordã€‚å…ˆå®šä¹‰è¿™ä¹‹é—´æ¯ä¸ªä½ç½®åˆ°ä¸­å¿ƒçš„è·ç¦»ï¼š</p>
<script type="math/tex; mode=display">d_{l}(i)=\left|\frac{i_{l}+j_{l}}{2}-i\right|</script><p>æ¥ç€ä½¿ç”¨è¯¥distanceä½œä¸ºreward functionï¼š</p>
<script type="math/tex; mode=display">w_{l}(i)=\frac{\exp \left(-d_{l}(i) / \tau\right)}{\sum_{i^{\prime}=i_{l}}^{j_{l}} \exp \left(-d_{l}\left(i^{\prime}\right) / \tau\right)}</script><p>å…¶ä¸­$\tau$è¶‹è¿‘0æ—¶è¡¨ç¤ºåªè€ƒè™‘ä¸­å¿ƒè¯ï¼Œè¶‹è¿‘âˆåˆ™æ˜¯uniformã€‚</p>
<p>å°†å…¶æ’å…¥åˆ°lossé‡Œï¼š</p>
<script type="math/tex; mode=display">slot-loss(x, \hat{y}, l)=\sum_{i=i_{l}}^{j_{l}}-\log p\left(y_{i}, l | x, \hat{y}\right) \cdot w_{l}(i)</script><p>è¿™å°±å¼ºè°ƒäº†ä¸­å¿ƒè¯è¦å…ˆè¢«é¢„æµ‹å‡ºæ¥ã€‚</p>
<p>ç¤ºæ„å›¾ï¼š</p>
<p><img src="/images/15660935753744.jpg" width="70%" height="50%"></p>
<p>ç°è‰²çš„è¯æ˜¯è¿˜æ²¡è¢«é¢„æµ‹çš„ï¼Œçº¢è‰²çš„ç›´æ–¹å›¾æ˜¯uniformçš„ï¼Œç»è¿‡reweightçš„æ˜¯ç™½è‰²çš„ã€‚</p>
<p>æœ€åæˆ‘ä»¬å°†æ‰€æœ‰çš„ä½ç½®çš„lossåŠ èµ·æ¥ï¼š</p>
<script type="math/tex; mode=display">\operatorname{loss}(x, \hat{y})=\frac{1}{k+1} \sum_{l=0}^{k} \operatorname{slot}-\operatorname{loss}(x, \hat{y}, l)</script><h4 id="Uniform"><a href="#Uniform" class="headerlink" title="Uniform"></a>Uniform</h4><p>è®ºæ–‡ä¸­è¿˜å°è¯•äº†uniformçš„æ–¹å¼ï¼Œä¹Ÿå³ä¸å¼ºè°ƒä¸­å¿ƒè¯ï¼š</p>
<script type="math/tex; mode=display">\operatorname{slot}-\operatorname{loss}(x, \hat{y}, l)=\frac{1}{j_{l}-i_{l}+1} \sum_{i=i_{l}}^{j_{l}}-\log p\left(y_{i}, l | x, \hat{y}\right)</script><p>å…¶å¥½å¤„ï¼ˆæ²¡çœ‹æ‡‚ï¼‰ï¼š<br>This neutral approach is useful insofar as it forces the model to be aware of all valid actions during each step of decoding, providing a rich learning signal during training and maximizing robustnessï¼›<br>Such an approach also bears resemblance to the principle of maximum entropy, which has successfully been employed for maximum entropy modeling across a number of domains in machine learning</p>
<h4 id="Termination"><a href="#Termination" class="headerlink" title="Termination"></a>Termination</h4><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»€ä¹ˆæ—¶å€™åœæ­¢ï¼Ÿ<br>æœ‰ä¸¤ç§ï¼šslot finalization å’Œ sequence finalizationã€‚</p>
<h5 id="slot-finalization"><a href="#slot-finalization" class="headerlink" title="slot finalization"></a>slot finalization</h5><p>å½“æ¨¡å‹é¢„æµ‹åˆ°æŸä¸ªlocationï¼Œè¯¥locationå¯¹åº”çš„æ˜¯åœ¨çœŸå®è¾“å‡ºä¸­ä¸å­˜åœ¨çš„spanï¼Œé‚£å°±ç›´æ¥å°†targetè®¾ä¸ºend-of-slot tokenã€‚<br>åœ¨æµ‹è¯•é˜¶æ®µï¼Œå½“æ‰€æœ‰çš„slotéƒ½é¢„æµ‹åˆ°end-of-slot tokenï¼Œåˆ™åœæ­¢decodeã€‚</p>
<h5 id="sequence-finalization"><a href="#sequence-finalization" class="headerlink" title="sequence finalization"></a>sequence finalization</h5><p>åœ¨è®­ç»ƒé˜¶æ®µï¼Œå½“é‡åˆ°ç©ºspanï¼Œåˆ™å°†è¯¥éƒ¨åˆ†çš„losså®šä¹‰ä¸ºæœªå®šä¹‰ï¼Œä¹Ÿå³ä¸çº³å…¥lossçš„è®¡ç®—ã€‚å½“æ•´ä¸ªå¥å­è¢«ç”Ÿæˆå®Œäº†ï¼Œå°†æ¯ä¸ªä½ç½®çš„lossè®¾ä¸ºend-of-sequence tokençš„lossï¼ˆç›¸å½“äºå¸Œæœ›æ¨¡å‹æ­¤æ—¶å…¨éƒ½é¢„æµ‹è¯¥tokenï¼‰ã€‚<br>åœ¨æµ‹è¯•é˜¶æ®µï¼Œä¸‹é¢è¯¦è°ˆã€‚</p>
<h5 id="Training-Differences"><a href="#Training-Differences" class="headerlink" title="Training Differences"></a>Training Differences</h5><p>ä¸æ™®é€šautoregressiveçš„æ¨¡å‹ç›¸æ¯”çš„ä¸åŒï¼š<br>â‘ generation stepä¹‹é—´æ²¡æœ‰stateçš„propagationï¼Œå› ä¸ºæ¯ç”Ÿæˆå®Œéƒ½è¦é‡æ–°è®¡ç®—stateï¼Œä¸èƒ½å¤ç”¨ã€‚<br>â‘¡æ™®é€šçš„autoregressiveåœ¨è®­ç»ƒæ—¶å¯ä»¥ä¸€æ¬¡æ€§è®¡ç®—å®Œæ‰€æœ‰çš„lossï¼Œè€Œè¿™é‡Œåªèƒ½ä¸€æ¬¡è®¡ç®—ä¸€ä¸ªã€‚å› æ­¤æ›´å å†…å­˜ã€‚<br>â‘¢subsamplingå¯èƒ½å¸¦æ¥varianceä¼°è®¡ä¸å‡†çš„é—®é¢˜ã€‚</p>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><h4 id="Greedy-Decoding"><a href="#Greedy-Decoding" class="headerlink" title="Greedy Decoding"></a>Greedy Decoding</h4><p>æ¯æ¬¡é€‰æ‹©æœ€å¤§çš„å³å¯ï¼š</p>
<script type="math/tex; mode=display">\left(\hat{c}_{t}, \hat{l}_{t}\right)=\underset{c, l}{\operatorname{argmax}} p\left(c, l | x, \hat{y}_{t}\right)</script><p>å¦‚æœæ˜¯sequence finalizationï¼Œåˆ™å½“ç›´åˆ°end-of-sequence tokenè¢«ä»»æ„ä½ç½®é€‰ä¸­åˆ™åœæ­¢ã€‚<br>å¦‚æœæ˜¯slot finalizationï¼Œé‚£ä¹ˆåªåœ¨è¿˜æ²¡ç”Ÿæˆend-of-slotçš„ä½ç½®ä¸Šç”¨argmaxï¼Œç›´åˆ°æ‰€æœ‰ä½ç½®éƒ½ç”Ÿæˆäº†end-of-slotã€‚</p>
<h4 id="Parallel-Decoding"><a href="#Parallel-Decoding" class="headerlink" title="Parallel Decoding"></a>Parallel Decoding</h4><p>å…ˆè®¡ç®—æ¯ä¸ªä½ç½®çš„lçš„argmaxï¼š</p>
<script type="math/tex; mode=display">\hat{c}_{l, t}=\underset{c}{\operatorname{argmax}} p\left(c | l, x, \hat{y}_{t}\right)</script><p>å¦‚æœæ˜¯å‰é¢æåˆ°çš„æ¡ä»¶æ¦‚ç‡$p(c, l)=p(l) p(c | l)$ï¼Œé‚£ä¹ˆæ­¤æ—¶$p(c | l)$å·²ç»æœ‰äº†ï¼›å¦‚æœæ˜¯ç›´æ¥è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒåˆ™å¯é€šè¿‡$p(c | l)=p(c, l) / p(l)=p(c, l) / \sum_{c^{\prime}} p\left(c^{\prime}, l\right)$ è·å¾—ã€‚</p>
<p>æ¥ç€å°†å·²ç»ç”Ÿæˆäº†end-of-slotçš„locationè¿‡æ»¤æ‰ï¼Œæœ€åæ’å…¥å¯¹åº”çš„é¢„æµ‹è¯ã€‚</p>
<p>è¿™ç§æ–¹æ³•ç†è®ºä¸Šå¯ä»¥åªéœ€è¦$\left\lfloor\log _{2} n\right\rfloor+ 1$ä¸ªstepsã€‚</p>
<h3 id="å®éªŒ-1"><a href="#å®éªŒ-1" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><h4 id="Part1"><a href="#Part1" class="headerlink" title="Part1"></a>Part1</h4><p><img src="/images/15660960806712.jpg" width="90%" height="50%"></p>
<p>æ‹¬å·éƒ½æ˜¯æŠ¥å‘Šçš„åŠ äº†EOSæœ€å¥½çš„ç»“æœã€‚<br>å‡ ä¸ªå€¼å¾—æ³¨æ„çš„ç‚¹ï¼š<br>â‘ å‘ç°EOSæ€»æ˜¯è¿‡æ—©è¢«ç”Ÿæˆï¼Œå› æ­¤å¼•å…¥EOS penaltyï¼Œä¹Ÿå³å°†EOSçš„æ¦‚ç‡å‡æ‰ä¸€ä¸ªÎ²ï¼Œå½“EOSçš„æ¦‚ç‡ä¸æ¦‚ç‡ç¬¬äºŒé«˜çš„å·®è·è¶…è¿‡Î²æ‰çœŸæ­£ç”ŸæˆEOSï¼Œå‘ç°ç¡®å®æœ‰ä¸é”™çš„æå‡ã€‚</p>
<p>â‘¡ä½¿ç”¨knowledge distillationæœ‰æ˜¾è‘—æå‡ï¼Œteacher modelæ˜¯transformer baselineã€‚</p>
<h4 id="Part2"><a href="#Part2" class="headerlink" title="Part2"></a>Part2</h4><p><img src="/images/15660961714055.jpg" width="60%" height="50%"></p>
<p>ä½¿ç”¨parallel decodingç›¸æ¯”greedy decodingç¨å¥½ä¸€äº›ï¼Œè¯æ˜æ¨¡å‹æ˜¯æœ‰èƒ½åŠ›åŒæ—¶ç”Ÿæˆæ–‡æœ¬çš„ã€‚</p>
<p>parallel decodingçš„å‡ ä¸ªä¾‹å­ï¼š</p>
<p><img src="/images/15660962394243.jpg" width="90%" height="50%"></p>
<h4 id="Part3"><a href="#Part3" class="headerlink" title="Part3"></a>Part3</h4><p><img src="/images/15660962832031.jpg" width="50%" height="50%"></p>
<p>åœ¨å®éªŒè¿‡ç¨‹ä¸­å‘ç°parallel decodingç¡®å®èƒ½é€¼è¿‘ä¸‹ç•Œã€‚</p>
<h4 id="Part4"><a href="#Part4" class="headerlink" title="Part4"></a>Part4</h4><p>æœ€åä¸€ä¸ªä¸å…¶ä»–related workçš„å¯¹æ¯”ï¼š</p>
<p><img src="/images/15660963462654.jpg" width="60%" height="50%"></p>
<p>å¯ä»¥çœ‹åˆ°å…¶å¤æ‚åº¦éå¸¸ä½ã€‚</p>
<hr>
<h2 id="æœ¬å‘¨è®ºæ–‡å°ç»“"><a href="#æœ¬å‘¨è®ºæ–‡å°ç»“" class="headerlink" title="[æœ¬å‘¨è®ºæ–‡å°ç»“]"></a>[æœ¬å‘¨è®ºæ–‡å°ç»“]</h2><p>æœ¬å‘¨ç”±äºè¦åœ¨ç»„ä¼šè®²æœºå™¨ç¿»è¯‘çš„è®ºæ–‡ï¼Œå› æ­¤ç»å¤§å¤šæ•°éƒ½æ˜¯ç›¸å…³çš„è®ºæ–‡ã€‚å…¶å®å¤§éƒ¨åˆ†éƒ½æ˜¯ACL19çš„best paperä»¥åŠç›¸å…³è®ºæ–‡ã€‚ç›®å‰æœºå™¨ç¿»è¯‘æœ‰å‡ ä¸ªæœ‰æ„æ€çš„æ–¹å‘å¦‚non-autoregressive NMTã€unsupervised/semi-supervised NMTéƒ½æ˜¯å€¼å¾—æ·±å…¥çš„ã€‚è€Œå®éªŒå®¤æ¥ä¸‹æ¥ä¹Ÿä¼šå›´ç»•æœºå™¨ç¿»è¯‘åšä¸€äº›å·¥ä½œï¼Œæˆ‘ä¸ªäººè¿˜æ˜¯å€¾å‘å°†Curriculum Learninigä¸NMTç»“åˆã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>exposure bias</tag>
      </tags>
  </entry>
  <entry>
    <title>ä½³å¥åˆ†äº«4</title>
    <url>/2019/08/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB4/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>å¦‚æœå°–é”çš„æ‰¹è¯„å®Œå…¨æ¶ˆå¤±ï¼Œæ¸©å’Œçš„æ‰¹è¯„å°†ä¼šå˜å¾—åˆºè€³ã€‚å¦‚æœæ¸©å’Œçš„æ‰¹è¯„ä¹Ÿä¸è¢«å…è®¸ï¼Œæ²‰é»˜å°†è¢«è®¤ä¸ºå±…å¿ƒåµæµ‹ã€‚å¦‚æœæ²‰é»˜ä¹Ÿä¸å†å…è®¸ï¼Œèµæ‰¬ä¸å¤Ÿå–åŠ›å°†æ˜¯ä¸€ç§ç½ªè¡Œã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯33</title>
    <url>/2019/08/11/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D33/</url>
    <content><![CDATA[<h3 id="é¢˜é¾™é˜³å¿é’è‰æ¹–"><a href="#é¢˜é¾™é˜³å¿é’è‰æ¹–" class="headerlink" title="é¢˜é¾™é˜³å¿é’è‰æ¹–"></a>é¢˜é¾™é˜³å¿é’è‰æ¹–</h3><p>[å…ƒ] å”ç™<br>è¥¿é£å¹è€æ´åº­æ³¢ï¼Œä¸€å¤œæ¹˜å›ç™½å‘å¤šã€‚<br><strong>é†‰åä¸çŸ¥å¤©åœ¨æ°´ï¼Œæ»¡èˆ¹æ¸…æ¢¦å‹æ˜Ÿæ²³ã€‚</strong></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†27</title>
    <url>/2019/08/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8627/</url>
    <content><![CDATA[<h3 id="PytorchåŠ é€Ÿå»ºè®®"><a href="#PytorchåŠ é€Ÿå»ºè®®" class="headerlink" title="[PytorchåŠ é€Ÿå»ºè®®]"></a>[PytorchåŠ é€Ÿå»ºè®®]</h3><p><a href="https://towardsdatascience.com/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565" target="_blank" rel="noopener">9 Tips For Training Lightning-Fast Neural Networks In Pytorch</a></p>
<p>å…¶ä¸­å‡ æ¡æ¯”è¾ƒæœ‰æ„æ€ã€‚</p>
<h4 id="Retained-graphs"><a href="#Retained-graphs" class="headerlink" title="Retained graphs"></a>Retained graphs</h4><p>åœ¨ä¿å­˜lossçš„æ—¶å€™ï¼Œè¦æ³¨æ„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># bad</span></span><br><span class="line">losses.append(loss)</span><br><span class="line"><span class="comment"># good</span></span><br><span class="line">losses.append(loss.item())</span><br></pre></td></tr></table></figure>
<p>å› ä¸ºå‰è€…ä¼šä¿å­˜æ•´å¼ è®¡ç®—å›¾ï¼Œå ç”¨å¤§é‡å†…å­˜ã€‚</p>
<h4 id="Moving-to-Multiple-GPUs"><a href="#Moving-to-Multiple-GPUs" class="headerlink" title="Moving to Multiple GPUs"></a>Moving to Multiple GPUs</h4><p>ä¸€èˆ¬æˆ‘ä»¬éƒ½æ˜¯Split-batchï¼Œä¹Ÿå³ï¼š</p>
<p><img src="/images/15654488718573.png" width="60%" height="50%"></p>
<p>å®ç°Split-batchåªéœ€è¦ä½¿ç”¨Pytorchçš„DataParallelã€‚</p>
<p>è€Œå¦ä¸€ä¸ªæ–¹æ³•æ˜¯Split Model Trainingï¼Œä¹Ÿå³ï¼š</p>
<p><img src="/images/15654489576969.png" width="50%" height="50%"></p>
<p>æ¯”å¦‚è¯´ç¿»è¯‘æ¨¡å‹æœ‰encoderä¸decoderéƒ¨åˆ†ï¼Œé‚£ä¹ˆå¯ä»¥å°†encode/decoderæ”¾åœ¨ä¸åŒGPUã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># each model is sooo big we can't fit both in memory</span></span><br><span class="line">encoder_rnn.cuda(<span class="number">0</span>)</span><br><span class="line">decoder_rnn.cuda(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run input through encoder on GPU 0</span></span><br><span class="line">encoder_out = encoder_rnn(x.cuda(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># run output through decoder on the next GPU</span></span><br><span class="line">out = decoder_rnn(encoder_out.cuda(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># normally we want to bring all outputs back to GPU 0</span></span><br><span class="line">out = out.cuda(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>å½“ç„¶ä¹Ÿå¯ä»¥å°†äºŒè€…ç»“åˆèµ·æ¥ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change these lines</span></span><br><span class="line">self.encoder = RNN(...)</span><br><span class="line">self.decoder = RNN(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># to these</span></span><br><span class="line"><span class="comment"># now each RNN is based on a different gpu set</span></span><br><span class="line">self.encoder = DataParallel(self.encoder, devices=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">self.decoder = DataParallel(self.encoder, devices=[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># in forward...</span></span><br><span class="line">out = self.encoder(x.cuda(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># notice inputs on first gpu in device</span></span><br><span class="line">sout = self.decoder(out.cuda(<span class="number">4</span>))  <span class="comment"># &lt;--- the 4 here</span></span><br></pre></td></tr></table></figure>
<h4 id="Faster-multi-GPU-training-on-a-single-node"><a href="#Faster-multi-GPU-training-on-a-single-node" class="headerlink" title="Faster multi-GPU training on a single node"></a>Faster multi-GPU training on a single node</h4><p>åœ¨å•ä¸ªæœºå™¨ä¹Ÿä½¿ç”¨DistributedDataParallelï¼ŒDistributedDataParallelä¼šæ¯”DataParallelæ›´å¿«ï¼ŒDistributedDataParallelåªéœ€è¦gradientçš„åŒæ­¥ã€‚</p>
<hr>
<h3 id="Python-assert"><a href="#Python-assert" class="headerlink" title="[Python assert]"></a>[Python assert]</h3><p><a href="https://www.oschina.net/translate/when-to-use-assert" target="_blank" rel="noopener">Python ä½¿ç”¨æ–­è¨€çš„æœ€ä½³æ—¶æœº</a></p>
<p>å¯¹ä¸€ä¸ªå‡½æ•°è€Œè¨€ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæ–­è¨€ç”¨äºæ£€æŸ¥å‡½æ•°è¾“å…¥çš„åˆæ³•æ€§ï¼Œè¦æ±‚è¾“å…¥æ»¡è¶³ä¸€å®šçš„æ¡ä»¶æ‰èƒ½ç»§ç»­æ‰§è¡Œ;</p>
<p>assertæ—¶å€™çš„å‡ ä¸ªæƒ…å†µï¼š<br>é˜²å¾¡æ€§çš„ç¼–ç¨‹ï¼šä¸ºäº†é˜²èŒƒç”±äºä»¥åçš„ä»£ç å˜æ›´è€Œå‘ç”Ÿé”™è¯¯<br>è¿è¡Œæ—¶å¯¹ç¨‹åºé€»è¾‘çš„æ£€æµ‹<br>åˆçº¦æ€§æ£€æŸ¥ï¼ˆæ¯”å¦‚å‰ç½®æ¡ä»¶ï¼Œåç½®æ¡ä»¶ï¼‰<br>ç¨‹åºä¸­çš„å¸¸é‡<br>æ£€æŸ¥æ–‡æ¡£</p>
<hr>
<h3 id="Python-globalå…³é”®å­—"><a href="#Python-globalå…³é”®å­—" class="headerlink" title="[Python globalå…³é”®å­—]"></a>[Python globalå…³é”®å­—]</h3><p>å¯¹äºä»€ä¹ˆæ—¶å€™å¿…é¡»è¦ä½¿ç”¨globalå…³é”®å­—ã€‚å¦‚æœå‡½æ•°å†…éƒ¨åªä½¿ç”¨å˜é‡è€Œä¸ä¿®æ”¹/èµ‹å€¼ï¼Œåˆ™ä¸éœ€è¦æ˜¾å¼åœ¨å‡½æ•°å†…éƒ¨globalï¼›å¦åˆ™å°±å¿…é¡»è¦globalã€‚å› ä¸ºå†…éƒ¨åšäº†æ”¹å˜ï¼ˆèµ‹å€¼ï¼‰ï¼Œç¼–è¯‘å™¨ä¼šè®¤ä¸ºè¯¥å˜é‡æ˜¯å‡½æ•°å†…éƒ¨çš„localå˜é‡è€Œä¸æ˜¯å¤–éƒ¨çš„å…¨å±€å˜é‡ã€‚</p>
<p>å¦‚ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Classifier(args)</span><br><span class="line">optimizer=torch.optim.SGD(model.parameters())</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> model  <span class="comment"># å¿…é¡»æ˜¾å¼åŠ globalï¼Œå› ä¸ºåœ¨mainå†…éƒ¨åšäº†æ”¹å˜</span></span><br><span class="line">    model.train()</span><br><span class="line">    train(model,optimizer)  <span class="comment"># optimizerç”±äºæ²¡æœ‰åœ¨mainå‡½æ•°å†…éƒ¨æ”¹å˜ï¼Œå› æ­¤ä¸éœ€è¦global</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
        <tag>assert</tag>
        <tag>global</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡27</title>
    <url>/2019/08/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8727/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Curriculum Learning for Domain Adaptation in Neural Machine Translation</li>
<li>Dynamically Composing Domain-Data Selection with Clean-Data Selection by â€œCo-Curricular Learningâ€ for Neural Machine Translation</li>
<li>Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation</li>
<li>Curriculum Learning for Natural Answer Generation</li>
<li>MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels</li>
</ol>
<h2 id="Curriculum-Learning-for-Domain-Adaptation-in-Neural-Machine-Translation"><a href="#Curriculum-Learning-for-Domain-Adaptation-in-Neural-Machine-Translation" class="headerlink" title="[Curriculum Learning for Domain Adaptation in Neural Machine Translation]"></a>[Curriculum Learning for Domain Adaptation in Neural Machine Translation]</h2><p>æå‡ºå°†CLç”¨äºç¿»è¯‘ä»»åŠ¡ä¸Šçš„domain adaptationã€‚</p>
<p>ä»»åŠ¡ï¼šæœ‰äº›é¢†åŸŸç›¸å…³çš„ç¿»è¯‘æ²¡æœ‰é‚£ä¹ˆå¤šå¹³è¡Œè¯­æ–™ï¼Œä¸€èˆ¬æœ‰çš„éƒ½æ˜¯general domainçš„ï¼Œè¿˜æœ‰çš„å°±æ˜¯ä¸çŸ¥é“æ˜¯ä»€ä¹ˆé¢†åŸŸçš„ï¼Œæ¯”å¦‚ä»ç½‘ç»œä¸Šçˆ¬ä¸‹æ¥çš„æ•°æ®paracrawlï¼Œæœ¬æ–‡å°±æ˜¯å¸Œæœ›èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è¿™äº›æœªçŸ¥é¢†åŸŸçš„æ•°æ®ä»¥è®­ç»ƒæ›´å¥½çš„ç‰¹å®šé¢†åŸŸæ¨¡å‹ã€‚</p>
<p>å…¶åŸºæœ¬åšæ³•æ˜¯ï¼šå…ˆè®­ä¸€ä¸ªgenericçš„æ¨¡å‹ï¼Œç„¶åä½œä¸ºinitializationã€‚æ¥ç€ä»è¿™äº›unlabeled domainçš„æ•°æ®ï¼Œæ ¹æ®ä¸ç‰¹å®šé¢†åŸŸæ•°æ®é›†çš„ç›¸ä¼¼ç¨‹åº¦æ’åºï¼Œç„¶ååˆ©ç”¨CLä»ç›¸ä¼¼æ€§æœ€é«˜çš„åˆ°ç›¸ä¼¼æ€§ä½çš„è®­ç»ƒã€‚æœ¬æ–‡æ˜¯ç¬¬ä¸€ä¸ªå°†CLç”¨äºdomain adaptationã€‚</p>
<p>Pipelineï¼š</p>
<p><img src="/images/15654423291460.jpg" width="60%" height="50%"></p>
<h3 id="æ’åºæŒ‡æ ‡-Domain-Similarity-Scoring"><a href="#æ’åºæŒ‡æ ‡-Domain-Similarity-Scoring" class="headerlink" title="æ’åºæŒ‡æ ‡(Domain Similarity Scoring)"></a>æ’åºæŒ‡æ ‡(Domain Similarity Scoring)</h3><p>ç¬¬ä¸€ä¸ªé—®é¢˜å³ï¼Œå¦‚ä½•åˆ¤æ–­å“ªäº›å¥å­æ˜¯domainç›¸å…³çš„ï¼Ÿ</p>
<p>è®°$I$æ˜¯in-domainçš„æ•°æ®ï¼›$N$æ˜¯unlabeled domainçš„æ•°æ®ï¼Œæ’åºæ‰€è¦åšçš„å°±æ˜¯æ ¹æ®$I$çš„æ•°æ®æŒ‰ç…§ç›¸ä¼¼åº¦æ¥æ’åºï¼Œå¹¶å–å‰nä¸ªç”¨äºè®­ç»ƒã€‚</p>
<p>æœ¬æ–‡ä½¿ç”¨äº†ä¸¤ç§æŒ‡æ ‡ã€‚</p>
<h4 id="Moore-Lewis-Method"><a href="#Moore-Lewis-Method" class="headerlink" title="Moore-Lewis Method"></a>Moore-Lewis Method</h4><p>å¯¹äºæ¯ä¸ªåœ¨$N$é‡Œé¢çš„å¥å­$s$éƒ½ä¼šåˆ†é…ä¸€ä¸ªåˆ†æ•°ï¼š</p>
<script type="math/tex; mode=display">H_{I}(s)-H_{N}(s)</script><p>å…¶ä¸­$H_{I}$æ˜¯åœ¨$I$ä¸Šè®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„cross entropyï¼›$H_{N}$æ˜¯åœ¨ä»$N$ä¸Šéšæœºé‡‡æ ·çš„å¤§å°ä¸$I$ç›¸è¿‘çš„æ•°æ®æ‰€è®­ç»ƒå¾—åˆ°çš„è¯­è¨€æ¨¡å‹çš„cross entropyã€‚</p>
<p>è¯¥æŒ‡æ ‡è¶Šå°ï¼Œä»£è¡¨å¥å­$s$ä¸in-domainæ•°æ®é›†$I$æ›´ç›¸è¿‘ã€‚</p>
<h4 id="Cynical-Data-Selection"><a href="#Cynical-Data-Selection" class="headerlink" title="Cynical Data Selection"></a>Cynical Data Selection</h4><p>å¾ªç¯é€‰æ‹©å¥å­æ„å»ºtraining corpusæ¥å¤§è‡´å¯¹$I$å»ºæ¨¡ã€‚æ¯ä¸ªiterationï¼Œæ¯ä¸ªsentenceéƒ½ä¼šè®¡ç®—å°†å…¶åŠ å…¥åˆ°å·²ç»æ„å»ºå¥½çš„training corpusæ‰€å¸¦æ¥çš„cross-entropy decreaseï¼Œè€Œå¸¦æ¥æœ€å¤§decreaseçš„å¥å­åˆ™è¢«é€‰ä¸­ï¼Œè¿™é‡Œçš„cross-entropyæ˜¯previously selected n-sentence corpusä¸Iä¹‹é—´çš„ã€‚</p>
<h3 id="Curriculum-Learning-Training-Strategy"><a href="#Curriculum-Learning-Training-Strategy" class="headerlink" title="Curriculum Learning Training Strategy"></a>Curriculum Learning Training Strategy</h3><p>é¦–å…ˆæ ¹æ®ä¸Šè¿°æŒ‡æ ‡æ’åºï¼Œç„¶ååˆ‡åˆ†æˆå¤šä¸ªshardsï¼›è®­ç»ƒè¿‡ç¨‹æ˜¯åˆ‡åˆ†æˆè‹¥å¹²ä¸ªphaseçš„ï¼Œæ¯ä¸ªphaseåªèƒ½ç”¨éƒ¨åˆ†çš„æ•°æ®ï¼›åœ¨ç¬¬ä¸€phaseï¼Œåªèƒ½ç”¨æœ€ç®€å•çš„shardè®­ç»ƒï¼Œç„¶åéšç€phaseçš„å¢åŠ ï¼Œå¢åŠ å‰©ä½™æœ€ç®€å•çš„shardï¼›æ³¨æ„åˆ°æ•°æ®å‘ˆç°çš„é¡ºåºä¸æ˜¯å›ºå®šçš„ï¼Œå¹¶ä¸æ˜¯ä¸¥æ ¼ç®€å•åˆ°éš¾ï¼Œè€Œæ˜¯éšæœºä»å½“å‰phaseèƒ½çœ‹åˆ°çš„shardä¸­é‡‡æ ·ã€‚è¿™æ ·èƒ½å¤Ÿå¸¦æ¥ä¸€å®šçš„éšæœºæ€§ï¼Œå¯¹æ¨¡å‹è®­ç»ƒæœ‰å¸®åŠ©ã€‚</p>
<p>åœ¨å®éªŒä¸­æ˜¯å°†æ•°æ®åˆ†æˆäº†40ä¸ªshardsï¼Œæ¯ä¸ªphaseéšæœºé‡‡æ ·1000ä¸ªbatchã€‚</p>
<hr>
<h2 id="Dynamically-Composing-Domain-Data-Selection-with-Clean-Data-Selection-by-â€œCo-Curricular-Learningâ€-for-Neural-Machine-Translation"><a href="#Dynamically-Composing-Domain-Data-Selection-with-Clean-Data-Selection-by-â€œCo-Curricular-Learningâ€-for-Neural-Machine-Translation" class="headerlink" title="[Dynamically Composing Domain-Data Selection with Clean-Data Selection by â€œCo-Curricular Learningâ€ for Neural Machine Translation]"></a>[Dynamically Composing Domain-Data Selection with Clean-Data Selection by â€œCo-Curricular Learningâ€ for Neural Machine Translation]</h2><p>æå‡ºå°†domain-data selectionä¸clean-data selectionç»“åˆï¼Œå¹¶æå‡ºè”åˆè¯¾ç¨‹å­¦ä¹ ï¼Œç”¨ä»¥ç¿»è¯‘ä»»åŠ¡ä¸Šçš„domain adaptationã€‚</p>
<p>ä»»åŠ¡èƒŒæ™¯æè¿°ï¼šdomain-data selectionæ˜¯ä»å¤§æ•°æ®é›†ä¸Šæ ¹æ®ç‰¹å®šé¢†åŸŸçš„å°æ•°æ®é›†é€‰æ‹©ä¸è¯¥ç‰¹å®šé¢†åŸŸæœ€ç›¸å…³çš„æ•°æ®ç”¨ä»¥æ‰©å……æ•°æ®é‡æ¥è®­ç»ƒï¼›åŒç†clean-data selectionåˆ™æ˜¯é€‰æ‹©å¹²å‡€/å™ªå£°è¾ƒå°‘çš„æ•°æ®æ¥è®­ç»ƒã€‚</p>
<p>æœ¬æ–‡å°†è¿™äºŒè€…çš„æ•°æ®é€‰æ‹©ç»“åˆèµ·æ¥å¹¶ç”¨äºCLçš„è®­ç»ƒã€‚</p>
<h3 id="domain-noiseçš„æµ‹é‡"><a href="#domain-noiseçš„æµ‹é‡" class="headerlink" title="domain/noiseçš„æµ‹é‡"></a>domain/noiseçš„æµ‹é‡</h3><p>ä¸€èˆ¬æ˜¯ä½¿ç”¨language modelæ¥è¡¡é‡ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªgeneral-domainçš„è¯­è¨€æ¨¡å‹$\widetilde{\vartheta}$å’Œä¸€ä¸ªin-domainçš„è¯­è¨€æ¨¡å‹$\widehat{\vartheta}$ï¼Œå¯¹äºä¸€ä¸ªå¥å­è€Œè¨€å…¶domainç›¸å…³æ€§å°±æœ‰ï¼š</p>
<script type="math/tex; mode=display">\varphi(x ; \widetilde{\vartheta}, \widehat{\vartheta})=\frac{\log P(x ; \widehat{\vartheta})-\log P(x ; \widetilde{\vartheta})}{|x|}</script><p>åŒæ ·ï¼Œå‡è®¾æˆ‘ä»¬æœ‰$\widetilde{\theta}$çš„NMT baselineæ¨¡å‹ï¼Œè®­ç»ƒäºæœ‰å™ªå£°çš„æ•°æ®ï¼›$\widehat{\theta}$åˆ™æ˜¯åœ¨å¹²å‡€çš„æ•°æ®ä¸ŠåŸºäº$\widetilde{\theta}$ fine-tuneçš„NMTæ¨¡å‹ï¼Œåˆ™è¡¡é‡noise levelæœ‰ï¼š</p>
<script type="math/tex; mode=display">\phi(x, y ; \widetilde{\theta}, \widehat{\theta})=\frac{\log P(y | x ; \widehat{\theta})-\log P(y | x ; \widetilde{\theta})}{|y|}</script><h3 id="é—®é¢˜è®¾ç½®"><a href="#é—®é¢˜è®¾ç½®" class="headerlink" title="é—®é¢˜è®¾ç½®"></a>é—®é¢˜è®¾ç½®</h3><p>è®°$\widetilde{D_{X Y}}$æ˜¯èƒŒæ™¯åŒè¯­æ•°æ®é›†ï¼Œå¯ä»¥æ˜¯ä»ç½‘ä¸Šçˆ¬ä¸‹æ¥çš„ï¼Œæœ‰ä¸åŒdomainå’Œnoiseï¼›$D_{X}^{\mathrm{ID}}$æ˜¯in-domainçš„å•è¯­è¯­æ–™ï¼Œå¯ä»¥è¾ƒå°ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¥å¯¹domain relevanceæ¥æ’åºï¼›$\widehat{D_{X Y}^{\mathrm{OD}}}$æ˜¯å°çš„ï¼Œå¯ä¿¡ä»»ï¼ˆå¹²å‡€ï¼‰çš„out-of-domainçš„å¹³è¡Œè¯­æ–™ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä»½æ•°æ®æ¥è¯­æ–™çš„å™ªå£°ç¨‹åº¦åšæ’åºï¼›$\widehat{D_{X Y}^{\mathrm{ID}}}$åˆ™æ˜¯åŒè¯­çš„in-domainè¯­æ–™ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå‡è®¾in-domainçš„åŒè¯­é¢„æ–™ä¸å­˜åœ¨ï¼Œå¸Œæœ›å€ŸåŠ©å…¶ä»–ä¸‰ä¸ªæ¥å­¦ä¼šdomain adaptationã€‚</p>
<h3 id="Co-Curricular-Learning"><a href="#Co-Curricular-Learning" class="headerlink" title="Co-Curricular Learning"></a>Co-Curricular Learning</h3><p>$\mathcal{D}_{\lambda}^{\phi}(t, D)$ æ˜¯ä¸€ä¸ªselection functionï¼Œåœ¨æ—¶é—´tä¸Šè¿”å›top Î»(t)çš„ç»è¿‡æ’åºçš„æ•°æ®ä½œä¸ºè®­ç»ƒã€‚</p>
<p>è¿™é‡Œä½¿ç”¨pace functionï¼š</p>
<script type="math/tex; mode=display">\lambda(t)=0.5^{t / H}</script><p>æ³¨æ„è¿™æ˜¯éšç€æ—¶é—´é€’å‡çš„ã€‚ä¹Ÿå³æˆ‘ä»¬å¸Œæœ›é‡åˆ°åé¢è¶Šdomainç›¸å…³/æ•°æ®è¶Šå¹²å‡€ã€‚ä¸€å¼€å§‹æ˜¯è®­ç»ƒä¸€ä¸ªgeneralçš„è¡¨ç¤ºï¼Œå¯ä»¥ç†è§£æˆæ˜¯ä¸€ä¸ªinitializationï¼Œç„¶ååé¢å†ç”¨å¥½çš„æ•°æ®å»fine-tuneã€‚</p>
<p>ç”±äºæ—¢è¦è€ƒè™‘clean-dataåˆè¦è€ƒè™‘in-domain dataï¼Œæ‰€ä»¥å°±å¼•å‡ºä¸¤ä¸ªç­–ç•¥ã€‚</p>
<h4 id="Mixed-Co-Curriculum"><a href="#Mixed-Co-Curriculum" class="headerlink" title="Mixed Co-Curriculum"></a>Mixed Co-Curriculum</h4><p>æˆ‘ä»¬å¯ä»¥ç›´æ¥å°†clean-data selectionä¸in-domain selectionçš„åˆ†æ•°ç›´æ¥åŠ èµ·æ¥ä½œä¸ºæ€»çš„æ’ååˆ†æ•°ï¼š</p>
<script type="math/tex; mode=display">\psi(x, y)=\phi(x, y)+\varphi(x)</script><p>ç„¶åå†ç”¨åŒä¸€ä¸ªpace-functioné€‰æ‹©åœ¨æ—¶é—´tä¸‹çš„topkä¸ªæ•°æ®ç”¨ä»¥è®­ç»ƒã€‚</p>
<p>ä½†è¿™ä¸ªæ–¹æ³•çš„é—®é¢˜åœ¨äºè¿™ä¸¤ä¸ªåˆ†æ•°å¹¶ä¸ä¸€å®šæ˜¯åŒä¸€ä¸ªé‡çº§çš„ï¼Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªåˆ†å¸ƒæ—ï¼Œä¸åº”è¯¥ç›´æ¥åŠ èµ·æ¥ã€‚</p>
<h4 id="Cascaded-Co-Curriculum"><a href="#Cascaded-Co-Curriculum" class="headerlink" title="Cascaded Co-Curriculum"></a>Cascaded Co-Curriculum</h4><p>å¦ä¸€ç§åˆ™æ˜¯åˆ†åˆ«å®šä¹‰äºŒè€…çš„pace functionï¼Œç„¶åç»“åˆèµ·æ¥ã€‚</p>
<script type="math/tex; mode=display">\beta(t)=0.5^{t / F},\gamma(t)=0.5^{t / G}</script><p>åˆ†åˆ«æ˜¯äºŒè€…çš„pace functionã€‚</p>
<p>å› æ­¤ç»“åˆèµ·æ¥ï¼Œåšä¸¤ä¸ªçš„äº¤é›†ï¼š</p>
<script type="math/tex; mode=display">\left(\mathcal{D}_{\gamma}^{\varphi} \circ \mathcal{D}_{\beta}^{\phi}\right)\left(t, \widetilde{D_{X Y}}\right)=\mathcal{D}_{\gamma}^{\varphi}\left(t, \mathcal{D}_{\beta}^{\phi}\left(t, \widetilde{D_{X Y}}\right)\right)</script><p>æ‰€ä»¥æ¯ä¸ªsampleçš„weightä¸ºï¼š</p>
<script type="math/tex; mode=display">W_{t}(x, y)=\left\{\begin{array}{ll}{\frac{1}{\left|\mathcal{D}_{\gamma}^{\varphi} \circ \mathcal{D}_{\beta}^{\phi}\right|}} & {\text { if }(x, y) \in \mathcal{D}_{\gamma}^{\varphi} \circ \mathcal{D}_{\beta}^{\phi}} \\ {0} & {\text { otherwise }}\end{array}\right.</script><p>ä»¥ä¸‹æ˜¯ä¸€ä¸ªtoy exampleï¼š</p>
<p><img src="/images/15654446572190.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³åªä¿ç•™ä¸¤ä¸ªæŒ‡æ ‡éƒ½é€‰æ‹©ä¿ç•™çš„æ•°æ®ã€‚</p>
<h3 id="CL-optimization"><a href="#CL-optimization" class="headerlink" title="CL optimization"></a>CL optimization</h3><p>è¯¥ç®—æ³•å¦‚ä½•ä¼˜åŒ–ï¼Ÿæœ¬æ–‡é‡‡ç”¨EM-styleçš„ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ä¸ªè¿­ä»£çš„è¿‡ç¨‹ã€‚</p>
<p><img src="/images/15654447383111.jpg" width="50%" height="50%"></p>
<p>æ¨¡å‹åœ¨æ›´æ–°è¿‡ç¨‹ä¸­è¿˜ä¼šåè¿‡æ¥é‡æ–°æ›´æ–°scoring functionã€‚</p>
<h3 id="ä¸€äº›æ€è€ƒ"><a href="#ä¸€äº›æ€è€ƒ" class="headerlink" title="ä¸€äº›æ€è€ƒ"></a>ä¸€äº›æ€è€ƒ</h3><p>åŸå…ˆçš„CLæ˜¯ä»ç®€å•åˆ°éš¾ã€‚è¿™é‡Œçš„æ˜¯ä»ä¸ç›¸å…³/ä¸å¹²å‡€ åˆ° ç›¸å…³/å¹²å‡€ï¼Œ å…¶motivationæ˜¯å¸Œæœ›ä¸€å¼€å§‹è®­ç»ƒä¸€ä¸ªgeneralçš„è¡¨ç¤ºï¼Œç„¶åå†ä¸æ–­åœ°é€šè¿‡è¶Šæ¥è¶Šç›¸å…³/å¹²å‡€çš„æ•°æ®å»fine-tuneã€‚è€Œä¼ ç»ŸCLåˆ™æ˜¯å¸Œæœ›å…ˆé€šè¿‡ç®€å•çš„æ•°æ®ä½¿æ¨¡å‹æ›´å¹³ç¨³åœ°å‘å±•ã€‚äºŒè€…ä¼¼ä¹å‡ºå‘ç‚¹ä¸åŒï¼Œå¦‚æœä¸¥æ ¼åœ°è¯´ï¼Œæœ¬æ–‡ä¸åº”è¯¥ç®—æ˜¯ä¸€ç§ä¼ ç»ŸCLï¼ˆä»ç®€å•åˆ°éš¾ï¼‰ï¼Ÿ</p>
<p>å®é™…ä¸Šè®ºæ–‡é‡Œé¢ä¹Ÿæåˆ°äº†ï¼Œè¿™æ›´åƒæ˜¯ä¸€ç§multi-task transfer learningï¼Œå‡è®¾æ¯ä¸ªæ—¶é—´téƒ½æ˜¯ä¸€ä¸ªtaskï¼Œæœ¬æ–‡æ˜¯å®šä¹‰äº†ä¸€ç³»åˆ—çš„task $\mathcal{M}=\left\langle m_{1}, \ldots, m_{t} \ldots, m_{f}\right\rangle$ï¼Œå…¶ä¸­æœ€åçš„taskæ‰æ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„ï¼ˆä¹Ÿå³in-domainï¼‰ï¼Œè€Œä¸­é—´çš„taskéƒ½æ˜¯ä¸€ç³»åˆ—çš„å«è„šçŸ³ï¼Œå¸Œæœ›èƒ½å¤Ÿå°†çŸ¥è¯†ä¸€æ­¥ä¸€æ­¥åœ°transferåˆ°æœ€ç»ˆçš„taskä¸Šï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆéšç€è®­ç»ƒè¿‡ç¨‹çš„è¿›è¡Œå¯ç”¨æ•°æ®è¶Šæ¥è¶Šå°‘çš„åŸå› ã€‚</p>
<p>é‚£ä¹ˆä¼ ç»ŸCLä¸è¿™ç§multi-task transfer learningä¹‹é—´æ˜¯å¦çŸ›ç›¾çš„åœ°æ–¹ï¼ŸäºŒè€…çš„motivationå¬èµ·æ¥éƒ½å¾ˆåˆç†ï¼Œä»–ä»¬ä¹‹é—´æ˜¯å¦æœ¬è´¨ä¸Šæœ‰ä¸€ä¸ªè”ç»“ç‚¹èƒ½å¤Ÿä½¿äºŒè€…ä¸çŸ›ç›¾ï¼Ÿ</p>
<p>å…¶å®æƒ³ä¸€æƒ³ä¼¼ä¹ä¹Ÿä¸çŸ›ç›¾ï¼Œä¸»è¦çœ‹æœ€ç»ˆçš„ç›®çš„æ˜¯å•¥ï¼Œä»¥åŠæ ‡å‡†æ˜¯å•¥ã€‚CLæ˜¯å…ˆä»ç®€å•åˆ°éš¾ï¼Œæœ€ç»ˆæ˜¯å¸Œæœ›åœ¨åŒä¸€ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ï¼›è€Œæœ¬æ–‡çš„transfer leanringåˆ™ä¸åŒï¼Œæ˜¯åœ¨generalæ•°æ®é›†ä¸Šé€æ¸å¼•å¯¼è‡³ç‰¹å®šdomainï¼Œå¸Œæœ›åœ¨ç‰¹å®šdomainçš„æ•°æ®é›†ä¸Šè¡¨ç°å¥½ï¼Œè€Œä¸æ˜¯å¸Œæœ›åœ¨è®­ç»ƒçš„general domainä¸Šè¡¨ç°å¥½ã€‚äºŒè€…çš„è¯„æµ‹æ ‡å‡†æ˜¯ä¸åŒçš„ï¼Œå‡ºå‘ç‚¹æ˜¯ä¸åŒçš„ï¼Œå› æ­¤åº”è¯¥æ˜¯ä¸çŸ›ç›¾çš„ã€‚</p>
<hr>
<h2 id="Pseudo-Labeling-Curriculum-for-Unsupervised-Domain-Adaptation"><a href="#Pseudo-Labeling-Curriculum-for-Unsupervised-Domain-Adaptation" class="headerlink" title="[Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation]"></a>[Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation]</h2><p>æœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨ä¼ªæ ‡ç­¾åŠ ä¸ŠCLè®­ç»ƒè¾¾åˆ°å›¾åƒåˆ†ç±»domain adaptationï¼ˆé¢†åŸŸè‡ªé€‚åº”ï¼‰çš„ç›®çš„ã€‚</p>
<p>ä»»åŠ¡ä»‹ç»ï¼šç»™å®šæœ‰æ ‡ç­¾çš„sourceï¼Œä»¥åŠæ— æ ‡ç­¾çš„targetï¼Œå…¶ä¸­sourceä¸targetçš„é¢†åŸŸæ˜¯ä¸åŒçš„ï¼Œä»»åŠ¡çš„ç›®çš„æ˜¯èƒ½å¤Ÿåˆ©ç”¨æœ‰æ ‡ç­¾çš„sourceè®­ç»ƒå¾—åˆ°èƒ½å¤Ÿæœ‰è¿ç§»åˆ°targeté¢†åŸŸèƒ½åŠ›çš„æ¨¡å‹ã€‚</p>
<p>åšæ³•ï¼šæœ¬æ–‡åˆ©ç”¨ä¹‹å‰æ–‡ç« CurriculumNet: Weakly Supervised Learning from Large-Scale Web Imagesæåˆ°çš„density-based clusteringï¼Œå…ˆå°†å›¾åƒæ ¹æ®densityåˆ†ç±»ï¼Œç„¶åé¦–å…ˆå¯¹densityè¾ƒå¤§çš„å›¾åƒæ‰“æ ‡ç­¾ï¼Œå¹¶åˆ©ç”¨è¿™äº›å›¾åƒè®­ç»ƒåˆ†ç±»å™¨ï¼Œç„¶åå†å¯¹densityå°ä¸€äº›çš„æ‰“æ ‡ç­¾ï¼Œä¸æ–­æ›´æ–°ä¸æ‰“æ ‡ç­¾è®­ç»ƒï¼Œæœ€ç»ˆè·å¾—ç”±è¿ç§»èƒ½åŠ›çš„æ¨¡å‹ã€‚</p>
<p><img src="/images/15654455360307.jpg" width="80%" height="50%"></p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15654455687375.jpg" width="70%" height="50%"></p>
<p>è®°source samples $D_{\mathcal{S}}=\left\{\left(x_{i}^{S}, y_{i}^{S}\right)\right\}_{i=1}^{N_{S}}$ æ˜¯æœ‰æ ‡ç­¾çš„ï¼›target samples $D_{\mathcal{T}}=\left\{x_{i}^{t}\right\}_{i=1}^{N_{t}}$ æ˜¯æ— æ ‡ç­¾çš„$\hat{\boldsymbol{y}}_{\boldsymbol{i}}^{\boldsymbol{t}}$ åˆ™æ˜¯ä¼ªæ ‡ç­¾ï¼Œç›®çš„æ˜¯è®­ç»ƒä¸€ä¸ª$C_t$èƒ½å¤Ÿå°†target samplesåˆ†ç±»ã€‚</p>
<p>$G_f$æ˜¯å…±äº«çš„ç‰¹å¾æå–å™¨ï¼Œ$C_t$ä¸$C_s$åˆ†åˆ«æ˜¯source/targetçš„åˆ†ç±»å™¨ï¼Œ$G_d$æ˜¯äºŒåˆ†ç±»å™¨ï¼Œè¾“å…¥sourceæˆ–è€…targetï¼Œèƒ½å¤Ÿåˆ¤æ–­è¾“å…¥æ˜¯sourceè¿˜æ˜¯target samplesã€‚</p>
<p>ä¸€å¼€å§‹ï¼Œæˆ‘ä»¬è®­ç»ƒ$G_f$ï¼Œ$C_s$ï¼Œ$G_d$ï¼Œå› ä¸ºä¸€å¼€å§‹æ¨¡å‹èƒ½åŠ›å¼±ï¼Œæ‰“æ ‡ç­¾çš„å¯é æ€§ä½ï¼š</p>
<script type="math/tex; mode=display">J_{1}\left(\theta_{f}, \theta_{d}, \theta_{s}\right)=\frac{1}{N_{s}} \sum_{i=1}^{N_{s}} L_{y}\left(C_{s}\left(f_{i}^{s}\right), y_{i}^{s}\right)-\frac{\lambda}{N_{s}} \sum_{i=1}^{N_{s}} L_{d}\left(G_{d}\left(f_{i}^{s}\right), d_{i}\right)-\frac{\lambda}{N_{t}} \sum_{i=1}^{N_{t}} L_{d}\left(G_{d}\left(f_{i}^{t}\right), d_{i}\right)</script><p>å…¶ä¸­$f$å°±æ˜¯$G_f$çš„è¾“å‡ºã€‚</p>
<p>æ¥ç€ï¼Œé€šè¿‡ä¹‹å‰æåˆ°çš„èšç±»æ–¹æ³•ï¼Œå°†targetèšä¸º3ç±»ï¼Œ$D_{e}, D_{m},D_{h}$ã€‚</p>
<p>ç»™local densityé«˜çš„æ‰“æ ‡ç­¾ï¼Œå‡è®¾local densityçš„æ›´ä¸ºå¯é ï¼Œæˆ‘ä»¬æ‰“å®Œè¿™äº›æ ‡ç­¾åå°±å¼€å§‹åˆ©ç”¨è¿™äº›æ¥è®­ç»ƒ$C_s$ï¼Œç„¶åæ›´æ–°å‚æ•°ï¼Œæ³¨æ„åˆ°è¿™é‡Œæ›´æ–°çš„æ˜¯æ‰€æœ‰ä¸ä¹‹ç›¸å…³çš„å‚æ•°ï¼Œä¹ŸåŒ…æ‹¬$G_f$ç­‰ã€‚</p>
<p>æ›´æ–°å®Œäº†æ¨¡å‹é‡æ–°å¯¹æ•°æ®æ‰“æ ‡ç­¾ï¼Œæ­¤æ—¶å°±å¯ä»¥å°†$D_m$çš„æ•°æ®ç”¨ä»¥è®­ç»ƒäº†ï¼Œç„¶åè®­ç»ƒå®Œå†æ›´æ–°å®Œæ ‡ç­¾ï¼Œå°±å¯ä»¥å°†$D_h$ç”¨ä»¥è®­ç»ƒäº†ã€‚</p>
<p>è¿™é‡Œçš„æ€æƒ³æœ‰ç‚¹å€Ÿé‰´äº†GANäº†ã€‚</p>
<hr>
<h2 id="Curriculum-Learning-for-Natural-Answer-Generation"><a href="#Curriculum-Learning-for-Natural-Answer-Generation" class="headerlink" title="[Curriculum Learning for Natural Answer Generation]"></a>[Curriculum Learning for Natural Answer Generation]</h2><p>å°†CLåº”ç”¨äºNAGçš„è®­ç»ƒä¸Šã€‚</p>
<p>NAGè¿™ä¸ªä»»åŠ¡æˆ‘ä¸ç†Ÿï¼Œåªè®¨è®ºCLï¼Œä»ç„¶æ˜¯ä»æŒ‡æ ‡å®šä¹‰ä¸è®­ç»ƒç­–ç•¥ä¸¤æ­¥è®¨è®ºã€‚</p>
<h3 id="æŒ‡æ ‡"><a href="#æŒ‡æ ‡" class="headerlink" title="æŒ‡æ ‡"></a>æŒ‡æ ‡</h3><p>å®šä¹‰å¤æ‚åº¦çš„æŒ‡æ ‡ï¼š<br>é€šè¿‡ä¸¤ä¸ªæŒ‡æ ‡ï¼Œå°†sampleåˆ†ä¸ºä¸¤ç±»ï¼štarget instanceä¸common instanceã€‚</p>
<h4 id="Term-Frequency-Selector"><a href="#Term-Frequency-Selector" class="headerlink" title="Term Frequency Selector"></a>Term Frequency Selector</h4><p>é€šè¿‡answerçš„term frequencyï¼Œå¦‚æœfrequencyå¤ªå¤§ï¼Œè¯´æ˜è¿™ä¸ªè¯å¤ªè¿‡äºæ™®é€šï¼Œå°çš„TFè¯´æ˜è¿™ä¸ªè¯æœ‰ä»·å€¼ï¼Œä½†å¤ªå°å¯èƒ½è¯´æ˜æ˜¯å™ªå£°ï¼Œæ‰€ä»¥ä¹Ÿè¦è®¾ä¸ªä¸‹é™ã€‚</p>
<h4 id="Grammar-Selector"><a href="#Grammar-Selector" class="headerlink" title="Grammar Selector"></a>Grammar Selector</h4><p>åˆ©ç”¨Stanford parser scoreä½œä¸ºgrammarçš„metricï¼Œæ‹¥æœ‰å¥½çš„grammarçš„å¥å­é€šå¸¸æœ‰æ›´é«˜çš„åˆ†æ•°ï¼ŒåŒæ—¶ç”±äºçŸ­å¥å®¹æ˜“è·å¾—æ›´é«˜çš„åˆ†æ•°ï¼Œå› æ­¤æŒ‰æ¯”ä¾‹è®©shortä¸long answerçš„æ¯”ä¾‹å„å 0.5ã€‚</p>
<p>è¢«é€‰ä¸­çš„å°±æ˜¯target instanceï¼Œä¹Ÿå°±æ˜¯æ¯”è¾ƒéš¾çš„ï¼Œå¦åˆ™å°±æ˜¯common instanceï¼Œä¹Ÿå³æ¯”è¾ƒç®€å•çš„ã€‚</p>
<h3 id="è®­ç»ƒç­–ç•¥"><a href="#è®­ç»ƒç­–ç•¥" class="headerlink" title="è®­ç»ƒç­–ç•¥"></a>è®­ç»ƒç­–ç•¥</h3><p>å¸Œæœ›æ¨¡å‹ä¸€å¼€å§‹å­¦ä¹ ç®€å•ç»“æ„çš„ï¼ŒçŸ­çš„ç­”æ¡ˆï¼Œä½¿å¾—æ¨¡å‹å­¦ä¼šåŸºæœ¬çš„QA modelï¼Œç„¶åå­¦ä¼šæ›´å¤æ‚çš„å†…å®¹ï¼Œèƒ½å¤Ÿæœ‰èƒ½åŠ›ç”Ÿæˆè‡ªç„¶çš„ç­”æ¡ˆï¼Œæ‰€ä»¥å…ˆç”¨common instanceï¼Œç„¶åå†ç”¨target instanceã€‚</p>
<p>é‡‡ç”¨çš„æ˜¯æ¦‚ç‡é‡‡æ ·çš„schedulã€‚è®°$Q_{c},Q_{t}$ åˆ†åˆ«æ˜¯commonå’Œtarget instanceã€‚ä¸€å¼€å§‹å¸Œæœ›æ¦‚ç‡$w_{Q_{c}} \gg w_{Q_{t}}$ï¼Œç„¶åé€æ¸$w_{Q_{c}}$å‡å°è€Œ$w_{Q_{t}}$å¢åŠ ï¼Œæœ€å$w_{Q_{c}} \ll w_{Q_{t}}$ã€‚</p>
<p>å› æ­¤æˆ‘ä»¬æœ‰ï¼š</p>
<script type="math/tex; mode=display">w_{Q_{t}}=\left(\frac{\text {epoch}_{t}}{ | \text {epoch} |}\right)^{2},w_{Q_{c}}=1-w_{Q_{t}}</script><hr>
<h2 id="MentorNet-Learning-Data-Driven-Curriculum-for-Very-Deep-Neural-Networks-on-Corrupted-Labels"><a href="#MentorNet-Learning-Data-Driven-Curriculum-for-Very-Deep-Neural-Networks-on-Corrupted-Labels" class="headerlink" title="[MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels]"></a>[MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels]</h2><p>æå‡ºé€šè¿‡è®­ç»ƒå¦ä¸€ä¸ªMentorNetç½‘ç»œæ¥è¾…åŠ©è®­ç»ƒç½‘ç»œï¼Œç”¨ä»¥è§£å†³åœ¨å—æ±¡æŸ“labelçš„æ•°æ®ä¸Šè®­ç»ƒçš„é—®é¢˜ã€‚<br>è®ºæ–‡æå‡ºçš„CLæ˜¯èƒ½å¤Ÿæ•°æ®é©±åŠ¨çš„ï¼Œä½†æœ¬è´¨ä¸Šå¹¶ä¸æ˜¯CLè€Œæ˜¯SPLã€‚<br>å…¶å®è¿™ç¯‡åé¢çš„ç†è®ºæ²¡æ€ä¹ˆçœ‹æ‡‚ã€‚</p>
<p>åŸºæœ¬åšæ³•æ˜¯æœ‰ä¸€ä¸ªè¾…åŠ©ç½‘ç»œMentorNetï¼Œèƒ½å¤Ÿç»™äºˆå½“å‰sampleåˆ°çš„æ•°æ®ä»¥ä¸€å®šæƒé‡ï¼Œè¯¥æƒé‡æ˜¯åŠ¨æ€çš„ï¼Œè€Œä¸åƒä¼ ç»ŸSPLé‚£æ ·è®¾å®šä¸€ä¸ªå›ºå®šçš„schedule Î»ï¼Œå°äºÎ»çš„å°±ç”¨äºè®­ç»ƒï¼Œè¿™æ˜¯ç”±äººæ¥ç¡®å®šscheduleçš„ï¼Œå¿½ç•¥äº†è¢«è®­ç»ƒçš„ç½‘ç»œçš„åé¦ˆï¼Œè€ŒMentorNetåˆ™æ˜¯æ•°æ®é©±åŠ¨çš„ï¼ŒåŒæ—¶MentorNetä¸StudentNetæ˜¯å¯ä»¥åŒæ—¶è®­ç»ƒæ›´æ–°çš„ã€‚</p>
<p>å› æ­¤ï¼ŒMentorNetçš„è¾“å‡ºå°±æ˜¯æ¯ä¸ªsampleçš„weightã€‚ä»–ä¸»è¦æœ‰ä¸¤ä¸ªå¯å­¦ä¹ çš„åœ°æ–¹ï¼Œä¸€ä¸ªæ˜¯å­¦ä¹ é¢„å®šä¹‰å¥½çš„curriculumï¼›å¦ä¸€ä¸ªå°±æ˜¯ä»æ•°æ®ä¸­å­¦ã€‚</p>
<h3 id="å¯å­¦ä¹ çš„Curriculum"><a href="#å¯å­¦ä¹ çš„Curriculum" class="headerlink" title="å¯å­¦ä¹ çš„Curriculum"></a>å¯å­¦ä¹ çš„Curriculum</h3><h4 id="å­¦ä¹ é¢„å®šä¹‰çš„curriculum"><a href="#å­¦ä¹ é¢„å®šä¹‰çš„curriculum" class="headerlink" title="å­¦ä¹ é¢„å®šä¹‰çš„curriculum"></a>å­¦ä¹ é¢„å®šä¹‰çš„curriculum</h4><p>å®é™…ä¸Šå°±æ˜¯åœ¨æ‹Ÿåˆé¢„å®šä¹‰çš„curriculumçš„å€¼ã€‚</p>
<script type="math/tex; mode=display">g_{m}\left(\mathbf{z}_{i} ; \Theta^{*}\right)=\left\{\begin{array}{ll}{\mathbb{1}\left(\ell_{i} \leq \lambda_{1}\right)} & {\lambda_{2}=0} \\ {\min \left(\max \left(0,1-\frac{\ell_{i}-\lambda_{1}}{\lambda_{2}}\right), 1\right)} & {\lambda_{2} \neq 0}\end{array}\right.</script><p>$g_{m}$å³MentorNetçš„è¾“å‡ºã€‚æˆ‘ä»¬åœ¨ç»™å®š$\mathbf{z}_{i}=\phi\left(\mathbf{x}_{i}, y_{i}, \mathbf{w}\right)$ï¼Œä¹Ÿå³æ¯ä¸ªsampleçš„ä¸€äº›featureï¼Œæ¨¡å‹èƒ½å¤Ÿè¾“å‡ºå’Œé¢„å®šä¹‰çš„curriculumä¸€æ ·çš„å€¼ã€‚</p>
<h4 id="ä»æ•°æ®ä¸­å­¦ä¹ Curriculum"><a href="#ä»æ•°æ®ä¸­å­¦ä¹ Curriculum" class="headerlink" title="ä»æ•°æ®ä¸­å­¦ä¹ Curriculum"></a>ä»æ•°æ®ä¸­å­¦ä¹ Curriculum</h4><p>æˆ‘ä»¬å¸Œæœ›ä»æ•°æ®é›†ä¸­$\left\{\left(\phi\left(\mathbf{x}_{i}, y_{i}, \mathbf{w}\right), v_{i}^{*}\right)\right\}$å­¦ä¹ å¦‚ä½•æ‰“åˆ†ï¼Œå…¶ä¸­v=1è¡¨ç¤ºè¯¥labelæ˜¯æ­£ç¡®çš„çš„ã€‚ä½†æ˜¾ç„¶æˆ‘ä»¬ä¸èƒ½ç›´æ¥ä»è®­ç»ƒæ•°æ®ä¸­è·å¾—è¯¥æ•°æ®é›†ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨è¢«æ±¡æŸ“labelçš„æ•°æ®ã€‚å› æ­¤è®ºæ–‡çš„åšæ³•åˆ™æ˜¯ä»å¦ä¸€ä¸ªå¯ä¿¡ä»»çš„å°æ•°æ®é›†ä¸Šå­¦ä¹ ï¼Œç›¸å½“äºçŸ¥è¯†è¿ç§»ã€‚æ¯”å¦‚æˆ‘ä»¬å¯ä»¥åœ¨CIFAR-10ä¸Šè®­ç»ƒè·å¾—è¿™æ ·ä¸€ä¸ªMentorNetç„¶ååœ¨CIFAR-100ä¸Šç”¨ã€‚</p>
<p>é‚£ä¹ˆè¦å¦‚ä½•å­¦ï¼Ÿ</p>
<p><img src="/images/15654473154044.jpg" width="60%" height="50%"></p>
<p>MentorNetåœ¨è¾“å…¥epochçš„ç™¾åˆ†æ¯”ä»¥åŠlabelåï¼Œè¿‡ä¸€ä¸ªembeddingï¼›ç„¶åå¦ä¸€è¾¹å°†è¿‡å»çš„lossä»¥åŠlossçš„å˜åŒ–å¤šå°‘è¿‡ä¸€ä¸ªåŒå‘çš„LSTMï¼Œè®ºæ–‡ä¸­å–LSTMçš„step size=1ï¼Œä¹Ÿå³åªè€ƒè™‘ä¸€æ¬¡è¿‡å»çš„å˜åŒ–ã€‚ç„¶åäºŒè€…catèµ·æ¥è¿›å…¥fcå±‚ï¼Œæœ€ç»ˆè·å¾—äº†ä¸€ä¸ªæ¦‚ç‡ã€‚å…¶ä¸­æœ€åä¸€å±‚æ˜¯dropoutï¼Œæ˜¯è®ºæ–‡æå‡ºçš„burn-inçš„è¿‡ç¨‹ã€‚burn-inæŒ‡çš„æ˜¯ä¸€å¼€å§‹åœ¨è®­ç»ƒçš„å‰20% epochè®©MentorNetå›ºå®šè¾“å‡º$g_{m}\left(\mathbf{z}_{i} ; \Theta^{*}\right)=r_{i}$ï¼Œå…¶ä¸­$r_{i}$æ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„é‡‡æ ·ç»“æœï¼Œç›¸å½“äºè®©training sampleéšæœºè¢«dropout p%ï¼Œè¿™æ ·èƒ½è®©StudentNetæ›´ç¨³å®šé¢„æµ‹ï¼Œä¸”ä¸“æ³¨äºå­¦ä¹ ç®€å•çš„pattern ï¼ˆwhyï¼Ÿï¼‰ã€‚</p>
<h3 id="ä¸€ç‚¹æ€è€ƒ"><a href="#ä¸€ç‚¹æ€è€ƒ" class="headerlink" title="ä¸€ç‚¹æ€è€ƒ"></a>ä¸€ç‚¹æ€è€ƒ</h3><p>ä»dataä¸­å­¦ä¹ ä¸€ä¸ªcurriculumï¼Œä¹Ÿå³å»å°è¯•ç»™å®šä¸€å®šçš„featureå»æ‹Ÿåˆå…¶labelçš„æ­£ç¡®æ¦‚ç‡ï¼Œè¿™æœ‰ç‚¹åƒæ˜¯meta-leanringåœ¨åšçš„äº‹æƒ…ï¼›åŒæ—¶åœ¨cifar10æ‹Ÿåˆåœ¨cifar100ä½¿ç”¨ï¼Œä¹Ÿæœ‰ç‚¹è¿ç§»å­¦ä¹ çš„æ„Ÿè§‰ã€‚ä½†è¿™ç¯‡çš„æœ¬è´¨å¹¶ä¸æ˜¯çœŸæ­£çš„CLï¼Œè€Œæ˜¯SPLï¼Œå› ä¸ºæ²¡æœ‰é¢„å…ˆæŒ‰ç…§difficultyæ’åºã€‚åŒæ—¶ï¼Œè¿™è®©æˆ‘æƒ³èµ·CurriculumNetï¼ŒCurriculumNetåšçš„ä¹Ÿæ˜¯ä»ä¸é è°±çš„æ•°æ®ä¸­å­¦åˆ°ä¸€ä¸ªå¥½çš„æ¨¡å‹ï¼Œä»–çš„åšæ³•åˆ™æ˜¯åˆ©ç”¨èšç±»å°†æ•°æ®åˆ†ä¸ºä¸‰ç±»ç„¶åæŒ‰é¡ºåºè®­ç»ƒï¼›è€Œè¿™é‡Œåˆ™æ˜¯é€šè¿‡çŸ¥è¯†è¿ç§»ï¼Œåœ¨ä¸€ä¸ªé è°±çš„æ•°æ®é›†ä¸Šè®­featureï¼Œç„¶ååœ¨å¦ä¸€ä¸ªä¸Šé¢æ—¶å€™ç”¨ï¼Œè¿™ä¹Ÿä¸å¤±ä¸ºå¦ä¸€ç§æ€è·¯ï¼Œä½†å¦‚æœä¸æ˜¯åŒä¸€ç±»å‹çš„æ•°æ®é›†å¦‚cifar10ä¸cifar100ï¼Œæ˜¯å¦èƒ½å¤Ÿè¿ç§»ä¹Ÿä¸å¥½è¯´ã€‚æœ€åï¼Œè¿™ç¯‡è®ºæ–‡å¯èƒ½å†™å¾—æœ‰äº›ç»•äº†ï¼Œçœ‹èµ·æ¥æœ‰ç‚¹ç´¯ã€‚</p>
<hr>
<h2 id="æœ¬å‘¨è®ºæ–‡å°ç»“"><a href="#æœ¬å‘¨è®ºæ–‡å°ç»“" class="headerlink" title="[æœ¬å‘¨è®ºæ–‡å°ç»“]"></a>[æœ¬å‘¨è®ºæ–‡å°ç»“]</h2><p>æœ¬å‘¨ç»§ç»­ä¸“æ³¨äºCurriculum Learningçš„è®ºæ–‡ã€‚ä½†æ¯”è¾ƒå·§çš„æ˜¯æœ¬å‘¨çš„è®ºæ–‡éƒ½æ˜¯å°†CLåº”ç”¨äºæ¯”è¾ƒå®é™…çš„é—®é¢˜ï¼Œå¦‚corrupted labelæˆ–è€…domain adaptationã€‚å¯¹äºè¿™æ ·çš„å®é™…é—®é¢˜ï¼Œæ›´å¤šéœ€è¦çš„æ°æ°æ˜¯è®­ç»ƒæ–¹æ³•ä¸Šçš„åˆ›æ–°ï¼Œè€ŒCLæ­£å¥½æ˜¯å±äºè¿™æ–¹é¢çš„æ–¹æ³•ï¼Œå¯¹äºè§£å†³è¿™æ ·å®é™…é—®é¢˜ï¼Œå¦‚ä½•å¼•å…¥CLæ˜¯å€¼å¾—å…³æ³¨çš„ã€‚corrupted labelåˆ‡ä¸­äº†å½“å‰ç½‘ç»œæ•°æ®å¾ˆå¤šä½†å™ªå£°å¾ˆå¤§è¿™ä¸€ç—›ç‚¹ï¼Œå¦‚ä½•è§£å†³è¿™ä¸€é—®é¢˜ï¼Œåˆ©ç”¨å¥½å¤§æ•°æ®ï¼Œæˆ–è®¸æ¯”è®¾è®¡ç²¾å·§çš„æ¨¡å‹æ‰€èƒ½å¸¦æ¥çš„æå‡æ›´å¤§ï¼›è€Œdomain adaptationåŒæ ·ä¹Ÿæ˜¯ä¸€å¤§ç—›ç‚¹ï¼Œè™½ç„¶æ•°æ®å¾ˆå¤šï¼Œä½†éƒ¨åˆ†é¢†åŸŸç›¸å…³çš„æ•°æ®ç¨€ç¼ºï¼Œæ¯”å¦‚ç¿»è¯‘é¢†åŸŸèƒ½æ”¶é›†åˆ°çš„éƒ½æ˜¯æ–°é—»çš„å¹³è¡Œè¯­æ–™ï¼Œæˆ–è€…å°è¯­ç§çš„æ•°æ®é›†å¾ˆéš¾æ”¶é›†ï¼Œç‰¹å®šä¸“ä¸šé¢†åŸŸå¦‚åŒ»ç–—çš„æ•°æ®ä¹Ÿéš¾ä»¥è·å–ã€‚å› æ­¤å¯ä»¥å¤šå¤šå…³æ³¨æ­¤ç±»è®ºæ–‡ï¼Œæ€è€ƒå¦‚ä½•è§£å†³è¿™äº›å®é™…é—®é¢˜ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>Domain Adaptation</tag>
        <tag>Pseudo Labeling</tag>
      </tags>
  </entry>
  <entry>
    <title>Curriculum Learning schedule æ€»ç»“</title>
    <url>/2019/08/09/%E8%AE%BA%E6%96%87/Curriculum%20Learning%20schedule%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>Curriculum Learningä¸»è¦æœ‰ä¸¤å—ï¼šâ‘ sampleçš„éš¾åº¦å®šä¹‰ï¼›â‘¡è®¾å®šç‰¹å®šçš„schedule</p>
<p>æœ¬æ–‡æ€»ç»“ä¸€ä¸‹ä¸åŒè®ºæ–‡ä¸­å‡ºç°çš„Curriculum Learning scheduleï¼Œå¹¶å°†å…¶åˆ†ä¸ºå‡ ç±»ã€‚</p>
<p>ä¸å®šæœŸæ›´æ–°â€¦</p>
<h2 id="è®ºæ–‡æ€»ç»“"><a href="#è®ºæ–‡æ€»ç»“" class="headerlink" title="è®ºæ–‡æ€»ç»“"></a>è®ºæ–‡æ€»ç»“</h2><h3 id="Early"><a href="#Early" class="headerlink" title="Early"></a>Early</h3><h4 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h4><p>åœ¨shape recognitionä»»åŠ¡ä¸Šæ˜¯è¾¾åˆ°switch epochæˆ–è€…ç›´åˆ°è§¦å‘early stoppingæ¢éš¾çš„æ•°æ®</p>
<h4 id="Learning-to-execute"><a href="#Learning-to-execute" class="headerlink" title="Learning to execute"></a>Learning to execute</h4><p>naive strategy: å½“validæ²¡æœ‰æå‡æ—¶å¢åŠ éš¾åº¦ï¼›mix: é€‰æ‹©ä¸€ä¸ªéš¾åº¦èŒƒå›´ï¼Œéšæœºsampleï¼›å‰äºŒè€…çš„ç»“åˆï¼šéƒ¨åˆ†æ˜¯naiveéƒ¨åˆ†æ˜¯mix</p>
<h3 id="2015"><a href="#2015" class="headerlink" title="2015"></a>2015</h3><h4 id="Self-Paced-Curriculum-Learning"><a href="#Self-Paced-Curriculum-Learning" class="headerlink" title="Self-Paced Curriculum Learning"></a>Self-Paced Curriculum Learning</h4><p>æœ¬è´¨æ˜¯self-paced learning</p>
<h4 id="Curriculum-learning-of-multiple-tasks"><a href="#Curriculum-learning-of-multiple-tasks" class="headerlink" title="Curriculum learning of multiple tasks"></a>Curriculum learning of multiple tasks</h4><p>SVMæ¨¡å‹ç›´åˆ°æ”¶æ•›å†æ¢éš¾çš„æ•°æ®</p>
<h3 id="2016"><a href="#2016" class="headerlink" title="2016"></a>2016</h3><h4 id="Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks"><a href="#Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks" class="headerlink" title="Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks"></a>Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks</h4><p>ç›´åˆ°pä¸ªepochæˆ–æ”¶æ•›å†å¢åŠ è¾ƒéš¾çš„æ•°æ®ã€‚</p>
<p><img src="/images/15653615039236.jpg" width="36%" height="50%"></p>
<h3 id="2107"><a href="#2107" class="headerlink" title="2107"></a>2107</h3><h4 id="Automated-Curriculum-Learning-for-Neural-Networks"><a href="#Automated-Curriculum-Learning-for-Neural-Networks" class="headerlink" title="Automated Curriculum Learning for Neural Networks"></a>Automated Curriculum Learning for Neural Networks</h4><p> RLè‡ªåŠ¨é€‰æ‹©task(multi-task)</p>
<h4 id="Curriculum-Learning-for-Multi-Task-Classification-of-Visual-Attributes"><a href="#Curriculum-Learning-for-Multi-Task-Classification-of-Visual-Attributes" class="headerlink" title="Curriculum Learning for Multi-Task Classification of Visual Attributes"></a>Curriculum Learning for Multi-Task Classification of Visual Attributes</h4><p>ç›´åˆ°lossæœ€å°å†åˆ‡æ¢è‡³å¦ä¸€æ•°æ®</p>
<h4 id="Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation"><a href="#Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation" class="headerlink" title="Curriculum Learning and Minibatch Bucketing in Neural Machine Translation"></a>Curriculum Learning and Minibatch Bucketing in Neural Machine Translation</h4><p>åˆ†ä¸ºå¤šä¸ªbinï¼Œå½“ç¬¬ä¸€ä¸ªbinçš„æ•°æ®è¢«å–å¾—å‰©ä¸‹ç¬¬äºŒä¸ªbinçš„ä¸€åŠï¼Œæ·»åŠ ç¬¬äºŒä¸ªbinçš„æ•°æ®ï¼Œä»ä¸¤ä¸ªbinå‰©ä¸‹çš„æ ·ä¾‹ä¸­å–ï¼Œç›´åˆ°å‰©ä¸‹çš„å’Œç¬¬ä¸‰ä¸ªbinæ ·ä¾‹æ•°ä¸€æ ·ã€‚ä»¥æ­¤ç±»æ¨</p>
<h4 id="Teacher-Student-Curriculum-Learning"><a href="#Teacher-Student-Curriculum-Learning" class="headerlink" title="Teacher-Student Curriculum Learning"></a>Teacher-Student Curriculum Learning</h4><p>æŒ‰æ¦‚ç‡ï¼Œæ¦‚ç‡ä¸é€Ÿç‡ç›¸å…³ï¼ŒRLåŠ¨æ€é€‰æ‹©èƒ½è®©æ¨¡å‹æå‡é€Ÿç‡æœ€å¤§çš„taskï¼Œå½“é€Ÿç‡ä¸‹é™ï¼Œæ¦‚ç‡ä¹Ÿä¸‹é™ï¼Œå½“æŸä¸ªtaskçš„scoreä¸‹é™äº†ï¼Œè¯´æ˜ä»–å¿˜äº†è¿™éƒ¨åˆ†çš„çŸ¥è¯†ï¼Œåˆæå‡è¯¥sampleçš„æ¦‚ç‡</p>
<p><img src="/images/15653616659179.jpg" width="70%" height="50%"></p>
<h3 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h3><h4 id="An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="An Empirical Exploration of Curriculum Learning for Neural Machine Translation"></a>An Empirical Exploration of Curriculum Learning for Neural Machine Translation</h4><p>å°†æ•°æ®åˆ†ä¸ºå¤šä¸ªshardï¼Œè®­ç»ƒçš„æ¯ä¸ªphaseå¢åŠ ä¸€ä¸ªshardçš„æ•°æ®ã€‚</p>
<p><img src="/images/15653627775691.jpg" width="50%" height="50%"></p>
<h4 id="LEARNING-TO-TEACH"><a href="#LEARNING-TO-TEACH" class="headerlink" title="LEARNING TO TEACH"></a>LEARNING TO TEACH</h4><p>åˆ©ç”¨RLå¸®åŠ©æ¨¡å‹é€‰æ‹©æ•°æ®ï¼Œä¹Ÿå³æœ‰ä¸€ä¸ªteacheræ¨¡å‹ç»™æ•°æ®æ‰“æ ‡ç­¾ï¼Œ1ä»£è¡¨ç»™å­¦ç”Ÿmodelè®­ç»ƒï¼Œ0åˆ™è¢«æŠ›å¼ƒæ‰</p>
<h4 id="Curriculum-Learning-for-Natural-Answer-Generation"><a href="#Curriculum-Learning-for-Natural-Answer-Generation" class="headerlink" title="Curriculum Learning for Natural Answer Generation"></a>Curriculum Learning for Natural Answer Generation</h4><p>æ ¹æ®æ¦‚ç‡ä»ä¸¤ä¸ªshardé‡‡æ ·ï¼Œé‡‡æ ·æ¦‚ç‡ä¼šéšç€epochè€Œæ”¹å˜ã€‚</p>
<script type="math/tex; mode=display">\begin{aligned} w_{Q_{t}} &=\left(\frac{\text { epoch}_{t}}{ | \text {epoch}_{t} |}\right)^{2} \\ w_{Q_{c}} &=1-w_{Q_{t}} \end{aligned}</script><h3 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h3><h4 id="Curriculumnet-Weakly-supervised-learning-from-large-scale-web-images"><a href="#Curriculumnet-Weakly-supervised-learning-from-large-scale-web-images" class="headerlink" title="Curriculumnet: Weakly supervised learning from large-scale web images"></a>Curriculumnet: Weakly supervised learning from large-scale web images</h4><p>åˆ†æˆ3ä¸ªshardï¼Œåˆ°æ”¶æ•›åæ·»åŠ æ–°çš„shard</p>
<h4 id="On-The-Power-of-Curriculum-Learning-in-Training-Deep-Network"><a href="#On-The-Power-of-Curriculum-Learning-in-Training-Deep-Network" class="headerlink" title="On The Power of Curriculum Learning in Training Deep Network"></a>On The Power of Curriculum Learning in Training Deep Network</h4><p>è®¾å®šå›ºå®šiterationæ•°åå¢åŠ æ•°æ®</p>
<p><img src="/images/15654067211386.jpg" width="60%" height="50%"></p>
<h4 id="Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation"><a href="#Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation" class="headerlink" title="Reinforcement Learning based Curriculum Optimization for Neural Machine Translation"></a>Reinforcement Learning based Curriculum Optimization for Neural Machine Translation</h4><p>å°†æ•°æ®åˆ‡åˆ†ä¸ºå¤šä¸ªbinï¼Œåˆ©ç”¨RLåŠ¨æ€é€‰æ‹©è®­ç»ƒå“ªä¸ªbin</p>
<h4 id="Dynamic-Curriculum-Learning-for-Imbalanced-Data-Classification"><a href="#Dynamic-Curriculum-Learning-for-Imbalanced-Data-Classification" class="headerlink" title="Dynamic Curriculum Learning for Imbalanced Data Classification"></a>Dynamic Curriculum Learning for Imbalanced Data Classification</h4><p>å°†æ•°æ®åˆ†ä¸ºå‡ ä¸ªshardï¼ŒæŒ‰æ¦‚ç‡é‡‡æ ·ï¼Œæœ‰scheduleè°ƒæ•´æ¦‚ç‡</p>
<p><img src="/images/15654068084345.jpg" width="40%" height="50%"></p>
<h4 id="Simple-and-Effective-Curriculum-Pointer-Generator-Networks-for-Reading-Comprehension-over-Long-Narratives"><a href="#Simple-and-Effective-Curriculum-Pointer-Generator-Networks-for-Reading-Comprehension-over-Long-Narratives" class="headerlink" title="Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives"></a>Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives</h4><p>å½“æ²¡æœ‰æå‡æ—¶ï¼Œæ¢éƒ¨åˆ†æ•°æ®åˆ°ç®€å•çš„æ•°æ®setå†…ï¼Œç›´åˆ°æ‰€æœ‰æ•°æ®éƒ½è¢«æ¢ï¼Œå†å°†æ•´ä¸ªæ•°æ®é›†æ¢æˆå¦ä¸€ä¸ªã€‚</p>
<p><img src="/images/15654069250310.jpg" width="34%" height="50%"></p>
<h4 id="Dynamically-Composing-Domain-Data-Selection-with-Clean-Data-Selection-by-â€œCo-Curricular-Learningâ€-for-Neural-Machine-Translation"><a href="#Dynamically-Composing-Domain-Data-Selection-with-Clean-Data-Selection-by-â€œCo-Curricular-Learningâ€-for-Neural-Machine-Translation" class="headerlink" title="Dynamically Composing Domain-Data Selection with Clean-Data Selection by â€œCo-Curricular Learningâ€ for Neural Machine Translation"></a>Dynamically Composing Domain-Data Selection with Clean-Data Selection by â€œCo-Curricular Learningâ€ for Neural Machine Translation</h4><p>å•è°ƒé€’å‡çš„å…‰æ»‘æ›²çº¿æ§åˆ¶å½“å‰å¯ç”¨äºè®­ç»ƒæ•°æ®çš„å¤§å°ã€‚</p>
<h4 id="Curriculum-Learning-for-Domain-Adaptation-in-Neural-Machine-Translation"><a href="#Curriculum-Learning-for-Domain-Adaptation-in-Neural-Machine-Translation" class="headerlink" title="Curriculum Learning for Domain Adaptation in Neural Machine Translation"></a>Curriculum Learning for Domain Adaptation in Neural Machine Translation</h4><p>åˆ†æˆshardï¼Œæ¯ä¸ªè®­ç»ƒçš„phaseå¢åŠ ä¸€ä¸ªshardã€‚</p>
<h4 id="Pseudo-Labeling-Curriculum-for-Unsupervised-Domain-Adaptation"><a href="#Pseudo-Labeling-Curriculum-for-Unsupervised-Domain-Adaptation" class="headerlink" title="Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation"></a>Pseudo-Labeling Curriculum for Unsupervised Domain Adaptation</h4><p>åˆ†å¤šä¸ªshardï¼Œæ”¶æ•›ååŠ shard</p>
<h4 id="Competence-based-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#Competence-based-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="Competence-based Curriculum Learning for Neural Machine Translation"></a>Competence-based Curriculum Learning for Neural Machine Translation</h4><p>ç»™å®šä¸€ä¸ªå•è°ƒé€’å¢çš„æ›²çº¿æ§åˆ¶å½“å‰å¯ç”¨äºè®­ç»ƒçš„æ•°æ®çš„æ¯”ä¾‹ã€‚</p>
<p><img src="/images/15654072010953.jpg" width="50%" height="50%"></p>
<h2 id="åˆ†ç±»"><a href="#åˆ†ç±»" class="headerlink" title="åˆ†ç±»"></a>åˆ†ç±»</h2><p>æŒ‰å¤§ç±»æœ‰ä¸‰ç§ï¼šä¸€ç§æ§åˆ¶è®­ç»ƒå¯è§çš„æ•°æ®ï¼›ä¸€ç§æ§åˆ¶å½“å‰è®­ç»ƒæ•°æ®è¢«sampleçš„æ¦‚ç‡ï¼›å¦ä¸€ç§RLç›´æ¥æ›¿æ¨¡å‹é€‰æ‹©ã€‚</p>
<p>å¯¹äºç¬¬ä¸€ç±»è€Œè¨€ï¼Œå¯åˆ†æˆï¼š</p>
<ol>
<li>ç»™å®šschedule<ol>
<li>æ¯kä¸ªstepå°±å¢åŠ p%å¯è§çš„æ•°æ®</li>
<li>å°†æ•°æ®åˆ†ä¸ºmä¸ªshardï¼Œæ¯kä¸ªstep/phaseåˆ™å¢åŠ ä¸€ä¸ªshard</li>
<li>å…¶ä»–æ›´ç²¾ç»†çš„scheduleã€‚å¦‚sampleåˆ°å‰©å¤šå°‘æ—¶æ·»åŠ æ–°æ•°æ®ï¼ˆCurriculum Learning and Minibatch Bucketing in Neural Machine Translationï¼‰ï¼Œæˆ–swapæ–°æ•°æ®åˆ°æ—§æ•°æ®é‡Œï¼ˆSimple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narrativesï¼‰</li>
</ol>
</li>
<li>è¾¾åˆ°æŸä¸ªæ¡ä»¶ï¼šåˆ°epochæ•°æˆ–æ”¶æ•›å°±å¢åŠ ä¸€ä¸ªshardæˆ–æ¢æ•°æ®ï¼ˆCurriculum learning of multiple tasksï¼‰</li>
</ol>
<p>å¯¹äºç¬¬äºŒç±»è€Œè¨€ï¼Œå¯åˆ†ä¸ºï¼š</p>
<ol>
<li>å®šä¹‰ä¸€ä¸ªå¹³æ»‘scheduleå‡½æ•°ï¼Œä¸epochæˆ–stepæŒ‚é’©ã€‚æ¯”å¦‚ï¼ŒCurriculum Learning for Natural Answer Generationæˆ–Dynamic Curriculum Learning for Imbalanced Data Classificationã€‚ä¸€èˆ¬æ­¤ç±»éƒ½æ˜¯å°†æ•°æ®åˆ†ä¸ºå‡ ä¸ªå—ï¼Œæ¦‚ç‡æ˜¯å®šä¹‰åœ¨å—ä¸Šè€Œä¸æ˜¯sampleä¸Š</li>
<li>RLæ§åˆ¶ï¼Œä¸å½“å‰æ¨¡å‹å¯¹è¯¥æ•°æ®çš„è¡¨ç°ç›¸å…³ï¼ˆTeacher-Student Curriculum Learningï¼‰</li>
</ol>
<p>å¯¹äºç¬¬ä¸‰ç±»RLè€Œè¨€ï¼Œè¾ƒä¸ºä¸°å¯Œï¼š<br>æœ‰ç¡®å®šmulti-taskçš„taské¡ºåºçš„ï¼›<br>æœ‰ä»å¤šä¸ªé¢„å®šä¹‰çš„binä¸­åŠ¨æ€é€‰æ‹©å“ªä¸ªbinçš„æ•°æ®çš„ï¼›<br>ä»è¢«sampleåˆ°çš„batchä¸­é€‰æ‹©å¯è®©æ¨¡å‹è®­ç»ƒçš„ï¼›<br>è¿˜æœ‰åŠ¨æ€æ§åˆ¶æ‰€æœ‰æ•°æ®è¢«sampleçš„æ¦‚ç‡ã€‚</p>
<p>æœªæ¥å¯ä»¥åšä¸€ä¸ªè¡¨æ ¼ï¼Œå°†å±äºæŸç±»çš„éƒ½å½’åœ¨ä¸€èµ·ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†26</title>
    <url>/2019/08/04/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8626/</url>
    <content><![CDATA[<h3 id="Python"><a href="#Python" class="headerlink" title="[Python]"></a>[Python]</h3><p>Pythonå·¥ç¨‹çš„æ–‡ä»¶å¤¹çš„initçš„ä½œç”¨æ˜¯è®¾ç½®å¯¹å¤–å¼€æ”¾çš„æ¥å£ï¼ˆä¹‹å‰ä¸€ç›´ä¸çŸ¥é“ğŸ˜…ï¼‰ã€‚</p>
<hr>
<h3 id="Mac"><a href="#Mac" class="headerlink" title="[Mac]"></a>[Mac]</h3><p>è§£å†³Mac Mojaveåœ¨æµè§ˆç½‘é¡µæ—¶å‡ºç°çš„â€æ‚¨çš„æµè§ˆå™¨é™åˆ¶äº†ç¬¬ä¸‰æ–¹Cookieâ€œï¼š</p>
<p><a href="https://chuill.com/post/107.html" target="_blank" rel="noopener">https://chuill.com/post/107.html</a></p>
<hr>
<h3 id="iTerm"><a href="#iTerm" class="headerlink" title="[iTerm]"></a>[iTerm]</h3><p>ä½¿ç”¨iTermåœ¨è¯ä¸è¯ä¹‹é—´è·³è½¬ï¼š</p>
<p><a href="https://coderwall.com/p/h6yfda/use-and-to-jump-forwards-backwards-words-in-iterm-2-on-os-x" target="_blank" rel="noopener">https://coderwall.com/p/h6yfda/use-and-to-jump-forwards-backwards-words-in-iterm-2-on-os-x</a></p>
<hr>
<h3 id="Linux"><a href="#Linux" class="headerlink" title="[Linux]"></a>[Linux]</h3><p>å¦‚ä½•cdè¿›å…¥å¼€å¤´ä¸ºâ€˜-â€™çš„æ–‡ä»¶å¤¹ï¼šåœ¨æ–‡ä»¶å¤¹å‰è¾“å…¥â€˜- -â€™</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> -- -1</span><br></pre></td></tr></table></figure>
<p><a href="https://segmentfault.com/q/1010000005684176" target="_blank" rel="noopener">https://segmentfault.com/q/1010000005684176</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Python</tag>
        <tag>Mac</tag>
        <tag>iTerm</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯32</title>
    <url>/2019/08/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D32/</url>
    <content><![CDATA[<h3 id="é¹Šè¸æ-Â·-è°é“é—²æƒ…æŠ›æ·ä¹…"><a href="#é¹Šè¸æ-Â·-è°é“é—²æƒ…æŠ›æ·ä¹…" class="headerlink" title="é¹Šè¸æ Â· è°é“é—²æƒ…æŠ›æ·ä¹…"></a>é¹Šè¸æ Â· è°é“é—²æƒ…æŠ›æ·ä¹…</h3><p>[äº”ä»£åå›½] å†¯å»¶å·³<br>è°é“é—²æƒ…æŠ›æ·ä¹…ï¼Ÿæ¯åˆ°æ˜¥æ¥ï¼Œæƒ†æ€…è¿˜ä¾æ—§ã€‚æ—¥æ—¥èŠ±å‰å¸¸ç—…é…’ï¼Œä¸è¾é•œé‡Œæœ±é¢œç˜¦ã€‚<br>æ²³ç•”é’èŠœå ¤ä¸ŠæŸ³ï¼Œä¸ºé—®æ–°æ„ï¼Œä½•äº‹å¹´å¹´æœ‰ï¼Ÿ<strong>ç‹¬ç«‹å°æ¥¼é£æ»¡è¢–ï¼Œå¹³æ—æ–°æœˆäººå½’å</strong>ã€‚</p>
<hr>
<h3 id="æ€¨æƒ…"><a href="#æ€¨æƒ…" class="headerlink" title="æ€¨æƒ…"></a>æ€¨æƒ…</h3><p>[å”] æç™½<br>ç¾äººå·ç å¸˜ï¼Œæ·±åé¢¦è›¾çœ‰ã€‚<br>ä½†è§æ³ªç—•æ¹¿ï¼Œä¸çŸ¥å¿ƒæ¨è°ã€‚</p>
<hr>
<h3 id="ç™»ä¹æ¸¸åŸ"><a href="#ç™»ä¹æ¸¸åŸ" class="headerlink" title="ç™»ä¹æ¸¸åŸ"></a>ç™»ä¹æ¸¸åŸ</h3><p>[å”] æå•†éš<br>å‘æ™šæ„ä¸é€‚ï¼Œé©±è½¦ç™»å¤åŸã€‚<br><strong>å¤•é˜³æ— é™å¥½ï¼Œåªæ˜¯è¿‘é»„æ˜</strong>ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>è®°åˆä¸€æ¬¡debugçš„è¡€æ³ªæ•™è®­</title>
    <url>/2019/08/04/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E8%AE%B0%E5%8F%88%E4%B8%80%E6%AC%A1debug%E7%9A%84%E8%A1%80%E6%B3%AA%E6%95%99%E8%AE%AD/</url>
    <content><![CDATA[<p>è¿™æ¬¡çš„è¡€æ³ªæ•™è®­å°±æ˜¯ï¼ŒshuffleçœŸçš„å¾ˆé‡è¦ï¼</p>
<p>è®­ç»ƒæ¨¡å‹å‘ç°ä¸€ä¸ªé—®é¢˜ï¼štrainé›†å’Œdevé›†çš„performanceå·®åˆ«å¾ˆå¤§ã€‚</p>
<p>æˆ‘çš„å¿ƒè·¯å†ç¨‹ï¼š</p>
<ol>
<li>æ€€ç–‘è‡ªå·±çš„iteratorå†™é”™äº†ï¼Œå°†å…¶æ¢æˆdataloaderä¹‹åï¼Œä»ç„¶æœ‰æ­¤é—®é¢˜ã€‚</li>
<li>æœ‰æ²¡æœ‰å¯èƒ½æ˜¯æ¨¡å‹çš„é—®é¢˜ï¼Ÿ å°è¯•æ¢æˆä»¥å‰å†™è¿‡çš„æ¨¡å‹ï¼Œä½†ä»ç„¶æœ‰è¿™ä¸ªç°è±¡</li>
<li>éš¾é“æ˜¯æ•°æ®é›†çš„é—®é¢˜ï¼Ÿæˆ‘å°è¯•printäº†å‡ æ¡æ•°æ®ï¼Œä¸€åˆ‡æ­£å¸¸ï¼Œä¹Ÿæ²¡æœ‰å‡ºç°å¤§é‡UNKã€‚</li>
<li>æ˜¯æˆ‘è®­ç»ƒæ–¹æ³•å‡ºç°é—®é¢˜ï¼Ÿ<ol>
<li>å°è¯•è°ƒæ•´å­¦ä¹ ç‡ã€‚å½“è°ƒå¤§å­¦ä¹ ç‡æ—¶ï¼Œè®­ç»ƒé›†çš„performanceéå¸¸å·®ï¼Œåªæœ‰10%ï¼Œè€Œvalidé›†æœ‰35%ï¼›å½“è°ƒå°å­¦ä¹ ç‡æ—¶ï¼Œè®­ç»ƒé›†çš„performanceæœ‰70%ï¼Œè€Œvalidé›†ä»ç„¶åªæœ‰30%å·¦å³ã€‚</li>
<li>å°è¯•ä¸clipã€‚è®­ç»ƒé›†çš„performanceå˜é«˜äº†ï¼Œä½†validä»ç„¶å¾ˆå·®ã€‚è®­ç»ƒå¤šå‡ ä¸ªepochä¹Ÿæ˜¯ä¸€æ ·ã€‚</li>
<li>æˆ‘æŠŠè®­ç»ƒé›†çš„æ•°æ®æ¢æˆéªŒè¯é›†çš„æ•°æ®ï¼Œç”¨éªŒè¯é›†æ¥è®­ç»ƒã€‚ç¥å¥‡çš„æ˜¯ï¼Œå±…ç„¶ä¸ä¼šè¿‡æ‹Ÿåˆã€‚è®­ç»ƒçš„performanceç”šè‡³æ¯”éªŒè¯çš„performanceæ›´å·®ï¼Œä½†æ˜æ˜æ˜¯åŒä¸€ä¸ªæ•°æ®é›†è®­ç»ƒçš„ã€‚</li>
</ol>
</li>
<li>éš¾é“æ˜¯æˆ‘ç»Ÿè®¡çš„é—®é¢˜ï¼Ÿ<ol>
<li>ä¼šä¸ä¼šæ˜¯æˆ‘åœ¨ç»Ÿè®¡losså’Œaccuracyå‡ºç°é—®é¢˜ï¼Ÿ ä½†è‚‰çœ¼debugäº†åŠå¤©ï¼Œå®Œå…¨æ²¡æ‰¾åˆ°é—®é¢˜ã€‚</li>
<li>æ‰“å°ä¸€ä¸‹predictçš„å€¼ï¼Œå‘ç°ä¸€ä¸ªbatchå†…éƒ¨é¢„æµ‹çš„å…¨éƒ¨éƒ½æ˜¯ä¸€æ ·çš„labelã€‚æ˜¯æ¨¡å‹åˆ†ç±»çš„é—®é¢˜ï¼Ÿä½†ä¸åº”è¯¥å•Šï¼Œæ˜æ˜checkè¿‡æ¨¡å‹äº†ï¼Œåº”è¯¥ä¸æ˜¯æ¨¡å‹çš„é”…</li>
<li>å—¯ï¼Ÿéš¾é“æ˜¯labelçš„é—®é¢˜ï¼Ÿç»Ÿè®¡ä¸€ä¸‹labelçš„åˆ†å¸ƒï¼Œç¡®å®labelç±»åˆ«ä¸å¹³è¡¡ï¼Œä½†ä¹Ÿåœ¨åˆç†èŒƒå›´å†…ã€‚</li>
<li>è¯•è¯•æ‰“å°ä¸€ä¸‹batchçš„labelå§ã€‚ â€¦è¿™ä¸‹å‘ç°ï¼Œä¸ºä»€ä¹ˆbatchå†…éƒ¨çš„labelå…¨éƒ¨éƒ½æ˜¯åŒä¸€ç±»çš„ï¼Ÿéš¾æ€ªpredictæ—¶ä¹Ÿæ˜¯åŒä¸€ç±»ã€‚æ˜¯ä¸æ˜¯æ•°æ®æœ¬æ¥å°±æ˜¯æŒ‰labelé¡ºåºæ’çš„ï¼Ÿ</li>
</ol>
</li>
</ol>
<p>ohï¼Œä¸ä¼šæ˜¯æ²¡æœ‰shuffleå§ã€‚checkäº†ä¸€ä¸‹ä»£ç ï¼Œå‘ç°æˆ‘çš„iteratoræ˜¯è¿™æ ·çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, self.data_len, self.batch_size):</span><br><span class="line">        start = i</span><br><span class="line">        end = min(self.data_len, i + self.batch_size)</span><br><span class="line">        sents = self.data[<span class="string">'sents'</span>][start:end]</span><br><span class="line">        labels = self.data[<span class="string">'labels'</span>][start:end]</span><br><span class="line">        batch = &#123;<span class="string">'sents'</span>: sents, <span class="string">'labels'</span>: labels&#125;</span><br><span class="line">        batch = convert2tensor(batch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> batch</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> self.shuffle:</span><br><span class="line">        start_state = random.getstate()</span><br><span class="line">        random.shuffle(self.data[<span class="string">'sents'</span>])</span><br><span class="line">        random.setstate(start_state)</span><br><span class="line">        random.shuffle(self.data[<span class="string">'labels'</span>])</span><br></pre></td></tr></table></figure>
<p>æœ‰shuffleå•Šã€‚ç­‰ç­‰ï¼Œæˆ‘å¥½åƒæ˜¯åœ¨iterå®Œåå†shuffleçš„ã€‚ä½†è¿™çœŸçš„æœ‰é—®é¢˜å—ï¼Ÿå¯èƒ½ç¬¬ä¸€æ¬¡æ²¡shuffleï¼Œä½†åé¢éƒ½shuffleäº†ä¸ºå•¥performanceè¿˜æ˜¯æ²¡æœ‰ä¸Šå»ï¼Ÿ</p>
<p>åæ­£æ‰¾ä¸åˆ°bugï¼Œé‚£å°±è¯•ä¸€ä¸‹å§ï¼Œæˆ‘æŠŠshuffleä»£ç æ”¾åœ¨å‰é¢ã€‚ç»“æœæ˜¯ï¼Œè®­ç»ƒè¿‡ç¨‹çš„ç»“æœå˜æ­£å¸¸äº†â€¦</p>
<p>æƒ³äº†ä¸€ä¸‹åŸå› ã€‚<br>ç¬¬ä¸€ï¼Œæ•°æ®çœŸçš„éå¸¸éœ€è¦shuffleï¼Œä¸€äº›æ•°æ®é›†æ˜¯æŒ‰ç…§labelæ¥æ’çš„ï¼Œå‡å¦‚ä¸shuffleç›´æ¥æŒ‰é¡ºåºå–‚æ•°æ®ä¼šå‡ºç°ä»€ä¹ˆæƒ…å†µå‘¢ï¼Ÿæ¨¡å‹ä¸€å¼€å§‹æ¥è§¦åˆ°çš„éƒ½æ˜¯åŒä¸€ç±»çš„æ•°æ®ï¼Œé‚£ä¹ˆå°±ä¼šç–¯ç‹‚overfitåˆ°è¯¥ç±»çš„patternï¼Œç­‰åˆ°ä»–æœ‰æœºä¼šæ¥è§¦ä¸‹ä¸€ç±»åï¼Œå¯èƒ½å·²ç»é™·å…¥local minimumäº†ï¼Œå†æ€ä¹ˆè®­éƒ½é›·æ‰“ä¸åŠ¨äº†ï¼Œè¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å½“è°ƒé«˜å­¦ä¹ ç‡æ—¶å‡ºç°training setåœ¨10%è€Œvalid setåœ¨30%ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹å·²ç»æ— æ³•æ‹Ÿåˆtraining setçš„å…¶ä»–ç±»äº†ï¼›æˆ–è€…å¦‚æœå­¦ä¹ ç‡å°ï¼Œé‚£ä¹ˆè¿˜æ²¡overfitå¾—å¾ˆä¸¥é‡ï¼Œåœ¨æ¥è§¦åˆ°ä¸‹ä¸€ç±»æ—¶ï¼Œä»ç„¶ä¼šå¾ˆå¿«overfitåˆ°è¯¥ç±»ï¼Œåœ¨ä¸€ä¸ªepochåï¼Œæ¨¡å‹ä¼šoverfitåˆ°æœ€åä¸€ä¸ªæ¥è§¦çš„ç±»ï¼Œæ­¤æ—¶åševaluationï¼Œå½“ç„¶ç»“æœå¥½ä¸åˆ°å“ªé‡Œå»ï¼Œä½†åœ¨training setä¸Šå´è¿˜å¯ä»¥ã€‚</p>
<p>ç¬¬äºŒï¼Œä¸ºä»€ä¹ˆåœ¨ç¬¬ä¸€ä¸ªepochååšshuffleï¼Œåœ¨åç»­çš„epochæ¨¡å‹ä»ç„¶ä¸æ­£å¸¸å‘¢ï¼Ÿå’Œä¸Šè¿°çš„åŸå› å¯èƒ½ç›¸åŒï¼Œå› ä¸ºoverfitåˆ°ä¸€ä¸ªç‰¹å®šç±»çš„patternäº†ï¼Œå†ä¹Ÿæ— æ³•ä»local minimumå‡ºæ¥äº†ã€‚å‡å¦‚å­¦ä¹ ç‡è°ƒçš„è¶³å¤Ÿå°ï¼Œæˆ–è®¸è¿˜æœ‰æ•‘ï¼Œä½†ä¸€èˆ¬æˆ‘ä»¬ç”¨çš„éƒ½æ˜¯Adamä¹‹ç±»çš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ ç‡å¯èƒ½è¶Šå˜è¶Šå¤§ï¼Œåˆ°æœ€åå¯èƒ½è¿˜æ˜¯æ²¡æ•‘ã€‚</p>
<p>æ‰€ä»¥å•Šï¼Œä¸€å®šä¸è¦å¿˜è®°shuffleï¼</p>
<p>æœ€åè´´ä¸Šæˆ‘åœ¨debugè¿‡ç¨‹ä¸­çš„è®°å½•ï¼Œæ¥çºªå¿µè¿™æ¬¡çš„è¡€æ³ªæ•™è®­ã€‚</p>
<p><img src="/images/debug%20record.png" width="80%" height="50%"></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºTransformerä¸­positionåœ¨ä»£ç å®ç°çš„ä¸€ç‚¹æ€è€ƒ</title>
    <url>/2019/08/04/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8ETransformer%E4%B8%ADposition%E5%9C%A8%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<p>Transformeréœ€è¦æ˜¾å¼åŠ positionï¼Œä¸åŒç‰ˆæœ¬çš„ä»£ç æœ‰ä¸åŒåˆ›å»ºpositionçš„æ–¹å¼ã€‚å‰å‡ å¤©åœ¨å®ç°ä¸­é‡åˆ°äº†ä¸€äº›å°é—®é¢˜ï¼Œå› æ­¤è®°å½•åœ¨æ­¤ã€‚</p>
<p>è¿‡å»åœ¨è·å–positionçš„æ—¶å€™ï¼Œä¸€èˆ¬éƒ½æ˜¯åœ¨å¤–éƒ¨åˆ›å»ºï¼Œä¹Ÿå³åœ¨åšbatchçš„æ—¶å€™åˆ›å»ºã€‚å…·ä½“è€Œè¨€ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span></span><br><span class="line">    sentences, labels = [], []</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> batch:</span><br><span class="line">        sentences.append(b[<span class="number">0</span>])</span><br><span class="line">        labels.append(b[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    max_len = max(len(sent) <span class="keyword">for</span> sent <span class="keyword">in</span> sentences)</span><br><span class="line">    batch_seq = np.array([</span><br><span class="line">        sent + [<span class="number">0</span>] * (max_len - len(sent))</span><br><span class="line">        <span class="keyword">for</span> sent <span class="keyword">in</span> sentences</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    batch_pos = np.array([</span><br><span class="line">        [pos_i + <span class="number">1</span> <span class="keyword">if</span> word_i != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">         <span class="keyword">for</span> pos_i, word_i <span class="keyword">in</span> enumerate(sent)] <span class="keyword">for</span> sent <span class="keyword">in</span> batch_seq</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    batch_label = np.array(labels)</span><br><span class="line"></span><br><span class="line">    batch_seq = torch.LongTensor(batch_seq)</span><br><span class="line">    batch_pos = torch.LongTensor(batch_pos)</span><br><span class="line">    batch_label = torch.LongTensor(batch_label)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_seq, batch_pos, batch_label</span><br></pre></td></tr></table></figure>
<p><code>collate_fn</code>æ˜¯Dataloaderçš„å‚æ•°ï¼Œå…·ä½“çš„ä½œç”¨æ˜¯åœ¨è·å–äº†sampleå’Œlabelåæ˜¾å¼paddingä»¥åŠè½¬æ¢ä¸ºtensorç­‰æ“ä½œã€‚</p>
<p>è€Œåœ¨æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ï¼Œåˆ™å°†positionä½œä¸ºå‚æ•°æ˜¾å¼ä¼ å…¥forwardé‡Œï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model(batch_seq, batch_pos)</span><br></pre></td></tr></table></figure>
<p>è¿™æ˜¯ä¸€ç§æ–¹æ³•ï¼Œä½†æˆ‘è®¤ä¸ºçœ‹èµ·æ¥ä¸å¤§ä¼˜é›…ã€‚å‡è®¾ä»¥ä¸‹æƒ…å½¢ï¼šæˆ‘å¸Œæœ›å°†Transformerä½œä¸ºencoderæ¥åˆ†ç±»ï¼ŒåŒæ—¶å¸Œæœ›ä¸LSTMä½œä¸ºencoderæ¥å¯¹æ¯”ã€‚ä½†LSTMä¸éœ€è¦positionï¼Œä¸”positionä½œä¸ºå‚æ•°å·²ç»å†™æ­»åœ¨å‡½æ•°é‡Œäº†ï¼Œè¿™æ ·ä¸€æ¥ï¼Œå°±ä¸èƒ½å¾ˆæ–¹ä¾¿åœ°æ¢æ¨¡å—äº†ã€‚</p>
<p>å› æ­¤ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåœ¨æ¨¡å‹å†…éƒ¨åˆ›å»ºpositionï¼Œä½¿å¾—ä¼ å…¥çš„å‚æ•°åªæœ‰<code>batch_seq</code>ï¼Œè¿™æ ·æ›´åŠ ä¼˜é›…ã€‚</p>
<p>æˆ‘ä¸€å¼€å§‹çš„åŠæ³•æ˜¯å°è£…ä¸€ä¸ª<code>EmbeddingLayer</code>ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmbeddingLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, args, pretrained_matrix=None)</span>:</span></span><br><span class="line">        super(EmbeddingLayer, self).__init__()</span><br><span class="line">        self.word_embedding = nn.Embedding(args.vocab_size, args.embed_dim, padding_idx=<span class="number">0</span>)</span><br><span class="line">        self.embed_factor = args.embed_dim ** (<span class="number">1</span> / <span class="number">2</span>)</span><br><span class="line">        self.dropout = nn.Dropout(args.dropout)</span><br><span class="line">        <span class="keyword">if</span> pretrained_matrix <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            pretrained_matrix = torch.from_numpy(pretrained_matrix).type(torch.FloatTensor)</span><br><span class="line">            self.word_embedding.weight = nn.Parameter(pretrained_matrix, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">        n_position = args.max_sent_len + <span class="number">1</span></span><br><span class="line">        self.position_embedding = nn.Embedding.from_pretrained(</span><br><span class="line">            get_sinusoid_encoding_table(n_position, args.embed_dim, padding_idx=<span class="number">0</span>),</span><br><span class="line">            freeze=<span class="keyword">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, seq)</span>:</span></span><br><span class="line">        x = self.word_embedding(seq) * self.embed_factor</span><br><span class="line"></span><br><span class="line">        pos = self._create_pos(seq)</span><br><span class="line">        x = x + self.position_embedding(pos)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_create_pos</span><span class="params">(self, seq)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param seq: batch,seq</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        seq_pos = np.array([</span><br><span class="line">             [pos_i + <span class="number">1</span> <span class="keyword">if</span> word_i != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">              <span class="keyword">for</span> pos_i, word_i <span class="keyword">in</span> enumerate(sent)] <span class="keyword">for</span> sent <span class="keyword">in</span> seq</span><br><span class="line">         ])</span><br><span class="line">        <span class="keyword">return</span> seq_pos.to(seq.device)</span><br></pre></td></tr></table></figure>
<p>ä¹Ÿå³åœ¨EmbeddingLayerå†…éƒ¨æ ¹æ®seqæ¥ç”Ÿæˆpositionã€‚</p>
<p>è™½ç„¶é€»è¾‘ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œä½†çœ‹GPUçš„åˆ©ç”¨ç‡æ€»æ˜¯å¾ˆä½ã€‚æ’æŸ¥äº†å¾ˆä¹…ä¹‹åï¼Œæ‰å‘ç°ä¸Šè¿°<code>_create_pos(self, seq)</code>çš„æ•ˆç‡å¤ªä½äº†ã€‚</p>
<p>çœ‹èµ·æ¥ä¼¼ä¹æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œè¿™å’Œ<code>collate_fn</code>çš„åšæ³•æ˜¯ä¸€æ ·çš„ã€‚ä½†ä¸ºä»€ä¹ˆå°±æ˜¯æ•ˆç‡é‚£ä¹ˆä½ï¼Ÿ</p>
<p>æ€è€ƒäº†ä¸€ä¸‹ï¼Œæˆ‘æ¨æµ‹æ˜¯å› ä¸ºï¼Œmodelå†…éƒ¨ä¸€èˆ¬éƒ½æ˜¯tensoræ“ä½œï¼Œä¸€èˆ¬éƒ½æ˜¯åœ¨GPUä¸Šçš„æ“ä½œï¼›è€Œ<code>_create_pos</code>ä½œä¸ºmodelå†…éƒ¨çš„å‡½æ•°ï¼Œå´æ˜¯åšäº†åœ¨CPUä¸Šçš„æ“ä½œã€‚è¿™æ ·ä¸€æ¥ï¼Œæœ¬æ¥æ•´ä¸ªGPUæµæ°´çº¿çš„è¿ç®—ï¼Œå´è¦ç­‰è¿™ä¸ªCPUçš„æ“ä½œå®Œæˆäº†æ‰èƒ½å¾€ä¸‹åšã€‚è¿™å°±å¯¼è‡´äº†åˆ©ç”¨ç‡ä½ä¸‹çš„é—®é¢˜ã€‚</p>
<p>ä¸ºäº†éªŒè¯æˆ‘çš„æƒ³æ³•ï¼Œæˆ‘å°è¯•å°†ä»£ç æ”¹æˆtensorçš„æ“ä½œï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_pos</span><span class="params">(self, seq)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param seq: batch,seq</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    batch_size, max_seq_len = seq.size()</span><br><span class="line">    pos_tensor = torch.arange(<span class="number">1</span>, max_seq_len + <span class="number">1</span>)[<span class="keyword">None</span>, :].expand(batch_size, <span class="number">-1</span>).long()  <span class="comment"># batch,max_seq_len we don't do padding</span></span><br></pre></td></tr></table></figure>
<p>é¦–å…ˆä¸Šè¿°ä»£ç æ˜¯å®Œå…¨çš„tensoræ“ä½œï¼Œæ˜¯åœ¨GPUä¸Šå®Œæˆçš„ï¼›ç¬¬äºŒï¼Œæˆ‘æ„è¯†åˆ°å…¶å®ä¸éœ€è¦æ˜¾å¼å°†sequenceä¸­paddingçš„ä½ç½®å¯¹åº”çš„positionä¹Ÿç½®ä¸º0ã€‚å› ä¸ºåªè¦paddingçš„ä½ç½®ä¸å‚ä¸è®¡ç®—losså°±æ²¡æœ‰å…³ç³»ï¼›æˆ–è€…å°†paddingçš„æ“ä½œäº¤ç»™åç»­çš„maskæ¥åšå³å¯ã€‚</p>
<p>è¿™æ ·æ”¹ä¸€ä¸‹ï¼Œå‘ç°GPUåˆ©ç”¨ç‡ç»ˆäºå¤§å¹…æå‡ï¼ŒåŸºæœ¬ä¸Š95%ä»¥ä¸Šã€‚</p>
<p>é‚£ä¹ˆå¦ä¸€é—®é¢˜åˆæ¥äº†ï¼Œä¸ºå•¥ä¹‹å‰<code>collate_fn</code>çš„åšæ³•ï¼Œä¹Ÿå³åœ¨å¤–éƒ¨åˆ›å»ºposæ²¡é—®é¢˜ï¼ŒåŒæ ·çš„åšæ³•ç§»åˆ°modelå†…éƒ¨æ¥å°±æœ‰é—®é¢˜ï¼Ÿ</p>
<p>æˆ‘æ¨æµ‹ï¼Œç¬¬ä¸€ï¼Œåœ¨CPUä¸Šçš„æ“ä½œæ˜¯å¯ä»¥å¤šçº¿ç¨‹çš„ï¼Œè¿™è¾¹CPUè¾¹åˆ›å»ºæ–°çš„batchï¼Œå¦ä¸€è¾¹modelåœ¨GPUè¾¹è®­ç»ƒï¼Œè¿™ä¸¤ä¸ªï¼ˆCPUå’ŒGPUï¼‰å®è´¨ä¸Šæ˜¯å¹¶è¡Œçš„è€Œä¸æ˜¯ä¸²è¡Œçš„ï¼›ç¬¬äºŒï¼Œå¦‚æœå°†å…¶ç§»åˆ°å†…éƒ¨æ“ä½œï¼Œå°±å˜æˆäº†å¤–éƒ¨CPUåˆ›å»ºå¥½batchï¼Œä¼ å…¥modelåï¼Œmodelå†…éƒ¨è¿˜è¦ç»å† GPU â€”&gt; CPU â€”&gt; GPUçš„æ“ä½œï¼Œæ˜¾ç„¶CPUä¼šæ‹–ç´¯æ•´ä¸ªè¿›åº¦ï¼Œä¸”å¯¼è‡´åˆ©ç”¨ç‡ä½ä¸‹çš„é—®é¢˜ã€‚</p>
<hr>
<p>å°±è¿™ä¹ˆä¸€ä¸ªå°å°çš„é—®é¢˜ï¼Œæˆ‘å°±debugäº†ä¸€å¤©ï¼Œä¸€å¼€å§‹æ€€ç–‘æ˜¯æˆ‘è‡ªå·±çš„iteratorå†™çš„æ•ˆç‡ä½ï¼Œç„¶åæ¢æˆäº†å®˜æ–¹çš„Dataloaderä¸”å¼€äº†10ä¸ªè¿›ç¨‹ï¼Œä½†ä»ç„¶æœ‰é—®é¢˜ï¼›åæ¥æ€€ç–‘æ˜¯æ¨¡å‹å†™é”™äº†ï¼Œcheckäº†åŠå¤©éƒ½æ²¡æœ‰å‘ç°å“ªé‡Œæœ‰é—®é¢˜ï¼›ç„¶åæ˜¯å¼€Pycharmçš„profileæŸ¥çœ‹æ˜¯å“ªäº›å‡½æ•°å ç”¨å¤ªå¤šæ—¶é—´ï¼Œä½†å› ä¸º<code>_create_pos</code>æœ¬èº«æ˜¯æ²¡æœ‰è¿è¡Œå¾ˆé•¿æ—¶é—´çš„ï¼Œåªæ˜¯é˜»ç¢äº†GPUçš„è¿è¡Œæ•ˆç‡ï¼Œå› æ­¤ä¹Ÿæ²¡æœ‰å‘ç°è¿™ä¸ªé—®é¢˜ï¼›ä¹Ÿæ˜¯åˆ°æœ€åï¼Œå°è¯•ä¸ç”¨positionåï¼Œæ‰å‘ç°æ•ˆç‡æœ‰å¤§å¹…æå‡ã€‚</p>
<p>ä»è¿™æ¬¡çš„debugç»å†ï¼Œæœ‰ä¸¤ä¸ªæ·±åˆ»æ•™è®­ï¼šâ‘ modelå†…éƒ¨å°½å¯èƒ½åˆ©ç”¨GPUè€Œä¸è¦åšå¤ªå¤šçš„CPUæ“ä½œï¼Œå¦åˆ™å°±å¯èƒ½å‡ºç°ä¸Šè¿°é—®é¢˜ï¼›â‘¡åœ¨debugè¦å¤§èƒ†å°è¯•æ§åˆ¶å˜é‡ï¼Œè€Œä¸è¦ä»…ä»…æ˜¯è‚‰çœ¼å»çœ‹ä»£ç æ‰¾bugã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•18</title>
    <url>/2019/08/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9518/</url>
    <content><![CDATA[<h3 id="ä¸å®šé•¿iteratorçš„å†™æ³•"><a href="#ä¸å®šé•¿iteratorçš„å†™æ³•" class="headerlink" title="[ä¸å®šé•¿iteratorçš„å†™æ³•]"></a>[ä¸å®šé•¿iteratorçš„å†™æ³•]</h3><p>ä¸ç¡®å®šiteratorçš„é•¿åº¦çš„å†™æ³•ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Iter</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        span_length = self.c * self.data_len</span><br><span class="line">        rand_index = random.sample(list(range(math.ceil(span_length))), self.batch_size)</span><br><span class="line">        sampled_sents = [self.data[<span class="string">'sents'</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> rand_index]</span><br><span class="line">        sampled_labels = [self.data[<span class="string">'labels'</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> rand_index]</span><br><span class="line">        batch = &#123;<span class="string">'sents'</span>: sampled_sents, <span class="string">'labels'</span>: sampled_labels&#125;</span><br><span class="line">        batch = convert2tensor(batch)</span><br><span class="line">        <span class="keyword">return</span> batch</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡26</title>
    <url>/2019/08/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8726/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Dynamic Curriculum Learning for Imbalanced Data Classification</li>
<li>Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives</li>
<li>CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</li>
</ol>
<h2 id="Dynamic-Curriculum-Learning-for-Imbalanced-Data-Classification"><a href="#Dynamic-Curriculum-Learning-for-Imbalanced-Data-Classification" class="headerlink" title="[Dynamic Curriculum Learning for Imbalanced Data Classification]"></a>[Dynamic Curriculum Learning for Imbalanced Data Classification]</h2><p>æå‡ºCLä¸“æ³¨äºåˆ†ç±»ä¸­çš„ä¸å¹³è¡¡é—®é¢˜ã€‚ä½†å®é™…ä¸Šåº”è¯¥ä¸ç®—æ˜¯CLã€‚</p>
<p>æœ¬è´¨æ˜¯sampling+lossè°ƒæ•´ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šå…ˆè®©æ¨¡å‹å­¦åˆ°ä¸€ä¸ªæ­£ç¡®çš„general representationï¼Œç„¶åå†è®©æ¨¡å‹å­¦ä¼šåˆ†ç±»ã€‚</p>
<h4 id="å››ç§scheduleçš„å˜ä½“"><a href="#å››ç§scheduleçš„å˜ä½“" class="headerlink" title="å››ç§scheduleçš„å˜ä½“"></a>å››ç§scheduleçš„å˜ä½“</h4><p>å…ˆæ˜¯æå‡ºå››ç§scheduleçš„å˜ä½“ï¼Œåœ¨ä¸‹æ–‡ä¸­ä¼šç”¨åˆ°ã€‚</p>
<p><img src="/images/15648828137885.jpg" width="50%" height="50%"></p>
<h4 id="Sampling"><a href="#Sampling" class="headerlink" title="Sampling"></a>Sampling</h4><script type="math/tex; mode=display">\begin{array}{c}{\mathcal{L}_{\mathrm{DSL}}=-\frac{1}{N} \sum_{j=1}^{M} \sum_{i=1}^{N_{j}} w_{j} * \log \left(p\left(y_{i, j}=\overline{y}_{i, j} | \mathbf{x}_{i, j}\right)\right)} \\ {w_{j}=\left\{\begin{array}{ll}{\frac{D_{j}(l)}{B_{j}}} & {\text { if } \frac{D_{j}(l)}{B_{j}} \geq 1} \\ {0 / 1} & {\text { if } \frac{D_{j}(l)}{B_{j}}<1}\end{array}\right.}\end{array}</script><p>å…¶ä¸­ï¼š$D(l)=D_{t r a i n} g(l)$ï¼Œ$g(l)$æ˜¯é€’å‡å‡½æ•°ï¼ˆä¸Šè¿°å››ç§schedule functionï¼‰ã€‚</p>
<p>ä¸Šè¿°å…¬å¼çš„æ„æ€å³å¯¹sampleå¾—åˆ°çš„batchå†…ç±»çš„åˆ†å¸ƒçš„é‡è°ƒæ•´ã€‚å‡å¦‚å½“å‰çš„batchä¸­ç¬¬jä¸ªç±»æœŸæœ›çš„åˆ†å¸ƒæ¯”æ•´ä¸ªè®­ç»ƒåˆ†å¸ƒ${B_{j}}$å¤§ï¼Œåˆ™ç›´æ¥åŠ å¼ºå…¶weightï¼›å¦åˆ™å°±åšsampleï¼Œè¢«sampleåˆ°çš„è®¾ä¸º1ï¼Œæ²¡è¢«sampleåˆ°çš„è®¾ä¸º0ã€‚ä¿è¯batchå†…çš„åˆ†å¸ƒå’ŒæœŸæœ›çš„åˆ†å¸ƒä¸€è‡´ã€‚ä¸€å¼€å§‹æ—¶ï¼ŒæœŸæœ›åˆ†å¸ƒå’Œæ€»ä½“åˆ†å¸ƒä¸€è‡´ï¼Œéšç€è®­ç»ƒè¿‡ç¨‹çš„è¿›è¡Œï¼Œ$g(l)$ä¸‹é™ï¼Œåˆ°æœ€ååˆ™æ˜¯æ‰€æœ‰çš„ç±»çš„æœŸæœ›åˆ†å¸ƒæ˜¯ä¸€è‡´çš„ã€‚</p>
<p>è¿™ç§imbalanceåˆ°balanceçš„motivationæ˜¯ï¼Œå¦‚æœä¸€å¼€å§‹å°±balanceï¼Œä¼šä¸¢å¼ƒæ‰å¤§é‡æ•°æ®çš„æœ‰ç”¨ä¿¡æ¯ï¼Œè¿‡äºå¼ºè°ƒminorityçš„ç‰¹æ€§ï¼Œå®¹æ˜“overfittingã€‚<br>è®ºæ–‡æåˆ°è¿™é‡Œæœ‰CLçš„ç‰¹æ€§ï¼ˆä¹Ÿå³ä»ç®€å•åˆ°éš¾ï¼‰ï¼Œæˆ‘çŒœæµ‹ä½œè€…çš„æ„æ€æ˜¯æ•°é‡å¤šçš„classç›¸å¯¹äºæ•°é‡å°‘çš„classå¹³å‡æ›´ä¸ºç®€å•ï¼Œå› ä¸ºæ›´å®¹æ˜“å­¦ã€‚å¦åˆ™æˆ‘æ²¡çœ‹å‡ºæ¥æœ‰ä»€ä¹ˆCLçš„æ€æƒ³ã€‚</p>
<h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><p>å¯¹lossåŠ äº†ä¸€é¡¹æ­£åˆ™åŒ–metric learning lossï¼Œè¯¥æ–¹æ³•æ˜¯å…¶ä»–è®ºæ–‡çš„æ–¹æ³•ï¼ˆä½†æˆ‘æ²¡çœ‹æ‡‚è¿™ä¸ªå…¬å¼çš„å…·ä½“ä½œç”¨ï¼‰ï¼Œå¤§æ¦‚æ„æ€å°±æ˜¯èƒ½å¤Ÿâ€™avoid the dominant effect of majority classesâ€˜ï¼Œå³å‡å°æ•°é‡å¤§çš„ç±»çš„ä¸»å¯¼å½±å“ã€‚å¹¶ä¸”è®ºæ–‡å¯¹è¯¥lossåšäº†ä¸€å®šæ”¹è¿›ã€‚</p>
<p>ä»ï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{crl}}=\frac{\sum_{T} \max \left(0, m_{j}+d\left(\mathbf{x}_{a l l, j}, \mathbf{x}_{+, j}\right)-d\left(\mathbf{x}_{a l l, j}, \mathbf{x}_{-, j}\right)\right)}{|T|}</script><p>æ”¹ä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{TEA}}=\frac{\sum_{T} \max \left(0, m_{j}+d\left(\mathbf{x}_{e a s y, j}, \mathbf{x}_{+, j}\right)-d\left(\mathbf{x}_{e s y, j}, \mathbf{x}_{-, j}\right)\right)}{|T|}</script><p>è¯¥å…¬å¼çš„ä½œç”¨ï¼štargets at learning a soft feature embedding to separate different samples in feature space without assigning labelsã€‚</p>
<p>å› æ­¤æ€»çš„lossç”±cross entropyä¸triplet lossç»„æˆï¼Œè€Œç»„æˆçš„æ¯”ä¾‹ç”±$f$æ§åˆ¶ã€‚</p>
<script type="math/tex; mode=display">\mathcal{L}_{\mathrm{DCL}}=\mathcal{L}_{\mathrm{DSL}}+f(l) * \mathcal{L}_{\mathrm{TEA}}</script><script type="math/tex; mode=display">f(l)=\left\{\begin{array}{ll}{\frac{1}{2} \cos \left(\frac{l}{L} \pi\right)+\frac{1}{2}+\epsilon} & {\text { if } l<p L} \\ {\epsilon} & {\text { if } l \geq p L}\end{array}\right.</script><p>æœ€åï¼Œè®ºæ–‡è¿˜å°†DCLä½œä¸ºä¸€ç§æ¡†æ¶åšæ³›åŒ–ï¼Œå°†å‡ ä¸ªç®—æ³•éƒ½å®¹çº³è¿›æ¥ï¼šå‡ ç§ç®—æ³•éƒ½æ˜¯ä»–çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µã€‚</p>
<p><img src="/images/15648834974285.jpg" width="60%" height="50%"></p>
<h4 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h4><p>æœ¬æ–‡çš„å‡ºå‘ç‚¹æ˜¯ä¸é”™çš„ï¼Œæ€æƒ³å¾ˆç®€å•æœ‰æ•ˆï¼Œsamplingéƒ¨åˆ†çš„scheduleæˆ‘è§‰å¾—ä¸é”™ï¼Œä¹Ÿå¯èƒ½æ˜¯ä»¥å‰æœ‰å‰äººçš„åŸºç¡€äº†ã€‚ä½†å¦‚æœè¯´æ˜¯CLï¼Œæˆ‘è§‰å¾—å…³ç³»ä¸æ˜¯å¾ˆå¤§ï¼Œè™½ç„¶æœ‰è¾“å…¥æ•°æ®çš„scheduleï¼Œä½†æ²¡æœ‰äº‹å…ˆçš„æŒ‰éš¾åº¦æ’ï¼Œæ„Ÿè§‰æ›´åƒæ˜¯æ˜¯self-paced learningã€‚</p>
<hr>
<h2 id="Simple-and-Effective-Curriculum-Pointer-Generator-Networks-for-Reading-Comprehension-over-Long-Narratives"><a href="#Simple-and-Effective-Curriculum-Pointer-Generator-Networks-for-Reading-Comprehension-over-Long-Narratives" class="headerlink" title="[Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives]"></a>[Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives]</h2><p>æå‡ºä¸€ç§æ–°çš„æ¡†æ¶ç”¨ä»¥é•¿æ–‡æœ¬çš„QAã€‚å…·ä½“æ¨¡å‹æˆ‘å¹¶ä¸å…³å¿ƒï¼Œè¿™é‡Œè®¨è®ºçš„ä¸»è¦æ˜¯CLçš„ç­–ç•¥ã€‚</p>
<p>åœ¨CLæ–¹é¢ï¼Œæå‡ºDiverse curriculum learning schemeï¼Œé€šè¿‡ä¸¤ä¸ªæŒ‡æ ‡æ¥å®šä¹‰difficultyã€‚answerabilityä¸understandability)</p>
<h4 id="æŒ‡æ ‡"><a href="#æŒ‡æ ‡" class="headerlink" title="æŒ‡æ ‡"></a>æŒ‡æ ‡</h4><h5 id="Answerability"><a href="#Answerability" class="headerlink" title="Answerability"></a>Answerability</h5><p>å¯¹äºä¸€ä¸ªsampleæ¥è¯´ï¼ŒåŸºäºquestionæŠ½å–çš„å°±æ˜¯hard settingï¼›åŸºäºanswerçš„åˆ™æ˜¯easy settingã€‚<br>â€œwe consider the set of documents retrieved based on questions as the hard setting, H. Conversely, the set of retrieved documents using answers is regarded as the easy setting, E.â€</p>
<h5 id="Understandability"><a href="#Understandability" class="headerlink" title="Understandability"></a>Understandability</h5><p>ä¾æ®documentçš„é•¿åº¦æ¥åˆ’åˆ†ã€‚é¢„å®šä¹‰å¥½çš„å‡ ä¸ªsizeï¼Œ$\{50,100,200,500\}$ã€‚</p>
<p>æ‰€ä»¥æŒ‰ç…§sizeä»¥åŠanswerabilityå°†sampleåˆ’åˆ†å‡ ä¸ªchunkã€‚</p>
<script type="math/tex; mode=display">\begin{aligned} k & \in\{50,100,200,500\} \\ E_{n} & \leftarrow F(\text { corpus, answer, } n) \\ H_{n} & \leftarrow F(\text { corpus, question }, n) \end{aligned}</script><p>ä¹Ÿå³å°äº50çš„æœ‰easyå’Œhardä¸¤ä¸ªchunkï¼ŒåŒç†å…¶ä»–sizeçš„ä¸€æ ·ã€‚</p>
<h4 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h4><p>åŸåˆ™ï¼šä»å°çš„sizeåˆ°å¤§çš„sizeï¼Œä»easy settingåˆ°hard settingã€‚è®ºæ–‡è®¤ä¸ºAnswerabilityåº”è¯¥ä¼˜å…ˆäºUnderstandabilityè€ƒè™‘ã€‚</p>
<p>å…·ä½“è€Œè¨€ï¼šä»$E_{50}$è¿™ä¸ªchunkå¼€å§‹ï¼Œå½“validæ²¡æœ‰æå‡æ—¶ï¼Œå°†å°ç™¾åˆ†æ¯”Î´ï¼ˆæ¯”å¦‚5%)çš„æ•°æ®ä»éš¾çš„swapåˆ°ç®€å•çš„chunké‡Œï¼ˆ$H_k$åˆ°$E_k$ï¼‰ä»¥æå‡answerabilityï¼Œå½“è¿™ä¹ˆåš1/Î´æ¬¡ä¹‹åï¼Œchunkçš„æ‰€æœ‰æ•°æ®å°±éƒ½æ˜¯hardçš„äº†ï¼Œç„¶åæ­¤æ—¶å°†æ•´ä¸ªchunk swapï¼Œæ¢æˆä¸‹ä¸€ä¸ªsizeçš„$E_k$ã€‚é‡å¤æ­¥éª¤ã€‚</p>
<p><img src="/images/15648849009112.jpg" width="50%" height="50%"></p>
<h4 id="æƒ³æ³•"><a href="#æƒ³æ³•" class="headerlink" title="æƒ³æ³•"></a>æƒ³æ³•</h4><p>é€šè¿‡å®šä¹‰éš¾åº¦çš„<strong>å¤šç»´åº¦</strong>å°†å…¶åˆ†ä¸ºå¤šä¸ªchunkï¼Œå¹¶ä¸”æå‡ºäº†æ¯”è¾ƒç²¾å·§çš„schemeï¼ˆswapçš„æ€è·¯ä¸ä¹‹å‰çš„Curriculum Learning and Minibatch Bucketing in Neural Machine Translationæœ‰äº›ç±»ä¼¼ï¼‰ã€‚<br><strong>diverse+chunkçš„æ€è·¯</strong></p>
<hr>
<h2 id="CurriculumNet-Weakly-Supervised-Learning-from-Large-Scale-Web-Images"><a href="#CurriculumNet-Weakly-Supervised-Learning-from-Large-Scale-Web-Images" class="headerlink" title="[CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images]"></a>[CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images]</h2><p>æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ–¹æ³•èƒ½å¤Ÿåœ¨å¤§é‡å¼±ç›‘ç£çš„ç½‘ç»œå›¾ç‰‡ï¼ˆæ•°æ®æ¥æºï¼šè¾“å…¥queryæ‰€è·å¾—çš„ç½‘ç»œå›¾ç‰‡è€Œä¸æ˜¯äººå·¥æ ‡æ³¨çš„ï¼‰ä¸Šè®­ç»ƒçš„æ–¹æ³•ï¼Œå¼•å…¥äº†CLã€‚å¹¶ä¸”å‘ç°noisy labelçš„æ•°æ®ä¹Ÿèƒ½å¤Ÿæå‡è¡¨ç°ï¼Œå¹¶ä¸”æœ‰regularizationçš„ä½œç”¨ã€‚</p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15648851046110.jpg" width="60%" height="50%"></p>
<p>ä¸‰éƒ¨æ›²ï¼šé¦–å…ˆåœ¨æ•´ä¸ªæ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œèƒ½å¤Ÿå¤§è‡´å­¦å¾—å›¾ç‰‡çš„representationï¼›æ¥ç€é€šè¿‡è¯¥åˆå§‹æ¨¡å‹ï¼Œå°†æ¯å¼ å›¾ç‰‡æ˜ å°„åˆ°ä¸€ä¸ªfeature spaceï¼Œå…¶æ½œåœ¨çš„ç»“æ„å’Œä¹‹é—´çš„å…³ç³»èƒ½å¤Ÿè¢«æŒ–æ˜ï¼Œä¹Ÿå³èƒ½å¤Ÿå°†å›¾ç‰‡æŒ‰ç…§å¤æ‚åº¦æ’åºä¸”åˆ†æˆsubsetï¼›ç¬¬ä¸‰ï¼Œä»ç®€å•åˆ°éš¾è®­ç»ƒï¼Œä¹Ÿå³å…ˆè®­clean labelçš„æ•°æ®ï¼Œç„¶åä¸æ–­æ·»åŠ noisyçš„æ•°æ®ã€‚</p>
<h3 id="initial-feature-generation"><a href="#initial-feature-generation" class="headerlink" title="initial feature generation"></a>initial feature generation</h3><p>åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ªæ¨¡å‹ã€‚</p>
<h3 id="curriculum-design"><a href="#curriculum-design" class="headerlink" title="curriculum design"></a>curriculum design</h3><p>å‡è®¾ï¼šåœ¨æ¯ä¸ªcategoryä¸‹ï¼Œclean labelçš„æ•°æ®å°†ä¼šæœ‰è¾ƒä¸ºæ¥è¿‘çš„è¡¨ç¤ºï¼Œè€Œnoisy labelçš„æ•°æ®åˆ™variance/diversityå¾ˆå¤§ã€‚</p>
<p>åˆ™æˆ‘ä»¬å¯ä»¥é€šè¿‡èšç±»çš„æ–¹æ³•å°†åŒä¸€ä¸ªcategoryä¸‹çš„æ•°æ®åˆ†ä¸ºä¸‰ä¸ªsubsetï¼Œåˆ†åˆ«å¯¹åº”clean; noisy ä¸highly noisyã€‚</p>
<p>å…·ä½“å¦‚ä½•åš/èšç±»ï¼Ÿ</p>
<p>é¦–å…ˆCNNè·å¾—çš„featureè¿›å…¥fcå±‚è·å¾—ä¸€ä¸ªæ·±å±‚çš„feature spaceçš„è¡¨ç¤º</p>
<script type="math/tex; mode=display">P_{i} \rightarrow f\left(P_{i}\right)</script><p>æ¥ç€è®¡ç®—æ¬§æ°è·ç¦»ï¼Œè·å¾—ä¸€ä¸ªä»»æ„iåˆ°jä¹‹é—´çš„è·ç¦»çŸ©é˜µ</p>
<script type="math/tex; mode=display">D_{i j}=\left\|f\left(P_{i}\right)-f\left(P_{j}\right)\right\|^{2}</script><p>æ­¤æ—¶ï¼Œè®¡ç®—æ¯å¼ imageçš„local densityï¼š</p>
<script type="math/tex; mode=display">\begin{array}{c}{\rho_{i}=\sum_{j} X\left(D_{i j}-d_{c}\right)}  {\qquad X(d)=\left\{\begin{array}{ll}{1} & {d<0} \\ {0} & {\text { other }}\end{array}\right.}\end{array}</script><p>ä¹Ÿå³ï¼Œè·ç¦»å°äº$d_c$çš„ç´¯è®¡1ã€‚$d_c$æ˜¯é€šè¿‡æ’åºåå–ç¬¬$k$%å¾—æ¥çš„ã€‚åˆ™$\rho$è¶Šå¤§ä»£è¡¨å…¶ä¸å…¶ä»–imageæ›´æ¥è¿‘ã€‚</p>
<p>æ¥ç€è®¡ç®—ï¼š</p>
<script type="math/tex; mode=display">\delta_{i}=\left\{\begin{array}{ll}{\min _{j : \rho_{j}>\rho_{i}}\left(D_{i j}\right)} & {i f \exists j \text { s.t. } \rho_{j}>\rho_{i}} \\ {\max \left(D_{i j}\right)} & {\text { otherwise }}\end{array}\right.</script><p>ä¹Ÿå³ï¼Œè‹¥å¯¹äºå›¾ç‰‡iï¼Œè‹¥å­˜åœ¨æ¯”ä»–local densityæ›´å¤§çš„ï¼Œå°†ä¸è¯¥æœ€å¤§local densityçš„å›¾ç‰‡çš„è·ç¦»è®¾ä¸ºå›¾ç‰‡içš„è·ç¦»ï¼›å¦åˆ™ï¼Œå°±è¯´æ˜è¯¥å›¾ç‰‡å°±æ˜¯cluster centerã€‚</p>
<p>é‚£ä¹ˆæœ‰äº†ä¸­å¿ƒä¹‹åï¼Œå°±å¯ä»¥èšç±»äº†ï¼Œ$Î´$å¤§çš„è¡¨ç¤ºå…¶å°±æ˜¯ä¸­å¿ƒã€‚å¯ä»¥æ ¹æ®å›¾åƒåˆ°ä¸­å¿ƒçš„è·ç¦»å¤§å°åˆ†ä¸ºä¸‰ç±»ï¼ˆè¿™é‡Œä¸æ¸…æ¥šæ˜¯å¦ç†è§£å¾—å¯¹ï¼‰ã€‚å¯¹äºä¸€ä¸ªç±»è€Œè¨€ï¼Œå¤§densityæ„å‘³ç€åˆ†å¸ƒæ›´å¯†é›†ï¼›è€Œå°densityåˆ™æ›´åŠ åˆ†æ•£ã€‚</p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œclean dataçš„åˆ†å¸ƒä¼šæ›´åŠ å¯†é›†è€Œnoisy dataæ›´åŠ åˆ†æ•£ï¼š</p>
<p><img src="/images/15648859217378.jpg" width="40%" height="50%"></p>
<h3 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><p>å½“åˆ†å¥½ä¸‰ç±»åï¼Œè®­ç»ƒå°±æ˜¯ä¸æ–­å°†noisyæ•°æ®æ”¾å…¥åˆ°cleanæ•°æ®è®­ç»ƒçš„è¿‡ç¨‹ã€‚</p>
<p><img src="/images/15648859490417.jpg" width="50%" height="50%"></p>
<p>æ³¨æ„subsetæ˜¯å°†ä¸åŒcategoryçš„åŒä¸€ç±»ï¼ˆclean/noisy/highly noisy)æ”¾åœ¨ä¸€èµ·ã€‚</p>
<p>å®éªŒè¯æ˜ï¼Œnoisy dataèƒ½å¤Ÿå¢å¼ºæ¨¡å‹çš„æ³›åŒ–æ€§ï¼Œä½¿å¾—æ¨¡å‹ä¸ä¼šoverfittingåˆ°clean dataï¼›åŒæ—¶ç”±äºæ¨¡å‹å·²ç»å…ˆåœ¨clean dataä¸Šè®­ç»ƒå¾—åˆ°ä¸€ä¸ªè¾ƒå¥½çš„æ¨¡å‹äº†ï¼Œå› æ­¤ä¹Ÿä¸ä¼šæ”¶åˆ°noisy dataçš„ä¸å¥½çš„å½±å“ã€‚</p>
<h3 id="æ€è€ƒ-1"><a href="#æ€è€ƒ-1" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>æˆ‘è§‰å¾—è¿™ä¸ªæ€è·¯ä¸é”™ï¼Œåœ¨categoryå†…éƒ¨åˆ’åˆ†subsetï¼Œèƒ½å¤Ÿæ›´å¥½ä¿è¯clean dataèšåœ¨ä¸€èµ·ã€‚èšç±»å€’ä¸æ˜¯å¾ˆé‡è¦ï¼Œå› ä¸ºå¯ä»¥æœ‰ä¸åŒçš„èšç±»æ–¹æ³•ã€‚åŒæ—¶ï¼Œæœ¬ç¯‡è®ºæ–‡è¯æ˜äº†å…ˆè®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿè·å¾—representationè¡¨ç¤ºä¸”è¶³å¤Ÿå¥½åˆ°å¯ä»¥èšç±»æ˜¯å¯è¡Œçš„ã€‚è€ŒCLè®­ç»ƒæ–¹æ³•ä¸Šåˆ™æ²¡æœ‰ä»€ä¹ˆæ–°çš„ä¸œè¥¿ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯åˆ†ä¸ºå‡ ä¸ªshard/bucketï¼Œç„¶åéšç€è®­ç»ƒè¿‡ç¨‹mix dataï¼Œè¿™åœ¨ä¹‹å‰çš„è®ºæ–‡An Empirical Exploration of Curriculum Learning for Neural Machine Translationè¿˜æœ‰å…¶ä»–çš„CLçš„è®ºæ–‡é‡Œé¢éƒ½æœ‰ã€‚</p>
]]></content>
      <tags>
        <tag>Classification</tag>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†25</title>
    <url>/2019/07/28/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8625/</url>
    <content><![CDATA[<h3 id="fairseq-CUDA"><a href="#fairseq-CUDA" class="headerlink" title="[fairseq CUDA]"></a>[fairseq CUDA]</h3><p>å¸¸å¸¸é‡åˆ°fairseqè·‘ç¿»è¯‘ï¼Œè·‘ç€è·‘ç€å°±printå¾ˆå¤štensorï¼Œæ˜¾ç¤ºCUDAé—®é¢˜ã€‚</p>
<p>å°è¯•æ·»åŠ <code>--ddp-backend=no_c10d</code>ä¹‹åï¼Œä¼¼ä¹å°±ä¸ä¼šå‡ºç°è¯¥é—®é¢˜äº†ã€‚ä¹Ÿå³ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m torch.distributed.launch --nproc_per_node <span class="number">4</span> \</span><br><span class="line">train.py --ddp-backend=no_c10d ...</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Overleaf"><a href="#Overleaf" class="headerlink" title="[Overleaf]"></a>[Overleaf]</h3><p>ä¸€èˆ¬overleafå¹¶ä¸ä¼šäº§ç”Ÿä¸­é—´æ–‡ä»¶ï¼Œå‡å¦‚ç¡®å®éœ€è¦bblè€Œä¸æ˜¯bibæ–‡ä»¶ï¼ˆæ¯”å¦‚æäº¤åˆ°arxivæ—¶å°±éœ€è¦bblï¼‰ï¼Œå¯ä»¥ç‚¹å‡»compileæ—è¾¹çš„log and other filesï¼Œç¿»åˆ°æœ€ä¸‹é¢å°±å¯ä»¥é€‰æ‹©ä¸‹è½½bblã€‚</p>
<p><a href="https://tex.stackexchange.com/questions/462314/overleaf-v2-how-to-get-bbl-file" target="_blank" rel="noopener">https://tex.stackexchange.com/questions/462314/overleaf-v2-how-to-get-bbl-file</a></p>
<hr>
<h3 id="Arxiv"><a href="#Arxiv" class="headerlink" title="[Arxiv]"></a>[Arxiv]</h3><p>arxivä¸Šä¼ æ—¶å‡ºç°warningçš„é—®é¢˜ï¼šâ€˜This version (v8.31) of natbib is stricter in its formatting requirements for bibitem entries than the previous version used at arXiv (v7.1)â€™ã€‚</p>
<p>æ£€æŸ¥ä¸€ä¸‹ï¼Œå¯èƒ½æ˜¯bblä¸ä¸»æ–‡ä»¶çš„åå­—ä¸åŒï¼Œæ”¹æˆç›¸åŒçš„å¯èƒ½å°±å¯ä»¥äº†ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>fairseq</tag>
        <tag>CUDA</tag>
        <tag>Arxiv</tag>
        <tag>LaTeX</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡25</title>
    <url>/2019/07/26/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8725/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Easy Samples First: Self-paced Reranking for Zero-Example Multimedia Search</li>
<li>Self-Paced Learning with Diversity</li>
<li>Self-paced dictionary learning for image classification</li>
<li>Self-Paced Learning for Matrix Factorization</li>
<li>Self-Paced Boost Learning for Classification</li>
</ol>
<h2 id="Easy-Samples-First-Self-paced-Reranking-for-Zero-Example-Multimedia-Search"><a href="#Easy-Samples-First-Self-paced-Reranking-for-Zero-Example-Multimedia-Search" class="headerlink" title="[Easy Samples First: Self-paced Reranking for Zero-Example Multimedia Search]"></a>[Easy Samples First: Self-paced Reranking for Zero-Example Multimedia Search]</h2><p>å°†self-paced learningç”¨äºrerankingä»»åŠ¡ä¸­ã€‚å¹¶ä¸”å°†self-paced learningæ›´ä¸€èˆ¬åŒ–ï¼Œä¹Ÿå³å°†åŸå…ˆçš„{0,1} weightæ‰©å±•åˆ°å®æ•°åŸŸã€‚</p>
<p>å…·ä½“è€Œè¨€ï¼ŒåŸå…ˆçš„self-paced learningï¼š</p>
<script type="math/tex; mode=display">\left(\mathbf{w}_{t+1}, \mathbf{v}_{t+1}\right)=\underset{\mathbf{w} \in \mathbb{R}^{d}, \mathbf{v} \in\{0,1\}^{n}}{\operatorname{argmin}}\left(r(\mathbf{w})+\sum_{i=1}^{n} v_{i} f\left(\mathbf{x}_{i}, \mathbf{y}_{i} ; \mathbf{w}\right)-\frac{1}{K} \sum_{i=1}^{n} v_{i}\right)</script><p>å…¶ä¸­ $v\in\{0,1 \}$ã€‚åé¡¹çš„æ­£åˆ™é¡¹ä¸º $f(\mathbf{v} ; k)=-\frac{1}{k}|\mathbf{v}|_{1}=-\frac{1}{k} \sum_{i=1}^{n} v_{i}$</p>
<p>å¾—å‡ºçš„è§£ä¸ºï¼š</p>
<script type="math/tex; mode=display">v_{i}^{*}=\left\{\begin{array}{ll}{1} & {\frac{1}{m} \sum_{j=1}^{m} C \ell_{i j}<\frac{1}{k}} \\ {0} & {\frac{1}{m} \sum_{j=1}^{m} C \ell_{i j} \geq \frac{1}{k}}\end{array}\right.</script><p>è€Œç°åœ¨ï¼š<br>â‘ çº¿æ€§ï¼Œä¹Ÿå³ä¸lossæ˜¯çº¿æ€§ç›¸å…³çš„ï¼š</p>
<script type="math/tex; mode=display">f(\mathbf{v} ; k)=\frac{1}{k}\left(\frac{1}{2}\|\mathbf{v}\|_{2}^{2}-\sum_{i=1}^{n} v_{i}\right)</script><p>å¾—å‡ºçš„è§£ä¸ºï¼š</p>
<script type="math/tex; mode=display">v_{i}^{*}=\left\{\begin{array}{ll}{-k\left(\frac{1}{m} \sum_{j=1}^{m} C \ell_{i j}\right)+1} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j}<\frac{1}{k}} \\ {0} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j} \geq \frac{1}{k}}\end{array}\right.</script><p>â‘¡logå…³ç³»</p>
<script type="math/tex; mode=display">f(\mathbf{v} ; k)=\sum_{i=1}^{n}\left(\zeta v_{i}-\frac{\zeta^{v_{i}}}{\log \zeta}\right)</script><p>è§£ä¸ºï¼š</p>
<script type="math/tex; mode=display">v_{i}^{*}=\left\{\begin{array}{ll}{\frac{1}{\log \zeta} \log \left(\frac{1}{m} \sum_{j=1}^{m} C \ell_{i j}+\zeta\right)} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j}<\frac{1}{k}} \\ {0} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j} \geq \frac{1}{k}}\end{array}\right.</script><p>â‘¢softä¸hardçš„æ··åˆ</p>
<script type="math/tex; mode=display">f\left(\mathbf{v} ; k, k^{\prime}\right)=-\zeta \sum_{i=1}^{n} \log \left(v_{i}+\zeta k\right)</script><p>è§£ä¸ºï¼š</p>
<script type="math/tex; mode=display">v_{i}^{*}=\left\{\begin{array}{ll}{1} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j} \leq \frac{1}{k^{\prime}}} \\ {0} & {\frac{1}{m} \sum_{i=1}^{m} C \ell_{i j} \geq \frac{1}{k}} \\ {\frac{m \zeta}{\sum_{i=1}^{m} C \ell_{i j}}-k \zeta} & {\text { otherwise }}\end{array}\right.</script><p>ä¹Ÿå³ï¼Œlosså¤ªå°ç½®ä¸º1ï¼Œå¤ªå¤§ç½®ä¸º0.ä¸­é—´åˆ™æ˜¯å®æ•°åŸŸã€‚</p>
<p><img src="/images/15642823398246.jpg" width="60%" height="50%"></p>
<hr>
<h2 id="Self-Paced-Learning-with-Diversity"><a href="#Self-Paced-Learning-with-Diversity" class="headerlink" title="[Self-Paced Learning with Diversity]"></a>[Self-Paced Learning with Diversity]</h2><p>æå‡ºåœ¨self-paced learningä¸­ï¼Œä¸ä»…ä»…è¦é€‰æ‹©ç®€å•çš„ï¼Œè¿˜è¦å¢åŠ diversityè¿™ä¸€æŒ‡æ ‡ï¼Œä½¿å¾—æ¨¡å‹ä¸ä¼šoverfittingåˆ°æŸä¸ªpatternä¸Šï¼ŒåŒæ—¶diverse sampleèƒ½å¤Ÿå¸®åŠ©æ¨¡å‹å­¦åˆ°æ›´ä¸ºcomprehensiveçš„çŸ¥è¯†ã€‚</p>
<p><img src="/images/15642828676000.jpg" width="80%" height="50%"></p>
<p>ç”±äºself-paced learningæ²¡æœ‰å…ˆéªŒçŸ¥è¯†ï¼Œä¸€å¼€å§‹æ¥æ”¶åˆ°çš„æŸé¢†åŸŸçš„sampleï¼Œä¹‹åä¼šå€¾å‘äºä¸€ç›´é€‰æ‹©è¯¥é¢†åŸŸçš„sampleï¼Œå› ä¸ºä¹‹å‰è·å–åˆ°è¯¥é¢†åŸŸçš„sampleï¼Œä½¿å¾—è¯¥é¢†åŸŸçš„sampleçš„lossç›¸è¾ƒå…¶ä»–é¢†åŸŸçš„lossæ›´ä½ã€‚è¿™æ ·å°±å®¹æ˜“overfitåˆ°æŸä¸ªç‰¹å®šçš„patternã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œéœ€è¦æ˜¾å¼å°†diversityä½œä¸ºobjectiveã€‚</p>
<p>åŸºäºè¿™ä¸€æ€æƒ³ï¼Œæœ‰ï¼š<br>å‡è®¾è®­ç»ƒæ•°æ®$\mathbf{X}=\left(\mathbf{x}_{1}, \cdots, \mathbf{x}_{n}\right) \in \mathbb{R}^{m \times n}$ï¼Œåˆ†æˆbä¸ªgroup $\mathbf{X}^{(1)}, \cdots, \mathbf{X}^{(b)}$ã€‚weight vectorä¸º$\mathbf{v}=\left[\mathbf{v}^{(1)}, \cdots, \mathbf{v}^{(b)}\right]$ï¼Œå…¶ä¸­$\mathbf{v}^{(j)}=\left(v_{1}^{(j)}, \cdots, v_{n_{j}}^{(j)}\right)^{T} \in[0,1]^{n_{j}}$</p>
<p>å› æ­¤objective functionä¸ºï¼š</p>
<script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda, \gamma)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, f\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)-\lambda \sum_{i=1}^{n} v_{i}-\gamma\|\mathbf{v}\|_{2,1}, \text { s.t. } \mathbf{v} \in[0,1]^{n}</script><p>å…¶ä¸­æ–°çš„regularizationä¸º$-|\mathbf{v}|_{2,1}=-\sum_{j=1}^{b}\left|\mathbf{v}^{(j)}\right|_{2}$ï¼Œè¯¥regularizationèƒ½å¤Ÿä½¿æ¨¡å‹å°½é‡å»é€‰æ‹©ä¸åŒgroupçš„sampleã€‚</p>
<p>å½“æ¯ä¸ªgroupåªæœ‰ä¸€ä¸ªsampleæ—¶ï¼Œå…¬å¼é€€åŒ–ä¸ºï¼š</p>
<script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, f\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)-\lambda \sum_{i=1}^{n} v_{i}, \text { s.t. } \mathbf{v} \in[0,1]^{n}</script><p>å› æ­¤æœ€ç»ˆçš„ç®—æ³•ï¼š</p>
<p><img src="/images/15642831390970.jpg" width="90%" height="50%"></p>
<p><img src="/images/15642831523214.jpg" width="90%" height="50%"></p>
<p>æ€è€ƒï¼šä»diversityçš„è§’åº¦ç¡®å®å¾ˆæœ‰é“ç†ï¼Œå¦‚æœä¸æ˜¯è¿™ç¯‡æ–‡ç« æˆ‘æƒ³ä¸åˆ°diversityã€‚ä½œè€…å¯¹é—®é¢˜çš„è®¤è¯†å¾ˆåˆ°ä½ã€‚</p>
<hr>
<h2 id="Self-paced-dictionary-learning-for-image-classification"><a href="#Self-paced-dictionary-learning-for-image-classification" class="headerlink" title="[Self-paced dictionary learning for image classification]"></a>[Self-paced dictionary learning for image classification]</h2><p>å°†self-paced learningç”¨äºdictionary learningï¼ˆå¯¹è¯¥é¢†åŸŸä¸äº†è§£ï¼‰ã€‚</p>
<p><img src="/images/15642834501198.jpg" width="60%" height="50%"></p>
<p>å¦ä¸€è´¡çŒ®æ˜¯æå‡ºæ–°çš„é˜ˆå€¼æ›´æ–°å…¬å¼ï¼š</p>
<script type="math/tex; mode=display">\sigma=f(\pi, t)=\pi+\log \left(\pi^{2}+c\right) t \quad(c \geq 1)</script><p>ä¿è¯ç¬¬ä¸€è½®æœ‰è¶…è¿‡ä¸€åŠçš„exampleè®¤å®šä¸ºeasyã€‚</p>
<hr>
<h2 id="Self-Paced-Learning-for-Matrix-Factorization"><a href="#Self-Paced-Learning-for-Matrix-Factorization" class="headerlink" title="[Self-Paced Learning for Matrix Factorization]"></a>[Self-Paced Learning for Matrix Factorization]</h2><p>å°†self-paced learningç”¨äºçŸ©é˜µåˆ†è§£ï¼ŒåŒæ—¶å°†hard weightæ”¹æˆsoft weightã€‚</p>
<p><img src="/images/15642835464066.jpg" width="60%" height="50%"></p>
<p><img src="/images/15642836554962.jpg" width="65%" height="50%"></p>
<hr>
<h2 id="Self-Paced-Boost-Learning-for-Classification"><a href="#Self-Paced-Boost-Learning-for-Classification" class="headerlink" title="[Self-Paced Boost Learning for Classification]"></a>[Self-Paced Boost Learning for Classification]</h2><p>æå‡ºå°†boostå’Œself-pacedçš„æ€æƒ³ç»“åˆåœ¨ä¸€èµ·çš„ç®—æ³•ã€‚</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæœ‰ä¸¤ä¸ªé‡è¦çš„åŸåˆ™ï¼šeffectivenesså’Œrobustnessã€‚effectivenessä¸“æ³¨äºè®©æ¨¡å‹åˆ†å¯¹ï¼Œæé«˜accuracyï¼›è€Œrobustnessåˆ™æ˜¯å‡å°‘noiseæˆ–è€…confusing exampleçš„å½±å“ã€‚<br>boostingç®—æ³•åˆ™ä¸“æ³¨äºeffectivenessï¼Œå› ä¸ºæ¸è¿›åœ°ä¸“æ³¨äºåˆ†é”™çš„exampleã€‚ä½†è¿™æ ·å°±å®¹æ˜“ä½¿å¾—æ¨¡å‹ç¼ºå°‘é²æ£’æ€§/æ³›åŒ–æ€§ã€‚<br>self-paced learningåˆ™æ˜¯ä»ç®€å•åˆ°éš¾ï¼Œè¿™æ ·å¯ä»¥é€šè¿‡ç¨³æ­¥æé«˜æ¨¡å‹èƒ½åŠ›ä¹‹åå‡å°‘confusing/noise exampleå¯¹æ¨¡å‹çš„å½±å“ï¼Œä¹Ÿå³ä¸€å¼€å§‹å°±èƒ½å¤Ÿå­¦ä¹ ç®€å•çš„patternï¼Œè€Œä¸ä¼šå—åˆ°confusing/noise exampleæ‰€æœ‰çš„å¤æ‚patternçš„å½±å“ã€‚</p>
<p>boostingä¸self-pacedæœ‰å…±é€šä¹‹å¤„ä»¥åŠäº’è¡¥ä¹‹å¤„ï¼š<br>äºŒè€…éƒ½æ˜¯ä¸€ä¸ªæ¸è¿›çš„è¿‡ç¨‹ï¼Œä»weak stateåˆ°strong stateã€‚<br>boostingæ›´è€ƒè™‘effectivenessï¼Œè€ŒSPLåˆ™æ›´è€ƒè™‘robustnessï¼›boostingå¯¹ä¸å……åˆ†å­¦ä¹ çš„æ ·æœ¬æ–½åŠ è´Ÿé¢æŠ‘åˆ¶ï¼ˆä¸å¤§æ‡‚æ„æ€ï¼Œåº”è¯¥æ˜¯è¯´ç®—æ³•å¼ºè°ƒä¸å……åˆ†å­¦ä¹ çš„æ ·æœ¬ï¼‰ï¼Œè€ŒSPLæ­£é¢é¼“åŠ±ç®€å•æ˜“å­¦çš„æ ·æœ¬ã€‚boostingæ›´ä¸“æ³¨äºclassä¹‹é—´çš„marginï¼Œå°è¯•å»æ‹Ÿåˆeach sampleï¼Œé€šè¿‡åŠ¨æ€é€‰æ‹©å…·æœ‰ä¸åŒæ¨¡å¼çš„ç®€å•æ ·æœ¬ï¼›SPLæ›´å…³æ³¨ç±»å†…å˜åŒ–ã€‚<br>å› æ­¤ï¼Œboostingå€¾å‘äºåæ˜ localçš„patternï¼Œæ›´åŠ å¯¹noiseæ•æ„Ÿï¼Œè€ŒSPLåˆ™æ›´åŠ å¹³æ»‘ï¼Œå…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚</p>
<p>å°†äºŒè€…ç»“åˆèµ·æ¥ï¼špositive encouragement (on reliable samples) and negative suppression (on misclassified samples)</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>é—®é¢˜å®šä¹‰ï¼šè®­ç»ƒæ•°æ®$\left\{\left(x_{i}, y_{i}\right)\right\}_{i=1}^{n}$ï¼Œå…¶ä¸­$x_{i} \in \mathbb{R}^{d}$ï¼Œ$y_{i} \in\{1,2, \ldots, C\}$ã€‚</p>
<p>è¦å­¦ä¹ ä¸€ä¸ªæ˜ å°„$\tilde{y}(x)=\underset{r \in\{1, \ldots, C\}}{\operatorname{argmax}} F_{r}(x ; \Theta)$ã€‚è€Œå¤šåˆ†ç±»çš„ç›®æ ‡/loss functionä¸ºï¼š</p>
<script type="math/tex; mode=display">\begin{array}{c}{\min _{\Theta} \sum_{i=1}^{n} \sum_{r=1}^{C} L\left(\rho_{i r}\right)+\nu R(\Theta)} \\ {\text {s.t.} \forall i, r, \rho_{i r}=F_{y_{i}}(x ; \Theta)-F_{r}(x ; \Theta)}\end{array}</script><p><strong>$F$å†³å®šeffectivenessï¼›è€Œ$L$å†³å®šrobustness</strong>ã€‚</p>
<p>åœ¨boostingä¸­ï¼š</p>
<script type="math/tex; mode=display">F_{r}(x ; W)=\sum_{j=1}^{k} w_{r j} h_{j}(x), r=1, \ldots, C</script><p>å…¶ä¸­$\left\{h_{j}(\cdot) \in \mathcal{H}\right\}_{j=1}^{k}$ï¼Œ$h_{j}(\cdot) : \mathbb{R}^{d} \rightarrow\{0,1\}$æ˜¯weak classifierã€‚$W$æ˜¯åˆ†é…ç»™æ¯ä¸ªclassifierçš„æƒé‡ã€‚</p>
<p>åœ¨boostingä¸­åŠ å…¥SPLçš„æ€æƒ³ï¼Œä¹Ÿå³å¼•å¯¼æ¨¡å‹å…ˆå­¦ç®€å•çš„å†å­¦éš¾çš„ï¼š</p>
<script type="math/tex; mode=display">\begin{array}{c}{\min _{W, v} \sum_{i=1}^{n} v_{i} \sum_{r=1}^{C} L\left(\rho_{i r}\right)+\sum_{i=1}^{n} g\left(v_{i} ; \lambda\right)+\nu R(W)} \\ {\text {s.t.} \forall i, r, \rho_{i r}=H_{i :} w_{y_{i}}-H_{i :} w_{r} ; W \geqslant 0 ; v \in[0,1]^{n}}\end{array}</script><p>å…¶ä¸­$\left[H_{i j}\right]=\left[h_{j}\left(x_{i}\right)\right]$ï¼Œ$W=\left[w_{1}, \cdots, w_{C}\right] \in \mathbb{R}^{k \times C}$</p>
<p>å°†$L$å…·ä½“åŒ–ä¸ºlogisticså‡½æ•°ï¼Œ$R(W)$æ˜¯$l_{2,1} \text{-norm}$ã€‚åˆ™ï¼š</p>
<script type="math/tex; mode=display">\begin{array}{l}{\min _{W, v} \sum_{i, r} v_{i} \ln \left(1+e^{-\rho_{i r}}\right)+\sum_{i} g\left(v_{i} ; \lambda\right)+\nu\|W\|_{2,1}} \\ {\text {s.t.} \forall i, r, \rho_{i r}=H_{i :} w_{y_{i}}-H_{i :} w_{r} ; W \geqslant 0 ; v \in[0,1]^{n}}\end{array}</script><p>é‡‡ç”¨column generation methodæ¥è§£å†³ä¸Šè¿°å…¬å¼ï¼ˆè¿™æ®µçœ‹ä¸æ‡‚å’‹ç®—å‡ºæ¥çš„ï¼‰ï¼š</p>
<p><img src="/images/15642848899908.jpg" width="60%" height="50%"></p>
<p><img src="/images/15642849290180.jpg" width="57%" height="50%"></p>
<blockquote>
<p>the future weak learners will put emphasis on samples that are both insufï¬ciently learned currently and easily learned previously</p>
</blockquote>
<p>ä¹Ÿå³æ˜¯boostingä¸SPLçš„ç»“åˆã€‚</p>
<h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>boostingç”±äºåªèƒ½é€šè¿‡åˆ†å¯¹åˆ†é”™æ¥ç»™æƒé‡è€Œä¸æ˜¯æ ¹æ®lossï¼Œæ˜¯ç²—ç²’åº¦çš„ï¼Œå¼ºè°ƒè¦è§£å†³éš¾çš„ï¼›è€ŒSPLåˆ™æ˜¯å¼ºè°ƒå…ˆå­¦ç®€å•çš„ï¼Œå†è§£å†³éš¾çš„ä¸è¿Ÿã€‚äºŒè€…å·§å¦™äº’è¡¥ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>SPL</tag>
        <tag>Self-paced Learning</tag>
        <tag>Boosting</tag>
        <tag>Boost</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯31</title>
    <url>/2019/07/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D31/</url>
    <content><![CDATA[<h3 id="æ»å·è¥¿æ¶§"><a href="#æ»å·è¥¿æ¶§" class="headerlink" title="æ»å·è¥¿æ¶§"></a>æ»å·è¥¿æ¶§</h3><p>[å”] éŸ¦åº”ç‰©<br>ç‹¬æ€œå¹½è‰æ¶§è¾¹ç”Ÿï¼Œä¸Šæœ‰é»„é¹‚æ·±æ ‘é¸£ã€‚<br>æ˜¥æ½®å¸¦é›¨æ™šæ¥æ€¥ï¼Œé‡æ¸¡æ— äººèˆŸè‡ªæ¨ªã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä½³å¥åˆ†äº«3</title>
    <url>/2019/07/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB3/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>ä¸–ç•Œä¸Šåªæœ‰ä¸€ç§çœŸæ­£çš„è‹±é›„ä¸»ä¹‰ï¼Œå°±æ˜¯è®¤æ¸…äº†ç”Ÿæ´»çš„çœŸç›¸åè¿˜ä¾ç„¶çƒ­çˆ±å®ƒã€‚</p>
<h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>å® è¾±ä¸æƒŠï¼Œé—²çœ‹åº­å‰èŠ±å¼€èŠ±è½ï¼›å»ç•™æ— æ„ï¼Œæ¼«éšå¤©å¤–äº‘å·äº‘èˆ’ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä½³å¥åˆ†äº«2</title>
    <url>/2019/07/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB2/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>Learn to be ordinary before you wish to be extraordinary.</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡24</title>
    <url>/2019/07/07/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8724/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Curriculum Learning for Multi-Task Classification of Visual Attributes</li>
<li>Highway Networks</li>
<li>Deep Residual Learning for Image Recognition</li>
<li>Gated Feedback Recurrent Neural Networks</li>
<li>Densely Connected Convolutional Networks</li>
</ol>
<h2 id="Curriculum-Learning-for-Multi-Task-Classiï¬cation-of-Visual-Attributes"><a href="#Curriculum-Learning-for-Multi-Task-Classiï¬cation-of-Visual-Attributes" class="headerlink" title="[Curriculum Learning for Multi-Task Classiï¬cation of Visual Attributes]"></a>[Curriculum Learning for Multi-Task Classiï¬cation of Visual Attributes]</h2><p>å¤§è‡´æ€è·¯æ˜¯ï¼šå°†æ•°æ®åˆ†ä¸ºä¸¤ä¸ªtaskï¼Œå…ˆè®­ç»ƒå¼ºç›¸å…³çš„taskï¼Œç„¶åå†è®­ç»ƒå¼±ç›¸å…³çš„taskã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºvisual attributeï¼Œå…ˆè®­ç»ƒå¼ºç›¸å…³labelï¼Œç„¶åå†è®­ç»ƒå¼±ç›¸å…³çš„labelã€‚<br><img src="/images/15624682482609.jpg" width="60%" height="50%"></p>
<p>å…·ä½“å½¢å¼ï¼š</p>
<p><img src="/images/15624684432867.jpg" width="80%" height="50%"></p>
<p>å¦‚ä½•è®¡ç®—ç›¸å…³æ€§ï¼š</p>
<script type="math/tex; mode=display">p_{i}=\sum_{j=1, j \neq i}^{T} \frac{\operatorname{cov}\left(y_{t_{i}}, y_{t_{j}}\right)}{\sigma\left(y_{t_{i}}\right) \sigma\left(y_{t_{j}}\right)}, i=1, \ldots, T</script><p>top 50%æ˜¯å¼ºç›¸å…³çš„ï¼Œå‰©ä¸‹éƒ½æ˜¯å¼±ç›¸å…³çš„ã€‚</p>
<p>æˆ‘çš„ç†è§£æ˜¯ï¼Œä¼¼ä¹æ˜¯å°†labelç»™åˆ‡åˆ†äº†ï¼š</p>
<p><img src="/images/15624684979775.jpg" width="60%" height="50%"></p>
<hr>
<h2 id="Highway-Networks"><a href="#Highway-Networks" class="headerlink" title="[Highway Networks]"></a>[Highway Networks]</h2><p>åŸå…ˆçš„æ™®é€šlayerï¼š</p>
<script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right)</script><p>ä¸ºäº†èƒ½å¤Ÿè®­ç»ƒå¾ˆæ·±çš„ç½‘ç»œï¼Œæ”¹æˆï¼š</p>
<script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right) \cdot T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)+\mathbf{x} \cdot C\left(\mathbf{x}, \mathbf{W}_{\mathbf{C}}\right)</script><p>ä¹Ÿå³å¢åŠ ä¸¤ä¸ªä»¿å°„å˜æ¢ã€‚å…¶ä¸­Tæ˜¯transformer gateï¼Œè€ŒCæ˜¯carry gateã€‚è¿™æ ·èƒ½å¤Ÿæœ‰åŠ©äºæ¨¡å‹çš„ä¼˜åŒ–ã€‚</p>
<p>ç®€å•èµ·è§ï¼š</p>
<script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right) \cdot T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)+\mathbf{x} \cdot\left(1-T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)\right)</script><p>åœ¨Tä¸­ï¼Œå¯ä»¥è®¾biasä¸ºè´Ÿï¼Œä¹Ÿå³ä¸€å¼€å§‹åå‘carryçš„è¡Œä¸ºã€‚</p>
<hr>
<h2 id="Deep-Residual-Learning-for-Image-Recognition"><a href="#Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="[Deep Residual Learning for Image Recognition]"></a>[Deep Residual Learning for Image Recognition]</h2><p><img src="/images/15624688998473.jpg" width="50%" height="50%"></p>
<p>æœ¬è´¨æ˜¯æ®‹å·®æ¯”ç›´æ¥å­¦ä¹ xçš„å˜æ¢æ›´å®¹æ˜“ã€‚å¯¹æ¨¡å‹çš„ä¼˜åŒ–æ›´å®¹æ˜“ã€‚</p>
<blockquote>
<p>if an identity mapping were optimal, it would be easier to push the residual to zero than to ï¬t an identity mapping by a stack of nonlinear layers</p>
</blockquote>
<p>å¯å¦ç†è§£highway networkæ˜¯ResNetçš„è¿›é˜¶ç‰ˆï¼Ÿ</p>
<hr>
<h2 id="Gated-Feedback-Recurrent-Neural-Networks"><a href="#Gated-Feedback-Recurrent-Neural-Networks" class="headerlink" title="[Gated Feedback Recurrent Neural Networks]"></a>[Gated Feedback Recurrent Neural Networks]</h2><p><img src="/images/15624692408778.jpg" width="80%" height="50%"></p>
<p>å¯¹äºå¤šå±‚çš„RNNï¼Œç¬¬lå±‚çš„time stepä¸ºtçš„hï¼Œå¯ä»¥æ¥æ”¶ä¸Šä¸€ä¸ªtime stepçš„å¤§äºlå±‚çš„ä¹Ÿæ¥æ”¶å°äºlå±‚çš„hidden stateã€‚</p>
<hr>
<h2 id="Densely-Connected-Convolutional-Networks"><a href="#Densely-Connected-Convolutional-Networks" class="headerlink" title="[Densely Connected Convolutional Networks]"></a>[Densely Connected Convolutional Networks]</h2><p>åœ¨ä¸€ä¸ªblockå†…ï¼Œæ¯å±‚éƒ½è¿æ¥åˆ°åé¢çš„å±‚ã€‚</p>
<p><img src="/images/15624693085589.jpg" width="70%" height="50%"></p>
<p>æ³¨æ„åˆ°ï¼Œåœ¨è¿æ¥å½¢å¼ä¸Šï¼Œresnetæ˜¯ç›¸åŠ ï¼š</p>
<script type="math/tex; mode=display">\mathbf{x}_{\ell}=H_{\ell}\left(\mathbf{x}_{\ell-1}\right)+\mathbf{x}_{\ell-1}</script><p>è€ŒDenseNetåˆ™æ˜¯concatï¼š</p>
<script type="math/tex; mode=display">\mathbf{x}_{\ell}=H_{\ell}\left(\left[\mathbf{x}_{0}, \mathbf{x}_{1}, \dots, \mathbf{x}_{\ell-1}\right]\right)</script><p>è¿™é‡Œçš„Hæ˜¯Bn-Relu-Convã€‚</p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>Paper</tag>
        <tag>RNN</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>ResNet</tag>
        <tag>Highway</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­infå¯¼æ•°çš„nané—®é¢˜</title>
    <url>/2019/07/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPyTorch%E4%B8%ADinf%E5%AF%BC%E6%95%B0%E7%9A%84nan%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>æƒ³è¦å®ç°ä¸€ä¸ªåŠŸèƒ½ã€‚å°†Transformerä¸­å¤šå±‚çš„attentionçŸ©é˜µåŠ æƒå¹³å‡ã€‚ä¹Ÿå³ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pre_attn shape: batch_size*n_head,6,target_len,source_len</span></span><br><span class="line">self.attn_alpha = Parameter(torch.zeros(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">normalized_alpha = F.softmax(self.attn_alpha, dim=<span class="number">-1</span>)  <span class="comment"># 1,6</span></span><br><span class="line">normalized_alpha = normalized_alpha.reshape(<span class="number">1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 1,6,1,1</span></span><br><span class="line"></span><br><span class="line">weighted_attn = prev_attn * normalized_alpha</span><br><span class="line">weighted_attn = weighted_attn.sum(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>è·å¾—çš„<code>weighted_attn</code>å°±æ˜¯æ‰€æœ‰å±‚çš„attentionçŸ©é˜µçš„åŠ æƒå¹³å‡ã€‚å†å°†<code>weighted_attn</code>ç”¨äºåé¢çš„è®¡ç®—ã€‚å…¶ä¸­<code>attn_alpha</code>æ˜¯å¯å­¦ä¹ çš„å‚æ•°ã€‚</p>
<p>åŠŸèƒ½å¾ˆç®€å•ï¼Œä½†åœ¨backwardå®Œåï¼Œ<code>attn_alpha</code>å°±ä¼šä¸€ä¸‹å­è·³åˆ°nanã€‚æŒ‰ç†è¯´ï¼Œè™½ç„¶attnçŸ©é˜µé‡Œé¢å­˜åœ¨-infï¼Œä½†åªè¦æ˜¯åŒä¸€ä¸ªbatchï¼Œinfå­˜åœ¨çš„ç´¢å¼•ä½ç½®åº”è¯¥éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå³ä½¿åŠ æƒæ±‚å’Œä¹Ÿä¸ä¼šå¯¼è‡´æŸä¸€è¡Œå…¨ä¸º-infï¼Œä½¿å¾—åœ¨softmaxåå­˜åœ¨nançš„æƒ…å†µã€‚</p>
<p>åœ¨èˆªæ€»æ’æŸ¥äº†ä¸€æ™šä¸Šåï¼Œä¹Ÿå°è¯•äº†å„ç§å‡è®¾ï¼Œæœ€ç»ˆå‘ç°ï¼Œæ˜¯å› ä¸ºæ¢¯åº¦å›ä¼ æ—¶çš„é—®é¢˜ã€‚ä¹Ÿå³å½“<code>weighted_attn = prev_attn * normalized_alpha</code>è¿™å¥ä»£ç æ¢¯åº¦å›ä¼ çš„æ—¶å€™ï¼Œç”±äºå­˜åœ¨â€™-infâ€™çš„å€¼ï¼Œalphaçš„æ¢¯åº¦å°±ä¼šæœ‰nanï¼ˆå› ä¸ºä¸Šå¥ä»£ç ä¸­alphaçš„å¯¼æ•°æ˜¯<code>prev_attn</code>ï¼Œå½“<code>prev_attn</code>å­˜åœ¨infæ—¶ï¼Œåˆ™gradåˆ™ä¸ºnanã€‚</p>
<p>è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œé¦–å…ˆè·å¾—attentionçŸ©é˜µçš„maskï¼Œæ¥ç€ä½¿ç”¨masked_fillå°†infçš„éƒ¨åˆ†ç½®ä¸º0ï¼Œå†å’Œalphaç›¸ä¹˜ï¼Œæ­¤æ—¶å°±ä¸ä¼šæœ‰nançš„æƒ…å†µå‡ºç°äº†ã€‚ä¹Ÿå³ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pre_attn shape: batch_size*n_head,6,target_len,source_len</span></span><br><span class="line">self.attn_alpha = Parameter(torch.zeros(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">normalized_alpha = F.softmax(self.attn_alpha, dim=<span class="number">-1</span>)  <span class="comment"># 1,6</span></span><br><span class="line">normalized_alpha = normalized_alpha.reshape(<span class="number">1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 1,6,1,1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----å¤šåŠ è¿™å‡ è¡Œ --- #</span></span><br><span class="line">_attn_mask = prev_attn == float(<span class="string">'-inf'</span>)  <span class="comment"># -infçš„ä½ç½®ä¸º1</span></span><br><span class="line">new_pre_attn = pre_attn.data.masked_fill(_attn_mask,<span class="number">0</span>) <span class="comment"># å°†-infå¡«å……ä¸º0</span></span><br><span class="line"><span class="comment"># --------------- # </span></span><br><span class="line"></span><br><span class="line">weighted_attn = new_pre_attn * normalized_alpha</span><br><span class="line">weighted_attn = weighted_attn.sum(dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>æ€»ç»“èµ·æ¥ï¼Œåˆ™æ˜¯ï¼Œå½“tensorå­˜åœ¨infæ—¶ï¼Œä¸å®ƒç›¸ä¹˜çš„tensorå¦‚æœæ˜¯å¯æ›´æ–°çš„ï¼Œåˆ™è¯¥tensorçš„gradä¸ºnanã€‚æ‰€ä»¥åœ¨å¤„ç†æœ‰infçš„tensorè¦ç‰¹åˆ«æ³¨æ„ï¼Œå¯èƒ½å‡ºç°ç›¸ä¹˜åæ¢¯åº¦å›ä¼ gradä¸ºnançš„æƒ…å†µï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µåˆ™æ˜¯è‹¥æŸä¸€è¡Œå…¨ä¸ºinfï¼Œè¿‡softmaxååˆ™ä¹Ÿä¼šå‡ºç°nanã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>nan</tag>
        <tag>inf</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†24</title>
    <url>/2019/06/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8624/</url>
    <content><![CDATA[<h3 id="Homebrew"><a href="#Homebrew" class="headerlink" title="[Homebrew]"></a>[Homebrew]</h3><p>Homebrewå®‰è£…é‡åˆ° Permission denied @ dir_s_mkdir</p>
<p>No need to chown the whole /usr/local if brew only fails to create a single directory.<br>For example, I fixed this error:<br>Permission denied @ dir_s_mkdir - /usr/local/Frameworks<br>With this command:<br>sudo install -d -o $(whoami) -g admin /usr/local/Frameworks</p>
<p><a href="https://gist.github.com/irazasyed/7732946" target="_blank" rel="noopener">https://gist.github.com/irazasyed/7732946</a></p>
<hr>
<h3 id="Alfred"><a href="#Alfred" class="headerlink" title="[Alfred]"></a>[Alfred]</h3><p>mac ä¸Š QQ ä¼šé˜»æ­¢ Alfred é”å±åŠŸèƒ½ï¼Œè¿™æ˜¯å› ä¸ºå¿«æ·é”®å†²çªï¼Œå–æ¶ˆæŸ¥çœ‹è”ç³»äººçš„å¿«æ·é”®å³å¯ã€‚</p>
<p><img src="/images/15618638268867.jpg" width="60%" height="50%"></p>
<p><a href="https://www.v2ex.com/t/477934" target="_blank" rel="noopener">https://www.v2ex.com/t/477934</a></p>
<hr>
<h3 id="Autodiff"><a href="#Autodiff" class="headerlink" title="[Autodiff]"></a>[Autodiff]</h3><p>Autodiffæœ‰ä¸¤ç§æ¨¡å¼ï¼Œforwardå’Œreverseã€‚å½“å‰çš„æ·±åº¦å­¦ä¹ æ¡†æ¶éƒ½ç”¨çš„reverseã€‚</p>
<p><a href="https://blog.csdn.net/aws3217150/article/details/70214422" target="_blank" rel="noopener">https://blog.csdn.net/aws3217150/article/details/70214422</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Mac</tag>
        <tag>Homebrew</tag>
        <tag>Alfred</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 8:Imitation Learning</title>
    <url>/2019/06/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%208:%20Imitation%20Learning/</url>
    <content><![CDATA[<p>è®¨è®ºäº†åœ¨æ²¡æœ‰rewardçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨expertæ¥è¿›è¡ŒRLã€‚</p>
<p>é—®é¢˜å®šä¹‰ï¼šåœ¨ä¸€äº›é—®é¢˜ä¸Šæ˜¯æ²¡æœ‰rewardçš„ï¼Œç»™å®šä¸€äº›expertçš„demonstration exampleï¼Œå¦‚ä½•åˆ©ç”¨è¿™äº›exampleä½¿å¾—æœºå™¨èƒ½å¤Ÿå­¦ä¹ ï¼Ÿ</p>
<h3 id="Behavior-Cloning"><a href="#Behavior-Cloning" class="headerlink" title="Behavior Cloning"></a>Behavior Cloning</h3><p>æœ¬è´¨å°±æ˜¯ç›‘ç£å­¦ä¹ ï¼Œç»™å®šè®­ç»ƒæ•°æ®ï¼Œè¦æ¨¡å‹è¾“å…¥sèƒ½å¤Ÿè·å¾—å°½é‡å’Œexpertç›¸ä¼¼çš„actionã€‚</p>
<p><img src="/images/15618627790626.jpg" width="60%" height="50%"></p>
<p>ç”±äºexpert exampleæ˜¯è¾ƒå°‘çš„ï¼Œæœºå™¨å¯èƒ½é‡åˆ°æ²¡é‡åˆ°çš„æƒ…å†µã€‚<br>åŒæ—¶ç”±äºæœºå™¨çš„capacityæ˜¯æœ‰é™çš„ï¼Œå¯èƒ½é€‰æ‹©æ— å…³çš„è¡Œä¸ºå»å­¦ä¹ ã€‚<br>è¿˜æœ‰å¯èƒ½å¸¦æ¥ç”±äºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„åˆ†å¸ƒä¸åŒå¯¼è‡´çš„é—®é¢˜ã€‚å› ä¸ºRLæœ‰åºåˆ—æ€§ï¼Œå¦‚æœä½¿ç”¨Behavior Cloningï¼Œåœ¨æŸä¸ªstateä¸‹é‡‡ç”¨äº†ä¸åŒçš„actionï¼Œåˆ™ä¹‹åçš„stateéƒ½ä¼šå®Œå…¨ä¸åŒï¼ˆå¤±ä¹‹æ¯«å˜è°¬ä»¥åƒé‡Œï¼‰</p>
<h3 id="Inverse-Reinforcement-Learning-IRL"><a href="#Inverse-Reinforcement-Learning-IRL" class="headerlink" title="Inverse Reinforcement Learning (IRL)"></a>Inverse Reinforcement Learning (IRL)</h3><p>é€šè¿‡expert exampleæ¥å­¦ä¹ reward functionï¼Œåœ¨å­¦ä¹ å®Œreward functionåè®©agentä¸ç¯å¢ƒäº¤äº’è·å¾—agent exampleã€‚æ¥ç€è°ƒæ•´reward functionä½¿å¾—expert exampleä¸€å®šå¤§äºagentçš„exampleã€‚ä¸æ–­å¾ªç¯ã€‚è¿™å’ŒGANçš„æ€æƒ³æœ‰ç‚¹åƒï¼š</p>
<p><img src="/images/15618628831028.jpg" width="60%" height="50%"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Imitation Learning</tag>
        <tag>IRL</tag>
        <tag>Inverse Reinforcement Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯30</title>
    <url>/2019/06/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D30/</url>
    <content><![CDATA[<h3 id="æ°´é¾™åŸ-Â·-ç™»å»ºåº·èµå¿ƒäº­"><a href="#æ°´é¾™åŸ-Â·-ç™»å»ºåº·èµå¿ƒäº­" class="headerlink" title="æ°´é¾™åŸ Â· ç™»å»ºåº·èµå¿ƒäº­"></a>æ°´é¾™åŸ Â· ç™»å»ºåº·èµå¿ƒäº­</h3><p>[å®‹] è¾›å¼ƒç–¾<br>æ¥šå¤©åƒé‡Œæ¸…ç§‹ï¼Œæ°´éšå¤©å»ç§‹æ— é™…ã€‚é¥å²‘è¿œç›®ï¼ŒçŒ®æ„ä¾›æ¨ï¼Œç‰ç°ªèºé«»ã€‚è½æ—¥æ¥¼å¤´ï¼Œæ–­é¸¿å£°é‡Œï¼Œæ±Ÿå—æ¸¸å­ã€‚æŠŠå´é’©çœ‹äº†ï¼Œæ å¹²æ‹éï¼Œæ— äººä¼šã€ç™»ä¸´æ„ã€‚<br>ä¼‘è¯´é²ˆé±¼å ªè„ï¼Œå°½è¥¿é£ã€å­£é¹°å½’æœªï¼Ÿæ±‚ç”°é—®èˆï¼Œæ€•åº”ç¾è§ï¼Œåˆ˜éƒæ‰æ°”ã€‚å¯æƒœæµå¹´ï¼Œå¿§æ„é£é›¨ï¼Œæ ‘çŠ¹å¦‚æ­¤ã€‚<strong>å€©ä½•äººå”¤å–ï¼Œçº¢å·¾ç¿ è¢–ï¼Œæ¾è‹±é›„æ³ª</strong>ã€‚</p>
<p>å€©ï¼ˆqÃ¬ngï¼‰ï¼šè¯·æ‰˜ã€‚<br>æ¾ï¼ˆwÃ¨nï¼‰ï¼šæ“¦æ‹­ã€‚</p>
<hr>
<h3 id="æ»¡æ±Ÿçº¢"><a href="#æ»¡æ±Ÿçº¢" class="headerlink" title="æ»¡æ±Ÿçº¢"></a>æ»¡æ±Ÿçº¢</h3><p>[å®‹] å²³é£<br>æ€’å‘å†²å† ï¼Œå‡­æ å¤„ã€æ½‡æ½‡é›¨æ­‡ã€‚æŠ¬æœ›çœ¼ï¼Œä»°å¤©é•¿å•¸ï¼Œå£®æ€€æ¿€çƒˆã€‚<strong>ä¸‰ååŠŸåå°˜ä¸åœŸï¼Œå…«åƒé‡Œè·¯äº‘å’Œæœˆ</strong>ã€‚<strong>è«ç­‰é—²ï¼Œç™½äº†å°‘å¹´å¤´ï¼Œç©ºæ‚²åˆ‡</strong>ï¼<br>é–åº·è€»ï¼ŒçŠ¹æœªé›ªã€‚è‡£å­æ¨ï¼Œä½•æ—¶ç­ï¼Ÿé©¾é•¿è½¦ã€è¸ç ´è´ºå…°å±±ç¼ºï¼å£®å¿—é¥¥é¤èƒ¡è™è‚‰ï¼Œç¬‘è°ˆæ¸´é¥®åŒˆå¥´è¡€ã€‚<strong>å¾…ä»å¤´ã€æ”¶æ‹¾æ—§å±±æ²³ï¼Œæœå¤©é˜™ï¼</strong></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡23</title>
    <url>/2019/06/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8723/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Reinforcement Learning based Curriculum Optimization for Neural Machine Translation</li>
<li>Curriculum Dropout</li>
<li>Self-Paced Curriculum Learning</li>
<li>Learning the Easy Things First: Self-Paced Visual Category Discovery</li>
<li>Curriculum Learning and Minibatch Bucketing in Neural Machine Translation</li>
<li>Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks</li>
<li>LEARNING TO TEACH</li>
<li>Learning to learn by gradient descent by gradient descent</li>
<li>Curriculum Learning of Multiple Tasks</li>
</ol>
<h2 id="Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation"><a href="#Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation" class="headerlink" title="[Reinforcement Learning based Curriculum Optimization for Neural Machine Translation]"></a>[Reinforcement Learning based Curriculum Optimization for Neural Machine Translation]</h2><p>ä½¿ç”¨RLæ¥è¿›è¡Œå­¦ä¹ curriculum learningï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å„å¼å„æ ·çš„æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆä¹Ÿå³é«˜æ•ˆåˆ©ç”¨noiseå¾ˆå¤§çš„æ•°æ®é›†ï¼Œå¦‚Paracrawl)ã€‚</p>
<p><img src="/images/15618207015732.jpg" width="60%" height="50%"></p>
<p>ä½¿ç”¨ä¸€ä¸ªæŒ‡æ ‡CDSæ¥å°†æ•°æ®åˆ‡åˆ†ï¼š</p>
<script type="math/tex; mode=display">s(e, f)=\log p_{\theta_{c}}(f | e)-\log p_{\theta_{n}}(f | e)</script><p>$e$å’Œ$f$æ˜¯ç¿»è¯‘å¯¹ã€‚å…¶ä¸­$\theta_c$æ˜¯åœ¨å¯ä¿¡ä»»çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼›$\theta_n$åœ¨noisy corpusä¸Šè®­ç»ƒçš„ï¼ˆæ¯”å¦‚Paracrawl)ã€‚</p>
<p>RLçš„å‡ ä¸ªåŸºæœ¬å› ç´ ï¼š</p>
<p>Observation Engineeringï¼šthe observation is the vector containing sentence-level log-likelihoods produced by the NMT system for this prototype batch  å‚è€ƒï¼ˆReinforced co-training.ï¼‰</p>
<p>Reward Engineeringï¼šThe reward is a function of the log-likelihood of the development set of interest.</p>
<p>Actionï¼šå°†æ•°æ®é›†åˆ†ä¸ºå¤šä¸ªbinï¼Œactionå°±æ˜¯é€‰æ‹©åœ¨å“ªä¸ªbiné‡Œé¢é€‰æ‹©æ•°æ®é›†ã€‚</p>
<hr>
<h2 id="Curriculum-Dropout"><a href="#Curriculum-Dropout" class="headerlink" title="[Curriculum Dropout]"></a>[Curriculum Dropout]</h2><p>é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯é€æ¸å¢åŠ dropout rateã€‚</p>
<p><img src="/images/15618211418694.jpg" width="40%" height="50%"></p>
<hr>
<h2 id="Self-Paced-Curriculum-Learning"><a href="#Self-Paced-Curriculum-Learning" class="headerlink" title="[Self-Paced Curriculum Learning]"></a>[Self-Paced Curriculum Learning]</h2><p>å°†self-paced learningä¸curriculum learningç»“åˆã€‚</p>
<h3 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><p>é€šè¿‡å…ˆéªŒçŸ¥è¯†å¯¹exampleçš„éš¾åº¦è¿›è¡Œé¢„å®šä¹‰ï¼Œç„¶åæŒ‰ç…§å…ˆåé¡ºåºè®­ç»ƒæ¨¡å‹ï¼›</p>
<p>è¿™æ˜¯ä¸€ç§Instructor-drivençš„è®­ç»ƒæ–¹æ³•ï¼›å¹¶ä¸è€ƒè™‘learnerçš„feedback</p>
<h3 id="Self-paced-Learning"><a href="#Self-paced-Learning" class="headerlink" title="Self-paced Learning"></a>Self-paced Learning</h3><p>æ˜¯ç›´æ¥å°†ç›®æ ‡å‡½æ•°å’Œcurriculumä¸€èµ·ç»“åˆèµ·æ¥ï¼Œä¹Ÿå³åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­æ ¹æ®æ¨¡å‹çš„å­¦ä¹ æƒ…å†µï¼ˆlossï¼‰è°ƒæ•´curriculumã€‚çµæ´»ï¼Œä½†ä¸è€ƒè™‘å…ˆéªŒçŸ¥è¯†ã€‚</p>
<script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v} \in[0,1]^{n}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, f\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)-\lambda \sum_{i=1}^{n} v_{i}</script><p>å½“losså°äº$\lambda$æ—¶ï¼Œå°±è¢«è®¤ä¸ºæ˜¯easy sampleï¼Œ$v=1$ï¼›è‹¥å¤§äº$\lambda$åˆ™$v=0$ã€‚</p>
<p>Î» controls the pace at which the model learns new samples, and physically Î» corresponds to the â€œageâ€ of the model</p>
<p>ç”±äºå­¦ä¹ è¿‡ç¨‹å®Œå…¨è¢«lossä¸»å¯¼ï¼Œå› æ­¤å¯èƒ½ä¼šoverfittingã€‚</p>
<h3 id="Self-paced-Curriculum-Learning"><a href="#Self-paced-Curriculum-Learning" class="headerlink" title="Self-paced Curriculum Learning"></a>Self-paced Curriculum Learning</h3><p>åœ¨äºŒè€…åŸºç¡€ä¸Šç»“åˆï¼Œåœ¨SPLçš„æ¡†æ¶ä¸‹å¼•å…¥CLçš„å…ˆéªŒçŸ¥è¯†ã€‚ä¹Ÿå³æ—¢è€ƒè™‘äº†å…ˆéªŒçŸ¥è¯†ï¼Œåˆè€ƒè™‘äº†æ¨¡å‹å­¦ä¹ çš„åé¦ˆï¼ˆlossï¼‰ã€‚</p>
<script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v} \in[0,1]^{n}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda, \Psi)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, g\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)+f(\mathbf{v} ; \lambda),\text { s.t. } \mathbf{v} \in \Psi</script><p>å…¶ä¸­$\Psi$ä»£è¡¨äº†é¢„å®šä¹‰çš„curriculumçš„é›†åˆã€‚</p>
<p>ç›¸å½“äºCLæä¾›äº†ä¸€ä¸ªå¼±sampleçš„é¡ºåºï¼Œå»ºè®®æ¨¡å‹è¦å…ˆå­¦å“ªäº›ï¼Œä½†ä»–æœ‰è‡ªç”±å»è°ƒæ•´å­¦ä¹ ç›®æ ‡ã€‚<br>æˆ‘çš„ç†è§£æ˜¯ï¼Œ$\Psi$æ˜¯å¯ä»¥åŠ¨æ€å¢å¤§çš„ã€‚ä½†æ˜¯æ¨¡å‹æ˜¯å¦è¦å°†é›†åˆé‡Œçš„exampleç”¨äºè®­ç»ƒè¿˜æ˜¯è¦çœ‹ä¸Šè¿°çš„ç›®æ ‡å‡½æ•°çš„ï¼Œlosså°çš„æ—¶å€™ä»£è¡¨çš„easy exampleï¼Œä¼šç”¨äºå­¦ä¹ ã€‚</p>
<p><img src="/images/15618570682762.jpg" width="60%" height="50%"></p>
<p>è¿™æ˜¯CL/SPL/SPCLçš„åŒºåˆ«ï¼š</p>
<p><img src="/images/15618570907601.jpg" width="100%" height="50%"></p>
<p>æ€è€ƒï¼š</p>
<p>$\lambda$ä»£è¡¨äº†æ¨¡å‹çš„æˆç†Ÿåº¦ï¼Œæ§åˆ¶çš„æ˜¯æ¨¡å‹è‡ªèº«çš„competenceï¼›è€Œ$\Psi$é›†åˆå¤§å°ä»£è¡¨äº†instructorè®¤ä¸ºæ¨¡å‹çš„æˆç†Ÿåº¦ã€‚è¿™äºŒè€…çš„ç»“åˆèƒ½å¤Ÿè®©æ¨¡å‹æ›´çµæ´»ã€‚ä½†æ˜¯competenceè¿˜æ˜¯éœ€è¦ä¸€ä¸ªæ‰‹åŠ¨çš„scheduleã€‚</p>
<hr>
<h2 id="Learning-the-Easy-Things-First-Self-Paced-Visual-Category-Discovery"><a href="#Learning-the-Easy-Things-First-Self-Paced-Visual-Category-Discovery" class="headerlink" title="[Learning the Easy Things First: Self-Paced Visual Category Discovery]"></a>[Learning the Easy Things First: Self-Paced Visual Category Discovery]</h2><p>å°†self-pacedçš„æ€è·¯åº”ç”¨äºvisual category discoveryã€‚ä¸ä¼ ç»Ÿself-paced learningä¸åŒçš„æ˜¯ï¼Œå¹¶æ²¡æœ‰å°†self-pacedç»‘å®šåœ¨loss functionä¸Šã€‚</p>
<p>æ¯ä¸€æ¬¡è®¡ç®—ä¸¤ä¸ªæŒ‡æ ‡ objectnesså’Œcontext-awarenessã€‚å°†æœ€ç®€å•çš„é€‰å‡ºæ¥è®­ç»ƒï¼Œç„¶åå†è®¡ç®—æŒ‡æ ‡ï¼Œå†é€‰å‡ºç®€å•çš„è®­ç»ƒã€‚ä¸æ–­å¾ªç¯ã€‚</p>
<p>self-pacedä¸curriculum learningä¸åŒï¼Œæ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„teacheræ¥åˆ¤æ–­éš¾æ˜“ç¨‹åº¦ï¼Œæ ¹æ®æ¯æ¬¡è‡ªå·±å­¦ä¹ çš„è¿›ç¨‹æ¥åˆ¤æ–­éš¾åº¦ã€‚æœ¬æ–‡ç›¸è¾ƒä¼ ç»Ÿself-pacedä¸åŒï¼Œå› ä¸ºå°†losså’Œå¯¹éš¾æ˜“ç¨‹åº¦çš„åˆ¤æ–­ä¸¤ä¸ªæ­¥éª¤åˆ†ç¦»å¼€æ¥ã€‚</p>
<hr>
<h2 id="Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation"><a href="#Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation" class="headerlink" title="[Curriculum Learning and Minibatch Bucketing in Neural Machine Translation]"></a>[Curriculum Learning and Minibatch Bucketing in Neural Machine Translation]</h2><p>åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šåšäº†ä¸€äº›è®­ç»ƒæ–¹æ³•ä¸Šçš„ç»„åˆå°è¯•ï¼Œç»™å‡ºäº†ä¸€äº›ç»“è®ºã€‚</p>
<h3 id="Minibatch-Bucketing"><a href="#Minibatch-Bucketing" class="headerlink" title="Minibatch Bucketing"></a>Minibatch Bucketing</h3><p>é¦–å…ˆæ˜¯å°è¯•äº†åœ¨åŒä¸€ä¸ªbatché‡Œä¸ä»…å¥å­é•¿åº¦ç›¸åŒï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰ï¼Œè¿˜å¸Œæœ›åŒä¸€ä¸ªbatchå†…éƒ¨æœ‰æŸç§linguisticçš„ä¿¡æ¯(sentence length, number of coordinating conjunctions, number of nouns, number of proper nouns and the number of verbs in the training data pairs)ã€‚å¯èƒ½ç”±äºä»–é€‰çš„è¿™äº›linguisticå¹¶ä¸å¥½ï¼Œæœ€ç»ˆå¹¶æ²¡æœ‰å‘ç°ç»“æœçš„æå‡ã€‚</p>
<p><img src="/images/15618573588977.jpg" width="55%" height="50%"></p>
<h3 id="Curriculum-Learning-1"><a href="#Curriculum-Learning-1" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><p>å¯¹curriculum learningè¿›è¡Œäº†æ”¹è¿›ï¼Œå®é™…ä¸Šæ™®é€šçš„CLé—´æ¥åœ°å¼ºè°ƒäº†easier exampleï¼Œå› ä¸ºä»–ä»¬è¢«sampleäº†å¤šæ¬¡ï¼Œæ‰€ä»¥è¿™é‡Œé‡‡ç”¨äº†ä¸€ç§æ–°çš„æ–¹æ³•èƒ½å¤Ÿè®©æ¯ä¸ªexampleåœ¨ä¸€ä¸ªepochéƒ½åªè¢«sampleä¸€æ¬¡ã€‚</p>
<p>æŒ‰ç…§éš¾åº¦å°†æ ·ä¾‹åˆ†ä¸ºå‡ ä¸ªbinï¼Œé¦–å…ˆä»æœ€ç®€å•çš„binå¼€å§‹å–æ ·ä¾‹ï¼Œç›´åˆ°è¯¥binçš„å‰©ä½™æ ·ä¾‹ä¸ªæ•°å’Œç¬¬äºŒä¸ªbinçš„æ ·ä¾‹ä¸€æ ·ï¼Œç„¶åä»è¿™ä¸¤ä¸ªbinå‰©ä¸‹çš„æ ·ä¾‹ä¸­å–æ ·ä¾‹ï¼Œç›´åˆ°å‰©ä¸‹å’Œç¬¬ä¸‰ä¸ªbinæ ·ä¾‹ä¸ªæ•°ä¸€æ ·ã€‚è¿™æ ·èƒ½ä¿è¯åœ¨ä¸€ä¸ªepochå†…æ¯ä¸ªexampleçš„æ¦‚ç‡æ˜¯ä¸€è‡´çš„ã€‚</p>
<p>å¦‚ä½•åˆ¤æ–­éš¾æ˜“ç¨‹åº¦ï¼Ÿé•¿åº¦ï¼Œè¯çš„é¢‘ç‡ç­‰</p>
<h4 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h4><p>â‘ <br>é¦–å…ˆï¼Œåœ¨è®­ç»ƒå®Œä¸€ä¸ªepochåï¼Œä½¿ç”¨CLç›¸æ¯”æ²¡ä½¿ç”¨CLæœ‰æå‡ï¼š</p>
<p><img src="/images/15618574547524.jpg" width="55%" height="50%"></p>
<p>â‘¡<br>åœ¨ä¸€ä¸ªepochå†…çš„è®­ç»ƒæ›²çº¿ï¼š</p>
<p><img src="/images/15618574884386.jpg" width="70%" height="50%"></p>
<p>å¯ä»¥çœ‹åˆ°ç”¨CLçš„åœ¨æ¯æ¬¡æ–°åŠ exampleåéƒ½ä¼šæœ‰ä¸€ä¸ªé™¡å³­çš„è·³è·ƒã€‚ç‰¹åˆ«è¦æ³¨æ„æŒ‰ç…§sourceé•¿åº¦å’ŒæŒ‰ç…§targeté•¿åº¦çš„CLæœ‰å¾ˆå¤§çš„ä¸åŒï¼Œå¯èƒ½æ˜¯æŒ‰ç…§targetçš„CLç»™äº†è®­ç»ƒè¿›ç¨‹ä¸€ä¸ªè¾ƒå¤§çš„penalizationã€‚</p>
<p>â‘¢<br>æ¨¡å‹å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆrecent exampleï¼Œå› æ­¤å¦‚æœåªæä¾›éš¾ä¸€ç‚¹çš„exampleï¼Œé‚£ä¹ˆåœ¨easyçš„exampleå°±å®¹æ˜“ä¸‹é™ã€‚æ‰€ä»¥éœ€è¦mixing strategyã€‚</p>
<p><img src="/images/15618575566938.jpg" width="70%" height="50%"></p>
<p>ä»CL by target lengthå¯ä»¥çœ‹å‡ºï¼Œé™¡å³­çš„è·³è·ƒè¯´æ˜æ¨¡å‹åœ¨æ–°åŠ å…¥æ•°æ®ä¹‹å‰å¾ˆå¿«åœ°adaptåœ¨çŸ­çš„å¥å­ï¼Œè€Œé•¿å¥ä¸€è¿›æ¥åˆå¾ˆå¿«adaptåˆ°é•¿å¥ã€‚è¿™ç§å¿«é€Ÿè½¬æ¢ä¼¼ä¹è¯´æ˜äº†æ¨¡å‹çš„å¿«é€Ÿé€‚åº”æ€§ã€‚<br>å¦‚æœä¸å›é¡¾ç®€å•çš„å¥å­ï¼Œè§sorted by lengthçš„æ›²çº¿ï¼Œå¯ä»¥çœ‹åˆ°performanceå¾ˆå·®ã€‚<br>åŒæ—¶å¦‚æœreverse CLï¼Œä¹Ÿå³ä¸€å¼€å§‹evenly coveræ‰€æœ‰å¥å­ï¼Œç„¶ååªä½¿ç”¨çŸ­çš„å¥å­ï¼Œé‚£ä¹ˆå¯ä»¥çœ‹åˆ°ä¸€å¼€å§‹æ•ˆæœä¸é”™ï¼Œåˆ°åé¢å°±é™ä½äº†ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹å¿«é€Ÿé€‚åº”äº†ç”ŸæˆçŸ­çš„å¥å­ï¼Œå°±æ²¡æ³•ç”Ÿæˆtesté›†çš„æ­£å¸¸é•¿åº¦çš„å¥å­ã€‚</p>
<p>â‘£<br>æ³¨æ„åˆ°ä»¥ä¸Šéƒ½æ˜¯åœ¨ä¸€ä¸ªepochå†…ï¼ˆä¹Ÿå³è¿‡å®Œäº†ä¸€éè®­ç»ƒæ•°æ®ï¼‰çš„ç»“è®ºã€‚åœ¨è¿™ä¸ªepochåç»§ç»­å‡ ç§è®­ç»ƒæ–¹å¼ï¼ˆåŸºäºâ€˜CL by target lengthâ€™ï¼‰ã€‚</p>
<p><img src="/images/15618576497211.jpg" width="70%" height="50%"></p>
<p>é‡æ–°ä»æœ€ç®€å•çš„å¼€å§‹ï¼ˆsecond epoch of CL by target length)ï¼Œä¼šä¼¤å®³performanceï¼Œä½†åˆ°åé¢è¿˜æ˜¯æœ‰æå‡çš„ã€‚å¦‚æœåœ¨ç¬¬äºŒä¸ªepochç”¨shuffleçš„æ•°æ®è®­ç»ƒï¼Œé‚£ä¹ˆå¯ä»¥çœ‹åˆ°æ˜¯å‡ ä¹æ²¡æœ‰æå‡çš„ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å·²ç»é™·å…¥äº†å½“å‰çš„optimumäº†ã€‚</p>
<h3 id="æ€è€ƒä¸ç»“è®º"><a href="#æ€è€ƒä¸ç»“è®º" class="headerlink" title="æ€è€ƒä¸ç»“è®º"></a>æ€è€ƒä¸ç»“è®º</h3><p>è¿™é‡Œçš„å›é¡¾å¼çš„CLï¼Œæ— æ³•å‡å°‘è®­ç»ƒæ—¶é—´ï¼Œå› ä¸ºè¦åˆ°æœ€åæ‰èƒ½è·å¾—è¶…è¶Šbaselineçš„performanceã€‚<br>åŒæ—¶å®éªŒè¯æ˜äº†ï¼Œæ¨¡å‹çš„å¿«é€Ÿé€‚åº”æ€§ï¼Œå¾ˆå®¹æ˜“overfittingåˆ°æœ€è¿‘çš„è®­ç»ƒæ ·ä¾‹ä¸Šï¼Œå› æ­¤è¦è®¾è®¡mixing strategyã€‚</p>
<hr>
<h2 id="Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks"><a href="#Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks" class="headerlink" title="[Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks]"></a>[Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks]</h2><p>å¯¹CLåœ¨LSTMçš„è®­ç»ƒçš„å½±å“è¿›è¡Œåˆ†æã€‚å¾—åˆ°ä¸€äº›ç»“è®ºã€‚</p>
<p>å¿«é€Ÿå›é¡¾äº†ä¸¤ç§CLï¼šOne-Pass Curriculumå’ŒBaby Steps Curriculumã€‚</p>
<p>One-Pass Curriculumï¼šå°†è®­ç»ƒæ•°æ®åˆ†ä¸ºå‡ ä¸ªbucketï¼Œç„¶åä»ç®€å•çš„bucketå¼€å§‹ï¼Œè®­ç»ƒå®Œç®€å•çš„bucketä¹‹åè·³åˆ°éš¾çš„bucketã€‚</p>
<p><img src="/images/15618578493722.jpg" width="60%" height="50%"></p>
<p>Baby Steps Curriculumï¼šä»ç®€å•çš„å¼€å§‹ï¼Œä½†åœ¨å¢åŠ éš¾çš„æ•°æ®åï¼Œä¸ä¼šdiscardç®€å•çš„æ•°æ®ã€‚</p>
<p><img src="/images/15618578792843.jpg" width="60%" height="50%"></p>
<h3 id="å®éªŒ-amp-ç»“è®º"><a href="#å®éªŒ-amp-ç»“è®º" class="headerlink" title="å®éªŒ&amp;ç»“è®º"></a>å®éªŒ&amp;ç»“è®º</h3><p>â‘ <br>Baby Stepåœ¨å¤šä¸ªä»»åŠ¡ä¸Šéƒ½æ˜æ˜¾æ›´å¥½ï¼Œå¦‚ï¼Œdigit sum</p>
<p><img src="/images/15618579415036.jpg" width="90%" height="50%"></p>
<p>ä¸ä»…ä»…æ˜¯ç»“æœå¥½ï¼ŒåŒæ—¶å…¶varianceä¹Ÿæ›´å°ï¼š</p>
<p><img src="/images/15618579749575.jpg" width="70%" height="50%"></p>
<p>â‘¡<br>åœ¨ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹ä¸Šï¼ŒCLæ•ˆæœéƒ½å¥½ï¼Œå½“æ¨¡å‹è¶Šå¤§ï¼Œæ•ˆæœçš„å·®è·ä¼šè¶Šå°ã€‚æ³¨æ„åˆ°ï¼ŒCLåœ¨å‚æ•°æ•°é‡æ›´å°‘çš„æƒ…å†µä¸‹æ•ˆæœæ›´å¥½ã€‚</p>
<p><img src="/images/15618584599852.jpg" width="60%" height="50%"></p>
<p>â‘¢<br>åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„ç»“æœ</p>
<p><img src="/images/15618585223767.jpg" width="60%" height="50%"></p>
<p>é¦–å…ˆæ˜¯ä½¿ç”¨CLæ•ˆæœå¥½ï¼Œå…¶æ¬¡æ˜¯ä½¿ç”¨conjunctionï¼ˆæ˜¯æŒ‡è¿æ¥ä¸¤ä¸ªæƒ…æ„Ÿææ€§ç›¸åå¥å­çš„è¯ï¼ˆbutç­‰ï¼‰ï¼ˆconjunctions where a span of text contradicts or supports overall sentiment polarityï¼‰ï¼‰æ•ˆæœå·®è·æ›´å¤§ã€‚è¯´æ˜ä½¿ç”¨CLä½¿å¾—æ¨¡å‹çš„é²æ£’æ€§æ›´å¼ºã€‚</p>
<p>åŒæ—¶CLåœ¨ä½¿ç”¨ä¸åŒè¯æ¥é¢„æµ‹ï¼Œå…¶è¡¨ç°è¾ƒä¸ºä¸€è‡´ï¼š</p>
<p><img src="/images/15618586132751.jpg" width="70%" height="50%"></p>
<p>åŒæ—¶ï¼Œåœ¨æ•°æ®é‡æ›´å°‘çš„æƒ…å†µä¸‹ï¼ŒCLçš„æ•ˆæœè¶Šæ˜æ˜¾ï¼š</p>
<p><img src="/images/15618586384812.jpg" width="60%" height="50%"></p>
<p>ç»“è®ºï¼š<br>CLåœ¨æ•°æ®å°‘ï¼Œæ¨¡å‹å°çš„æƒ…å†µä¸‹å¾ˆé‡è¦ã€‚</p>
<hr>
<h2 id="LEARNING-TO-TEACH"><a href="#LEARNING-TO-TEACH" class="headerlink" title="[LEARNING TO TEACH]"></a>[LEARNING TO TEACH]</h2><p>é‡‡ç”¨RLçš„æ–¹æ³•æ¥è¿›è¡Œschedule learningã€‚ ä¸»è¦ç»“æ„æ˜¯ï¼Œä¸€ä¸ªteacherå†³å®šç»™å­¦ç”Ÿçš„æ•°æ®ï¼Œä¸€ä¸ªå­¦ç”Ÿé€šè¿‡ç»™å®šçš„æ•°æ®è®­ç»ƒï¼Œå¹¶è·å¾—rewardå’Œstateä½œä¸ºfeedbackè¿”å›ç»™teacherã€‚ </p>
<p>teacherçš„ç›®æ ‡æ˜¯æä¾›æ•°æ®ï¼Œloss functionå’Œhypothesis spaceã€‚å®é™…ä¸Šè®ºæ–‡åªè®¨è®ºäº†æ•°æ®çš„æä¾›ã€‚ç›®æ ‡ï¼š</p>
<script type="math/tex; mode=display">\min _{D, L, \Omega} \mathcal{M}\left(\mu(D, L, \Omega), D_{t e s t}\right)</script><p><img src="/images/15618587842064.jpg" width="55%" height="50%"></p>
<p>RLçš„å‡ ä¸ªè¦ç´ ï¼š</p>
<p>actionï¼šéšæœºsampleæ•°æ®ï¼Œç„¶åä»è¿™äº›sampleçš„æ•°æ®é‡Œå†ç­›é€‰å‡ºæ•°æ®ã€‚ä¹Ÿå³å¯¹æ‰€æœ‰sampleçš„æ•°æ®æ‰“æ ‡ç­¾ï¼Œ1ä»£è¡¨ç»™å­¦ç”Ÿmodelè®­ç»ƒï¼Œ0åˆ™è¢«æŠ›å¼ƒæ‰ã€‚</p>
<p>stateï¼šå®é™…ä¸Šå°±æ˜¯ä¸€äº›äººå·¥å®šå¥½çš„featureã€‚æ•°æ®çš„featureï¼Œæ¯”å¦‚label categoryï¼Œå¥å­é•¿åº¦ï¼Œlinguistic featureç­‰ï¼›student modelçš„featureï¼Œä¹Ÿå³ä»£è¡¨äº†å½“å‰NNè¢«è®­ç»ƒå¾—å¤šå¥½çš„featureï¼Œå†å²training losså’Œå†å²çš„validation accuracyç­‰ï¼›è¿˜æœ‰å°±æ˜¯äºŒè€…çš„ç»“åˆï¼Œæ¯”å¦‚predicted probability ï¼›dataçš„lossç­‰</p>
<p>rewardï¼šå’Œstudent modelæ”¶æ•›é€Ÿåº¦ç›¸å…³ï¼Œä¹Ÿå³è®°å½•ç¬¬ä¸€ä¸ªåœ¨æµ‹è¯•é›†ä¸Šå‡†ç¡®ç‡è¶…è¿‡æŸä¸ªé˜ˆå€¼çš„mini-batchçš„ç´¢å¼•ï¼Œç„¶åè®¡ç®—ï¼š</p>
<script type="math/tex; mode=display">r_{T}=-\log \left(i_{\tau} / T^{\prime}\right)</script><p>è¿™æ˜¯ä¸ºäº†é¼“åŠ±æ—©ç‚¹æ”¶æ•›ã€‚</p>
<p>æœ¬ç¯‡æ–‡ç« æ¡†æ¶è®¾å®šå¾—å¾ˆå¥½ï¼Œä½†å¹¶æ²¡æœ‰è®¨è®ºå¦å¤–ä¸¤ä¸ªã€‚</p>
<hr>
<h2 id="Learning-to-learn-by-gradient-descent-by-gradient-descent"><a href="#Learning-to-learn-by-gradient-descent-by-gradient-descent" class="headerlink" title="[Learning to learn by gradient descent by gradient descent]"></a>[Learning to learn by gradient descent by gradient descent]</h2><p>meta-learningçš„ä¸€ç§æ–¹æ³•ã€‚è¢«é¢˜ç›®å¸å¼•ï¼Œå¤§æ¦‚çœ‹äº†çœ‹ã€‚</p>
<p>åˆ©ç”¨LSTMæ¥å­¦ä¹ optimizerçš„æ¢¯åº¦ï¼Œä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½çš„è®­ç»ƒã€‚</p>
<p><img src="/images/15618590469237.jpg" width="50%" height="50%"></p>
<p><img src="/images/15618590754597.jpg" width="60%" height="50%"></p>
<p>å…¶ä¸­è™šçº¿ä¸å›ä¼ ï¼Œå®çº¿å›ä¼ ã€‚</p>
<p>åŒæ—¶ï¼Œæ³¨æ„åˆ°ä¸ºäº†è®©å‚æ•°çš„é¡ºåºå¯¹è¾“å‡ºæ²¡æœ‰å½±å“ï¼Œå› ä¸ºå‡è®¾æ¯ä¸ªå‚æ•°åæ ‡éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤ä½¿ç”¨separate hidden stateï¼Œä½†LSTMçš„å‚æ•°æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³æ¯ä¸ªè¾“å…¥æ¢¯åº¦éƒ½å•ç‹¬å¤„ç†ã€‚</p>
<p><img src="/images/15618591345801.jpg" width="45%" height="50%"></p>
<hr>
<h2 id="Teacher-Student-Curriculum-Learning"><a href="#Teacher-Student-Curriculum-Learning" class="headerlink" title="[Teacher-Student Curriculum Learning]"></a>[Teacher-Student Curriculum Learning]</h2><p>æ²¡ä»”ç»†çœ‹ï¼Œå¤§æ¦‚æ€æƒ³æ˜¯ï¼Œä¸€ä¸ªteacherå¸®å¿™é€‰æ‹©sub-taskè®©studentå­¦ã€‚</p>
<p><img src="/images/15618591847957.jpg" width="50%" height="50%"></p>
<p>stateä»£è¡¨çš„æ˜¯studentçš„æ•´ä¸ªçŠ¶æ€ï¼Œneural network parameters and optimizer state) and is not observable to the Teacher.</p>
<p>actionæ˜¯teacheræ‰€é‡‡å–çš„åŠ¨ä½œï¼Œä¹Ÿå³é€‰æ‹©æŸä¸ªtaskï¼›</p>
<p>observation æ˜¯åœ¨é€‰æ‹©äº†taskåæ‰€è·å¾—çš„scoreï¼›</p>
<p>rewardä¹Ÿå³åœ¨è¯¥timestepçš„scoreçš„æ”¹å˜ $r_{t}=x_{t}^{(i)}-x_{t_{i}^{\prime}}^{(i)}$</p>
<p>CLçš„åœ°æ–¹åœ¨äºä»ç®€å•çš„å­¦èµ·ï¼ˆä¹Ÿå³å¸¦æ¥çš„æ”¹å˜æœ€å¤§çš„taskï¼‰ï¼Œç„¶åå½“å…¶æå‡çš„é€Ÿç‡é™ä½äº†ï¼Œåˆ™é™ä½å…¶sampleçš„æ¦‚ç‡ã€‚</p>
<p>æ€»ç»“èµ·æ¥ï¼ŒCLçš„å‡ ä¸ªåŸåˆ™ï¼š</p>
<p><img src="/images/15618592716048.jpg" width="80%" height="50%"></p>
<p>ç†æƒ³åŒ–çš„CLï¼š</p>
<p><img src="/images/15618593002197.jpg" width="76%" height="50%"></p>
<p>å½“æŸä¸ªtaskçš„scoreä¸‹é™äº†ï¼Œè¯´æ˜ä»–å¿˜äº†è¿™éƒ¨åˆ†çš„çŸ¥è¯†ï¼Œåˆè¦æå‡è¯¥sampleçš„æ¦‚ç‡ã€‚</p>
<hr>
<h2 id="Curriculum-Learning-of-Multiple-Tasks"><a href="#Curriculum-Learning-of-Multiple-Tasks" class="headerlink" title="[Curriculum Learning of Multiple Tasks]"></a>[Curriculum Learning of Multiple Tasks]</h2><p>å­¦ä¹ å¤šä¸ªtaskï¼ŒæŒ‰ç…§å…ˆåé¡ºåºæ¥ï¼Œè€Œä¸æ˜¯è”åˆè®­ç»ƒã€‚ä¸Šä¸€ä¸ªtaskå­¦åˆ°çš„weightç”¨äºä¸‹ä¸€ä¸ªtaskçš„åˆå§‹åŒ–ã€‚</p>
<p><img src="/images/15618593717627.jpg" width="55%" height="50%"></p>
<p>è‡ªåŠ¨é€‰æ‹©taské¡ºåºã€‚æˆ‘çš„ç†è§£æ˜¯ï¼Œæ¯å½“è®­ç»ƒå®Œä¸€ä¸ªsubtaskï¼Œæµ‹è¯•æ‰€æœ‰å…¶ä»–subtaskï¼Œé€‰æ‹©è¡¨ç°æœ€å¥½çš„é‚£ä¸ªï¼ˆæŸä¸ªæŒ‡æ ‡ï¼Œå¹³å‡æœŸæœ›è¯¯å·®ï¼‰ï¼Œç„¶åé€‰æ‹©è¯¥subtaskç»§ç»­è®­ç»ƒã€‚</p>
]]></content>
      <tags>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>LSTM</tag>
        <tag>Dropout</tag>
        <tag>meta-learning</tag>
        <tag>multi-task</tag>
        <tag>SPL</tag>
        <tag>Self-paced Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯29</title>
    <url>/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D29/</url>
    <content><![CDATA[<h3 id="æ°¸é‡ä¹-Â·-äº¬å£åŒ—å›ºäº­æ€€å¤"><a href="#æ°¸é‡ä¹-Â·-äº¬å£åŒ—å›ºäº­æ€€å¤" class="headerlink" title="æ°¸é‡ä¹ Â· äº¬å£åŒ—å›ºäº­æ€€å¤"></a>æ°¸é‡ä¹ Â· äº¬å£åŒ—å›ºäº­æ€€å¤</h3><p>[å®‹] è¾›å¼ƒç–¾<br>åƒå¤æ±Ÿå±±ï¼Œè‹±é›„æ— è§…ï¼Œå­™ä»²è°‹å¤„ã€‚èˆæ¦­æ­Œå°ï¼Œé£æµæ€»è¢«ï¼Œé›¨æ‰“é£å¹å»ã€‚æ–œé˜³è‰æ ‘ï¼Œå¯»å¸¸å··é™Œï¼Œäººé“å¯„å¥´æ›¾ä½ã€‚æƒ³å½“å¹´ã€é‡‘æˆˆé“é©¬ï¼Œæ°”åä¸‡é‡Œå¦‚è™ã€‚<br>å…ƒå˜‰è‰è‰ï¼Œå°ç‹¼å±…èƒ¥ï¼Œèµ¢å¾—ä»“çš‡åŒ—é¡¾ã€‚å››åä¸‰å¹´ï¼Œæœ›ä¸­çŠ¹è®°ï¼Œçƒ½ç«æ‰¬å·è·¯ã€‚å¯å ªå›é¦–ï¼Œä½›è²ç¥ ä¸‹ï¼Œä¸€ç‰‡ç¥é¸¦ç¤¾é¼“ã€‚å‡­è°é—®ï¼Œ<strong>å»‰é¢‡è€çŸ£ï¼Œå°šèƒ½é¥­å¦</strong>ï¼Ÿ</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä½³å¥åˆ†äº«1</title>
    <url>/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB1/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>ä»“ä¿ƒæœ¬èº«å°±æ˜¯æœ€è¦ä¸å¾—çš„æ€åº¦ã€‚å½“ä½ åšæŸä»¶äº‹çš„æ—¶å€™ï¼Œä¸€æ—¦æƒ³è¦æ±‚å¿« ï¼Œå°±è¡¨ç¤ºä½ å†ä¹Ÿä¸å…³å¿ƒå®ƒï¼Œè€Œæƒ³å»åšåˆ«çš„äº‹ â€”ã€Šç¦…ä¸æ‘©æ‰˜è½¦ç»´ä¿®è‰ºæœ¯ã€‹</p>
<h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>è‡ªå¾‹ä½¿æˆ‘ä»¬ä¸ä¼—ä¸åŒï¼Œè‡ªå¾‹ä»¤æˆ‘ä»¬æ´»å¾—æ›´é«˜çº§ã€‚<br>ä¹Ÿæ­£æ˜¯è‡ªå¾‹ï¼Œä½¿æˆ‘ä»¬è·å¾—æ›´è‡ªç”±çš„äººç”Ÿã€‚<br>å‡å¦‚æˆ‘ä»¬åƒåŠ¨ç‰©ä¸€æ ·ï¼Œå¬ä»æ¬²æœ›ï¼Œé€ƒé¿ç—›è‹¦ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯çœŸçš„è‡ªç”±è¡ŒåŠ¨ã€‚æˆ‘ä»¬åªæ˜¯æˆäº†æ¬²æœ›å’Œå†²åŠ¨çš„å¥´éš¶ã€‚æˆ‘ä»¬ä¸æ˜¯åœ¨é€‰æ‹©ï¼Œè€Œæ˜¯åœ¨æœä»ã€‚ä½†äººä¹‹æ‰€ä»¥ä¸ºäººï¼Œ å°±åœ¨äºï¼Œäººä¸æ˜¯è¢«æ¬²æœ›ä¸»å®°ï¼Œè€Œæ˜¯è‡ªæˆ‘ä¸»å®°ã€‚ â€”åº·å¾·</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†23</title>
    <url>/2019/06/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8623/</url>
    <content><![CDATA[<h3 id="NAS"><a href="#NAS" class="headerlink" title="[NAS]"></a>[NAS]</h3><p>å…³äºNAS(Neural Architecture Search)çš„ç§‘æ™®æ–‡ã€‚<br><a href="https://medium.com/@ashiqbuet14/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136" target="_blank" rel="noopener">https://medium.com/@ashiqbuet14/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136</a></p>
<p><img src="/images/15612604991653.jpg" width="60%" height="50%"></p>
<p><strong>Search space</strong>ï¼šå°±æ˜¯ä¸€ä¸ªæ¥ä¸€ä¸ªçš„layerï¼Œä¹Ÿå¯ä»¥åŒ…æ‹¬skip connectionï¼›</p>
<p><img src="/images/15612605302179.jpg" width="60%" height="50%"></p>
<p>å¦‚æœå¸Œæœ›å¤§çš„æ¡†æ¶å®šå¥½ï¼Œåªæ˜¯é‡Œé¢çš„layeræœç´¢ï¼Œè¿™ç§°ä¸ºmicro-searchã€‚</p>
<p><strong>RL</strong>ï¼šå¯ä»¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥åšNASï¼Œä»¥RNNä¸ºåŸºæœ¬æ¨¡å‹ã€‚</p>
<p><img src="/images/15612606028985.jpg" width="77%" height="50%"></p>
<p>å…¶å®å°±æ˜¯æ¯ä¸ªè¾“å‡ºæŒ‡ç¤ºä¸€ä¸ªlayeré€‰é¡¹ï¼Œç„¶åé€šè¿‡RLè·å¾—çš„rewardæ¥æ›´æ–°ã€‚</p>
<p><img src="/images/15612606279730.jpg" width="65%" height="50%"></p>
<p><strong>Progressive Neural Architecture Search(PNAS)</strong>ï¼šè¿™å°±æ˜¯å‰é¢æåˆ°çš„å›ºå®šæ•´ä¸ªå¤§çš„æ¡†æ¶ï¼ˆblockï¼‰ï¼Œç„¶åæœç´¢é‡Œé¢çš„layerã€‚</p>
<p><img src="/images/15612606813899.jpg" width="70%" height="50%"></p>
<p><img src="/images/15612606939857.jpg" width="40%" height="50%"></p>
<p><img src="/images/15612607076908.jpg" width="68%" height="50%"></p>
<p>å¯ä»¥é€šè¿‡æ¯å±‚é€‰å®Œå»æ‰ä¸€äº›é€‰é¡¹æ¥å‡å°‘æ’åˆ—ç»„åˆå·¨å¤§çš„æ€»æ•°ã€‚</p>
<p><strong>Differentiable Architecture Search(DARTS)</strong>ï¼šå°†é€‰æ‹©layerçš„discreteçš„åŠ¨ä½œå˜æˆè¿ç»­çš„ï¼Œä½¿å¾—èƒ½å¤Ÿé€šè¿‡æ±‚å¯¼çš„æ–¹å¼æ›´æ–°ã€‚</p>
<p>å…¶æœ¬è´¨å°±æ˜¯ä¸¤ä¸ªnodeä¹‹é—´è¿å¤šä¸ªoperationï¼Œç„¶åè®­ç»ƒè·å¾—æ¯ä¸ªoperationçš„æ¯”ä¾‹ï¼Œåªä¿ç•™æœ€å¤§çš„ã€‚</p>
<p><img src="/images/15612607664055.jpg" width="40%" height="50%"></p>
<p><img src="/images/15612607797249.jpg" width="80%" height="50%"></p>
<p>è¿™ä¸ªç”¨è¿ç»­æ¥è¾¾åˆ°ç¦»æ•£çš„åšæ³•è¿˜æŒºæœ‰åˆ›æ–°çš„ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 7:Sparse Reward</title>
    <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%207:%20Sparse%20Reward/</url>
    <content><![CDATA[<p>è®¨è®ºäº†å½“RLé‡åˆ°sparse rewardæ—¶çš„å‡ ä¸ªè§£å†³æ–¹æ¡ˆã€‚</p>
<h2 id="Reward-Shaping"><a href="#Reward-Shaping" class="headerlink" title="Reward Shaping"></a>Reward Shaping</h2><h3 id="hand-crafted"><a href="#hand-crafted" class="headerlink" title="hand-crafted"></a>hand-crafted</h3><p>ä¹Ÿå³è™šæ„å‡ºrewardå¼•å¯¼agentèµ°å‘è‡ªå·±æœŸæœ›çš„ç»“æœã€‚</p>
<p><img src="/images/15612581947292.jpg" width="80%" height="50%"></p>
<p>å¦‚ä¸Šå›¾ï¼Œä»”ç»†å®šä¹‰äº†æ¸¸æˆä¸­æ¯ä¸ªæ“ä½œçš„rewardã€‚</p>
<h3 id="Curiosity"><a href="#Curiosity" class="headerlink" title="Curiosity"></a>Curiosity</h3><p>å¾€agenté‡Œæ·»åŠ å¥½å¥‡å¿ƒã€‚</p>
<p><img src="/images/15612582253155.jpg" width="60%" height="50%"></p>
<p>è¾“å…¥æ˜¯$a_t$å’Œ$s_t$å°è¯•é¢„æµ‹å‡º$s_{t+1}$ï¼Œå¦‚æœé¢„æµ‹çš„å’ŒçœŸå®çš„å·®è·è¾ƒå¤§æ—¶ï¼Œåˆ™è¯¥actionçš„rewardå¤§ï¼Œè¿™æ ·èƒ½å¤Ÿé¼“åŠ±agentæ¢ç´¢æ›´å¤šçš„æ“ä½œã€‚</p>
<p><img src="/images/15612583393730.jpg" width="60%" height="50%"></p>
<p>ä½†æœ‰æ—¶å€™éš¾ä»¥é¢„æµ‹çš„stateå¹¶ä¸ä»£è¡¨å…¶é‡è¦ã€‚åº”å½“è¿‡æ»¤æ‰è¿™æ ·çš„stateï¼Œæ¯”å¦‚æ¸¸æˆä¸­æ ‘å¶é£˜åŠ¨ï¼Œä½†è¿™ä¸ªstateå®Œå…¨ä¸é‡è¦ã€‚å› æ­¤å¯¹ä¸Šè¿°æ¨¡å‹è¿›è¡Œæ”¹è¿›ï¼š</p>
<p><img src="/images/15612583648401.jpg" width="60%" height="50%"></p>
<p>æ·»åŠ feature extractorï¼ŒåŒæ—¶æ·»åŠ å¦ä¸€ä¸ªç½‘ç»œï¼Œæ¥é€šè¿‡$s_t$å’Œ$s_{t+1}$é¢„æµ‹actionï¼Œè¿™æ ·å°±èƒ½å¤Ÿè¿‡æ»¤æ‰stateä¸­æ²¡æ„ä¹‰çš„éƒ¨åˆ†ã€‚</p>
<h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h2><p>ä»ç®€å•çš„å¼€å§‹å­¦èµ·ï¼Œæ¯”å¦‚ç©æ¸¸æˆçš„ä¾‹å­ï¼š</p>
<p><img src="/images/15612584604093.jpg" width="74%" height="50%"></p>
<p>è¿™ä¸ªéœ€è¦äººå·¥è¾ƒä¸ºç²¾ç»†çš„è°ƒæ•´ã€‚</p>
<h3 id="Reverse-Curriculum-Generation"><a href="#Reverse-Curriculum-Generation" class="headerlink" title="Reverse Curriculum Generation"></a>Reverse Curriculum Generation</h3><p>é¦–å…ˆç»™å®šä¸€ä¸ªgold stateï¼Œä¹Ÿå³ç›®æ ‡ï¼Œç„¶åå¯»æ‰¾ä¸gold stateæœ€æ¥è¿‘çš„stateè·å¾—ç›¸åº”çš„rewardã€‚</p>
<p><img src="/images/15612585028635.jpg" width="40%" height="50%"></p>
<p>ç„¶åå»æ‰rewardå¤ªå¤§æˆ–å¤ªå°çš„ã€‚åœ¨ç•™ä¸‹æ¥çš„stateä¸­å†è·å–ä¸ä»–ä»¬æ¥è¿‘çš„stateï¼Œç»§ç»­ä»¥ä¸Šæµç¨‹ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Sparse Reward</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 6:Actor-Critic</title>
    <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%206:%20Actor-Critic/</url>
    <content><![CDATA[<p>ä»‹ç»äº†actor-criticçš„ç®—æ³•ï¼Œç»“åˆäº†policy gradientå’ŒQ-learningã€‚</p>
<h2 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h2><p>åŸå…ˆpolicy gradientçš„ç®—æ³•æ˜¯ç›´æ¥å­¦ä¹ ä¸€ä¸ªpolicyï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n}-b\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ä½†æ˜¾ç„¶rewardæ˜¯ä¸ç¨³å®šçš„ï¼Œå®ƒä»£è¡¨äº†é‡‡å–actionä¹‹åçš„rewardçš„æœŸæœ›å€¼ï¼Œå½“sampleæ¬¡æ•°ä¸å¤Ÿå¤šï¼Œå…¶é¢„ä¼°çš„ä¹Ÿä¸å‡†ã€‚</p>
<p>å› æ­¤åœ¨è¿™é‡Œå°†Q-learningå¼•å…¥åˆ°é¢„ä¼°rewardä¸­ï¼Œä¹Ÿå³policy gradientå’Œq-learningçš„ç»“åˆã€‚</p>
<p>ä¹Ÿå³æˆ‘ä»¬å°†rewardæ›¿æ¢æˆ$E\left[G_{t}^{n}\right]=Q^{\pi_{\theta}}\left(s_{t}^{n}, a_{t}^{n}\right)$ã€‚åŒæ—¶æ ¹æ®baselineçš„å®šä¹‰ï¼Œæˆ‘ä»¬å°†å…¶æ›¿æ¢æˆ$V^{\pi_{\theta}}\left(s_{t}^{n}\right)$ã€‚</p>
<p>æ‰€ä»¥æ‹¬å·å†…çš„$\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n}-b$å°±å˜æˆ$Q^{\pi \theta}\left(s_{t}^{n}, a_{t}^{n}\right)-V^{\pi_{\theta}}\left(s_{t}^{n}\right)$ã€‚</p>
<p>å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦åˆ†åˆ«è®­ç»ƒä¸¤ä¸ªç½‘ç»œï¼Œç›´æ¥æ•´åˆæˆä¸€ä¸ªç½‘ç»œå³å¯ã€‚ä¹Ÿå³å°†$Q^{\pi \theta}\left(s_{t}^{n}, a_{t}^{n}\right)-V^{\pi_{\theta}}\left(s_{t}^{n}\right)$æ”¹æˆ$r_{t}^{n}+V^{\pi}\left(s_{t+1}^{n}\right)-V^{\pi}\left(s_{t}^{n}\right)$ã€‚</p>
<p>å› æ­¤æ•´ä¸ªæµç¨‹ï¼š</p>
<p><img src="/images/15612575693660.jpg" width="40%" height="50%"></p>
<p>å½¢å¼åŒ–ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(r_{t}^{n}+V^{\pi}\left(s_{t+1}^{n}\right)-V^{\pi}\left(s_{t}^{n}\right)\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ç”±äº$\pi$å’Œ$V$çš„è¾“å…¥éƒ½æ˜¯$s$ï¼Œåœ¨å®é™…æ“ä½œä¸­å¯ä»¥å°†è¿™ä¸¤ä¸ªç½‘ç»œçš„å‰å‡ å±‚å‚æ•°å…±äº«ï¼š</p>
<p><img src="/images/15612576221669.jpg" width="50%" height="50%"></p>
<p>åŒæ—¶å¯¹$\pi$çš„è¾“å‡ºåŠ ä»¥é™åˆ¶ï¼Œå¸Œæœ›æœ‰æ›´å¤§çš„entropyï¼Œè¿™æ ·èƒ½å¤Ÿæ¢ç´¢æ›´å¤šæƒ…å†µã€‚</p>
<h2 id="Pathwise-Derivative-Policy-Gradient"><a href="#Pathwise-Derivative-Policy-Gradient" class="headerlink" title="Pathwise Derivative Policy Gradient"></a>Pathwise Derivative Policy Gradient</h2><p>æ¥ä¸‹æ¥ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç›´æ¥å­¦ä¹ ä¸€ä¸ª$\pi$ï¼Œè¾“å…¥$s$å¯ä»¥è·å¾—èƒ½å¤Ÿæœ€å¤§åŒ–Qçš„actionã€‚è¿™å’ŒGANçš„æ€æƒ³å¾ˆç›¸ä¼¼ã€‚</p>
<p><img src="/images/15612577121214.jpg" width="60%" height="50%"></p>
<p>è¿™æ ·$\pi$å¤©ç„¶åœ°èƒ½å¤Ÿå¤„ç†continuousçš„æƒ…å†µã€‚</p>
<p>æ‰€ä»¥æ•´ä¸ªæµç¨‹ï¼š</p>
<p><img src="/images/15612577508356.jpg" width="55%" height="50%"></p>
<p>å…ˆäº¤äº’ï¼Œå­¦ä¹ ä¸€ä¸ªå¥½çš„$Q$ï¼Œç„¶åå°†è¿™ä¸ª$Q$ä½œä¸ºæ ‡å‡†ï¼Œå­¦ä¹ $\pi$ä½¿å¾—è¾“å‡ºçš„$Q$æœ€å¤§ã€‚å’ŒGANå¾ˆåƒã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Actor-Critic</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 5:Q-learning (Continuous Action)</title>
    <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%205:%20Q-learning%20(Continuous%20Action)/</url>
    <content><![CDATA[<p>è®¨è®ºäº†å¦‚ä½•å°†Q-learningç”¨äºè¿ç»­çš„actionä¸­ã€‚</p>
<p>å‰é¢æåˆ° Q-learningå°±æ˜¯ï¼š</p>
<script type="math/tex; mode=display">a=\arg \max _{a} Q(s, a)</script><p>è‹¥aæ˜¯è¿ç»­çš„ï¼Œå‡ ç§è§£å†³æ–¹æ¡ˆï¼š</p>
<p>â‘ sampleä¸€å †action$\left\{a_{1}, a_{2}, \cdots, a_{N}\right\}$ï¼Œç„¶åæŒ‰ç…§discreteçš„æƒ…å†µæ¥å¤„ç†ã€‚ä½†ç²¾åº¦ä¸é«˜ï¼Œå› ä¸ºæ²¡æ³•sampleå¤ªå¤šæƒ…å†µã€‚</p>
<p>â‘¡ä½¿ç”¨gradient ascentæ¥è®¡ç®—å¤„ç†ä¸Šå¼ã€‚è¯¥æ–¹æ³•æ˜¾ç„¶å¤ªè€—æ—¶ï¼Œå› ä¸ºæ¯ä¸ªsampleéƒ½ç­‰äºè¦è®­ç»ƒä¸€éæ¨¡å‹ã€‚</p>
<p>â‘¢è®¾è®¡ä¸“é—¨çš„ç½‘ç»œä½¿å¾—è¯¥ä¼˜åŒ–å¯è¡Œã€‚<br>é¦–å…ˆè¾“å…¥stateï¼š</p>
<p><img src="/images/15612569949700.jpg" width="60%" height="50%"></p>
<p>è·å¾—ä¸€ä¸ª$\mu$ï¼Œ$\Sigma$å’Œ$V$ã€‚æ¥ç€å’Œactionäº¤äº’ï¼š</p>
<script type="math/tex; mode=display">Q(s, a)=-(a-\mu(s))^{T} \Sigma(s)(a-\mu(s))+V(s)</script><p>æ˜¾ç„¶,ç¬¬ä¸€é¡¹è‹¥$\Sigma$åŠæ­£å®šï¼Œå¿…å®šå°äºç­‰äº0ï¼Œæ‰€ä»¥å½“$a=\mu(s)$æ—¶$Q$æœ€å¤§ã€‚å®é™…ä¸Š$\Sigma$æ˜¯é€šè¿‡å…ˆè·å¾—ä¸€ä¸ªçŸ©é˜µ$A$ï¼Œç„¶å$A\times A^{T}$ä¿è¯å…¶æ­£å®šæ€§ã€‚</p>
<p>å› æ­¤ï¼š</p>
<script type="math/tex; mode=display">\mu(s)=\arg \max _{a} Q(s, a)</script><p>â‘£åˆ«ç”¨Q-learningå¤„ç†è¿ç»­çš„æƒ…å†µï¼Œå› ä¸ºå¤„ç†è¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦çš„ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Q-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 4:Q-learning (Advanced Tips)</title>
    <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%204:%20Q-learning%20(Advanced%20Tips)/</url>
    <content><![CDATA[<p>ä»‹ç»ä¸€äº›è¿›é˜¶çš„Q-learning tipsï¼Œèƒ½å¤Ÿå¸®åŠ©Q-learningæå‡è¡¨ç°ã€‚</p>
<h3 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h3><p>å‘ç°Q-valueæ€»æ˜¯å®¹æ˜“è¢«é«˜ä¼°ï¼ŒåŸå› æ˜¯ç®—æ³•ä¸­æœ‰$Q\left(s_{t}, a_{t}\right)=r_{t}+\max _{a} Q\left(s_{t+1}, a\right)$ã€‚è¯¥å…¬å¼çš„maxä½¿å¾—$Q$æ€»æ˜¯é€‰æ‹©æœ€å¤§çš„actionï¼Œä½¿å¾—$Q$çš„æ‹Ÿåˆæ€»æ˜¯åå¤§ã€‚</p>
<p><img src="/images/15612561913726.jpg" width="40%" height="50%"></p>
<p>é‚£ä¹ˆåœ¨è¿™é‡Œå¤šåŠ ä¸€ä¸ª$Q^{\prime}$ä»¥è§„é¿ä¸Šè¿°æƒ…å†µï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">Q\left(s_{t}, a_{t}\right)=r_{t}+Q^{\prime}\left(s_{t+1}, \arg \max _{a} Q\left(s_{t+1}, a\right)\right)</script><p>è‹¥$Q$é«˜ä¼°äº†aï¼Œ$Q^{\prime}$ä¸é«˜ä¼°é‚£ä¹ˆ$Q^{\prime}$çš„å€¼ä¹Ÿä¸ä¼šé‚£ä¹ˆå¤§åˆ™å·¦å¼çš„å€¼å°±ä¸ä¼šè¢«é«˜ä¼°ï¼›è‹¥$Q^{\prime}$å¯¹æŸä¸ªactioné«˜ä¼°äº†ï¼Œåªè¦$Q$ä¸é«˜ä¼°è¯¥actionï¼Œé‚£ä¹ˆä¹Ÿä¸ä¼šé€‰æ‹©è¯¥actionã€‚</p>
<h3 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h3><p>å°†æ¨¡å‹ç»“æ„åšäº†æ”¹å˜ï¼š</p>
<p><img src="/images/15612563207080.jpg" width="60%" height="50%"></p>
<p>ä¹Ÿå³å°†$Q$åˆ†ç¦»å¼€æ¥ã€‚ä¸€ç§è§£é‡Šæ˜¯è¿™æ ·çš„åˆ†ç¦»å¯ä»¥ä½¿å¾—æ•°æ®çš„ä½¿ç”¨æ›´æœ‰æ•ˆç‡ï¼Œä½¿å¾—æ¨¡å‹æ›´ä¸ºçµæ´»ã€‚è¯¾ä»¶ä¸Šè¿˜ä¸¾äº†ä¸€ä¸ªä¾‹å­ã€‚ åŒæ—¶è¿˜å¯ä»¥å¯¹$A$åŠ ä¸€äº›é™åˆ¶ï¼Œæ¯”å¦‚å‘é‡å’Œä¸º0ã€‚</p>
<h3 id="Prioritized-Reply"><a href="#Prioritized-Reply" class="headerlink" title="Prioritized Reply"></a>Prioritized Reply</h3><p>å¯¹replay bufferè¿›è¡Œæ”¹è¿›ã€‚å¯¹TD errorè¾ƒå¤§çš„ä¼˜å…ˆsampleï¼Œä¹Ÿå³å¯¹é‚£äº›å­¦å¾—ä¸å¥½çš„exampleä¼˜å…ˆå­¦ä¹ ã€‚</p>
<h3 id="Multi-step"><a href="#Multi-step" class="headerlink" title="Multi-step"></a>Multi-step</h3><p>å°†MCå’ŒTDç»¼åˆèµ·æ¥ã€‚ç»™å®š$\left(s_{t}, a_{t}, r_{t}, \cdots, s_{t+N}, a_{t+N}, r_{t+N}, s_{t+N+1}\right)$ï¼Œæœ‰ï¼š</p>
<p><img src="/images/15612565388930.jpg" width="65%" height="50%"></p>
<p>ä¹Ÿå³ä»‹äºMCçš„æ•´ä¸ªepisodeå®Œæˆåå†è®¡ç®—å’ŒTDçš„æ¯ä¸ªstepéƒ½è®¡ç®—ä¸€æ¬¡ã€‚</p>
<h3 id="Noisy-Net"><a href="#Noisy-Net" class="headerlink" title="Noisy Net"></a>Noisy Net</h3><p>epsilon greedyä¹Ÿå¯ä»¥çœ‹åšæ˜¯åŠ å™ªå£°ï¼Œä½†æ˜¯æ˜¯åŠ åœ¨actionä¸Šï¼š</p>
<script type="math/tex; mode=display">a=\left\{\begin{aligned} \arg \max _{a} Q(s, a), & \text {with probability } 1-\varepsilon \\ \text {random}, & \text { otherwise } \end{aligned}\right.</script><p>è¿™æ ·ä½¿å¾—æ¨¡å‹çš„è¡Œä¸ºä¸ä¸€è‡´ï¼Œå¯èƒ½ä¸å¤§å¥½ã€‚</p>
<p>è€ŒNoisy Netæ˜¯åœ¨parameterä¸ŠåŠ å™ªå£°ã€‚ä¹Ÿå³åœ¨episodeå¼€å§‹ä¹‹å‰å¯¹$Q$åŠ å™ªå£°ï¼Œå˜æˆ$\tilde{Q}$ï¼š</p>
<script type="math/tex; mode=display">a=\arg \max _{a} \tilde{Q}(s, a)</script><p>è€Œåœ¨episodeæœŸé—´ä¸ä¼šæ”¹å˜noiseã€‚è¿™æ ·æ›´æœ‰ç³»ç»Ÿæ€§çš„æ¢ç´¢å¯èƒ½ä¼šæ›´å¥½ï¼Œå› ä¸ºæ¨¡å‹è¡Œä¸ºä¸€è‡´ã€‚</p>
<h3 id="Distributional-Q-function"><a href="#Distributional-Q-function" class="headerlink" title="Distributional Q-function"></a>Distributional Q-function</h3><p>åŸºæœ¬æ€æƒ³æ˜¯ä»¤$Q$é¢„æµ‹æ¯ä¸ªè¡Œä¸ºçš„rewardçš„åˆ†å¸ƒè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªæœŸæœ›å€¼ã€‚å› ä¸ºæœŸæœ›å€¼æŸå¤±äº†å¤ªå¤šä¿¡æ¯äº†ï¼Œä¸åŒçš„distributionå¯èƒ½æœ‰åŒæ ·å¤§å°çš„æœŸæœ›ã€‚</p>
<p><img src="/images/15612567428631.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Šæ“ä½œä¹Ÿå³ï¼š</p>
<p><img src="/images/15612567546608.jpg" width="60%" height="50%"></p>
<p>Distributional Q-functionå¾€å¾€ä¸ä¼šé«˜ä¼°expectationè€Œæ˜¯ä½ä¼°ã€‚å› ä¸ºåœ¨é¢„æµ‹distributionæ—¶å·²ç»é™å®šäº†æœ€é«˜å’Œæœ€ä½çš„èŒƒå›´äº†ï¼Œå¯¹äºé‚£äº›å¤§äºæˆ–å°äºçš„å€¼éƒ½å¿½ç•¥æ‰ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Q-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 3:Q-learning (Basic Idea)</title>
    <url>/2019/06/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%203:%20Q-learning%20(Basic%20Idea)/</url>
    <content><![CDATA[<p>ç®€å•ä»‹ç»Q-learningçš„æ€æƒ³ä»¥åŠç›¸å…³çš„è®­ç»ƒtipsã€‚</p>
<h3 id="æ˜¯ä»€ä¹ˆ"><a href="#æ˜¯ä»€ä¹ˆ" class="headerlink" title="æ˜¯ä»€ä¹ˆ"></a>æ˜¯ä»€ä¹ˆ</h3><p>ä¸Policy Gradientä¸åŒçš„æ˜¯ï¼ŒQ-Learningæ˜¯å±äºvalue basedï¼Œä¹Ÿå³å­¦ä¹ ä¸€ä¸ªcriticå»ä¼°è®¡ç‰¹å®šactor Ï€åœ¨æŸä¸ªstate sä¸‹çš„ç´¯ç§¯rewardã€‚</p>
<p>æ³¨æ„åˆ°Q-learningè™½ç„¶åªå­¦ä¹ äº†criticï¼Œä½†ä»ç„¶å¯ä»¥ç”¨äºåšå†³ç­–ã€‚</p>
<p>é¦–å…ˆæ˜¯å¦‚ä½•é¢„ä¼°criticï¼Ÿ<br>criticçš„æœ¬è´¨å°±æ˜¯å‡½æ•°æ˜ å°„$V^{\pi}(s)$ï¼Œè¾“å…¥$s$ï¼Œè¾“å‡ºä¸€ä¸ªscalarä½œä¸ºä½¿ç”¨äº†actor $\pi$çš„ç´¯ç§¯rewardã€‚æœ‰ä¸¤ç§æ–¹æ³•ï¼šMonte-Carlo (MC) based approachå’ŒTemporal-difference (TD) approachã€‚</p>
<h4 id="Monte-Carlo-MC-based-approach"><a href="#Monte-Carlo-MC-based-approach" class="headerlink" title="Monte-Carlo (MC) based approach"></a>Monte-Carlo (MC) based approach</h4><p>criticçœ‹å®Œæ•´ä¸ªepisodeï¼Œç„¶åå¯¹$s$åšå‡ºé¢„ä¼°ï¼š</p>
<p><img src="/images/15612136873633.jpg" width="35%" height="50%"></p>
<p>å…¶å®è´¨ä¸Šå°±æ˜¯åœ¨åšregressionã€‚</p>
<h4 id="Temporal-difference-TD-approach"><a href="#Temporal-difference-TD-approach" class="headerlink" title="Temporal-difference (TD) approach"></a>Temporal-difference (TD) approach</h4><p>ç”±äºæœ‰äº›episodeéå¸¸é•¿ï¼Œç­‰è·‘å®Œå†é¢„ä¼°æ•ˆç‡å¤ªä½ï¼Œå› æ­¤ç›´æ¥å¯¹æ¯ä¸ªstepè¿›è¡Œé¢„ä¼°ã€‚<br>å¯¹äºä¸€ä¸ªtime step $\cdots s_{t}, a_{t}, r_{t}, s_{t+1} \cdots$ï¼Œç›´æ¥é¢„ä¼°ï¼š</p>
<p><img src="/images/15612137939102.jpg" width="70%" height="50%"></p>
<p>ä»‹ç»å®Œ$V^{\pi}(s)$ï¼Œè¿˜æœ‰ä¸€ç§criticï¼Œè¾“å…¥$s$å’Œ$a$ä»¥è·å¾—ä¸€ä¸ªç´¯ç§¯rewardã€‚è¿™é‡Œå’Œ$V^{\pi}(s)$ä¸åŒçš„æ˜¯ï¼Œå¯¹äºåŒä¸€ä¸ªÏ€ï¼Œèƒ½å¤Ÿè¯„ä¼°å¼ºåˆ¶é‡‡ç”¨$a$æ‰€è·å¾—çš„rewardã€‚</p>
<p><img src="/images/15612139717700.jpg" width="70%" height="50%"></p>
<h3 id="å¦‚ä½•ä½¿ç”¨criticå†³ç­–"><a href="#å¦‚ä½•ä½¿ç”¨criticå†³ç­–" class="headerlink" title="å¦‚ä½•ä½¿ç”¨criticå†³ç­–"></a>å¦‚ä½•ä½¿ç”¨criticå†³ç­–</h3><p>åœ¨è®­ç»ƒå®Œäº†ä¸€ä¸ªcriticï¼Œå¦‚ä½•ç”¨äºè¿›è¡Œå†³ç­–ï¼Ÿ</p>
<p>å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šç»™å®š$Q$ï¼Œæ€»èƒ½æ‰¾åˆ°ä¸€ä¸ª$\pi^{\prime}$ æ¯”$\pi$å¥½ï¼Œä¹Ÿå³$V^{\pi^{\prime}}(s) \geq V^{\pi}(s)$ã€‚å½¢å¼åŒ–ï¼š</p>
<script type="math/tex; mode=display">\pi^{\prime}(s)=\arg \max _{a} Q^{\pi}(s, a)</script><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨å­¦ä¹ å®Œä¸€ä¸ªç‰¹å®š$\pi$å¯¹åº”çš„$Q$åï¼Œåªéœ€è¦éµç…§æ¯é‡åˆ°ä¸€ä¸ªstateï¼Œé€‰æ‹©èƒ½ä½¿$Q$æœ€å¤§åŒ–çš„actionï¼Œè¯¥æ–°çš„$\pi$å°±ä¼šæ¯”åŸæ¥çš„$\pi$æ›´ä¼˜ã€‚</p>
<p>ä¸ºä»€ä¹ˆä¸€å®šä¼šæ›´ä¼˜ã€‚æä¾›è¯æ˜ï¼š</p>
<p><img src="/images/15612142985976.jpg" width="60%" height="50%"></p>
<p>æ¯ä¸€æ­¥é€‰æ‹©æœ€ä¼˜éƒ½ä¼šæ¯”åŸæ¥å¥½ä¸€äº›ã€‚</p>
<h3 id="å¦‚ä½•è®­ç»ƒQ-function"><a href="#å¦‚ä½•è®­ç»ƒQ-function" class="headerlink" title="å¦‚ä½•è®­ç»ƒQ function"></a>å¦‚ä½•è®­ç»ƒQ function</h3><p>æˆ‘ä»¬é€šè¿‡ç±»ä¼¼TDçš„æ–¹æ³•æ¥è®­ç»ƒã€‚ç»™å®š$\cdots s_{t}, a_{t}, r_{t}, s_{t+1} \cdots$,æˆ‘ä»¬æœ‰ï¼š</p>
<script type="math/tex; mode=display">\mathrm{Q}^{\pi}\left(s_{t}, a_{t}\right)=r_{t}+\mathrm{Q}^{\pi}\left(s_{t+1}, \pi\left(s_{t+1}\right)\right)</script><p>å…¶ä¸­ç”±äºå…¬å¼æœ‰ä¸¤ä¸ªQï¼Œè‹¥è®©ä¸¤ä¸ªQåŒæ—¶å˜ï¼Œä¸å¥½åšå›å½’ã€‚å› æ­¤æˆ‘ä»¬è®©å³è¾¹çš„Qå›ºå®šä½ï¼Œè®­ç»ƒå·¦è¾¹çš„Qï¼Œåœ¨æ›´æ–°å®Œå‡ æ¬¡åï¼Œç›´æ¥å°†å·¦è¾¹çš„Qè¦†ç›–å³è¾¹ã€‚é‡å¤å¤šæ¬¡ï¼š</p>
<p><img src="/images/15612553664628.jpg" width="65%" height="50%"></p>
<p>å¦ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚ä½•æ”¶é›†æ•°æ®ï¼Ÿ</p>
<p>ç”±äºactionæ˜¯åŸºäºQå‡½æ•°çš„ï¼Œä¹Ÿå³æ¯æ¬¡éƒ½é‡‡ç”¨è´ªå¿ƒçš„ç­–ç•¥ï¼Œä¼šä½¿å¾—åœ¨åˆå§‹æƒ…å†µä¸‹å›ºå®šçš„actionä¼šä¸€ç›´å‡ºç°ï¼Œæ— æ³•æ¢ç´¢åˆ°å…¶ä»–æƒ…å†µã€‚å› æ­¤é‡‡ç”¨ä¸¤ç§ç­–ç•¥ï¼š</p>
<p>â‘ epsilon greedyï¼š</p>
<script type="math/tex; mode=display">a=\left\{\begin{aligned} \arg \max _{a} Q(s, a), & \text { with probability } 1-\varepsilon \\ \text {random}, & \text { otherwise } \end{aligned}\right.</script><p>å…¶ä¸­$\varepsilon$éšç€æ—¶é—´è€Œé€æ¸å˜å°ã€‚</p>
<p>â‘¡boltzmann explorationï¼š<br>æŒ‰æ¦‚ç‡é‡‡æ ·</p>
<script type="math/tex; mode=display">P(a | s)=\frac{\exp (Q(s, a))}{\sum_{a} \exp (Q(s, a))}</script><p>è¿˜æœ‰ä¸€ä¸ªå°æŠ€å·§ç”¨äºæ›´å¥½åˆ©ç”¨sampleï¼Œä¹Ÿå³replay bufferï¼šå°†æ¯æ¬¡Ï€ä¸ç¯å¢ƒäº¤äº’çš„episodeéƒ½æ”¾åœ¨ä¸€ä¸ªbufferé‡Œé¢ï¼Œå¯ä»¥éƒ½ç”¨æ¥å­¦ä¹ Qå‡½æ•°ï¼Œå³ä½¿æ•°æ®æ¥è‡ªä¸åŒçš„policyä¹Ÿæ²¡å…³ç³»ã€‚è¿™å’Œoff-policyæœ‰ç‚¹åƒã€‚ä¸ºä»€ä¹ˆå¯ä»¥è¿™ä¹ˆç”¨ä¸€ç§è§£é‡Šæ˜¯è¿™æ ·å¯ä»¥ä½¿å¾—æ•°æ®æ›´diverseï¼ŒåŒæ—¶å‡å°‘sampleæ¬¡æ•°åŠ å¿«è®­ç»ƒã€‚</p>
<p><img src="/images/15612559617307.jpg" width="40%" height="50%"></p>
<p>å› æ­¤ä¸€ä¸ªå…¸å‹çš„q-learningåˆ™æ˜¯ï¼š</p>
<p><img src="/images/15612560018865.jpg" width="60%" height="50%"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Q-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡22</title>
    <url>/2019/06/22/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8722/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Boosting Neural Machine Translation</li>
<li>Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks</li>
<li>On The Power of Curriculum Learning in Training Deep Networks</li>
<li>XLNet: Generalized Autoregressive Pretraining for Language Understanding</li>
<li>An Empirical Exploration of Curriculum Learning for Neural Machine Translation</li>
</ol>
<h2 id="Boosting-Neural-Machine-Translation"><a href="#Boosting-Neural-Machine-Translation" class="headerlink" title="[Boosting Neural Machine Translation]"></a>[Boosting Neural Machine Translation]</h2><p>é€šè¿‡å°†æœºå™¨å­¦ä¹ ä¸­çš„boostingå¼•å…¥NMTï¼Œå¯¹ç¿»è¯‘æ•ˆæœæœ‰ä¸€å®šæå‡ã€‚åŒæ—¶è¿˜æå‡ºäº†å¦å¤–å‡ ç§æ–¹æ³•ï¼Œå¯¹è¾“å…¥æ•°æ®pipelineè¿›è¡Œäº†ä¿®æ”¹ï¼Œå‘ç°éƒ½æœ‰ä¸€å®šçš„æå‡ã€‚æœ¬æ–‡çš„ä¸­å¿ƒæ€æƒ³å°±æ˜¯focus on difficult examplesï¼Œä½œè€…è®¤ä¸ºæ›´å¤šå…³æ³¨äºdifficult exampleï¼Œèƒ½å¤Ÿå¯¹æ¨¡å‹æœ‰æå‡çš„ä½œç”¨ã€‚</p>
<h3 id="å‡ ç§policy"><a href="#å‡ ç§policy" class="headerlink" title="å‡ ç§policy"></a>å‡ ç§policy</h3><p><img src="/images/15611921654433.jpg" width="40%" height="50%"></p>
<p>originalï¼šå°±æ˜¯å°†æ‰€æœ‰çš„æ•°æ®éƒ½è¿‡ä¸€é<br>boostï¼šå°†æœ€éš¾çš„10%é‡å¤ä¸€é<br>reduceï¼šå°†æœ€ç®€å•çš„20%å»æ‰ã€‚å…·ä½“æ“ä½œæ˜¯ï¼Œæ¯ä¸ªepoché‡æ–°è¡¡é‡ä¸€æ¬¡ï¼Œæ¯ä¸‰ä¸ªepochä½œä¸ºä¸€ä¸ªè®­ç»ƒï¼Œä¹Ÿå³ä¸‰ä¸ªepochå†…éƒ¨åˆ†åˆ«ä½¿ç”¨100% 80% 64%çš„æ•°æ®<br>bootstrapï¼šæ¯ä¸ªepochéƒ½re-sampleä¸€éï¼Œä¹Ÿå³å…è®¸é‡å¤ä»¥åŠéƒ¨åˆ†å¥å­æ¶ˆå¤±ã€‚</p>
<p>éš¾åº¦æ˜¯é€šè¿‡perplexityæ¥è¡¡é‡çš„ï¼Œå› ä¸ºæ¯ä¸ªepochåœ¨è®­ç»ƒæ—¶å°±å·²ç»è®¡ç®—è¿‡perplexityäº†ï¼Œå› æ­¤æ²¡æœ‰å¼•å…¥é¢å¤–çš„è®¡ç®—å¤æ‚åº¦ã€‚</p>
<h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p>è®ºæ–‡çš„å®éªŒé‡‡ç”¨çš„æ˜¯åŒå‘LSTMä½œä¸ºç¿»è¯‘çš„æ¨¡å—ã€‚</p>
<p><img src="/images/15611922669857.jpg" width="40%" height="50%"></p>
<p><img src="/images/15611922830047.jpg" width="40%" height="50%"></p>
<p>å‡ ä¸ªå®éªŒç»“è®ºï¼š<br>boostingèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œå¹¶ä¸”ç»“æœæ›´å¥½ï¼›<br>reduceç”¨æ›´å°‘çš„æ•°æ®ï¼Œè¾¾åˆ°æœ€å¥½çš„æ•ˆæœã€‚è¿™ç‚¹ä»¤äººå°è±¡æ·±åˆ»<br>boostrapï¼Œç¨å¾®å¥½ä¸€äº›ï¼Œä¸”è®­ç»ƒæ›´ç¨³å®šã€‚</p>
<p>ä¸ºä»€ä¹ˆè¦focus on difficult example?</p>
<blockquote>
<p>We emulate a human spending additional energy on learning complex concepts<br>To force the system to pay much attention on them can adjust it towards â€œmasteringâ€ more information for these sentences.</p>
</blockquote>
<h3 id="å‡ ä¸ªæƒ³æ³•"><a href="#å‡ ä¸ªæƒ³æ³•" class="headerlink" title="å‡ ä¸ªæƒ³æ³•"></a>å‡ ä¸ªæƒ³æ³•</h3><p>è¿™ç¯‡æ–‡ç« æ˜¯ä¸€ç¯‡çŸ­æ–‡ï¼Œå¾ˆæ˜æ˜¾å¾ˆå¤šå®éªŒæ²¡åšï¼Œä¼°è®¡æ˜¯åˆ°deadlineäº†å°±æäº¤äº†ï¼Œæ¯”å¦‚åˆ†æä¸åŒæ¯”ä¾‹çš„ç»“æœï¼Œä»¥åŠä¸€äº›æ¶ˆèå®éªŒä¹Ÿæ²¡åšã€‚</p>
<p>ä¸ºä»€ä¹ˆboostrapèƒ½å¤Ÿæœ‰æå‡å¹¶ä¸”æœ‰æ›´ç¨³å®šçš„è®­ç»ƒï¼Ÿè¿™ç§resampleçš„æ–¹å¼èƒ½å¤Ÿå¸¦æ¥ä¸€å®šçš„uncertaintyï¼Œå¯èƒ½ä¼šæœ‰ä¸€å®šçš„å¸®åŠ©ï¼Œè™½ç„¶å¸®åŠ©ä¸å¤§ï¼Œè®ºæ–‡é‡Œé¢ä¹Ÿä»…ä»…æåˆ°äº†uncertaintyï¼Œæ˜¾ç„¶åº”è¯¥åšè¿›ä¸€æ­¥çš„åˆ†æã€‚</p>
<p>è¿™ç¯‡è®ºæ–‡æä¾›çš„insightæˆ‘è®¤ä¸ºè¿˜æ˜¯æœ‰ä¸€å®šå¯å‘çš„ï¼Œé¦–å…ˆè¿™å¹¶ä¸æ˜¯curriculum-learningï¼Œä¹Ÿå³æ²¡æœ‰ä»ç®€å•åˆ°éš¾ï¼Œè€Œæ˜¯æ­£å¸¸çš„è®­ç»ƒï¼Œåªä¸è¿‡é€šè¿‡å¢åŠ æ›´å¤šçš„difficult exampleï¼ŒåŒæ—¶å»æ‰äº†éƒ¨åˆ†å¤ªç®€å•çš„sampleï¼Œè¯´æ˜ä»…ä»…æ˜¯ä¿®æ”¹æ•°æ®åˆ†å¸ƒè€Œä¸æ˜¯ä¿®æ”¹æ•°æ®çš„è¾“å…¥é¡ºåºï¼ˆæœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¿®æ”¹æ•°æ®åˆ†å¸ƒï¼‰ï¼Œä¹Ÿèƒ½å¤Ÿå¸¦æ¥æå‡æ•ˆæœï¼›ç¬¬äºŒï¼Œé€šè¿‡å‡å°‘ç®€å•æ•°æ®ï¼Œæ˜¯å¦æ„å‘³ç€ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ‰ä¸€ä¸ªä¸‹é™ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¥ç»ç½‘ç»œè¿™ç§èƒ½åŠ›å¾ˆå¼ºçš„æ¨¡å‹ï¼‰ï¼Œä½è¿‡è¿™ä¸ªä¸‹é™çš„æ•°æ®å¯¹æ¨¡å‹çš„è®­ç»ƒæ˜¯æ²¡æœ‰å¸®åŠ©çš„ï¼Œåè€Œå¯èƒ½ä¼šä½¿æ¨¡å‹overfitåˆ°æŸä¸ªç®€å•çš„patternï¼ˆè¿™å’Œlearning to executeçš„ç»“è®ºä¼¼ä¹æœ‰äº›ç±»ä¼¼ï¼‰ï¼›åŒæ—¶ï¼Œå¢åŠ æ›´å¤šçš„difficult sampleï¼Œä½¿å¾—æ¨¡å‹çš„ä¸Šé™è¢«æé«˜äº†ï¼›ä»¥åŠï¼Œæ˜¯å¦å¯ä»¥å°†curriculum learningä¸è¯¥æ€è·¯ç»“åˆèµ·æ¥ï¼Œè¾¾åˆ°æ›´å¥½çš„ç»“æœï¼Œä¸€æ–¹é¢ç”±æ˜“åˆ°éš¾ï¼Œå¦ä¸€æ–¹é¢ä¿®æ”¹æ•°æ®åˆ†å¸ƒï¼Œä½¿å¾—æ¨¡å‹æ›´å¤šå…³æ³¨éš¾çš„æ•°æ®ã€‚</p>
<hr>
<h2 id="Curriculum-Learning-by-Transfer-Learning-Theory-and-Experiments-with-Deep-Networks"><a href="#Curriculum-Learning-by-Transfer-Learning-Theory-and-Experiments-with-Deep-Networks" class="headerlink" title="[Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks]"></a>[Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks]</h2><p>ICML18çš„æ–‡ç« ï¼Œæå…¶ç¡¬æ ¸ï¼Œæ ¹æœ¬çœ‹ä¸æ‡‚ç†è®ºçš„éƒ¨åˆ†ã€‚</p>
<p>å…ˆè´´å‡ºICML oralçš„ä¸‰å¼ PPTï¼š</p>
<p><img src="/images/15611926258594.jpg" width="60%" height="50%"></p>
<p><img src="/images/15611926643253.jpg" width="60%" height="50%"></p>
<p><img src="/images/15611926800604.jpg" width="60%" height="50%"></p>
<p>ä»ç†è®ºä¸Šè¯æ˜äº†ï¼š</p>
<p>â‘ the rate of convergence of an ideal curriculum learning method is monotonically increasing with the difï¬culty of the examples</p>
<p>â‘¡convergence is faster when using points which incur higher loss with respect to the current hypothesis.<br>å½“difficulty scoreæ˜¯å›ºå®šçš„ï¼Œå¯¹äºcurrent hypothesisè€Œè¨€ï¼Œé«˜çš„lossèƒ½å¤Ÿæ¯”ä½çš„lossæ‹Ÿåˆé€Ÿåº¦æ›´å¿«ã€‚è¯¥ç»“è®ºéå¸¸ç›´è§‚ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œéš¾çš„exampleæ›´æœ‰ç›Šæ˜¯é’ˆå¯¹å½“å‰è€Œè¨€ï¼ˆcurrent hypothesisï¼‰è€Œç®€å•çš„exampleæ›´æœ‰ç›Šæ˜¯é’ˆå¯¹final hypothesisè€Œè¨€çš„ã€‚</p>
<p>â‘¢ä½¿ç”¨pretrainå¥½çš„æ¨¡å‹æ¥ä½œä¸ºdifficultyçš„ä¼°è®¡ï¼Œa signiï¬cant boost in convergence speed at the beginning of training</p>
<p>â‘£ä½¿ç”¨curriculum learningèƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿæ‹Ÿåˆï¼›å½“ä»»åŠ¡éš¾åº¦ï¼ˆè¿™å’Œæ¨¡å‹æœ¬èº«çš„å®¹é‡ä¹Ÿæœ‰å…³ï¼Œæ¨¡å‹è¶Šå¼±ç›¸å¯¹çš„ä»»åŠ¡éš¾åº¦ä¹Ÿå°±è¶Šå¤§ï¼ŒåŒæ—¶ä¹Ÿå’Œregularizationç›¸å…³ï¼Œè¶Šå¼ºä»£è¡¨æ¨¡å‹çš„è‡ªç”±åº¦è¶Šå¼±ï¼‰è¶Šå¤§æ—¶ï¼Œä½¿ç”¨CLçš„æ•ˆæœå°±è¶Šæ˜æ˜¾ã€‚</p>
<p>å‡ ä¸ªç»“æœï¼š</p>
<p><img src="/images/15611928935044.jpg" width="90%" height="50%"></p>
<p><img src="/images/15611929075096.jpg" width="45%" height="50%"></p>
<p>æ€è€ƒï¼š<br>æ–‡ä¸­çš„ç»“è®ºè¿˜æ˜¯å¯ä»¥å‚è€ƒå‚è€ƒçš„ï¼Œä½†theoreticalçš„ç»“è®ºæ¯•ç«Ÿæ˜¯åœ¨å‡¸å‡½æ•°ä¸Šå¾—åˆ°çš„ï¼Œä¼¼ä¹è¯´æœåŠ›ä¸å¤§ã€‚æ–‡ä¸­çš„æ€è·¯æ˜¯ä»ç†è®ºä¸Šè¯æ˜å‡¸å‡½æ•°çš„ç»“è®ºï¼›ç„¶åé€šè¿‡å®éªŒåœ¨éå‡¸å‡½æ•°ä¸Šä»å®è·µè¯æ˜ç›¸ä¼¼ç»“è®ºã€‚å…¶ä¸»è¦çš„è´¡çŒ®åœ¨äºä¸€äº›CLç›¸å…³çš„ç»“è®ºå’Œå¼•å…¥transfer learningä½œä¸ºdifficulty scoreã€‚</p>
<hr>
<h2 id="On-The-Power-of-Curriculum-Learning-in-Training-Deep-Networks"><a href="#On-The-Power-of-Curriculum-Learning-in-Training-Deep-Networks" class="headerlink" title="[On The Power of Curriculum Learning in Training Deep Networks]"></a>[On The Power of Curriculum Learning in Training Deep Networks]</h2><p>ICML19ä¸€ç¯‡å¾ˆç¡¬æ ¸çš„æ–‡ç« ï¼Œè¯´å®è¯é‡Œé¢çš„è¯æ˜ä»¥åŠéƒ¨åˆ†å®éªŒè®¾è®¡æˆ‘è¿˜æ˜¯æ²¡æ€ä¹ˆææ‡‚ã€‚ä½†æ˜¯ä¸€äº›ç»“è®ºå€¼å¾—æ³¨æ„ã€‚è¿™å±äºæœ‰å¯å‘çš„ä¸€ç±»è®ºæ–‡ã€‚</p>
<p>é€šè¿‡transfer-learningå’Œself-taughtçš„æ–¹æ³•è·å¾—æ–°çš„curriculum-learningç®—æ³•ï¼ŒåŒæ—¶é€šè¿‡ç†è®ºè¯æ˜è·å¾—äº†ä¸€äº›æœ‰å¯å‘æ€§çš„ç»“è®ºã€‚</p>
<p>curriculum learningæœ‰ä¸¤ä¸ªæŒ‘æˆ˜ï¼š å¦‚ä½•å®šä¹‰æ•°æ®çš„éš¾åº¦ï¼›ä»¥åŠæ•°æ®å–‚ç»™æ¨¡å‹çš„é€Ÿåº¦ï¼Œå¤ªå¿«ä¼šè®©æ¨¡å‹æ›´confusedï¼Œå¤ªæ…¢å¯¼è‡´å­¦ä¹ å¤ªæ…¢</p>
<p>æœ¬æ–‡å¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜éƒ½æœ‰ä¸€å®šçš„è§£å†³æ–¹æ¡ˆï¼šåˆ†åˆ«å®šä¹‰äº†scoring function å’Œ pacing function</p>
<p>scoring functionæœ‰ä¸¤ç§ï¼štransfer learningå’Œself-tutoringï¼Œä¸€ä¸ªå°±æ˜¯pretrained modelï¼Œå¦ä¸€ä¸ªæ˜¯ä½¿ç”¨è®­ç»ƒå¥½çš„æœªé‡‡ç”¨curriculum learningçš„æ¨¡å‹ã€‚</p>
<p>pacing functionï¼šâ‘ Fixed exponential pacingæ²¡å›ºå®šæ¬¡æ•°çš„stepå°±æå‡ä¸€ä¸‹ â‘¡Varied exponential pacing æå‡çš„stepå¯ä»¥æ˜¯å˜åŒ–çš„ â‘¢Single-step pacing ç®€åŒ–ç‰ˆçš„â‘ </p>
<p><img src="/images/15611932107816.jpg" width="50%" height="50%"></p>
<p>å…³äºcurrent hypothesisä¸target hypothesisï¼š</p>
<p>æœ‰äº›æ–¹æ³•ä¸­ï¼ˆself-paced learning hard example mining æˆ– active learningï¼‰æ›´å€¾å‘äºhard exampleã€‚å®é™…ä¸Šå’ŒCLä¸åŒï¼Œæ˜¯å› ä¸ºfocus on hard exampleæ˜¯åŸºäºå½“å‰æ¨¡å‹çš„çŠ¶æ€å»å®šä¹‰éš¾åº¦çš„ï¼ˆcurrent hypothesisï¼‰ï¼ŒCLåˆ™æ˜¯åŸºäºæœ€ç»ˆçš„çŠ¶æ€ï¼ˆtarget hypothesisï¼‰ã€‚å®é™…ä¸Šè¿™ä¸¤ç§å¹¶ä¸çŸ›ç›¾ï¼Œæœ‰ç ”ç©¶è¡¨æ˜æ¨¡å‹å¯ä»¥åŒæ—¶å—ç›Šäºè¿™ä¸¤ç§ã€‚è¿™ç¯‡æ–‡ç« ä¹Ÿä»ç†è®ºè§’åº¦å»è¯æ˜äº†è¿™ä¸€ç»“è®ºã€‚</p>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>å…³äºcurriculum by transferçš„ç»“è®ºï¼š<br>Curriculum learning is clearly and signiï¬cantly beneï¬cial - learning starts faster, and converges to a better solution.<br>the observed advantage of CL is more signiï¬cant when the task is more difï¬cultï¼ˆå¾ˆç›´è§‚ï¼Œå› ä¸ºè¶Šéš¾çš„ä»»åŠ¡è¶Šéœ€è¦CLï¼‰</p>
<p>å…¶ä¸­anti-curriculumæŒ‡çš„æ˜¯æŒ‰ç…§éš¾åº¦ä»é«˜åˆ°ä½æ’ï¼›randomåˆ™æ˜¯å¯¹éš¾åº¦éšæœºæ’ï¼š</p>
<p><img src="/images/15611933223227.jpg" width="70%" height="50%"></p>
<p>å…¶ä»–ç»“è®ºï¼š</p>
<p>ä½¿ç”¨ä¸åŒçš„transfer functionéƒ½æŒ‡å‘äº†ç›¸ä¼¼çš„gradientæ–¹å‘ï¼›ä¸ä½¿ç”¨æ‰€æœ‰æ•°æ®ç›¸æ¯”ï¼Œtransfer functionåˆ™æŒ‡å‘äº†ä¸åŒçš„æ–¹å‘ï¼›åŒæ—¶ä½¿ç”¨æ‰€æœ‰æ•°æ®çš„gradientå’Œä½¿ç”¨random scoring functionçš„gradientç›¸ä¼¼ï¼Œè¯´æ˜randomèƒ½å¤Ÿè¾ƒä¸ºåˆç†çš„å»estimateçœŸæ­£çš„empirical gradientã€‚å¦‚å›¾ï¼š</p>
<p><img src="/images/15611934853212.jpg" width="65%" height="50%"></p>
<h3 id="ç†è®º"><a href="#ç†è®º" class="headerlink" title="ç†è®º"></a>ç†è®º</h3><p>ç•¥è¿‡å¤§é‡å…¬å¼ã€‚ç›´æ¥è°ˆç»“è®ºï¼š</p>
<p>â‘ é€šè¿‡CLä¿®æ”¹åçš„optimization landscapeæ‹¥æœ‰å’ŒåŸæ¥ä¸€æ ·çš„optimization functionï¼›å¹¶ä¸”ä¿®æ”¹åçš„global maximum æ¯”åŸå…ˆçš„æ›´æ˜æ˜¾ï¼ˆpronouncedï¼‰</p>
<p>â‘¡å¦‚æœæ•°æ®åˆ†å¸ƒpå’Œæœ€ä¼˜çš„utility $U_{\tilde{\vartheta}}(X)$ æ˜¯æ­£ç›¸å…³çš„ï¼Œä¸”æ¯”å…¶ä»–çš„$U_{\vartheta}(X)$æ›´æ­£ç›¸å…³ï¼Œé‚£ä¹ˆå¾€optimal parameter $\tilde{\vartheta}$ æ€»ä½“ä¸Šä¼šæ›´åŠ steeperï¼ˆé™¡å³­ï¼‰ã€‚</p>
<p>â‘¢the optimization landscape is modiï¬ed to amplify the difference between the optimal parameters vector and all other parameter values whose covariance with the optimal solution (the covariance is measured between the induced prior vectors) is small, and speciï¬cally smaller than the variance of the optimum. </p>
<h3 id="ç»“è®ºä¸æ€è€ƒ"><a href="#ç»“è®ºä¸æ€è€ƒ" class="headerlink" title="ç»“è®ºä¸æ€è€ƒ"></a>ç»“è®ºä¸æ€è€ƒ</h3><p>å°±æˆ‘çš„ç†è§£è€Œè¨€ï¼Œæœ¬æ–‡çš„æœ€å¤§è´¡çŒ®å°±æ˜¯ï¼šç»Ÿä¸€äº†åŸå…ˆçš„ä»ç®€å•åˆ°éš¾ï¼ˆcurriculum learningæˆ–self-paced learningï¼‰å’Œfocus on difficulty examplesï¼ˆboostingæˆ–hard data miningï¼‰ï¼Œåªè¦ä¿®æ”¹åçš„æ•°æ®åˆ†å¸ƒä¸optimal utilityæ˜¯æ­£ç›¸å…³çš„ï¼Œé‚£ä¹ˆå°±å¯ä»¥æå‡è¡¨ç°ï¼Œå› æ­¤ä¸¤ç§strategyéƒ½æ˜¯æœ‰æ•ˆçš„ã€‚ It may even be possible to find a curriculum which is directly correlated with the optimal utility, and that outperforms both methods</p>
<p>ä¸è¿‡è¿™ç¯‡æ–‡ç« æœ‰äº›å¥‡æ€ªï¼Œempiricalå’Œtheoreticalçš„éƒ¨åˆ†å®Œå…¨å‰²è£‚çš„æ„Ÿè§‰ã€‚</p>
<hr>
<h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="[XLNet: Generalized Autoregressive Pretraining for Language Understanding]"></a>[XLNet: Generalized Autoregressive Pretraining for Language Understanding]</h2><p>æœ€è¿‘æ¯”è¾ƒç«çš„æ–‡ç« ï¼Œå¯¹Bertçš„å…¨é¢è¶…è¶Šã€‚å°†bertçš„åŒå‘å’Œcontextä»¥åŠlanguage modelçš„long range dependencyå·§å¦™ç»“åˆï¼Œè·å¾—æ–°çš„pretrain modelã€‚</p>
<h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><p>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¯ä»¥åˆ†ä¸ºä¸¤ç§ autoregressive(AR)è¯­è¨€æ¨¡å‹å’Œ autoencodingï¼ˆAEï¼‰ã€‚ARå°±æ˜¯ä¼ ç»Ÿçš„è¯­è¨€æ¨¡å‹ï¼Œä»å‰åˆ°åæˆ–ä»ååˆ°å‰é¢„æµ‹ï¼Œå…¸å‹çš„å°±æ˜¯GPTï¼›AEåˆ™æ˜¯é€šè¿‡å—ç ´åçš„æ•°æ®è¿˜åŸå‡ºåŸå§‹æ•°æ®ï¼ŒBertå°±æ˜¯å…¶ä¸­ä¸€å‘˜ã€‚</p>
<p>ä½†è¿™ä¸¤ç§æ–¹æ³•å„æœ‰ç¼ºç‚¹ï¼š</p>
<p>bertçš„AEæ–¹æ³•å‡è®¾äº†æ‰€æœ‰è¢«é¢„æµ‹çš„tokenæ˜¯ç‹¬ç«‹çš„ï¼ˆä¹Ÿå³maskæ‰çš„è¯ç›¸äº’ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œä¹Ÿå³ä¸Šä¸€ä¸ªmaskçš„è¯å¹¶ä¸èƒ½å¯¹é¢„æµ‹ä¸‹ä¸€ä¸ªmaskçš„è¯æœ‰å¸®åŠ©ï¼‰ï¼Œä½†è‡ªç„¶è¯­è¨€ä¸­è¿™ç§ä¾èµ–å…³ç³»åº”è¯¥æ˜¯å­˜åœ¨çš„ï¼›åŒæ—¶[Mask]åœ¨çœŸå®æ•°æ®ä¸­å¹¶ä¸å­˜åœ¨ï¼Œä¹Ÿå³å­˜åœ¨input noiseï¼Œå¯¼è‡´pretrain-ï¬netune discrepancyã€‚</p>
<p>è€ŒARçš„é—®é¢˜ä¸»è¦åœ¨æ²¡æœ‰å……åˆ†åˆ©ç”¨å‰åçš„ä¸Šä¸‹æ–‡ï¼Œåªä½¿ç”¨äº†éƒ¨åˆ†ã€‚</p>
<p>æœ¬æ–‡é€šè¿‡permutationæ¥è¾¾åˆ°è§„é¿è¿™ä¸¤ä¸ªç¼ºç‚¹çš„ç›®çš„ï¼Œä¹Ÿå³ æ—¢åˆ©ç”¨äº†å‰åä¸Šä¸‹æ–‡ï¼Œåˆæ²¡æœ‰input noiseï¼ŒåŒæ—¶è¿˜æ²¡æœ‰independence assumptionã€‚</p>
<h3 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><p>å®šä¹‰ä¸€ä¸ªfactorization ordersï¼ˆæ³¨æ„æ˜¯è™šæ‹Ÿçš„é¡ºåºï¼ŒåŸå§‹é¡ºåºè¿˜æ˜¯ä¼šä¿ç•™çš„ï¼‰ï¼Œå°†åŸå§‹çš„é¡ºåºæ‰“ä¹±ã€‚ä½¿å¾—ä¸€ä¸ªè¯çš„é¢„æµ‹å¯ä»¥ç”±ä¸¤ä¾§çš„è¯æ¥å¸®åŠ©ã€‚</p>
<p>å¦‚å›¾ï¼Œè¾“å…¥çš„åŸå§‹é¡ºåºè¿˜æ˜¯ä¸å˜ï¼Œä½†é€šè¿‡ mask attentionæ¥è¾¾åˆ°ä¸åŒçš„factorization orderçš„ç›®çš„ï¼Œåœ¨ä¸åŒorderä¸‹é¢„æµ‹åŒä¸€ä¸ª$x_3$ï¼Œç”±äºfactorization orderçš„é¡ºåºä¸åŒï¼Œåœ¨3ä¹‹å‰çš„è¯å‘æŒ¥äº†ä½œç”¨ï¼Œè€Œåœ¨ä»–ä¹‹åçš„è¯å°±æ²¡æœ‰å‚ä¸é¢„æµ‹ã€‚</p>
<p><img src="/images/15611948252404.jpg" width="70%" height="50%"></p>
<p>å½¢å¼åŒ–åˆ™æœ‰ï¼š</p>
<script type="math/tex; mode=display">\max _{\theta} \mathbb{E}_{\mathbf{z} \sim \mathcal{Z}_{T}}\left[\sum_{t=1}^{T} \log p_{\theta}\left(x_{z_{t}} | \mathbf{x}_{\mathbf{z}_{<t}}\right)\right]</script><p>å…¶ä¸­$z$æ˜¯permutation/factorization orderã€‚</p>
<p>æ˜¾ç„¶è¿™ä¸ªæ¨¡å‹å¦‚æœåªä½¿ç”¨åŸæ¥çš„transformerç»“æ„æ˜¯æœ‰é—®é¢˜çš„ï¼Œä¹Ÿå³target position unawareã€‚å‡è®¾ä»Šå¤©æœ‰ä¸¤ç§factorization orderï¼Œåœ¨tä¹‹å‰çš„å†…å®¹éƒ½æ˜¯ä¸€è‡´çš„ï¼Œåœ¨tä¸Šåˆ™æœ‰ä¸åŒçš„è¯ï¼Œé‚£ä¹ˆä»–ä»¬é¢„æµ‹çš„åˆ†å¸ƒéƒ½ä¼šæ˜¯ä¸€æ ·çš„ï¼Œä½†æŒ‰ç†è¯´ä¸åº”è¯¥ä¸€æ ·ï¼Œå› ä¸ºtargetä¸ä¸€æ ·ã€‚æ‰€ä»¥éœ€è¦è®©targetå‘æŒ¥ä½œç”¨ã€‚</p>
<p>å› æ­¤åœ¨è¿™é‡Œä¿®æ”¹äº†ä¸€ä¸‹transformeræ¶æ„ï¼Œå¼•å…¥Two-Stream Self-Attention for Target-Aware Representationsã€‚</p>
<p><img src="/images/15611949233220.jpg" width="90%" height="50%"></p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œç°åœ¨å…µåˆ†ä¸¤è·¯ï¼Œæ¯ä¸€å±‚éƒ½å¾—åˆ°ä¸¤ä¸ªè¡¨ç¤ºã€‚å…¶ä¸­$h$å’ŒåŸæ¥transformerä¸€æ ·ï¼Œè€Œ$g$åˆ™æ˜¯æ–°å¼•è¿›çš„ï¼Œä¹Ÿå³åœ¨Qä¸­åªä½¿ç”¨<strong>position</strong>è€Œæ²¡æœ‰contentã€‚</p>
<p>å½¢å¼åŒ–æœ‰ï¼š</p>
<script type="math/tex; mode=display">\begin{array}{l}{g_{z_{t}}^{(m)} \leftarrow \text { Attention }\left(\mathbf{Q}=g_{z_{t}}^{(m-1)}, \mathbf{K V}=\mathbf{h}_{\mathbf{z}<t}^{(m-1)} ; \theta\right)} \text{  (query stream: use } z_t \text{ but cannot see }  x_{z_t}) \\ {h_{z_{t}}^{(m)} \leftarrow \text { Attention }\left(\mathbf{Q}=h_{z_{t}}^{(m-1)}, \mathbf{K V}=\mathbf{h}_{\mathbf{z} \leq t}^{(m-1)} ; \theta\right)} \text{  (content stream: use both } z_t \text{ and }  x_{z_t})\end{array}</script><p>æ‰€ä»¥ï¼Œè¿›è¡Œé¢„æµ‹è¯æ“ä½œçš„æ—¶å€™åªä½¿ç”¨$g$å»é¢„æµ‹ç›¸åº”ä½ç½®ä¸Šçš„å†…å®¹å³å¯ã€‚</p>
<p>ä¸€äº›ç»†èŠ‚ï¼š<br>â‘  ä¸ºäº†è®©è®­ç»ƒæ›´å®¹æ˜“ï¼Œåªé¢„æµ‹æœ€åçš„å‡ ä¸ªtokensï¼ˆfactorization orderçš„æœ€åå‡ ä¸ªï¼‰ï¼›<br>â‘¡å°†transformer-xlå¼•å…¥ï¼Œä¹Ÿå³ç›¸å¯¹ä½ç½®å’Œå†å²ä¿¡æ¯çš„idea<br>â‘¢å¼•å…¥ç›¸å¯¹ä½ç½®çš„segment encodingï¼Œä½¿å¾—æ›´çµæ´»ï¼Œå› ä¸ºè¿™æ ·å°±å¯ä»¥encodeè¶…è¿‡ä¸¤ä¸ªè¾“å…¥çš„segmentäº†ï¼Œä½¿ç”¨absolute segmentåˆ™ä¸è¡Œ.</p>
<h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>ç›¸å¯¹bertè€Œè¨€ï¼Œæœ‰æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œå› ä¸ºbertä½¿ç”¨äº†maskï¼Œä½¿å¾—maskä¹‹é—´ä¸èƒ½ç›¸äº’å¸®åŠ©ã€‚åŒæ—¶ä¹Ÿæœ‰åŸå…ˆlanguage modelçš„ç‰¹ç‚¹ï¼Œä¹Ÿå³é¡ºåºé¢„æµ‹çš„ç‰¹ç‚¹ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥ç”¨äºä¸€äº›æœ‰è¯¥ç‰¹ç‚¹çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä½œè€…æ•´ä¸ªæ€è·¯è¡Œäº‘æµæ°´ï¼Œå¹¶ä¸”å¯¹æ¨¡å‹çš„æœ¬è´¨çœ‹å¾—å¾ˆé€ã€‚</p>
<p>ä½†è¿™ç§æ–¹æ³•å› ä¸ºè¦ä¿å­˜ä¸¤ä»½hidden stateï¼Œä¼šéœ€è¦æ›´å¤šçš„å†…å­˜å’Œè®¡ç®—èµ„æºã€‚</p>
<p>è¿™ç¯‡æ–‡ç« çš„ç»“æœå¾ˆå¼ºï¼Œä¸”æ¨¡å‹ä¹Ÿæœ‰è¯´æœåŠ›ã€‚ä½†è®­ç»ƒä½¿ç”¨äº†512å¼ TPUï¼Œä»¥åŠç”¨äº†è¶…è¿‡Bertçš„æ•°æ®é‡ï¼ˆæ•°æ®é‡æ˜¯å¦å¯¹è¶…è¿‡Bertæœ‰å¾ˆå¤§çš„å¸®åŠ©ï¼Ÿï¼‰ã€‚ä¸å¾—ä¸è¯´è¿™ç±»æ–‡ç« æ™®é€šäººåªèƒ½çœ‹çœ‹ï¼ŒNLPå·²ç»è¿›å…¥äº†å†›å¤‡ç«èµ›äº†ã€‚</p>
<hr>
<h2 id="An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="[An Empirical Exploration of Curriculum Learning for Neural Machine Translation]"></a>[An Empirical Exploration of Curriculum Learning for Neural Machine Translation]</h2><p>è®¨è®ºäº†ä¸€äº›å…³äºåœ¨NMTä¸Šä½¿ç”¨CLçš„ç­–ç•¥ï¼ˆç›¸æ¯”åŸæœ¬çš„CLæ›´åŠ çµæ´»ï¼‰ï¼Œå¹¶åšäº†ä¸€ç³»åˆ—å®éªŒå¾—åˆ°ä¸€äº›ç»“è®ºã€‚</p>
<h3 id="ç­–ç•¥åˆ›æ–°"><a href="#ç­–ç•¥åˆ›æ–°" class="headerlink" title="ç­–ç•¥åˆ›æ–°"></a>ç­–ç•¥åˆ›æ–°</h3><p>â‘ <br>é¦–å…ˆæ˜¯å°†sample distributionçš„æ¦‚å¿µæ‰©å±•åˆ°shardçš„å±‚é¢è€Œä¸æ˜¯å•ä¸€çš„exampleã€‚ä¹Ÿå³ï¼š</p>
<p><img src="/images/15612123996612.jpg" width="50%" height="50%"></p>
<p>å°†exampleç»“æˆgroupã€‚å°†ç›¸ä¼¼difficultyçš„æ”¾åœ¨åŒä¸€ä¸ªshardé‡Œé¢ã€‚</p>
<p>å…·ä½“åº”å¦‚ä½•åšï¼Ÿæœ‰ä¸‰ç§æ–¹æ¡ˆï¼š<br>â‘ è®¾å®šä¸€ä¸ªéš¾åº¦scoreçš„é˜ˆå€¼ï¼Œæ˜¾ç„¶è¿™ä¸ªæ–¹æ³•ä¸å¥½å¼„ï¼Œå› ä¸ºä¸å¥½æ‰‹åŠ¨è®¾é˜ˆå€¼ã€‚<br>â‘¡ç›´æ¥ç­‰å¤§å°åˆ†ï¼Œæ¯ä¸ªshardçš„ä¸ªæ•°ä¸€æ ·ï¼Œä½†è¿™æ ·å¯èƒ½ä¼šå¸¦æ¥shardå†…éƒ¨çš„éš¾åº¦scoreçš„æ³¢åŠ¨ã€‚  â‘¢æœ¬æ–‡é‡‡ç”¨çš„æ˜¯<strong>Jenks Natural Breaks classiï¬cation algorithm</strong>ï¼Œä¹Ÿå³shardå†…éƒ¨çš„varianceå°½é‡å°ï¼Œshardä¹‹é—´çš„varianceå°½é‡å¤§</p>
<p>â‘¡<br>ç¬¬äºŒæ˜¯sample difficulty criteriaï¼š<br>é‡‡ç”¨äº†ä¸¤ç§æ–¹æ³•ï¼šä¸€ä¸ªæ˜¯è®­ç»ƒè¾…åŠ©ï¼ˆå°çš„ï¼‰æ¨¡å‹æ¥åšåˆ¤æ–­ï¼›å¦ä¸€ä¸ªæ˜¯é‡‡ç”¨linguisticçš„feature</p>
<p>ç¬¬ä¸€ç§ä¹Ÿå³Model-based Difï¬culty Criteriaï¼Œç»™å®šsource sentenceï¼Œè·å¾—targetçš„æ¦‚ç‡ã€‚<br>ç¬¬äºŒç§æ˜¯Linguistic Difï¬culty Criteriaï¼Œä¹Ÿå³word frequencyï¼Œç„¶åå°†å¥å­æŒ‰ç…§least frequent wordæ¥æ’åºï¼ˆè¿™å®é™…ä¸Šå’Œé€æ­¥æ·»åŠ è¯è¡¨å¤§å°ï¼Œç„¶åè®­ç»ƒæ‰€æœ‰è¯éƒ½åœ¨è¯¥è¯è¡¨çš„å¥å­æ˜¯ç­‰ä»·çš„ï¼‰</p>
<p>â‘¢<br>ç¬¬ä¸‰æ˜¯scheduleï¼š</p>
<p><img src="/images/15612125916364.jpg" width="60%" height="50%"></p>
<p>æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªé˜¶æ®µï¼ˆphaseï¼‰ã€‚</p>
<p>æ³¨æ„åˆ°defaultæ˜¯æœ‰shuffleçš„ï¼ˆshardä¹‹é—´çš„shuffleï¼‰ï¼›è€Œnoshuffleæ˜¯shardå†…éƒ¨æœ‰shuffleï¼Œä½†ä¹‹é—´æ²¡æœ‰shuffleã€‚</p>
<h3 id="å®éªŒç»“è®º"><a href="#å®éªŒç»“è®º" class="headerlink" title="å®éªŒç»“è®º"></a>å®éªŒç»“è®º</h3><p>ä¼¼ä¹ä¸¥æ ¼æŒ‰ç…§é¡ºåºæ¥åšï¼ˆnoshuffle)å¹¶æ²¡æœ‰å¸®åŠ©ï¼ˆç›¸å¯¹defaultè€Œè¨€ï¼‰ï¼›<br>å¯¹learning rateæ•æ„Ÿï¼›<br>CLç¡®å®æœ‰å¸®åŠ©ï¼Œdifficulty criteriaæ˜¯å…³é”®ï¼Œè¯è¡¨é¢‘ç‡å’Œä½¿ç”¨å°æ¨¡å‹æ¥åšæ ‡å‡†éƒ½æœ‰ç”¨ï¼Œä½†åœ¨è¿™é‡Œå¥å­é•¿åº¦æ²¡ç”¨ã€‚</p>
<h3 id="å‡ ä¸ªæ€è€ƒ"><a href="#å‡ ä¸ªæ€è€ƒ" class="headerlink" title="å‡ ä¸ªæ€è€ƒ"></a>å‡ ä¸ªæ€è€ƒ</h3><p>å®éªŒåšå¾—æœ‰ç‚¹å¥‡æ€ªï¼›è®ºæ–‡ä¸­çš„phaseä¼¼ä¹æ˜¯æ¯æ¬¡æ•°æ®è¿‡ä¸€éå°±åˆ°ä¸‹ä¸€ä¸ªphaseäº†ï¼Œç„¶è€Œshardåˆ†å¾—ä¹Ÿå¤ªå°‘äº†ï¼Œé‚£å…¶å®å‰å‡ ä¸ªepochå°±æŠŠCLçš„phaseå…¨éƒ¨èµ°å®Œäº†ï¼›<br>ä¸ºä»€ä¹ˆnoshuffleæ²¡æœ‰å¸®åŠ©ï¼Œæ˜¯å¦æ„å‘³ç€åœ¨ä¸€ä¸ªphaseå†…éƒ¨ä¸¥æ ¼æŒ‰ç…§ä»æ˜“åˆ°éš¾æ˜¯æ²¡æœ‰å¸®åŠ©çš„ï¼Œè€Œæ¨¡å‹æ›´éœ€è¦çš„æ˜¯é‚£äº›å¯¹å®ƒå½“å‰æœ€éš¾çš„é‚£ä¸€æ‰¹ï¼Œè€Œåœ¨è¿™ä¸ªphaseå†…æ˜¯å…ˆå‡ºç°è¿˜æ˜¯åå‡ºç°éƒ½æ²¡æœ‰å…³ç³»ï¼Ÿè¿™æ ·æ˜¯å¦å¯ä»¥åœ¨phaseå†…éƒ¨ä½¿ç”¨boostingï¼Ÿæˆ–è€…å¹²è„†åˆ æ‰ä¸é‡è¦çš„ä¾‹å­ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>Language Modeling</tag>
        <tag>boosting</tag>
        <tag>XLNet</tag>
        <tag>pretrain</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 2:Proximal Policy Optimization (PPO)</title>
    <url>/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%202:%20Proximal%20Policy%20Optimization%20(PPO)/</url>
    <content><![CDATA[<p>Policy Gradientçš„é—®é¢˜ï¼šæ¯æ¬¡sampleçš„dataåªèƒ½ä½¿ç”¨ä¸€æ¬¡ï¼Œè¾ƒä¸ºè€—è´¹æ—¶é—´ã€‚å› æ­¤å¼•å…¥off-policyï¼Œæ¯æ¬¡sampleçš„æ•°æ®å¯ä»¥å¤šæ¬¡ä½¿ç”¨ã€‚</p>
<p>ç‰¹ç‚¹ï¼šon-policyä¸­å­¦ä¹ çš„agentä¸å’Œç¯å¢ƒäº¤äº’çš„agentæ˜¯ä¸€è‡´çš„ï¼›è€Œoff-policyåˆ™æ˜¯æœ‰ä¸¤ä¸ªagentï¼Œå…¶ä¸­ä¸€ä¸ªagentè´Ÿè´£ä¸ç¯å¢ƒäº¤äº’æ¥è·å¾—episodeï¼Œå¦ä¸€ä¸ªagentåˆ™é€šè¿‡è¿™äº›episodeæ›´æ–°å‚æ•°ã€‚</p>
<p>åœ¨è¿™é‡Œåˆ©ç”¨importance-samplingæ¥è¾¾åˆ°è¿™ä¸€ç›®çš„ã€‚</p>
<h3 id="importance-sampling"><a href="#importance-sampling" class="headerlink" title="importance-sampling"></a>importance-sampling</h3><p>ç»™å®šæ¦‚ç‡$p$è¦è®¡ç®—$f(x)$çš„æœŸæœ›ï¼šå¯ä»¥é‡‡ç”¨sampleçš„æ–¹å¼æ¥è¾¾åˆ°è¯¥ç›®çš„ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">E_{x \sim p}[f(x)] \approx \frac{1}{N} \sum_{i=1}^{N} f\left(x^{i}\right)</script><p>è€Œè‹¥$p$åˆ†å¸ƒæ— æ³•è·å¾—ï¼Œå¯ä»¥åˆ©ç”¨å¦ä¸€ä¸ªå¯è·å¾—çš„åˆ†å¸ƒ$q$æ¥è¿‘ä¼¼ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">E_{x \sim p}[f(x)]=\int f(x) p(x) d x=\int f(x) \frac{p(x)}{q(x)} q(x) d x=E_{x \sim q}[f(x) \frac{p(x)}{q(x)}]</script><p>ç„¶åå†ç”±$q$æ¥åšsamplingã€‚</p>
<p>æ³¨æ„è¿™é‡Œ$p$ä¸$q$çš„åˆ†å¸ƒä¸åº”è¯¥å·®è·å¤ªå¤§ï¼Œå¦åˆ™å…¶varianceåˆ™ä¼šç›¸å·®å¾ˆå¤§ï¼Œé€ æˆè¿‘ä¼¼ç»“æœå·®è·è¾ƒå¤§ã€‚</p>
<h3 id="off-policy"><a href="#off-policy" class="headerlink" title="off-policy"></a>off-policy</h3><p>å°†importance samplingç”¨äºoff-policyã€‚</p>
<p>åŸæ¥ï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta}=E_{\tau \sim p_{\theta}(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right]</script><p>å˜æˆï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta}=E_{\tau \sim p_{\theta^{\prime}}(\tau)}\left[\frac{p_{\theta}(\tau)}{p_{\theta^{\prime}}(\tau)} R(\tau) \log p_{\theta}(\tau)\right]</script><p>å…¶ä¸­$p_{\theta^{\prime}}$æ˜¯å¦ä¸€ä¸ªagentçš„åˆ†å¸ƒï¼Œä¹Ÿå³dataæ˜¯ä»è¯¥agentçš„åˆ†å¸ƒsampleå¾—åˆ°çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨è¯¥dataæ¥å¤šæ¬¡è®­ç»ƒÎ¸ã€‚</p>
<p>å› æ­¤æ¢¯åº¦å…¬å¼åˆ™ä¸ºï¼š</p>
<script type="math/tex; mode=display">\begin{array}{l}{=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta}}\left[A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]} \\ {=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{P_{\theta}\left(s_{t}, a_{t}\right)}{P_{\theta^{\prime}}\left(s_{t}, a_{t}\right)} A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]} \\ {=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{p_{\theta}\left(a_{t} | s_{t}\right)}{p_{\theta^{\prime}}\left(a_{t} | s_{t}\right)} \frac{p_{\theta}\left(s_{t}\right)}{p_{\theta^{\prime}}\left(s_{t}\right)} A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]}\end{array}</script><p>å…¶ä¸­ï¼Œæˆ‘ä»¬å°†$A^{\theta}\left(s_{t}, a_{t}\right)$æ”¹æˆ$A^{\theta^{\prime}}\left(s_{t}, a_{t}\right)$ï¼Œå› ä¸ºæ•°æ®æ˜¯ä»$\theta^{\prime}$ æ¥çš„ï¼›åŒæ—¶æˆ‘ä»¬å‡è®¾$\frac{p_{\theta}\left(s_{t}\right)}{p_{\theta^{\prime}}\left(s_{t}\right)}=1$ï¼Œä¸€æ–¹é¢æ˜¯ä¸æ–¹ä¾¿è®¡ç®—ï¼Œä½œæ­¤å‡è®¾å¯ä»¥æ–¹ä¾¿è®¡ç®—ï¼›å¦ä¸€æ–¹é¢è¯¥å‡è®¾ä¹Ÿæœ‰ä¸€å®šåˆç†æ€§ï¼Œå› ä¸ºæŸä¸ªstateå‡ºç°çš„å‡ ç‡åº”è¯¥å’Œagentçš„å…³ç³»è¾ƒå°ã€‚</p>
<p>é€šè¿‡æ¢¯åº¦å…¬å¼æˆ‘ä»¬å¯ä»¥è¿˜åŸå‡ºåŸå¼ï¼š </p>
<script type="math/tex; mode=display">J^{\theta^{\prime}}(\theta)=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{p_{\theta}\left(a_{t} | s_{t}\right)}{p_{\theta^{\prime}}\left(a_{t} | s_{t}\right)} A^{\theta^{\prime}}\left(s_{t}, a_{t}\right)\right]</script><p>å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåœ¨ä»€ä¹ˆæ—¶å€™åœæ­¢ä½¿ç”¨åŒä¸€ç»„dataæ›´æ–°å‚æ•°ï¼Ÿä¹Ÿå³åŒä¸€ç»„dataèƒ½å¤Ÿæ›´æ–°å‚æ•°å‡ æ¬¡ï¼Ÿ</p>
<p>ä¸€ä¸ªåŸåˆ™æ˜¯ï¼šæˆ‘ä»¬å¸Œæœ›ä¸¤ä¸ªagentçš„åˆ†å¸ƒå·®å¼‚å°ä¸€äº›ï¼Œå› ä¸ºåˆ†å¸ƒå·®å¼‚ä¸€æ—¦å¤§äº†ï¼Œvarianceåˆ™ä¼šå˜å¤§ï¼Œå› æ­¤è¿™é‡Œæ·»åŠ ä¸€ä¸ªconstraintã€‚</p>
<script type="math/tex; mode=display">J_{P P O}^{\theta^{\prime}}(\theta)=J^{\theta^{\prime}}(\theta)-\beta K L\left(\theta, \theta^{\prime}\right)</script><p>æ³¨æ„è¿™é‡Œçš„KLæ•£åº¦æ˜¯å¯¹actionåˆ†å¸ƒçš„KLæ•£åº¦è€Œä¸æ˜¯å‚æ•°çš„ã€‚</p>
<p>æ‰€ä»¥æœ€ç»ˆçš„ç®—æ³•ä¸ºï¼š</p>
<p><img src="/images/15606497157322.jpg" width="60%" height="50%"></p>
<p>å…¶ä¸­$\theta_{k}$æ˜¯ä¸Šæ¬¡æ›´æ–°å®Œçš„agentçš„å‚æ•°ã€‚ä¹Ÿå³ä¸ç¯å¢ƒäº¤äº’çš„agentçš„å‚æ•°æ€»æ˜¯ä¸Šä¸ªiteration å¦ä¸€ä¸ªagentæ›´æ–°åçš„å‚æ•°ã€‚</p>
<p>è¿˜æœ‰å‡ ä¸ªç»†èŠ‚ï¼Œ$\beta$å¯ä»¥æ˜¯adaptiveçš„ï¼›ä»¥åŠPPO2å¯¹PPOä¸­constraintçš„æ”¹è¿›ï¼Œä¸è¿‡éƒ½æ˜¯ç»†ææœ«èŠ‚ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>PPO</tag>
      </tags>
  </entry>
  <entry>
    <title>DRL Lecture 1:Policy Gradient (Review)</title>
    <url>/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%201:%20Policy%20Gradient%20(Review)/</url>
    <content><![CDATA[<p><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_" target="_blank" rel="noopener">æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</a>ç¬”è®°ã€‚</p>
<hr>
<p>æœ¬lectureä¸»è¦æ˜¯å¤ä¹ å¼ºåŒ–å­¦ä¹ çš„policy gradientã€‚åŸºæœ¬çš„ä»‹ç»éƒ½åœ¨ä¹‹å‰çš„<a href="http://www.linzehui.me/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/">å¼ºåŒ–å­¦ä¹ ç¬”è®°</a>é‡Œé¢ã€‚</p>
<p>åŸºæœ¬å¤§è‡´æ¡†æ¶ä¸ºï¼š</p>
<p><img src="/images/15606479563499.jpg" width="50%" height="50%"></p>
<p>æ¯æ¬¡sampleå‡ ä¸ªepisodeï¼Œç„¶åæ›´æ–°æ¨¡å‹ï¼š</p>
<p><img src="/images/15606479845586.jpg" width="50%" height="50%"></p>
<p>å€¼å¾—æçš„å‡ ä¸ªæ–°çš„ç‚¹ï¼š<br>â‘ æˆ‘ä»¬è¦å¯¹rewardåŠ baselineï¼Œå› ä¸ºé˜²æ­¢rewardä¸€ç›´ä¸ºæ­£ï¼Œé¼“åŠ±å…¶ä»–å‡ºç°å‡ ç‡å°ä½†rewardé«˜çš„episodeè¢«sampleåˆ°ã€‚å› æ­¤åŠ ä¸€ä¸ªbaselineï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(R\left(\tau^{n}\right) -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>å…¶ä¸­$b$å¯ä»¥è®¾ä¸º$b \approx E[R(\tau)]$</p>
<p>â‘¡å¯¹æ¯ä¸ªactionåº”è¯¥åˆ†é…ä¸åŒçš„weightï¼Œé¼“åŠ±rewardé«˜çš„actionå‡ºç°ï¼š<br>ä¸€ç§æ–¹æ³•ï¼Œæ˜¯å°†å…¨å±€çš„Ræ¢æˆç´¯ç§¯çš„Rï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} r_{t^{\prime}}^{n} -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ä¹Ÿå³å½“å‰actionåˆ°episodeç»“æŸç´¯åŠ çš„rewardã€‚</p>
<p>æ›´è¿›ä¸€æ­¥ï¼Œæ·»åŠ è¡°å‡å› å­ï¼Œå…¶ä¸­$\gamma&lt;1$ï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n} -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>å½“ç„¶ï¼Œä¸ºäº†ç®€ä¾¿ï¼Œå°†reward $R(\tau^{n})$ ç»Ÿä¸€å†™æˆ $A^Î¸ (s_t,a_t )$ï¼Œä»£è¡¨çš„æ˜¯åœ¨å½“å‰stateä¸‹é‡‡ç”¨actionçš„rewardã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>å¼ºåŒ–å­¦ä¹ </tag>
        <tag>RL</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Policy Gradient</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡21</title>
    <url>/2019/06/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8721/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Named Entity Recognition with Bidirectional LSTM-CNNs</li>
</ol>
<h2 id="Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs"><a href="#Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs" class="headerlink" title="[Named Entity Recognition with Bidirectional LSTM-CNNs]"></a>[Named Entity Recognition with Bidirectional LSTM-CNNs]</h2><p>å…³äºNERçš„ç»å…¸è®ºæ–‡ã€‚</p>
<p>æ€»çš„ç»“æ„å¾ˆç®€å•ï¼Œå…¶å®å°±æ˜¯åˆ©ç”¨word embedding + CNN-char features + additional word featuresä½œä¸ºæ€»çš„featuresï¼Œè¿‡ä¸€ä¸ªåŒå‘LSTMè·å¾—ä¸Šä¸‹æ–‡ç›¸å…³çš„å‘é‡è¡¨ç¤ºï¼Œæœ€ç»ˆè·å¾—åˆ†ç±»ç»“æœã€‚</p>
<p><img src="/images/15606462750491.jpg" width="55%" height="50%"></p>
<p>å…¶ä¸­CNNçš„featureæ˜¯characterçº§åˆ«çš„ï¼š</p>
<p><img src="/images/15606463343904.jpg" width="55%" height="50%"></p>
<p>åŒæ—¶è¿˜åŠ äº†ä¸€äº›äººå·¥çš„featureï¼šæ¯”å¦‚å¤§å†™çš„featureï¼›æ¯”å¦‚å¤–éƒ¨è¯å…¸ç­‰ã€‚</p>
<p>æœ€ç»ˆ</p>
<p><img src="/images/15606463626767.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NER</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯28</title>
    <url>/2019/06/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D28/</url>
    <content><![CDATA[<h3 id="è¶æ‹èŠ±"><a href="#è¶æ‹èŠ±" class="headerlink" title="è¶æ‹èŠ±"></a>è¶æ‹èŠ±</h3><p>[å®‹] æ¬§é˜³ä¿®<br>åº­é™¢æ·±æ·±æ·±å‡ è®¸ï¼Ÿæ¨æŸ³å †çƒŸï¼Œå¸˜å¹•æ— é‡æ•°ã€‚ç‰å‹’é›•éæ¸¸å†¶å¤„ï¼Œæ¥¼é«˜ä¸è§ç« å°è·¯ã€‚<br>é›¨æ¨ªé£ç‹‚ä¸‰æœˆæš®ï¼Œé—¨æ©é»„æ˜ï¼Œæ— è®¡ç•™æ˜¥ä½ã€‚<strong>æ³ªçœ¼é—®èŠ±èŠ±ä¸è¯­ï¼Œä¹±çº¢é£è¿‡ç§‹åƒå»</strong>ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†22</title>
    <url>/2019/06/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8622/</url>
    <content><![CDATA[<h3 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="[Sequence Labeling]"></a>[Sequence Labeling]</h3><p>ä»‹ç»sequence labelingåšå®¢ï¼š<br><a href="https://www.cnblogs.com/jiangxinyang/p/9368482.html" target="_blank" rel="noopener">https://www.cnblogs.com/jiangxinyang/p/9368482.html</a></p>
<p>å…³äºå‡ ä¸ªä»»åŠ¡çš„å®šä¹‰ï¼š</p>
<p>å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NER)ï¼šä»æ–‡æœ¬ä¸­è¯†åˆ«å‡ºå‘½åå®ä½“ï¼Œå®ä½“ä¸€èˆ¬åŒ…æ‹¬äººå(PER)ã€åœ°å(LOC)ã€æœºæ„å(ORG)ã€æ—¶é—´ã€æ—¥æœŸã€è´§å¸ã€ç™¾åˆ†æ¯”ç­‰ã€‚<br>ç»„å—åˆ†æ (Chunking)ï¼šæ ‡å‡ºå¥å­ä¸­çš„çŸ­è¯­å—ï¼Œä¾‹å¦‚åè¯çŸ­è¯­ï¼ˆNPï¼‰ï¼ŒåŠ¨è¯çŸ­è¯­ï¼ˆVPï¼‰ç­‰<br>è¯æ€§æ ‡æ³¨ (Part-of-speech Tagging, POS)ï¼šç¡®å®šæ–‡æœ¬ä¸­æ¯ä¸ªè¯çš„è¯æ€§ã€‚è¯æ€§åŒ…æ‹¬åŠ¨è¯ï¼ˆVerbï¼‰ã€åè¯ï¼ˆNounï¼‰ã€ä»£è¯ï¼ˆpronounï¼‰ç­‰ã€‚</p>
<h3 id="Active-learning"><a href="#Active-learning" class="headerlink" title="[Active learning]"></a>[Active learning]</h3><p>å®šä¹‰ï¼š</p>
<p>æ ·æœ¬ä¿¡æ¯å°±æ˜¯è¯´åœ¨è®­ç»ƒæ•°æ®é›†å½“ä¸­æ¯ä¸ªæ ·æœ¬å¸¦ç»™æ¨¡å‹è®­ç»ƒçš„ä¿¡æ¯æ˜¯ä¸åŒçš„ï¼Œå³æ¯ä¸ªæ ·æœ¬ä¸ºæ¨¡å‹è®­ç»ƒçš„è´¡çŒ®æœ‰å¤§æœ‰å°ï¼Œå®ƒä»¬ä¹‹é—´æ˜¯æœ‰å·®å¼‚çš„ã€‚<br>å› æ­¤ï¼Œä¸ºäº†å°½å¯èƒ½åœ°å‡å°è®­ç»ƒé›†åŠæ ‡æ³¨æˆæœ¬ï¼Œåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸä¸­ï¼Œæå‡ºä¸»åŠ¨å­¦ä¹ ï¼ˆactive learningï¼‰æ–¹æ³•ï¼Œä¼˜åŒ–åˆ†ç±»æ¨¡å‹ã€‚<br>ä¸»åŠ¨å­¦ä¹ (active learning)ï¼ŒæŒ‡çš„æ˜¯è¿™æ ·ä¸€ç§å­¦ä¹ æ–¹æ³•ï¼š<br>æœ‰çš„æ—¶å€™ï¼Œæœ‰ç±»æ ‡çš„æ•°æ®æ¯”è¾ƒç¨€å°‘è€Œæ²¡æœ‰ç±»æ ‡çš„æ•°æ®æ˜¯ç›¸å½“ä¸°å¯Œçš„ï¼Œä½†æ˜¯å¯¹æ•°æ®è¿›è¡Œäººå·¥æ ‡æ³¨åˆéå¸¸æ˜‚è´µï¼Œè¿™æ—¶å€™ï¼Œå­¦ä¹ ç®—æ³•å¯ä»¥ä¸»åŠ¨åœ°æå‡ºä¸€äº›æ ‡æ³¨è¯·æ±‚ï¼Œå°†ä¸€äº›ç»è¿‡ç­›é€‰çš„æ•°æ®æäº¤ç»™ä¸“å®¶è¿›è¡Œæ ‡æ³¨ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Sequence Labeling</tag>
        <tag>Active learning</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡20</title>
    <url>/2019/06/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8720/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Neural Machine Translation in Linear Time</li>
<li>Curriculum Learning</li>
<li>Bilingual Word Embeddings for Phrase-Based Machine Translation</li>
<li>LEARNING TO EXECUTE</li>
<li>Self-Paced Learning for Latent Variable Models</li>
</ol>
<h2 id="Neural-Machine-Translation-in-Linear-Time"><a href="#Neural-Machine-Translation-in-Linear-Time" class="headerlink" title="[Neural Machine Translation in Linear Time]"></a>[Neural Machine Translation in Linear Time]</h2><p>ä½¿ç”¨æ–°çš„ç»“æ„å°†ç¿»è¯‘æ§åˆ¶åœ¨çº¿æ€§å¤æ‚åº¦ã€‚æ„Ÿè§‰æ€è·¯è¿˜è›®æ¸…æ™°ï¼ŒæŒºæ–°é¢–çš„ã€‚</p>
<p><img src="/images/15600510169611.jpg" width="55%" height="50%"></p>
<p>ä¸»è¦æœ‰ä¸‰ä¸ªç‚¹ï¼š</p>
<p>ç¬¬ä¸€ï¼Œç»“æ„ä¸Šé‡‡ç”¨bytenetï¼Œä¹Ÿå³é‡‡ç”¨äº†ç©ºæ´å·ç§¯çš„ç½‘ç»œï¼Œä½¿å¾—è®¡ç®—ä»£ä»·å‡å°ã€‚</p>
<p>ç¬¬äºŒï¼Œç›´æ¥å°†decoderå †åœ¨encoderä¸Šï¼Œæ¯æ¬¡decoderåªå–å¯¹åº”å¯¹åº”ä½ç½®ä¸Šçš„encoderï¼Œè¿™å’Œä¸€èˆ¬çš„åŸºäºencoder-decoderçš„æ–¹æ³•ä¸åŒã€‚</p>
<p>ç¬¬ä¸‰ï¼Œé‡‡ç”¨dynamic unfoldingä»¥è§£å†³encoderä¸decoderé•¿åº¦ä¸åŒçš„é—®é¢˜ã€‚äººå·¥é¢„å…ˆå®šä¹‰å¥½decoderçš„ä¸Šç•Œï¼š</p>
<script type="math/tex; mode=display">|\hat{\mathbf{t}}|=a|\mathbf{s}|+b</script><p>ä¹Ÿå³encoderå°†ä¼šç”Ÿæˆè¿™ä¹ˆå¤šçš„representationã€‚</p>
<p>è€Œå®é™…ä¸Štargetæ˜¯å¯ä»¥è¶…å‡ºè¿™ä¸ªä¸Šç•Œçš„ï¼Œç›´åˆ°ç”ŸæˆEOSä¸ºæ­¢ï¼Œå¦‚æœè¶…å‡ºä¸Šç•Œåˆ™åœ¨è¯¥æ­¥ä¸åˆ©ç”¨encoderçš„representationï¼Œä¸Šç•Œåªæ˜¯ç”¨ä»¥æŒ‡å¯¼encoderåº”è¯¥ç”Ÿæˆå¤šå°‘representationã€‚</p>
<p><img src="/images/15600511595880.jpg" width="80%" height="50%"></p>
<p>è¯¥æ¨¡å‹éå¸¸è½»é‡çº§ï¼›ä½†æˆ‘è¿˜æ˜¯æ²¡æœ‰æ€ä¹ˆææ‡‚encoderå¦‚ä½•ç”Ÿæˆå‡ºæ¯”sourceé•¿åº¦è¿˜é•¿çš„ä¿¡æ¯çš„ã€‚</p>
<hr>
<h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="[Curriculum Learning]"></a>[Curriculum Learning]</h2><p>è¯¾ç¨‹å­¦ä¹ çš„å¼€å±±ä¹‹ä½œã€‚å¯¹curriculum learningè¿›è¡Œäº†å½¢å¼åŒ–çš„æ€»ç»“ï¼Œå¹¶ä¸”é€šè¿‡å‡ ä¸ªå®éªŒå¯¹curriculum learningçš„æ€§è´¨è¿›è¡Œäº†æ¢ç´¢ã€‚è¯¥æ–‡ç« å±äºå¯¹å…¶ä»–äººæœ‰å¯å‘çš„æ€§è´¨ã€‚</p>
<p>curriculum learningçš„æ€æƒ³ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå…ˆä½¿ç”¨ç®€å•çš„æ ·ä¾‹è¿›è¡Œè®­ç»ƒï¼Œç„¶åé€æ¸å°†éš¾çš„æ ·ä¾‹åŠ å…¥åˆ°è®­ç»ƒæ ·ä¾‹ä¸­ã€‚æœ¬è´¨å°±æ˜¯ä»æ˜“åˆ°éš¾çš„è¿‡ç¨‹ï¼Œç¬¦åˆäººçš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿè·å¾—æ›´å¥½çš„æ•ˆæœã€‚</p>
<p>å½¢å¼åŒ–ï¼š<br>æ„Ÿè§‰ä¸é‡è¦ï¼Œå…¶å®å°±æ˜¯å¯¹data distributionè¿›è¡Œäº†é‡æ’ã€‚</p>
<p>æ€§è´¨ï¼š</p>
<p>â‘ è·å¾—æ›´å¥½çš„ç»“æœ </p>
<p>â‘¡èƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œâ€˜Cleaner Examples May Yield Better Generalization Faster â€™ï¼Œå› ä¸ºç®€å•çš„exampleèƒ½å¤Ÿé¿å…confuse the learner </p>
<p>â‘¢curriculum learningå±•ç°å‡ºregularizerçš„æ€§è´¨ï¼Œä¹Ÿå³åœ¨åŒæ ·training errorçš„æƒ…å†µä¸‹èƒ½å¤Ÿè·å¾—æ›´ä½çš„generalization errorã€‚</p>
<p>å¯¹äºlearneræ¥è¯´ï¼Œåœ¨è®­ç»ƒçš„æ¯ä¸ªé˜¶æ®µéƒ½æœ‰å¯¹ä»–æ¥è¯´å¤ªç®€å•å’Œå¤ªéš¾çš„çŸ¥è¯†ï¼Œå¤ªç®€å•çš„å­¦ä¸åˆ°ä»€ä¹ˆï¼Œå¤ªéš¾çš„å­¦ä¸ä¼šã€‚å› æ­¤åœ¨æ¯ä¸ªé˜¶æ®µé€‰æ‹©å¯¹learnerè€Œè¨€interestingçš„ä¾‹å­ï¼Œä¸å¤ªéš¾ä¹Ÿä¸å¤ªç®€å•çš„ï¼Œæ˜¯æœ€å¥½çš„ã€‚</p>
<p>åŒæ—¶curriculum learningä¸boosting algorithmä¸åŒï¼Œå› ä¸ºboosting algorithm æ˜¯å¼ºè°ƒéš¾çš„exampleè€Œcurriculum learningåªæ˜¯æ¯ä¸ªé˜¶æ®µæŒ‰ç…§éš¾åº¦å¯¹exampleèµ‹äºˆä¸åŒçš„æƒå€¼ã€‚</p>
<p>curriculum learningå¯ä»¥çœ‹åšæ˜¯transfer learningçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ã€‚transfer learningæ˜¯åˆ©ç”¨åŸå§‹ä»»åŠ¡æ¥å¼•å¯¼learneråœ¨æœ€ç»ˆä»»åŠ¡è·å¾—æ›´å¥½çš„ç»“æœï¼›è€Œcurriculum learningå°±æ˜¯åˆ©ç”¨è®­ç»ƒä¸Šçš„æŠ€å·§æ¥å¼•å¯¼learnerè·å¾—æ›´å¥½çš„æœ€ç»ˆç»“æœã€‚</p>
<p>å…¶å®curriculum learningçš„éš¾ç‚¹å°±åœ¨äºå¦‚ä½•å®šä¹‰easy exampleï¼Œå› ä¸ºä¸åŒä»»åŠ¡å¯èƒ½æœ‰ä¸åŒçš„å®šä¹‰ã€‚</p>
<hr>
<h2 id="Bilingual-Word-Embeddings-for-Phrase-Based-Machine-Translation"><a href="#Bilingual-Word-Embeddings-for-Phrase-Based-Machine-Translation" class="headerlink" title="[Bilingual Word Embeddings for Phrase-Based Machine Translation]"></a>[Bilingual Word Embeddings for Phrase-Based Machine Translation]</h2><p>è®²å…³äºè®­ç»ƒåŒè¯­word embeddingçš„ã€‚æˆ‘åªå…³æ³¨curriculum learningéƒ¨åˆ†ï¼Œä½†å…¶å®è®²çš„ä¸å¤šã€‚</p>
<hr>
<h2 id="LEARNING-TO-EXECUTE"><a href="#LEARNING-TO-EXECUTE" class="headerlink" title="[LEARNING TO EXECUTE]"></a>[LEARNING TO EXECUTE]</h2><p>è¿™ç¯‡è®ºæ–‡æ˜¯ä½¿ç”¨LSTMæ¥è¯„ä¼°çŸ­çš„è®¡ç®—æœºç¨‹åºã€‚æˆ‘æ¯”è¾ƒå…³æ³¨curriculum learningçš„éƒ¨åˆ†ï¼Œå…¶ä¸­çš„ä¸€äº›è§£é‡Šæˆ–è®¸èƒ½å¤Ÿæœ‰ä¸€äº›å¯å‘ã€‚</p>
<p>æœ¬æ–‡åœ¨ä½¿ç”¨ä¼ ç»Ÿcurriculum learningè®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œå‘ç°æ•ˆæœå¹¶ä¸å¥½ï¼Œå› æ­¤è½¬è€Œä½¿ç”¨ä¸€ç§æ··åˆè®­ç»ƒæ–¹æ³•ã€‚ä¹Ÿå³éƒ¨åˆ†éšæœºé‡‡æ ·ï¼Œéƒ¨åˆ†é‡‡ç”¨ä¼ ç»Ÿcurriculum learningçš„é€æ¸æå‡éš¾åº¦ã€‚</p>
<p>ä¸ºä»€ä¹ˆä¼ ç»Ÿçš„ä¸å¤Ÿå¥½ï¼Ÿ<br>ä½œè€…çš„è§£é‡Šæ˜¯ï¼Œå¦‚æœä»ç®€å•çš„å¼€å§‹å­¦ï¼ŒLSTMä¼šå°†æ‰€æœ‰çš„memoryç”¨ä»¥è®°å¿†ç®€å•çš„æ ·æœ¬ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±æ„å»ºå¥½äº†è¿™å¥—patternï¼Œè€Œåœ¨é€æ¸å¢åŠ éš¾åº¦æ—¶ï¼Œè¦æ±‚å¯¹memoryçš„patterné‡ç»„ï¼Œè€Œè¿™ç‚¹ä¸å®¹æ˜“åšåˆ°ã€‚è€Œå¦‚æœé‡‡æ ·éƒ¨åˆ†éšæœºæ ·æœ¬ï¼Œåˆ™èƒ½å¤ŸåŒæ—¶å­¦ä¹ åˆ°éƒ¨åˆ†éš¾çš„exampleï¼Œä»è€Œ<strong>é˜²æ­¢overfitåˆ°æŸä¸ªç®€å•çš„patternä¸Š</strong>ã€‚</p>
<hr>
<h2 id="Self-Paced-Learning-for-Latent-Variable-Models"><a href="#Self-Paced-Learning-for-Latent-Variable-Models" class="headerlink" title="[Self-Paced Learning for Latent Variable Models]"></a>[Self-Paced Learning for Latent Variable Models]</h2><p>ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ä¼˜åŒ–ç®—æ³•ã€‚<del>è¯æ˜äº†curriculum learningä¹Ÿèƒ½åœ¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•ä¸­å–å¾—æ•ˆæœã€‚</del> 7.2æ›´æ–°ï¼šä¹‹å‰ç†è§£é”™äº†ï¼Œself-paced learningä¸Curriculum Learningè™½æœ‰å…±é€šä¹‹å¤„ä½†å¹¶ä¸æ˜¯ä¸€ä¸ªä¸œè¥¿ã€‚CLçš„difficulty scoreæ˜¯åœ¨è®­ç»ƒå‰å›ºå®šçš„ï¼Œè€ŒSPLæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ ¹æ®exampleçš„lossæ¥åŠ¨æ€å†³å®šçš„ã€‚</p>
<script type="math/tex; mode=display">\left(\mathbf{w}_{t+1}, \mathbf{v}_{t+1}\right)=\underset{\mathbf{w} \in \mathbb{R}^{d}, \mathbf{v} \in\{0,1\}^{n}}{\operatorname{argmin}}\left(r(\mathbf{w})+\sum_{i=1}^{n} v_{i} f\left(\mathbf{x}_{i}, \mathbf{y}_{i} ; \mathbf{w}\right)-\frac{1}{K} \sum_{i=1}^{n} v_{i}\right)</script><p>åªæœ‰é‚£äº›èƒ½å¤Ÿå¾ˆå¥½fitçš„sampleä½œæ•°ï¼Œä¹Ÿå³ä½¿ç”¨äºŒå…ƒå˜é‡væ¥æ§åˆ¶ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯27</title>
    <url>/2019/06/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D27/</url>
    <content><![CDATA[<h3 id="å¤œä¸Šå—é™åŸé—»ç¬›"><a href="#å¤œä¸Šå—é™åŸé—»ç¬›" class="headerlink" title="å¤œä¸Šå—é™åŸé—»ç¬›"></a>å¤œä¸Šå—é™åŸé—»ç¬›</h3><p>[å”] æç›Š<br>å›ä¹å³°å‰æ²™ä¼¼é›ªï¼Œå—é™åŸå¤–æœˆå¦‚éœœã€‚<br><strong>ä¸çŸ¥ä½•å¤„å¹èŠ¦ç®¡ï¼Œä¸€å¤œå¾äººå°½æœ›ä¹¡</strong>ã€‚</p>
<p><a href="http://lib.xcz.im/work/57b91effa633bd00665e4f15" target="_blank" rel="noopener">http://lib.xcz.im/work/57b91effa633bd00665e4f15</a></p>
<hr>
<h3 id="é¥®ä¸­å…«ä»™æ­Œ"><a href="#é¥®ä¸­å…«ä»™æ­Œ" class="headerlink" title="é¥®ä¸­å…«ä»™æ­Œ"></a>é¥®ä¸­å…«ä»™æ­Œ</h3><p>[å”] æœç”«<br>â€¦<br>æç™½æ–—é…’è¯—ç™¾ç¯‡ï¼Œé•¿å®‰å¸‚ä¸Šé…’å®¶çœ ï¼Œ<br>å¤©å­å‘¼æ¥ä¸ä¸Šèˆ¹ï¼Œè‡ªç§°è‡£æ˜¯é…’ä¸­ä»™ã€‚<br>â€¦</p>
<p><a href="http://lib.xcz.im/work/57b8e3a7c4c97100558e7dc6" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8e3a7c4c97100558e7dc6</a></p>
<p>æ–°å”ä¹¦Â·æç™½ä¼ ã€‹è½½ï¼šæç™½åº”è¯è‡³é•¿å®‰ï¼Œå”ç„å®—åœ¨é‡‘éŠ®æ®¿å¬è§ä»–ï¼Œå¹¶èµé£Ÿï¼Œäº²ä¸ºè°ƒç¾¹ï¼Œè¯ä¸ºä¾›å¥‰ç¿°æ—ã€‚æœ‰ä¸€æ¬¡ï¼Œç„å®—åœ¨æ²‰é¦™äº­å¬ä»–å†™é…ä¹çš„è¯—ï¼Œè€Œä»–å´åœ¨é•¿å®‰é…’è‚†å–å¾—å¤§é†‰ã€‚èŒƒä¼ æ­£ã€Šæç™½æ–°å¢“ç¢‘ã€‹è½½ï¼šç„å®—æ³›èˆŸç™½è²åœ°ï¼Œå¬æç™½æ¥å†™æ–‡ç« ï¼Œè€Œè¿™æ—¶æç™½å·²åœ¨ç¿°æ—é™¢å–é†‰äº†ï¼Œç„å®—å°±å‘½é«˜åŠ›å£«æ‰¶ä»–ä¸Šèˆ¹æ¥è§ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†21</title>
    <url>/2019/06/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8621/</url>
    <content><![CDATA[<h3 id="Dying-Relu"><a href="#Dying-Relu" class="headerlink" title="[Dying Relu]"></a>[Dying Relu]</h3><p>Dying Reluç°è±¡æŒ‡çš„æ˜¯ï¼Œåœ¨ä½¿ç”¨Reluä½œä¸ºæ¿€æ´»å‡½æ•°æ—¶ï¼Œå› ä¸ºå­¦ä¹ ç‡è¾ƒå¤§æˆ–æŸäº›åŸå› ï¼Œå¯¼è‡´æŸä¸€å±‚çš„biaså­¦åˆ°è¾ƒå¤§çš„è´Ÿå€¼ï¼Œä½¿å¾—è¯¥å±‚åœ¨è¿‡å®ŒReluæ¿€æ´»å‡½æ•°åçš„è¾“å‡ºå§‹ç»ˆæ˜¯0ã€‚</p>
<p><img src="/images/15594400435056.jpg" width="30%" height="50%"></p>
<p>å½“è¿›å…¥åˆ°è¿™ä¸€çŠ¶æ€æ—¶ï¼ŒåŸºæœ¬ä¸Šæ²¡åŠæ³•å†å›åˆ°æ­£å¸¸çŠ¶æ€ã€‚å› ä¸ºåœ¨å›ä¼ æ—¶ï¼Œå€¼ä¸º0å¯¼è‡´æ¢¯åº¦ä¹Ÿä¸º0ã€‚</p>
<p><a href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" target="_blank" rel="noopener">https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Dying Relu</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯26</title>
    <url>/2019/05/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D26/</url>
    <content><![CDATA[<h3 id="å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—"><a href="#å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—" class="headerlink" title="å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—"></a>å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—</h3><p>å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—ï¼Œ<br>æ•Œäººç”¨åˆºåˆ€<br>æ€æ­»äº†æˆ‘ä»¬ï¼Œ<br>è¿˜è¦ç”¨æ‰‹æŒ‡ç€æˆ‘ä»¬éª¨å¤´è¯´ï¼š<br>â€œçœ‹ï¼Œ<br>è¿™æ˜¯å¥´éš¶ï¼â€</p>
<hr>
<h3 id="èœ€å…ˆä¸»åº™"><a href="#èœ€å…ˆä¸»åº™" class="headerlink" title="èœ€å…ˆä¸»åº™"></a>èœ€å…ˆä¸»åº™</h3><p>[å”] åˆ˜ç¦¹é”¡<br><strong>å¤©åœ°è‹±é›„æ°”ï¼Œåƒç§‹å°šå‡›ç„¶ã€‚</strong><br>åŠ¿åˆ†ä¸‰è¶³é¼ï¼Œä¸šå¤äº”é“¢é’±ã€‚<br>å¾—ç›¸èƒ½å¼€å›½ï¼Œç”Ÿå„¿ä¸è±¡è´¤ã€‚<br>å‡„å‡‰èœ€æ•…å¦“ï¼Œæ¥èˆé­å®«å‰ã€‚</p>
<p><a href="http://lib.xcz.im/work/57b90d29d342d3005ac78cb5" target="_blank" rel="noopener">http://lib.xcz.im/work/57b90d29d342d3005ac78cb5</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>AIS2019è®ºæ–‡æŠ¥å‘Šä¼šä¹‹æ­å·è¡Œæµæ°´è´¦</title>
    <url>/2019/05/28/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/AIS2019%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E6%9D%AD%E5%B7%9E%E8%A1%8C/</url>
    <content><![CDATA[<p>è¶ç€AIS2019è®ºæ–‡æŠ¥å‘Šä¼šï¼Œç»ˆäºæœ‰æœºä¼šå…¬è´¹æ—…æ¸¸å•¦ğŸ˜„</p>
<p>æ­å·éƒŠåŒºè¿˜æ˜¯è›®ç¹åçš„å“‡ã€‚å¦¹æƒ³åˆ°ã€‚</p>
<p><img src="/images/15590541433996.jpg" width="70%" height="50%"></p>
<p>ä¸ºäº†ç­‰lzyä¸‹è½¦ï¼Œåˆ°åç‚¹é’Ÿæ‰åƒæ™šé¥­ï¼Œéš¾é¡¶ğŸ™„ï¼Œåƒåˆ°12ç‚¹åŠã€‚</p>
<p><img src="/images/lzy.jpg" width="70%" height="50%"></p>
<p>æ‰¾äº†åŠå°æ—¶æ‰¾ä¸åˆ°é…’åº—ï¼Œè¿˜æ˜¯æ±‚åŠ©äº†åŒè¡Œçš„å…¶ä»–å°ä¼™ä¼´æ‰æ‰¾åˆ°ğŸ¤¦â€â™‚ï¸</p>
<p><img src="/images/room.jpg" width="70%" height="50%"></p>
<p><strong>Day1</strong>ï¼š</p>
<p>ç¡åˆ°11ç‚¹æ‰åŒ†åŒ†èµ¶åˆ°ä¼šåœº</p>
<p><img src="/images/15590935394726.jpg" width="70%" height="50%"></p>
<p>å¬äº†å‡ åœºå°±æ˜æ˜æ¬²ç¡äº†ï¼Œè€Œä¸”ä¼šè®®å®¤å†…ç½‘ç»œä¹Ÿå¤ªå·®äº†8ï¸âƒ£</p>
<p><img src="/images/15590935878376.jpg" width="70%" height="50%"></p>
<p>å†³å®šä¸‹åˆå·è·‘</p>
<p>ä¸‹åˆé¸½äº†ä»–ä»¬ï¼Œå›åˆ°å®¿èˆä¸€è§‰åˆç¡åˆ°5ç‚¹ã€‚ç™¾æ— èŠèµ–ï¼Œè¿˜æ˜¯åˆ°è¥¿æ¹–èµ°èµ°8ï¸âƒ£ğŸ˜†</p>
<p><img src="/images/15590936999475.jpg" width="70%" height="50%"></p>
<p><img src="/images/15590937248588.jpg" width="70%" height="50%"></p>
<p><img src="/images/15590938011843.jpg" width="70%" height="50%"></p>
<p>å¤©ä¸‹ç€é›¨ï¼Œåˆæ˜¯å¤§æ™šä¸Šï¼Œå…¶å®å•¥ä¹Ÿçœ‹ä¸åˆ°ã€‚èµ°äº†ä¸¤ä¸ªå°æ—¶ï¼Œä»æ–­æ¡¥èµ°åˆ°é›·å³°å¡”ğŸ¤¦â€â™‚ï¸ã€‚</p>
<p>å›åˆ°å®¿èˆï¼Œæœ¬æ¥è¦ç¡äº†ï¼Œä½†åˆé¢‡æœ‰äº›é¥¿ã€‚æŠŠåŒè¡Œçš„å°ä¼™ä¼´éƒ½æ‹‰ä¸Šï¼Œå¼€å§‹æ‰¾å®µå¤œğŸ˜‹</p>
<p><img src="/images/751559093999_.pic_hd.jpg" width="70%" height="50%"></p>
<p>ç­‰ljzä¸‹æ¥ç­‰åˆ°ä¸‰ä¸ªäººéƒ½å¼€å§‹æ‰“æ¸¸æˆäº†ğŸ™„</p>
<p><img src="/images/771559094127_.pic_hd.jpg" width="40%" height="50%"></p>
<p>å¼€å†²ï¼<br><img src="/images/781559094310_.pic_hd.jpg" width="70%" height="50%"></p>
<p>å…­ä¸ªäººç‚¹äº†4ç“¶é…’æœ€åé€€äº†ä¸¤ç“¶ã€‚å¤§å®¶å¯çœŸæ˜¯å¤ªèœäº†8ï¸âƒ£ğŸ¤¦â€â™‚ï¸</p>
<hr>
<p>Day2:</p>
<p>åˆæ˜¯ç¡åˆ°11ç‚¹ï¼Œåƒäº†ç‚¹ä¸œè¥¿ä¼‘æ¯ä¸€ä¸‹å°±å»åƒåˆé¥­äº†ã€‚</p>
<p>è‚¯å¾·åŸºçš„é¥­çœŸæ˜¯éš¾åƒåˆ°çˆ†ï¼Œå·®ç‚¹åäº†ğŸ¤¢ã€‚</p>
<p><img src="/images/15590944817604.jpg" width="40%" height="50%"></p>
<p>åœ¨åº§ä½ä¸Šç™¾æ— èŠèµ–çœ‹äº†ä¸¤ä¸ªå°æ—¶è§†é¢‘ï¼Œå‡ºå‘åˆ°ä¼šåœºï¼Œç­‰å…¶ä»–äººä¸€èµ·åˆ°é™†æ€»ğŸ åƒé¥­ğŸ˜¬ï¼ˆæ­¤è¡Œæœ€å¤§çš„motivation</p>
<p>é™†æ€»ğŸ çš„é¥­èœä¹Ÿå¤ªä¸°ç››äº†8ï¸âƒ£ï¼Œåƒåˆ°æ’‘ã€‚è¿˜è®¤è¯†äº†å‡ ä¸ªæ–°çš„å°ä¼™ä¼´(wsä¸xlw)ã€‚äº†è§£åˆ°è¶…å¤šä»¥å‰è½¯ä»¶å­¦é™¢çš„å…«å¦ã€‚æ€»çš„æ¥è¯´éå¸¸å¼€å¿ƒ</p>
<p><img src="/images/791559094738_.pic_hd.jpg" width="60%" height="50%"></p>
<p><img src="/images/801559094815_.pic_hd.jpg" width="60%" height="50%"></p>
<p>æºœäº†æºœäº†ã€‚</p>
]]></content>
      <tags>
        <tag>æ´»åŠ¨</tag>
        <tag>AIS</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡19</title>
    <url>/2019/05/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8719/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>Generating Long Sequences with Sparse Transformers</li>
<li>CBAM: Convolutional Block Attention Module</li>
<li>Pyramid Scene Parsing Network</li>
</ol>
<h2 id="Generating-Long-Sequences-with-Sparse-Transformers"><a href="#Generating-Long-Sequences-with-Sparse-Transformers" class="headerlink" title="[Generating Long Sequences with Sparse Transformers]"></a>[Generating Long Sequences with Sparse Transformers]</h2><p>Motivationï¼štransformerå¯¹é•¿åºåˆ—ä¸å‹å¥½ï¼Œå¤æ‚åº¦è¾ƒé«˜ï¼›æœ¬æ–‡æå‡ºsparse transformerå¯¹<strong>ç”Ÿæˆ</strong>é•¿åºåˆ—çš„è®¡ç®—è¿›è¡Œä¼˜åŒ–ï¼Œå¤æ‚åº¦èƒ½å¤Ÿé™åˆ°$O(n \sqrt{n})$ã€‚</p>
<p>å®é™…ä¸Šå°±æ˜¯å°†å…¨è¿æ¥çš„attentionåˆ†åŒ–æˆå‡ ä¸ªsparseçš„attentionã€‚</p>
<p><img src="/images/15590983353143.jpg" width="60%" height="50%"></p>
<p>å¦‚ä¸Šå›¾ï¼Œå®é™…ä¸Šå°±æ˜¯è®©éƒ¨åˆ†head attendå‰é¢å‡ ä¸ªlocalï¼›éƒ¨åˆ†head attendåˆ°æ›´æ—©çš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ˜¯è·³ç€çœ‹çš„ï¼ˆä¸¤ç§patternï¼‰ã€‚æˆ–è€…è¿˜å¯ä»¥è®©æ‰€æœ‰headéƒ½attendåˆ°è¿™äº›sparseçš„ç‚¹ã€‚</p>
<p>å½“ç„¶ä¹Ÿå¯ä»¥æ‰©å±•åˆ°å¤šç»´ç©ºé—´ã€‚å°†headåˆ†ä¸ºnç»„ï¼Œæ¯ä¸ªç»„è·³ç€çœ‹çš„ä¸ä¸€æ ·ã€‚</p>
<p>å…¶ä»–ä¼¼ä¹éƒ½æ˜¯ç»†èŠ‚ï¼Œæ²¡å•¥å¸®åŠ©ã€‚</p>
<p>å¹¶ä¸”è¿˜æ”¹äº†ä¸€ä¸‹transformerçš„è®¡ç®—è¿‡ç¨‹ï¼Œä»¥åŠåšäº†GPU kernelåº•å±‚çš„åŠ é€Ÿã€‚å…¶ä»–ä¼¼ä¹æ²¡æœ‰ä»€ä¹ˆinsightçš„åœ°æ–¹ã€‚</p>
<p>æ€è€ƒï¼š<br>è¿™å®é™…ä¸Šå°±æ˜¯å‡è®¾äº†ä¸€ä¸ªè¾ƒå¼ºçš„å…ˆéªŒäº†ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆçš„æ—¶å€™ç¡®å®å¯èƒ½å­˜åœ¨è¿™ç§patternï¼Œå› ä¸ºç”Ÿæˆè¦è¾¾åˆ°å¥½çš„æ•ˆæœï¼Œæ¯ä¸ªç‚¹éƒ½å¿…é¡»æ€»ç»“å‰é¢æ‰€æœ‰ç‚¹çš„ä¿¡æ¯ã€‚ä½†å¦‚æœä¸æ˜¯ç”Ÿæˆï¼Œæ˜¯å¦ä¹Ÿæœ‰è¿™ç§patternï¼Ÿ<br>è®ºæ–‡å¼ºè¡Œå°†æ–‡æœ¬ä¹Ÿåˆ‡æˆäºŒç»´ï¼Œè€Œä¸”ç”¨äº†30å±‚ï¼›æ„Ÿè§‰ä¸æ˜¯é‚£ä¹ˆæœ‰é“ç†ã€‚å› ä¸ºè¿™ç§sparseæ˜¯ä»å›¾åƒä¸­è§‚å¯Ÿå¾—åˆ°çš„ï¼Œæ˜¯å¦ä¹Ÿèƒ½åº”ç”¨äºæ–‡æœ¬ï¼Ÿä¼šä¸ä¼šæœ‰å¯èƒ½æ˜¯30å±‚æ‰è¾¾åˆ°è¿™ä¹ˆå¥½çš„æ•ˆæœï¼Ÿ</p>
<hr>
<h2 id="CBAM-Convolutional-Block-Attention-Module"><a href="#CBAM-Convolutional-Block-Attention-Module" class="headerlink" title="[CBAM: Convolutional Block Attention Module]"></a>[CBAM: Convolutional Block Attention Module]</h2><p>æå‡ºåœ¨channelç»´åº¦ä¸ç©ºé—´ç»´åº¦çš„åŒé‡attentionã€‚å’ŒSE-Netç›¸æ¯”åŠ äº†ä¸€å±‚ç©ºé—´ç»´åº¦ä¸Šçš„äº¤äº’ï¼Œåšæ³•å‡ ä¹éƒ½å·®ä¸å¤šã€‚</p>
<p><img src="/images/15590990182833.jpg" width="60%" height="50%"></p>
<p>å…·ä½“åšæ³•ï¼š<br><img src="/images/15590991719663.jpg" width="60%" height="50%"></p>
<p>â‘ åœ¨channelç»´åº¦ä¸Šåšattention</p>
<script type="math/tex; mode=display">\begin{aligned} \mathbf{M}_{\mathbf{c}}(\mathbf{F}) &=\sigma(M L P(A v g P o o l(\mathbf{F}))+M L P(M a x P o o l(\mathbf{F}))) \\ &=\sigma\left(\mathbf{W}_{\mathbf{1}}\left(\mathbf{W}_{\mathbf{0}}\left(\mathbf{F}_{\mathbf{a v g}}^{\mathbf{c}}\right)\right)+\mathbf{W}_{\mathbf{1}}\left(\mathbf{W}_{\mathbf{0}}\left(\mathbf{F}_{\mathbf{m a x}}^{\mathbf{c}}\right)\right)\right) \end{aligned}</script><p>å¯¹è¾“å…¥æŒ‰ç©ºé—´ç»´åº¦æ‹æ‰è·å¾—Cç»´çš„poolingã€‚å®é™…ä¸Šå°±æ˜¯ç”¨average poolingå’Œmax pooling è¿‡çº¿æ€§å±‚+sigmoidã€‚å’ŒSE-Netç›¸æ¯”åªæ˜¯å¤šåˆ©ç”¨äº†max-poolingã€‚</p>
<p>â‘¡åœ¨ç©ºé—´ç»´åº¦ä¸Šåšattention</p>
<script type="math/tex; mode=display">\begin{aligned} \mathbf{M}_{\mathbf{s}}(\mathbf{F}) &=\sigma\left(f^{7 \times 7}([A v g P o o l(\mathbf{F}) ; M a x P \operatorname{ool}(\mathbf{F})])\right) \\ &=\sigma\left(f^{7 \times 7}\left(\left[\mathbf{F}_{\mathbf{a v g}}^{\mathbf{s}} ; \mathbf{F}_{\mathbf{m a x}}^{\mathbf{s}}\right]\right)\right) \end{aligned}</script><p>åŒæ ·æ˜¯æŒ‰channelç»´åº¦æ‹æ‰åšmax/mean poolingã€‚è·å¾—çš„æ˜¯H<em>W</em>1çš„ç»´åº¦ï¼Œç„¶åæ‹¼èµ·æ¥è¿‡CNN+sigmoidã€‚</p>
<p>æ€è€ƒï¼šä¼¼ä¹åˆ›æ–°æ€§ä¸è¶³ï¼Œå¹¶æ²¡æœ‰æä¾›ä¸€äº›æœ‰ç”¨çš„insightã€‚</p>
<hr>
<h2 id="Pyramid-Scene-Parsing-Network"><a href="#Pyramid-Scene-Parsing-Network" class="headerlink" title="[Pyramid Scene Parsing Network]"></a>[Pyramid Scene Parsing Network]</h2><p><img src="/images/15590993469941.jpg" width="70%" height="50%"></p>
<p>åˆ©ç”¨pyramid poolingï¼ˆä¹Ÿå³ä¸åŒkernel sizeçš„poolingçš„ç»“åˆï¼‰åšåˆ‡å‰²çš„ä»»åŠ¡ã€‚</p>
<p>è¿™æ˜¯pyramid poolingï¼Œä¹Ÿå³åˆ†å±‚æ¬¡çš„poolingï¼š</p>
<p><img src="/images/15590994146803.jpg" width="60%" height="50%"></p>
<p>å…¶ä»–æ²¡æ„Ÿè§‰ã€‚</p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>CBAM</tag>
        <tag>pyramid pooling</tag>
      </tags>
  </entry>
  <entry>
    <title>åªæœ‰åœ¨ä½ å·¥ä½œå †ç§¯å¦‚å±±æ—¶ï¼Œä½ æ‰å¯èƒ½äº«å—é—²æš‡</title>
    <url>/2019/05/27/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E5%8F%AA%E6%9C%89%E5%9C%A8%E4%BD%A0%E5%B7%A5%E4%BD%9C%E5%A0%86%E7%A7%AF%E5%A6%82%E5%B1%B1%E6%97%B6%EF%BC%8C%E4%BD%A0%E6%89%8D%E5%8F%AF%E8%83%BD%E4%BA%AB%E5%8F%97%E9%97%B2%E6%9A%87/</url>
    <content><![CDATA[<p>â€œåªæœ‰åœ¨ä½ å·¥ä½œå †ç§¯å¦‚å±±æ—¶ï¼Œä½ æ‰å¯èƒ½äº«å—é—²æš‡ã€‚å½“ä½ æ— äº‹å¯åšæ—¶ï¼Œç©ºé—²å°±å˜å¾—ä¸€ç‚¹ä¹Ÿä¸æœ‰è¶£ï¼Œå› ä¸ºç©ºé—²å°±æ˜¯ä½ çš„å·¥ä½œï¼Œè€Œä¸”æ˜¯æœ€è€—äººçš„å·¥ä½œã€‚é—²æ‡’å’Œå»ä¸€æ ·ï¼Œå½“å®ƒè¢«ç›—èµ°äº†ä¹‹åï¼Œå®ƒçš„å‘³é“æ‰æ˜¯ç”œçš„ã€‚â€â€”â€”â€” æ°ç½—å§†Â·KÂ·æ°ç½—å§†</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ— åè‹±é›„çºªå¿µç¢‘é“­</title>
    <url>/2019/05/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E5%90%8D%E8%8B%B1%E9%9B%84%E7%BA%AA%E5%BF%B5%E7%A2%91%E9%93%AD/</url>
    <content><![CDATA[<h3 id="æ— åè‹±é›„çºªå¿µç¢‘é“­"><a href="#æ— åè‹±é›„çºªå¿µç¢‘é“­" class="headerlink" title="æ— åè‹±é›„çºªå¿µç¢‘é“­"></a>æ— åè‹±é›„çºªå¿µç¢‘é“­</h3><p>å¤«å¤©ä¸‹æœ‰å¤§å‹‡è€…ï¼Œæ™ºä¸èƒ½æµ‹ï¼Œåˆšä¸èƒ½åˆ¶ï¼ŒçŒç„¶ä¸´ä¹‹è€Œä¸æƒŠï¼Œæ— æ•…åŠ ä¹‹è€Œä¸æ€’ï¼Œæ­¤å…¶æ™ºç”šè¿œï¼Œæ‰€æ€€ç”šå¤§ä¹Ÿã€‚æ‰€æ€€è€…ä½•ï¼Ÿå¤©ä¸‹æœ‰é¥¥è€…ï¼Œå¦‚å·±ä¹‹é¥¥ï¼Œå¤©ä¸‹æœ‰æººè€…ï¼Œå¦‚å·±ä¹‹æººè€³ã€‚æ°‘æ—å±æ€¥ï¼Œåˆ«äº²ç¦»å­è€Œèµ´æ°´ç«ï¼Œæ˜“é¢äº‹æ•Œè€Œæ±‚å¤§åŒã€‚é£è§æ°´å¯’ï¼Œæ—Œéœœå±¥è¡€ï¼Œæˆ–æˆæˆ–è´¥ï¼Œæˆ–å›šæˆ–æ®(mÃ²)ï¼Œäººä¸çŸ¥ä¹‹ï¼Œä¹ƒè‡³æ®’åæ— åã€‚  é“­æ›°ï¼šå‘œå‘¼ï¼å¤§éŸ³å¸Œå£°ï¼Œå¤§è±¡æ— å½¢ã€‚æ¥å…®ç²¾é­„ï¼Œå®‰å…®è‹±çµã€‚é•¿æ²³ä¸ºå’½ï¼Œé’å±±ä¸ºè¯ï¼›å²‚æ›°æ— å£°ï¼Ÿæ²³å±±å³åï¼  äººæœ‰æ‰€å¿˜ï¼Œå²æœ‰æ‰€è½»ã€‚ä¸€ç»Ÿå¯æœŸï¼Œæ°‘æ—å°†å…´ï¼Œè‚ƒä¹‹å˜‰çŸ³ï¼Œæ²æ‰‹å‹’é“­ã€‚å™«æˆ‘å­å­™ï¼Œä»£ä»£æ°¸æ—Œã€‚ å…¬å…ƒäºŒé›¶ä¸€ä¸‰å¹´åæœˆç«‹ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ— é¢˜</title>
    <url>/2019/05/14/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%F0%9F%87%A8%F0%9F%87%B3/</url>
    <content><![CDATA[<p>äº”åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå¤åŸƒåŠäººä¸€æ ·é¢å¯¹æ´ªæ°´ï¼›<br>å››åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå·´æ¯”ä¼¦äººä¸€æ ·ç©é’é“œå™¨ï¼›<br>ä¸‰åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå¤å¸Œè…Šäººä¸€æ ·æ€è€ƒå“²å­¦ï¼›<br>ä¸¤åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œç½—é©¬äººä¸€æ ·å››å¤„å¾ä¼ï¼›<br>ä¸€åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œé˜¿æ‹‰ä¼¯äººä¸€æ ·æ— æ¯”å¯Œè¶³ï¼›<br>äº”åƒå¹´äº†ï¼Œ<br>æˆ‘ä»¬ä¸€ç›´åœ¨ä¸–ç•Œçš„ç‰Œæ¡Œä¸Šæ‰“ç€éº»å°†ï¼Œ<br>è€Œå¦å¤–å‡ å®¶å·²ç»æ¢è¿‡å¥½å¤šè½®ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•17</title>
    <url>/2019/05/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9517/</url>
    <content><![CDATA[<h3 id="Pytorch-restartå†™æ³•"><a href="#Pytorch-restartå†™æ³•" class="headerlink" title="[Pytorch restartå†™æ³•]"></a>[Pytorch restartå†™æ³•]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.restart:</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(args.restart_dir, <span class="string">'model.pt'</span>), <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model = torch.load(f)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡"><a href="#Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡" class="headerlink" title="[Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡]"></a>[Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">args.n_all_param = sum([p.nelement() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()])</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥"><a href="#Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥" class="headerlink" title="[Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥]"></a>[Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># transformer-xlæ ·ä¾‹</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_lm_corpus</span><span class="params">(datadir, dataset)</span>:</span></span><br><span class="line">    fn = os.path.join(datadir, <span class="string">'cache.pt'</span>)</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(fn):</span><br><span class="line">        print(<span class="string">'Loading cached dataset...'</span>)</span><br><span class="line">        corpus = torch.load(fn)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'Producing dataset &#123;&#125;...'</span>.format(dataset))</span><br><span class="line">        kwargs = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> dataset <span class="keyword">in</span> [<span class="string">'wt103'</span>, <span class="string">'wt2'</span>]:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = [<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">elif</span> dataset == <span class="string">'ptb'</span>:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = [<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">elif</span> dataset == <span class="string">'lm1b'</span>:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = []</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">False</span></span><br><span class="line">            kwargs[<span class="string">'vocab_file'</span>] = os.path.join(datadir, <span class="string">'1b_word_vocab.txt'</span>)</span><br><span class="line">        <span class="keyword">elif</span> dataset <span class="keyword">in</span> [<span class="string">'enwik8'</span>, <span class="string">'text8'</span>]:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        corpus = Corpus(datadir, dataset, **kwargs)</span><br><span class="line">        torch.save(corpus, fn)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corpus</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="Pytorchè‡ªå¸¦APIå®ç°inverse-sqrtçš„lr-schedule"><a href="#Pytorchè‡ªå¸¦APIå®ç°inverse-sqrtçš„lr-schedule" class="headerlink" title="[Pytorchè‡ªå¸¦APIå®ç°inverse sqrtçš„lr schedule]"></a>[Pytorchè‡ªå¸¦APIå®ç°inverse sqrtçš„lr schedule]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># from transformer-xl</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># originally used for Transformer (in Attention is all you need)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_lambda</span><span class="params">(step)</span>:</span></span><br><span class="line">    <span class="comment"># return a multiplier instead of a learning rate</span></span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span> <span class="keyword">and</span> args.warmup_step == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (step ** <span class="number">0.5</span>) <span class="keyword">if</span> step &gt; args.warmup_step \</span><br><span class="line">            <span class="keyword">else</span> step / (args.warmup_step ** <span class="number">1.5</span>)</span><br><span class="line">            </span><br><span class="line">scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯25</title>
    <url>/2019/05/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D25/</url>
    <content><![CDATA[<h3 id="è¥¿æ±Ÿæœˆ"><a href="#è¥¿æ±Ÿæœˆ" class="headerlink" title="è¥¿æ±Ÿæœˆ"></a>è¥¿æ±Ÿæœˆ</h3><p><strong>ä¸–äº‹ä¸€åœºå¤§æ¢¦ï¼Œäººç”Ÿå‡ åº¦æ–°å‡‰</strong>ï¼Ÿå¤œæ¥é£å¶å·²é¸£å»Šï¼Œçœ‹å–çœ‰å¤´é¬“ä¸Šã€‚<br>é…’è´±å¸¸æ„å®¢å°‘ï¼Œæœˆæ˜å¤šè¢«äº‘å¦¨ã€‚ä¸­ç§‹è°ä¸å…±å­¤å…‰ï¼ŒæŠŠç›å‡„ç„¶åŒ—æœ›ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡18</title>
    <url>/2019/05/12/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8718/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</li>
<li>Ordered Neurons- Integrating Tree Structures into Recurrent Neural Networks</li>
<li>Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification</li>
<li>Unified Language Model Pre-training for Natural Language Understanding and Generation</li>
<li>Language Models are Unsupervised Multitask Learners</li>
<li>MASS: Masked Sequence to Sequence Pre-training for Language Generation</li>
<li>Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks</li>
<li>PSANet: Point-wise Spatial Attention Network for Scene Parsing</li>
<li>CCNet: Criss-Cross Attention for Semantic Segmentation</li>
</ol>
<h2 id="GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond"><a href="#GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond" class="headerlink" title="[GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond]"></a>[GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond]</h2><p>æå‡ºä¸€ç§æ–°çš„å¯¹é•¿è·ç¦»ä¾èµ–å»ºæ¨¡çš„æ–¹æ³•ï¼Œå¹¶ç»“åˆäº†ä¹‹å‰å…¶ä»–ç ”ç©¶è€…çš„å·¥ä½œï¼ŒæŠ½è±¡å¾—åˆ°å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ï¼ˆglobal context modelingï¼‰çš„æ¡†æ¶ã€‚</p>
<p>ç›®å‰é•¿è·ç¦»ä¾èµ–å»ºæ¨¡æœ‰ä¸¤ç§ï¼šä¸€ç§æ˜¯å¼•å…¥self-attentionæœºåˆ¶ï¼Œè·å¾—query-dependentçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¦‚NL-Netï¼›å¦ä¸€ç§åˆ™æ˜¯query-independentçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¦‚SE-Netã€‚</p>
<h3 id="Simplified-NL-Net"><a href="#Simplified-NL-Net" class="headerlink" title="Simplified NL-Net"></a>Simplified NL-Net</h3><p>Motivationï¼šé€šè¿‡å¯¹Non-local networkçš„åˆ†æï¼Œå‘ç°ç½‘ç»œå®é™…ä¸Šå­¦åˆ°çš„æ˜¯queryæ— å…³çš„ä¸Šä¸‹æ–‡ï¼Œå› æ­¤å¯ä»¥ç›´æ¥å¯¹NL-Netè¿›è¡Œç®€åŒ–ã€‚</p>
<p>é¦–å…ˆæ˜¯å¯¹NL-Netçš„è§‚å¯Ÿï¼Œé€šè¿‡å¯è§†åŒ–ï¼Œä»¥åŠç»Ÿè®¡å¾—åˆ°çš„æ•°æ®ï¼Œå¯ä»¥å‘ç°ï¼ŒNL-Netå¯¹äºæ¯ä¸ªqueryæ¥è¯´ï¼Œå…¶å­¦åˆ°çš„å…¨å±€ä¿¡æ¯å·®å¼‚å¾ˆå°ã€‚</p>
<p><img src="/images/15576253999087.jpg" width="80%" height="50%"></p>
<p><img src="/images/15576254102911.jpg" width="60%" height="50%"></p>
<p>åŒæ—¶ï¼ŒNL-Netç”±äºè¿™ç§query-dependentçš„é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ï¼Œæ‹¥æœ‰è¾ƒé«˜çš„å¤æ‚åº¦ï¼ˆå¹³æ–¹çº§åˆ«ï¼‰ã€‚å› æ­¤é¦–å…ˆæˆ‘ä»¬å¯ä»¥å¯¹NL-Netè¿›è¡Œç®€åŒ–ã€‚</p>
<p><img src="/images/15576254433886.jpg" width="60%" height="50%"></p>
<p>åŸæ¥çš„NL-Netæ˜¯ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{z} \sum_{j=1}^{N_{p}} \frac{f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)}{\mathcal{C}(\mathbf{x})}\left(W_{v} \cdot \mathbf{x}_{j}\right)</script><p>æ¯ä¸¤ä¸ªfeatureä¹‹é—´è®¡ç®—ä¸€ä¸ªattentionåˆ†æ•°ã€‚</p>
<p>å°†query-dependentå»æ‰åï¼Œåˆ™æœ‰ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+\sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)}\left(W_{v} \cdot \mathbf{x}_{j}\right)</script><p>è¿˜å¯ä»¥å°†$W_{v}$ç§»åˆ°å¤–é¢ï¼Œæ›´è¿›ä¸€æ­¥åœ°ç®€åŒ–ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{v} \sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)} \mathbf{x}_{j}</script><h3 id="Global-Context-Modeling-Framework"><a href="#Global-Context-Modeling-Framework" class="headerlink" title="Global Context Modeling Framework"></a>Global Context Modeling Framework</h3><p>é€šè¿‡å¯¹æ¯”è¿‘æœŸç›¸å…³çš„å·¥ä½œï¼Œä½œè€…å°†å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡çš„æ–¹æ³•æŠ½è±¡å‡ºæ¥ï¼Œåˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š<br>a)global attention pooling å°†å…¨å±€çš„ä¿¡æ¯æ”¶é›†èµ·æ¥ï¼Œä¼´éšç€ä¸€ä¸ªå…¨è¿æ¥å’Œsoftmax<br>b)feature transform via a 1x1 convolution Wv  å°†æ‰€è·å¾—çš„featureè¿›è¡Œçº¿æ€§è½¬æ¢ã€‚<br>c)feature aggregation å°†global featureä¸æ¯ä¸ªpositionèåˆã€‚</p>
<p>å½¢å¼åŒ–åˆ™æœ‰ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=F\left(\mathbf{x}_{i}, \delta\left(\sum_{j=1}^{N_{p}} \alpha_{j} \mathbf{x}_{j}\right)\right)</script><p>å¦‚æœä»è¿™ä¸ªè§’åº¦å»ç†è§£ï¼Œé‚£ä¹ˆSE-Netä¹Ÿæ˜¯å±äºè¯¥æ¡†æ¶çš„ä¸€ç§å®ä¾‹ã€‚</p>
<p><img src="/images/15576257652930.jpg" width="87%" height="50%"></p>
<p>ä½œè€…åœ¨è¯¥æ¡†æ¶çš„åŸºç¡€ä¸Šæå‡ºäº†æ–°çš„å®ä¾‹ï¼Œä¹Ÿå³GC-Netï¼ŒåŒæ—¶æœ‰NL-Netçš„é«˜æ•ˆå»ºæ¨¡çš„ä¼˜ç‚¹å’ŒSE-Netçš„è®¡ç®—æ•ˆç‡é«˜çš„ä¼˜ç‚¹ã€‚</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{v 2} \operatorname{ReLU}\left(\operatorname{LN}\left(W_{v 1} \sum_{j=1}^{N_{p}} \frac{e^{W_{k} \mathbf{x}_{j}}}{\sum_{m=1}^{N_{p}} e^{W_{k} \mathbf{x}_{m}}} \mathbf{x}_{j}\right)\right)</script><p>ç¬¬ä¸€ï¼ŒåŸºæœ¬é‡‡ç”¨NL-Netçš„å½¢å¼ï¼Œç®€åŒ–æˆquery-independentçš„å½¢å¼ï¼Œå¹¶ä¸”ä½¿ç”¨çš„æ˜¯åŠ çš„å½¢å¼è€Œä¸æ˜¯SE-Netçš„rescaleçš„å½¢å¼ï¼Œå°†global featureä¸æ¯ä¸ªä½ç½®èåˆã€‚<br>ç¬¬äºŒï¼Œé‡‡ç”¨SE-Netçš„bottleneckçš„å½¢å¼å»å‡å°‘å‚æ•°å’Œè®¡ç®—é‡ï¼Œå¹¶ä¸”åœ¨æ­¤åŸºç¡€ä¸Šå¤šäº†ä¸€æ­¥layer normä½¿å¾—æ¨¡å‹æ›´æ˜“è®­ç»ƒï¼Œå®è·µè¯æ˜ï¼Œlayer normèƒ½å¤Ÿæå‡è¡¨ç°ã€‚</p>
<h3 id="å¯¹æ¯”"><a href="#å¯¹æ¯”" class="headerlink" title="å¯¹æ¯”"></a>å¯¹æ¯”</h3><p>å¯¹æ¯”NL-Netï¼šä¸åŒä¹‹å¤„åœ¨äºglobal attention poolingï¼Œç”¨çš„æ˜¯query-independent<br>å¯¹æ¯”SE-Netï¼šä¸åŒä¹‹å¤„åœ¨äºfusion moduleï¼ˆæ¡†æ¶çš„ç¬¬ä¸‰æ­¥ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯additionè€Œä¸æ˜¯rescaleï¼›ä»¥åŠåœ¨bottleneckä¸Šåšäº†ä¸€ç‚¹æ”¹è¿›ï¼ŒåŠ äº†layer normã€‚</p>
<p>æ€è€ƒï¼š<br>æ–‡ç« æœ‰æ„æ€çš„ç‚¹æ˜¯ç«‹è¶³äºå®éªŒè§‚å¯Ÿï¼Œè¿™ç‚¹å€¼å¾—å­¦ä¹ ï¼Œä»å®è·µä¸­å‘ç°é—®é¢˜ã€‚åŒæ—¶ï¼Œåº”å­¦ä¼šç”¨æŠ½è±¡çš„æ€æƒ³å»æ€»ç»“å‰äººçš„å·¥ä½œï¼ˆæ¯”å¦‚NL-Netå®é™…ä¸Šä¹Ÿæ˜¯å¯¹å‰é¢çš„å·¥ä½œçš„æŠ½è±¡æ€»ç»“ï¼Œå®é™…ä¸Šä¸ªäººè®¤ä¸ºå¹¶æ²¡æœ‰ä»€ä¹ˆå¤§çš„åˆ›æ–°ï¼‰ï¼Œä»ä¸€ä¸ªæ›´é«˜çš„è§’åº¦å»çœ‹é—®é¢˜èƒ½å°†é—®é¢˜çœ‹å¾—æ›´æ¸…æ™°ã€‚</p>
<p>æŠ½è±¡å‡ºæ¡†æ¶æ˜¯æœ‰å¿…è¦çš„å—ï¼Ÿæˆ‘çœ‹åœ¨è¿™ç¯‡è®ºæ–‡é‡Œé¢æœ‰äº›å‹‰å¼ºï¼Œå› ä¸ºå®Œå…¨å¯ä»¥è¯´inspired by SE-Net for the computation efficiencyâ€¦ ä½†éè¦æŠ½è±¡æˆæ¡†æ¶ï¼Œä¼šä¸ä¼šåªæ˜¯è¦è¡¨ç°å‡ºå¯¹æ¨¡å‹çš„ç†è§£å¤Ÿæ·±ï¼Ÿä»¥åŠå¢åŠ ç‚¹å†…å®¹ï¼Ÿ</p>
<p>ä»¥åŠquery-dependentæ˜¯å¦çœŸçš„æ²¡å¿…è¦ï¼Ÿä¼¼ä¹åœ¨å…¶ä»–è®ºæ–‡ä¸­çš„ç»“è®ºåè€Œæ˜¯ç›¸åçš„ã€‚</p>
<hr>
<h2 id="Ordered-Neurons-Integrating-Tree-Structures-into-Recurrent-Neural-Networks"><a href="#Ordered-Neurons-Integrating-Tree-Structures-into-Recurrent-Neural-Networks" class="headerlink" title="[Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks]"></a>[Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks]</h2><p>ICLR19 best paperã€‚</p>
<p>åœ¨LSTMä¸­å¼•å…¥äº†æ–°çš„inductive biasï¼Œéšå¼å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚</p>
<p>Motivationï¼š<br>è¯­è¨€éƒ½æœ‰ä¸€å®šçš„æ ‘çš„ç»“æ„è€Œä¸æ˜¯åºåˆ—ç»“æ„ã€‚å‰äººç ”ç©¶è¡¨æ˜ï¼Œåœ¨NLPä¸­å¼•å…¥æ ‘çš„ç»“æ„æœ‰åŠ©äºå¢å¼ºæ³›åŒ–ï¼Œå¸®åŠ©å‡å°‘é•¿ç¨‹ä¾èµ–é—®é¢˜ï¼Œèƒ½å¤Ÿè·å¾—æ›´å¥½çš„æŠ½è±¡è¡¨ç¤ºã€‚<br>ä¸€äº›æ–¹æ³•åŒ…æ‹¬å¢åŠ ç›‘ç£ä¿¡å·ï¼Œä¹Ÿå³è¯­æ³•æ ‘ç­‰ï¼Œä½†è¯¥æ–¹æ³•æœ‰é™åˆ¶ï¼Œå¦‚æ ‡æ³¨æ•°æ®ä¸è¶³ï¼Œåœ¨ä¸€äº›é¢†åŸŸè¯­æ³•è§„åˆ™å®¹æ˜“è¢«æ‰“ç ´ï¼ˆå¦‚æ¨ç‰¹ï¼‰ï¼›åŒæ—¶éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¯­æ³•ä¹Ÿåœ¨å˜åŒ–ã€‚<br>åŒæ—¶ï¼Œä¸€äº›ç ”ç©¶ä¹Ÿè¡¨æ˜ï¼Œæœ‰è¶³å¤Ÿå®¹é‡çš„LSTMåœ¨èƒ½å¤Ÿéšå¼åœ°å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚</p>
<p>å› æ­¤åœ¨æœ¬æ–‡å¼•å…¥æ–°çš„inductive biasï¼Œ<strong>å®Œå…¨æ•°æ®é©±åŠ¨</strong>ï¼ˆç›¸å¯¹äºæ˜¾å¼æ„å»ºæ ‘ï¼‰ï¼Œéšå¼åœ°å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚è¿™ç§å½’çº³åç½®ä¿ƒè¿›äº†æ¯ä¸ªç¥ç»å…ƒå†…å­˜å‚¨çš„ä¿¡æ¯çš„ç”Ÿå‘½å‘¨æœŸçš„åˆ†åŒ–ã€‚high-rankingçš„ç¥ç»å…ƒä¿å­˜é•¿ç¨‹çš„ä¿¡æ¯ï¼Œåœ¨ä¸€ä¸ªè¾ƒé•¿æ—¶é—´æ­¥å†…ä¿å­˜ï¼Œè€Œlow-rankingåˆ™ä¿å­˜çŸ­ç¨‹ä¿¡æ¯ï¼Œèƒ½å¤Ÿå¿«é€Ÿè¢«é—å¿˜ã€‚å¼•å…¥cumulative softmaxï¼Œä¸€ç§æ–°çš„æ¿€æ´»å‡½æ•°æ¥ç”Ÿæˆmaster input gateå’Œforget gate ä¿è¯å½“ä¸€ä¸ªç¥ç»å…ƒè¢«æ›´æ–°/é—å¿˜ï¼Œå…¶åçš„ç¥ç»å…ƒéƒ½ä¼šè¢«æ›´æ–°/é—å¿˜ã€‚</p>
<h3 id="ORDERED-NEURONS"><a href="#ORDERED-NEURONS" class="headerlink" title="ORDERED NEURONS"></a>ORDERED NEURONS</h3><p>ç»™å®šè¯­è¨€åºåˆ—$S=\left(x_{1}, \dots, x_{T}\right)$ä»¥åŠå¯¹åº”çš„constituency treeï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è®¡ç®—æ—¶é—´æ­¥tçš„æ—¶å€™ï¼ŒéšçŠ¶æ€$h_t$èƒ½åŒ…å«è¯¥èŠ‚ç‚¹åˆ°æ ¹èŠ‚ç‚¹è·¯å¾„ä¸Šæ‰€æœ‰èŠ‚ç‚¹çš„ä¿¡æ¯ã€‚ç›´è§‚ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›è¯¥è·¯å¾„ä¸Šçš„èŠ‚ç‚¹éƒ½èƒ½å¤Ÿè¢«$h_t$çš„ä¸€éƒ¨åˆ†ç¥ç»å…ƒè¡¨ç¤ºã€‚ç”±äº$h_t$çš„ç»´åº¦æ˜¯å›ºå®šçš„ï¼Œè€Œè·¯å¾„ä¸Šçš„èŠ‚ç‚¹åˆ™æ˜¯åŠ¨æ€çš„ï¼Œå› æ­¤ä¸€ç§æœ€å¥½çš„æƒ…å†µå°±æ˜¯èƒ½å¤ŸåŠ¨æ€åˆ†é…æ¯ä¸ªèŠ‚ç‚¹åœ¨hidden stateçš„ç»´åº¦ã€‚</p>
<p>åœ¨ä¸Šè¿°æ€è·¯çš„åŸºç¡€ä¸Šï¼Œä½œè€…å¼•å…¥äº†ordered neuronsï¼Œå¼ºåˆ¶è®©ç¥ç»å…ƒè¡¨ç¤ºä¸åŒæ—¶é—´å°ºåº¦ä¸Šçš„ä¿¡æ¯ã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œhigh-rankingçš„ç¥ç»å…ƒä¿å­˜çš„æ—¶é—´é•¿ï¼Œä»£è¡¨çš„å°±æ˜¯æ¥è¿‘æ ‘æ ¹çš„èŠ‚ç‚¹ï¼Œè€Œlow-rankingçš„ç¥ç»å…ƒä¿å­˜æ—¶é—´çŸ­ï¼Œä»£è¡¨çš„å°±æ˜¯å°çš„æˆåˆ†ï¼ˆå¦‚phraseï¼‰ã€‚åŸåˆ™æ˜¯ï¼šè¦æ›´æ–°/é—å¿˜high-rankingçš„ç¥ç»å…ƒï¼Œåº”è¯¥å…ˆæŠŠlow-rankingçš„ç¥ç»å…ƒå…ˆæ›´æ–°/é—å¿˜æ‰ã€‚</p>
<p>å¦‚å›¾ï¼š</p>
<p><img src="/images/15576268851485.jpg" width="80%" height="50%"></p>
<h3 id="ON-LSTM-â€œOrdered-Neurons-LSTMâ€"><a href="#ON-LSTM-â€œOrdered-Neurons-LSTMâ€" class="headerlink" title="ON-LSTM (â€œOrdered Neurons LSTMâ€)"></a>ON-LSTM (â€œOrdered Neurons LSTMâ€)</h3><p>LSTMç»“æ„ï¼š</p>
<p>$\begin{array}{ll}{f_{t}=\sigma\left(W_{f} x_{t}+U_{f} h_{t-1}+b_{f}\right)} \\ {i_{t}=\sigma\left(W_{i} x_{t}+U_{i} h_{t-1}+b_{i}\right)} \\ {o_{t}=\sigma\left(W_{o} x_{t}+U_{o} h_{t-1}+b_{o}\right)} \\ {\hat{c}_{t}=\tanh \left(W_{c} x_{t}+U_{c} h_{t-1}+b_{c}\right)} \\ {h_{t}=o_{t} \circ \tanh \left(c_{t}\right)}\end{array}$</p>
<p>OH-LSTMä¸LSTMçš„ä¸åŒåœ¨äºä¿®æ”¹äº†cell stateçš„æ›´æ–°æ–¹å¼ã€‚</p>
<p>é¦–å…ˆå®šä¹‰æ–°çš„æ¿€æ´»å‡½æ•°ï¼š</p>
<script type="math/tex; mode=display">\hat{g}=\operatorname{cumax}(\ldots)=\operatorname{cumsum}(\operatorname{softmax}(\ldots))</script><p>$\hat{g}$å¯ä»¥çœ‹åšæ˜¯äºŒå…ƒgateçš„æœŸæœ›ï¼Œè€Œgå°†cell stateåˆ†æˆä¸¤ä¸ªsegment $g=(0, \dots, 0,1, \dots, 1)$ã€‚</p>
<p>å› ä¸ºç¦»æ•£çš„æ–¹æ³•ä¸å¥½ä¼˜åŒ–ï¼Œä»¥åŠå¤ªè¿‡ä¸¥æ ¼ã€‚å…·ä½“çš„è§£é‡Šå’Œè¯æ˜åœ¨è®ºæ–‡é‡Œã€‚</p>
<p>å¼•å…¥ä¸¤ä¸ªæ–°çš„gateï¼Œmaster forget gateå’Œmaster input gateã€‚forget gateçš„å€¼å•è°ƒé€’å¢ï¼›è€Œinput gateçš„å€¼å•è°ƒé€’å‡ã€‚</p>
<p>$\begin{aligned} \tilde{f}_{t} &amp;=\operatorname{cumax}\left(W_{\tilde{f}} x_{t}+U_{\tilde{f}} h_{t-1}+b_{\tilde{f}}\right) \\ \tilde{i}_{t} &amp;=1-\operatorname{cumax}\left(W_{\tilde{i}} x_{t}+U_{i} h_{t-1}+b_{\tilde{i}}\right) \end{aligned}$</p>
<p>æ–°çš„æ›´æ–°è§„åˆ™ï¼š<br>$\begin{aligned} \omega_{t} &amp;=\tilde{f}_{t} \circ \tilde{i}_{t} \\ \hat{f}_{t} &amp;=f_{t} \circ \omega_{t}+\left(\tilde{f}_{t}-\omega_{t}\right)=\tilde{f}_{t} \circ\left(f_{t} \circ \tilde{i}_{t}+1-\tilde{i}_{t}\right) \\ \hat{i}_{t} &amp;=i_{t} \circ \omega_{t}+\left(\tilde{i}_{t}-\omega_{t}\right)=\tilde{i}_{t} \circ\left(i_{t} \circ \tilde{f}_{t}+1-\tilde{f}_{t}\right) \\ c_{t} &amp;=\hat{f}_{t} \circ c_{t-1}+\hat{i}_{t} \circ \hat{c}_{t} \end{aligned}$</p>
<p>master forget gate æ§åˆ¶çš„æ˜¯erasingè¡Œä¸ºï¼›master input gateåˆ™æ˜¯æ§åˆ¶writingè¡Œä¸ºã€‚å…·ä½“çš„ä¾‹å­è§è®ºæ–‡ã€‚$\omega_{t}$åˆ™æ˜¯$\tilde{f}_{t}$ä¸$\tilde{i}_{t}$çš„é‡å éƒ¨åˆ†ï¼Œè¡¨ç¤ºçš„æ˜¯ ç›¸åº”çš„ç¥ç»å…ƒæ®µç¼–ç åŒ…å«ä¸€äº›å…ˆå‰å•è¯å’Œå½“å‰è¾“å…¥å•è¯$x_t$çš„ä¸å®Œæ•´æˆåˆ†ã€‚</p>
<p>åŒæ—¶ï¼Œmaster gatesä¸“æ³¨ä¸€äº›ç²—ç²’åº¦çš„æ§åˆ¶ï¼Œå› æ­¤æ²¡å¿…è¦å’Œhidden stateä¸€æ ·çš„ç»´åº¦ï¼Œåˆ†é…å°ä¸€äº›çš„ç»´åº¦$D_{m}=\frac{D}{C}$å³å¯ã€‚å› æ­¤æ¯C-sizedä¸ªchunkæœ‰åŒæ ·çš„master gatesã€‚</p>
<p>æ€è€ƒï¼š<br>è®¾è®¡å¾ˆç²¾å·§ï¼Œé€šè¿‡å°†ç¥ç»å…ƒåˆ†åŒ–ï¼Œéšå¼å»ºæ¨¡ã€‚æ›´æ–°è§„åˆ™éƒ¨åˆ†æˆ‘å…¶å®è¿˜æ²¡ä»”ç»†å»çœ‹ï¼Œä½†è¯¥æ€æƒ³ç¡®å®å¾ˆæœ‰æ„æ€ã€‚</p>
<hr>
<h2 id="Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification"><a href="#Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification" class="headerlink" title="[Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification]"></a>[Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification]</h2><p>é…åˆä¸Šä¸€ç¯‡ON-LSTMçœ‹ï¼Œå‘ç°ä»–ä»¬ä¹‹é—´å…·æœ‰ç›¸ä¼¼ä¹‹å¤„ã€‚</p>
<p>æœ¬æ–‡åœ¨LSTMä¸Šå¼•å…¥cacheæœºåˆ¶ï¼Œå°†memoryåˆ‡åˆ†ä¸ºå¤šä¸ªgroupå¹¶èµ‹äºˆä¸åŒçš„forget rateï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°ä¿ç•™å…¨å±€çš„ä¿¡æ¯ï¼Œå¯¹documentçº§åˆ«çš„æƒ…æ„Ÿåˆ†ç±»èƒ½å¤Ÿæœ‰æ›´å¥½çš„ç»“æœã€‚</p>
<p>LSTMï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} \mathbf{i}^{(t)} &=\sigma\left(\mathbf{W}_{i} \mathbf{x}^{(t)}+\mathbf{U}_{i} \mathbf{h}^{(t-1)}\right) \\ \mathbf{f}^{(t)} &=\sigma\left(\mathbf{W}_{f} \mathbf{x}^{(t)}+\mathbf{U}_{f} \mathbf{h}^{(t-1)}\right) \\ \mathbf{o}^{(t)} &=\sigma\left(\mathbf{W}_{o} \mathbf{x}^{(t)}+\mathbf{U}_{o} \mathbf{h}^{(t-1)}\right) \\ \tilde{\mathbf{c}}^{(t)} &=\tanh \left(\mathbf{W}_{c} \mathbf{x}^{(t)}+\mathbf{U}_{c} \mathbf{h}^{(t-1)}\right) \\ \mathbf{c}^{(t)} &=\mathbf{f}^{(t)} \odot \mathbf{c}^{(t-1)}+\mathbf{i}^{(t)} \odot \tilde{\mathbf{c}}^{(t)} ) \\ \mathbf{h}^{(t)} &=\mathbf{o}^{(t)} \odot \tanh \left(\mathbf{c}^{(t)}\right) \end{aligned}</script><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå®é™…ä¸Šæ˜¯ä½¿ç”¨äº†LSTMçš„å˜ä½“ï¼Œå°†input gateä¸forget gateåˆå¹¶ä¸ºä¸€ä¸ªï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\mathbf{c}^{(t)}=\mathbf{f}^{(t)} \odot \mathbf{c}^{(t-1)}+\left(\mathbf{1}-\mathbf{f}^{(t)}\right) \odot \tilde{\mathbf{c}}^{(t)}</script><h3 id="Cached-LSTM"><a href="#Cached-LSTM" class="headerlink" title="Cached LSTM"></a>Cached LSTM</h3><p>æ”¹è¿›LSTMï¼Œå°†memoryåˆ†ä¸ºå¤šä¸ªgroupï¼Œæ¯ä¸ªgroupä»£è¡¨ä¸åŒçš„é•¿ç¨‹ä¾èµ–ï¼Œåˆ†é…ä¸åŒçš„forget rateã€‚ç›´è§‚ä¸Šï¼Œé«˜çš„rateä»£è¡¨äº†çŸ­ç¨‹ä¾èµ–ï¼Œä½çš„rateä»£è¡¨é•¿ç¨‹ä¾èµ–ã€‚</p>
<p>å°†memory cellåˆ‡æˆKå—$\left\{G_{1}, \cdots, G_{K}\right\}$ã€‚å› æ­¤æœ‰å¦‚ä¸‹å…¬å¼ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} \mathbf{r}_{k}^{(t)} &=\psi_{k}\left(\sigma\left(\mathbf{W}_{r}^{k} \mathbf{x}^{(t)}+\sum_{j=1}^{K} \mathbf{U}_{f}^{j \rightarrow k} \mathbf{h}_{j}^{(t-1)}\right)\right) \\ \mathbf{o}_{k}^{(t)} &=\sigma\left(\mathbf{W}_{o}^{k} \mathbf{x}^{(t)}+\sum_{j=1}^{K} \mathbf{U}_{o}^{j \rightarrow k} \mathbf{h}_{j}^{(t-1)}\right) \\ \tilde{\mathbf{c}}_{k}^{(t)} &=\tanh \left(\mathbf{W}_{c}^{(t)} \mathbf{x}^{(t-1)}+\left(\mathbf{r}_{k}^{(t)}\right) \odot \tilde{\mathbf{c}}_{k}^{(t)}\right) \\ \mathbf{h}_{k}^{(t)} &=\mathbf{o}_{k}^{(t)} \odot \tanh \left(\mathbf{c}_{k}^{(t)}\right) \end{aligned}</script><p>$\psi_{k}(\mathbf{z})$æ˜¯å‹ç¼©å‡½æ•°ï¼š</p>
<script type="math/tex; mode=display">\mathbf{r}_{k}=\psi_{k}(\mathbf{z})=\frac{1}{K} \cdot \mathbf{z}+\frac{k-1}{K}</script><p>å°†forget rateå‹ç¼©åœ¨ä¸€å®šèŒƒå›´$\left(\frac{k-1}{K}, \frac{k}{K}\right)$ã€‚</p>
<p>ç±»ä¼¼bi-LSTMï¼ŒåŒæ ·CLSTMå¯ä»¥æœ‰åŒå‘ã€‚åœ¨åšåˆ†ç±»æ—¶ï¼Œåªå°†ä»£è¡¨é•¿ç¨‹ä¾èµ–çš„é‚£ç»„å–å‡ºæ¥è¿‡softmaxã€‚</p>
<p><img src="/images/15576279206849.jpg" width="55%" height="50%"></p>
<p>æ€è€ƒï¼š<br>ä¸Ordered Neuronç›¸æ¯”ï¼Œè¿™é‡Œæ˜¾å¼åœ°å°†å›ºå®šç»´åº¦åˆ‡åˆ†æˆå¤šä¸ªç»„ï¼Œç›¸æ¯”è€Œè¨€Ordered Neuronæ›´åŠ çµæ´»ï¼Œä½†äºŒè€…è¿˜æ˜¯æœ‰ç›¸å½“çš„ç›¸ä¼¼ç¨‹åº¦çš„ï¼Œè™½ç„¶ä»»åŠ¡å’Œmotivationä¸åŒã€‚</p>
<hr>
<h2 id="Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation"><a href="#Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation" class="headerlink" title="[Unified Language Model Pre-training for Natural Language Understanding and Generation]"></a>[Unified Language Model Pre-training for Natural Language Understanding and Generation]</h2><p>å°†pretrainæ‰©å±•åˆ°ç”Ÿæˆé¢†åŸŸï¼Œä½¿ç”¨ç”Ÿæˆä»»åŠ¡æ¥å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œpretrainã€‚</p>
<p><img src="/images/15576282560620.jpg" width="80%" height="50%"></p>
<p>åŒæ—¶ä½¿ç”¨ä¸‰ç§è¯­è¨€æ¨¡å‹æ¥è¿›è¡Œpretrainã€‚ä¸€ç§æ˜¯bidirectionalçš„ï¼Œå’Œbertä¸€æ ·ï¼›ä¸€ç§æ˜¯ä»å·¦åˆ°å³/ä»å³åˆ°å·¦å•å‘çš„ï¼Œå’ŒGPTä¸€æ ·ï¼›å¦ä¸€ç§æ˜¯åšç”Ÿæˆçš„ï¼Œä¹Ÿå³encoderç«¯ç›¸äº’éƒ½attendåˆ°ï¼Œè€Œdecoderç«¯åªèƒ½çœ‹åˆ°encoderéƒ¨åˆ†å’Œdecoderçš„å·¦è¾¹ã€‚</p>
<p>ç»Ÿä¸€ä½¿ç”¨[MASK]çš„æ–¹æ³•ï¼ˆbertï¼‰åŒæ—¶è®­ç»ƒè¿™ä¸‰ç§è¯­è¨€æ¨¡å‹ï¼Œè¿™æ ·å¯ä»¥ä½¿ç”¨åŒä¸€å¥—è®­ç»ƒæµç¨‹åŒæ—¶è®­ç»ƒä¸‰ç§æ¨¡å‹ã€‚</p>
<p>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®å°±æ˜¯å°†ç”ŸæˆåŠ è¿›æ¥äº†å§ï¼Œå¹¶ä¸”æ•ˆæœè¿˜å¯ä»¥ã€‚å…¶ä»–å¹¶æ²¡æœ‰å¾ˆå¤§çš„åˆ›æ–°ç‚¹ã€‚</p>
<hr>
<h2 id="Language-Models-are-Unsupervised-Multitask-Learners"><a href="#Language-Models-are-Unsupervised-Multitask-Learners" class="headerlink" title="[Language Models are Unsupervised Multitask Learners]"></a>[Language Models are Unsupervised Multitask Learners]</h2><p>å¤§åé¼é¼çš„GPT2.0 é€šè¿‡å¢åŠ æ›´å¤šå±‚ï¼Œå¢åŠ æ›´å¤šæ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªæ›´å¥½çš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä¸”å°è¯•åœ¨ä¸fine-tuneçš„æƒ…å†µä¸‹å®Œæˆä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶å–å¾—ä¸é”™çš„æ•ˆæœã€‚</p>
<p>å…¨æ–‡éƒ½åœ¨è®¨è®ºæ€ä¹ˆè·å¾—æ•°æ®ä»¥åŠæ€ä¹ˆè®­ç»ƒã€‚å®é™…ä¸Šå¸®åŠ©å¹¶ä¸å¤§ï¼Œä½†ä¸ªäººè®¤ä¸ºæœ¬æ–‡æœ€å¤§çš„è´¡çŒ®å°±æ˜¯å°è¯•å»åšç”Ÿæˆï¼Œå¹¶ä¸”åœ¨zero-shotçš„æƒ…æ™¯ä¸‹å»æ¢ç´¢language modelçš„ä¸Šé™ã€‚</p>
<p>å…¶ä»–æˆ‘æ²¡ä»”ç»†çœ‹ã€‚</p>
<hr>
<h2 id="MASS-Masked-Sequence-to-Sequence-Pre-training-for-Language-Generation"><a href="#MASS-Masked-Sequence-to-Sequence-Pre-training-for-Language-Generation" class="headerlink" title="[MASS: Masked Sequence to Sequence Pre-training for Language Generation]"></a>[MASS: Masked Sequence to Sequence Pre-training for Language Generation]</h2><p>å¼•å…¥encoder-decoderç»“æ„æ¥åšpretrainï¼Œå¯ä»¥åŒæ—¶è®­ç»ƒencoderå’Œdecoderï¼Œå¯ä»¥ç”¨äºç”Ÿæˆä»»åŠ¡ã€‚ ideaè¿˜æ˜¯æŒºæœ‰æ„æ€çš„ã€‚</p>
<p>Motivation:<br>é‡‡ç”¨encoder-decoderæ¡†æ¶èƒ½è¿›ä¸€æ­¥æ›´å¥½åœ°ç”¨äºç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè€Œä¸åƒbertå’ŒGPTé‚£æ ·åªæœ‰ä¸€ä¸ªencoderæˆ–decoderï¼Œæ²¡æ³•å¯¹attentioné¢„è®­ç»ƒï¼Œå¯¹ç”Ÿæˆä»»åŠ¡ä¸å‹å¥½ã€‚</p>
<p>åšæ³•ï¼šåœ¨encoderç«¯maskè¿ç»­çš„è¯ï¼Œç„¶åä½¿ç”¨transformerå¯¹å…¶è¿›è¡Œencodeï¼›ç„¶åå†decoderç«¯è¾“å…¥åŒæ ·çš„å¥å­ï¼Œä½†æ˜¯maskedæ‰çš„æ­£å¥½å’Œencoderç›¸åï¼Œå’Œç¿»è¯‘ä¸€æ ·ï¼Œä½¿ç”¨attentionæœºåˆ¶å»è®­ç»ƒï¼Œä½†åªé¢„æµ‹encoderç«¯è¢«maskæ‰çš„è¯ã€‚</p>
<p><img src="/images/15576285238806.jpg" width="80%" height="50%"></p>
<p>ä½œè€…è®¤ä¸ºè¿™æ ·åšçš„å¥½å¤„ï¼š<br>å¯¹encoderç«¯çš„maskèƒ½å¤Ÿå¼ºåˆ¶è®©encoderç«¯æ›´å¥½åœ°å­¦ä¹ æœªè¢«maskæ‰çš„è¯çš„æ„ä¹‰ï¼Œè¿™æ ·æ‰èƒ½é¢„æµ‹maskæ‰çš„è¯ï¼›å¯¹decoderç«¯çš„inputè¿›è¡Œmaskèƒ½å¤Ÿå¼ºåˆ¶æ¨¡å‹æ›´å¤šä¾èµ–äºsourceç«¯ï¼Œè€Œä¸æ˜¯å‰é¢çš„inputã€‚</p>
<p>ä½œè€…è¿˜å°†MASSä¸Bert/GPTåšäº†å¯¹æ¯”ï¼Œå‘ç°Bert/GPTæ˜¯MASSçš„ä¸€ä¸ªç‰¹ä¾‹ã€‚MASSæœ‰ä¸€ä¸ªè¶…å‚kï¼Œæ§åˆ¶maskæ‰çš„segmenté•¿åº¦ã€‚å½“k=1æ—¶ï¼Œåˆ™æ˜¯BERTï¼›å½“k=mï¼Œä¹Ÿå³æ•´ä¸ªå¥å­é•¿åº¦æ—¶åˆ™æ˜¯GPTã€‚</p>
<p><img src="/images/15576285809670.jpg" width="50%" height="50%"></p>
<p><img src="/images/15576285948426.jpg" width="100%" height="50%"></p>
<p>å½“k=1æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºdecoderç«¯æ²¡æœ‰inputä¿¡æ¯ï¼Œå…¨éƒ¨ä¿¡æ¯æ¥è‡ªencoderï¼Œå’ŒBertå¯¹æ¯”ä¸€ä¸‹ï¼Œè™½ç„¶åœ¨ç»“æ„ä¸Šä¸ä¸€æ ·ï¼Œä½†åšçš„äº‹æƒ…æ˜¯ä¸€æ ·çš„ï¼Œæ­¤æ—¶decoderçš„è§’è‰²å°±æ˜¯berté‡Œé¢çš„åˆ†ç±»å™¨ã€‚<br>å½“k=mæ—¶ï¼Œå®é™…ä¸Šå°±æ˜¯å°†encoderç«¯çš„æ‰€æœ‰ä¿¡æ¯éƒ½maskæ‰äº†ï¼Œæ­¤æ—¶decoderè¦é¢„æµ‹åªèƒ½é decoderç«¯çš„inputï¼Œè¿™å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªæ ‡å‡†çš„è¯­è¨€æ¨¡å‹ã€‚</p>
<p>åœ¨å‡ ä¸ªç”Ÿæˆä»»åŠ¡ä¸Šçš„ç»“æœç›¸å½“ä¸é”™ï¼Œæˆ‘æ²¡ä»”ç»†çœ‹ã€‚</p>
<p>æ€è€ƒï¼šå°†bertå’ŒGPTæŠ½è±¡å‡ºæ¥ï¼Œä½œä¸ºå…¶æ¡†æ¶çš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼Œè¿™åˆå’ŒNL-Netæœ‰ä¸€äº›ç›¸ä¼¼ã€‚</p>
<hr>
<h2 id="Gather-Excite-Exploiting-Feature-Context-in-Convolutional-Neural-Networks"><a href="#Gather-Excite-Exploiting-Feature-Context-in-Convolutional-Neural-Networks" class="headerlink" title="[Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks]"></a>[Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks]</h2><p>å¦ä¸€ç§Gather-Distributeæ€æƒ³çš„å®ä¾‹ã€‚è¯¥æ¨¡å‹åŒæ ·æ˜¯ä¸ºäº†æ•è·é•¿è·ç¦»ä¸Šä¸‹æ–‡ï¼Œä»¥æå‡è¡¨ç°ã€‚</p>
<p>åˆ†ä¸ºä¸¤æ­¥ï¼šgatherï¼Œå°†è¾ƒå¤§ç©ºé—´å†…çš„ä¿¡æ¯èšé›†èµ·æ¥ï¼Œexciteï¼Œå°†ä¿¡æ¯é‡æ–°åˆ†å‘ç»™local featuresã€‚</p>
<p><img src="/images/15576287381755.jpg" width="80%" height="50%"></p>
<p>Motivationï¼šCNNçš„ä¿¡æ¯æµåŠ¨æ–¹å¼ã€‚æ¯æ¬¡æŠ½å–å‘¨å›´çš„ä¿¡æ¯èšåˆåœ¨ä¸€èµ·ï¼Œéšç€å±‚æ•°çš„å¢å¤šé€æ¸æŠ½è±¡ï¼Œå…¶æ„Ÿå—é‡ä¹Ÿé€æ¸å¢å¤§ã€‚æœ¬æ–‡æå‡ºçš„æ¨¡å‹å®é™…ä¸Šå°±æ˜¯åœ¨åŒä¸€å±‚å†…è®©æ¯ä¸ªç‚¹éƒ½æ„Ÿå—åˆ°å…¶å‘¨å›´æ›´å¤§ç©ºé—´çš„ä¿¡æ¯ã€‚</p>
<h3 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><p>æ¨¡å‹å®šä¹‰ï¼š<br>è¾“å…¥ï¼š$x=\left\{x^{c} : c \in\{1, \ldots, C\}\right\}$<br>Cä»£è¡¨Cä¸ªfeature mapsï¼Œä¹Ÿå³channelç»´ã€‚</p>
<p>å®šä¹‰selection operatorï¼š<br>$\iota(u, e)=\left\{e u+\delta : \delta \in[-\lfloor(2 e-1) / 2\rfloor,\lfloor(2 e-1) / 2\rfloor]^{2}\right\}$</p>
<p>uæ˜¯è¾“å‡ºçš„å…ƒç´ ï¼Œeæ˜¯extent ratioï¼Œä»£è¡¨çš„å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªçª—å£å¤§å°ã€‚</p>
<p>å› æ­¤gather operatorå¯ä»¥å®šä¹‰ä¸ºæ˜ å°„å‡½æ•°ï¼š<br>$\xi_{G} : \mathbb{R}^{H \times W \times C} \rightarrow \mathbb{R}^{H^{\prime} \times W^{\prime} \times C}\left(H^{\prime}=\left\lceil\frac{H}{e}\right\rceil, W^{\prime}=\left\lceil\frac{W}{e}\right\rceil\right)$<br>$\xi_{G}(x)_{u}^{c}=\xi_{G}\left(x \odot \mathbf{1}_{\iota_{(u, e)}}^{c}\right)$</p>
<p>å…¶å®å°±æ˜¯å¯¹è¯¥çª—å£å†…çš„å…ƒç´ è¿›è¡Œäº†æ˜ å°„ï¼ˆå¦‚mean-poolingï¼‰ã€‚å…¶ä¸­$u \in\left\{1, \ldots, H^{\prime}\right\} \times\left\{1, \ldots, W^{\prime}\right\}, c \in\{1, \ldots, C\}$</p>
<p>ä»ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œgatheræ“ä½œå®é™…ä¸Šå°±æ˜¯å¯¹äºæ¯ä¸ªè¾“å‡ºuï¼Œå…¶æ„Ÿå—é‡ä¸ºå•ä¸ªchannelçš„ä¸€ä¸ªçª—å£ã€‚å¦‚æœè¯¥çª—å£æ°å¥½è¦†ç›–äº†æ•´ä¸ªç©ºé—´ï¼Œåˆ™ç§°è¯¥gatheræ“ä½œæœ‰global extentã€‚</p>
<p>è€Œexciteæ“ä½œåˆ™æ˜¯åˆ©ç”¨gatherè·å¾—çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ›´æ–°æ¯ä¸ªfeatureã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\begin{array}{l}{\xi_{E}(x, \hat{x})=x \odot f(\hat{x})} \\ {f : \mathbb{R}^{H^{\prime} \times W^{\prime} \times C} \rightarrow[0,1]^{\overline{H} \times W \times C}}\end{array}</script><p>é‚£ä¹ˆGæ˜¯å¦‚ä½•è·å¾—çš„ï¼Ÿå¯ä»¥æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯æ— å‚æ•°ï¼Œå¦ä¸€ç§æ˜¯æœ‰å‚æ•°ã€‚</p>
<h4 id="æ— å‚æ•°GE"><a href="#æ— å‚æ•°GE" class="headerlink" title="æ— å‚æ•°GE"></a>æ— å‚æ•°GE</h4><p>å®é™…ä¸Šå°±æ˜¯mean-poolingã€‚<br>åˆ™æ•´ä¸ªGE-Netä¸ºï¼š</p>
<script type="math/tex; mode=display">y^{c}=x \odot \sigma\left(\text {interp}\left(\xi_{G}(x)^{c}\right)\right)</script><p>å…¶ä¸­interp(Â·)ä»£è¡¨äº†æœ€é‚»è¿‘æ’å€¼ã€‚å®é™…ä¸Šå¯ä»¥ç†è§£æˆï¼Œå°†ä¸€ä¸ªè¾ƒå¤§çª—å£çš„ä¿¡æ¯éƒ½mean-poolingä¸€ä¸‹ï¼Œç„¶åè¯¥çª—å£çš„featureéƒ½ç”¨mean-poolingçš„å€¼ä¹˜ä¸€ä¸‹ï¼ˆå› ä¸ºæœ€é‚»è¿‘çš„ç‰¹ç‚¹ï¼Œè¯¥çª—å£çš„æ’å€¼éƒ½æ˜¯è‡ªèº«ï¼‰ã€‚</p>
<p>å½“è®¾è®¡ä¸åŒçš„eæ—¶ï¼Œä¹Ÿå³çª—å£å¤§å°ï¼Œå¯ä»¥çœ‹åˆ°çª—å£è¶Šå¤§ï¼Œå…¶è¡¨ç°è¶Šå¥½ã€‚</p>
<p><img src="/images/15576291070929.jpg" width="40%" height="50%"></p>
<h4 id="æœ‰å‚æ•°GE"><a href="#æœ‰å‚æ•°GE" class="headerlink" title="æœ‰å‚æ•°GE"></a>æœ‰å‚æ•°GE</h4><p>é‡‡ç”¨strided depth-wise convolutionã€‚</p>
<p>åŒæ ·è¶Šå¤§çš„eè¶Šå¥½ï¼š</p>
<p><img src="/images/15576291449392.jpg" width="40%" height="50%"></p>
<p>å¹¶ä¸”è¡¨ç°ä¼šæ¯”æ— å‚æ•°çš„æ›´å¥½ã€‚</p>
<p>å®éªŒè¡¨æ˜ï¼Œåœ¨æ•´ä¸ªæ¨¡å‹çš„ä¸­é—´å±‚æˆ–è€…åé¢å±‚ï¼ˆæœ‰æ›´å¤šçš„channelï¼‰åŠ GEä¼šæ›´å¥½ã€‚</p>
<h3 id="ä¸SE-Netçš„å…³ç³»"><a href="#ä¸SE-Netçš„å…³ç³»" class="headerlink" title="ä¸SE-Netçš„å…³ç³»"></a>ä¸SE-Netçš„å…³ç³»</h3><p>SE-Netå¯ä»¥çœ‹åšæ˜¯ç‰¹æ®Šçš„GE-Netã€‚SE-Netçš„gatheræ“ä½œå°±æ˜¯å…¨å±€çš„mean-poolingï¼›è€Œåœ¨exciteæ—¶å¤šäº†ä¸€å±‚å…¨è¿æ¥çš„ç½‘ç»œï¼ˆï¼Ÿè®ºæ–‡è¯´å°±æ˜¯ä¸€å±‚å…¨è¿æ¥ï¼Œä½†ä¼¼ä¹ä¸æ˜¯è¿™æ ·çš„ï¼‰ã€‚</p>
<p><img src="/images/15576291939204.jpg" width="70%" height="50%"></p>
<p>è®ºæ–‡ä¸­è¿˜å°†SE-Netå’ŒGE-Netç»“åˆèµ·æ¥ï¼Œå‘ç°æœ‰æ›´å¤§çš„æå‡ï¼Œè¯æ˜äºŒè€…ä¸æ˜¯æ’æ–¥çš„ã€‚</p>
<p>åº”ç”¨GE-Netçš„å‡ ä¸ªä¾‹å­ï¼š</p>
<p><img src="/images/15576292257307.jpg" width="80%" height="50%"></p>
<p>æˆ‘çš„æ€è€ƒï¼š<br>ä¸SE-Netçš„å…³ç³»å¯†åˆ‡ï¼ˆå®é™…ä¸Šå°±æ˜¯åŒä¸€æ‹¨äººåšçš„ï¼‰ã€‚ä½†è¿™é‡Œå¼ºè°ƒçš„æ˜¯channelä¹‹é—´æ²¡æœ‰è”ç³»ï¼Œä»…ä»…æ˜¯é€šè¿‡æ‰©å¤§æ„Ÿå—é‡ï¼Œå¢å¼ºglobalçš„ä¿¡æ¯ï¼›è€ŒSE-Netåˆ™æ˜¯å¼ºè°ƒçš„channelä¹‹é—´çš„è”ç³»ï¼Œå¹¶æ²¡æœ‰è€ƒè™‘channelå†…éƒ¨çš„å…³ç³»ï¼Œç›¸å½“äºGE-Netå…·æœ‰å…¨å±€æ„Ÿå—é‡ã€‚å¦‚æœGE-Netæœ‰å…¨å±€æ„Ÿå—é‡ï¼Œé‚£ä¹ˆä»–æ¯”SE-Netå°±å·®åœ¨channelä¹‹é—´çš„è”ç³»äº†ã€‚</p>
<hr>
<h2 id="PSANet-Point-wise-Spatial-Attention-Network-for-Scene-Parsing"><a href="#PSANet-Point-wise-Spatial-Attention-Network-for-Scene-Parsing" class="headerlink" title="[PSANet: Point-wise Spatial Attention Network for Scene Parsing]"></a>[PSANet: Point-wise Spatial Attention Network for Scene Parsing]</h2><p>æå‡ºå¦ä¸€ç§è§£å†³local constraintçš„æ–¹æ¡ˆï¼Œä¹Ÿå³ä½¿å¾—featureä¹‹é—´èƒ½å¤Ÿå»ºç«‹é•¿è·ç¦»ä¾èµ–ã€‚feature mapä¸Šçš„æ¯ä¸ªä½ç½®é€šè¿‡attention mapä¸å…¶ä»–ç‚¹è¿›è¡Œè¿æ¥ï¼ŒåŒæ—¶ä¿¡æ¯æµåŠ¨æ˜¯åŒå‘çš„ï¼Œæ¯ä¸ªç‚¹åŒæ—¶è¿›è¡Œæ”¶é›†ä¸åˆ†å‘çš„æ“ä½œã€‚</p>
<p>é€šå¸¸è€Œè¨€ï¼Œä¿¡æ¯çš„aggregationå¯ä»¥å½¢å¼åŒ–æˆï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F\left(\mathbf{x}_{i}, \mathbf{x}_{j}, \Delta_{i j}\right) \mathbf{x}_{j}</script><p>$\mathbf{z}_{i}$æ˜¯ç¬¬iä¸ªä½ç½®çš„è¾“å‡ºï¼›$\mathbf{x}_{j}$æ˜¯è¾“å…¥çš„feature map $X$ã€‚$\forall j \in \Omega(i)$ æ˜¯ä¸iç›¸å…³çš„æ‰€æœ‰ä½ç½®çš„featureé›†åˆã€‚$ F\left(\mathbf{x}_{i}, \mathbf{x}_{j}, \Delta_{i j}\right)$ ä»£è¡¨çš„æ˜¯jåˆ°içš„ä¿¡æ¯æµåŠ¨ã€‚$\Delta$ ä»£è¡¨çš„æ˜¯ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p>
<p>å¯ä»¥å°†ä¸Šè¿°å¼å­ç®€åŒ–ä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \mathbf{x}_{j}</script><p>å…¶ä¸­$\left\{F_{\Delta_{i j}}\right\}$æ˜¯ä½ç½®ç›¸å…³çš„å‡½æ•°æ˜ å°„ã€‚</p>
<p>å½“ä¸€ä¸ªfeature mapçš„ä½ç½®å¾ˆå¤šæ—¶ï¼Œ$x_i$ä¸$x_j$çš„pairå°†ä¼šå¾ˆå¤§ã€‚</p>
<p>å› æ­¤å°†ä¸Šå¼å‡½æ•°æ˜ å°„ç®€åŒ–ä¸ºï¼š</p>
<script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)</script><p>ä¹Ÿå³$j$åˆ°$i$çš„ä¿¡æ¯æµåŠ¨åªä¸$i$ä½ç½®çš„featureä»¥åŠ$i$ä¸$j$ä¹‹é—´çš„ç›¸å¯¹ä½ç½®æœ‰å…³ã€‚</p>
<p>åŒç†ï¼Œè¿˜å¯ä»¥å°†å‡½æ•°æ˜ å°„ç®€åŒ–æˆï¼š</p>
<script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)</script><p>ä¹Ÿå³ä¿¡æ¯æµåŠ¨åªä¸$i$ä¸$j$çš„ç›¸å¯¹ä½ç½®ä»¥åŠ$j$ä½ç½®ä¸Šçš„featureæœ‰å…³ã€‚</p>
<p>å°†ä¸Šè¿°ä¸¤ä¸ªç®€åŒ–å‡½æ•°ç»“åˆèµ·æ¥ï¼Œå¯ä»¥è·å¾—åŒå‘ä¿¡æ¯ä¼ æ’­è·¯å¾„ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)+F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)</script><p>æ­¤æ—¶æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right) \mathbf{x}_{j}+\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right) \mathbf{x}_{j}</script><p>ç¬¬ä¸€é¡¹$F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)$encodeäº†åœ¨å…¶ä»–ä½ç½®ä¸Šçš„ä¿¡æ¯åœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿå¸®åŠ©ä½ç½®iï¼ˆé€šè¿‡ä½ç½®içš„featureä»¥åŠç›¸å¯¹ä½ç½®ï¼‰ã€‚</p>
<p>ç¬¬äºŒé¡¹$F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)$æ‰€åšçš„ä¹Ÿå³é¢„æµ‹å…¶ä»–ä½ç½®ä¸Šçš„featureçš„é‡è¦æ€§ï¼ˆé€šè¿‡ç›¸å¯¹ä½ç½®ï¼Œä»¥åŠä½ç½®jçš„featureï¼‰ã€‚</p>
<p>å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="/images/15576301327447.jpg" width="70%" height="50%"></p>
<p>ä¸Šè¿°ä¸¤ä¸ªFå®é™…ä¸Šå¯ä»¥çœ‹åšæ˜¯åœ¨é¢„æµ‹ä¸€ä¸ªattentionçš„å€¼ï¼Œå»åšaggregationã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j} \mathbf{a}_{i, j}^{c} \mathbf{x}_{j}+\frac{1}{N} \sum_{\forall j} \mathbf{a}_{i, j}^{d} \mathbf{x}_{j}</script><p>é—®é¢˜åœ¨äºå¦‚ä½•è·å¾—aï¼Ÿ<br>ä¸‹å›¾æ˜¯è¾ƒä¸ºæ¸…æ™°çš„ä¸€ä¸ªæ¡†æ¶å›¾ï¼š</p>
<p><img src="/images/15576302667770.jpg" width="70%" height="50%"></p>
<p>å¯ä»¥çœ‹å‡ºæ˜¯é€šè¿‡å¤šä¸ªCNNæ¥è·å¾—attentionçŸ©é˜µçš„ã€‚</p>
<p>ä¸Šä¸‹ä¸¤æ¡çº¿å¾ˆç±»ä¼¼ã€‚ç¬¬ä¸€æ­¥æ˜¯å…ˆå‹ç¼©channelä»¥å‡å°‘è®¡ç®—é‡ï¼ˆC2&lt;C1)ã€‚ç¬¬äºŒæ­¥æ‰©å±•channelä¸º$(2H-1)\times(2W-1)$ï¼Œä¸‹é¢è§£é‡Šä¸ºä»€ä¹ˆã€‚æ¥ä¸‹æ¥åœ¨é‡æ–°è·å¾—$H\times W$çš„channelç»´ï¼Œè¯¥channelç»´çš„æ¯ä¸€ç»´æ‰€ä»£è¡¨çš„å°±æ˜¯ä¸€ä¸ªfeatureï¼ˆå…±æœ‰$H\times W$ä¸ªfeatureï¼‰çš„attentionå€¼ã€‚æœ€åä¹˜èµ·æ¥å†concatä¸€ä¸‹ï¼Œè·å¾—æœ€åçš„outputã€‚</p>
<p>ä¸ºä»€ä¹ˆæ˜¯$(2H-1)\times(2W-1)$çš„channelç»´ï¼Œå› ä¸ºå¸Œæœ›å°†è¯¥featureå‰ªè£ä¸€ä¸‹å˜æˆ$H\times W$ï¼Œæ­£å¥½å¯ä»¥è¡¨ç¤ºç›¸å¯¹ä½ç½®ã€‚</p>
<p><img src="/images/15576304353141.jpg" width="80%" height="50%"></p>
<p>å¯¹äºä¸€ä¸ª$(2H-1)\times(2W-1)$çš„featureå¯ä»¥å±•å¼€æˆäºŒç»´çš„ï¼Œå…¶ä¸­ä½ç½®iä¸ºä¸­å¿ƒï¼Œä»…æœ‰$H\times W$ä¸ªæœ‰ç”¨ã€‚å…·ä½“è€Œè¨€,åœ¨ç¬¬kè¡Œç¬¬låˆ—çš„ä½ç½®iï¼Œåˆ™æœ‰ç”¨çš„çŸ©é˜µæ˜¯ä»$H-k$è¡Œå’Œ$W-l$åˆ—å¼€å§‹çš„ã€‚è¿™ä¸ªåšæ³•å€’æŒºæœ‰æ„æ€çš„ã€‚</p>
<p>ä¸NL-Netçš„å…³ç³»ï¼šNL-Netæ²¡æœ‰è€ƒè™‘ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p>
<p>æ€è€ƒï¼š<br>è¯¥æ–¹æ³•ä¼¼ä¹ç¡®å®ç›¸æ¯”NL-Netçš„è®¡ç®—é‡å°ï¼Œè™½ç„¶çœ‹èµ·æ¥ä¹Ÿå¾ˆå¤§ã€‚NL-Netçš„è®¡ç®—é‡æ˜¯(HW)^2ã€‚è€Œè¿™é‡Œçš„æ•°é‡çº§æ˜¯HWã€‚ç©¶å…¶åŸå› ï¼Œæ˜¯å› ä¸ºattentionæ˜¯é¢„æµ‹å‡ºæ¥çš„ã€‚</p>
<p>ä»è·å¾—attentionçŸ©é˜µçš„æ–¹å¼å¯ä»¥çœ‹å‡ºï¼Œchannelä¸channelä¹‹é—´æœ‰äº¤äº’ã€‚</p>
<p>attentionçŸ©é˜µæ˜¯é¢„æµ‹å‡ºæ¥çš„ï¼ˆ$1\times 1$çš„convolutionï¼‰ï¼Œè€Œä¸æ˜¯ä¸€å¯¹pairè®¡ç®—å‡ºæ¥çš„ã€‚ä¼¼ä¹å°±æ²¡é‚£ä¹ˆæœ‰é“ç†ã€‚</p>
<p><del>å¹¶ä¸”ï¼Œä¸Šä¸‹ä¸¤æ¡æ”¯çº¿çš„æ“ä½œéƒ½æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯å°†å…¶è§£é‡Šä¸ºåŒå‘ä¿¡æ¯æµåŠ¨ï¼›é‚£è¿˜å¯ä»¥è§£é‡ŠæˆåƒTransformeré‚£æ ·ï¼Œå¤šä¸ªheadï¼Œå°†åŒä¸€ä¸ªè¡¨ç¤ºæ˜ å°„åˆ°å¤šä¸ªéšç©ºé—´ä¸­å¢å¼ºè¡¨ç¤ºã€‚</del>ä¹‹å‰ç†è§£é”™äº†ã€</p>
<hr>
<h2 id="CCNet-Criss-Cross-Attention-for-Semantic-Segmentation"><a href="#CCNet-Criss-Cross-Attention-for-Semantic-Segmentation" class="headerlink" title="[CCNet: Criss-Cross Attention for Semantic Segmentation]"></a>[CCNet: Criss-Cross Attention for Semantic Segmentation]</h2><p>å¯¹NL-Netçš„æ”¹è¿›ï¼Œé€šè¿‡å¼•å…¥åå­—äº¤å‰çš„attentionå’Œrecurrentç»“æ„ï¼Œå‡å°‘äº†è®¡ç®—é‡ï¼ŒåŒæ—¶ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•è·é•¿è·ç¦»ä¾èµ–ï¼Œä»¥åŠæå‡äº†æ¨¡å‹è¡¨ç°ã€‚</p>
<p>Motivation:<br>NL-Netä¼šç”Ÿæˆä¸€ä¸ªå¾ˆå¤§çš„attention mapï¼Œå…¶å¤æ‚åº¦ä¸º${\mathcal{O}}((H \times W)\times(H \times W))$ã€‚</p>
<p>ä¸»è¦åšæ³•ï¼Œå°†è¯¥position-wiseçš„attentionåˆ†è§£æˆä¸¤æ­¥ï¼šç¬¬ä¸€æ­¥æ˜¯æ¯ä¸ªç‚¹åªå’Œå…¶åŒä¸€è¡Œå’ŒåŒä¸€åˆ—çš„è¿›è¡Œattentionï¼Œå°†attentionçš„æ“ä½œå¾ªç¯å¤šæ¬¡ï¼Œè¾¾åˆ°æ¯ä¸ªç‚¹é—´æ¥å’Œå…¶ä»–ç‚¹éƒ½åšäº†attentionã€‚å…¶å¤æ‚åº¦åˆ™ä¸º $\mathcal{O}((H \times W) \times(H+W-1))$</p>
<p>ä¸¤ç§æ–¹æ³•çš„å¯¹æ¯”ï¼š</p>
<p><img src="/images/15576307417016.jpg" width="50%" height="50%"></p>
<p>æ³¨æ„åˆ°recurrentçš„ç»“æ„ä¸­å‚æ•°æ˜¯å…±äº«çš„ã€‚</p>
<p>å…·ä½“çš„æ¡†æ¶ï¼š</p>
<p><img src="/images/15576307988403.jpg" width="80%" height="50%"></p>
<p>å…ˆè¿›è¡Œé™ç»´ï¼Œåšå®Œcriss-cross attentionåçš„outputä¸åŸå…ˆçš„xæ‹¼èµ·æ¥ï¼Œå†è¿‡CNNç­‰è¿›è¡Œèåˆã€‚</p>
<h3 id="Criss-Cross-Attention"><a href="#Criss-Cross-Attention" class="headerlink" title="Criss-Cross Attention"></a>Criss-Cross Attention</h3><p><img src="/images/15576308514373.jpg" width="50%" height="50%"></p>
<p>è¿‡ä¸‰ä¸ªçº¿æ€§å±‚å¾—åˆ°QKVï¼ˆå’Œtransformerç±»ä¼¼ï¼‰ï¼›æ¥ç€Qä¸Kåšçºµæ¨ªäº¤å‰çš„attentionï¼Œè·å¾—softmaxï¼Œæ¥ç€å†å’ŒVå¯¹åº”çš„ä½ç½®ç›¸ä¹˜ã€‚</p>
<p>å…·ä½“è€Œè¨€ï¼š<br>è¾“å…¥ï¼š$\mathbf{H} \in \mathbb{R}^{C \times W \times H}$<br>è¿‡çº¿æ€§å±‚ï¼š$\{\mathbf{Q}, \mathbf{K}\} \in \mathbb{R}^{C^{\prime} \times W \times H}$<br>attentionåˆ†æ•°ï¼š$\mathbf{A} \in \mathbb{R}^{(H+W-1) \times W \times H}$<br>ä¸uå…ƒç´ åšattentionçš„featureé›†åˆï¼Œä¹Ÿå³åŒä¸€è¡Œæˆ–åŒä¸€åˆ—çš„featureï¼š$\boldsymbol{\Omega}_{\mathbf{u}} \in \mathbb{R}^{(H+W-1) \times C^{\prime}} \cdot \mathbf{\Omega}_{\mathbf{i}, \mathbf{u}} \in \mathbb{R}^{C^{\prime}}$<br>åšattentionï¼š$d_{i, u}=\mathbf{Q}_{\mathbf{u}} \mathbf{\Omega}_{\mathbf{i}, \mathbf{u}^{\top}}$<br>å†åšsoftmaxï¼Œæœ€ç»ˆè·å¾—outputï¼š$\mathbf{H}_{\mathbf{u}}^{\prime}=\sum_{i \in\left|\mathbf{\Phi}_{\mathbf{u}}\right|} \mathbf{A}_{\mathbf{i}, \mathbf{u}} \mathbf{\Phi}_{\mathbf{i}, \mathbf{u}}+\mathbf{H}_{\mathbf{u}}$<br>$\boldsymbol{\Phi}_{\mathbf{i}, \mathbf{u}}$ä¸$\boldsymbol{\Omega}_{\mathbf{u}}$æ˜¯åŒä¸€é›†åˆã€‚</p>
<h3 id="Recurrent-Criss-Cross-Attention"><a href="#Recurrent-Criss-Cross-Attention" class="headerlink" title="Recurrent Criss-Cross Attention"></a>Recurrent Criss-Cross Attention</h3><p>å¤šåšå‡ æ¬¡ï¼Œæ¯æ¬¡éƒ½å…±äº«ï¼Œå°±æ˜¯recurrentäº†ã€‚<br>å½“å¾ªç¯æ¬¡æ•°æ˜¯2æ—¶ï¼Œæ¯ä¸ªç‚¹éƒ½èƒ½å¤Ÿattendåˆ°å…¶ä»–ä»»ä½•ç‚¹äº†ã€‚</p>
<p><img src="/images/15576311079687.jpg" width="66%" height="50%"></p>
<p>æ€è€ƒï¼š<br>é€šè¿‡çºµæ¨ªæ¥é—´æ¥attendåˆ°æ‰€æœ‰ç‚¹ï¼Œè¿™ä¸ªæƒ³æ³•è¿˜è›®æœ‰è¶£çš„ã€‚å¹¶ä¸”å‡å°‘äº†è®¡ç®—é‡ã€‚å°±æ˜¯è¿™ç§çºµæ¨ªçš„æ–¹æ³•ä»£ç è¦æ€ä¹ˆå®ç°ï¼Ÿæœ‰äº›å¥½å¥‡ã€‚<br>åŒæ—¶æœ¬æ–‡çš„å›¾ä¹Ÿå¾ˆæ¼‚äº®ï¼Œæ¯ä¸ªå›¾éƒ½æ°åˆ°å¥½å¤„ï¼Œå¯ä»¥é€šè¿‡å›¾å°±å¤§è‡´ç†è§£æœ¬æ–‡åœ¨è®²ä»€ä¹ˆã€‚</p>
]]></content>
      <tags>
        <tag>Classification</tag>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>LSTM</tag>
        <tag>Language Modeling</tag>
        <tag>pretrain</tag>
        <tag>long-term dependency</tag>
        <tag>GC-Net</tag>
        <tag>Ordered Neuron</tag>
        <tag>GPT</tag>
        <tag>GE-Net</tag>
        <tag>PSANet</tag>
        <tag>CCNet</tag>
      </tags>
  </entry>
  <entry>
    <title>Macä¸Šå¾ˆå¥½ç”¨çš„è½¯ä»¶æ¨è</title>
    <url>/2019/05/07/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E4%B8%8A%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<p>è®°å½•ä¸ªäººè§‰å¾—å¾ˆå¥½ç”¨çš„Macè½¯ä»¶ï¼Œè®©Macä½œä¸ºï¼ˆç¨‹åºå‘˜ğŸ‘¨â€ğŸ’»â€/ç§‘ç ”äººå‘˜ğŸ‘¨â€ğŸ”¬ï¼‰ç”Ÿäº§åŠ›å·¥å…·æ›´é¡ºæ‰‹ï¼Œæå‡ç”Ÿäº§æ•ˆç‡ã€‚</p>
<h3 id="Alfred3"><a href="#Alfred3" class="headerlink" title="[Alfred3]"></a>[Alfred3]</h3><p>ç½‘ä¸Šæœ‰å¤ªå¤šæ¨èAlfredçš„äº†ï¼Œæˆ‘ä¸»è¦æ˜¯ç”¨Alfredåšä¸€äº›å¸¸è§„æ“ä½œï¼Œå¦‚æ‰“å¼€/æœç´¢æ–‡ä»¶ï¼Œæ–‡æœ¬æ‰©å±•ç­‰ï¼Œä»¥åŠä¸€äº›workflowï¼Œå¦‚æœ‰é“ç¿»è¯‘ã€‚</p>
<p><img src="/images/15572414068036.jpg" width="50%" height="50%"></p>
<h3 id="SwitchResX"><a href="#SwitchResX" class="headerlink" title="[SwitchResX]"></a>[SwitchResX]</h3><p>ç”¨äºæ˜¾ç¤ºå™¨çš„è°ƒæ•´ï¼Œå¯¹äºæˆ‘è€Œè¨€ä¸»è¦ç”¨äºå¤–æ¥å±å¹•å¼€å¯HiDPIã€‚éå¸¸å¥½ç”¨ï¼</p>
<p><img src="/images/15572767190389.jpg" width="100%" height="50%"></p>
<p>å¦‚ä½•å¼€å¯HiDPIï¼š<br><a href="https://www.zhihu.com/question/35300978/answer/126332986" target="_blank" rel="noopener">https://www.zhihu.com/question/35300978/answer/126332986</a></p>
<h3 id="gfxCardStatus"><a href="#gfxCardStatus" class="headerlink" title="[gfxCardStatus]"></a>[gfxCardStatus]</h3><p>ç”¨äºåˆ‡æ¢å¤–æ¥æ˜¾å¡å’Œç‹¬ç«‹æ˜¾å¡ã€‚èƒ½å¤Ÿåœ¨menu barä¸Šè°ƒæ•´ï¼Œæ¯”æ¯æ¬¡è¿›å…¥system preferenceè®¾ç½®æ–¹ä¾¿ä¸€äº›ã€‚</p>
<p><img src="/images/15572214150588.jpg" width="25%" height="50%"></p>
<h3 id="Mendeley"><a href="#Mendeley" class="headerlink" title="[Mendeley]"></a>[Mendeley]</h3><p>æ–‡çŒ®ç®¡ç†å·¥å…·ï¼Œæœ‰ä¸°å¯Œçš„åŠŸèƒ½å’ŒåŒæ­¥åŠŸèƒ½ã€‚å¤šå¹³å°ä¸”å…è´¹ï¼Œå¾ˆçœå¿ƒã€‚</p>
<p><img src="/images/15572214826817.jpg" width="100%" height="50%"></p>
<h3 id="Bartender3"><a href="#Bartender3" class="headerlink" title="[Bartender3]"></a>[Bartender3]</h3><p>å¦‚æœå¤ªå¤šå›¾æ ‡éƒ½æ˜¾ç¤ºåœ¨menu barä¸Šï¼Œä¼šå½±å“è§‚æ„Ÿï¼Œä¸èƒ½ä¸€ä¸‹å­æ‰¾åˆ°è‡ªå·±æƒ³è¦çš„ä¸œè¥¿ã€‚ä½¿ç”¨Bartender3èƒ½å¤Ÿéšè—éƒ¨åˆ†å›¾æ ‡ï¼Œå¹¶ä¸”å¾ˆä¼˜é›…ã€‚</p>
<p>éšè—çŠ¶æ€ï¼š<br><img src="/images/15572217046758.jpg" width="60%" height="50%"></p>
<p>å±•å¼€çŠ¶æ€ï¼š<br><img src="/images/15572217330397.jpg" width="25%" height="50%"></p>
<h3 id="Todoist"><a href="#Todoist" class="headerlink" title="[Todoist]"></a>[Todoist]</h3><p>å­˜æ”¾è¦å®Œæˆçš„äº‹åŠ¡ï¼Œè¿˜å¯ä»¥å­˜æ”¾ä¸€äº›å…¶ä»–çš„ä¸œè¥¿ã€‚ç•Œé¢éå¸¸å¥½çœ‹ï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œå¹¶ä¸”ä¹Ÿæ˜¯å…¨å¹³å°çš„ã€‚ä»˜è´¹ï¼Œä½†å®Œå…¨å€¼å¾—ã€‚å¯¹æˆ‘è€Œè¨€Todoistå¸®åŠ©æˆ‘å°†å·¥ä½œæ•´ç†å¾—äº•äº•æœ‰æ¡ã€‚é™¤äº†å·¥ä½œï¼Œæˆ‘è¿˜ä¼šä¿å­˜ä¸€äº›å…¶ä»–listï¼ˆå¦‚èœå•/æ„¿æœ›æ¸…å•ğŸ˜„ï¼‰ã€‚</p>
<p><img src="/images/15572221262487.jpg" width="90%" height="50%"></p>
<h3 id="MWeb"><a href="#MWeb" class="headerlink" title="[MWeb]"></a>[MWeb]</h3><p>Markdownå†™ä½œå·¥å…·ã€‚æˆ‘ç”¨è¿™ä¸ªè½¯ä»¶å†™æ‰€æœ‰çš„åšå®¢ï¼Œé¢œå€¼å¾ˆé«˜ï¼Œå¹¶ä¸”åŠŸèƒ½ä¹Ÿå¾ˆå¼ºå¤§ï¼Œèƒ½å¤Ÿå®æ—¶é¢„è§ˆæ•ˆæœã€‚æ’å…¥å›¾ç‰‡å’Œå…¬å¼éå¸¸éå¸¸æ–¹ä¾¿ã€‚</p>
<p><img src="/images/15572255396438.jpg" width="110%" height="60%"></p>
<h3 id="IINA"><a href="#IINA" class="headerlink" title="[IINA]"></a>[IINA]</h3><p>Macä¸Šæœ€å¥½ç”¨çš„æ’­æ”¾å™¨ã€‚</p>
<p><img src="/images/15572256826384.jpg" width="80%" height="50%"></p>
<h3 id="VMware-Fusion"><a href="#VMware-Fusion" class="headerlink" title="[VMware Fusion]"></a>[VMware Fusion]</h3><p>å¶å°”éœ€è¦ç”¨åˆ°è™šæ‹Ÿæœºï¼Œå¯ä»¥æ— ç¼åˆ‡æ¢å¤šç³»ç»Ÿã€‚</p>
<p><img src="/images/15572258471958.jpg" width="100%" height="50%"></p>
<h3 id="Dash"><a href="#Dash" class="headerlink" title="[Dash]"></a>[Dash]</h3><p>APIæµè§ˆå™¨ï¼Œä¸€ä¸ªçª—å£æŸ¥æ‰€æœ‰è¯­è¨€/åŒ…çš„APIã€‚</p>
<p><img src="/images/15572259911688.jpg" width="80%" height="50%"></p>
<h3 id="Cinch"><a href="#Cinch" class="headerlink" title="[Cinch]"></a>[Cinch]</h3><p>[Deprecated]</p>
<p><del>Macä¸Šçš„åˆ†å±ç¡®å®ä¸å¦‚Windowsä¸Šçš„å¥½ç”¨ï¼ŒCinchè‡´åŠ›äºåœ¨Macä¸Šä¹Ÿæœ‰Windowsçš„åˆ†å±ä½“éªŒã€‚å°†çª—å£å‘ä¸Šæ‹–æˆ–å‘ä¸¤è¾¹æ‹–ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å…¨å±æˆ–è€…åˆ†å±ã€‚</del> å¯¹å¤šå±å¹•ä¸æ˜¯å¾ˆå‹å¥½ï¼Œå¦‚æœæ˜¯å‘å³æ‹–åˆ†å±å¯èƒ½ä¼šæ‹–åˆ°å¤–æ¥å±å¹•ä¸Šã€‚</p>
<!--<img src="/images/15572261520468.jpg" width="100%" height="50%">-->
<h3 id="Moom"><a href="#Moom" class="headerlink" title="[Moom]"></a>[Moom]</h3><p>åŠŸèƒ½æå…¶å¼ºå¤§çš„åˆ†å±åº”ç”¨ã€‚æ—¢é€‚åˆæ™®é€šé¼ æ ‡å…šä½¿ç”¨ï¼Œä¹Ÿæ”¯æŒé«˜åº¦å®šåˆ¶åŒ–é€‚åˆé”®ç›˜å…šçš„ä½¿ç”¨ã€‚</p>
<p><img src="/images/15613895824781.jpg" width="55%" height="50%"></p>
<p><a href="https://zhuanlan.zhihu.com/p/20258341" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20258341</a></p>
<h3 id="Mathpix-Snipping-Tool"><a href="#Mathpix-Snipping-Tool" class="headerlink" title="[Mathpix Snipping Tool]"></a>[Mathpix Snipping Tool]</h3><p>å¼ºçƒˆæ¨èè¿™æ¬¾è½¯ä»¶ï¼å†™åšå®¢æ—¶ç»å¸¸è¦æ’å…¥è®ºæ–‡é‡Œé¢çš„å…¬å¼ï¼Œå¦‚æœè‡ªå·±æ‰“ä¸ä»…éº»çƒ¦ï¼Œæœ‰äº›è¿˜ä¸çŸ¥é“æ€ä¹ˆæ‰“ã€‚Mathpixèƒ½å¤Ÿå°†æˆªå›¾è‡ªåŠ¨è½¬æ¢æˆå…¬å¼ï¼Œå¹¶ä¸”è¯†åˆ«ç‡æŒºé«˜ï¼Œçœäº†å¾ˆå¤šåŠ›æ°”ã€‚</p>
<p><img src="/images/15572263265931.jpg" width="70%" height="50%"></p>
<h3 id="Xnip"><a href="#Xnip" class="headerlink" title="[Xnip]"></a>[Xnip]</h3><p>ä¸€æ¬¾å¾ˆæ–¹ä¾¿çš„æˆªå›¾è½¯ä»¶ã€‚æä¾›äº†è®¸å¤šå¦‚é©¬èµ›å…‹ç”»å›¾çš„åŠŸèƒ½ï¼Œè¿˜æ”¯æŒæˆªé•¿å›¾ã€‚</p>
<h3 id="Paste"><a href="#Paste" class="headerlink" title="[Paste]"></a>[Paste]</h3><p>ä¿å­˜æ‰€æœ‰ä¹‹å‰å¤åˆ¶å†…å®¹çš„å†å²ï¼ŒåŒ…æ‹¬æ–‡æœ¬ï¼Œå›¾ç‰‡ï¼Œæ–‡ä»¶ç­‰ï¼Œè¿˜å¯ä»¥ä¿å­˜ä¸€äº›å¸¸ç”¨çš„å†…å®¹ã€‚å¹¶ä¸”å…¶æœ€å¤§çš„äº®ç‚¹åœ¨äºèƒ½å¤Ÿä¸iOSåŒæ­¥ï¼Œä¹Ÿå³åœ¨ä¸€ä¸ªå¹³å°å¤åˆ¶çš„å†…å®¹å¯ä»¥ç›´æ¥åœ¨å¦ä¸€ä¸ªå¹³å°ç”¨åˆ°ã€‚</p>
<p><img src="/images/15572265842706.jpg" width="100%" height="50%"></p>
<p><img src="/images/15572267155023.png" width="35%" height="50%"></p>
<h3 id="Transmit"><a href="#Transmit" class="headerlink" title="[Transmit]"></a>[Transmit]</h3><p>Macä¸ŠFTPåšå¾—å¾ˆå¥½çš„ä¸€ä¸ªè½¯ä»¶ï¼Œé¢œå€¼ä¹ŸæŒºé«˜ã€‚</p>
<p><img src="/images/15572269805499.jpg" width="100%" height="50%"></p>
<h3 id="iStat-Menus"><a href="#iStat-Menus" class="headerlink" title="[iStat Menus]"></a>[iStat Menus]</h3><p>ç›‘æ§ç³»ç»ŸçŠ¶æ€ï¼ˆCPU/GPU/å†…å­˜/ç½‘ç»œï¼‰çš„è½¯ä»¶ã€‚ç¨³å®šä¸”ç¾è§‚ã€‚æŒ‚åœ¨menu barä¸Šå¯ä»¥å¾ˆæ–¹ä¾¿æŸ¥çœ‹ã€‚</p>
<p><img src="/images/15572272550552.jpg" width="20%" height="50%"></p>
<p><img src="/images/istat.png" width="100%" height="50%"></p>
<h3 id="Downie3"><a href="#Downie3" class="headerlink" title="[Downie3]"></a>[Downie3]</h3><p>è½»é‡çº§çš„ä¸€ä¸ªä¸‹è½½è§†é¢‘çš„å·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨/æ‰‹åŠ¨æå–æµè§ˆå™¨çš„è§†é¢‘é“¾æ¥ã€‚</p>
<p><img src="/images/15572277461936.jpg" width="90%" height="50%"></p>
<h3 id="The-Unarchiver"><a href="#The-Unarchiver" class="headerlink" title="[The Unarchiver]"></a>[The Unarchiver]</h3><p>è½»é‡çº§çš„è§£å‹è½¯ä»¶ï¼Œè½»åˆ°ç”šè‡³æ„Ÿè§‰ä¸åˆ°ä»–çš„å­˜åœ¨ã€‚</p>
<h3 id="OneNote"><a href="#OneNote" class="headerlink" title="[OneNote]"></a>[OneNote]</h3><p>è®°ç¬”è®°çš„åˆ©å™¨ï¼Œofficeå¥—ä»¶ä¸­æˆ‘ç”¨å¾—æœ€é¢‘ç¹çš„è½¯ä»¶ã€‚è®°å½•è®ºæ–‡é˜…è¯»ç¬”è®°/æƒ³æ³•/å®éªŒã€‚ç‹¬ä¸€æ— äºŒçš„çµæ´»æ€§ï¼Œå¯ä»¥åœ¨é¡µé¢çš„ä»»ä½•åœ°æ–¹åˆ›å»ºç¬”è®°ï¼ˆæˆ‘è¯•äº†å¸‚é¢ä¸Šæ‰€æœ‰æµè¡Œçš„ç¬”è®°è½¯ä»¶ï¼Œéƒ½æ²¡æœ‰è¿™æ ·çš„çµæ´»æ€§ï¼‰ã€‚åŒæ—¶è¿˜æ˜¯å…¨å¹³å°ï¼Œè¿˜æ”¯æŒç¬”ï¼Œåœ¨iPadä¸Šçš„ç¬”è¿¹å¯ä»¥å¾ˆå¿«é€ŸåŒæ­¥åˆ°Macä¸Šã€‚å½“ç„¶ç›®å‰è€Œè¨€åŠŸèƒ½è¿˜æ²¡æœ‰Windowsä¸Šçš„OneNoteé‚£ä¹ˆå¼ºå¤§ã€‚</p>
<p><img src="/images/15572281358175.jpg" width="90%" height="50%"></p>
<h3 id="Maipo"><a href="#Maipo" class="headerlink" title="[Maipo]"></a>[Maipo]</h3><p>Macç«¯å¾ˆä¸é”™çš„å¾®åšå®¢æˆ·ç«¯ã€‚å¯ä»¥å¾ˆæ–¹ä¾¿åœ°åœ¨ç”µè„‘ç«¯åˆ·å¾®åšå­¦ä¹ ï¼ˆå¤§é›¾ ã€‚</p>
<p><img src="/images/15572363838509.jpg" width="70%" height="50%"></p>
<h3 id="linux-command"><a href="#linux-command" class="headerlink" title="[linux-command]"></a>[linux-command]</h3><p>æ–¹ä¾¿æœç´¢Linuxå‘½ä»¤ã€‚</p>
<p><img src="/images/15572363564485.jpg" width="90%" height="50%"></p>
<h3 id="iTerm"><a href="#iTerm" class="headerlink" title="[iTerm]"></a>[iTerm]</h3><p>å‘½ä»¤è¡Œæ˜¯ğŸ‘¨â€ğŸ’»â€å¿…å¤‡ã€‚è€ŒiTermç›¸å¯¹åŸç”Ÿterminalæœ‰æ›´ä¸°å¯Œçš„è®¾ç½®ä»¥åŠæ›´å¼ºå¤§çš„åŠŸèƒ½ã€‚</p>
<p><img src="/images/15572775111514.jpg" width="90%" height="50%"></p>
<h3 id="AppCleaner"><a href="#AppCleaner" class="headerlink" title="[AppCleaner]"></a>[AppCleaner]</h3><p>è½»æ¾åœ°åˆ é™¤Macè½¯ä»¶ï¼Œå¯ä»¥æ£€æµ‹è¯¥è½¯ä»¶æ‰€å¸¦çš„å…¶ä»–æ–‡ä»¶ï¼Œä¸€å¹¶åˆ é™¤ã€‚é…åˆAlfredçš„workflowå¾ˆæ–¹ä¾¿ã€‚</p>
<p><img src="/images/15572414475923.jpg" width="70%" height="50%"></p>
<h3 id="Mos"><a href="#Mos" class="headerlink" title="[Mos]"></a>[Mos]</h3><p>Macçš„è§¦æ§æ¿å’Œé¼ æ ‡çš„é€»è¾‘æ˜¯åçš„ã€‚å¦‚æœå¸Œæœ›è§¦æ§æ¿å’Œé¼ æ ‡ä¸€èµ·ç”¨ï¼Œå¹¶ä¸”é€»è¾‘å„ä¸ç›¸åŒï¼Œåˆ™å¯ä»¥ä½¿ç”¨Mosï¼ŒMosèƒ½å¤Ÿå°†é¼ æ ‡ç¿»è½¬ã€‚</p>
<p><img src="/images/15572415681851.jpg" width="70%" height="50%"></p>
<h3 id="PDF-Expert"><a href="#PDF-Expert" class="headerlink" title="[PDF Expert]"></a>[PDF Expert]</h3><p>å¼ºçƒˆæ¨èçš„PDFé˜…è¯»ç¼–è¾‘è½¯ä»¶ã€‚ç®€å•æ˜“ç”¨ï¼Œå¹¶ä¸”åŠŸèƒ½ä¹Ÿè¶³å¤Ÿå¼ºå¤§ã€‚å¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯å¯ä»¥å¤šå¹³å°åŒæ­¥ï¼ˆMac/iOSï¼‰ï¼Œè¿˜å¯ä»¥ä½¿ç”¨â€æ¥åŠ›â€œåŠŸèƒ½ï¼Œå‡å°‘åˆ‡æ¢è®¾å¤‡çš„éº»çƒ¦ã€‚</p>
<p><img src="/images/15572417246059.jpg" width="80%" height="50%"></p>
<h3 id="Contexts"><a href="#Contexts" class="headerlink" title="[Contexts]"></a>[Contexts]</h3><p>å¿«é€Ÿåˆ‡æ¢çª—å£çš„æ•ˆç‡å·¥å…·ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤šæ˜¾ç¤ºå™¨çš„æƒ…å†µä¸‹ï¼Œå¾€å¾€ä¼šæ‰¾ä¸åˆ°æƒ³è¦çš„çª—å£ã€‚å¯¹æˆ‘è€Œè¨€ï¼ŒContextsæå¤§å¢åŠ äº†æ•ˆç‡ã€‚è°ƒå‡ºçª—å£åˆ—è¡¨ï¼Œæ¥ç€æœç´¢å³å¯ï¼Œè¿˜å¯ä»¥é€šè¿‡é¼ æ ‡ç‚¹å‡»å±å¹•è¾¹ä¸Šçš„æµ®åŠ¨çª—å£åˆ‡æ¢ã€‚</p>
<p><img src="/images/context.png" width="90%" height="50%"></p>
<h3 id="SnippetsLab"><a href="#SnippetsLab" class="headerlink" title="[SnippetsLab]"></a>[SnippetsLab]</h3><p>æ”¶è—ä¸€äº›æœ‰ç”¨çš„ä»£ç ç‰‡æ®µã€‚ä¿æŒè®°å½•çš„ä¹ æƒ¯èƒ½å¤Ÿæé«˜ä»£ç æ•ˆç‡ã€‚</p>
<p><img src="/images/15572422193062.jpg" width="100%" height="50%"></p>
<h3 id="Sublime-Text"><a href="#Sublime-Text" class="headerlink" title="[Sublime Text]"></a>[Sublime Text]</h3><p>ä¸éœ€è¦æ¨èï¼Œå¤§åé¼é¼çš„æ–‡æœ¬ç¼–è¾‘è½¯ä»¶ã€‚ğŸ‘¨â€ğŸ’»â€å¿…å¤‡ã€‚</p>
<h3 id="AdGuard-for-Safari"><a href="#AdGuard-for-Safari" class="headerlink" title="[AdGuard for Safari]"></a>[AdGuard for Safari]</h3><p>å› ä¸ºSafariçš„è½»é‡ä»¥åŠé¢œå€¼æ”¾å¼ƒäº†ä½¿ç”¨å¾ˆä¹…çš„Chromeï¼Œä½†ä¹Ÿæ„å‘³ç€æ”¾å¼ƒäº†ä¸°å¯Œçš„æµè§ˆå™¨æ’ä»¶ã€‚åœ¨Chromeå¯ä»¥ä½¿ç”¨AdBlockï¼Œåœ¨Safariåˆ™å¯ä»¥ä½¿ç”¨AdGuardï¼Œéå¸¸è½»é‡ï¼Œç”šè‡³æ„Ÿè§‰ä¸åˆ°å®ƒçš„å­˜åœ¨ã€‚</p>
<h3 id="CatchMouse"><a href="#CatchMouse" class="headerlink" title="[CatchMouse]"></a>[CatchMouse]</h3><p>é’ˆå¯¹å¤šå±å¹•è€Œè®¾è®¡ã€‚æœ‰æ—¶å€™ä¼šæ‰¾ä¸åˆ°é¼ æ ‡åœ¨å“ªä¸ªå±å¹•ã€‚é€šè¿‡è®¾ç½®å¿«æ·é”®ï¼Œèƒ½å¤Ÿå¿«é€Ÿå°†é¼ æ ‡ç§»åŠ¨åˆ°æŒ‡å®šå±å¹•ï¼Œåœ¨åˆ‡æ¢çš„æ—¶å€™è¿˜ä¼šç¼©æ”¾é¼ æ ‡çš„å›¾æ ‡ä½œä¸ºæé†’ã€‚ï¼ˆæ‰¾äº†å¥½ä¹…æ‰æ‰¾åˆ°è¿™ä¸ªç¬¦åˆæˆ‘éœ€æ±‚çš„è½¯ä»¶ï¼‰</p>
<p><img src="/images/15572424938492.jpg" width="60%" height="50%"></p>
<p><img src="/images/15572425907175.jpg" width="60%" height="50%"></p>
<h3 id="Zoom"><a href="#Zoom" class="headerlink" title="[Zoom]"></a>[Zoom]</h3><p>ä¼šè®®ç”µè¯çš„è½¯ä»¶ã€‚å¼€è¿œç¨‹PaperReadingå¯ä»¥ç”¨ğŸŒšã€‚</p>
<h3 id="Mate-Translate"><a href="#Mate-Translate" class="headerlink" title="[Mate Translate]"></a>[Mate Translate]</h3><p>é›†æˆåœ¨å³é”®çš„ç¿»è¯‘å·¥å…·ã€‚åœ¨çœ‹è®ºæ–‡æˆ–è€…æµè§ˆç½‘é¡µæ—¶å¯ä»¥éšæ—¶ç¿»è¯‘å¥å­ã€‚</p>
<p><img src="/images/15592926038793.jpg" width="40%" height="50%"></p>
<p><img src="/images/15592926623566.jpg" width="55%" height="50%"></p>
<h3 id="ToothFairy"><a href="#ToothFairy" class="headerlink" title="[ToothFairy]"></a>[ToothFairy]</h3><p>ä¸€é”®è¿æ¥è“ç‰™è®¾å¤‡çš„åº”ç”¨ã€‚é©»æ‰åœ¨MenuBarä¸Šå¯ä»¥ä¸€é”®è¿æ¥è‡ªå·±çš„è“ç‰™è®¾å¤‡ã€‚æˆ‘ä¸€èˆ¬ç”¨äºè¿æ¥æ— çº¿è“ç‰™è€³æœºï¼ˆXM3ï¼‰å’ŒAirpodsã€‚</p>
<p><img src="/images/15613850296455.jpg" width="10%" height="50%"></p>
<h3 id="Quicklookæ’ä»¶"><a href="#Quicklookæ’ä»¶" class="headerlink" title="[Quicklookæ’ä»¶]"></a>[Quicklookæ’ä»¶]</h3><p>Macä¸Šä¸€ä¸ªå¾ˆäººæ€§åŒ–çš„æ“ä½œå°±æ˜¯å¯ä»¥ç©ºæ ¼é¢„è§ˆã€‚ä½†å¯¹äºä¸€äº›æ ¼å¼æ”¯æŒè¿˜ä¸å¤Ÿå¥½ï¼Œæ¯”å¦‚æ— æ‰©å±•åçš„æ— æ³•æ”¯æŒé¢„è§ˆï¼ŒMarkdownåªèƒ½é¢„è§ˆæºä»£ç ï¼Œé¢„è§ˆæºä»£ç åªæ”¯æŒé¢„è§ˆçº¯æ–‡æœ¬ï¼Œå¹¶æ²¡æœ‰é«˜äº®æ˜¾ç¤ºã€‚å› æ­¤Quicklookæ’ä»¶å¯ä»¥è§£å†³è¿™äº›ç»†èŠ‚é—®é¢˜ã€‚</p>
<p><a href="https://github.com/sindresorhus/quick-look-plugins" target="_blank" rel="noopener">https://github.com/sindresorhus/quick-look-plugins</a></p>
<p>é¢„è§ˆMarkdownï¼š</p>
<p><img src="/images/15613853773728.jpg" width="50%" height="50%"></p>
<p>é¢„è§ˆæ— æ‰©å±•åçš„çº¯æ–‡æœ¬ï¼š</p>
<p><img src="/images/15613855291056.jpg" width="60%" height="50%"></p>
<h3 id="UltraCompare"><a href="#UltraCompare" class="headerlink" title="[UltraCompare]"></a>[UltraCompare]</h3><p>æ–‡ä»¶å¯¹æ¯”å·¥å…·ã€‚</p>
<p><img src="/images/15648879772101.jpg" width="70%" height="50%"></p>
<h3 id="Texpad"><a href="#Texpad" class="headerlink" title="[Texpad]"></a>[Texpad]</h3><p>Macä¸Šè¿›è¡ŒLaTexç¼–è¾‘çš„ä¸äºŒé€‰æ‹©ã€‚ç•Œé¢ä¼˜é›…ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œç¼–è¯‘é€Ÿåº¦é£å¿«ã€‚é‡è¦çš„æ˜¯å„ç§tableå’Œlabeléƒ½åœ¨å·¦è¾¹æ˜¾ç¤ºå‡ºæ¥ï¼Œå¯ä»¥æ–¹ä¾¿å¿«é€Ÿè·³è½¬ã€‚åœ¨ç”¨overleafçš„æ—¶å€™å°±ç»å¸¸è¦åˆ°å¤„æ‰¾tableã€‚</p>
<p><img src="/images/15648883057108.jpg" width="90%" height="50%"></p>
<h3 id="Alternote"><a href="#Alternote" class="headerlink" title="[Alternote]"></a>[Alternote]</h3><p>Macä¸Šnoteçš„ä¸€å®šç¨‹åº¦ä¸Šçš„æ›¿ä»£å“ã€‚Macè‡ªå¸¦çš„å¤‡å¿˜å½•åœ¨é”®å…¥è¶…è¿‡1000å­—ä¹‹åå°±ä¼šå˜å¾—å¡é¡¿ï¼Œå› æ­¤éœ€è¦ä¸€æ¬¾æ›¿ä»£å“ã€‚åœ¨å¯¹æ¯”äº†å‡ æ¬¾ä¹‹åé€‰æ‹©Alternoteã€‚Alternoteæ˜¯å°è±¡ç¬”è®°çš„ç¬¬ä¸‰æ–¹appï¼Œåªä¿ç•™æœ€åŸºæœ¬çš„åŠŸèƒ½ï¼Œä¸”ç•Œé¢æ›´åŠ ä¼˜é›…ï¼Œä¹Ÿç¬¦åˆæˆ‘è½»é‡çº§çš„éœ€æ±‚ã€‚</p>
<p>âŒAgenda å¤ªè¿‡å¤æ‚äº†ï¼Œæ²¡å¿…è¦<br>âŒsimplenote æœ‰äº›è¿‡äºç®€å•ï¼Œåªæœ‰ä¸€çº§èœå•<br>âŒQuip æ˜¯åŠå…¬å¥—ä»¶ï¼Œä¸æˆ‘çš„éœ€æ±‚ä¸ç¬¦<br>âŒzoho   ä¸å¥½ç”¨ï¼Œæˆ‘ä¸å–œæ¬¢è¿™ç§é£æ ¼<br>âŒPendo<br>âœ…alternote  ç•Œé¢ä¸é”™ä¸”ç®€æ´<br>âŒnotability å¤ªè¿‡å¤æ‚<br>âŒpaper ä¸æ˜¯æˆ‘çš„é£æ ¼</p>
<p><img src="/images/15648886006772.jpg" width="40%" height="50%"></p>
<h3 id="Scapple"><a href="#Scapple" class="headerlink" title="[Scapple]"></a>[Scapple]</h3><p>æ€ç»´å¯¼å›¾å·¥å…·ã€‚è½»é‡ï¼Œæ˜“ç”¨ï¼ŒåŠŸèƒ½å¼ºå¤§ã€‚</p>
<p><img src="/images/15648890419056.jpg" width="70%" height="50%"></p>
<h3 id="MonitorControl"><a href="#MonitorControl" class="headerlink" title="[MonitorControl]"></a>[MonitorControl]</h3><p>èƒ½å¤Ÿæ§åˆ¶å¤–æ¥å±çš„äº®åº¦å¯¹æ¯”åº¦ç­‰ï¼Œä¸å†éœ€è¦æŒ‰ç‰©ç†é”®äº†ã€‚</p>
<p><img src="/images/15664846144052.jpg" width="30%" height="50%"></p>
<h3 id="Noizio"><a href="#Noizio" class="headerlink" title="[Noizio]"></a>[Noizio]</h3><p>ç™½å™ªå£°åº”ç”¨ã€‚æˆ´ä¸Šé™å™ªè€³æœºå†å¼€å¯ç™½å™ªå£°ï¼Œå¯ä»¥å®Œå…¨å±è”½å‘¨å›´çš„å£°éŸ³åŒ…æ‹¬äººå£°ã€‚å¹¶ä¸”æœ‰èº«ä¸´å…¶å¢ƒçš„æ„Ÿè§‰ï¼Œèƒ½å¤Ÿæ›´åŠ ä¸“æ³¨äºå·¥ä½œã€‚</p>
<p><img src="/images/15664847839748.jpg" width="40%" height="50%"></p>
<h3 id="pap-er"><a href="#pap-er" class="headerlink" title="[pap.er]"></a>[pap.er]</h3><p>ä¸€ä¸ªè½»é‡çº§çš„å£çº¸åº”ç”¨ã€‚æ‹¥æœ‰è¶…é«˜æ¸…çš„æµ·é‡çš„å£çº¸ã€‚</p>
<p><img src="/images/15664848978708.jpg" width="30%" height="50%"></p>
<h3 id="CheatSheet"><a href="#CheatSheet" class="headerlink" title="[CheatSheet]"></a>[CheatSheet]</h3><p>æŸ¥çœ‹å„ç§åº”ç”¨çš„å¿«æ·é”®ã€‚æ‰“å¼€å®ƒï¼Œé•¿æŒ‰commandå°±ä¼šè·³å‡ºå½“å‰æ´»è·ƒçš„åº”ç”¨çš„æ‰€æœ‰å¿«æ·é”®ã€‚</p>
<p><img src="/images/15664850960793.jpg" width="30%" height="50%"></p>
<h3 id="TimeMachineEditor"><a href="#TimeMachineEditor" class="headerlink" title="[TimeMachineEditor]"></a>[TimeMachineEditor]</h3><p>èƒ½å¤Ÿä¿®æ”¹TimeMachineçš„å¤‡ä»½è®¡åˆ’ã€‚å¦‚æœæ˜¯åƒæˆ‘è¿™æ ·é•¿æœŸæ’ç€TimeMachineå¤‡ä»½ç›˜çš„ï¼Œç»å¸¸ä¼šåœ¨ä½¿ç”¨çš„æ—¶å€™å› ä¸ºå¤‡ä»½è€Œå¯¼è‡´ç”µè„‘å¡é¡¿ã€‚ä¸€èˆ¬è€Œè¨€TMæ˜¯æ¯å°æ—¶å¤‡ä»½ä¸€æ¬¡ï¼Œæ— è®ºç”µè„‘æ˜¯å¦åœ¨å·¥ä½œï¼Œè€Œæˆ‘ä»¬å¹¶ä¸éœ€è¦å¦‚æ­¤é«˜é¢‘ç‡çš„å¤‡ä»½ï¼Œå› æ­¤å¯ä»¥é€šè¿‡TimeMachineEditoræ¥è®¾å®šä¸åŒçš„å¤‡ä»½è®¡åˆ’ï¼Œå¦‚è®¾å®šå½“ç”µè„‘ä¸æ´»è·ƒçš„æ—¶å€™å¼€å§‹å¤‡ä»½ã€‚</p>
<p><img src="/images/15674259207857.jpg" width="50%" height="50%"></p>
<h3 id="Typeeto"><a href="#Typeeto" class="headerlink" title="[Typeeto]"></a>[Typeeto]</h3><p><img src="/images/15709598457082.jpg" width="30%" height="50%"></p>
<p>é€šè¿‡è“ç‰™è¿æ¥å…¶ä»–è®¾å¤‡ï¼Œå¯ä»¥é€šè¿‡Macçš„é”®ç›˜åœ¨å…¶ä»–è®¾å¤‡è¾“å…¥ã€‚åœ¨éœ€è¦å¤§é‡è¾“å…¥çš„åœºæ™¯ä¸‹éå¸¸å¥½ç”¨ã€‚</p>
<hr>
]]></content>
      <tags>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>Mac</tag>
        <tag>app</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºtransformer-xlä¸­rel-shiftå®ç°çš„è§£è¯»</title>
    <url>/2019/05/07/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E5%85%B3%E4%BA%8Etransformer-xl%E4%B8%ADrel-shift%E5%AE%9E%E7%8E%B0%E7%9A%84%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<h4 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h4><p>transformer-xlä¸­æœ‰ä¸€æ­¥ä½¿ç”¨ç›¸å¯¹ä½ç½®è®¡ç®—attention weightï¼š</p>
<p>$\mathbf{A}_{i, j}^{\mathrm{rel}}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(b)}+\underbrace{u^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{v^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(d)}$</p>
<p>ç”±äºç›¸å¯¹ä½ç½®è¦è®¡ç®—æ‰€æœ‰çš„queryä¸keyå¯¹ï¼Œå› æ­¤æ˜¯å¹³æ–¹çš„å¤æ‚åº¦ã€‚è€Œåœ¨è®ºæ–‡çš„é™„å½•ä¸­æåˆ°å¯ä»¥é€šè¿‡ç®€å•çš„æ¨å¯¼å°†å¤æ‚åº¦é™ä¸ºçº¿æ€§ã€‚<br>ç®€å•åœ°è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›è·å¾—ï¼š<br>$\mathbf{B} = \left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}} &amp; {0} &amp; {\cdots} &amp; {0} \\ {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+1}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{1}} &amp; {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}} &amp; {\cdots} &amp; {0} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+L-1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+L-1}} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{L-1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}}\end{array}\right] \\  = \left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{Q}_{L-1}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M+L-1}} &amp; {0} &amp; {\cdots} &amp; {0} \\ {q_{1}^{\top} \mathbf{Q}_{L-2}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-2}} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-1}} &amp; {\cdots} &amp; {0} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M}} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+L-1}}\end{array}\right]$</p>
<p>å…¶ä¸­ï¼š<br>$\mathbf{Q} :=\left[ \begin{array}{c}{\mathbf{R}_{M+L-1}^{\top}} \\ {\mathbf{R}_{M+L-2}^{\top}} \\ {\vdots} \\ {\mathbf{R}_{1}^{\top}} \\ {\mathbf{R}_{0}^{\top}}\end{array}\right] \mathbf{W}_{k, R}^{\top}=\left[ \begin{array}{c}{\left[\mathbf{W}_{k, R} \mathbf{R}_{M+L-1}\right]^{\top}} \\ {\vdots} \\ {\vdots} \\ {\left[\mathbf{W}_{k, R} \mathbf{R}_{1}\right]^{\top}} \\ {\left[\mathbf{W}_{k, R} \mathbf{R}_{0}\right]^{\top}}\end{array}\right] \in \mathbb{R}^{(M+L) \times d}$</p>
<p>è€Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è·å¾—çš„æ˜¯ï¼š<br>$\tilde{\mathbf{B}}=\mathbf{q} \mathbf{Q}^{\top}=\left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M}} &amp; {q_{0}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M+L-1}} \\ {q_{1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M}} &amp; {q_{1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-1}} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M}} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+L-1}}\end{array}\right]<br>$</p>
<p>$\tilde{\mathbf{B}}$ä¸$\mathbf{B}$çš„åŒºåˆ«åœ¨äº$\mathbf{B}$æ˜¯$\tilde{\mathbf{B}}$çš„left-shiftedç‰ˆæœ¬ï¼Œå…¶ä¸­ç¬¬ä¸€è¡Œå·¦ç§»äº†L-1ï¼Œåé¢æ¯è¡Œä¾æ¬¡é€’å‡å·¦ç§»ä¸ªæ•°ï¼Œæœ€åä¸€è¡Œåˆ™ä¸å·¦ç§»ã€‚</p>
<h4 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h4><p>æŠ½è±¡åœ°çœ‹ï¼Œæˆ‘ä»¬è¦åšçš„äº‹æƒ…å°±æ˜¯ï¼Œç»™å®šä¸€ä¸ªçŸ©é˜µï¼Œæ¯è¡Œéƒ½è¿›è¡Œå·¦ç§»ï¼Œè€Œç§»åŠ¨çš„ä¸ªæ•°éšè¡Œæ•°é€’å¢è€Œé€’å‡ã€‚</p>
<p>æˆ‘ç›®å‰æƒ³åˆ°çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨gatherï¼Œå°†æƒ³è¦çš„indexæå‰å®šå¥½ï¼Œç„¶åä½¿ç”¨Pytorchçš„gatherå°±èƒ½å¤Ÿå®ç°ã€‚</p>
<p>è€Œtransformer-xlå®ç°äº†å¦ä¸€ç§æ›´å¥½çš„æ–¹æ³•ï¼š<code>_rel_shift</code>ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_rel_shift</span><span class="params">(self, x, zero_triu=False)</span>:</span></span><br><span class="line">    <span class="comment"># x: q,k,bs,n_head</span></span><br><span class="line">    zero_pad = torch.zeros((x.size(<span class="number">0</span>), <span class="number">1</span>, *x.size()[<span class="number">2</span>:]),</span><br><span class="line">                           device=x.device, dtype=x.dtype)</span><br><span class="line">    x_padded = torch.cat([zero_pad, x], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x_padded = x_padded.view(x.size(<span class="number">1</span>) + <span class="number">1</span>, x.size(<span class="number">0</span>), *x.size()[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line">    x = x_padded[<span class="number">1</span>:].view_as(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>ç¬¬ä¸€æ­¥æ˜¯ï¼Œå°†xçš„ç¬¬ä¸€åˆ—å¡«ä¸Špaddingï¼Œæ­¤æ—¶<code>x.size()=q,k+1,bs,n_head</code>ï¼Œæ¥ä¸‹æ¥å°†å…¶é‡æ–°reshapeï¼Œåˆ™å˜æˆäº†<code>x.size()=k+1,q,bs,n_head</code>ï¼Œæœ€åå°†ç¬¬ä¸€è¡Œå»æ‰ï¼Œå˜æˆ<code>x.size()=k,q,bs,n_head</code>ï¼Œå†å°†å…¶reshapeå›xåŸæ¥çš„æ ·å­ã€‚</p>
<p>ä¸ºä»€ä¹ˆè¿™ä¹ˆåšå®ç°äº†æˆ‘ä»¬æƒ³è¦çš„å·¦ç§»çš„åŠŸèƒ½ï¼Ÿæˆ‘ä»¬åº”è¯¥ä»ä¸€ç»´çš„è§’åº¦å»ç†è§£ã€‚å› ä¸ºå®é™…ä¸Šåœ¨å†…å­˜ä¸­æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æŒ‰ç…§ä¸€ç»´å»æ’åˆ—çš„ã€‚</p>
<p>åŸæ¥çš„çŸ©é˜µï¼š<br><img src="/images/15572009149790.jpg" width="60%" height="50%"></p>
<p>å®é™…ä¸Šå°±æ˜¯æœ‰qä¸ªkeyæŒ‰ç…§ä¸€è¡Œå»æ’åˆ—ã€‚</p>
<p>åœ¨åšå®Œpaddingä¹‹åï¼Œåˆ™ï¼š<br><img src="/images/15572009689231.jpg" width="60%" height="50%"></p>
<p>å®é™…ä¸Šå°±æ˜¯åœ¨æ¯ä¸ªkeyå‰é¢æ’å…¥äº†0ã€‚</p>
<p>æ¥ä¸‹æ¥viewï¼Œå®é™…ä¸Šæ•°æ®çš„å…ˆåé¡ºåºè¿˜æ˜¯æ²¡æœ‰å˜ï¼ˆå› ä¸ºä¸æ˜¯transposeï¼‰ï¼š<br><img src="/images/15572010355613.jpg" width="60%" height="50%"></p>
<p>å®é™…ä¸Šåªæ˜¯å¼ºè¡Œå°†è¯¥è¡Œåˆ‡æˆä¸€ä¸ªä¸€ä¸ªqè€Œå·²ã€‚</p>
<p>é‚£ä¹ˆæœ€åä¸€ä¸ªæ“ä½œï¼Œå°†ç¬¬ä¸€è¡Œä¸¢æ‰ï¼Œå®é™…ä¸Šå°±æ˜¯è¦æŠŠåŸæ¥çš„xçš„ç¬¬ä¸€è¡Œå¼ºè¡Œå·¦ç§»q-1ä¸ªï¼ˆå› ä¸ºæœ‰paddingï¼‰ã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆåé¢çš„è¡Œèƒ½å¤Ÿå·¦ç§»çš„ä¸ªæ•°ä¾æ¬¡å‡å°‘ï¼Ÿåˆ«å¿˜äº†paddingï¼Œç¬¬ä¸€è¡Œå·¦ç§»äº†q-1ä¸ªï¼Œä½†ç¬¬äºŒä¸ªkeyå‰é¢ä¹Ÿæœ‰ä¸€ä¸ªpaddingï¼Œæ‰€ä»¥ç›¸å½“äºå°†å…¶å‘å³æ¨äº†ä¸€æ ¼ï¼›ç¬¬ä¸‰ä¸ªåˆæœ‰ä¸€ä¸ªpaddingï¼Œå°±åœ¨åŸæ¥çš„åŸºç¡€ä¸Šåˆæ¨äº†ä¸€æ ¼ï¼Œä¹Ÿå³æ¨äº†ä¸¤æ ¼ã€‚å› æ­¤æœ€åè¾¾åˆ°äº†æˆ‘ä»¬æƒ³è¦çš„ç›®çš„ã€‚</p>
<p>å®é™…ä¸Šè¦ç†è§£è¯¥æ–¹æ³•ï¼Œéœ€è¦ç‰¢ç‰¢æŠŠæ¡æ•°æ®å­˜å‚¨çš„æœ¬è´¨æ˜¯ä¸€æ•´è¡Œã€‚</p>
<p>è¯¥æ–¹æ³•æ²¡æœ‰æ•°æ®çš„æ‹·è´ï¼Œå…¨éƒ¨éƒ½æ˜¯viewæ“ä½œï¼Œå› æ­¤æ›´é«˜æ•ˆã€‚</p>
<p>ä¸å¾—ä¸ä½©æœæƒ³åˆ°è¯¥æ–¹æ³•çš„äººçš„å·¥ç¨‹èƒ½åŠ›ï¼ŒåŒæ—¶ä¹Ÿæ„Ÿè°¢æˆ´å®å¸¦æˆ‘ç†è§£è¯¥æ–¹æ³•çš„æœ¬è´¨ï¼Œä¸€å¼€å§‹æˆ‘æ˜¯æ­»æ´»ä¸ç†è§£çš„ã€‚ä»¥åæˆ–è®¸å¯ä»¥å°†è¯¥æ€æƒ³çµæ´»åº”ç”¨åˆ°å…¶ä»–æ–¹é¢ã€‚</p>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
        <tag>transformer-xl</tag>
        <tag>rel-shift</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­Parameterçš„nan</title>
    <url>/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADParameter%E7%9A%84nan/</url>
    <content><![CDATA[<p>å‰å‡ å¤©é‡åˆ°ä¸€ä¸ªå¾ˆç¥å¥‡çš„bugï¼Œåœ¨Modelé‡Œé¢å®šä¹‰ä¸€ä¸ªParameterï¼ŒParameterå‡ºç°äº†nanã€‚<br>å¦‚ï¼š<br><img src="/images/15571956719188.jpg" width="80%" height="50%"></p>
<p><del>æ‰¾äº†ä¸€åœˆç½‘ä¸Šæ²¡æœ‰æ‰¾åˆ°å…¶åŸå› ï¼Œå·²ç»åœ¨è®ºå›æé—®äº†ã€‚</del><br>æˆ‘çš„è§£å†³æ–¹æ¡ˆæ˜¯æ˜¾å¼å¯¹å…¶è¿›è¡Œåˆå§‹åŒ–ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.init == <span class="string">'uniform'</span>:</span><br><span class="line">    nn.init.uniform_(self.u, -args.init_range, args.init_range)</span><br><span class="line">    nn.init.uniform_(self.v, -args.init_range, args.init_range)</span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> args.init == <span class="string">'normal'</span>:</span><br><span class="line">    nn.init.normal_(self.u, <span class="number">0.0</span>, args.init_std)</span><br><span class="line">    nn.init.normal_(self.v, <span class="number">0.0</span>, args.init_std)</span><br></pre></td></tr></table></figure>
<hr>
<p>åŸæ¥æ˜¯torch.Tensorçš„é”…ï¼Œtorch.Tensorä¼šåˆ†é…å†…å­˜ç©ºé—´ï¼Œä½†ä¸ä¼šæ¸…ç©ºè¯¥ç©ºé—´çš„å€¼ï¼Œå› æ­¤é‡Œé¢å¯èƒ½ä¼šæœ‰å¥‡æ€ªçš„å€¼ã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.Parameter(torch.rand(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># æˆ–è€…</span></span><br><span class="line">torch.nn.Parameter(torch.zeros(<span class="number">10</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>å‚è€ƒèµ„æ–™ï¼š<br><a href="https://discuss.pytorch.org/t/nan-in-torch-tensor/8987" target="_blank" rel="noopener">https://discuss.pytorch.org/t/nan-in-torch-tensor/8987</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>nan</tag>
        <tag>Parameter</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorchä¸­é‡åˆ°çš„é—®é¢˜ï¼ˆåˆé›†ï¼‰</title>
    <url>/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/PyTorch%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E5%90%88%E9%9B%86%EF%BC%89/</url>
    <content><![CDATA[<p>æ–­æ–­ç»­ç»­è®°å½•ä¸€ä¸‹åœ¨å†™ä»£ç è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ä»¥åŠè§£å†³æ–¹æ¡ˆã€‚</p>
<h3 id="Parameter-nan"><a href="#Parameter-nan" class="headerlink" title="[Parameter nan]"></a>[Parameter nan]</h3><p><a href="http://www.linzehui.me/2019/05/07/ç¢ç‰‡çŸ¥è¯†/å…³äºPytorchä¸­Parameterçš„nan/">http://www.linzehui.me/2019/05/07/ç¢ç‰‡çŸ¥è¯†/å…³äºPytorchä¸­Parameterçš„nan/</a></p>
<h4 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>åœ¨å®šä¹‰Parameteræ—¶é‡åˆ°å…¶å…ƒç´ å­˜åœ¨nançš„é—®é¢˜ã€‚</p>
<p><img src="/images/15571956719188.jpg" width="80%" height="50%"></p>
<h4 id="åŸå› "><a href="#åŸå› " class="headerlink" title="åŸå› "></a>åŸå› </h4><p><code>torch.Tensor(m,n)</code>åªåˆ†é…ç©ºé—´è€Œæ²¡æœ‰å°†å…¶ä¸­çš„å€¼æ›´æ–°ã€‚</p>
<h4 id="è§£å†³æ–¹æ¡ˆ"><a href="#è§£å†³æ–¹æ¡ˆ" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p><code>torch.Tensor(m,n)</code>æ˜¯ä¸å»ºè®®ä½¿ç”¨çš„åˆå§‹åŒ–æ–¹æ³•ã€‚æ”¹æˆ<code>torch.nn.Parameter(torch.rand(10,10))</code>æˆ–<code>torch.nn.Parameter(torch.zeros(10,10))</code>ã€‚</p>
<hr>
<h3 id="inplace-operation"><a href="#inplace-operation" class="headerlink" title="[+= inplace operation]"></a>[+= inplace operation]</h3><p><a href="http://www.linzehui.me/2018/12/09/ç¢ç‰‡çŸ¥è¯†/Pythonä¸­çš„+=æ“ä½œ/">http://www.linzehui.me/2018/12/09/ç¢ç‰‡çŸ¥è¯†/Pythonä¸­çš„+=æ“ä½œ/</a></p>
<h4 id="é—®é¢˜æè¿°-1"><a href="#é—®é¢˜æè¿°-1" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output+=pos  <span class="comment"># posæ˜¯ä¸å¯æ›´æ–°çš„tensorï¼Œoutputæ˜¯å¯æ›´æ–°çš„tensor</span></span><br></pre></td></tr></table></figure>
<p>ç¨‹åºæŠ¥é”™ï¼šâ€œone of the variables needed for gradient computation has been modified by an inplace operationâ€ã€‚</p>
<h4 id="åŸå› -1"><a href="#åŸå› -1" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>åœ¨Pythonä¸­ï¼Œ<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ä¸åŒçš„ï¼Œå¦‚æœè¢«æ“ä½œæ•°æ²¡æœ‰éƒ¨ç½² â€™<strong>iadd</strong>â€˜æ–¹æ³•ï¼Œåˆ™<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ç­‰ä»·çš„ï¼Œâ€™+=â€˜å¹¶ä¸ä¼šäº§ç”Ÿin-placeæ“ä½œï¼›å½“è¢«æ“ä½œæ•°æœ‰éƒ¨ç½²è¯¥æ–¹æ³•ä¸”æ­£ç¡®éƒ¨ç½²ï¼Œåˆ™æ˜¯ä¼šäº§ç”Ÿin-placeæ“ä½œçš„ã€‚å½“æ²¡æœ‰in-placeæ“ä½œæ—¶ï¼Œ<code>i=i+1</code>è¡¨ç¤ºå¯¹ié‡åˆ†é…ï¼Œä¹Ÿå³iæŒ‡å‘äº†å¦ä¸€ä¸ªç©ºé—´è€Œä¸æ˜¯åŸæ¥çš„ç©ºé—´ã€‚<br>åœ¨Pytorchä¸­ï¼Œä¹Ÿæœ‰éƒ¨ç½²â€™<strong>iadd</strong>()â€˜æ“ä½œï¼Œæ‰€ä»¥å¯¹äº<code>output+=pos</code>ï¼Œoutputå†…éƒ¨çš„å€¼è¢«æ”¹å˜äº†ï¼Œä¹Ÿå³åœ¨è®¡ç®—å›¾ä¸­å¼•å…¥äº†ç¯ï¼Œåœ¨åå‘æ±‚å¯¼æ—¶åˆ™ä¼šå‡ºé”™ã€‚</p>
<h4 id="è§£å†³æ–¹æ¡ˆ-1"><a href="#è§£å†³æ–¹æ¡ˆ-1" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>å°½é‡ä¸ä½¿ç”¨inplaceæ“ä½œï¼Œå³ä½¿æ˜¯å®˜æ–¹çš„APIï¼Œå¦‚<code>unsqueeze_()</code>ã€‚å·²ç»å¥½å‡ æ¬¡è¢«inplaceæ“ä½œå‘äº†ã€‚</p>
<hr>
<h3 id="squeeze-dim"><a href="#squeeze-dim" class="headerlink" title="[squeeze dim]"></a>[squeeze dim]</h3><p><a href="http://www.linzehui.me/2019/05/06/ç¢ç‰‡çŸ¥è¯†/æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20/">http://www.linzehui.me/2019/05/06/ç¢ç‰‡çŸ¥è¯†/æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20/</a></p>
<h4 id="é—®é¢˜æè¿°-2"><a href="#é—®é¢˜æè¿°-2" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>å½“éœ€è¦squeezeæ—¶ï¼ŒæœªæŒ‡å®šsqueezeçš„ç»´åº¦ï¼Œå¯¼è‡´åé¢çš„ç»´æ•°ä¸ä¸€è‡´ï¼ŒæŠ¥é”™ã€‚</p>
<h4 id="åŸå› -2"><a href="#åŸå› -2" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>ç”±äºåœ¨æŸäº›æç«¯æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šå‡ºç°batch sizeä¸º1çš„æƒ…å†µï¼Œå½“é‡åˆ°è¿™ä¸ªæƒ…å†µæ—¶ï¼Œsqueezeä¼šå°†å…¶ä¸€å¹¶å‹ç¼©æ‰ï¼Œä½¿å¾—åé¢ä¼šå‡ºé”™ã€‚</p>
<h4 id="è§£å†³æ–¹æ¡ˆ-2"><a href="#è§£å†³æ–¹æ¡ˆ-2" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>å°½å¯èƒ½æ˜¾å¼æŒ‡å®šè¦å‹ç¼©çš„ç»´åº¦ï¼Œé™¤éå¾ˆæ˜ç¡®å°±è¦å°†æ‰€æœ‰çš„å‹ç¼©æ‰ã€‚</p>
<hr>
<h3 id="infâ€”-gt-nan"><a href="#infâ€”-gt-nan" class="headerlink" title="[infâ€”&gt;nan]"></a>[infâ€”&gt;nan]</h3><p><a href="http://www.linzehui.me/2019/07/03/ç¢ç‰‡çŸ¥è¯†/å…³äºPyTorchä¸­infå¯¼æ•°çš„nané—®é¢˜/">http://www.linzehui.me/2019/07/03/ç¢ç‰‡çŸ¥è¯†/å…³äºPyTorchä¸­infå¯¼æ•°çš„nané—®é¢˜/</a></p>
<h4 id="é—®é¢˜æè¿°-3"><a href="#é—®é¢˜æè¿°-3" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>ä¸¤ä¸ªtensorç›¸ä¹˜ï¼Œè‹¥å…¶ä¸­ä¸€ä¸ªtensorå¸¦æœ‰infï¼Œåˆ™å¦ä¸€ä¸ªtensorï¼ˆè¯¥tensorå¯æ›´æ–°ï¼‰çš„gradåˆ™ä¸ºnanã€‚</p>
<h4 id="åŸå› -3"><a href="#åŸå› -3" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>ä¹˜æ³•çš„å¯¼æ•°çš„å®šä¹‰ã€‚ä¸¤ä¸ªtensorç›¸ä¹˜ï¼Œå¯¼æ•°ä¸ºå¯¹æ–¹ã€‚åœ¨PyTorchä¸­ï¼Œinfçš„gradåˆ™ä¸ºnanã€‚</p>
<h4 id="è§£å†³æ–¹æ¡ˆ-3"><a href="#è§£å†³æ–¹æ¡ˆ-3" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>åœ¨ç›¸ä¹˜å‰ï¼Œå°†å¸¦æœ‰infçš„tensoråšmasked_fillï¼Œinfè¢«ç½®ä¸º0åå†ç›¸ä¹˜ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>nan</tag>
        <tag>inf</tag>
        <tag>Parameter</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•16</title>
    <url>/2019/05/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9516/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorchæ£€æŸ¥tensor-nan"><a href="#1ï¸âƒ£-Pytorchæ£€æŸ¥tensor-nan" class="headerlink" title="1ï¸âƒ£[Pytorchæ£€æŸ¥tensor nan]"></a>1ï¸âƒ£[Pytorchæ£€æŸ¥tensor nan]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># æ³•ä¸€ï¼ŒåŸºäºnan!=nan </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, np.nan])</span><br><span class="line">tensor([  <span class="number">1.</span>,   <span class="number">2.</span>, nan.])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x != x</span><br><span class="line">tensor([ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>], dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ³•äºŒï¼Œtorch.isnan(x)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.isnan(x)</span><br><span class="line">tensor([ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>], dtype=torch.uint8)</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20</title>
    <url>/2019/05/06/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8620/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>â‘ <br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.gather(input, dim, index, out=<span class="keyword">None</span>) â†’ Tensor</span><br></pre></td></tr></table></figure></p>
<p>èƒ½å¤Ÿæ ¹æ®indexçš„å€¼åœ¨æŒ‡å®šç»´åº¦æ”¶é›†æ•°å€¼ã€‚å¯ä»¥ç”¨äºåˆ‡sliceã€‚</p>
<p>â‘¡<br>expandå’Œrepeatä¸åŒï¼Œä¸ä¼šåˆ†é…æ–°çš„å†…å­˜ã€‚å¦‚æœä¸€ä¸ªtensorä½¿ç”¨expandå†catåˆ°å…¶ä»–tensorä¸Šï¼Œè¿™ä¸ªexpandè¿˜ä¼šçœå†…å­˜å—ï¼Ÿ<br>ä¸ä¼šã€‚<br>åœ¨catçš„æ—¶å€™ä¼šé‡æ–°åˆ†é…æ•´ä¸ªtensorçš„å†…å­˜ï¼Œå¹¶ä¸”å°†å…ƒç´ ä¸€ä¸ªä¸€ä¸ªcopyè¿‡å»ã€‚</p>
<p><a href="https://discuss.pytorch.org/t/efficiency-of-torch-cat/8830" target="_blank" rel="noopener">https://discuss.pytorch.org/t/efficiency-of-torch-cat/8830</a></p>
<blockquote>
<p>it pre-allocates the full tensor and then copy into it each element</p>
</blockquote>
<p>â‘¢</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.einsum(equation, *operands) â†’ Tensor</span><br></pre></td></tr></table></figure>
<blockquote>
<p>This function provides a way of computing multilinear expressions (i.e. sums of products) using the Einstein summation convention.</p>
</blockquote>
<p>å‘ç°ä¸€ä¸ªç¥å¥‡çš„apiï¼ŒPytorchæ”¯æŒçˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š(Einstein summation convention)ã€‚ä¹Ÿå³åœ¨ç»™å®šä¸¤ä¸ªtensoræ—¶ï¼Œå¯ä»¥æŒ‡å®šç»´åº¦è¿›è¡Œæ±‚å’Œï¼Œç›¸å½“çµæ´»ï¼Œå¯ä»¥ç†è§£æˆbmmæˆ–è€…mmçš„æ‰©å±•ç‰ˆï¼Œè¿™æ ·åœ¨åšä¸€äº›tensorä¹‹é—´çš„æ“ä½œå°±ä¸éœ€è¦view/permuteè°ƒæ•´æˆbmmæ”¯æŒçš„æ ¼å¼äº†ã€‚</p>
<p>å®˜æ–¹ä¾‹å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.randn(<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'i,j-&gt;ij'</span>, x, y)  <span class="comment"># outer product</span></span><br><span class="line">tensor([[<span class="number">-0.0570</span>, <span class="number">-0.0286</span>, <span class="number">-0.0231</span>,  <span class="number">0.0197</span>],</span><br><span class="line">        [ <span class="number">1.2616</span>,  <span class="number">0.6335</span>,  <span class="number">0.5113</span>, <span class="number">-0.4351</span>],</span><br><span class="line">        [ <span class="number">1.4452</span>,  <span class="number">0.7257</span>,  <span class="number">0.5857</span>, <span class="number">-0.4984</span>],</span><br><span class="line">        [<span class="number">-0.4647</span>, <span class="number">-0.2333</span>, <span class="number">-0.1883</span>,  <span class="number">0.1603</span>],</span><br><span class="line">        [<span class="number">-1.1130</span>, <span class="number">-0.5588</span>, <span class="number">-0.4510</span>,  <span class="number">0.3838</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l = torch.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = torch.randn(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'bn,anm,bm-&gt;ba'</span>, l, A, r) <span class="comment"># compare torch.nn.functional.bilinear</span></span><br><span class="line">tensor([[<span class="number">-0.3430</span>, <span class="number">-5.2405</span>,  <span class="number">0.4494</span>],</span><br><span class="line">        [ <span class="number">0.3311</span>,  <span class="number">5.5201</span>, <span class="number">-3.0356</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>As = torch.randn(<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Bs = torch.randn(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'bij,bjk-&gt;bik'</span>, As, Bs) <span class="comment"># batch matrix multiplication</span></span><br><span class="line">tensor([[[<span class="number">-1.0564</span>, <span class="number">-1.5904</span>,  <span class="number">3.2023</span>,  <span class="number">3.1271</span>],</span><br><span class="line">         [<span class="number">-1.6706</span>, <span class="number">-0.8097</span>, <span class="number">-0.8025</span>, <span class="number">-2.1183</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">4.2239</span>,  <span class="number">0.3107</span>, <span class="number">-0.5756</span>, <span class="number">-0.2354</span>],</span><br><span class="line">         [<span class="number">-1.4558</span>, <span class="number">-0.3460</span>,  <span class="number">1.5087</span>, <span class="number">-0.8530</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">2.8153</span>,  <span class="number">1.8787</span>, <span class="number">-4.3839</span>, <span class="number">-1.2112</span>],</span><br><span class="line">         [ <span class="number">0.3728</span>, <span class="number">-2.1131</span>,  <span class="number">0.0921</span>,  <span class="number">0.8305</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'ii-&gt;i'</span>, A) <span class="comment"># diagonal</span></span><br><span class="line">tensor([<span class="number">-0.7825</span>,  <span class="number">0.8291</span>, <span class="number">-0.1936</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'...ii-&gt;...i'</span>, A) <span class="comment"># batch diagonal</span></span><br><span class="line">tensor([[<span class="number">-1.0864</span>,  <span class="number">0.7292</span>,  <span class="number">0.0569</span>],</span><br><span class="line">        [<span class="number">-0.9725</span>, <span class="number">-1.0270</span>,  <span class="number">0.6493</span>],</span><br><span class="line">        [ <span class="number">0.5832</span>, <span class="number">-1.1716</span>, <span class="number">-1.5084</span>],</span><br><span class="line">        [ <span class="number">0.4041</span>, <span class="number">-1.1690</span>,  <span class="number">0.8570</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'...ij-&gt;...ji'</span>, A).shape <span class="comment"># batch permute</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>æˆ‘å¯¹è¿™ä¸ªapiä¸€èˆ¬çš„ç”¨æ³•å°±æ˜¯ï¼Œå°†ä¸¤ä¸ªtensorçš„æ¯ä¸€ç»´ç”¨ä¸åŒçš„è®°å·æ ‡å·ï¼Œç„¶åæƒ³ä¸€ä¸‹æˆ‘æƒ³è¦çš„tensorçš„æ ¼å¼ï¼ŒæŒ‰ç…§è®°å·å†™ä¸‹å°±å¯ä»¥ç›´æ¥å¾—åˆ°äº†ã€‚</p>
<p>â‘£<br>squeezeåœ¨ä½¿ç”¨çš„æ—¶å€™å°½é‡æŒ‡å®šç»´åº¦ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°åœ¨è®­ç»ƒæœ€åä¸€ä¸ªbatchæ—¶ï¼Œbatch_sizeæ­£å¥½æ˜¯1ï¼Œå°±æŠŠbatch_sizeç»™squeezeæ‰äº†ã€‚ï¼ˆå·²ç»ä¸¤æ¬¡é‡åˆ°è¿™æ ·çš„bugäº†ï¼‰</p>
<p>â‘¤</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">apply(fn)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Applies fn recursively to every submodule (as returned by .children()) as well as self. Typical use includes initializing the parameters of a model (see also torch-nn-init).</p>
</blockquote>
<p>å¯ä»¥ç”¨äºæ‰€æœ‰çš„å­æ¨¡å—çš„åˆå§‹åŒ–ï¼Œå¥½åƒå¾ˆæ–¹ä¾¿çš„æ ·å­ã€‚ä½†æˆ‘çªç„¶æƒ³åˆ°è¿™ç§æ–¹æ³•å¯èƒ½ä¼šä¸å°å¿ƒæŠŠembeddingåˆå§‹åŒ–ç»™è¦†ç›–äº†ï¼Œå¦‚æœembeddingæœ‰ç”¨pretrainåˆå§‹åŒ–çš„è¯ã€‚</p>
<p>å®˜æ–¹ä¾‹å­ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">(m)</span>:</span></span><br><span class="line">        print(m)</span><br><span class="line">        <span class="keyword">if</span> type(m) == nn.Linear:</span><br><span class="line">            m.weight.data.fill_(<span class="number">1.0</span>)</span><br><span class="line">            print(m.weight)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">2</span>), nn.Linear(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.apply(init_weights)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h3 id="2ï¸âƒ£-bpc"><a href="#2ï¸âƒ£-bpc" class="headerlink" title="2ï¸âƒ£[bpc]"></a>2ï¸âƒ£[bpc]</h3><p>bits per character(bpc)æ˜¯language modelä¸€ä¸ªè¯„ä»·æŒ‡æ ‡ï¼Œå¦ä¸€ä¸ªå¸¸ç”¨æŒ‡æ ‡æ˜¯pplï¼ˆå›°æƒ‘åº¦ï¼‰ã€‚å®é™…ä¸Šbpcå’Œppléƒ½æ˜¯å’Œäº¤å‰ç†µæŒ‚é’©çš„ï¼Œå…¶è®¡ç®—å…¬å¼ä¸ºï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} b p c(s t r i n g)=\frac{1}{T} \sum_{t=1}^{T} H\left(P_{t}, \hat{P}_{t}\right) &=-\frac{1}{T} \sum_{t=1}^{T} \sum_{c=1}^{n} P_{t}(c) \log _{2} \hat{P}_{t}(c) \\ &=-\frac{1}{T} \sum_{t=1}^{T} \log _{2} \hat{P}_{t}\left(x_{t}\right) \end{aligned}</script><p>åœ¨ä»£ç ä¸­è®¡ç®—äº¤å‰ç†µçš„lossæ˜¯ä»¥eä¸ºåº•çš„ï¼Œå› æ­¤éœ€è¦å°†lossé™¤ä»¥$\log _{e}2$å³å¯ï¼ˆlogçš„æ¢åº•å…¬å¼ï¼‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cur_loss / math.log(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><a href="https://stats.stackexchange.com/questions/211858/how-to-compute-bits-per-character-bpc" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/211858/how-to-compute-bits-per-character-bpc</a><br><a href="https://arxiv.org/pdf/1308.0850.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1308.0850.pdf</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>bpc</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯24</title>
    <url>/2019/05/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D24/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-è§‚ä¹¦"><a href="#1ï¸âƒ£-è§‚ä¹¦" class="headerlink" title="1ï¸âƒ£ è§‚ä¹¦"></a>1ï¸âƒ£ è§‚ä¹¦</h3><p>[æ˜] äºè°¦<br>ä¹¦å·å¤šæƒ…ä¼¼æ•…äººï¼Œæ™¨æ˜å¿§ä¹æ¯ç›¸äº²ã€‚<br>çœ¼å‰ç›´ä¸‹ä¸‰åƒå­—ï¼Œèƒ¸æ¬¡å…¨æ— ä¸€ç‚¹å°˜ã€‚<br>æ´»æ°´æºæµéšå¤„æ»¡ï¼Œä¸œé£èŠ±æŸ³é€æ—¶æ–°ã€‚<br><strong>é‡‘éç‰å‹’å¯»èŠ³å®¢ï¼Œæœªä¿¡å¾åºåˆ«æœ‰æ˜¥ã€‚</strong></p>
<p><a href="http://lib.xcz.im/work/582ee1a2da2f600063ec45ea" target="_blank" rel="noopener">http://lib.xcz.im/work/582ee1a2da2f600063ec45ea</a></p>
<hr>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡17</title>
    <url>/2019/04/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8717/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>PHRASE-BASED ATTENTIONS</li>
<li>Regularizing and Optimizing LSTM Language Models</li>
</ol>
<h2 id="1ï¸âƒ£-PHRASE-BASED-ATTENTIONS"><a href="#1ï¸âƒ£-PHRASE-BASED-ATTENTIONS" class="headerlink" title="1ï¸âƒ£[PHRASE-BASED ATTENTIONS]"></a>1ï¸âƒ£[PHRASE-BASED ATTENTIONS]</h2><p>è¿™ç¯‡æŠ•äº†ICLRä½†æ²¡ä¸­ã€‚<br>æå‡ºå¯¹Transformerçš„attentionæœºåˆ¶è¿›è¡Œæ”¹è¿›ï¼Œä»¥è¯ç»„ä¸ºå•ä½è¿›è¡Œattentionï¼Œå¼•å…¥è¯ç»„çš„å¯¹é½æ¥æå‡ç¿»è¯‘è¡¨ç°ã€‚æå‡ºçš„æƒ³æ³•ä¹Ÿæ˜¯æ¯”è¾ƒç®€å•ç›´è§‚çš„ã€‚</p>
<p>å›é¡¾ï¼š<br>transformerçš„åšæ³•ï¼š<br>$\begin{aligned} \text { Attention }\left(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}_{q}, \boldsymbol{W}_{k}, \boldsymbol{W}_{v}\right) &amp;=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right)\left(\boldsymbol{K} \boldsymbol{W}_{k}\right)^{T}}{\sqrt{d_{k}}}\right)\left(\boldsymbol{V} \boldsymbol{W}_{v}\right) \\ \text { Head }^{i} &amp;=\text { Attention }\left(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}_{q}^{i}, \boldsymbol{W}_{k}^{i}, \boldsymbol{W}_{v}^{i}\right) \text { for } i=1 \ldots h \\ \text { AttentionOutput }(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}) &amp;=\text { concat (Head}^{1}, \text { Head}^{2}, \ldots, \text { Head}^{h} ) \boldsymbol{W} \end{aligned}<br>$</p>
<h3 id="æ¨¡å‹ä»‹ç»"><a href="#æ¨¡å‹ä»‹ç»" class="headerlink" title="æ¨¡å‹ä»‹ç»"></a>æ¨¡å‹ä»‹ç»</h3><h4 id="PHRASE-BASED-ATTENTION-METHODS"><a href="#PHRASE-BASED-ATTENTION-METHODS" class="headerlink" title="PHRASE-BASED ATTENTION METHODS"></a>PHRASE-BASED ATTENTION METHODS</h4><p>å…¶æœ¬è´¨æ˜¯ä½¿ç”¨CNNæ“ä½œä½¿å¾—è¯æœ‰phraseçš„ä¿¡æ¯ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">O_{t}=\mathbf{w} \oplus_{k=0}^{n} \mathbf{x}_{t \pm k}</script><p>ä¸‹é¢ä½¿ç”¨$\operatorname{Conv}_{n}(\boldsymbol{X}, \boldsymbol{W})$ä»£è¡¨$\boldsymbol{W}$å¯¹$\boldsymbol{X}$è¿›è¡Œå·ç§¯æ“ä½œã€‚å…¶ä¸­$\boldsymbol{W} \in \mathbb{R}^{n \times d_{1} \times d_{2}}$</p>
<p>æ¥ä¸‹æ¥æå‡ºä¸¤ç§æ–¹æ³•ã€‚</p>
<h5 id="KEY-VALUE-CONVOLUTION"><a href="#KEY-VALUE-CONVOLUTION" class="headerlink" title="KEY-VALUE CONVOLUTION"></a>KEY-VALUE CONVOLUTION</h5><script type="math/tex; mode=display">\operatorname{Conv} \mathrm{KV}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right) \operatorname{Conv}_{n}\left(\boldsymbol{K}, \boldsymbol{W}_{k}\right)^{T}}{\sqrt{d_{k}}}\right) \operatorname{Conv}_{n}\left(\boldsymbol{V}, \boldsymbol{W}_{v}\right)</script><p>Qä¸å˜ï¼Œåªå¯¹Kå’ŒVè¿›è¡Œå·ç§¯ã€‚</p>
<h5 id="QUERY-AS-KERNEL-CONVOLUTION"><a href="#QUERY-AS-KERNEL-CONVOLUTION" class="headerlink" title="QUERY AS-KERNEL CONVOLUTION"></a>QUERY AS-KERNEL CONVOLUTION</h5><script type="math/tex; mode=display">\operatorname{QUERYK}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\mathcal{S}\left(\frac{\operatorname{Conv}_{n}\left(\boldsymbol{K} \boldsymbol{W}_{k}, \boldsymbol{Q} \boldsymbol{W}_{q}\right)}{\sqrt{d_{k} * n}}\right) \operatorname{Conv}_{n}\left(\boldsymbol{V}, \boldsymbol{W}_{v}\right)</script><p>å°†Qä½œä¸ºconvolutionçš„kernelå‚æ•°è¿›è¡Œå·ç§¯ã€‚$\boldsymbol{W}_{q} \in \mathbb{R}^{n \times d_{q} \times d_{k}}, \boldsymbol{W}_{k} \in \mathbb{R}^{d_{k} \times d_{k}}, \boldsymbol{W}_{v} \in \mathbb{R}^{n \times d_{v} \times d_{v}}$</p>
<p>ä»¥ä¸Šæ˜¯åŸºæœ¬å½¢å¼ï¼Œæ‰©å±•åˆ°å¤šä¸ªheadå¯ä»¥æœ‰å¤šç§æ–¹æ³•ã€‚</p>
<h4 id="MULTI-HEADED-PHRASAL-ATTENTION"><a href="#MULTI-HEADED-PHRASAL-ATTENTION" class="headerlink" title="MULTI-HEADED PHRASAL ATTENTION"></a>MULTI-HEADED PHRASAL ATTENTION</h4><h5 id="HOMOGENEOUS-N-GRAM-ATTENTION"><a href="#HOMOGENEOUS-N-GRAM-ATTENTION" class="headerlink" title="HOMOGENEOUS N-GRAM ATTENTION"></a>HOMOGENEOUS N-GRAM ATTENTION</h5><p><img src="/images/15564587340044.jpg" width="90%" height="50%"></p>
<p>æ¯ä¸ªheadä¸“æ³¨æŸç§gramã€‚ä½†è¿™æ ·ä¼¼ä¹ä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºå¼ºè¡Œå¯¹æŸäº›headå¼•å…¥è¿™ç§ç‰¹æ€§ï¼Œæœ‰æ—¶å€™è¯ä¸è¯ä¹‹é—´æ²¡æœ‰è¿™ç§å…³ç³»ï¼Œè¿™æ ·ä¼šå¸¦æ¥å™ªå£°ã€‚</p>
<h5 id="HETEROGENEOUS-N-GRAM-ATTENTION"><a href="#HETEROGENEOUS-N-GRAM-ATTENTION" class="headerlink" title="HETEROGENEOUS N-GRAM ATTENTION"></a>HETEROGENEOUS N-GRAM ATTENTION</h5><p><img src="/images/15564587795887.jpg" width="90%" height="50%"></p>
<p>å°†æ‰€æœ‰çš„graméƒ½åŒæ—¶attendã€‚</p>
<p>ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{k, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{k, 2}\right)^{T} ; \ldots\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right) ; \ldots\right]</script><p>æˆ–ï¼š</p>
<script type="math/tex; mode=display">\mathcal{S}\left(\left[\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{k, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{k, 2}, \boldsymbol{Q} \boldsymbol{W}_{q, 2}\right)}{\sqrt{d * n_{2}}} ; \ldots\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right) ; \ldots\right]</script><h4 id="INTERLEAVED-PHRASES-TO-PHRASE-HETEROGENEOUS-ATTENTION"><a href="#INTERLEAVED-PHRASES-TO-PHRASE-HETEROGENEOUS-ATTENTION" class="headerlink" title="INTERLEAVED PHRASES TO PHRASE HETEROGENEOUS ATTENTION"></a>INTERLEAVED PHRASES TO PHRASE HETEROGENEOUS ATTENTION</h4><p>ä¸Šé¢ä»‹ç»çš„éƒ½æ˜¯sourceç«¯çš„phraseåˆ°targetçš„tokenï¼Œæœ‰æ—¶å€™éœ€è¦åè¿‡æ¥ï¼Œå› æ­¤å¯ä»¥äº¤å‰åœ°äº¤äº’ã€‚<br><img src="/images/15564588967513.jpg" width="90%" height="50%"></p>
<p>æˆ‘ä»¬å…ˆå¯¹Qè¿›è¡Œä¸¤ç§å·ç§¯ï¼Œè·å¾—unigramå’Œbigramã€‚ç„¶åä¸KVçš„unigramä¸æ¯”bigramè¿›è¡Œäº¤å‰ã€‚<br>$\boldsymbol{A}_{1, \mathrm{ConvKV}}=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q_{1}}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{k, 2}\right)^{T}\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p>
<p>$\boldsymbol{A}_{2, \text {ConvKV }}=\mathcal{S}\left(\frac{\operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{\boldsymbol{k}, 2}\right)^{T}\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p>
<p>$\boldsymbol{A}_{1, \text {QueryK }}=\mathcal{S}\left(\left[\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q_{1}, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 2}, \boldsymbol{Q} \boldsymbol{W}_{q_{1}, 2}\right)}{\sqrt{d * n_{2}}}\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p>
<p>$\boldsymbol{A}_{2, \text { QueryK }}=\mathcal{S}\left(\left[\frac{\operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 2}, \operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}, 2}\right)\right)}{\sqrt{d * n_{2}}}\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p>
<p>æ€è€ƒï¼š<br>è¿™æ ·ä¼¼ä¹å‚æ•°é‡ä¼šæš´å¢ï¼Œå…¶å®åº”è¯¥å¯¹æ¯”çš„å°±ä¸æ˜¯transformer baseäº†ï¼Œåº”è¯¥æ˜¯å‚æ•°é‡å¤§è‡´ç›¸ç­‰çš„transformerï¼Œè¿™ä¹Ÿåœ¨reviewé‡Œé¢æåˆ°è¿‡ã€‚åŒæ—¶æˆ‘è§‰å¾—è¿™ä¸ªæ–¹æ³•æ˜¯å¦æœ‰äº›å¤ªå¤æ‚ï¼Œä¸å¤Ÿç®€å•æ˜äº†ã€‚ä»¥åŠç»“æœä¼¼ä¹ä¸å¤§ä»¤äººä¿¡æœï¼Œå› ä¸ºä»–çš„baselineæ²¡æœ‰å¤ç°å‡ºtransformer baseçš„ç»“æœï¼ˆdue to the limited GPU)ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Regularizing-and-Optimizing-LSTM-Language-Models"><a href="#2ï¸âƒ£-Regularizing-and-Optimizing-LSTM-Language-Models" class="headerlink" title="2ï¸âƒ£[Regularizing and Optimizing LSTM Language Models]"></a>2ï¸âƒ£[Regularizing and Optimizing LSTM Language Models]</h2><p>æå‡ºä¸€äº›ä¼˜åŒ–æå‡LSTM-basedè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ã€‚æ­¤å³å¤§åé¼é¼çš„AWD-LSTMã€‚</p>
<h3 id="Weight-dropped-LSTM"><a href="#Weight-dropped-LSTM" class="headerlink" title="Weight-dropped LSTM"></a>Weight-dropped LSTM</h3><p>LSTMå…¬å¼å›é¡¾ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} i_{t} &=\sigma\left(W^{i} x_{t}+U^{i} h_{t-1}\right) \\ f_{t} &=\sigma\left(W^{f} x_{t}+U^{f} h_{t-1}\right) \\ o_{t} &=\sigma\left(W^{o} x_{t}+U^{o} h_{t-1}\right) \\ \tilde{c}_{t} &=\tanh \left(W^{c} x_{t}+U^{c} h_{t-1}\right) \\ c_{t} &=i_{t} \odot \tilde{c}_{t}+f_{t} \odot+\tilde{c}_{t-1} \\ h_{t} &=o_{t} \odot \tanh \left(c_{t}\right) \end{aligned}</script><p>å¯¹hidden-to-hiddençš„weightåº”ç”¨DropConnectã€‚ä¹Ÿå³å¯¹å…¶ä¸­çš„$\left[U^{i}, U^{f}, U^{o}, U^{c}\right]$è¿›è¡Œdropconnectã€‚æ³¨æ„åˆ°maskçŸ©é˜µåœ¨åŒä¸€ä¸ªbatchçš„æ¯ä¸ªæ—¶é—´æ­¥téƒ½æ˜¯ä¸€æ ·çš„ã€‚</p>
<h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>ä¹‹å‰çš„å·¥ä½œè¡¨æ˜ï¼Œåœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œä½¿ç”¨æ™®é€šçš„SGDï¼Œä¸å¸¦momentumï¼Œèƒ½è¶…è¿‡å…¶ä»–çš„ä¼˜åŒ–æ–¹æ³•ã€‚æ™®é€šSGDï¼š<br>$w_{k+1}=w_{k}-\gamma_{k} \hat{\nabla} f\left(w_{k}\right)$</p>
<p>æœ¬æ–‡æå‡ºåœ¨averaged SGD(ASGDï¼‰çš„åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ã€‚</p>
<p>ASGDå’Œä¸Šå¼ä¸€è‡´ï¼Œåªä¸è¿‡æœ€åæ›´æ–°å®Œæ˜¯å°†æœ€åå‡ æ¬¡æ›´æ–°çš„weightåšäº†å¹³å‡å¹¶è¿”å›ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\frac{1}{(K-T+1)} \sum_{i=T}^{K} w_{i}</script><p>å…¶ä¸­Kæ˜¯totalçš„å¾ªç¯æ¬¡æ•°ï¼›Tæ˜¯äººå·¥å®šä¹‰çš„é˜ˆå€¼ã€‚ä½†Tçš„é˜ˆå€¼éœ€è¦äººå·¥è°ƒï¼Œå› æ­¤è¯¥æ–¹æ³•ä¸æ˜¯å¾ˆå¥½ã€‚æœ€ç†æƒ³çš„å°±æ˜¯åœ¨SGDæ‹Ÿåˆåˆ°ä¸€ä¸ªç¨³å®šçŠ¶æ€æ—¶å†å¹³å‡ã€‚</p>
<p>å› æ­¤æå‡ºä¸€ç§æ–°çš„æ–¹æ³•ä»¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œé€šè¿‡validation lossè§¦å‘æœºåˆ¶ã€‚</p>
<p><img src="/images/15564599688438.jpg" width="50%" height="50%"></p>
<h3 id="Extended-regularization-techniques"><a href="#Extended-regularization-techniques" class="headerlink" title="Extended regularization techniques"></a>Extended regularization techniques</h3><h4 id="Variable-length-backpropagation-sequences"><a href="#Variable-length-backpropagation-sequences" class="headerlink" title="Variable length backpropagation sequences"></a>Variable length backpropagation sequences</h4><p>è‹¥æ¯æ¬¡éƒ½å›ºå®šçª—å£åˆ‡åˆ†å¥å­ï¼Œåˆ™æ€»ä¼šæœ‰ä¸€äº›è¯æ²¡æ³•æ›´æ–°è‡ªå·±ï¼Œå¦‚æœ€åä¸€ä¸ªè¯ï¼ŒåŒæ—¶é™¤äº†ç¬¬ä¸€ä¸ªè¯ï¼Œå…¶ä»–çš„è¯éƒ½åªèƒ½æ¥æ”¶åˆ°éƒ¨åˆ†bpã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ç§data inefficientã€‚</p>
<p>å¯ä»¥ä»åˆ‡åˆ†å¥å­çš„æ–¹æ³•ä¸Šè¿›è¡Œæ”¹è¿›ã€‚ä½¿ç”¨éšæœºé‡‡æ ·å¥å­é•¿åº¦çš„æ–¹å¼å»ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚ä»¥è¾ƒé«˜çš„pé€‰æ‹©seqé•¿åº¦ï¼Œ1-pé€‰æ‹©seq/2ã€‚æ¥ç€ä»¥æ­¤ä¸ºé«˜æ–¯å‡å€¼ï¼Œä»¥æ­£æ€åˆ†å¸ƒ$\mathcal{N}(\operatorname{seq}, s)$é‡‡æ ·å¥å­é•¿åº¦ã€‚</p>
<h4 id="Variational-dropout"><a href="#Variational-dropout" class="headerlink" title="Variational dropout"></a>Variational dropout</h4><p>åœ¨LSTMä¸­ï¼Œé™¤äº†hidden-to-hiddençš„ï¼Œå…¶ä»–åœ°æ–¹éƒ½é‡‡ç”¨variational dropoutã€‚</p>
<h4 id="Embedding-dropout"><a href="#Embedding-dropout" class="headerlink" title="Embedding dropout"></a>Embedding dropout</h4><p>å­—çº§åˆ«ï¼Œä¹Ÿå³å°†æ•´ä¸ªå­—çš„embeddingå»æ‰ã€‚åŒæ—¶ç”±äºæ˜¯åœ¨embedding matrixä¸Šåšçš„ï¼Œåœ¨ä¸€ä¸ªå®Œæ•´çš„forward passä¸backward passéƒ½ç”¨äº†ï¼Œå› æ­¤å°±ç›¸å½“äºä½¿ç”¨variational dropoutç”¨åœ¨one-hot embeddingä¸embedding lookupä¹‹é—´ã€‚</p>
<h4 id="Weight-tying"><a href="#Weight-tying" class="headerlink" title="Weight tying"></a>Weight tying</h4><p> embeddingä¸softmaxçš„æƒé‡ç»‘å®šã€‚</p>
<h4 id="Independent-embedding-size-and-hidden-size"><a href="#Independent-embedding-size-and-hidden-size" class="headerlink" title="Independent embedding size and hidden size"></a>Independent embedding size and hidden size</h4><p>LSTMçš„ç¬¬ä¸€å±‚ä¸æœ€åä¸€å±‚ä¸embedding sizeä¸€è‡´ï¼Œå…¶å®ƒå±‚çš„å°±æœ‰è‡ªå·±çš„hidden sizeã€‚</p>
<h4 id="Activation-Regularization-AR-and-Temporal-Activation-Regularization-TAR"><a href="#Activation-Regularization-AR-and-Temporal-Activation-Regularization-TAR" class="headerlink" title="Activation Regularization (AR) and Temporal Activation Regularization (TAR)"></a>Activation Regularization (AR) and Temporal Activation Regularization (TAR)</h4><p>ARï¼š<br>L2æ­£åˆ™åŒ–ï¼š$\alpha L_{2}\left(m \odot h_{t}\right)$<br>å…¶ä¸­mæ˜¯maskï¼Œhæ˜¯hidden state</p>
<p>TARï¼š<br>$\beta L_{2}\left(h_{t}-h_{t+1}\right)$<br>å‡å°‘ä¸¤ä¸ªhä¹‹é—´çš„å·®è·ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯23</title>
    <url>/2019/04/28/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D23/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£è¡Œé¦™å­-Â·-è¿°æ€€"><a href="#1ï¸âƒ£è¡Œé¦™å­-Â·-è¿°æ€€" class="headerlink" title="1ï¸âƒ£è¡Œé¦™å­ Â· è¿°æ€€"></a>1ï¸âƒ£è¡Œé¦™å­ Â· è¿°æ€€</h3><p>[å®‹] è‹è½¼<br><strong>æ¸…å¤œæ— å°˜ï¼Œæœˆè‰²å¦‚é“¶</strong>ã€‚é…’æ–Ÿæ—¶ã€é¡»æ»¡ååˆ†ã€‚æµ®åæµ®åˆ©ï¼Œè™šè‹¦åŠ³ç¥ã€‚<strong>å¹éš™ä¸­é©¹ï¼ŒçŸ³ä¸­ç«ï¼Œæ¢¦ä¸­èº«</strong>ã€‚<br>è™½æŠ±æ–‡ç« ï¼Œå¼€å£è°äº²ã€‚ä¸”é™¶é™¶ã€ä¹å°½å¤©çœŸã€‚å‡ æ—¶å½’å»ï¼Œä½œä¸ªé—²äººã€‚å¯¹ä¸€å¼ ç´ï¼Œä¸€å£¶é…’ï¼Œä¸€æºªäº‘ã€‚</p>
<p>éš™ä¸­é©¹ï¼šè¯­å‡ºã€Šåº„å­Â·çŸ¥åŒ—æ¸¸ã€‹ï¼šâ€œäººç”Ÿå¤©åœ°ä¹‹é—´ï¼Œè‹¥ç™½é©¹ä¹‹è¿‡éš™ï¼Œå¿½ç„¶è€Œå·²ã€‚â€œ<br>çŸ³ä¸­ç«ï¼Œæ¢¦ä¸­èº«ï¼šæ¯”å–»ç”Ÿå‘½çŸ­ä¿ƒï¼Œåƒå‡»çŸ³è¿¸å‡ºä¸€é—ªå³ç­çš„ç«èŠ±ï¼Œåƒåœ¨æ¢¦å¢ƒä¸­çŸ­æš‚çš„ç»å†ã€‚çŸ³ä¸­ç«ï¼Œè¯­å‡ºåŒ—é½åˆ˜æ˜¼ã€Šæ–°è®ºÂ·æƒœæ—¶ã€‹ï¼šâ€œäººä¹‹çŸ­ç”Ÿï¼ŒçŠ¹å¦‚çŸ³ç«ï¼Œç‚¯ç„¶è€Œè¿‡ã€‚â€æ¢¦ä¸­èº«ï¼Œè¯­å‡ºã€Šå…³å°¹å­Â·å››ç¬¦ã€‹ï¼šâ€œçŸ¥æ­¤èº«å¦‚æ¢¦ä¸­èº«ã€‚â€</p>
<p><a href="http://lib.xcz.im/work/57b2c8fa7db2a20054377ecd" target="_blank" rel="noopener">http://lib.xcz.im/work/57b2c8fa7db2a20054377ecd</a></p>
<hr>
<h3 id="2ï¸âƒ£æ—·æ€¡äº­å£å "><a href="#2ï¸âƒ£æ—·æ€¡äº­å£å " class="headerlink" title="2ï¸âƒ£æ—·æ€¡äº­å£å "></a>2ï¸âƒ£æ—·æ€¡äº­å£å </h3><p>[ç°ä»£] é©¬ä¸€æµ®<br>æµè½¬çŸ¥ä½•ä¸–ï¼Œæ±Ÿå±±å°šæ­¤äº­ã€‚<br>ç™»ä¸´çš†æ—·å£«ï¼Œä¸§ä¹±æœ‰é—ç»ã€‚<br><strong>å·²è¯†ä¹¾å¤å¤§ï¼ŒçŠ¹æ€œè‰æœ¨é’</strong>ã€‚<br>é•¿ç©ºé€é¸Ÿå°ï¼Œç•™å¹»ä¸äººçµã€‚</p>
<p><a href="http://lib.xcz.im/work/5992e274570c35006b8394b3" target="_blank" rel="noopener">http://lib.xcz.im/work/5992e274570c35006b8394b3</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†19</title>
    <url>/2019/04/22/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8619/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>expand&amp;repeat</p>
<p>expandåªèƒ½å¯¹ç»´æ•°ä¸º1çš„ç»´åº¦è¿›è¡Œæ‰©å±•ï¼Œä¸”æ‰©å±•è¿‡ç¨‹ä¸­ä¸åˆ†é…æ–°å†…å­˜ï¼›repeatèƒ½å¯¹ä»»æ„ç»´åº¦è¿›è¡Œæ‰©å±•ï¼Œä½†éœ€è¦åˆ†é…æ–°å†…å­˜ã€‚</p>
<p>å¦‚æœæ»¡è¶³expandçš„éœ€è¦ï¼Œåº”å°½é‡ä½¿ç”¨expandã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯22</title>
    <url>/2019/04/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D22/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜"><a href="#1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜" class="headerlink" title="1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜"></a>1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜</h3><p>[å”] æœç‰§<br>æ±Ÿæ¶µç§‹å½±é›åˆé£ï¼Œä¸å®¢æºå£¶ä¸Šç¿ å¾®ã€‚<br>å°˜ä¸–éš¾é€¢å¼€å£ç¬‘ï¼ŒèŠèŠ±é¡»æ’æ»¡å¤´å½’ã€‚<br>ä½†å°†é…©é…Šé…¬ä½³èŠ‚ï¼Œä¸ç”¨ç™»ä¸´æ¨è½æ™–ã€‚<br><strong>å¤å¾€ä»Šæ¥åªå¦‚æ­¤ï¼Œç‰›å±±ä½•å¿…ç‹¬æ²¾è¡£ï¼Ÿ</strong></p>
<p><a href="http://lib.xcz.im/work/57ba4972efa631005a799815" target="_blank" rel="noopener">http://lib.xcz.im/work/57ba4972efa631005a799815</a></p>
<hr>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡16</title>
    <url>/2019/04/21/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8716/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p>
<ol>
<li>MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES</li>
<li>Fine-Grained Attention Mechanism for Neural Machine Translation</li>
<li>Competence-based Curriculum Learning for Neural Machine Translation</li>
</ol>
<h2 id="1ï¸âƒ£-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES"><a href="#1ï¸âƒ£-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES" class="headerlink" title="1ï¸âƒ£[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]"></a>1ï¸âƒ£[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]</h2><p>æœ¬æ–‡æ¢ç©¶æ·±åº¦å­¦ä¹ ä¸­çš„è¿‡é‡å‚æ•°é—®é¢˜ï¼Œé€šè¿‡å®šä¹‰intrinsic dimensionï¼Œå»è¡¡é‡ç‰¹å®šæ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šæ‰€éœ€ç»´åº¦ã€‚</p>
<p>åœ¨ç»™å®šæ¨¡å‹ç»“æ„å’Œloss functionæ—¶ï¼Œæ•´ä¸ªä¼˜åŒ–ç©ºé—´ä¹Ÿéšä¹‹ç¡®å®šï¼Œè®­ç»ƒè¿‡ç¨‹ç±»ä¼¼äºåœ¨ä¸€ä¸ªç©ºé—´å†…ç§»åŠ¨ä½¿å¾—losså°½é‡å°ã€‚</p>
<p>ç»™å®šä¸€ä¸ªæœ‰Dä¸ªå‚æ•°çš„æ¨¡å‹ï¼Œé€šè¿‡é™åˆ¶è®­ç»ƒéšæœºsliceçš„å‚æ•°ï¼Œä¹Ÿå³é€‰å–ä¸€ä¸ªéšæœºæœ‰dä¸ªå‚æ•°çš„å­ç©ºé—´è®­ç»ƒï¼Œä¸æ–­å¢åŠ dï¼Œä½¿å¾—é¢„å®šä¹‰çš„solutionç¬¬ä¸€æ¬¡å‡ºç°ï¼Œåˆ™ç§°dä¸ºintrinsic dimensionï¼Œå¯ä»¥ç†è§£ä¸ºè¯¥dæ˜¯è§£å†³æŸç‰¹å®šé—®é¢˜æ‰€éœ€çš„å‚æ•°é‡ã€‚</p>
<p>å¦‚ä½•åšï¼Ÿ<br>$\theta^{(D)}=\theta_{0}^{(D)}+P \theta^{(d)}$<br>å…¶ä¸­Pæ˜¯éšæœºç”Ÿæˆçš„$D\times d$çš„æŠ•å½±çŸ©é˜µï¼Œè€Œ$\theta (d)$ æ˜¯å­ç©ºé—´çš„å‚æ•°ï¼›$P$æ˜¯å›ºå®šçš„è€Œä¸æ˜¯å¯è®­ç»ƒçš„ï¼Œä¸”$P$å¯ä»¥æ˜¯å½’ä¸€åŒ–ä¸ºå•ä½é•¿åº¦ä¸”æ­£äº¤çš„ã€‚</p>
<p><img src="/images/15559193313833.jpg" width="40%" height="50%"></p>
<p>ï¼ˆè¿™é‡Œçš„æŠ•å½±ç°åœ¨è¿˜æ˜¯ä¸èƒ½ç†è§£ï¼Ÿç­‰ä¹‹åçœ‹è¿™æ–¹é¢çš„è®ºæ–‡å†è¯´å§ï¼‰</p>
<p>å› ä¸ºä¸€äº›éšæœºæ€§ä»¥åŠå®é™…æ•ˆæœé—®é¢˜ï¼Œæ¯”å¦‚æ­£åˆ™åŒ–æ•ˆæœåœ¨å­ç©ºé—´æ— æ³•è¾¾åˆ°åœ¨å…¨ç©ºé—´çš„æ•ˆæœï¼Œå› æ­¤åœ¨è¿™é‡Œå®šä¹‰$d_{\mathrm{int} 90}$ï¼Œä¹Ÿå³è¾¾åˆ°baselineçš„90%æ‰€éœ€è¦çš„å‚æ•°é‡ã€‚</p>
<p>ä¸€äº›ç»“æœï¼š<br><img src="/images/15559195161338.jpg" width="70%" height="50%"></p>
<p>MNISTçš„æ¨¡å‹å¯ä»¥çœ‹åˆ°æ‰€éœ€å‚æ•°éå¸¸å°‘ï¼›æ¨ªå‘å¯¹æ¯”ï¼ŒCNNä¼šæ¯”å…¨è¿æ¥æ‰€éœ€çš„å°‘å¤šäº†ï¼Œè¿™ä¹Ÿç¬¦åˆæˆ‘ä»¬çš„ç›´è§‰ï¼Œä¹Ÿå³CNNæ¯”å…¨è¿æ¥æ›´é«˜æ•ˆã€‚</p>
<p><img src="/images/15559195378407.jpg" width="70%" height="50%"></p>
<p>åœ¨å…¨è¿æ¥ä¸­ï¼Œå¯¹äºæ¨¡å‹ä¸åŒçš„å®½åº¦ä»¥åŠlayeræ•°ï¼Œå‘ç°ä»–ä»¬çš„dint90ç›¸å·®ä¸å¤§ï¼Œè¯´æ˜å¯¹äºç‰¹å®šä»»åŠ¡ï¼ŒåŒä¸€ä¸ªæ¨¡å‹å®¶æ—æ‰€éœ€è¦çš„å‚æ•°é‡æ˜¯ç±»ä¼¼çš„ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation"><a href="#2ï¸âƒ£-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation" class="headerlink" title="2ï¸âƒ£[Fine-Grained Attention Mechanism for Neural Machine Translation]"></a>2ï¸âƒ£[Fine-Grained Attention Mechanism for Neural Machine Translation]</h2><p>æœ¬æ–‡æå‡ºå¯¹attentionè¿›è¡Œç»†åŒ–ï¼Œå°†åŸæ¥çš„æ¯ä¸ªè¯åˆ†é…ä¸€ä¸ªscoreæ‰©å±•ä¸ºæ¯ä¸ªè¯åˆ†é…dç»´ä¸ªscoreï¼Œå¹¶åœ¨æœºå™¨ç¿»è¯‘ä¸Šæœ‰ä¸€å®šæå‡ã€‚</p>
<p><img src="/images/15559197269175.jpg" width="80%" height="50%"></p>
<p>ç®€å•åœ°è¯´ï¼ŒåŸæ¥çš„attentionæœºåˆ¶æ˜¯ï¼š<br>$e_{t^{\prime}, t}=f_{\mathrm{Att}}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}\right)$</p>
<p>å…¶ä¸­$t^{\prime}$æ˜¯decoderç«¯çš„æ—¶é—´æ­¥ï¼Œ$t$åˆ™æ˜¯encoderç«¯çš„ç¬¬$t$ä¸ªè¯ã€‚</p>
<p>è€Œæœ¬æ–‡çš„ç»†ç²’åº¦attentionæœºåˆ¶ï¼š<br>$e_{t^{\prime}, t}^{d}=f_{\mathrm{Att} \mathrm{Y} 2 \mathrm{D}}^{d}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}, \boldsymbol{y}_{t^{\prime}-1}\right)$</p>
<p>ä¹Ÿå³åœ¨åŸæ¥çš„åŸºç¡€ä¸Šåšäº†dæ¬¡æ“ä½œï¼Œä¹Ÿå³å®é™…ä¸Šåœ¨è·å¾—æ¯ä¸€ç»´çš„åˆ†æ•°æ—¶ï¼Œæ˜¯èƒ½çœ‹åˆ°å…¶ä»–ç»´çš„ä¿¡æ¯çš„ã€‚ï¼ˆå¦‚æœæ˜¯æˆ‘è‡ªå·±åšï¼Œæˆ‘å¯èƒ½ä¼šå°†ä»–ä»¬éš”ç»å¼€æ¥ã€‚ï¼‰</p>
<p>æ€è€ƒï¼š<br>å°†RNNä½œä¸ºbaselineï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨transformerï¼Ÿå½“æ—¶transformerå·²ç»å‡ºäº†ï¼Œå¯èƒ½æ˜¯transformerä¸Šæ²¡æ•ˆæœï¼Ÿå› ä¸ºtransformerè‡ªå¸¦å¤šheadï¼Œå¯èƒ½è¡¨ç¤ºèƒ½åŠ›å°±å·²ç»è¶³å¤Ÿäº†ã€‚</p>
<hr>
<h2 id="3ï¸âƒ£-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#3ï¸âƒ£-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="3ï¸âƒ£[Competence-based Curriculum Learning for Neural Machine Translation]"></a>3ï¸âƒ£[Competence-based Curriculum Learning for Neural Machine Translation]</h2><h3 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h3><p>æå‡ºä¸€ç§æ–°çš„<strong>è®­ç»ƒ</strong>ç¿»è¯‘æ¨¡å‹çš„ç®—æ³•ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯è®©æ¨¡å‹ä»ç®€å•çš„æ ·ä¾‹å¼€å§‹å­¦èµ·ï¼Œéšç€è®­ç»ƒè¿‡ç¨‹çš„è¿›è¡Œé€æ¸å¢åŠ éš¾åº¦è¾ƒå¤§çš„æ ·ä¾‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¢å¼ºæ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œä¸”åœ¨æ•ˆæœä¸Šä¹Ÿæœ‰æå‡ï¼ŒåŒæ—¶è¿˜èƒ½å‡å°‘æ”¶æ•›æ‰€éœ€çš„è®­ç»ƒæ—¶é—´ã€‚</p>
<p><img src="/images/15559206435828.jpg" width="50%" height="50%"></p>
<p>è®ºæ–‡çš„Motivationï¼šå¦‚æœè®­ç»ƒæ•°æ®ä»¥ç‰¹å®šçš„é¡ºåºè¾“å…¥ï¼Œä¹Ÿå³ä»ç®€å•çš„æ•°æ®å¼€å§‹å­¦ï¼Œç­‰åˆ°æ¨¡å‹æœ‰ä¸€å®šçš„èƒ½åŠ›åå†å»å­¦éš¾çš„æ•°æ®ï¼Œè¿™æ ·ä¹Ÿæ›´ç¬¦åˆäººç±»çš„ç›´è§‰ï¼›åŒæ—¶ï¼Œä»æœºå™¨å­¦ä¹ çš„è§’åº¦å»çœ‹ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥é¿å…è¿‡æ—©é™·å…¥ä¸å¥½çš„å±€éƒ¨æœ€ä¼˜è§£ã€‚</p>
<p>è®ºæ–‡è¿˜æåˆ°äº†å¯¹äºç¿»è¯‘è€Œè¨€ï¼Œæ¨¡å‹å¾ˆéš¾è®­ç»ƒï¼Œéœ€è¦å¤æ‚çš„è°ƒå‚ï¼Œè´¹æ—¶è´¹åŠ›ã€‚ç‰¹åˆ«æ˜¯å¯¹äºTransformerè€Œè¨€ï¼Œéœ€è¦ç²¾ç»†çš„learning rate scheduleã€‚</p>
<p>æœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼Œåªæœ‰ä¸€ä¸ªå‚æ•°ï¼Œå› æ­¤ä¸éœ€è¦ç²¾ç»†çš„è°ƒå‚ï¼ŒåŒæ—¶å› ä¸ºåªæ”¹å˜è¾“å…¥çš„pipelineï¼Œå› æ­¤å¾ˆæ–¹ä¾¿åœ°ä½¿ç”¨åˆ°å·²æœ‰çš„æ¨¡å‹ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å¼•å…¥ä¸¤ä¸ªæ¦‚å¿µï¼š<br><strong>Difficulty</strong>ï¼šä»£è¡¨ä¸€ä¸ªè®­ç»ƒæ ·ä¾‹çš„éš¾åº¦ï¼Œå¯èƒ½å’Œæ¨¡å‹å½“å‰çš„çŠ¶æ€ç›¸å…³ã€‚æ¯”å¦‚å¥å­é•¿åº¦å°±æ˜¯è¡¡é‡æ ·ä¾‹éš¾åº¦çš„ä¸€ä¸ªæŒ‡æ ‡ã€‚</p>
<p><strong>Competence</strong>ï¼šèŒƒå›´0-1çš„æ•°å€¼ï¼Œä»£è¡¨æ¨¡å‹è®­ç»ƒçš„è¿›åº¦ï¼Œå®šä¹‰ä¸ºæ¨¡å‹çŠ¶æ€çš„ä¸€ä¸ªå‡½æ•°ã€‚æ›´è¿›ä¸€æ­¥ï¼Œå®šä¹‰$c(t)$ä¸ºæ¨¡å‹åœ¨æ—¶é—´æ­¥tæ‰€å…è®¸ä½¿ç”¨çš„è®­ç»ƒæ ·ä¾‹çš„æ¯”ä¾‹ã€‚ä¹Ÿå³è®­ç»ƒæ ·ä¾‹æ ¹æ®difficultyæ’åˆ—ï¼Œåœ¨æ—¶é—´æ­¥$t$åªå…è®¸top $c(t)$çš„æ•°æ®ä½¿ç”¨ã€‚</p>
<p>æ ¹æ®ä¸Šè¿°ä¸¤ä¸ªå®šä¹‰ï¼Œå¼•å…¥ç®—æ³•ï¼š<br><img src="/images/15559212081520.jpg" width="50%" height="50%"></p>
<p><img src="/images/15559212315953.jpg" width="100%" height="50%"></p>
<p><img src="/images/15559212598339.jpg" width="50%" height="50%"></p>
<p>é‚£ä¹ˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œå¦‚ä½•è¡¡é‡difficultyä»¥åŠcompetenceï¼Ÿ</p>
<h4 id="Difficulty-Metrics"><a href="#Difficulty-Metrics" class="headerlink" title="Difficulty Metrics"></a>Difficulty Metrics</h4><p>â‘ å¥å­é•¿åº¦<br>é•¿å¥å­æ›´éš¾ç¿»è¯‘ï¼Œå› ä¸ºé•¿å¥å­å¾€å¾€åŒ…å«äº†çŸ­å¥å­ï¼ŒåŒæ—¶åœ¨ç”Ÿæˆç›®æ ‡è¯­è¨€æ—¶ï¼Œå®¹æ˜“å‡ºç°é”™è¯¯ä¼ æ’­ã€‚</p>
<script type="math/tex; mode=display">d_{\text { length }}\left(s_{i}\right) \triangleq N_{i}</script><p>â‘¡Word Rarity<br>è‹¥ä¸€ä¸ªå¥å­å­˜åœ¨ç½•è§è¯ï¼Œæ›´éš¾ç¿»è¯‘è¯¥å¥å­ï¼Œå› ä¸ºæ¨¡å‹éœ€è¦å¤šæ¬¡çœ‹è§è¯¥è¯æ‰èƒ½å­¦åˆ°é²æ£’çš„è¡¨ç¤ºï¼›åŒæ—¶ç½•è§è¯çš„æ¢¯åº¦å®¹æ˜“æœ‰è¾ƒå¤§çš„æ–¹å·®ã€‚</p>
<p>å› æ­¤æˆ‘ä»¬å®šä¹‰ç›¸å¯¹è¯é¢‘ï¼š</p>
<script type="math/tex; mode=display">\hat{p}\left(w_{j}\right) \triangleq \frac{1}{N_{\text {total }}} \sum_{i=1}^{M} \sum_{k=1}^{N_{i}} \mathbb{1}_{w_{k}^{i}=w_{j}}</script><p>å…¶ä¸­ï¼Œ$j=1, \ldots, \{\text {unique words in corpus}\}$ï¼Œ$\mathbb{1}$ ä¸ºæŒ‡ç¤ºå‡½æ•°ã€‚</p>
<p>å› æ­¤æœ€ç»ˆåº¦é‡æ–¹æ³•ä¸ºï¼š<br>$d_{\text {rarity}}\left(s_{i}\right) \triangleq-\sum_{k=1}^{N_{i}} \log \hat{p}\left(w_{k}^{i}\right)$</p>
<p>è¿™æ ·å³è€ƒè™‘åˆ°äº†é•¿åº¦ä¹Ÿè€ƒè™‘åˆ°äº†è¯é¢‘ï¼ŒåŒæ—¶è¯¥æ–¹æ³•æœ‰ç‚¹ç±»ä¼¼language modelï¼Œå¯ä»¥ç†è§£ä¸ºlanguage modelçš„è¿‘ä¼¼ã€‚</p>
<h4 id="Competence-Functions"><a href="#Competence-Functions" class="headerlink" title="Competence Functions"></a>Competence Functions</h4><p>æˆ‘ä»¬å®šä¹‰competence functionåªä¸æ—¶é—´æ­¥$t$æœ‰å…³ï¼Œå› æ­¤åªéœ€è¦è€ƒè™‘å…·ä½“çš„å½¢å¼ã€‚<br>â‘ linearï¼š</p>
<script type="math/tex; mode=display">c(t) \triangleq \min \left(1, t r+c_{0}\right)</script><p>$c_{0}$æ˜¯åˆå§‹å€¼ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰Tä¸ºæ—¶é—´æ­¥é˜ˆå€¼ï¼Œå½“è¶…è¿‡è¯¥é˜ˆå€¼ï¼Œæˆ‘ä»¬è®¤ä¸ºæ¨¡å‹å·²ç»å®Œå…¨æœ‰èƒ½åŠ›äº†ï¼Œåˆ™ä¸Šå¼è¿˜å¯ä»¥å†™æˆï¼š</p>
<script type="math/tex; mode=display">c_{\text { linear }}(t) \triangleq \min \left(1, t \frac{1-c_{0}}{T}+c_{0}\right)</script><p>â‘¡Rootï¼š<br>çº¿æ€§çš„ä¸€ä¸ªä¸å¥½çš„åœ°æ–¹ï¼Œå½“æ ·ä¾‹å¢åŠ æ—¶ï¼Œæ¯ä¸ªæ ·ä¾‹è¢«sampleçš„å‡ ç‡å‡å°ï¼Œå› æ­¤æ–°åŠ è¿›å»çš„æ ·ä¾‹è¢«sampleåˆ°çš„å‡ ç‡ä¹Ÿå‡å°ï¼Œå› æ­¤åº”æ¯æ¬¡å‡å°‘æ–°åŠ å…¥çš„æ ·ä¾‹ï¼Œä½¿å¾—æ¨¡å‹æœ‰è¶³å¤Ÿçš„æ—¶é—´å»å­¦ä¹ çŸ¥è¯†ã€‚<br>ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\frac{d c(t)}{d t}=\frac{P}{c(t)}</script><p>ç§¯åˆ†åå¯å¾—ï¼š</p>
<script type="math/tex; mode=display">c_{\mathrm{sqrt}}(t) \triangleq \min \left(1, \sqrt{t \frac{1-c_{0}^{2}}{T}+c_{0}^{2}}\right)</script><p>å½“ç„¶è¿˜å¯ä»¥å°†å¼€næ¬¡æ–¹æ ¹</p>
<script type="math/tex; mode=display">c_{\mathrm{root}-p}(t) \triangleq \min \left(1, \sqrt[p]{t \frac{1-c_{0}^{p}}{T}+c_{0}^{p}}\right)</script><p>ä½¿å¾—æ›²çº¿æ›´ä¸ºé™¡å³­ï¼Œä¹Ÿå³ç»™æ¯ä¸ªæ ·ä¾‹çš„æ—¶é—´æ›´å¤šã€‚</p>
<p>æ›²çº¿å¯¹æ¯”ï¼š<br><img src="/images/15559218944874.jpg" width="50%" height="50%"></p>
<p>å®éªŒè¯æ˜æ˜¯p=2æ—¶æœ€å¥½ã€‚</p>
<h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p><img src="/images/15559219317633.jpg" width="70%" height="50%"></p>
<p>å®éªŒæœ‰ç›¸å½“ä¸é”™çš„ç»“æœï¼Œåœ¨RNNä»¥åŠåœ¨Transformerä¸Šéƒ½æœ‰æå‡ï¼Œå¹¶ä¸”æ˜¯åœ¨ä¸ç”¨learning rate scheduleçš„æƒ…å†µä¸‹ï¼Œå¹¶ä¸”æ—¶é—´æ›´çŸ­ã€‚</p>
<p>å‡ ä¸ªå®éªŒç°è±¡ï¼š<br>â‘ RNNçš„æå‡è¾ƒå°‘ï¼Œè€ŒTransformerå¾ˆå¤šï¼Œè¯´æ˜RNNæ¯”Transformeræ›´é²æ£’ã€‚RNNæ¯”Transformerè®­ç»ƒæ›´ä¸ºç¨³å®šã€‚<br>â‘¡å¯¹äºTransformerè€Œè¨€ï¼Œè‹¥åŒæ ·ä½¿ç”¨learning rate scheduleï¼Œä»ç„¶æœ‰å¸®åŠ©ï¼Œè¯´æ˜è¯¥æ–¹æ³•æ˜¯è¾ƒä¸ºé€šç”¨çš„ã€‚<br>â‘¢ä¸ä½¿ç”¨lr scheduleè€Œåªä½¿ç”¨æœ¬æ–‡æ–¹æ³•ï¼Œä¹Ÿèƒ½è¾¾åˆ°ä¸ä½¿ç”¨æœ¬æ–‡æ–¹æ³•è€Œä½¿ç”¨lr scheduleçš„ç»“æœï¼Œä½†éœ€è¦æ›´å¤šçš„stepã€‚</p>
<h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>ä¸ºä»€ä¹ˆè¯¥æ–¹æ³•èƒ½workï¼Ÿ<br>ç¬¦åˆç›´è§‰ï¼Œæ¨¡å‹ä»ç®€å•åˆ°éš¾ï¼Œæ›´å¥½è®­ã€‚åŒæ—¶ä»æœºå™¨å­¦ä¹ è§’åº¦ï¼Œå¦‚æœå®Œå…¨æ­£å¸¸çš„sampleï¼Œåˆ™å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°æˆ–è€…saddle pointï¼Œå› æ­¤éœ€è¦æ›´é•¿æ—¶é—´æˆ–è€…ä¸å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</p>
<p>åŒæ—¶è®ºæ–‡è¿˜æåˆ°äº†ï¼Œä¸ºä»€ä¹ˆTransformeråœ¨å¢åŠ batchèƒ½å¤Ÿæœ‰æ›´å¥½çš„æ”¶æ•›ï¼Œè¿™æ˜¯å› ä¸ºä¸€å¼€å§‹è®­ç»ƒçš„noisy gradientå¤ªå¤§ï¼Œè‹¥å¢åŠ batchèƒ½å¤Ÿä¿¡å™ªæ¯”ï¼Œè€Œæœ¬æ–‡æ–¹æ³•åœ¨æŸç§ç¨‹åº¦ä¸Šä¹Ÿè§£å†³äº†è¯¥é—®é¢˜ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Curriculum Learning</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>intrinsic dimension</tag>
        <tag>attention mechanism</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformerç›¸å…³è¿‘æœŸç›˜ç‚¹</title>
    <url>/2019/04/12/%E8%AE%BA%E6%96%87/Transformer%E7%9B%B8%E5%85%B3%E8%BF%91%E6%9C%9F%E7%9B%98%E7%82%B9/</url>
    <content><![CDATA[<p>è¿‘å¹´æ¥è‡ªç„¶è¯­è¨€å¤„ç†æœ‰ç›¸å½“å¤§çš„è¿›å±•ï¼Œå›¿äºä¸ªäººæµ…è–„çš„èƒ½åŠ›ï¼Œå› æ­¤ä»…è°ˆè°ˆè‡ªå·±è¾ƒä¸ºäº†è§£çš„ä¸Transformerç›¸å…³ä¸€è·¯ä¸‹æ¥çš„ä¸€äº›å·¥ä½œã€‚è¿™ç¯‡çš„ä¸»è¦ç›®çš„æ˜¯å®Œæˆé‚±åšç»™æˆ‘çš„ä»»åŠ¡ï¼Œä¹Ÿé¡ºä¾¿æ¢³ç†ä¸€ä¸‹æ€ç»ªã€‚</p>
<hr>
<p>è‡ª2017å¹´çš„é—®ä¸–ï¼ŒTransformerå°±å¸å¼•äº†å¤§æ‰¹å­¦è€…çš„æ³¨æ„ï¼Œ2018å¹´Bertçš„å‡ºç°ï¼Œæ›´æ˜¯å°†Transformeræ¨ä¸Šäº†NLPèˆå°çš„ä¸­å¤®ã€‚Transformerä»¥å…¶é«˜æ•ˆç‡ï¼ˆé«˜å¹¶è¡Œæ€§ï¼‰ä»¥åŠæå¼ºçš„æ¨¡å‹èƒ½åŠ›ï¼Œä¿¨ç„¶æœ‰æ›¿ä»£ä¼ ç»ŸRNN/CNNçš„æ€åŠ¿ã€‚å› æ­¤æœ¬æ¬¡å°±è®¨è®ºè®¨è®ºTransformeråŠå…¶ç³»åˆ—ï¼ŒåŒæ—¶æœ€ååŠ ä¸Šæˆ‘ä¸ªäººå…³äºRNN/CNN/Transformerçš„ä¸€ç‚¹æ€è€ƒã€‚</p>
<p>è¦ç‚¹ï¼š</p>
<ol>
<li>TransformeråŠå…¶å˜ä½“</li>
<li>Transformeråœ¨å…¶ä»–ä»»åŠ¡</li>
<li>é¢„è®­ç»ƒæ¨¡å‹</li>
<li>Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ</li>
</ol>
<h2 id="TransformeråŠå…¶å˜ä½“"><a href="#TransformeråŠå…¶å˜ä½“" class="headerlink" title="TransformeråŠå…¶å˜ä½“"></a>TransformeråŠå…¶å˜ä½“</h2><h3 id="Transformerç®€å•å›é¡¾"><a href="#Transformerç®€å•å›é¡¾" class="headerlink" title="Transformerç®€å•å›é¡¾"></a>Transformerç®€å•å›é¡¾</h3><p>Transformer[1]é‡‡ç”¨å®Œå…¨çš„attentionæœºåˆ¶ç”¨ä»¥åºåˆ—å»ºæ¨¡ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œè¿™æ˜¯é€šè¿‡attentionæœºåˆ¶æ¥å®ç°çš„ã€‚</p>
<h4 id="Transformeræ¨¡å‹æ¶æ„"><a href="#Transformeræ¨¡å‹æ¶æ„" class="headerlink" title="Transformeræ¨¡å‹æ¶æ„"></a>Transformeræ¨¡å‹æ¶æ„</h4><p>Transformeræ¶æ„ï¼š<br><img src="/images/15550349717464.jpg" width="50%" height="50%"></p>
<p>ç”±äºTransformeræœ€æ—©ç”±äºç¿»è¯‘æ¨¡å‹ä¸­ï¼Œå› æ­¤æ¶æ„æ˜¯ç”±ä¸€ä¸ªencoderå’Œä¸€ä¸ªdecoderç»„æˆï¼Œè€Œencoderå’Œdecoderéƒ½æ˜¯ç”±å¤šä¸ªåŸºæœ¬çš„blockå †å è€Œæˆã€‚ä¸€ä¸ªblockç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¹Ÿå³multi-head attentionå±‚å’ŒPosition-wise Feed-Forward Networkså±‚ã€‚</p>
<h5 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h5><p>å¯¹äºåºåˆ—ä¸­ä¸€ä¸ªç‰¹å®šèŠ‚ç‚¹$x_i$ï¼Œ$x_i$ä½œä¸ºqueryï¼Œå…¶ä»–èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰ä½œä¸ºkeyå’Œvalueï¼Œé€šè¿‡å‘é‡ç‚¹ç§¯è®¡ç®—å‡ºattentionåˆ†æ•°ï¼Œè¿›è¡Œå½’ä¸€åŒ–åï¼ˆsoftmaxï¼‰å°†valueåŠ æƒå¹³å‡è·å¾—è¯¥èŠ‚ç‚¹$x_i$æ–°çš„è¡¨ç¤ºã€‚<br>åŒæ—¶ï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œä¸ºäº†å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œå¯ä»¥å°†å…¶æ˜ å°„åˆ°å¤šä¸ªä¸åŒéšç©ºé—´ä¸­ï¼Œåˆ†åˆ«å®Œæˆä¸Šè¿°åŸºæœ¬æ“ä½œã€‚</p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br><img src="/images/15550350386364.jpg" width="70%" height="50%"></p>
<p>å·¦å›¾ä¸ºåŸºæœ¬æ“ä½œä¹Ÿå³scale-dot productï¼Œå³å›¾ä¸ºå¤šä¸ªscale-dot productåœ¨ä¸åŒéšç©ºé—´åŒæ—¶è¿›è¡Œï¼Œå¹¶ä¸”å°†å¤šä¸ªheadçš„ç»“æœæ‹¼æ¥èµ·æ¥ä½œä¸ºæœ€ç»ˆç»“æœã€‚</p>
<h5 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h5><p>ä¸ºäº†å¢å¼ºæ¨¡å‹è¡¨ç¤ºèƒ½åŠ›ï¼Œåœ¨Multi-head attentionä¹‹åï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½è¿‡ä¸¤å±‚MLPä»¥è·å¾—æ–°çš„å‘é‡è¡¨ç¤ºã€‚<br>ä¹Ÿå³:</p>
<script type="math/tex; mode=display">\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}</script><p>ç›¸æ¯”ä¼ ç»Ÿçš„RNN/CNNè€Œè¨€ï¼Œå…¶æœ€å¤§çš„ä¼˜åŠ¿æ˜¯å…¨å±€çš„æ„Ÿå—é‡ï¼ˆGlobal Receptive Fieldï¼‰ä»¥åŠé«˜åº¦å¹¶è¡Œæ€§ï¼ˆparallelizationï¼‰ã€‚</p>
<h3 id="å˜ä½“"><a href="#å˜ä½“" class="headerlink" title="å˜ä½“"></a>å˜ä½“</h3><h4 id="Universal-Transformers"><a href="#Universal-Transformers" class="headerlink" title="Universal Transformers"></a>Universal Transformers</h4><p>æå‡ºä¸€ç§æ–°å‹é€šç”¨çš„Transformerï¼Œåœ¨Transformerçš„åŸºç¡€ä¸Šå¼•å…¥RNNçš„å½’çº³åç½®(inductive bias)ï¼Œä¹Ÿå³è¿­ä»£å­¦ä¹ (learning iterative)çš„ç‰¹å¾ã€‚Universal Transformer[2]çš„ä¸»è¦ç‰¹ç‚¹æœ‰ï¼š</p>
<ol>
<li>åœ¨Transformerä¸­æ¯å±‚çš„æƒé‡æ˜¯ç‹¬ç«‹çš„ï¼Œè€Œåœ¨Universal Transformerä¸­ï¼Œæ¯å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³multi-head Attentionä¸Feed-Forwardåœ¨æ¯å±‚çš„æƒé‡æ˜¯ä¸€è‡´çš„ã€‚</li>
<li>åœ¨Transformerä¸­å¼•å…¥è‡ªé€‚åº”è®¡ç®—æ—¶é—´(Adaptive Computation Time, ACT[3])ï¼Œä¹Ÿå³å¯¹äºä¸åŒçš„è¯å…è®¸è¿­ä»£ä¸åŒæ¬¡æ•°ã€‚è¿™æ˜¯åŸºäºæœ‰äº›è¯ç›¸æ¯”å…¶ä»–è¯è¯æ„æ›´ä¸°å¯Œï¼Œæ›´éš¾è¢«æ¨¡å‹å­¦ä¼šï¼Œå› æ­¤éœ€è¦æ›´å¤šçš„è¿­ä»£æ¬¡æ•°ã€‚ä¸å›ºå®šå±‚æ•°çš„Transformerç›¸æ¯”æœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li>
</ol>
<p>å› æ­¤å…¶æ€»ä½“ç»“æ„ä¸ºï¼š<br><img src="/images/15556585300051.jpg" width="70%" height="50%"></p>
<p>åœ¨è¿™é‡Œæœ‰ä¸¤ä¸ªç»†èŠ‚ï¼š</p>
<ol>
<li>åŠ äº†Timestep embeddingå»æŒ‡ç¤ºå½“å‰è¿­ä»£çš„æ¬¡æ•°</li>
<li>å°†Feedforward Functionç”¨æ›´ä¸ºé€šç”¨çš„Transition Functionï¼Œå¯ä»¥æ˜¯æ™®é€šçš„å…¨è¿æ¥ï¼Œä¹Ÿå¯ä»¥æ˜¯å‚æ•°æ›´å°‘çš„Depth-wise Convolutionã€‚</li>
</ol>
<h4 id="Star-Transformer"><a href="#Star-Transformer" class="headerlink" title="Star Transformer"></a>Star Transformer</h4><p>Star Transformer[20]æ˜¯ä¸€ç§è½»é‡çº§çš„Transformerï¼Œé€šè¿‡å°†å…¨è¿æ¥çš„ç»“æ„æ›¿æ¢ä¸ºæ˜Ÿå‹æ‹“æ‰‘ç»“æ„ï¼Œæ˜¾è‘—å‡å°Transformerçš„å¤æ‚åº¦ï¼Œä»$O(n^2)$å‡ä¸º$O(n)$ã€‚</p>
<p><img src="/images/15556834830687.jpg" width="50%" height="50%"></p>
<p>å…¶ä¸»è¦æ€æƒ³æ˜¯â€™Gather-Distributeâ€™ï¼Œä¹Ÿå³æ¯ä¸ªèŠ‚ç‚¹ä¸ç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œæ˜¯ä¸å…¨å±€èŠ‚ç‚¹è¿›è¡Œäº¤äº’ã€‚<br><img src="/images/15556836008776.jpg" width="50%" height="50%"></p>
<p>å®éªŒè¡¨æ˜ï¼ŒStar Transformerä¸ä»…åœ¨å¤šä¸ªæ•°æ®é›†è¡¨ç°æ›´ä¼˜ï¼Œä¸”é€Ÿåº¦æ›´å¿«ã€‚</p>
<p><img src="/images/15557700601922.jpg" width="90%" height="50%"></p>
<p><img src="/images/15557701172639.jpg" width="90%" height="50%"></p>
<h4 id="å…¶ä»–å°æ”¹è¿›"><a href="#å…¶ä»–å°æ”¹è¿›" class="headerlink" title="å…¶ä»–å°æ”¹è¿›"></a>å…¶ä»–å°æ”¹è¿›</h4><p>æ¥ä¸‹æ¥ä»‹ç»åŸºäºTransformerçš„å‡ ä¸ªå°æ”¹è¿›å·¥ä½œã€‚</p>
<p>åœ¨Convolutional Self-Attention Network[5]ä¸­ï¼Œé€šè¿‡åœ¨self-attentionå±‚å¼•å…¥CNNçš„å½’çº³åç½®ï¼Œåœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šæœ‰ä¸€å®šçš„æå‡ã€‚å…·ä½“åšæ³•ï¼š<br><img src="/images/15556604248879.jpg" width="80%" height="50%"><br>æ™®é€šself-attentionå±‚ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œåœ¨1D-Convolutionalçš„self-attentionå±‚ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹åªèƒ½ä¸ä»¥è¯¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„çª—å£å†…çš„èŠ‚ç‚¹äº¤äº’ã€‚è€Œåœ¨2D-Convolutionä¸­ï¼Œå¯¹headè¿™ä¸€ç»´è¿›è¡Œæ‰©å±•ï¼Œä¹Ÿå³å¯¹äºä»»æ„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸ä»…èƒ½å’Œå‘¨å›´çš„èŠ‚ç‚¹äº¤äº’ï¼Œè¿˜å¯ä»¥ä¸å…¶ä»–headçš„èŠ‚ç‚¹äº¤äº’ã€‚<br>å®éªŒç»“æœï¼š<br><img src="/images/15556607769307.jpg" width="80%" height="50%"></p>
<p>åœ¨Multi-Head Attention with Disagreement Regularization[6]ä¸­ï¼Œæ˜¾å¼å¯¹multi-head attentionæ·»åŠ æ­£åˆ™åŒ–ï¼Œä½¿å¾—ä¸åŒheadå°½é‡åŒºåˆ†å¼€æ¥ï¼Œä»¥ä½¿å¾—ä¸åŒheadæ•è·åˆ°ä¸åŒçš„ç‰¹å¾ã€‚è®ºæ–‡æå‡ºäº†ä¸‰ç§ä¸åŒä½ç½®çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼š<br>â‘ å¯¹Valueï¼š</p>
<script type="math/tex; mode=display">D_{\text {subpace}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H} \frac{V^{i} \cdot V^{j}}{\left\|V^{i}\right\|\left\|V^{j}\right\|}</script><p>ä¹Ÿå³å¯¹ä¸åŒheadä¹‹é—´çš„valueï¼Œè®¡ç®—ä»–ä»¬ä¹‹é—´çš„coså€¼ï¼Œä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¹‹ä¸€ã€‚</p>
<p>â‘¡å¯¹Attentionæƒé‡ï¼š</p>
<script type="math/tex; mode=display">D_{\text {position}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H}\left|A^{i} \odot A^{j}\right|</script><p>ä¹Ÿå³å°†æ¯ä¸ªheadæ‰€è®¡ç®—å¾—åˆ°çš„attentionçŸ©é˜µï¼Œè®¡ç®—ä»–ä»¬ä¹‹é—´çš„element-wiseä¹˜æ³•ï¼Œä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¹‹ä¸€ã€‚</p>
<p>â‘¢å¯¹è¾“å‡ºï¼š</p>
<script type="math/tex; mode=display">D_{\text {output}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H} \frac{O^{i} \cdot O^{j}}{\left\|O^{i}\right\|\left\|O^{j}\right\|}</script><p>ä¹Ÿå³å¯¹æ¯ä¸ªheadçš„è¾“å‡ºé€šè¿‡coså€¼è¿›è¡Œæ­£åˆ™åŒ–ã€‚</p>
<p>Modeling Localness for Self-Attention Networks[7]åˆ™æ˜¯é€šè¿‡åŠ å¼ºå¯¹å±€éƒ¨ä¿¡æ¯çš„å…³æ³¨ï¼Œåœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šæå‡è¡¨ç°ã€‚å…¶ä¸»è¦çš„åŠ¨æœºæ˜¯ï¼šâ‘ åœ¨Transformerä¸­æ¯ä¸ªè¯éƒ½ç›´æ¥ä¸æ‰€æœ‰è¯äº¤äº’ï¼Œå¯¹æ‰€æœ‰è¯è¿›è¡Œçº¿æ€§åŠ æƒå¯¼è‡´å¯¹é‚»è¿‘è¯çš„å…³æ³¨ä¸å¤Ÿï¼ˆå› ä¸ºæƒé‡çš„åˆ†æ•£ï¼‰ï¼›â‘¡ä»ç›´æ¥ä¸Šçœ‹ï¼Œå½“è¯$i$ä¸è¯$j$æœ‰å¯¹é½å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸è¯$j$å‘¨å›´çš„è¯ä¹Ÿå¯¹é½ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•è·æ•´ä¸ªè¯­ä¹‰å•å…ƒçš„ä¿¡æ¯ã€‚å…¶å…·ä½“åšæ³•æ˜¯åœ¨softmaxå‡½æ•°å†…å¢åŠ ä¸€ä¸ªé«˜æ–¯åç½®ï¼ˆGaussian biasï¼‰å»ä¿®æ­£attentionæƒé‡åˆ†å¸ƒï¼š</p>
<script type="math/tex; mode=display">\operatorname{ATT}(Q, K)=\operatorname{softmax}(\text {energy}+G)</script><p>$G_{ij}$æ˜¯è¡¡é‡è¯jä¸è¯iæ‰€é¢„æµ‹çš„ä¸­å¿ƒè¯ä¹‹é—´çš„è”ç³»ç´§å¯†ç¨‹åº¦ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p>
<script type="math/tex; mode=display">G_{i, j}=-\frac{\left(j-P_{i}\right)^{2}}{2 \sigma_{i}^{2}}</script><p>å…¶ä¸­$\sigma_{i}=\frac{D_{i}}{2}$ï¼Œ$D_{i}$æ˜¯çª—å£å¤§å°ã€‚è€Œ$P_{i}$æ˜¯é€šè¿‡è®¡ç®—å¾—å‡ºçš„ï¼Œ$P_{i}$ä¸å¯¹åº”çš„queryæœ‰å…³ï¼Œå› æ­¤å¯ä»¥é€šè¿‡$p_{i}=U_{p}^{T} \tanh \left(W_{p} Q_{i}\right)$è®¡ç®—å¾—åˆ°ï¼›è€Œçª—å£å¤§å°$D_{i}$å¯ä»¥æœ‰å¤šç§é€‰æ‹©ï¼Œâ‘ å›ºå®šçª—å£å¤§å°ï¼›â‘¡æ¯å±‚ç‰¹å®šçš„å¤§å°ï¼Œä¹Ÿå³å°†è¯¥å±‚çš„keyå¹³å‡èµ·æ¥ï¼Œé€šè¿‡$z=U_{d}^{T} \tanh \left(W_{d} \overline{\mathbf{K}}\right)$è®¡ç®—ï¼›â‘¢æ¯ä¸ªqueryéƒ½æœ‰è‡ªå·±çš„çª—å£å¤§å°ï¼š$z_{i}=U_{d}^{T} \tanh \left(W_{p} Q_{i}\right)$ã€‚</p>
<p>Self-attention with relative position representations[8]åˆ™æ˜¯å°†Transformerä¸­çš„ç»å¯¹ä½ç½®embeddingæ”¹ä¸ºç›¸å¯¹ä½ç½®embeddingä»¥æå‡ç¿»è¯‘æ•ˆæœã€‚</p>
<h2 id="Transformeråœ¨å…¶ä»–ä»»åŠ¡"><a href="#Transformeråœ¨å…¶ä»–ä»»åŠ¡" class="headerlink" title="Transformeråœ¨å…¶ä»–ä»»åŠ¡"></a>Transformeråœ¨å…¶ä»–ä»»åŠ¡</h2><h3 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer XL"></a>Transformer XL</h3><p>æœ¬æ–‡æ¢ç´¢å°†Transformerç”¨äºè¯­è¨€æ¨¡å‹(language model)ï¼Œå¹¶åœ¨Transformerå¼•å…¥RNNçš„å½’çº³åç½®ï¼Œä¹Ÿå³RNNçš„å†å²ä¿¡æ¯ï¼Œä½¿å¾—Transformerèƒ½å¤Ÿå¤„ç†é•¿å¥å­ã€‚</p>
<p>ç”±äºTransformerçš„å¤æ‚åº¦æ˜¯$O(n^2)$ï¼Œè™½ç„¶åœ¨GPUä¸Šèƒ½å¤Ÿå¹¶è¡Œæ“ä½œï¼Œä½†å ç”¨æ˜¾å­˜è¾ƒå¤§ï¼Œå› æ­¤åœ¨å®ç°æ—¶ï¼Œé€šå¸¸æ˜¯å°†å¥å­åˆ‡åˆ†ä¸ºä¸€ä¸ªä¸€ä¸ªsegmentï¼Œsegmentä¹‹é—´æ²¡æœ‰è”ç³»ï¼š</p>
<p><img src="/images/15556764280028.jpg" width="30%" height="50%"></p>
<p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œåˆ™æ¯ç”Ÿæˆä¸€ä¸ªè¯æ—¶æ»‘åŠ¨ä¸€ä¸ªçª—å£ï¼š</p>
<p><img src="/images/15556765079362.jpg" width="60%" height="50%"></p>
<p>è¿™æ ·çš„æ–¹æ³•æ˜¾ç„¶æ•ˆç‡å¾ˆä½ã€‚</p>
<p>è€Œåœ¨Transformer-XL[9]ä¸­ï¼Œæ¯ä¸ªsegmenté˜¶æ®µéƒ½æ¥å—å‰ä¸€ä¸ª(ç”šè‡³å‰Lä¸ª)çš„å†å²ä¿¡æ¯ï¼š<br>å› æ­¤è¿‡ç¨‹å¦‚ä¸‹ï¼š<br><img src="/images/15556768100801.jpg" width="60%" height="50%"></p>
<p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œç”±äºæœ‰å†å²ä¿¡æ¯ï¼Œåˆ™ä¸éœ€è¦æ»‘åŠ¨çª—å£ï¼Œå› æ­¤æ•ˆç‡æ›´é«˜ã€‚</p>
<p>å…·ä½“è€Œè¨€ï¼š<br>$\begin{aligned} \widetilde{\mathbf{h}}_{\tau+1}^{n-1} &amp;=\left[\mathrm{SG}\left(\mathbf{h}_{\tau}^{n-1}\right) \circ \mathbf{h}_{\tau+1}^{n-1}\right] \\ \mathbf{q}_{\tau+1}^{n}, \mathbf{k}_{\tau+1}^{n}, \mathbf{v}_{\tau+1}^{n} &amp;=\mathbf{h}_{\tau+1}^{n-1} \mathbf{W}_{q}^{\top}, \widetilde{\mathbf{h}}_{\tau+1}^{n-1} \mathbf{W}_{k}^{\top}, \widetilde{\mathbf{h}}_{\tau+1}^{n-1} \mathbf{W}_{v}^{\top} \\ \mathbf{h}_{\tau+1}^{n} &amp;=\text { Transformer-Layer }\left(\mathbf{q}_{\tau+1}^{n}, \mathbf{k}_{\tau+1}^{n}, \mathbf{v}_{\tau+1}^{n}\right) \end{aligned}$<br>SGä»£è¡¨stop gradientï¼Œè€Œå†å²ä¿¡æ¯ä¸å½“å‰é˜¶æ®µçš„éšçŠ¶æ€æ‹¼æ¥åœ¨ä¸€èµ·ã€‚</p>
<p>åŒæ—¶æœ¬æ–‡å¦ä¸€å¤§ä¸¤ç‚¹æ˜¯å¼•å…¥ç›¸å¯¹ä½ç½®çš„encodingã€‚å¦‚æœä½¿ç”¨ç»å¯¹ä½ç½®encodingï¼Œé‚£ä¹ˆåˆ™ä¼šå‡ºç°ä¸‹è¿°æƒ…å†µï¼š<br>$\mathbf{h}_{\tau+1}=f\left(\mathbf{h}_{\tau}, \mathbf{E}_{\mathbf{s}_{\tau+1}}+\mathbf{U}_{1 : L}\right) \quad \text { and } \quad \mathbf{h}_{\tau}=f\left(\mathbf{h}_{\tau-1}, \mathbf{E}_{\mathbf{s}_{\tau}}+\mathbf{U}_{1 : L}\right)$<br>ä¹Ÿå³æ¯ä¸ªsegmentéƒ½ä¼šæœ‰ç›¸åŒçš„ä½ç½®ä¿¡æ¯ã€‚å› æ­¤åœ¨è¿™é‡Œå¼•å…¥$\mathbf{R} \in \mathbb{R}^{L_{\max } \times d}$ï¼Œç¬¬$i$è¡Œä»£è¡¨ç›¸å¯¹è·ç¦»$i$çš„encodingã€‚</p>
<p>å…·ä½“è€Œè¨€ï¼š<br>åœ¨æ ‡å‡†Transformerä¸­ï¼Œquery $q_i$ä¸key $k_j$æ‰€è·å¾—çš„attentionåˆ†æ•°å¯ä»¥æ‹†è§£ä¸ºï¼š<br>$\mathbf{A}_{i, j}^{\mathrm{abs}}=q_{i}^{\top} k_{j}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{U}_{j}}_{(b)}+\underbrace{\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{U}_{j}}_{(d)}$</p>
<p>å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œè½¬åŒ–ä¸ºç›¸å¯¹ä½ç½®encodingï¼Œæœ‰ï¼š<br>$\mathbf{A}_{i, j}^{\mathrm{rel}}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{R}_{i-j}}_{(b)}+\underbrace{u^{\top} \mathbf{W}_{k, R} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{v^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(d)}$</p>
<p>é¦–å…ˆæ˜¯å°†æ‰€æœ‰å‡ºç°ç»å¯¹ä½ç½®çš„åœ°æ–¹éƒ½æ”¹ä¸ºç›¸å¯¹ä½ç½®ï¼Œç¬¬äºŒæ˜¯å°†å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„$u \in \mathbb{R}^{d}$å’Œ$v \in \mathbb{R}^{d}$å»æ›¿ä»£$\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top}$å’Œ$\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top}$ã€‚ç¬¬ä¸‰ï¼Œæ˜¯å°†åŒæ ·çš„$\mathbf{W}_{k}$ç»†åŒ–æˆä¸¤ä¸ªä¸åŒçš„$\mathbf{W}_{k, E}$ä¸$\mathbf{W}_{k, R}$ã€‚</p>
<p>Transformer-XLåœ¨ä¸åŒæ•°æ®é›†ä¸Šæœ‰ç›¸å½“å¥½çš„æ•ˆæœï¼š<br><img src="/images/15556790567795.jpg" width="80%" height="50%"></p>
<p><img src="/images/15556790839030.jpg" width="80%" height="50%"></p>
<h3 id="Character-Level-Language-Modeling-with-Deeper-Self-Attention"><a href="#Character-Level-Language-Modeling-with-Deeper-Self-Attention" class="headerlink" title="Character-Level Language Modeling with Deeper Self-Attention"></a>Character-Level Language Modeling with Deeper Self-Attention</h3><p>åŒæ ·æ˜¯åœ¨è¯­è¨€æ¨¡å‹ä¸Šä½¿ç”¨Transformerï¼Œä½†æ˜¯characterçº§åˆ«çš„è¯­è¨€æ¨¡å‹ã€‚å…¶ä¸»è¦æ€è·¯æ˜¯æ·»åŠ å¤šä¸ªlossæ¥æå‡å…¶è¡¨ç°ä»¥åŠåŠ å¿«æ‹Ÿåˆé€Ÿåº¦ã€‚</p>
<p>å¯¹äºä¼ ç»Ÿçš„RNN character-levelè¯­è¨€æ¨¡å‹ï¼Œä¸€èˆ¬åšæ³•æ˜¯â€œtruncated backpropagation through timeâ€ (TBTT)ï¼šä¹Ÿå³æ¯ä¸ªbatché¢„æµ‹æœ€åä¸€ä¸ªå­—ç¬¦ï¼Œç„¶åå°†è¯¥batchçš„éšçŠ¶æ€ä¼ å…¥ä¸‹ä¸€ä¸ªbatchã€‚</p>
<p>è€Œåœ¨Transformerä¸­ä¹Ÿå¯ä»¥é‡‡ç”¨è¯¥æ–¹æ³•ã€‚ä½†åœ¨è¯¥åŸºç¡€ä¸Šï¼Œå¼•å…¥ä¸‰ç§lossã€‚<br>â‘ Multiple Positions<br>åœ¨ä¸€ä¸ªbatchå†…ï¼Œæ¯ä¸ªæ—¶é—´æ­¥téƒ½é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•ï¼Œåªé¢„æµ‹batchæœ€åä¸€ä¸ªå­—ç¬¦ï¼š</p>
<p><img src="/images/15556794194598.jpg" width="60%" height="50%"></p>
<p>â‘¡Intermediate Layer Losses<br>ä¸ä»…ä»…æœ€åä¸€å±‚è¦è¿›è¡Œé¢„æµ‹ï¼Œä¸­é—´å±‚ä¹Ÿéœ€è¦é¢„æµ‹ã€‚</p>
<p><img src="/images/15556795039170.jpg" width="60%" height="50%"><br>è¶Šåº•å±‚çš„lossæ‰€åˆ†é…çš„æƒé‡è¶Šå°ã€‚</p>
<p>â‘¢Multiple Targets<br>æ¯ä¸ªä½ç½®ä¸ä»…ä»…è¦é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œè¿˜éœ€è¦é¢„æµ‹åå‡ ä¸ªçš„å­—ç¬¦ï¼š</p>
<p><img src="/images/15556796677182.jpg" width="60%" height="50%"></p>
<p>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨å¤šä¸ªlossèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œä¸”èƒ½å¤Ÿè·å¾—æ›´å¥½çš„ç»“æœã€‚</p>
<h2 id="é¢„è®­ç»ƒæ¨¡å‹"><a href="#é¢„è®­ç»ƒæ¨¡å‹" class="headerlink" title="é¢„è®­ç»ƒæ¨¡å‹"></a>é¢„è®­ç»ƒæ¨¡å‹</h2><p>è‡ªELMoå¼€å§‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹å°±å¼€å§‹å—åˆ°å¹¿æ³›çš„å…³æ³¨ï¼Œè€ŒBertéšåçš„é—®ä¸–åˆ™æ›´æ˜¯å°†é¢„è®­ç»ƒæ¨¡å‹æ¨ä¸Šäº†æ–°çš„é˜¶æ®µã€‚å› æ­¤åœ¨è¿™é‡Œç®€è¦ä»‹ç»é¢„è®­ç»ƒæ¨¡å‹çš„å†å²ã€‚</p>
<h3 id="Non-Transformer-based"><a href="#Non-Transformer-based" class="headerlink" title="Non-Transformer-based"></a>Non-Transformer-based</h3><h4 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h4><p>è¯å‘é‡æ˜¯æœ€æ—©çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ŒBengio, et al.[10] æœ€æ—©æå‡ºç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹ï¼Œè¯å‘é‡ä½œä¸ºè®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‰¯äº§å“ï¼Œå¯ä»¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚è€Œéšååˆ™å‡ºç°äº†word2vec[11],GloVe[12]ï¼Œæ˜¯ç›®å‰æœ€ä¸ºå¹¿æ³›ä½¿ç”¨çš„è¯å‘é‡ã€‚</p>
<h4 id="CoVe-ELMo"><a href="#CoVe-ELMo" class="headerlink" title="CoVe/ELMo"></a>CoVe/ELMo</h4><p>word2vecä¸GloVeä½œä¸ºé™æ€è¯å‘é‡ï¼Œä¸€å¤§é—®é¢˜å°±æ˜¯éš¾ä»¥è§£å†³å¤šä¹‰è¯ï¼Œè€Œå¤šä¹‰è¯çš„è¡¨ç¤ºå¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡æ¥æ¨æµ‹ã€‚CoVe[13]å°†è¯å‘é‡ä»é™æ€æ‰©å±•ä¸ºåŠ¨æ€ã€‚é€šè¿‡ä¸Šä¸‹æ–‡æ¥è·å¾—ç‰¹å®šè¯çš„åŠ¨æ€è¡¨ç¤ºï¼Œå…·ä½“æ˜¯é€šè¿‡ç¿»è¯‘æ¨¡å‹æ¥è¾¾åˆ°è¯¥ç›®çš„çš„ã€‚<br>è€ŒELMo[14]ç»§æ‰¿äº†åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œä¸è¿‡æ˜¯é€šè¿‡åŒå‘è¯­è¨€æ¨¡å‹æ¥è¾¾åˆ°è¿™ä¸€ç›®çš„çš„ã€‚é€šè¿‡åŒå‘LSTMçš„è¯­è¨€æ¨¡å‹ï¼Œå°†å‰å‘ä¸åå‘éšçŠ¶æ€æ‹¼æ¥èµ·æ¥ä½œä¸ºè¯¥è¯çš„è¡¨ç¤ºã€‚<br>ä»…ä»…æ˜¯å°†ä¼ ç»Ÿé™æ€è¯å‘é‡æ›¿æ¢æˆELMoï¼Œå°±èƒ½æœ‰å¾ˆå¤§çš„æå‡ã€‚è‡ªæ­¤å¼€å§‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹å¼€å§‹å—åˆ°å¹¿æ³›çš„å…³æ³¨ã€‚</p>
<h4 id="ULMFit"><a href="#ULMFit" class="headerlink" title="ULMFit"></a>ULMFit</h4><p>åœ¨ä¸Šè¿°é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œç ”ç©¶è€…çš„æ€è·¯ä¸»è¦é›†ä¸­åœ¨é¢„è®­ç»ƒè¯å‘é‡ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚ULMFit[16]åˆ™å°è¯•ç›´æ¥å¯¹åˆ†ç±»æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œæ¥ç€å†é€šè¿‡å¾®è°ƒ(fine-tuning)ä»¥æé«˜åˆ†ç±»çš„æ•ˆæœã€‚</p>
<p><img src="/images/15556816887199.jpg" width="80%" height="50%"></p>
<p>ULMFitçš„æˆåŠŸè¯´æ˜ç›´æ¥å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒè€Œä¸æ˜¯åªé¢„è®­ç»ƒè¯å‘é‡ç”¨äºä¸‹æ¸¸ä»»åŠ¡æ˜¯å¯è¡Œçš„ã€‚</p>
<h3 id="Transformer-based"><a href="#Transformer-based" class="headerlink" title="Transformer-based"></a>Transformer-based</h3><p>GPT[15]å°è¯•é€šè¿‡æ¢ç´¢æ„å»ºä¸€ç§é€šç”¨æ¨¡å‹å¹¶åœ¨å…¶ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥åœ¨å¤šç§ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚å…¶ä¸»è¦äº®ç‚¹åœ¨äºâ‘ æ„å»ºä¸€ç§é€šç”¨æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒä»»åŠ¡ï¼Œç¬¬äºŒä½¿ç”¨Transformerè€Œä¸æ˜¯LSTMä½œä¸ºå…¶åŸºæœ¬æ¨¡å‹ã€‚<br>å…¶åŸºæœ¬æ¨¡å‹ï¼š</p>
<p><img src="/images/15556818289287.jpg" width="85%" height="50%"></p>
<p>å…·ä½“è€Œè¨€ï¼Œä¸»è¦æ˜¯æ— ç›‘ç£çš„è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŠ ä¸Šæœ‰ç›‘ç£çš„å¾®è°ƒã€‚</p>
<p>è€ŒBert[17]åœ¨GPTçš„åŸºç¡€ä¸Šï¼Œå¼•å…¥maskedè¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡éšæœºmaskæ‰éƒ¨åˆ†è¯ï¼Œå¼ºè¿«æ¨¡å‹é€šè¿‡ä¸Šä¸‹æ–‡å»é¢„æµ‹maskæ‰çš„è¯ï¼ŒåŠ å¼ºäº†æ¨¡å‹çš„èƒ½åŠ›ã€‚</p>
<p><img src="/images/15556821324062.jpg" width="85%" height="50%"></p>
<p>åŒæ—¶å¼•å…¥æœ‰ç›‘ç£å­¦ä¹ ï¼Œä¹Ÿå³é¢„æµ‹ä¸‹ä¸€å¥ï¼ˆNext Sentence Predictionï¼‰ï¼Œéšæœºåœ¨å¥å¯¹ä¸­å–ä¸¤ä¸ªå¥å­ï¼Œä½¿å¾—æœ‰50%å¯èƒ½å¥å­å¯¹æœ‰ä¸Šä¸‹æ–‡å…³ç³»ï¼Œ50%å¥å¯¹æ²¡æœ‰å…³ç³»ï¼Œä½¿æ¨¡å‹å»é¢„æµ‹å¥å¯¹ä¹‹é—´çš„å…³ç³»ã€‚å…·ä½“è€Œè¨€åˆ™æ˜¯é€šè¿‡åœ¨å¥å­å¼€å¤´åŠ [CLS]ç¬¦å·ï¼Œåœ¨æœ€é«˜å±‚å°†è¯¥ç¬¦å·çš„è¡¨ç¤ºé€šè¿‡å…¨è¿æ¥å±‚ã€‚</p>
<p>Bertåœ¨11é¡¹æ•°æ®é›†ä¸Šåˆ·æ–°æœ€é«˜è®°å½•ã€‚</p>
<p>åœ¨æ­¤ä¹‹åï¼ŒMT-DNN[19]ã€GPT2.0[18]ç›¸ç»§é—®ä¸–ï¼Œé€šè¿‡æ·»åŠ æ›´å¤šçš„ä»»åŠ¡æˆ–è€…æ›´å¤šçš„æ•°æ®ä½¿å¾—æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚ç›¸ä¿¡åœ¨æ¥ä¸‹æ¥ä¸€æ®µæ—¶é—´å†…ï¼Œç›¸å…³ä¸»é¢˜çš„è®ºæ–‡ä¹Ÿä¼šæœ‰å¾ˆå¤šã€‚</p>
<h2 id="Transformer-CNN-RNNå¯¹æ¯”åŠæ€è€ƒ"><a href="#Transformer-CNN-RNNå¯¹æ¯”åŠæ€è€ƒ" class="headerlink" title="Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ"></a>Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ</h2><p>ä¸Šè¿°çš„ä»‹ç»ï¼Œå¤§æ¦‚å¯¹Transformerä¸€æ”¯æœ‰ä¸€ä¸ªç®€å•çš„æ¢³ç†ã€‚Transformerä½œä¸ºä¸RNN/CNNå¹¶ç«‹çš„æ¨¡å‹ï¼Œç¡®å®å€¼å¾—é‡è§†ã€‚</p>
<p>ä¸ºä»€ä¹ˆTransformerè¿™ä¹ˆå¥½ï¼Œæ˜¯å¦èƒ½å¤Ÿæ›¿ä»£RNN/CNNï¼Ÿè¿™ä¹Ÿæ˜¯å€¼å¾—æ‰€æœ‰äººæ€è€ƒçš„ã€‚</p>
<p>æ­£å¦‚å‰é¢ä»‹ç»çš„é‚£æ ·ï¼ŒTransformerçš„ä¸€å¤§ä¼˜åŠ¿æ˜¯å…¨å±€æ„Ÿå—é‡ï¼Œä¹Ÿå³RNN/CNNæ¯æ¬¡åªèƒ½â€˜çœ‹â€™åˆ°éƒ¨åˆ†ä¸Šä¸‹æ–‡ï¼Œè€ŒTransformeråˆ™æ²¡æœ‰è¿™ä¸ªé™åˆ¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹è¿›è¡Œäº¤äº’ã€‚ä¹Ÿå¯ä»¥è¿™ä¹ˆè¯´ï¼ŒRNN/CNNå…·æœ‰æ›´å¼ºçš„å…ˆéªŒ(prior)ã€‚<br>ä½†è¿™ç§ä¼˜åŠ¿æœ‰æ—¶ä¹Ÿä¼šæˆä¸ºåŠ£åŠ¿ï¼šå®è·µè¯æ˜ï¼ŒTransformeråœ¨å°æ•°æ®é›†ä¸Šçš„æ•ˆæœæ˜¯ä¸å¦‚RNN/CNNçš„ã€‚æˆ–è®¸å¯ä»¥è¿™ä¹ˆç†è§£è¿™ç§ç°è±¡ï¼šTransformerç”±äºä¸å¼•å…¥å¼ºçš„å…ˆéªŒï¼Œå› æ­¤éœ€è¦å¤§é‡çš„æ•°æ®å»ä»å¤´å­¦ä¹ æ•°æ®æ‰€å­˜åœ¨çš„æŸç§patternï¼ˆå¦‚å±€éƒ¨æ€§ï¼‰ï¼Œè€Œå¼•å…¥å¼ºçš„å…ˆéªŒçš„RNN/CNNåˆ™å¯¹å°æ•°æ®é›†æ›´åŠ å‹å¥½ä¸€äº›ã€‚ä½†å½“æœ‰å¤§é‡è®­ç»ƒæ•°æ®æ—¶ï¼ˆå¦‚ç¿»è¯‘ã€è¯­è¨€æ¨¡å‹ï¼‰ï¼ŒTransformeråˆ™ä¼šæœ‰æ›´é«˜çš„ä¸Šé™ï¼ŒBert/GPTä¹Ÿå°è¯äº†è¿™ç‚¹ã€‚è€Œè¿™ç§Transformerçš„åŠ£åŠ¿æˆ–è®¸ä¹Ÿæ˜¯ä¸Šè¿°å‡ ä¸ªå·¥ä½œï¼ˆå¦‚universal transformerï¼‰çš„å…¶ä¸­ä¸€ä¸ªå‡ºå‘ç‚¹ï¼Œä¹Ÿå³åœ¨Transformerå†…å¼•å…¥RNN/CNNçš„å½’çº³åç½®ï¼ŒåŠ å¼ºå¯¹Transformerçš„å…ˆéªŒçŸ¥è¯†çš„çº¦æŸã€‚</p>
<h2 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h2><p>[1] Vaswani, Ashish, et al. â€œAttention is all you need.â€ Advances in neural information processing systems. 2017.<br>[2]Dehghani, Mostafa, et al. â€œUniversal transformers.â€ arXiv preprint arXiv:1807.03819 (2018).<br>[3]Graves, Alex. â€œAdaptive computation time for recurrent neural networks.â€ arXiv preprint arXiv:1603.08983 (2016).<br>[4]Ahmed, Karim, Nitish Shirish Keskar, and Richard Socher. â€œWeighted transformer network for machine translation.â€ arXiv preprint arXiv:1711.02132 (2017).<br>[5]Yang, Baosong, et al. â€œConvolutional Self-Attention Networks.â€ arXiv preprint arXiv:1904.03107 (2019).<br>[6]Li, Jian, et al. â€œMulti-head attention with disagreement regularization.â€ arXiv preprint arXiv:1810.10183 (2018).<br>[7]Yang, Baosong, et al. â€œModeling localness for self-attention networks.â€ arXiv preprint arXiv:1810.10182 (2018).<br>[8]Shaw, Peter, Jakob Uszkoreit, and Ashish Vaswani. â€œSelf-attention with relative position representations.â€ arXiv preprint arXiv:1803.02155 (2018).<br>[9]Dai, Zihang, et al. â€œTransformer-xl: Attentive language models beyond a fixed-length context.â€ arXiv preprint arXiv:1901.02860 (2019).<br>[10]Bengio, Yoshua, et al. â€œA neural probabilistic language model.â€ Journal of machine learning research 3.Feb (2003): 1137-1155.<br>[11]Mikolov, Tomas, et al. â€œEfficient estimation of word representations in vector space.â€ arXiv preprint arXiv:1301.3781 (2013).<br>[12]Pennington, Jeffrey, Richard Socher, and Christopher Manning. â€œGlove: Global vectors for word representation.â€ Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014.<br>[13]McCann, Bryan, et al. â€œLearned in translation: Contextualized word vectors.â€ Advances in Neural Information Processing Systems. 2017.<br>[14]Peters, Matthew E., et al. â€œDeep contextualized word representations.â€ arXiv preprint arXiv:1802.05365 (2018).<br>[15]Radford, Alec, et al. â€œImproving language understanding by generative pre-training.â€ URL <a href="https://s3-us-west-2" target="_blank" rel="noopener">https://s3-us-west-2</a>. amazonaws. com/openai-assets/research-covers/languageunsupervised/language understanding paper. pdf (2018).<br>[16]Universal Language Model Fine-tuning for Text Classification<br>[17]Devlin, Jacob, et al. â€œBert: Pre-training of deep bidirectional transformers for language understanding.â€ arXiv preprint arXiv:1810.04805 (2018).<br>[18]Radford, Alec, et al. â€œLanguage models are unsupervised multitask learners.â€ OpenAI Blog 1 (2019): 8.<br>[19]Multi-Task Deep Neural Networks for Natural Language Understanding<br>[20]Guo, Qipeng, et al. â€œStar-Transformer.â€ arXiv preprint arXiv:1902.09113 (2019).</p>
]]></content>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>æ— é¢˜</title>
    <url>/2019/04/11/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E7%B1%BB%E6%B0%B8%E6%81%92%E7%9A%84%E6%84%9A%E8%A0%A2/</url>
    <content><![CDATA[<p>äººç±»æ°¸æ’çš„æ„šè ¢ï¼Œæ˜¯æŠŠè«åå…¶å¦™çš„æ‹…å¿§ï¼Œç­‰åŒäºæ™ºåŠ›è¶…ç¾¤ã€‚  â€”â€”ç¾å›½åŠ å°”å¸ƒé›·æ–¯</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡15</title>
    <url>/2019/03/31/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8715/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡:</p>
<ol>
<li>Selective Kernel Networks</li>
<li>Attentional pooling for action recognition</li>
</ol>
<h2 id="1ï¸âƒ£-Selective-Kernel-Networks"><a href="#1ï¸âƒ£-Selective-Kernel-Networks" class="headerlink" title="1ï¸âƒ£[Selective Kernel Networks]"></a>1ï¸âƒ£[Selective Kernel Networks]</h2><p>é€šè¿‡å¯¹ä¸åŒkernel sizeçš„feature mapä¹‹é—´è¿›è¡Œä¿¡æ¯ç­›é€‰è·å¾—æ›´ä¸ºé²æ£’çš„è¡¨ç¤ºï¼Œèƒ½å¤Ÿå¯¹ä¸åŒçš„æ„Ÿå—é‡è¿›è¡Œæ•´åˆï¼Œå®ç°åŠ¨æ€è°ƒæ•´æ„Ÿå—é‡ã€‚å…¶æ€è·¯è¿˜æŒºæœ‰æ„æ€çš„ã€‚</p>
<p>Introductionå°†è¯¥æ¨¡å‹ä¸è§†è§‰ç¥ç»çš„ç†è®ºç»“åˆåœ¨ä¸€èµ·ï¼Œä¹Ÿå³ï¼Œå¯¹äºäººç±»è€Œè¨€ï¼Œåœ¨çœ‹ä¸åŒå°ºå¯¸ä¸åŒè¿œè¿‘çš„ç‰©ä½“æ—¶ï¼Œè§†è§‰çš®å±‚ç¥ç»å…ƒ<strong>æ„Ÿå—é‡å¤§å°</strong>æ˜¯ä¼šæ ¹æ®åˆºæ¿€æ¥è¿›è¡Œè°ƒèŠ‚çš„ï¼Œä½†ä¸€èˆ¬è€Œè¨€åœ¨CNNä¸­å·ç§¯æ ¸çš„å¤§å°æ˜¯å›ºå®šçš„ã€‚è¯¥æ¨¡å‹æ­£æ˜¯ä»è¿™ä¸€ç°è±¡ä¸­è·å¾—çµæ„Ÿã€‚</p>
<p>æ•´ä¸ªæ¨¡å‹ä¸€å…±åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼šsplitï¼Œfuseï¼Œselect</p>
<p>splitç”Ÿæˆå¤šä¸ªä¸åŒkernel sizeçš„feature mapï¼Œä¹Ÿå³å¯¹åº”ä¸åŒçš„æ„Ÿå—é‡å¤§å°ï¼›fuseå°†ä¸åŒfeature mapç»“åˆèµ·æ¥ï¼Œè·å¾—ä¸€ä¸ªå…¨å±€çš„ç»¼åˆçš„å‘é‡è¡¨ç¤ºï¼›selectæ ¹æ®ä¸åŒçš„weighté€‰æ‹©ä¸åŒæ„Ÿå—é‡çš„feature mapã€‚</p>
<p><img src="/images/15540416698404.jpg" width="80%" height="50%"></p>
<p>ä»¥ä¸Šå›¾ä¸ºä¾‹ã€‚</p>
<h3 id="SK-Net"><a href="#SK-Net" class="headerlink" title="SK-Net"></a>SK-Net</h3><h4 id="ç¬¬ä¸€æ­¥split"><a href="#ç¬¬ä¸€æ­¥split" class="headerlink" title="ç¬¬ä¸€æ­¥split"></a>ç¬¬ä¸€æ­¥split</h4><p>ç»™å®šè¾“å…¥$\mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}}$ï¼Œé€šè¿‡ä¸åŒçš„kernel sizeçš„CNNçš„å·ç§¯è·å¾—ä¸åŒçš„feature mapï¼Œä¸Šå›¾æ˜¯$3\times 3$ä¸$5\times 5$çš„å·ç§¯æ ¸ã€‚å·ç§¯å¯ä»¥æ˜¯ä¼ ç»Ÿçš„convolutionå·ç§¯ï¼Œä¹Ÿå¯ä»¥æ˜¯ç©ºæ´å·ç§¯ï¼ˆdilated convolutionï¼‰ï¼Œæˆ–è€…æ·±åº¦å·ç§¯ï¼ˆdepthwise convolutionï¼‰ã€‚åˆ™æœ‰ï¼š<br>$\widetilde{\mathcal{F}} : \mathbf{X} \rightarrow \widetilde{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$ ä¸ $\widehat{\mathcal{F}} : \mathbf{X} \rightarrow \widehat{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$ï¼Œå…¶ä¸­$\widetilde{\mathcal{F}},\widehat{\mathcal{F}}$æ˜¯å·ç§¯å˜æ¢ã€‚</p>
<h4 id="ç¬¬äºŒæ­¥fuse"><a href="#ç¬¬äºŒæ­¥fuse" class="headerlink" title="ç¬¬äºŒæ­¥fuse"></a>ç¬¬äºŒæ­¥fuse</h4><p>ç›´æ¥å°†ä¸åŒçš„feature mapç»“åˆèµ·æ¥ä»¥è·å¾—å…¨å±€ä¿¡æ¯ï¼Œç”¨ä»¥ä¹‹åçš„åŠ¨æ€è°ƒæ•´ã€‚è¿™é‡Œé‡‡ç”¨ç®€å•çš„æ±‚å’Œä»¥åŠglobal average poolingä»¥è·å¾—channel-wiseçš„ä¿¡æ¯$\mathbf{s} \in \mathbb{R}^{C}$ï¼š</p>
<script type="math/tex; mode=display">\mathbf{U}=\widetilde{\mathbf{U}}+\widehat{\mathbf{U}} \\ s_{c}=\mathcal{F}_{g p}\left(\mathbf{U}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} \mathbf{U}_{c}(i, j)</script><p>åœ¨è·å¾—$\mathbf{s}$åå†é€šè¿‡MLPè·å¾—$\mathbf{z}$ï¼š</p>
<script type="math/tex; mode=display">\mathbf{z}=\mathcal{F}_{f c}(\mathbf{s})=\delta(\mathcal{B}(\mathbf{W} \mathbf{s}))</script><p>å…¶ä¸­$\mathcal{B}$æ˜¯batch normalizationï¼›$\delta$æ˜¯Reluã€‚</p>
<h4 id="ç¬¬ä¸‰æ­¥select"><a href="#ç¬¬ä¸‰æ­¥select" class="headerlink" title="ç¬¬ä¸‰æ­¥select"></a>ç¬¬ä¸‰æ­¥select</h4><p>ä½¿ç”¨soft attentionå»é€‰æ‹©ä¸åŒkernel sizeçš„feature mapå¹¶ç»“åˆåœ¨ä¸€èµ·ã€‚ä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">a_{c}=\frac{e^{\mathbf{A}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}, b_{c}=\frac{e^{\mathbf{B}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}</script><p>å…¶ä¸­$\mathbf{A}_{c}$æ˜¯å¯¹åº”$\widetilde{\mathbf{U}}$ç¬¬$c$ä¸ªchannelçš„å‚æ•°ï¼Œ$\mathbf{B}_{c}$æ˜¯å¯¹åº”$\widehat{\mathbf{U}}$ç¬¬$c$ä¸ªchannelçš„å‚æ•°ã€‚$\mathbf{A}, \mathbf{B} \in \mathbb{R}^{C \times d}$ï¼Œé‚£ä¹ˆ$a_{c},b_{c}$å°±å¯¹åº”ä¸åŒfeature mapçš„weightã€‚</p>
<p>å› æ­¤ï¼Œæœ€ç»ˆçš„feature map $\mathbf{V}$ï¼š</p>
<script type="math/tex; mode=display">\mathbf{V}_{c}=a_{c} \cdot \tilde{\mathbf{U}}_{c}+b_{c} \cdot \widehat{\mathbf{U}}_{c}, \quad a_{c}+b_{c}=1 \\ \mathbf{V}=\left[\mathbf{V}_{1}, \mathbf{V}_{2}, \dots, \mathbf{V}_{C}\right], \mathbf{V}_{c} \in \mathbb{R}^{H \times W}</script><h3 id="å¯¹æ¯”-amp-æ€è€ƒ"><a href="#å¯¹æ¯”-amp-æ€è€ƒ" class="headerlink" title="å¯¹æ¯”&amp;æ€è€ƒ"></a>å¯¹æ¯”&amp;æ€è€ƒ</h3><h4 id="ä¸SE-Net"><a href="#ä¸SE-Net" class="headerlink" title="ä¸SE-Net"></a>ä¸SE-Net</h4><p>SE-Netæ˜¯é€šè¿‡ä¸åŒchannelä¹‹é—´çš„äº¤äº’ï¼Œä½¿å¾—channelè·å¾—å…¨å±€çš„æ„Ÿå—é‡ï¼Œä½¿ç”¨çš„æ˜¯å¯¹channelçš„æ”¾ç¼©ï¼ˆè¯¦è§ä¸Šä¸€ç¯‡è®ºæ–‡ç¬”è®°ï¼‰ï¼›è€ŒSK-Netæ˜¯ä¸åŒçš„æ„Ÿå—é‡ä¹‹é—´çš„åŒä¸€channelåœ¨é€šè¿‡å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹ä»¥soft-attentionçš„å½¢å¼åŠ æƒå¹³å‡ï¼Œè¿™å°±å’Œè®ºæ–‡ä¸­æåˆ°çš„äººç±»è§†è§‰å¯¹ä¸åŒç‰©ä½“è¿›è¡ŒåŠ¨æ€è°ƒæ•´æ„Ÿå—é‡çš„æ€è·¯ä¸€è‡´ã€‚</p>
<h4 id="ä¸dynamic-convolution"><a href="#ä¸dynamic-convolution" class="headerlink" title="ä¸dynamic convolution"></a>ä¸dynamic convolution</h4><p>åœ¨è®ºæ–‡[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]ä¸­ï¼Œç ”ç©¶äººå‘˜æå‡ºåŠ¨æ€æ„Ÿå—é‡çš„convolutionï¼Œé€šè¿‡åˆ©ç”¨å½“å‰è¯é¢„æµ‹ä¸€ä¸ªå·ç§¯çª—å£ï¼Œå¢åŠ äº†æ¨¡å‹çš„çµæ´»æ€§ï¼Œå¹¶åœ¨æœºå™¨ç¿»è¯‘ä¸Šå–å¾—äº†å¾ˆå¥½çš„ç»“æœã€‚</p>
<p>è™½ç„¶ç›®çš„ä¸æœ¬ç¯‡è®ºæ–‡ä¸€è‡´ï¼Œä½†æ€è·¯æ˜¯å®Œå…¨ä¸åŒçš„ã€‚ä¸€ä¸ªæ˜¯é€šè¿‡é¢„æµ‹ï¼›å¦ä¸€ä¸ªæ˜¯åœ¨å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹è¿›è¡ŒåŠ æƒã€‚åœ¨æˆ‘çš„ç†è§£çœ‹æ¥ï¼Œæˆ–è®¸æœ¬ç¯‡è®ºæ–‡çš„æ€è·¯æ›´åŠ åˆç†ä¸€äº›ï¼Œç¬¬ä¸€ï¼Œåœ¨æœ‰äº†å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹èƒ½å¤Ÿæ›´å¥½çš„è¿›è¡ŒåŠ æƒï¼Œè€Œé€šè¿‡é¢„æµ‹ï¼Œä¼¼ä¹æœ‰äº›ç›²ç›®ï¼Œå¯èƒ½éœ€è¦æ›´å¤šçš„æ•°æ®æ‰èƒ½å­¦å¾—æ›´å¥½ï¼›ç¬¬äºŒï¼Œdynamic convolutionè®ºæ–‡ä¸­ä¹Ÿæåˆ°äº†ï¼Œå¦‚æœä¸ä½¿ç”¨å¦‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯ç­‰è½»é‡çº§å·ç§¯æ–¹æ³•ï¼Œdynamic convolutionä¸å¤§ç°å®ï¼ˆA dynamic version of standard convolutions would be impractical for current GPUs due to their large memory requirementsï¼‰ï¼Œè€ŒSK-Netåˆ™ä¸ä¼šæœ‰è¿™ä¸ªé—®é¢˜ã€‚</p>
<h4 id="å…¶ä»–æ€è€ƒ"><a href="#å…¶ä»–æ€è€ƒ" class="headerlink" title="å…¶ä»–æ€è€ƒ"></a>å…¶ä»–æ€è€ƒ</h4><p>ä»å¦ä¸€ä¸ªè§’åº¦å»æ€è€ƒï¼ŒSK-Neté€šè¿‡äººå·¥å®šä¹‰å¥½çš„å‡ ç§ä¸åŒå¤§å°çš„å·ç§¯ï¼Œç›¸å½“äºåœ¨æ¨¡å‹ä¸­å¼•å…¥æ›´å¼ºçš„å…ˆéªŒï¼ˆinductive biasï¼‰ï¼Œä¹Ÿå³å‡è®¾äº†æ•°æ®ä¸ä¼šè¶…è¿‡è¿™å‡ ç§å¤§å°çš„å·ç§¯çš„å¤„ç†èŒƒå›´ï¼Œè¿™æˆ–è®¸æ¯”ä¸å¼•å…¥å…ˆéªŒï¼Œå®Œå…¨é æ•°æ®å»å­¦æŸç§ç‰¹å®špatternçš„dynamic convolutionå¯¹å°æ•°æ®é›†æ›´å‹å¥½ï¼Œå› æ­¤å¯ä»¥ä¸éœ€è¦æ›´å¤šçš„æ•°æ®æ¥ä½¿å¾—æ¨¡å‹è¡¨ç°è‰¯å¥½ã€‚ç±»ä¼¼çš„ç†è§£å¯ä»¥åœ¨CNN/RNNä¸Transformerçš„å¯¹æ¯”ä¸­çœ‹è§ï¼Œå› ä¸ºCNN/RNNå¼•å…¥äº†è¾ƒå¼ºçš„local biasï¼Œå› æ­¤å¯¹äºå°æ•°æ®é›†æ›´å‹å¥½ï¼Œä½†åŒæ—¶å…¶ä¸Šé™æˆ–è®¸ä¸å¦‚Transformeré«˜ï¼›è€ŒTransformerä¸€å¼€å§‹å°±æ˜¯å…¨å±€æ„Ÿå—é‡ï¼Œä½¿å¾—éœ€è¦æ›´å¤šæ•°æ®æ¥å¸®åŠ©æ¨¡å‹å­¦åˆ°æŸç§ç‰¹å®špatternï¼ˆå¦‚æŸç§local biasï¼‰ï¼Œä½†å½“æ•°æ®å……è¶³æ—¶ï¼ŒTransformerçš„ä¸Šé™æ›´é«˜ï¼Œè¿‘æœŸéå¸¸ç«çš„pretrained model GPT/GPT-2.0/Bertä¼¼ä¹ä¹Ÿå°è¯äº†è¿™ç‚¹ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Attentional-pooling-for-action-recognition"><a href="#2ï¸âƒ£-Attentional-pooling-for-action-recognition" class="headerlink" title="2ï¸âƒ£[Attentional pooling for action recognition]"></a>2ï¸âƒ£[Attentional pooling for action recognition]</h2><p>æå‡ºä¸€ç§åŸºäºattentionçš„poolingç­–ç•¥ï¼Œé‡‡ç”¨ä½ç§©è¿‘ä¼¼çš„æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨è®¡ç®—é‡ä¸å¢åŠ å¾ˆå¤šçš„æƒ…å†µä¸‹è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚å¯ä»¥å°†è¯¥æ–¹æ³•ç†è§£æˆå¯¹äºŒé˜¶poolingçš„ä½ç§©è¿‘ä¼¼ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><h4 id="ä¸€é˜¶pooling"><a href="#ä¸€é˜¶pooling" class="headerlink" title="ä¸€é˜¶pooling"></a>ä¸€é˜¶pooling</h4><p>è®°$X \in R^{n \times f}$ä¸ºè¢«poolingçš„å±‚ï¼Œå…¶ä¸­nä¸ºç©ºé—´ä½ç½®çš„ä¸ªæ•°ï¼Œå¦‚$16\times 16$ï¼Œ$f$ä¸ºchannelä¸ªæ•°ã€‚æ ‡å‡†çš„sum/max poolingå°†è¯¥çŸ©é˜µç¼©å‡ä¸º$R^{f \times 1}$ï¼Œç„¶åä½¿ç”¨å…¨è¿æ¥çš„æƒé‡$\mathbf{w} \in R^{f \times 1}$è·å¾—ä¸€ä¸ªåˆ†ç±»çš„åˆ†æ•°ã€‚è¿™é‡Œå‡è®¾çš„æ˜¯äºŒåˆ†ç±»ï¼Œä½†å¯ä»¥å¾ˆå®¹æ˜“æ¨å¹¿ä¸ºå¤šåˆ†ç±»ã€‚</p>
<p>ä¸Šè¿°æ“ä½œå½¢å¼åŒ–å¯ä»¥å†™æˆï¼š</p>
<script type="math/tex; mode=display">\operatorname{score}_{p o o l}(X)=\mathbf{1}^{T} X \mathbf{w}, \quad \text { where } \quad X \in R^{n \times f}, \mathbf{1} \in R^{n \times 1}, \mathbf{w} \in R^{f \times 1}</script><p>å…¶ä¸­$\mathbf{1}$ä¸ºå…¨1å‘é‡ï¼Œ$\mathbf{x}=\mathbf{1}^{T} X \in R^{1 \times f}$å°±æ˜¯é€šè¿‡sum poolingåçš„featureã€‚</p>
<h4 id="äºŒé˜¶pooling"><a href="#äºŒé˜¶pooling" class="headerlink" title="äºŒé˜¶pooling"></a>äºŒé˜¶pooling</h4><p>æ„å»ºäºŒé˜¶feature $X^{T} X \in R^{f \times f}$ï¼Œåœ¨è·å¾—äºŒé˜¶featureåï¼Œé€šå¸¸æˆ–å‘é‡åŒ–è¯¥çŸ©é˜µï¼Œå†é€å…¥å…¨è¿æ¥ä»¥åšåˆ†ç±»ã€‚ä¹Ÿå³æˆ‘ä»¬ä¼šå­¦ä¹ ä¸€ä¸ª$f\times f$çš„å…¨è¿æ¥æƒé‡å‘é‡ã€‚è‹¥ä¿æŒäºŒé˜¶featureä¸å¯¹åº”çš„å…¨è¿æ¥æƒé‡å‘é‡çš„å½¢å¼ä¸ºçŸ©é˜µï¼ŒçŸ©é˜µç›¸ä¹˜ï¼Œå…¶ä¸­çš„è¿¹å®é™…ä¸Šå°±æ˜¯è¿™ä¸¤ä¸ªå‘é‡åŒ–åçš„çŸ©é˜µæ‰€åšå†…ç§¯è·å¾—çš„åˆ†æ•°ã€‚å½¢å¼åŒ–å¯ä»¥å†™æˆï¼š</p>
<script type="math/tex; mode=display">\text {score}_{order2}(X)=\operatorname{Tr}\left(X^{T} X W^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W \in R^{f \times f}</script><p>è¿™å¯ä»¥ç”¨è¿¹çš„å®šä¹‰å»è¯æ˜ï¼šç¤ºæ„å›¾<br><img src="/images/15540862875594.jpg" width="100%" height="50%"></p>
<h4 id="ä½ç§©äºŒé˜¶pooling"><a href="#ä½ç§©äºŒé˜¶pooling" class="headerlink" title="ä½ç§©äºŒé˜¶pooling"></a>ä½ç§©äºŒé˜¶pooling</h4><p>ç°å°è¯•ä½¿ç”¨ä½ç§©å»è¿‘ä¼¼è¯¥äºŒé˜¶poolingï¼Œä¹Ÿå³å¯¹$W$è¿‘ä¼¼ï¼Œå°†$W$å†™æˆä¸¤ä¸ªå‘é‡çš„ä¹˜ç§¯ï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">W=\mathbf{a b}^{T} \text { where } \mathbf{a}, \mathbf{b} \in R^{f \times 1}</script><p>å°†ä¸Šå¼ä»£å…¥äºŒé˜¶poolingï¼Œå¯è·å¾—ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\operatorname{Tr}\left(X^{T} X \mathbf{b a}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, \mathbf{a}, \mathbf{b} \in R^{f \times 1} \\ &=\operatorname{Tr}\left(\mathbf{a}^{T} X^{T} X \mathbf{b}\right) \\ &=\mathbf{a}^{T} X^{T} X \mathbf{b} \\ &=\mathbf{a}^{T}\left(X^{T}(X \mathbf{b})\right) \end{aligned}</script><p>ç¬¬äºŒè¡Œä½¿ç”¨çš„æ˜¯è¿¹çš„å®šç†ï¼š$\operatorname{Tr}(A B C)=\operatorname{Tr}(C A B)$<br>ç¬¬ä¸‰è¡Œä½¿ç”¨çš„æ˜¯æ ‡é‡çš„è¿¹ç­‰äºæ ‡é‡æœ¬èº«ã€‚<br>æœ€åä¸€è¡Œè¡¨æ˜æ•´ä¸ªæµç¨‹ï¼šç»™å®šä¸€ä¸ªfeature map $X$ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªå¯¹æ‰€æœ‰ç©ºé—´ä½ç½®çš„attentional mapï¼š$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$ï¼›ç„¶åæ ¹æ®è¯¥attentional mapè®¡ç®—åŠ æƒå¹³å‡çš„featureï¼š$\mathbf{x}=X^{T} \mathbf{h} \in R^{f \times 1}$ã€‚è¯¥featureå†é€šè¿‡çº¿æ€§å±‚è·å¾—æœ€ç»ˆçš„åˆ†æ•°ã€‚</p>
<p>å®é™…ä¸Šä¸Šå¼è¿˜æœ‰å…¶ä»–ç†è§£çš„è§’åº¦ï¼š</p>
<script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\left((X \mathbf{a})^{T} X\right) \mathbf{b} \\ &=(X \mathbf{a})^{T}(X \mathbf{b}) \end{aligned}</script><p>ç¬¬ä¸€è¡Œè¡¨æ˜attentional mapä¹Ÿå¯ä»¥é€šè¿‡$X \mathbf{a} \in R^{n \times 1}$æ¥è®¡ç®—ï¼Œ$\mathbf{b}$æ¥åšclassifierã€‚<br>ç¬¬äºŒè¡Œè¡¨æ˜ï¼Œè¯¥å¼å­æœ¬è´¨ä¸Šæ˜¯å¯¹ç§°çš„ï¼Œå¯ä»¥çœ‹æˆ<strong>ä¸¤ä¸ªattentional heapmapçš„å†…ç§¯</strong>ã€‚</p>
<p>ä¸‹å›¾æ˜¯æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15540869385196.jpg" width="80%" height="50%"></p>
<h4 id="Top-down-attention"><a href="#Top-down-attention" class="headerlink" title="Top-down attention"></a>Top-down attention</h4><p>ç°å°†äºŒåˆ†ç±»æ¨å¹¿ä¸ºå¤šåˆ†ç±»ï¼š</p>
<script type="math/tex; mode=display">\text {score}_{order2}(X, k)=\operatorname{Tr}\left(X^{T} X W_{k}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W_{k} \in R^{f \times f}</script><p>ä¹Ÿå³å°†$W$æ›¿æ¢æˆç±»ç›¸å…³çš„å‚æ•°ï¼Œä»¿ç…§ä¸Šé¢çš„æ¨å¯¼ï¼Œå¯ä»¥æ¨å‡ºæ¯ä¸ªç±»éƒ½æœ‰ç‰¹å®šçš„$\boldsymbol{a}_{k}$ä¸$\boldsymbol{b}_{k}$ã€‚</p>
<p>ä½†åœ¨è¿™é‡Œé€šè¿‡å›ºå®šå…¶ä¸­ä¸€ä¸ªå‚æ•°ä¸ºä¸ç±»æ— å…³çš„å‚æ•°ï¼Œä¹Ÿå³$\boldsymbol{b}_{k}=\boldsymbol{b}$ã€‚å®é™…ä¸Šå°±ç­‰ä»·äºä¸€ä¸ªæ˜¯ç±»ç›¸å…³çš„top-down attentionï¼›å¦ä¸€ä¸ªæ˜¯ç±»æ— å…³çš„bottom-up attentionã€‚ä¸€ä¸ªè·å¾—ç±»ç‰¹å®šçš„ç‰¹å¾ï¼›å¦ä¸€ä¸ªè·å¾—å…¨å±€é€šç”¨çš„ç‰¹å¾ã€‚</p>
<p>å› æ­¤æœ€ç»ˆä½ç§©attention modelä¸ºï¼š</p>
<script type="math/tex; mode=display">\text {score}_{attention}(X, k)=\mathbf{t}_{k}^{T} \mathbf{h}, \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{a}_{k}, \mathbf{h}=X \mathbf{b}</script><h4 id="Average-pooling-Revisited"><a href="#Average-pooling-Revisited" class="headerlink" title="Average-pooling Revisited"></a>Average-pooling Revisited</h4><p>å½“ç„¶åœ¨ç»™å®šäº†ä¸Šè¿°ä¸€ç³»åˆ—çš„æ¨å¯¼ï¼Œæˆ‘ä»¬å¯¹average-poolingé‡æ–°è¿›è¡Œå½¢å¼åŒ–ï¼š</p>
<script type="math/tex; mode=display">\text {score}_{top-down}(X, k)=\mathbf{1}^{T} X \mathbf{w}_{k}=\mathbf{1}^{T} \mathbf{t}_{k} \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{w}_{k}</script><p>å°†$\mathbf{w}$æ›¿æ¢æˆç±»ç›¸å…³çš„$\mathbf{w}_{k}$ï¼Œå®é™…ä¸Šå°±æ˜¯å°†äºŒåˆ†ç±»æ¨å¹¿ä¸ºå¤šåˆ†ç±»ã€‚ä½†è¯¥å½¢å¼èµ‹äºˆäº†average-poolingæ–°çš„ç†è§£ã€‚</p>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†rank-1æ¨å¹¿ä¸ºrank-kï¼Œå®éªŒè¯æ˜å¯¹äºå¤§æ•°æ®é›†ä½¿ç”¨å¤§çš„ç§©ä¼šæ›´å¥½ã€‚</p>
<h3 id="å¯¹æ¯”"><a href="#å¯¹æ¯”" class="headerlink" title="å¯¹æ¯”"></a>å¯¹æ¯”</h3><h4 id="ä¸Self-attentiveçš„è”ç³»"><a href="#ä¸Self-attentiveçš„è”ç³»" class="headerlink" title="ä¸Self-attentiveçš„è”ç³»"></a>ä¸Self-attentiveçš„è”ç³»</h4><p>è®ºæ–‡[A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING]å°±æå‡ºäº†åˆ©ç”¨å¯å­¦ä¹ çš„headå¯¹featureè¿›è¡ŒattentionåŠ æƒå¹³å‡çš„æ–¹æ³•ï¼Œå¹¶ä¸”å°†ä¸€ä¸ªheadæ¨å¹¿åˆ°å¤šä¸ªheadã€‚<br>å®é™…ä¸Šåœ¨$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$æˆ‘ä»¬å°±å¯ä»¥çœ‹å‡ºï¼Œ$\mathbf{b}$åœ¨è¿™é‡Œæ‰®æ¼”çš„è§’è‰²å°±æ˜¯self-attentiveçš„headçš„è§’è‰²ã€‚å¯¹äºç§©ä¸º1çš„è¿‘ä¼¼ï¼Œå°±æ˜¯headä¸º1çš„æƒ…å†µï¼Œè‹¥å°†ç§©ä¸º1æ¨å¹¿ä¸ºç§©ä¸ºkï¼Œä¹Ÿå³ç­‰ä»·äºåœ¨Self-attentiveä¸­å¤šä¸ªheadçš„æƒ…å†µã€‚</p>
<p>æœ¬æ–‡å·§å¦™çš„åœ°æ–¹åœ¨äºheadæœ‰ä¸¤ä¸ªä½œç”¨ï¼Œä¸€ç§æ˜¯top-downçš„headï¼Œè·å¾—çš„æ˜¯ç±»ç›¸å…³çš„featureï¼›å¦ä¸€ä¸ªæ˜¯bottom-upçš„featureï¼Œè·å¾—çš„æ˜¯é€šç”¨çš„featureã€‚å¹¶ä¸”æœ¬æ–‡é€šè¿‡å·§å¦™çš„æ•°å­¦æ¨å¯¼æ¥è·å¾—æ–°çš„è§£é‡Šï¼Œæœ¬æ¥ä»…ä»…æ˜¯äºŒé˜¶featureè¿‡ä¸€ä¸ªå…¨è¿æ¥ï¼Œä½†é€šè¿‡å…¬å¼æ¨å¯¼èµ‹äºˆäº†attentionçš„è§£é‡Šï¼Œè¿™ç‚¹è®©äººçœ¼å‰ä¸€äº®ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>second-order</tag>
        <tag>pooling</tag>
        <tag>SK-Net</tag>
        <tag>attentional pooling</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯21</title>
    <url>/2019/03/31/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D21/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£é†‰è½é­„-Â·-å¸­ä¸Šå‘ˆå…ƒç´ "><a href="#1ï¸âƒ£é†‰è½é­„-Â·-å¸­ä¸Šå‘ˆå…ƒç´ " class="headerlink" title="1ï¸âƒ£é†‰è½é­„ Â· å¸­ä¸Šå‘ˆå…ƒç´ "></a>1ï¸âƒ£é†‰è½é­„ Â· å¸­ä¸Šå‘ˆå…ƒç´ </h3><p>[å®‹] è‹è½¼<br>åˆ†æºå¦‚æ˜¨ï¼Œäººç”Ÿåˆ°å¤„èé£˜æ³Šã€‚å¶ç„¶ç›¸èšè¿˜ç¦»ç´¢ã€‚å¤šç—…å¤šæ„ï¼Œé¡»ä¿¡ä»æ¥é”™ã€‚<br><strong>å°Šå‰ä¸€ç¬‘ä¼‘è¾å´ï¼Œå¤©æ¶¯åŒæ˜¯ä¼¤æ²¦è½</strong>ã€‚æ•…å±±çŠ¹è´Ÿå¹³ç”Ÿçº¦ã€‚è¥¿æœ›å³¨åµ‹ï¼Œé•¿ç¾¡å½’é£é¹¤ã€‚</p>
<p><a href="http://lib.xcz.im/work/57c467a86be3ff0058452840" target="_blank" rel="noopener">http://lib.xcz.im/work/57c467a86be3ff0058452840</a></p>
<hr>
<h3 id="2ï¸âƒ£æˆä¸ºå…­ç»å¥"><a href="#2ï¸âƒ£æˆä¸ºå…­ç»å¥" class="headerlink" title="2ï¸âƒ£æˆä¸ºå…­ç»å¥"></a>2ï¸âƒ£æˆä¸ºå…­ç»å¥</h3><p>[å”] æœç”«<br>ã€å…¶ä¸€ã€‘<br>åº¾ä¿¡æ–‡ç« è€æ›´æˆï¼Œå‡Œäº‘å¥ç¬”æ„çºµæ¨ªã€‚<br>ä»Šäººå—¤ç‚¹æµä¼ èµ‹ï¼Œä¸è§‰å‰è´¤ç•åç”Ÿã€‚</p>
<p>ã€å…¶ä¸‰ã€‘<br>çºµä½¿å¢ç‹æ“ç¿°å¢¨ï¼ŒåŠ£äºæ±‰é­è¿‘é£éªšã€‚<br>é¾™æ–‡è™è„Šçš†å›é©­ï¼Œå†å—è¿‡éƒ½è§å°”æ›¹ã€‚</p>
<p>è¿‡éƒ½å†å— (guÃ² dÅu lÃ¬ kuÃ i)<br>è§£é‡Šï¼šè¶Šè¿‡éƒ½å¸‚ï¼Œç»è¿‡å±±é˜œã€‚æ„æŒ‡çºµæ¨ªé©°éª‹ï¼Œæ–½å±•æ‰èƒ½ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡14</title>
    <url>/2019/03/24/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8714/</url>
    <content><![CDATA[<p>æœ¬å‘¨è®ºæ–‡:</p>
<ol>
<li>Is Second-order Information Helpful for Large-scale Visual Recognition?</li>
<li>The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification</li>
</ol>
<h2 id="1ï¸âƒ£-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition"><a href="#1ï¸âƒ£-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition" class="headerlink" title="1ï¸âƒ£[Is Second-order Information Helpful for Large-scale Visual Recognition?]"></a>1ï¸âƒ£[Is Second-order Information Helpful for Large-scale Visual Recognition?]</h2><p>é€šè¿‡åæ–¹å·®çš„æ–¹æ³•è·å¾—å›¾åƒçš„äºŒé˜¶ä¿¡æ¯ã€‚<br>å‚è€ƒäº†<a href="https://zhuanlan.zhihu.com/p/46864160" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46864160</a></p>
<p>æ·±åº¦åˆ†ç±»ç½‘ç»œä¸»è¦åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šç‰¹å¾æå–å’Œåˆ†ç±»å™¨ã€‚æ— è®ºæ˜¯VGGè¿˜æ˜¯GoogleNetï¼Œåæ¥çš„Resnetã€Densenetï¼Œåœ¨è¿æ¥åˆ†ç±»å™¨ä¹‹å‰ï¼Œä¸€èˆ¬éƒ½è¿æ¥äº†ä¸€ä¸ªPoolingå±‚ã€‚<br>ä½†poolingåªè·å¾—äº†featureçš„ä¸€é˜¶ä¿¡æ¯ï¼Œå¯¹äºç»†åˆ†ç±»é—®é¢˜ä¸­ç±»é—´å·®å¼‚ä¸æ˜¾è‘—ï¼Œä¸€é˜¶ä¿¡æ¯å¯èƒ½æœ‰ä¸€äº›ä¸é€‚ç”¨ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€é˜¶ä¿¡æ¯è·å¾—äºŒé˜¶ä¿¡æ¯ï¼Œä»è€Œè·å–æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</p>
<p>æœ¬æ–‡é€šè¿‡è·å–<strong>ç‰¹å¾åæ–¹å·®</strong>çš„æ–¹æ³•ï¼Œä»¥è¾¾åˆ°è¯¥ç›®çš„ã€‚</p>
<p>è¾“å…¥:$\mathbf{X} \in \mathbb{R}^{d \times N}$</p>
<p>åˆ™åæ–¹å·®çŸ©é˜µä¸º$\mathbf{X} \mapsto \mathbf{P}, \quad \mathbf{P}=\mathbf{X} \overline{\mathbf{I}} \mathbf{X}^{T}$ï¼Œå…¶ä¸­$\overline{\mathbf{I}}=\frac{1}{N}\left(\mathbf{I}-\frac{1}{N} \mathbf{1} \mathbf{1}^{T}\right)$, $\mathbf{I}$æ˜¯å•ä½é˜µï¼Œ$\mathbf{1}$æ˜¯å…¨1çš„å‘é‡ã€‚</p>
<p>åæ–¹å·®çŸ©é˜µæ˜¯åŠæ­£å®šçŸ©é˜µï¼Œå› æ­¤å¯å†™æˆ$\mathbf{P} \mapsto(\mathbf{U}, \mathbf{\Lambda}), \quad \mathbf{P}=\mathbf{U} \mathbf{\Lambda} \mathbf{U}^{T}$ï¼Œå…¶ä¸­$\boldsymbol{\Lambda}=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{d}\right)$ï¼Œ$\mathbf{U}=\left[\mathbf{u}_{1}, \dots, \mathbf{u}_{d}\right]$ï¼Œ$\mathbf{U}$æ˜¯å¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚</p>
<p>æœ€ç»ˆå¯è·å¾—$\mathbf{Q}$çŸ©é˜µï¼š$(\mathbf{U}, \boldsymbol{\Lambda}) \mapsto \mathbf{Q}, \mathbf{Q} \triangleq \mathbf{P}^{\alpha}=\mathbf{U F}(\mathbf{\Lambda}) \mathbf{U}^{T}$ï¼Œå…¶ä¸­$\alpha$æ˜¯ä¸€ä¸ªæ­£å®æ•°ï¼Œ$\mathbf{F}(\boldsymbol{\Lambda})=\operatorname{diag}\left(f\left(\lambda_{1}\right), \ldots, f\left(\lambda_{d}\right)\right)$ï¼Œå…¶ä¸­$f\left(\lambda_{i}\right)=\lambda_{i}^{\alpha}$ï¼Œæ˜¯ç‰¹å¾å€¼çš„å¹‚ï¼Œå¦‚æœè¦åšå½’ä¸€åŒ–ï¼Œé‚£ä¹ˆå¯ä»¥æœ‰ï¼š</p>
<script type="math/tex; mode=display">f\left(\lambda_{i}\right)=\left\{\begin{array}{cc}{\lambda_{i}^{\alpha} / \lambda_{1}^{\alpha}} & {\text { for MPN+M }-\ell_{2}} \\ {\lambda_{i}^{\alpha} /\left(\sum_{k} \lambda_{k}^{2 \alpha}\right)^{\frac{1}{2}}} & {\text { for MPN+M-Fro }}\end{array}\right.</script><p>ä¹‹æ‰€ä»¥å–å¹‚ï¼Œæ˜¯ä¸ºäº†è§£å†³åœ¨åæ–¹å·®ä¼°è®¡ä¸­å°æ ·æœ¬é«˜ç»´åº¦çš„é—®é¢˜ï¼Œä»¥resnetä¸ºä¾‹ï¼Œæœ€åå¾—åˆ°çš„featureä¸º7X7X512ï¼Œä¹Ÿå°±æ˜¯49ä¸ª512ç»´çš„featureï¼Œè¿™æ ·ä¼°è®¡å‡ºæ¥çš„åæ–¹å·®çŸ©é˜µæ˜¯ä¸é è°±çš„ï¼Œè€Œé€šè¿‡å¹‚è¿™ä¸ªæ“ä½œï¼Œå¯ä»¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚é€šè¿‡å®éªŒå¯ä»¥å‘ç°ï¼Œå½“å¹‚æ¬¡ä¸º0.5ä¹Ÿå°±æ˜¯å¹³æ–¹æ ¹æ“ä½œæ—¶ï¼Œæ•ˆæœæœ€ä¼˜ã€‚ï¼ˆä¼¼ä¹ç±»ä¼¼çš„æœ‰word2vecçš„å¹³æ»‘ï¼‰</p>
<p>ï¼ˆè™½ç„¶è¿™ç¯‡æœ‰äº›çœ‹ä¸å¤§æ‡‚ï¼Œä½†ä¸€ä¸ªå¯å‘å°±æ˜¯ï¼Œå¯ä»¥é€šè¿‡åæ–¹å·®çš„æ–¹å¼è¿›è¡Œç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼‰</p>
<hr>
<h2 id="2ï¸âƒ£-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification"><a href="#2ï¸âƒ£-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification" class="headerlink" title="2ï¸âƒ£[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]"></a>2ï¸âƒ£[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]</h2><p>æå‡ºä½¿ç”¨å·ç§¯å‡ºæ¥åçš„featureç»è¿‡poolingä½œä¸ºæœ€åçš„å›¾åƒç‰¹å¾è¡¨ç¤ºè€Œä¸æ˜¯å…¨è¿æ¥åçš„ç‰¹å¾è¡¨ç¤ºã€‚</p>
<p>Motivationï¼šåªä½¿ç”¨æœ€åä¸€å±‚fcçš„ç‰¹å¾æœ‰ä¸€ä¸ªç¼ºç‚¹ï¼Œå°±æ˜¯ä¸¢å¤±ä½ç½®ä¿¡æ¯ï¼Œè€Œconvolution layeråŒ…å«äº†ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯ã€‚åœ¨poolingå®Œåæ¯ä¸ªlocalåŒºåŸŸéƒ½èƒ½è·å¾—ä¸€ä¸ªç‰¹å¾ï¼Œå¹¶æ‹¼æ¥èµ·æ¥ä½œä¸ºæœ€åçš„è¡¨ç¤ºã€‚</p>
<p><img src="/images/15533936911589.jpg" width="60%" height="50%"></p>
<p>prerequisite:<br>â‘ é¦–å…ˆæœ‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹<br>â‘¡æœ‰ä¸¤å±‚ä¸€æ ·$H\times W$çš„convolutionã€‚è®ºæ–‡ä»¥AlexNetä½œä¸ºä¾‹å­</p>
<p>å‡è®¾å·ç§¯åçš„feature mapæ˜¯$H Ã— W Ã— D$ï¼Œé‚£ä¹ˆå¯ä»¥ç†è§£æˆï¼Œæˆ‘ä»¬å°†å›¾ç‰‡åˆ†ä¸º$H Ã— W$çš„åŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸçš„ç‰¹å¾ç”¨$D$ç»´è¡¨ç¤ºã€‚æˆ‘ä»¬ç§°æ¯ä¸ª$D$ç»´ç‰¹å¾ä¸€ä¸ªspatial unitã€‚å½“ä½¿ç”¨å…¨è¿æ¥æ—¶ï¼Œè¿™éƒ¨åˆ†çš„ç©ºé—´ä¿¡æ¯å°±ä¸¢å¤±äº†ï¼Œå¹¶ä¸”æ— æ³•è¿˜åŸã€‚</p>
<p>æœ¬æ–‡æå‡ºï¼Œå°†æ¯ä¸ªåŒºåŸŸæå–å‡ºä¸€ä¸ªç‰¹å¾ï¼Œç„¶åæ‹¼èµ·æ¥ç»„æˆä¸€æ•´å¼ å›¾çš„ç‰¹å¾ï¼Œå¦‚ä¸‹å›¾ï¼Œæ¯ä¸ªé•¿æ¡ï¼ˆä¹Ÿå³$1\times 1\times channel$ï¼‰ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼š</p>
<p><img src="/images/15533939765641.jpg" width="50%" height="50%"></p>
<p>å¦‚ä½•åˆ¤æ–­åŒºåŸŸï¼Ÿä¸€ç§æ–¹æ³•æ˜¯é¦–å…ˆæ£€æµ‹å‡ºå¤šä¸ªåŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸå¯¹åº”ä¸€ç§object partï¼Œç„¶åå¯¹äºè½å…¥è¯¥åŒºåŸŸçš„ç‰¹å¾è¿›è¡Œpoolingï¼Œç»™å®šDç§human-specified object partsï¼Œé‚£ä¹ˆå¯ä»¥è·å¾—Dä¸ªfeatureä¸”æ‹¼åœ¨ä¸€èµ·ã€‚</p>
<script type="math/tex; mode=display">\mathbf{P}_{k}^{t}=\sum_{i=1} \mathbf{x}_{i} I_{i, k}</script><p>å…·ä½“è€Œè¨€ï¼Œ$\mathbf{x}_{i}$æ˜¯ç‰¹å¾ï¼Œ$I_{i, k}$æ˜¯äºŒå…ƒçš„indicatorï¼Œè¡¨æ˜$\mathbf{x}_{i}$æ˜¯å¦è½å…¥è¯¥åŒºåŸŸï¼Œæ¯ä¸ª$I$å®é™…ä¸Šå®šä¹‰äº†ä¸€ä¸ªæ± åŒ–é€šé“ã€‚å½“ç„¶ï¼Œè¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å°†indicatorä»äºŒå…ƒæ‰©å±•ä¸ºæƒé‡ã€‚</p>
<p>ä½†åœ¨å®ç°çš„è¿‡ç¨‹ä¸­ï¼Œå¹¶æ²¡æœ‰human-specifiedçš„åŒºåŸŸã€‚è¿™é‡Œæˆ‘ä»¬å°±å€ŸåŠ©ä¸‹ä¸€å±‚çš„å·ç§¯ä½œä¸ºindicatorã€‚</p>
<blockquote>
<p>By doing so, D t+1 pooling channels are created for the local features extracted from the tth convolutional layer</p>
</blockquote>
<p>è¿™ä¹Ÿå°±è¢«ç§°ä¸ºcross-convolutional-layer poolingã€‚</p>
<p>å¦‚ä½•åšï¼Ÿ</p>
<blockquote>
<p>the filter of a convolutional layer works as a part detector and its feature map serves a similar role as the part region indicator map.</p>
</blockquote>
<p>å…·ä½“è€Œè¨€ï¼Œæœ‰ï¼š</p>
<script type="math/tex; mode=display">\begin{array}{l}{\mathbf{P}^{t}=\left[\mathbf{P}_{1}^{t}, \mathbf{P}_{2}^{t}, \cdots, \mathbf{P}_{k}^{t}, \cdots, \mathbf{P}_{D_{t+1}}^{t}\right]} \\ {\text { where, } \mathbf{P}_{k}^{t}=\sum_{i=1}^{N_{t}} \mathbf{x}_{i}^{t} a_{i, k}^{t+1}}\end{array}</script><p>$\mathbf{P}^{t}$è¡¨ç¤ºç¬¬tå±‚convolutionåœ¨å·ç§¯è¿‡ååšcross-poolingåçš„ç‰¹å¾é›†åˆï¼Œä¹Ÿå³æˆ‘ä»¬è¦è·å¾—çš„è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºé€šè¿‡$D_{t+1}$æ¬¡poolingåçš„ç»“æœæ‹¼æ¥è€Œæˆã€‚$D_{t+1}$å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯ç¬¬t+1å±‚çš„å·ç§¯çš„channelç»´æ•°ã€‚å‡è®¾$\mathbf{a}_{i}^{t+1} \in \mathbb{R}^{D_{t+1}}$æ˜¯ç¬¬t+1å±‚convolutionçš„ç¬¬iä¸ªç©ºé—´å•ä½ï¼ˆspatial unitï¼‰çš„feature vectorï¼Œå…¶ä¸­$a_{i, k}^{t+1}$æ˜¯è¯¥å‘é‡çš„ä¸€ä¸ªå€¼ï¼Œè¯¥å€¼å°±ä½œä¸ºpoolingçš„æƒé‡ã€‚</p>
<p>ä¸Šè¿°æœ‰äº›ç»•å£ä¸”éš¾æ‡‚ï¼Œç›´æ¥çœ‹ä¾‹å­ï¼š<br><img src="/images/15533957004853.jpg" width="80%" height="50%"><br><img src="/images/15533957336100.jpg" width="80%" height="50%"></p>
<p>å³ï¼Œç¬¬t+1å±‚convolutionçš„channelç»´åº¦ä¸ºå¤šå°‘ï¼Œåˆ™poolingåçš„ç‰¹å¾ä¸ªæ•°å³ä¸ºå¤šå°‘ã€‚å› ä¸ºç¬¬tå±‚ä¸ç¬¬t+1å±‚çš„$H\times W$æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆå¯ä»¥ç”¨t+1å±‚çš„æ¯ä¸ªsliceå»å¯¹ç¬¬tå±‚çš„convolutionè¿›è¡ŒåŠ æƒã€‚</p>
<p>ä¸ºä»€ä¹ˆè¿™æ ·æ˜¯åˆç†çš„ï¼Ÿ<br>å› ä¸ºç¬¬t+1å±‚çš„convolutionæå–äº†$D_{t+1}$ä¸ªç‰¹å¾ï¼Œä½¿ç”¨çš„æ˜¯$m\times n$çš„kernel sizeï¼Œå¦‚æœ$x$æ˜¯è¢«$m\times n$çš„æŸä¸ªkernelæå–äº†ï¼Œé‚£ä¹ˆå¾ˆè‡ªç„¶çš„ï¼Œ$x$å°±æ˜¯å¯¹åº”è¯¥kernelæå–å‡ºæ¥çš„featureçš„ä¸€ä¸ªspatial unitã€‚è¯´ç™½äº†å°±æ˜¯ç¬¬tå±‚ä¸ç¬¬t+1å±‚çš„ç©ºé—´å¯¹åº”ã€‚</p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>second-order</tag>
        <tag>pooling</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯20</title>
    <url>/2019/03/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D20/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰"><a href="#1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰" class="headerlink" title="1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰"></a>1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰</h3><p>[ä¸‰å›½] æ›¹æ¤<br>å—å›½æœ‰ä½³äººï¼Œå®¹åè‹¥æ¡ƒæã€‚<br>æœæ¸¸æ±ŸåŒ—å²¸ï¼Œå¤•å®¿æ½‡æ¹˜æ²šã€‚<br>æ—¶ä¿—è–„æœ±é¢œï¼Œè°ä¸ºå‘çš“é½¿ï¼Ÿ<br>ä¿¯ä»°å²å°†æš®ï¼Œè£è€€éš¾ä¹…æƒã€‚</p>
<p><a href="http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f" target="_blank" rel="noopener">http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f</a></p>
<hr>
<h3 id="2ï¸âƒ£æ¢¦æ±Ÿå—"><a href="#2ï¸âƒ£æ¢¦æ±Ÿå—" class="headerlink" title="2ï¸âƒ£æ¢¦æ±Ÿå—"></a>2ï¸âƒ£æ¢¦æ±Ÿå—</h3><p>[å”] æ¸©åº­ç­ <br>åƒä¸‡æ¨ï¼Œæ¨æåœ¨å¤©æ¶¯ã€‚å±±æœˆä¸çŸ¥å¿ƒé‡Œäº‹ï¼Œæ°´é£ç©ºè½çœ¼å‰èŠ±ï¼Œæ‘‡æ›³ç¢§äº‘æ–œã€‚</p>
<p><a href="http://lib.xcz.im/work/57b8d0c77db2a2005425c856" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8d0c77db2a2005425c856</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡13</title>
    <url>/2019/03/17/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8713/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation"><a href="#1ï¸âƒ£-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation" class="headerlink" title="1ï¸âƒ£[Depthwise Separable Convolutions for Neural Machine Translation]"></a>1ï¸âƒ£[Depthwise Separable Convolutions for Neural Machine Translation]</h2><p>å°†depthwise separable convolution æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ç”¨äºç¿»è¯‘ä»»åŠ¡ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹depthwise separableè¿›è¡Œæ›´è¿›ä¸€æ­¥çš„å‚æ•°é‡ä¼˜åŒ–ï¼Œä¹Ÿå³super-separableã€‚ï¼ˆå…¶å®æˆ‘è§‰å¾—å¹¶æ²¡æœ‰å•¥åˆ›æ–°æ€§çš„æ„Ÿè§‰ï¼‰</p>
<p><img src="/images/15528281403428.jpg" width="90%" height="50%"></p>
<p>é¦–å…ˆä»‹ç»ä»€ä¹ˆæ˜¯depthwise separable convolutionï¼Œå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªdepthwise+pointwiseã€‚</p>
<script type="math/tex; mode=display">\operatorname{Conv}(W, y)_{(i, j)}=\sum_{k, l, m}^{K, L, M} W_{(k, l, m)} \cdot y_{(i+k, j+l, m)}</script><script type="math/tex; mode=display">\operatorname{PointwiseConv}(W, y)_{(i, j)}=\sum_{m}^{M} W_{m} \cdot y_{(i, j, m)}</script><script type="math/tex; mode=display">\text {DepthwiseConv}(W, y)_{(i, j)}=\sum_{k, l}^{K, L} W_{(k, l)} \odot y_{(i+k, j+l)}</script><script type="math/tex; mode=display">\operatorname{SepConv}\left(W_{p}, W_{d}, y\right)_{(i, j)}=\text {PointwiseConv}_{(i, j)}\left(W_{p}, \text { DepthwiseConv }_{(i, j)}\left(W_{d}, y\right)\right)</script><p>å‡ ç§convolutionçš„å‚æ•°é‡å¯¹æ¯”ï¼š<br><img src="/images/15528283555357.jpg" width="80%" height="50%"><br>å…¶ä¸­kæ˜¯kernel sizeï¼Œcæ˜¯channelï¼Œgæ˜¯groupã€‚</p>
<p>g-Sub-separableæ˜¯æŒ‡å°†channelåˆ†ä¸ºå‡ ä¸ªgroupï¼Œæ¯ä¸ªgroupè¿›è¡Œå¸¸è§„çš„convolutionæ“ä½œï¼›g-Super-separableï¼Œä¹Ÿå³æœ¬æ–‡ä¸­æå‡ºçš„convolutionï¼ŒåŒæ ·æ˜¯å°†channelåˆ†ä¸ºå‡ ä¸ªgroupï¼Œç„¶åå¯¹æ¯ä¸ªgroupè¿›è¡Œdepthwise-separableçš„å·ç§¯ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Squeeze-and-Excitation-Networks"><a href="#2ï¸âƒ£-Squeeze-and-Excitation-Networks" class="headerlink" title="2ï¸âƒ£[Squeeze-and-Excitation Networks]"></a>2ï¸âƒ£[Squeeze-and-Excitation Networks]</h2><p>æå‡ºä¸€ç§æ–°å‹çš„ç½‘ç»œï¼Œèƒ½å¤Ÿé€šè¿‡å»ºæ¨¡channelä¹‹é—´çš„å…³ç³»ï¼Œä½¿å¾—æ¯ä¸ªchannelèƒ½å¤Ÿè·å¾—å…¨å±€çš„ä¿¡æ¯ï¼Œè¿›è€Œæé«˜æ¨¡å‹çš„èƒ½åŠ›ã€‚<br><img src="/images/15528285519609.jpg" width="90%" height="50%"></p>
<p>åˆ†ä¸ºä¸¤æ­¥ï¼šç¬¬ä¸€æ­¥æ˜¯è·å¾—ä¸€ä¸ªå…¨å±€çš„è¡¨ç¤ºï¼Œç¬¬äºŒæ­¥æ˜¯æ ¹æ®å…¨å±€ä¿¡æ¯æ›´æ–°æ¯ä¸ªchannelçš„ä¿¡æ¯ã€‚</p>
<h3 id="ç¬¦å·"><a href="#ç¬¦å·" class="headerlink" title="ç¬¦å·"></a>ç¬¦å·</h3><p>è¾“å…¥ï¼š$ \mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}} $<br>ç»è¿‡ç‰¹å¾æå–åï¼ˆå¦‚Convolution)ï¼š$\mathbf{U} \in \mathbb{R}^{H \times W \times C}$ï¼Œä¹Ÿå³ï¼š$\mathbf{U}=\mathbf{F}_{t r}(\mathbf{X})$<br>å°†$\mathbf{U}$å†™æˆï¼š$\mathbf{U}=\left[\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{C}\right]$<br>$\mathbf{V}$ æ˜¯å¯å­¦ä¹ çš„å·ç§¯æ ¸å‚æ•°ï¼š $\mathbf{V}=\left[\mathbf{v}_{1}, \mathbf{v}_{2}, \ldots, \mathbf{v}_{C}\right]$</p>
<p>åˆ™ä¸Šè¿°å·ç§¯å˜æ¢å¯å†™æˆï¼š$\mathbf{u}_{c}=\mathbf{v}_{c} \ast \mathbf{X}=\sum_{s=1}^{C^{\prime}} \mathbf{v}_{c}^{s} \ast \mathbf{x}^{s}$</p>
<h3 id="Squeeze-Global-Information-Embedding"><a href="#Squeeze-Global-Information-Embedding" class="headerlink" title="Squeeze: Global Information Embedding"></a>Squeeze: Global Information Embedding</h3><p>ç¬¬ä¸€æ­¥ï¼Œå°†æ‰€æœ‰çš„ç‰¹å¾è¿›è¡Œæ•´åˆå¾—åˆ°å…¨å±€çš„ç‰¹å¾ï¼š</p>
<script type="math/tex; mode=display">z_{c}=\mathbf{F}_{s q}\left(\mathbf{u}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} u_{c}(i, j)</script><p>è®ºæ–‡æå–å…¨å±€ç‰¹å¾çš„æ–¹æ³•ç›´æ¥ç”¨ç®€å•çš„global average poolingã€‚é‚£ä¹ˆ$\mathbf{z} \in \mathbb{R}^{C}$çš„æ¯ä¸€ç»´å°±ä»£è¡¨æ¯ä¸€ç»´çš„channelã€‚</p>
<h3 id="Excitation-Adaptive-Recalibration"><a href="#Excitation-Adaptive-Recalibration" class="headerlink" title="Excitation: Adaptive Recalibration"></a>Excitation: Adaptive Recalibration</h3><p>ä¸attentionä¸åŒçš„æ˜¯ï¼Œè®ºæ–‡å¸Œæœ›èƒ½å¤ŸåŒæ—¶å¼ºè°ƒä¸åŒå¤šä¸ªchannelçš„é‡è¦ï¼ˆè€Œä¸æ˜¯one-hotçš„å½¢å¼ï¼‰ï¼Œå› æ­¤ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é—¨æ§åˆ¶æœºåˆ¶ï¼Œé‡‡ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼šï¼ˆè¿™é‡Œçš„æƒ³æ³•æŒºæœ‰æ„æ€ï¼Œç›¸å¯¹attentionçš„softmaxä¼¼ä¹ç¡®å®ä¼šæ›´å¥½çš„æ ·å­ï¼‰</p>
<script type="math/tex; mode=display">\mathbf{s}=\mathbf{F}_{ex}(\mathbf{z}, \mathbf{W})=\sigma(g(\mathbf{z}, \mathbf{W}))=\sigma\left(\mathbf{W}_{2} \delta\left(\mathbf{W}_{1} \mathbf{z}\right)\right)</script><p>ä¸ºäº†å‡å°‘å‚æ•°è¿™é‡Œçš„MLPé‡‡ç”¨äº†bottleneckçš„å½¢å¼ã€‚äº¦å³ï¼š<br>${\mathbf{W}_{1} \in \mathbb{R}^{\frac{C}{r} \times C}}$ $ {\mathbf{W}_{2} \in \mathbb{R}^{C \times \frac{C}{r}}}$<br>$r$æ˜¯reduction ratioã€‚</p>
<p>è´´ä¸Šä½œè€…çš„æ€è·¯ï¼š</p>
<blockquote>
<p>To make use of the information aggregated in the squeeze operation, we follow it with a second operation which aims to fully capture channel-wise dependencies. To fulfill this objective, the function must meet two criteria: first, it must be ï¬‚exible (in particular, it must be capable of learning a nonlinear interaction between channels) and second, it must learn a non-mutually-exclusive relationship since we would like to ensure that multiple channels are allowed to be emphasised (rather than enforcing a one-hot activation). To meet these criteria, we opt to employ a simple gating mechanism with a sigmoid activation.</p>
</blockquote>
<p>æœ€åå¯¹æ¯ä¸ªchannelè¿›è¡Œ<strong>æ”¾ç¼©</strong>ï¼Œè·å¾—æ–°çš„è¡¨ç¤ºï¼š</p>
<script type="math/tex; mode=display">\widetilde{\mathbf{x}}_{c}=\mathbf{F}_{\text {scale}}\left(\mathbf{u}_{c}, s_{c}\right)=s_{c} \cdot \mathbf{u}_{c}</script><hr>
<h2 id="3ï¸âƒ£-Non-local-Neural-Networks"><a href="#3ï¸âƒ£-Non-local-Neural-Networks" class="headerlink" title="3ï¸âƒ£[Non-local Neural Networks]"></a>3ï¸âƒ£[Non-local Neural Networks]</h2><p>æå‡ºä¸€ç§æ–°çš„ç»“æ„ï¼Œä¸ä¸Šä¸€ç¯‡ç±»ä¼¼ï¼Œå¸Œæœ›æ¨¡å‹çš„æ¯ä¸ªä½ç½®éƒ½èƒ½æ„ŸçŸ¥åˆ°å…¶ä»–ä½ç½®ï¼Œä»è€Œæ•è·é•¿ç¨‹ä¾èµ–ï¼Œæ‹¥æœ‰å…¨å±€ä¿¡æ¯ã€‚</p>
<p><img src="/images/15528297540165.jpg" width="60%" height="50%"></p>
<h3 id="Non-local-Network"><a href="#Non-local-Network" class="headerlink" title="Non-local Network"></a>Non-local Network</h3><p>å®šä¹‰non-localç½‘ç»œï¼š</p>
<script type="math/tex; mode=display">\mathbf{y}_{i}=\frac{1}{\mathcal{C}(\mathbf{x})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) g\left(\mathbf{x}_{j}\right)</script><p>å…¶ä¸­$\mathcal{C}$æ˜¯å½’ä¸€åŒ–å‡½æ•°ï¼›$f$æ˜¯ç¬¬$i$ä¸ªä½ç½®ä¸ç¬¬$j$ä¸ªä½ç½®çš„äº¤äº’å‡½æ•°ï¼›$g$è®¡ç®—ç¬¬$j$ä¸ªä½ç½®çš„è¡¨ç¤ºã€‚</p>
<h4 id="g-çš„å…·ä½“å½¢å¼"><a href="#g-çš„å…·ä½“å½¢å¼" class="headerlink" title="$g$çš„å…·ä½“å½¢å¼"></a>$g$çš„å…·ä½“å½¢å¼</h4><p>ä¸€ä¸ªçº¿æ€§å‡½æ•°ï¼š$g\left(\mathbf{x}_{j}\right)=W_{g} \mathbf{x}_{j}$<br>åœ¨å®ç°çš„æ—¶å€™æ˜¯ä¸€ä¸ª$1\times1$æˆ– $1\times1\times1$çš„convolutionã€‚</p>
<h4 id="f-çš„å…·ä½“å½¢å¼"><a href="#f-çš„å…·ä½“å½¢å¼" class="headerlink" title="$f$çš„å…·ä½“å½¢å¼"></a>$f$çš„å…·ä½“å½¢å¼</h4><p>â‘ Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\mathbf{x}_{i}^{T} \mathbf{x}_{j}}$<br>åˆ™å½’ä¸€åŒ–å®šä¹‰ä¸º$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$ ã€‚</p>
<p>â‘¡Embedded Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)}$<br>å…¶ä¸­ï¼š$\theta\left(\mathbf{x}_{i}\right)=W_{\theta} \mathbf{x}_{i} $, $ \phi\left(\mathbf{x}_{j}\right)=W_{\phi} \mathbf{x}_{j}$<br>å½’ä¸€åŒ–ï¼š$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$</p>
<p>å¯ä»¥çœ‹åˆ°self-attentionæ˜¯Embedded Gaussiançš„ä¸€ç§å½¢å¼ã€‚è™½ç„¶æœ‰è¿™æ ·çš„å…³ç³»ï¼Œä½†ä½œè€…åœ¨å®éªŒä¸­å‘ç°softmaxå¹¶ä¸æ˜¯å¿…è¦çš„ã€‚</p>
<p>â‘¢Dot product<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)$<br>å½’ä¸€åŒ–ï¼š$\mathcal{C}(\mathbf{x})=N$</p>
<p>â‘£Concatenation<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\operatorname{ReLU}\left(\mathbf{w}_{f}^{T}\left[\theta\left(\mathbf{x}_{i}\right), \phi\left(\mathbf{x}_{j}\right)\right]\right)$<br>$\mathcal{C}(\mathbf{x})=N$</p>
<p>æœ‰äº†ä¸Šé¢çš„non-localçš„ä»‹ç»ï¼Œå¯ä»¥ç›´æ¥å°†å…¶ç”¨äºresidual networkã€‚<br>$\mathbf{z}_{i}=W_{z} \mathbf{y}_{i}+\mathbf{x}_{i}$<br>$y$åˆ™æ˜¯non-local networkçš„è¾“å‡ºã€‚</p>
<h3 id="Non-local-blockçš„ç­–ç•¥-tricks"><a href="#Non-local-blockçš„ç­–ç•¥-tricks" class="headerlink" title="Non-local blockçš„ç­–ç•¥/tricks"></a>Non-local blockçš„ç­–ç•¥/tricks</h3><p>â‘ è®¾ç½®$W_g$,$W_Î¸$,$W_Ï•$çš„channelçš„æ•°ç›®ä¸ºxçš„channelæ•°ç›®çš„ä¸€åŠï¼Œè¿™æ ·å°±å½¢æˆäº†ä¸€ä¸ªbottleneckï¼Œèƒ½å¤Ÿå‡å°‘ä¸€åŠçš„è®¡ç®—é‡ã€‚Wzå†é‡æ–°æ”¾å¤§åˆ°xçš„channelæ•°ç›®ï¼Œä¿è¯è¾“å…¥è¾“å‡ºç»´åº¦ä¸€è‡´ã€‚</p>
<p>â‘¡åœ¨$\frac{1}{\mathcal{C}(\hat{\mathbf{x}})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \hat{\mathbf{x}}_{j}\right) g\left(\hat{\mathbf{x}}_{j}\right)$ä½¿ç”¨ä¸‹é‡‡æ ·ï¼Œå¦‚max-poolingï¼Œå‡å°‘è®¡ç®—é‡ã€‚</p>
<hr>
<h2 id="4ï¸âƒ£-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition"><a href="#4ï¸âƒ£-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition" class="headerlink" title="4ï¸âƒ£[Bilinear CNN Models for Fine-grained Visual Recognition]"></a>4ï¸âƒ£[Bilinear CNN Models for Fine-grained Visual Recognition]</h2><p>æå‡ºä¸€ç§åŒçº¿æ€§æ¨¡å‹ï¼Œç”±ä¸¤ä¸ªç‰¹å¾æå–å™¨ç»„æˆï¼Œä»–ä»¬çš„è¾“å‡ºåš<strong>å¤–ç§¯</strong>ï¼Œæœ€ç»ˆè·å¾—å›¾åƒæè¿°ç‰¹å¾ã€‚</p>
<p>Motivation(?ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™æ ·)ï¼šå¯¹äºç»†ç²’åº¦ç‰©ä½“çš„åˆ†ç±»ï¼Œå…ˆå¯¹å±€éƒ¨å®šä½ï¼Œå†æå–ç‰¹å¾ã€‚ä¸¤ä¸ªç‰¹å¾æå–å™¨ä¸€ä¸ªæ˜¯æå–locationï¼Œå¦ä¸€ä¸ªæå–ç‰¹å¾ã€‚</p>
<p><img src="/images/15528310057673.jpg" width="60%" height="50%"></p>
<p>ä¸ºä»€ä¹ˆç”¨<strong>å¤–ç§¯</strong>ï¼Ÿ</p>
<blockquote>
<p>outer product captures pairwise correlations between the feature channels</p>
</blockquote>
<p>æœ‰æ„æ€çš„æ˜¯ä½œè€…å°†è¯¥æ¨¡å‹å’Œäººè„‘è§†è§‰å¤„ç†çš„ä¸¤ä¸ªå‡è®¾è”ç³»åœ¨ä¸€èµ·(stream hypothesis)ï¼š<br>here are two main pathways, or â€œstreamsâ€. The ventral stream (or, â€œwhat pathwayâ€) is involved with object identiï¬cation and recognition. The dorsal stream (or, â€œwhere pathwayâ€) is involved with processing the objectâ€™s spatial location relative to the viewer.<br>ä¸è¿‡çœ‹çœ‹å°±å¥½ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆé“ç†ã€‚</p>
<p>å¯¹äºä¸€ä¸ªåˆ†ç±»çš„åŒçº¿æ€§æ¨¡å‹è€Œè¨€ï¼Œå…¶ä¸€èˆ¬å½¢å¼æ˜¯ä¸€ä¸ªå››å…ƒç»„ï¼š$\mathcal{B}=\left(f_{A}, f_{B}, \mathcal{P}, \mathcal{C}\right)$ã€‚å…¶ä¸­$f$æ˜¯ç‰¹å¾å‡½æ•°ï¼Œ$\mathcal{P}$æ˜¯poolingå‡½æ•°ï¼Œ$\mathcal{C}$æ˜¯åˆ†ç±»å‡½æ•°ã€‚å…·ä½“è€Œè¨€ï¼Œ$f$æ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œ${f : \mathcal{L} \times \mathcal{I} \rightarrow} {R^ {c\times D}} $ã€‚ä¹Ÿå³å°†ä¸€ä¸ªimageå’Œä¸€ä¸ªlocation L æ˜ å°„æˆfeatureã€‚ï¼ˆWe refer to locations generally which can include position and scale å…¶å®è¿™é‡Œä¸æ˜¯å¾ˆæ‡‚locationçš„æ„æ€ï¼‰</p>
<p>å°†feature aå’Œfeature bç»“åˆåœ¨ä¸€èµ·ï¼š<br>$\text { bilinear }\left(l, \mathcal{I}, f_{A}, f_{B}\right)=f_{A}(l, \mathcal{I})^{T} f_{B}(l, \mathcal{I})$</p>
<p>poolingæœ‰å¥½å‡ ç§ï¼Œå¯ä»¥ç›´æ¥åŠ èµ·æ¥ï¼Œæˆ–è€…ä½¿ç”¨max-poolingã€‚è¿™é‡Œä½¿ç”¨ç›´æ¥åŠ èµ·æ¥çš„æ–¹å¼ï¼Œå¯ä»¥ç†è§£ä¸ºï¼Œè¿™äº›ç‰¹å¾æ˜¯æ— åº(orderless)çš„å åŠ ã€‚</p>
<p>åœ¨è·å¾—è¾“å‡ºåå†åšä¸€äº›æ“ä½œ/trickèƒ½å¤Ÿæå‡è¡¨ç°ï¼š<br>$\begin{array}{l}{\mathbf{y} \leftarrow \operatorname{sign}(\mathbf{x}) \sqrt{|\mathbf{x}|}} \\ {\mathbf{z} \leftarrow \mathbf{y} /|\mathbf{y}|_{2}}\end{array}$</p>
<p>è®¨è®ºï¼š<br>â‘ But do the networks specialize into roles of localization (â€œwhereâ€) and appearance modeling (â€œwhatâ€) when initialized asymmetrically and ï¬ne-tuned?<br>é€šè¿‡å¯è§†åŒ–å‘ç°ï¼Œå¹¶æ²¡æœ‰æ˜ç¡®çš„åŠŸèƒ½åˆ†å¼€ã€‚<br>Both these networks tend to activate strongly on highly speciï¬c semantic parts</p>
<p>â‘¡bilinearçš„å¥½å¤„è¿˜å¯ä»¥æ‰©å±•æˆtrilinearï¼Œæ·»åŠ æ›´å¤šçš„ä¿¡æ¯ã€‚</p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>SE-Net</tag>
        <tag>Non-local</tag>
        <tag>Bilinear</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯19</title>
    <url>/2019/03/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D19/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£é€çµæ¾ˆä¸Šäºº"><a href="#1ï¸âƒ£é€çµæ¾ˆä¸Šäºº" class="headerlink" title="1ï¸âƒ£é€çµæ¾ˆä¸Šäºº"></a>1ï¸âƒ£é€çµæ¾ˆä¸Šäºº</h3><p>[å”] åˆ˜é•¿å¿<br>è‹è‹ç«¹æ—å¯ºï¼Œæ³æ³é’Ÿå£°æ™šã€‚<br>è·ç¬ å¸¦æ–œé˜³ï¼Œé’å±±ç‹¬å½’è¿œã€‚</p>
<p>è·ï¼ˆhÃ¨ï¼‰ç¬ ï¼šèƒŒç€æ–—ç¬ ã€‚</p>
<p><a href="http://lib.xcz.im/work/57b90887128fe10054c9c750" target="_blank" rel="noopener">http://lib.xcz.im/work/57b90887128fe10054c9c750</a></p>
<hr>
<h3 id="2ï¸âƒ£è‹å¹•é®-Â·-æ€€æ—§"><a href="#2ï¸âƒ£è‹å¹•é®-Â·-æ€€æ—§" class="headerlink" title="2ï¸âƒ£è‹å¹•é® Â· æ€€æ—§"></a>2ï¸âƒ£è‹å¹•é® Â· æ€€æ—§</h3><p>[å®‹] èŒƒä»²æ·¹<br>ç¢§äº‘å¤©ï¼Œé»„å¶åœ°ï¼Œç§‹è‰²è¿æ³¢ï¼Œæ³¢ä¸Šå¯’çƒŸç¿ ã€‚å±±æ˜ æ–œé˜³å¤©æ¥æ°´ï¼ŒèŠ³è‰æ— æƒ…ï¼Œæ›´åœ¨æ–œé˜³å¤–ã€‚<br>é»¯ä¹¡é­‚ï¼Œè¿½æ—…æ€ã€‚å¤œå¤œé™¤éï¼Œå¥½æ¢¦ç•™äººç¡ã€‚æ˜æœˆæ¥¼é«˜ä¼‘ç‹¬å€šï¼Œé…’å…¥æ„è‚ ï¼ŒåŒ–ä½œç›¸æ€æ³ªã€‚</p>
<p><a href="http://lib.xcz.im/work/57b8ee4a128fe10054c91757" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8ee4a128fe10054c91757</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡12</title>
    <url>/2019/03/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8712/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS"><a href="#1ï¸âƒ£-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS" class="headerlink" title="1ï¸âƒ£[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]"></a>1ï¸âƒ£[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]</h2><p>Facebookç ”ç©¶äººå‘˜æå‡ºçš„ä¸¤ç§åŸºäºå·ç§¯çš„æ–¹æ³•å°è¯•æ›¿ä»£self-attentionåœ¨transformerä¸­çš„ä½œç”¨ï¼Œæ‹¥æœ‰æ›´å°‘çš„å‚æ•°ä»¥åŠæ›´å¿«çš„é€Ÿåº¦ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚</p>
<p><img src="/images/15521843619624.jpg" width="80%" height="80%"></p>
<h3 id="Lightweight-convolution"><a href="#Lightweight-convolution" class="headerlink" title="Lightweight convolution"></a>Lightweight convolution</h3><p>èƒŒæ™¯ï¼šdepthwise convolution<br>æ¯ä¸ªchannelç‹¬ç«‹è¿›è¡Œå·ç§¯ï¼Œæ³¨æ„åˆ°æ”¾åˆ°NLPä»»åŠ¡ä¸Šchannelæ˜¯æŒ‡embeddingçš„æ¯ä¸€ç»´ã€‚</p>
<script type="math/tex; mode=display">O_{i, c}=\text{DepthwiseConv}\left(X, W_{c, :}, i, c\right)=\sum_{j=1}^{k} W_{c, j} \cdot X_{\left(i+j-\left\lceil\frac{k+1}{2}\right]\right), c}</script><p>å› æ­¤Lightweight convolutionçš„è®¡ç®—æ–¹æ³•ä¸ºï¼š</p>
<script type="math/tex; mode=display">\operatorname{LightConv}\left(X, W_{\left\lceil\frac{c H}{d}\right\rceil,:}, i, c\right)=\text { DepthwiseConv}\left(X, \text{softmax}(W_{\left\lceil\frac{c H}{d}\right\rceil,:}), i, c\right)</script><p>æ¯ä¸€å±‚éƒ½æœ‰å›ºå®šçš„window sizeï¼Œè¿™å’Œself-attentionä¸åŒï¼Œself-attentionæ˜¯æ‰€æœ‰çš„contextéƒ½è¿›è¡Œäº¤äº’ã€‚</p>
<ul>
<li>Weight sharing æ³¨æ„åˆ°è¿™é‡Œè®²æ¯d/Hä¸ªchannelçš„å‚æ•°è¿›è¡Œç»‘å®šï¼Œè¿›ä¸€æ­¥å‡å°‘å‚æ•°ã€‚</li>
<li>Softmax-normalization å¯¹channelä¸€ç»´è¿›è¡Œsoftmaxï¼Œç›¸å½“äºå½’ä¸€åŒ–æ¯ä¸ªè¯çš„æ¯ä¸€ç»´çš„çš„é‡è¦æ€§ï¼ˆæ¯”self-attentionæ›´ç²¾ç»†ï¼‰ã€‚å®éªŒè¯æ˜ï¼Œå¦‚æœæ²¡æœ‰softmaxæ²¡åŠæ³•æ”¶æ•›ã€‚</li>
</ul>
<p>å› æ­¤æ€»ä½“çš„æ¶æ„ä¸ºï¼š<br>inputâ€”&gt;linear â€”&gt; GLU(gated linear unit) â€”&gt; lightconv/dynamicConv â€”&gt; linear</p>
<h3 id="Dynamic-convolution"><a href="#Dynamic-convolution" class="headerlink" title="Dynamic convolution"></a>Dynamic convolution</h3><p>ä¸lightweight convolutionç›¸ä¼¼ï¼Œä½†åŠ äº†ä¸€ä¸ªåŠ¨æ€çš„kernel sizeã€‚</p>
<script type="math/tex; mode=display">\text { DynamicConv}( X , i , c ) = \operatorname{LightConv}\left(X, f\left(X_{i}\right)_{h,:}, i, c\right)</script><p>è¿™é‡Œçš„kernel sizeç®€å•ä½¿ç”¨çº¿æ€§æ˜ å°„ï¼š$f : \mathbb { R } ^ { d } \rightarrow \mathbb { R } ^ { H \times k }$<br>å¦‚ï¼š$f\left(X_{i}\right)=\sum_{c=1}^{d} W_{h, j, c}^{Q} X_{i, c}$</p>
<hr>
<h2 id="2ï¸âƒ£-Joint-Embedding-of-Words-and-Labels-for-Text-Classiï¬cation"><a href="#2ï¸âƒ£-Joint-Embedding-of-Words-and-Labels-for-Text-Classiï¬cation" class="headerlink" title="2ï¸âƒ£[Joint Embedding of Words and Labels for Text Classiï¬cation]"></a>2ï¸âƒ£[Joint Embedding of Words and Labels for Text Classiï¬cation]</h2><p>æå‡ºä¸€ç§æœºåˆ¶å°†labelä½œä¸ºembeddingä¸è¯ä¸€åŒè®­ç»ƒï¼ŒåŒæ—¶å¼•å…¥labelå’Œwordçš„attentionæœºåˆ¶ï¼Œåœ¨åˆ†ç±»ä¸Šè·å¾—æ•ˆæœã€‚</p>
<p><img src="/images/15521854844061.jpg" width="40%" height="50%"></p>
<p>ä¸Šå›¾ä¸­ï¼ŒCæ˜¯label embeddingï¼Œç»´åº¦ä¸º$P\times K$ ; Væ˜¯å¥å­æ‰€æœ‰è¯çš„embeddingçŸ©é˜µï¼Œç»´åº¦ä¸º$P\times L$ã€‚<br>$\mathbf{G}$çš„è®¡ç®—å…¬å¼ä¸ºï¼š</p>
<script type="math/tex; mode=display">\mathbf{G}=\left(\mathbf{C}^{\top} \mathbf{V}\right) \oslash \hat{\mathbf{G}}</script><p>$\oslash$è¡¨ç¤ºelement-wiseç›¸é™¤ã€‚$\hat{\mathbf{G}}$è¡¨ç¤ºl2 normï¼Œä¹Ÿå³ï¼š</p>
<script type="math/tex; mode=display">\hat{g}_{k l}=\left\|\boldsymbol{c}_{k}\right\|\left\|\boldsymbol{v}_{l}\right\|</script><p>å› æ­¤å…¬å¼çš„æœ¬è´¨å³åœ¨è®¡ç®—labelä¸æ¯ä¸ªè¯çš„cosè·ç¦»ã€‚</p>
<p>åœ¨è·å¾—äº†$\mathbf{G}$åï¼Œä¸ºäº†è·å¾—æ›´é«˜çš„çš„è¡¨ç¤ºï¼Œå¦‚phraseï¼Œå°†ä¸€ä¸ªä¸€ä¸ªblockå–å‡ºï¼Œå¹¶è¿‡çº¿æ€§å±‚ï¼š</p>
<script type="math/tex; mode=display">\boldsymbol{u}_{l}=\operatorname{ReLU}\left(\mathbf{G}_{l-r : l+r} \mathbf{W}_{1}+\boldsymbol{b}_{1}\right)</script><p>æ¥ç€å¯¹æ¯ä¸ª$\boldsymbol{u}_{l}$å–æœ€å¤§å€¼ï¼š</p>
<script type="math/tex; mode=display">m_{l}=\textbf{max-pooling}\left(\boldsymbol{u}_{l}\right)</script><p>æ­¤æ—¶çš„$\mathbf{m}$æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºLçš„å‘é‡ã€‚æœ€ç»ˆå¯¹måšsoftmaxè·å¾—ä¸€ä¸ªåˆ†æ•°çš„åˆ†å¸ƒï¼š</p>
<script type="math/tex; mode=display">\boldsymbol{\beta}=\operatorname{SoftMax}(\boldsymbol{m})</script><p>å°†è¯¥åˆ†æ•°å’Œæ¯ä¸ªè¯åšåŠ æƒæ±‚å’Œï¼Œè·å¾—æœ€ç»ˆçš„å‘é‡è¡¨ç¤ºï¼š</p>
<script type="math/tex; mode=display">\boldsymbol{z}=\sum_{l} \beta_{l} \boldsymbol{v}_{l}</script><p>æ€è€ƒï¼šå°†labelä¸embeddingæ”¾åœ¨ä¸€èµ·è®­ç»ƒè¿™ä¸ªæ€è·¯ä¸é”™ã€‚ä½†æ•´åˆçš„æ–¹å¼æ˜¯å¦è¿‡äºç®€å•ç²—æš´äº†<br>ï¼Ÿç‰¹åˆ«æ˜¯phraseçš„æå–å’Œéšåçš„max-poolingçš„å¯è§£é‡Šæ€§å¹¶ä¸å¼ºçš„æ ·å­ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>Convolution</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>embedding</tag>
        <tag>text classification</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†18</title>
    <url>/2019/03/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8618/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Depthwise-seperable-convolution"><a href="#1ï¸âƒ£-Depthwise-seperable-convolution" class="headerlink" title="1ï¸âƒ£[Depthwise seperable convolution]"></a>1ï¸âƒ£[Depthwise seperable convolution]</h3><p>Depthwise seperable convolution = depthwise + pointwise<br>å…ˆæ¯ä¸ªå·ç§¯æ ¸ç‹¬ç«‹å¯¹ä¸€ä¸ªfeature mapè¿›è¡Œå·ç§¯ï¼Œå†é€šè¿‡ä¸€ä¸ª$1\times 1 \times n$çš„å·ç§¯æ ¸å¯¹feature mapè¿›è¡Œæ•´åˆã€‚</p>
<p><a href="https://blog.csdn.net/tintinetmilou/article/details/81607721" target="_blank" rel="noopener">https://blog.csdn.net/tintinetmilou/article/details/81607721</a></p>
<hr>
<h3 id="2ï¸âƒ£-å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr"><a href="#2ï¸âƒ£-å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr" class="headerlink" title="2ï¸âƒ£[å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr]"></a>2ï¸âƒ£[å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr]</h3><p>ä¸€ç§å¯å‘å¼çš„æ–¹æ³•ï¼š</p>
<blockquote>
<p>Over an epoch begin your SGD with a very low learning rate (like 10âˆ’8) but change it (by multiplying it by a certain factor for instance) at each mini-batch until it reaches a very high value (like 1 or 10). Record the loss each time at each iteration and once youâ€™re finished, plot those losses against the learning rate.</p>
</blockquote>
<p><a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html" target="_blank" rel="noopener">https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Convolution</tag>
        <tag>learning rate</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯18</title>
    <url>/2019/03/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D18/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£è¥¿æ±Ÿæœˆ-Â·-é£å…´"><a href="#1ï¸âƒ£è¥¿æ±Ÿæœˆ-Â·-é£å…´" class="headerlink" title="1ï¸âƒ£è¥¿æ±Ÿæœˆ Â· é£å…´"></a>1ï¸âƒ£è¥¿æ±Ÿæœˆ Â· é£å…´</h3><p>[å®‹] è¾›å¼ƒç–¾<br>é†‰é‡Œä¸”è´ªæ¬¢ç¬‘ï¼Œè¦æ„é‚£å¾—å·¥å¤«ã€‚è¿‘æ¥å§‹è§‰å¤äººä¹¦ï¼Œä¿¡è‘—å…¨æ— æ˜¯å¤„ã€‚<br>æ˜¨å¤œæ¾è¾¹é†‰å€’ï¼Œé—®æ¾ã€Œæˆ‘é†‰ä½•å¦‚ã€ã€‚åªç–‘æ¾åŠ¨è¦æ¥æ‰¶ï¼Œä»¥æ‰‹æ¨æ¾æ›°ã€Œå»ã€ï¼</p>
<p><a href="http://lib.xcz.im/work/57b935bcd342d3005ac8e63f" target="_blank" rel="noopener">http://lib.xcz.im/work/57b935bcd342d3005ac8e63f</a></p>
<hr>
<h3 id="2ï¸âƒ£è¶æ‹èŠ±"><a href="#2ï¸âƒ£è¶æ‹èŠ±" class="headerlink" title="2ï¸âƒ£è¶æ‹èŠ±"></a>2ï¸âƒ£è¶æ‹èŠ±</h3><p>[å®‹] æ™æ®Š<br>æ§›èŠæ„çƒŸå…°æ³£éœ²ï¼Œç½—å¹•è½»å¯’ï¼Œç‡•å­åŒé£å»ã€‚æ˜æœˆä¸è°™ç¦»æ¨è‹¦ï¼Œæ–œå…‰åˆ°æ™“ç©¿æœ±æˆ·ã€‚<br>æ˜¨å¤œè¥¿é£å‡‹ç¢§æ ‘ï¼Œç‹¬ä¸Šé«˜æ¥¼ï¼Œæœ›å°½å¤©æ¶¯è·¯ã€‚æ¬²å¯„å½©ç¬ºå…¼å°ºç´ ï¼Œå±±é•¿æ°´é˜”çŸ¥ä½•å¤„ï¼Ÿ</p>
<p><a href="http://lib.xcz.im/work/57b318dd1532bc00618ffaff" target="_blank" rel="noopener">http://lib.xcz.im/work/57b318dd1532bc00618ffaff</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>å¦‚ä½•ä½¿ç”¨fairseqå¤ç°Transformer NMT</title>
    <url>/2019/01/28/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8fairseq%E5%A4%8D%E7%8E%B0Transformer%20NMT/</url>
    <content><![CDATA[<p>åŸºäºTransformerçš„NMTè™½ç„¶ç»“æœå¥½ï¼Œä½†è¶…å‚éå¸¸éš¾è°ƒï¼Œåªè¦æœ‰ä¸€ä¸¤ä¸ªå‚æ•°å’Œè®ºæ–‡ä¸ä¸€æ ·ï¼Œå°±æœ‰å¯èƒ½å¾—åˆ°å’Œè®ºæ–‡ç›¸å»ç”šè¿œçš„ç»“æœã€‚fairseqæ˜¯ç°æœ‰æ¯”è¾ƒå®Œå–„çš„seq2seqåº“ï¼Œç”±äºæ˜¯å¤§å…¬å¸å‡ºå“ï¼Œå› æ­¤ä¹Ÿå†™å¾—è¾ƒä¸ºå®Œå–„ï¼Œä¸è®ºæ˜¯ä»£ç è¿˜æ˜¯æ–‡æ¡£ã€‚</p>
<p>æœ¬æ–‡è®¨è®ºå¦‚ä½•ä½¿ç”¨fairseqå¤ç°åŸºäºTransformerçš„ç¿»è¯‘ä»»åŠ¡ï¼Œä¹Ÿå³å¤ç°Vaswani, et al. çš„è®ºæ–‡ç»“æœã€‚æœ¬æ–‡å°½é‡ä¸è®¨è®ºå®ç°ç»†èŠ‚ï¼Œåªè®¨è®ºå¦‚ä½•å¤ç°å‡ºç»“æœã€‚</p>
<p>fairseqé¡¹ç›®åœ°å€ï¼š<a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">https://github.com/pytorch/fairseq</a></p>
<h2 id="ä½¿ç”¨æ•™ç¨‹"><a href="#ä½¿ç”¨æ•™ç¨‹" class="headerlink" title="ä½¿ç”¨æ•™ç¨‹"></a>ä½¿ç”¨æ•™ç¨‹</h2><p>åœ¨è¿™é‡Œæˆ‘ä»¬å‚è€ƒçš„æ˜¯18å¹´çš„æ–‡ç« <a href="https://arxiv.org/abs/1806.00187" target="_blank" rel="noopener">Scaling Neural Machine Translation</a>ï¼ŒåŒæ ·æ˜¯åŸºäºTransformerçš„NMTã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨WMT16 EN-DEè€Œä¸æ˜¯Vaswani, et al.è®ºæ–‡ä¸­çš„WMT14 EN-DEã€‚äºŒè€…åªåœ¨ä¸€ä¸ªæ–‡ä»¶ï¼ˆcommoncrawlï¼‰ä¸Šæœ‰åŒºåˆ«ï¼Œå…¶ä»–æ˜¯ä¸€æ ·çš„ï¼Œç”±äºWMT16 EN-DEæœ‰é¢„å¤„ç†å¥½çš„æ•°æ®ï¼Œä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å°±ä½¿ç”¨è¯¥ä»½æ•°æ®ï¼ˆä¸‹æ–‡ä¹Ÿæœ‰é¢„å¤„ç†WMT14æ•°æ®çš„æ–¹æ³•ï¼‰</p>
<h3 id="å‡†å¤‡å·¥ä½œ"><a href="#å‡†å¤‡å·¥ä½œ" class="headerlink" title="å‡†å¤‡å·¥ä½œ"></a>å‡†å¤‡å·¥ä½œ</h3><ol>
<li>å®‰è£…fairseqï¼Œåœ¨Readmeå†…æœ‰</li>
<li>é˜…è¯»Readmeï¼ˆoptionalï¼‰</li>
<li>é˜…è¯»docï¼ˆoptionalï¼‰</li>
</ol>
<h3 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h3><h4 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h4><p>æ•°æ®é¢„å¤„ç†ä¸»è¦æ˜¯ä¸‹è½½å¤šä¸ªæ–‡ä»¶å¹¶åˆå¹¶â€”&gt;æ¸…ç†/tokenizeæ•°æ®â€”&gt;å°†æ•°æ®åˆ†ä¸ºtrainã€validâ€”&gt;bpe(bype pair encoding)ã€‚fairseqæä¾›äº†ä¸€æ•´å¥—å¤„ç†æµç¨‹çš„è„šæœ¬ï¼Œåœ¨examples/translation/prepare-wmt14en2de.sh</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Adapted from https://github.com/facebookresearch/MIXER/blob/master/prepareData.sh</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Moses github repository (for tokenization scripts)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/moses-smt/mosesdecoder.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Subword NMT repository (for BPE pre-processing)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/rsennrich/subword-nmt.git</span><br><span class="line"></span><br><span class="line">SCRIPTS=mosesdecoder/scripts</span><br><span class="line">TOKENIZER=<span class="variable">$SCRIPTS</span>/tokenizer/tokenizer.perl</span><br><span class="line">CLEAN=<span class="variable">$SCRIPTS</span>/training/clean-corpus-n.perl</span><br><span class="line">NORM_PUNC=<span class="variable">$SCRIPTS</span>/tokenizer/normalize-punctuation.perl</span><br><span class="line">REM_NON_PRINT_CHAR=<span class="variable">$SCRIPTS</span>/tokenizer/remove-non-printing-char.perl</span><br><span class="line">BPEROOT=subword-nmt</span><br><span class="line">BPE_TOKENS=40000</span><br><span class="line"></span><br><span class="line">URLS=(</span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/dev.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt14/test-full.tgz"</span></span><br><span class="line">)</span><br><span class="line">FILES=(</span><br><span class="line">    <span class="string">"training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"dev.tgz"</span></span><br><span class="line">    <span class="string">"test-full.tgz"</span></span><br><span class="line">)</span><br><span class="line">CORPORA=(</span><br><span class="line">    <span class="string">"training/europarl-v7.de-en"</span></span><br><span class="line">    <span class="string">"commoncrawl.de-en"</span></span><br><span class="line">    <span class="string">"training/news-commentary-v12.de-en"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will make the dataset compatible to the one used in "Convolutional Sequence to Sequence Learning"</span></span><br><span class="line"><span class="comment"># https://arxiv.org/abs/1705.03122</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> == <span class="string">"--icml17"</span> ]; <span class="keyword">then</span></span><br><span class="line">    URLS[2]=<span class="string">"http://statmt.org/wmt14/training-parallel-nc-v9.tgz"</span></span><br><span class="line">    FILES[2]=<span class="string">"training-parallel-nc-v9.tgz"</span></span><br><span class="line">    CORPORA[2]=<span class="string">"training/news-commentary-v9.de-en"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">"<span class="variable">$SCRIPTS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Please set SCRIPTS variable correctly to point to Moses scripts."</span></span><br><span class="line">    <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">src=en</span><br><span class="line">tgt=de</span><br><span class="line">lang=en-de</span><br><span class="line">prep=wmt14_en_de</span><br><span class="line">tmp=<span class="variable">$prep</span>/tmp</span><br><span class="line">orig=orig</span><br><span class="line">dev=dev/newstest2013</span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$orig</span> <span class="variable">$tmp</span> <span class="variable">$prep</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$orig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;<span class="variable">$&#123;#URLS[@]&#125;</span>;++i)); <span class="keyword">do</span></span><br><span class="line">    file=<span class="variable">$&#123;FILES[i]&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$file</span> already exists, skipping download"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        url=<span class="variable">$&#123;URLS[i]&#125;</span></span><br><span class="line">        wget <span class="string">"<span class="variable">$url</span>"</span></span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> successfully downloaded."</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> not successfully downloaded."</span></span><br><span class="line">            <span class="built_in">exit</span> -1</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tgz"</span> ]; <span class="keyword">then</span></span><br><span class="line">            tar zxvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">elif</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tar"</span> ]; <span class="keyword">then</span></span><br><span class="line">            tar xvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing train data..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    rm <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;CORPORA[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">        cat <span class="variable">$orig</span>/<span class="variable">$f</span>.<span class="variable">$l</span> | \</span><br><span class="line">            perl <span class="variable">$NORM_PUNC</span> <span class="variable">$l</span> | \</span><br><span class="line">            perl <span class="variable">$REM_NON_PRINT_CHAR</span> | \</span><br><span class="line">            perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt;&gt; <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing test data..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$l</span>"</span> == <span class="string">"<span class="variable">$src</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        t=<span class="string">"src"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        t=<span class="string">"ref"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    grep <span class="string">'&lt;seg id'</span> <span class="variable">$orig</span>/<span class="built_in">test</span>-full/newstest2014-deen-<span class="variable">$t</span>.<span class="variable">$l</span>.sgm | \</span><br><span class="line">        sed -e <span class="string">'s/&lt;seg id="[0-9]*"&gt;\s*//g'</span> | \</span><br><span class="line">        sed -e <span class="string">'s/\s*&lt;\/seg&gt;\s*//g'</span> | \</span><br><span class="line">        sed -e <span class="string">"s/\â€™/\'/g"</span> | \</span><br><span class="line">    perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/<span class="built_in">test</span>.<span class="variable">$l</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">""</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"splitting train and valid..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 == 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/valid.<span class="variable">$l</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 != 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/train.<span class="variable">$l</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">TRAIN=<span class="variable">$tmp</span>/train.de-en</span><br><span class="line">BPE_CODE=<span class="variable">$prep</span>/code</span><br><span class="line">rm -f <span class="variable">$TRAIN</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    cat <span class="variable">$tmp</span>/train.<span class="variable">$l</span> &gt;&gt; <span class="variable">$TRAIN</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"learn_bpe.py on <span class="variable">$&#123;TRAIN&#125;</span>..."</span></span><br><span class="line">python <span class="variable">$BPEROOT</span>/learn_bpe.py -s <span class="variable">$BPE_TOKENS</span> &lt; <span class="variable">$TRAIN</span> &gt; <span class="variable">$BPE_CODE</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> train.<span class="variable">$L</span> valid.<span class="variable">$L</span> <span class="built_in">test</span>.<span class="variable">$L</span>; <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"apply_bpe.py to <span class="variable">$&#123;f&#125;</span>..."</span></span><br><span class="line">        python <span class="variable">$BPEROOT</span>/apply_bpe.py -c <span class="variable">$BPE_CODE</span> &lt; <span class="variable">$tmp</span>/<span class="variable">$f</span> &gt; <span class="variable">$tmp</span>/bpe.<span class="variable">$f</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.train <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/train 1 250</span><br><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.valid <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/valid 1 250</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    cp <span class="variable">$tmp</span>/bpe.test.<span class="variable">$L</span> <span class="variable">$prep</span>/<span class="built_in">test</span>.<span class="variable">$L</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>å¦‚æœå¸Œæœ›ä½¿ç”¨é¢„å¤„ç†å¥½çš„æ•°æ®ï¼Œåˆ™å¯ä»¥ä½¿ç”¨WMT16 EN-DEï¼Œåœ°å€ä¸ºï¼š<a href="https://drive.google.com/uc?export=download&amp;id=0B_bZck-ksdkpM25jRUN2X2UxMm8" target="_blank" rel="noopener">https://drive.google.com/uc?export=download&amp;id=0B_bZck-ksdkpM25jRUN2X2UxMm8</a><br>å¹¶è§£å‹ã€‚</p>
<h4 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h4><p>æ¥ä¸‹æ¥å¯¹æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–(binarize):</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">TEXT=wmt16_en_de_bpe32k</span><br><span class="line">mkdir <span class="variable">$TEXT</span></span><br><span class="line">tar -xzvf wmt16_en_de.tar.gz -C <span class="variable">$TEXT</span>  <span class="comment"># è§£å‹æ–‡ä»¶</span></span><br><span class="line">python preprocess.py --<span class="built_in">source</span>-lang en --target-lang de \</span><br><span class="line">  --trainpref <span class="variable">$TEXT</span>/train.tok.clean.bpe.32000 \</span><br><span class="line">  --validpref <span class="variable">$TEXT</span>/newstest2013.tok.bpe.32000 \</span><br><span class="line">  --testpref <span class="variable">$TEXT</span>/newstest2014.tok.bpe.32000 \</span><br><span class="line">  --destdir data-bin/wmt16_en_de_bpe32k \</span><br><span class="line">  --nwordssrc 32768 --nwordstgt 32768 \</span><br><span class="line">  --joined-dictionary</span><br></pre></td></tr></table></figure>
<p>åˆ°è¿™é‡Œï¼Œéº»çƒ¦çš„é¢„å¤„ç†å°±ç»“æŸäº†ã€‚</p>
<h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><p>cdåˆ°fairseqç›®å½•ä¸‹ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  python -m torch.distributed.launch --nproc_per_node 8 train.py data-bin/wmt16_en_de_bpe32k \        --arch transformer_wmt_en_de --share-all-embeddings \          --optimizer adam --adam-betas <span class="string">'(0.9, 0.98)'</span> --clip-norm 0.0 \            --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000 \              --lr 0.0007 --min-lr 1e-09 \             --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --weight-decay 0.0\              --max-tokens  4096   --save-dir checkpoints/en-de-base\               --no-progress-bar --<span class="built_in">log</span>-format json --<span class="built_in">log</span>-interval 50\             --save-interval-updates  1000 --keep-interval-updates 20</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„åˆ°è¯¥è®¾ç½®ä¸åŸè®ºæ–‡ä¸å¤§ä¸€è‡´ã€‚ä½†å·²è¯å®è¯¥è®¾ç½®å¯ä»¥å¤ç°è®ºæ–‡ç»“æœã€‚</p>
<p>å¦‚æœæ²¡æœ‰è¿™ä¹ˆå¤šå¡ï¼Œé‚£ä¹ˆå¯ä»¥è®¾ç½®<code>update freq</code>ä»¥æ¨¡æ‹Ÿ8å¡è¡Œä¸ºã€‚å¦‚ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3  python -m torch.distributed.launch --nproc_per_node 4 \</span><br><span class="line">train.py data-bin/wmt16_en_de_bpe32k    \</span><br><span class="line"> --arch transformer_wmt_en_de --share-all-embeddings \</span><br><span class="line">--optimizer adam --adam-betas <span class="string">'(0.9, 0.98)'</span> \</span><br><span class="line">--clip-norm 0.0   --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000  \</span><br><span class="line">--lr 0.0007 --min-lr 1e-09 --criterion label_smoothed_cross_entropy \</span><br><span class="line">--label-smoothing 0.1 --weight-decay 0.0 --max-tokens  4096   \</span><br><span class="line">--save-dir checkpoints/en-de-16-base   \ </span><br><span class="line">--no-progress-bar --<span class="built_in">log</span>-format json --<span class="built_in">log</span>-interval 50 --save-interval-updates  1000 \</span><br><span class="line">--keep-interval-updates 20  --update-freq 2 |tee exp2.log</span><br></pre></td></tr></table></figure>
<p>4å¼ å¡åˆ™è®¾<code>update freq=2</code>ï¼Œ2å¼ å¡åˆ™è®¾<code>update freq=4</code>ï¼Œä»¥æ­¤ç±»æ¨ã€‚</p>
<p>å¤§æ¦‚åœ¨100ä¸ªepochå†…èƒ½å¤Ÿæ”¶æ•›(å®é™…ä¸Šåº”è¯¥åœ¨150-200ä¸ªepochæ”¶æ•›ï¼Œ100epochçš„BLEUæ˜¯27.3ï¼Œ150-200epochçš„ç»“æœæ˜¯27.67)ï¼Œä¹Ÿå³åœ¨475000ä¸ªstepã€‚8å¼ 1080Tiåœ¨å¤§æ¦‚ä¸¤å¤©èƒ½å¤Ÿè®­ç»ƒå®Œæˆï¼Œ4å¼ 1080Tiå¤§æ¦‚4å¤©è®­ç»ƒå®Œæˆã€‚</p>
<p>å¼€å§‹è®­ç»ƒâ€¦<br><img src="/images/15491934129135.jpg" width="80%" height="50%"></p>
<p>æœ€ååˆ™ä¼šè·å¾—checkpointï¼š<br><img src="/images/15491934935157.jpg" width="80%" height="50%"></p>
<h3 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h3><p>æµ‹è¯•åˆ†ä¸ºå‡ ä¸ªé˜¶æ®µï¼šé¦–å…ˆå°†å‡ ä¸ªcheckpointè¿›è¡Œå¹³å‡ï¼Œå®éªŒè¡¨æ˜ï¼Œè¿›è¡Œå¹³å‡èƒ½å¤Ÿæœ‰ä¸€å®šçš„æå‡ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨å¹³å‡åçš„æ¨¡å‹å¯¹testé›†çš„å¥å­è¿›è¡Œç¿»è¯‘ï¼›æœ€ç»ˆå°†ç”Ÿæˆçš„å¥å­å’Œæ­£ç¡®çš„å¥å­è®¡ç®—bleuå€¼ã€‚</p>
<h4 id="average-checkpoint"><a href="#average-checkpoint" class="headerlink" title="average checkpoint"></a>average checkpoint</h4><p>åœ¨æµ‹è¯•é˜¶æ®µï¼Œè®ºæ–‡åœ¨Transformer-baseä¸­å¯¹æœ€åäº”ä¸ªcheckpointè¿›è¡Œå¹³å‡ï¼Œä¹Ÿå³å¯¹æƒå€¼è¿›è¡Œå¹³å‡ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python scripts/average_checkpoints.py \</span><br><span class="line">--inputs checkpoints/en-de-base/ \</span><br><span class="line">--num-epoch-checkpoints  5 --output averaged_model.pt</span><br></pre></td></tr></table></figure>
<p>æœ€ç»ˆè·å¾—averaged_model.ptï¼Œæˆ‘ä»¬å°†ç”¨è¯¥æ–‡ä»¶è¿›è¡Œæµ‹è¯•ã€‚</p>
<h4 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h4><p>æˆ‘ä»¬é‡‡ç”¨å’Œè®ºæ–‡ä¸€è‡´çš„è¶…å‚ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 python generate.py \</span><br><span class="line">data-bin/wmt16_en_de_bpe32k/ --path /some_checkpoint \</span><br><span class="line">--remove-bpe --beam 4 --batch-size 64 --lenpen 0.6 \</span><br><span class="line">--max-len<span class="_">-a</span> 1 --max-len-b 50|tee generate.out</span><br></pre></td></tr></table></figure>
<p>å…¶ä¸­lenpenæ˜¯ç”Ÿæˆå¥å­çš„é•¿åº¦æƒ©ç½šç³»æ•°ï¼›<code>max-len-a</code>å’Œ<code>max-len-b</code>æŒ‡çš„æ˜¯æ¯ä¸ªå¥å­çš„æœ€é•¿é•¿åº¦é™åˆ¶ï¼Œä¹Ÿå³ï¼šå‡è®¾æºå¥å­é•¿åº¦ä¸ºxï¼Œåˆ™ç›®æ ‡å¥å­çš„é•¿åº¦åº”å°äºax+b ã€‚</p>
<p>æœ€ç»ˆæˆ‘ä»¬ç¿»è¯‘å¥½çš„å¥å­ä»¥åŠç›¸å¯¹åº”çš„è¯¦ç»†ä¿¡æ¯éƒ½åœ¨generate.outé‡Œé¢ã€‚æˆ‘ä»¬éœ€è¦æå–æºè¯­è¨€å¥å­å’Œç›®æ ‡è¯­è¨€å¥å­ï¼Œä»¥æ–¹ä¾¿åé¢çš„è®¡ç®—ã€‚å› æ­¤ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep ^T generate.out | cut -f2- | perl -ple <span class="string">'s&#123;(\S)-(\S)&#125;&#123;$1 ##AT##-##AT## $2&#125;g'</span> &gt; generate.ref</span><br><span class="line"></span><br><span class="line">grep ^H generate.out |cut -f3- | perl -ple <span class="string">'s&#123;(\S)-(\S)&#125;&#123;$1 ##AT##-##AT## $2&#125;g'</span> &gt; generate.sys</span><br></pre></td></tr></table></figure>
<p>åˆ†åˆ«è¿è¡Œè¿™ä¸¤ä¸ªbashå‘½ä»¤ï¼Œæˆ‘ä»¬åˆ™è·å¾—äº†generate.refå’Œgenerate.sysï¼Œåˆ†åˆ«æ˜¯ç›®æ ‡å’Œæºè¯­è¨€çš„å¥å­ã€‚</p>
<p>æ³¨æ„åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„å°trickï¼Œä¹Ÿå³<strong>split compound</strong>ã€‚å› ä¸ºä¸€äº›å†å²åŸå› ï¼ˆæˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºå•¥ï¼Œtensor2tensoré‡Œé¢çš„è„šæœ¬æœ‰æåˆ°ï¼‰ï¼Œè¯¥trickå·²ç»åœ¨ä¸Šé¢çš„è„šæœ¬å‘½ä»¤ä½“ç°å‡ºæ¥äº†ã€‚å®è·µè¯æ˜ï¼Œä½¿ç”¨è¯¥trickèƒ½å¤Ÿæé«˜bleuå€¼ 0.5ä¸ªç‚¹ä»¥ä¸Šã€‚</p>
<h4 id="score"><a href="#score" class="headerlink" title="score"></a>score</h4><p>æˆ‘ä»¬æ­¤æ—¶å°±å¯ä»¥è®¡ç®—bleuå€¼äº†ï¼Œfairseqæä¾›äº†è¯¥è„šæœ¬ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python score.py --sys generate.sys --ref generate.ref</span><br></pre></td></tr></table></figure>
<p>å¤§åŠŸå‘Šæˆï¼æˆ‘ä»¬ç»ˆäºå¤ç°å‡ºç»“æœäº†ã€‚<br>ä½œä¸ºå‚è€ƒï¼šæ ¹æ®æˆ‘çš„å®éªŒï¼Œåªä½¿ç”¨checkpointä¸­æœ€å¥½çš„ä¸€ä¸ªcheckpointï¼Œåœ¨ç»è¿‡äº†ä¸Šè¿°çš„æµç¨‹åï¼Œå¯ä»¥å¾—åˆ°27.30çš„ç»“æœã€‚</p>
<h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><p>æ ¹æ®æˆ‘çš„éœ€æ±‚ï¼Œæˆ‘è¿˜éœ€è¦è¯¦ç»†è®°å½•ä¸­é—´ç»“æœï¼Œå¹¶æ‰“å°åœ¨tensorboardä¸Šæ–¹ä¾¿å¯è§†åŒ–ï¼Œå¦‚ï¼š<br><img src="/images/15491946401169.jpg" width="90%" height="50%"></p>
<p>fairseqå¹¶æ²¡æœ‰æä¾›è¿™ç§åŠŸèƒ½ï¼Œå› æ­¤éœ€è¦è‡ªå·±ä¿®æ”¹éƒ¨åˆ†æºä»£ç ã€‚<br>åªéœ€è¦ä¿®æ”¹train.pyæºæ–‡ä»¶å³å¯ã€‚</p>
<p>â‘ åœ¨å¼€å¤´åŠ summary writer<br><img src="/images/15492019614168.jpg" width="70%" height="50%"></p>
<p>æ³¨æ„åˆ°æ¯æ¬¡å®éªŒéƒ½éœ€è¦ä¿®æ”¹å®éªŒçš„åå­—ã€‚</p>
<p>â‘¡ä¿®æ”¹trainå‡½æ•°<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492020396304.jpg" width="70%" height="50%"></p>
<p>åœ¨epochç»“æŸï¼Œæ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492021296611.jpg" width="70%" height="50%"></p>
<p>å¯¹validateçš„ä½¿ç”¨è¿›è¡Œä¿®æ”¹ï¼ˆæ·»åŠ äº†is_epochï¼‰ï¼š<br><img src="/images/15492022604000.jpg" width="70%" height="50%"></p>
<p>trainå‡½æ•°å…¨éƒ¨ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(args, trainer, task, epoch_itr)</span>:</span></span><br><span class="line">    <span class="string">"""Train the model for one epoch."""</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameters every N batches</span></span><br><span class="line">    <span class="keyword">if</span> epoch_itr.epoch &lt;= len(args.update_freq):</span><br><span class="line">        update_freq = args.update_freq[epoch_itr.epoch - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        update_freq = args.update_freq[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize data iterator</span></span><br><span class="line">    itr = epoch_itr.next_epoch_itr(fix_batches_to_gpus=args.fix_batches_to_gpus)</span><br><span class="line">    itr = iterators.GroupedIterator(itr, update_freq)</span><br><span class="line">    progress = progress_bar.build_progress_bar(</span><br><span class="line">        args, itr, epoch_itr.epoch, no_progress_bar=<span class="string">'simple'</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    extra_meters = collections.defaultdict(<span class="keyword">lambda</span>: AverageMeter())</span><br><span class="line">    first_valid = args.valid_subset.split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">    max_update = args.max_update <span class="keyword">or</span> math.inf</span><br><span class="line">    <span class="keyword">for</span> i, samples <span class="keyword">in</span> enumerate(progress, start=epoch_itr.iterations_in_epoch):</span><br><span class="line">        log_output = trainer.train_step(samples)</span><br><span class="line">        <span class="keyword">if</span> log_output <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># log mid-epoch stats</span></span><br><span class="line">        stats = get_training_stats(trainer)</span><br><span class="line">        num_updates = stats[<span class="string">'num_updates'</span>]</span><br><span class="line">        <span class="comment"># print(type(num_updates))</span></span><br><span class="line">        <span class="comment"># print(type(stats['loss']))</span></span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_loss_update'</span>, float(stats[<span class="string">'loss'</span>]), num_updates)</span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_nll_loss_update'</span>, float(stats[<span class="string">'nll_loss'</span>]), num_updates)</span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_ppl_update'</span>, float(stats[<span class="string">'ppl'</span>]), num_updates)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ------record training metrics --- #</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> log_output.items():</span><br><span class="line">            <span class="keyword">if</span> k <span class="keyword">in</span> [<span class="string">'loss'</span>, <span class="string">'nll_loss'</span>, <span class="string">'ntokens'</span>, <span class="string">'nsentences'</span>, <span class="string">'sample_size'</span>]:</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># these are already logged above</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'loss'</span> <span class="keyword">in</span> k:</span><br><span class="line">                extra_meters[k].update(v, log_output[<span class="string">'sample_size'</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                extra_meters[k].update(v)</span><br><span class="line">            stats[k] = extra_meters[k].avg</span><br><span class="line">        progress.log(stats)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ignore the first mini-batch in words-per-second calculation</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            trainer.get_meter(<span class="string">'wps'</span>).reset()</span><br><span class="line"></span><br><span class="line">        num_updates = trainer.get_num_updates()</span><br><span class="line">        <span class="keyword">if</span> args.save_interval_updates &gt; <span class="number">0</span> <span class="keyword">and</span> num_updates % args.save_interval_updates == <span class="number">0</span> <span class="keyword">and</span> num_updates &gt; <span class="number">0</span>:</span><br><span class="line">            valid_losses = validate(args, trainer, task, epoch_itr, [first_valid], is_epoch=<span class="keyword">False</span>)</span><br><span class="line">            save_checkpoint(args, trainer, epoch_itr, valid_losses[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_updates &gt;= max_update:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># log end-of-epoch stats</span></span><br><span class="line">    stats = get_training_stats(trainer)</span><br><span class="line">    <span class="comment"># ------record training metrics --- #</span></span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_loss_epoch'</span>, float(stats[<span class="string">'loss'</span>]), epoch_itr.epoch)</span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_nll_loss_epoch'</span>, float(stats[<span class="string">'nll_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_ppl_epoch'</span>, float(stats[<span class="string">'ppl'</span>]), epoch_itr.epoch)</span><br><span class="line">    <span class="keyword">for</span> k, meter <span class="keyword">in</span> extra_meters.items():</span><br><span class="line">        stats[k] = meter.avg</span><br><span class="line">    progress.print(stats)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reset training meters</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [</span><br><span class="line">        <span class="string">'train_loss'</span>, <span class="string">'train_nll_loss'</span>, <span class="string">'wps'</span>, <span class="string">'ups'</span>, <span class="string">'wpb'</span>, <span class="string">'bsz'</span>, <span class="string">'gnorm'</span>, <span class="string">'clip'</span>,</span><br><span class="line">    ]:</span><br><span class="line">        meter = trainer.get_meter(k)</span><br><span class="line">        <span class="keyword">if</span> meter <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            meter.reset()</span><br></pre></td></tr></table></figure>
<p>â‘¢ä¿®æ”¹validateå‡½æ•°<br>æ·»åŠ äº†ä¸€ä¸ªå‚æ•°<code>is_epoch</code>ï¼š<br><img src="/images/15492023879130.jpg" width="50%" height="50%"></p>
<p>æ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492024686078.jpg" width="90%" height="50%"></p>
<p>validateå…¨éƒ¨ä»£ç ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">def validate(args, trainer, task, epoch_itr, subsets, is_epoch=True):</span><br><span class="line">    <span class="string">""</span><span class="string">"Evaluate the model on the validation set(s) and return the losses."</span><span class="string">""</span></span><br><span class="line">    valid_losses = []</span><br><span class="line">    <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">        <span class="comment"># Initialize data iterator</span></span><br><span class="line">        itr = task.get_batch_iterator(</span><br><span class="line">            dataset=task.dataset(subset),</span><br><span class="line">            max_tokens=args.max_tokens,</span><br><span class="line">            max_sentences=args.max_sentences_valid,</span><br><span class="line">            max_positions=utils.resolve_max_positions(</span><br><span class="line">                task.max_positions(),</span><br><span class="line">                trainer.get_model().max_positions(),</span><br><span class="line">            ),</span><br><span class="line">            ignore_invalid_inputs=args.skip_invalid_size_inputs_valid_test,</span><br><span class="line">            required_batch_size_multiple=8,</span><br><span class="line">            seed=args.seed,</span><br><span class="line">            num_shards=args.distributed_world_size,</span><br><span class="line">            shard_id=args.distributed_rank,</span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">        ).next_epoch_itr(shuffle=False)</span><br><span class="line">        progress = progress_bar.build_progress_bar(</span><br><span class="line">            args, itr, epoch_itr.epoch,</span><br><span class="line">            prefix=<span class="string">'valid on \'</span>&#123;&#125;\<span class="string">' subset'</span>.format(subset),</span><br><span class="line">            no_progress_bar=<span class="string">'simple'</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reset validation loss meters</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">'valid_loss'</span>, <span class="string">'valid_nll_loss'</span>]:</span><br><span class="line">            meter = trainer.get_meter(k)</span><br><span class="line">            <span class="keyword">if</span> meter is not None:</span><br><span class="line">                meter.reset()</span><br><span class="line">        extra_meters = collections.defaultdict(lambda: AverageMeter())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> sample <span class="keyword">in</span> progress:</span><br><span class="line">            log_output = trainer.valid_step(sample)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> log_output.items():</span><br><span class="line">                <span class="keyword">if</span> k <span class="keyword">in</span> [<span class="string">'loss'</span>, <span class="string">'nll_loss'</span>, <span class="string">'ntokens'</span>, <span class="string">'nsentences'</span>, <span class="string">'sample_size'</span>]:</span><br><span class="line">                    <span class="built_in">continue</span></span><br><span class="line">                extra_meters[k].update(v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log validation stats</span></span><br><span class="line">        stats = get_valid_stats(trainer)</span><br><span class="line">        <span class="comment"># ------record validate metrics --- #</span></span><br><span class="line">        <span class="keyword">if</span> is_epoch:  <span class="comment"># every epoch</span></span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_loss_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_nll_loss_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_nll_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_ppl_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_ppl'</span>]), epoch_itr.epoch)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># every n update</span></span><br><span class="line">            num_updates = stats[<span class="string">'num_updates'</span>]</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_loss_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_loss'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_nll_loss_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_nll_loss'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_ppl_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_ppl'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k, meter <span class="keyword">in</span> extra_meters.items():</span><br><span class="line">            stats[k] = meter.avg</span><br><span class="line">        progress.print(stats)</span><br><span class="line"></span><br><span class="line">        valid_losses.append(stats[<span class="string">'valid_loss'</span>])</span><br><span class="line">    <span class="built_in">return</span> valid_losses</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://github.com/pytorch/fairseq/tree/master/examples/translation#replicating-results-from-scaling-neural-machine-translation" target="_blank" rel="noopener">Replicating results from â€œScaling Neural Machine Translationâ€
</a></p>
<p><a href="https://github.com/pytorch/fairseq/issues/346" target="_blank" rel="noopener">How to reproduce the result of WMT14 en-de on transformer BASE model?</a></p>
]]></content>
      <tags>
        <tag>æ•™ç¨‹</tag>
        <tag>Transformer</tag>
        <tag>fairseq</tag>
        <tag>NMT</tag>
        <tag>æœºå™¨ç¿»è¯‘</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•15</title>
    <url>/2019/01/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9515/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-flatten-multi-dimentional-list"><a href="#1ï¸âƒ£-flatten-multi-dimentional-list" class="headerlink" title="1ï¸âƒ£[flatten multi-dimentional list]"></a>1ï¸âƒ£[flatten multi-dimentional list]</h3><p>å¯¹å¤šå±‚åµŒå¥—çš„listè¿›è¡Œå±•å¹³ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># é€’å½’</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten</span><span class="params">(nestedList)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aux</span><span class="params">(listOrItem)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(listOrItem, list):</span><br><span class="line">            <span class="keyword">for</span> elem <span class="keyword">in</span> listOrItem:</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> aux(elem):</span><br><span class="line">                    <span class="keyword">yield</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> listOrItem</span><br><span class="line">    <span class="keyword">return</span> list(aux(nestedList))</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£-sorted-index"><a href="#2ï¸âƒ£-sorted-index" class="headerlink" title="2ï¸âƒ£[sorted index]"></a>2ï¸âƒ£[sorted index]</h3><p>ä½¿ç”¨å†…ç½®æ–¹æ³•è·å¾—æ’å¥½åºçš„index</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sorted_index=[i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(enumerate(sent_length),</span><br><span class="line">                                    key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],</span><br><span class="line">                                    reverse=self.reverse)]</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡11</title>
    <url>/2019/01/06/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8711/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Multi-Head-Attention-with-Disagreement-Regularization"><a href="#1ï¸âƒ£-Multi-Head-Attention-with-Disagreement-Regularization" class="headerlink" title="1ï¸âƒ£[Multi-Head Attention with Disagreement Regularization]"></a>1ï¸âƒ£[Multi-Head Attention with Disagreement Regularization]</h2><p>EMNLPçš„çŸ­æ–‡ã€‚</p>
<p>é¼“åŠ±transformerä¸­headä¸headä¹‹é—´çš„å·®å¼‚ã€‚</p>
<p>åŠ äº†ä¸‰ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼š<br>â‘ on subspace<br><img src="/images/15467399912055.jpg" width="40%" height="50%"></p>
<p>â‘¡on attention position<br><img src="/images/15467400218650.jpg" width="40%" height="50%"></p>
<p>â‘¢on output<br><img src="/images/15467400417247.jpg" width="40%" height="50%"></p>
<p>æ²¡ä»€ä¹ˆäº®ç‚¹ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overï¬tting"><a href="#2ï¸âƒ£-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overï¬tting" class="headerlink" title="2ï¸âƒ£[Dropout: A Simple Way to Prevent Neural Networks from Overï¬tting]"></a>2ï¸âƒ£[Dropout: A Simple Way to Prevent Neural Networks from Overï¬tting]</h2><p>ç»å…¸è®ºæ–‡ã€‚<br>dropoutæ–¹æ³•å¾ˆç®€å•ï¼Œä½†å¦‚ä½•æƒ³åˆ°ï¼Œå…¶èƒŒåçš„intuitionï¼Œä»¥åŠä¸€äº›ç°è±¡å¾ˆæœ‰å¯å‘æ„ä¹‰ã€‚<br>ä»…ç½—åˆ—ä¸€äº›intuition/motivationä»¥åŠç°è±¡ï¼š</p>
<ol>
<li>ç½‘ç»œå¤æ‚å…³ç³»å­¦åˆ°å¾ˆå¤šå™ªå£°ï¼Œå¯¼è‡´overfitting</li>
<li>æœ€å¥½çš„regularizationæ–¹æ³•æ˜¯å¯¹æ‰€æœ‰çš„parameter settingçš„ç»“æœè¿›è¡Œaverageã€‚è¿™å°±æ˜¯è´å¶æ–¯æ–¹æ³•ï¼Œ dropoutæ˜¯å¯¹è¯¥æ–¹æ³•è¿›è¡Œè¿‘ä¼¼ï¼Œè®ºæ–‡ä¹Ÿæåˆ°äº†model combination</li>
<li>dropoutèƒ½å¤Ÿå‡å°‘unitä¹‹é—´å¤æ‚çš„co-adaptationï¼Œèƒ½å¤Ÿæ›´é²æ£’ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸éœ€è¦ä¾èµ–å…¶ä»–unitå»çº æ­£è‡ªå·±çš„é”™è¯¯ã€‚each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes</li>
<li>dropoutçš„ç‰¹æ€§ï¼šsparsityã€‚æ ‡å‡†çš„ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå›ºåŒ–å…¶ä»–unitçš„é”™è¯¯ï¼Œå¯¼è‡´å¤æ‚çš„co-adaptationï¼Œä½†è¿™ç§å¤æ‚çš„adaptationä¼šå¯¼è‡´æ³›åŒ–æ€§çš„é™ä½ï¼Œå› ä¸ºå¯¹äºæœªè§åˆ°çš„æ•°æ®è¿™ç§å¤æ‚çš„adaptationæ˜¯æ²¡ç”¨çš„ã€‚å› æ­¤dropoutçš„ç½‘ç»œä¸­æ¯ä¸ªunitéƒ½è¦å­¦ä¼šè‡ªå·±çº æ­£è‡ªå·±çš„é”™è¯¯ï¼Œå› æ­¤æ¯ä¸ªunitèƒ½å¤Ÿç‹¬ç«‹å­¦åˆ°æ•°æ®çš„ä¸€éƒ¨åˆ†ç‰¹æ€§ã€‚dropoutä¼šå¯¼è‡´ç¨€ç–åŒ–ï¼Œæ¯æ¬¡éƒ½åªä¼šæœ‰ä¸€å°éƒ¨åˆ†çš„activationé«˜ã€‚ä½¿ç”¨dropouté…åˆé«˜çš„å­¦ä¹ ç‡æ¯”è¾ƒå¥½ï¼Œå› ä¸ºdropoutå¯èƒ½ä¼šå¯¼è‡´gradientä¹‹é—´äº’ç›¸cancelï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨é«˜çš„momentumã€‚</li>
</ol>
<p><img src="/images/15467404963033.jpg" width="80%" height="50%"></p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>dropout</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>regularization</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­index_copy_åŠå…¶æ€è€ƒ</title>
    <url>/2018/12/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADindex_copy_%E5%8F%8A%E5%85%B6%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<p>å‰å‡ æ—¥å› ä¸ºin-placeæ“ä½œçš„é—®é¢˜ï¼Œdebugäº†å¥½å‡ å¤©ï¼Œæœ€ç»ˆæ‰å‘ç°é—®é¢˜ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure>
<p>å› ä¸ºPytorchä¸­pack_sequenceéœ€è¦å°†batchæŒ‰é•¿åº¦æ’åˆ—ï¼Œæˆ‘åœ¨è¿‡å®ŒGRUåéœ€è¦å°†å…¶é¡ºåºè¿˜åŸï¼Œåœ¨è¿™è¾¹sorted_indexå³æ˜¯è®°å½•åŸæ¥indexæ˜ å°„ã€‚</p>
<p>ç„¶è€Œæˆ‘åœ¨å†™çš„æ—¶å€™ï¼Œå‚è€ƒçš„æ˜¯å®˜æ–¹çš„exampleï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.float)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([<span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.index_copy_(<span class="number">0</span>, index, t)</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>]])</span><br></pre></td></tr></table></figure>
<p>å› æ­¤æˆ‘ä¹Ÿä¸å‡æ€ç´¢åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy_(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure></p>
<p>å°±å› ä¸ºå¤šäº†ä¸€ä¸ª_ï¼Œå¯¼è‡´é€»è¾‘å’Œæˆ‘æƒ³è±¡ä¸­çš„ä¸ä¸€æ ·ã€‚</p>
<p>ä¸€ä¸ªç®€å•çš„ä¾‹å­å±•ç¤ºä¸ºä»€ä¹ˆè¿™ä¹ˆæ˜¯é”™çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.Tensor([<span class="number">21</span>,<span class="number">42</span>,<span class="number">45</span>,<span class="number">59</span>])</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 42., 45., 59.])</span></span><br><span class="line"></span><br><span class="line">index=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">x=x.index_copy_(<span class="number">0</span>,index,x)</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 21., 21., 59.])</span></span><br></pre></td></tr></table></figure>
<p>ç”±äºæ˜¯in-placeæ“ä½œï¼Œç¬¬ä¸€æ­¥ï¼Œå°†index=0çš„æ•°å€¼ï¼ˆä¹Ÿå³21ï¼‰å¤åˆ¶åˆ°index=1çš„åœ°æ–¹ï¼Œæ­¤æ—¶å˜æˆ[21,21,45,59]ï¼›æ¥ç€å°†index=1çš„æ•°å€¼å¤åˆ¶åˆ°index=2çš„ä½ç½®ä¸Šï¼Œæ³¨æ„åˆ°ä¹‹å‰å·²ç»æ˜¯in-placeæ“ä½œï¼Œå› æ­¤æ­¤æ—¶å–çš„ä¸æ˜¯æƒ³è±¡ä¸­çš„42ï¼Œè€Œæ˜¯å·²ç»è¢«æ›¿æ¢çš„21ã€‚åé¢çš„ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<p>æ­£ç¡®çš„åšæ³•åªéœ€è¦å»æ‰in-placeå³å¯ã€‚</p>
<hr>
<p>å·²ç»å¥½å‡ æ¬¡é‡åˆ°in-placeçš„é—®é¢˜äº†ï¼Œåœ¨æ¯æ¬¡åšin-placeæ“ä½œæ—¶ï¼Œéƒ½è¦è­¦æƒ•ã€‚åº”å°½å¯èƒ½é¿å…in-placeæ“ä½œã€‚å®é™…ä¸ŠPytorchå®˜æ–¹ä¹Ÿä¸å»ºè®®ä½¿ç”¨in-placeæ“ä½œã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>index_coopy</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•14</title>
    <url>/2018/12/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9514/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-shuffle-list"><a href="#1ï¸âƒ£-shuffle-list" class="headerlink" title="1ï¸âƒ£[shuffle list]"></a>1ï¸âƒ£[shuffle list]</h3><p>shuffle listå¯ä»¥ä½¿ç”¨randomçš„shuffleå‡½æ•°ï¼Œäº¦å³ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">shuffle(l)  <span class="comment"># in place operation</span></span><br></pre></td></tr></table></figure>
<p>è€Œæƒ³è¦shuffleä¸¤ä¸ªå¯¹åº”listï¼Œä¹Ÿå³ç­‰é•¿ä¸”ä¸€ä¸€å¯¹åº”çš„listï¼Œåˆ™å¯ä»¥ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># borrow from stackoverflow</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(a) == len(b)</span><br><span class="line">    start_state = random.getstate()</span><br><span class="line">    random.shuffle(a)</span><br><span class="line">    random.setstate(start_state)</span><br><span class="line">    random.shuffle(b)</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br><span class="line">b = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">19</span>]</span><br><span class="line">shuffle(a,b)</span><br><span class="line">print(a) <span class="comment"># [9, 7, 3, 1, 2, 5, 4, 8, 6]</span></span><br><span class="line">print(b) <span class="comment"># [19, 17, 13, 11, 12, 15, 14, 18, 16]</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£-inverse-tensor"><a href="#2ï¸âƒ£-inverse-tensor" class="headerlink" title="2ï¸âƒ£[inverse tensor]"></a>2ï¸âƒ£[inverse tensor]</h3><p>Pytorchç›®å‰è¿˜ä¸æ”¯æŒæ­¥è¿›ä¸ºè´Ÿçš„æƒ…å†µï¼Œå› æ­¤ä¸èƒ½ä½¿ç”¨ç±»ä¼¼Pythonçš„<code>l[::-1]</code>çš„æ–¹æ³•reverse tensorã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">inv_idx = torch.arange(tensor.size(<span class="number">0</span>)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>).long()</span><br><span class="line"><span class="comment"># or equivalently torch.range(tensor.size(0)-1, 0, -1).long()</span></span><br><span class="line">inv_tensor = tensor.index_select(<span class="number">0</span>, inv_idx)</span><br><span class="line"><span class="comment"># or equivalently</span></span><br><span class="line">inv_tensor = tensor[inv_idx]</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="3ï¸âƒ£-GRU-initialization"><a href="#3ï¸âƒ£-GRU-initialization" class="headerlink" title="3ï¸âƒ£[GRU initialization]"></a>3ï¸âƒ£[GRU initialization]</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gru_init</span><span class="params">(self)</span>:</span>   <span class="comment"># use orthogonal seems better</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_ih_l0.data)  <span class="comment">#æ²¡æœ‰dataä¸è¡Œï¼Œä¼šæŠ¥leaf variable in-placeé”™è¯¯ï¼Œå¯èƒ½weight_ih_l0ä¸æ˜¯parameter</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_hh_l0.data)</span><br><span class="line">    self.word_RNN.bias_ih_l0.data.zero_()</span><br><span class="line">    self.word_RNN.bias_hh_l0.data.zero_()</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4ï¸âƒ£-sort-counter"><a href="#4ï¸âƒ£-sort-counter" class="headerlink" title="4ï¸âƒ£[sort counter]"></a>4ï¸âƒ£[sort counter]</h3><p>éœ€æ±‚ï¼šç»Ÿè®¡documentçš„å¥å­ä¸ªæ•°çš„åˆ†å¸ƒï¼Œå¹¶æŒ‰ç…§é•¿åº¦é¡ºåºæ’åˆ—ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n_sents=[len(sentences) <span class="keyword">for</span> sentences <span class="keyword">in</span> documents]</span><br><span class="line">n_lengths=Counter(n_sents)</span><br><span class="line">n_lengths=sorted(n_lengths.items())</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†17</title>
    <url>/2018/12/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8617/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨æœ‰RNNçš„ä»£ç ä¸­ï¼Œå¦‚æœå‡ºç°</p>
<blockquote>
<p>Cuda Error : RuntimeError: CUDNN_STATUS_EXECUTION_FAILED</p>
</blockquote>
<p>é‚£ä¹ˆå¯èƒ½çš„å‡ºé”™åŸå› æ˜¯æ²¡æœ‰å°†init stateæ”¾å…¥cudaä¸­ã€‚</p>
<p>Reference: <a href="https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625" target="_blank" rel="noopener">https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625</a></p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>clone() â†’ Tensor<br>Returns a copy of the self tensor. The copy has the same size and data type as self.<br><strong>Unlike copy_(), this function is recorded in the computation graph. Gradients propagating to the cloned tensor will propagate to the original tensor.</strong></p>
<p>å¦‚æœéœ€è¦å¦ä¸€ä¸ªç›¸åŒçš„tensoråšå…¶ä»–è®¡ç®—ï¼Œåˆ™ä½¿ç”¨clone()è€Œä¸æ˜¯copy_()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">forward_vec=sent_vec</span><br><span class="line"><span class="comment"># backward_vec=sent_vec   wrong</span></span><br><span class="line">backward_vec=sent_vec.clone()</span><br></pre></td></tr></table></figure>
<p>å½“ç„¶ä¹Ÿä¸èƒ½ç›´æ¥èµ‹å€¼ï¼Œå› ä¸ºèµ‹çš„åªæ˜¯æŒ‡é’ˆï¼Œæ”¹å˜backward_vecä¹Ÿä¼šæ”¹å˜åŸæ¥çš„å€¼ã€‚</p>
<hr>
<h3 id="3ï¸âƒ£-Python"><a href="#3ï¸âƒ£-Python" class="headerlink" title="3ï¸âƒ£[Python]"></a>3ï¸âƒ£[Python]</h3><p>Pythonä¸­<code>==</code>å’Œ<code>is</code>çš„åŒºåˆ«ï¼š<br>isè¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªobjectï¼›è€Œ==è¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªå€¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str=<span class="string">'GRU'</span></span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str=str.upper()</span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># False</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4ï¸âƒ£-RNN"><a href="#4ï¸âƒ£-RNN" class="headerlink" title="4ï¸âƒ£[RNN]"></a>4ï¸âƒ£[RNN]</h3><p>åœ¨RNNçš„åˆå§‹åŒ–ä¸­ï¼Œä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ä¼šæ¯”å…¶ä»–æ–¹æ³•å¥½ä¸€äº›ï¼ˆå¾…å¯¹æ¯”å®éªŒæµ‹éªŒï¼‰ã€‚<br>Reference: <a href="https://smerity.com/articles/2016/orthogonal_init.html" target="_blank" rel="noopener">https://smerity.com/articles/2016/orthogonal_init.html</a></p>
<hr>
<h3 id="5ï¸âƒ£-Pytorch"><a href="#5ï¸âƒ£-Pytorch" class="headerlink" title="5ï¸âƒ£[Pytorch]"></a>5ï¸âƒ£[Pytorch]</h3><p>åœ¨æä¾›é¢„è®­ç»ƒembeddingä½œä¸ºåˆå§‹åŒ–æ—¶ï¼Œæ­£ç¡®åšæ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> pretrained_matrix <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    pretrained_matrix=torch.from_numpy(pretrained_matrix).type(torch.FloatTensor)</span><br><span class="line">    self.embedding.weight= nn.Parameter(pretrained_matrix,</span><br><span class="line">                                                requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>å¿…é¡»è¦æœ‰<code>.type(torch.FloatTensor)</code>ï¼Œå¦åˆ™ä¼šå‡ºé”™ï¼šCuDNN error: CUDNN_STATUS_EXECUTION_FAILED</p>
<hr>
<h3 id="6ï¸âƒ£-Pytorch"><a href="#6ï¸âƒ£-Pytorch" class="headerlink" title="6ï¸âƒ£[Pytorch]"></a>6ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ï¼Œå°†åˆå§‹hidden stateä½œä¸ºå¯å­¦ä¹ å‚æ•°å®è·µï¼š<br><a href="https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9" target="_blank" rel="noopener">https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9</a><br><a href="https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7" target="_blank" rel="noopener">https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>A Day with Google</title>
    <url>/2018/12/23/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/A%20Day%20with%20Google/</url>
    <content><![CDATA[<p>æœ¬å‘¨ä¸€ä¹¡ä¸‹äººç»ˆäºå†æ¬¡è¿›åŸäº†ğŸ™ˆ<br><img src="/images/IMG_2243.jpg" width="70%" height="50%"></p>
<p><img src="/images/IMG_8631.jpg" width="70%" height="50%"></p>
<p>æœ¬æ¬¡çš„ç›®çš„æ˜¯æ¥å‚è§‚Googleã€‚</p>
<p>é«˜æ¥¼æ—ç«‹ï¼š<br><img src="/images/IMG_2273.jpg" width="70%" height="50%"></p>
<p>Here We are:<br><img src="/images/IMG_9209-1.jpg" width="70%" height="50%"></p>
<p>å’•æœæ˜¯ä»€ä¹ˆé¬¼ï¼Ÿ<br><img src="/images/IMG_3389.jpg" width="70%" height="50%"></p>
<p>å®£è®²ï¼š<br><img src="/images/IMG_1782.jpg" width="70%" height="50%"></p>
<p><img src="/images/IMG_1075.jpg" width="70%" height="50%"></p>
<p>ä¸å¾—ä¸æ„Ÿæ…¨é£Ÿå ‚çœŸå¥½ğŸ¦†ï¼Œè¿˜æœ‰ä¸“é—¨åƒé¢çš„é£Ÿå ‚ã€‚è€Œä¸”è¿˜éƒ½ä¸ç”¨é’±ğŸ™‰ï¼Œå¯¹æ¯”å¼ æ±Ÿçš„é£Ÿå ‚ğŸ™‰ï¼š</p>
<p><img src="/images/IMG_0546.jpg" width="70%" height="50%"></p>
<p>æºœäº†æºœäº†ï¼š<br><img src="/images/IMG_1255.jpg" width="70%" height="50%"></p>
<p><img src="/images/IMG_1256.jpg" width="70%" height="50%"></p>
]]></content>
      <tags>
        <tag>Google</tag>
        <tag>æ´»åŠ¨</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡10</title>
    <url>/2018/12/23/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8710/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect"><a href="#1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect" class="headerlink" title="1ï¸âƒ£[Regularization of Neural Networks using DropConnect]"></a>1ï¸âƒ£[Regularization of Neural Networks using DropConnect]</h2><p>åœ¨dropoutçš„åŸºç¡€ä¸Šæå‡ºdropconnectã€‚ä¸dropoutä¸åŒçš„æ˜¯ï¼Œdropconnectå¯¹weightè¿›è¡Œdropè€Œä¸æ˜¯å¯¹layerè¿›è¡Œdropã€‚</p>
<p>åˆ›æ–°ä¹‹å¤„åœ¨äºinferenceçš„æ—¶å€™å’Œdropoutä¸åŒã€‚</p>
<h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><p><img src="/images/15455297378934.jpg" width="50%" height="50%"></p>
<h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><img src="/images/15455297645976.jpg" width="50%" height="50%"></p>
<p>åœ¨inferenceçš„æ—¶å€™é€šè¿‡é«˜æ–¯é‡‡æ ·çš„æ–¹æ³•å»æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚<br><strong>intuition</strong>ï¼š<br>æœ¬æ–‡å¯¹dropoutåœ¨inferenceç®€å•å¯¹unitè¿›è¡Œç¼©æ”¾è¿›è¡Œåæ€ï¼Œè®¤ä¸ºè¿™åœ¨æ•°å­¦ä¸Šå¹¶ä¸åˆç†ï¼Œå› æ­¤æå‡ºç”¨é«˜æ–¯åˆ†å¸ƒå»é‡‡æ ·ã€‚<br><img src="/images/15455299241433.jpg" width="50%" height="50%"></p>
<p><img src="/images/15455299403032.jpg" width="50%" height="50%"></p>
<p><img src="/images/15455299548705.jpg" width="50%" height="50%"></p>
<hr>
<h2 id="2ï¸âƒ£-Attentive-Pooling-Networks"><a href="#2ï¸âƒ£-Attentive-Pooling-Networks" class="headerlink" title="2ï¸âƒ£[Attentive Pooling Networks]"></a>2ï¸âƒ£[Attentive Pooling Networks]</h2><p>æå‡ºattentive poolingæœºåˆ¶ï¼Œç”¨ä»¥answer selectionã€‚<br>ï¼ˆä»€ä¹ˆæ˜¯answer selectionï¼šç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œç»™å®šå¤šä¸ªç­”æ¡ˆå€™é€‰ï¼Œè¦ä»ç­”æ¡ˆé€‰é¡¹ä¸­é€‰æ‹©æ­£ç¡®çš„ç­”æ¡ˆã€‚ï¼‰</p>
<p>ä¼ ç»Ÿanswer selectionï¼š<br><img src="/images/15455301265939.jpg" width="35%" height="50%"><br>é¦–å…ˆå°†è¯è½¬åŒ–æˆè¯å‘é‡ï¼Œæ¥ç€é€šè¿‡bi-LSTMæˆ–CNNè·å¾—ä¸€ä¸ªçŸ©é˜µè¡¨ç¤ºï¼Œæ¥ä¸‹æ¥å¯¹Qå’ŒAåˆ†åˆ«è¿›è¡Œmax-poolingè·å¾—å›ºå®šè¡¨ç¤ºï¼Œæœ€åé€šè¿‡cosè·ç¦»åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ˜¯æ­£ç¡®ç­”æ¡ˆï¼Œä»ç­”æ¡ˆå€™é€‰ä¸­é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ã€‚</p>
<p>ä½†è¿™æ ·çš„é—®é¢˜åœ¨äºQå’ŒAä¹‹é—´æ²¡æœ‰äº¤äº’ã€‚</p>
<p>æœ¬æ–‡åˆ©ç”¨attentionä½œä¸ºQå’ŒAçš„äº¤äº’ã€‚<br><img src="/images/15455301891043.jpg" width="39%" height="50%"></p>
<p>è·å¾—Qå’ŒAçŸ©é˜µçš„æ–¹å¼æ˜¯ä¸€è‡´çš„ã€‚<br>æ¥ä¸‹æ¥ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªGçŸ©é˜µï¼Œé€šè¿‡åŒçº¿æ€§attentionå…¬å¼è·å¾—ï¼š<br><img src="/images/15455302279543.jpg" width="20%" height="50%"></p>
<p>Gæ‰€ä»£è¡¨çš„æ„ä¹‰æ˜¯Qå’ŒAçš„æ¯ä¸ªè¯ä¹‹é—´çš„å¯¹é½ï¼šå¯¹äºç¬¬iè¡Œæ¥è¯´ï¼Œä»£è¡¨Qçš„ç¬¬iä¸ªè¯å’ŒAä¸­æ‰€æœ‰è¯çš„ä¸€ä¸ªåˆ†æ•°ï¼›å¯¹äºç¬¬jåˆ—æ¥è¯´ï¼Œä»£è¡¨ç¬¬jä¸ªè¯å’ŒQä¸­æ‰€æœ‰è¯çš„åˆ†æ•°ã€‚</p>
<p>æ¥ä¸‹æ¥å¯¹Gçš„è¡Œå’Œåˆ—åˆ†åˆ«è¿›è¡Œmax-poolingæ“ä½œï¼š<br><img src="/images/15455303089243.jpg" width="25%" height="50%"></p>
<p>æ­¤æ­¥ä»£è¡¨é€‰æ‹©ä¸æŸè¯å…³ç³»æœ€é‡è¦çš„è¯ã€‚</p>
<p>æ¥ä¸‹æ¥å¯¹gåˆ†åˆ«è¿›è¡Œsoftmaxï¼Œå†åˆ†åˆ«è¿›è¡Œç‚¹ç§¯ä»¥è·å¾—æœ€ç»ˆå‘é‡è¡¨ç¤ºï¼š<br><img src="/images/15455303516483.jpg" width="13%" height="50%"></p>
<p>åŒæ ·ï¼Œæœ€ç»ˆä½¿ç”¨cosè·ç¦»è®¡ç®—ç›¸ä¼¼åº¦ã€‚</p>
<hr>
<h2 id="3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout"><a href="#3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout" class="headerlink" title="3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]"></a>3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]</h2><p>æ˜¯ä»æ•°æ®å¢å¼ºå’Œdropoutçš„è§’åº¦ï¼š</p>
<blockquote>
<p>dropout in convolutional layers simply acts to increase robustness to noisy inputs, rather than having the same model averaging effect that is observed in fully-connected layers</p>
</blockquote>
<p>æŸä¸ªè¾“å…¥è¢«ç§»å»ï¼Œæ‰€æœ‰åé¢ç›¸å…³çš„çš„feature mapéƒ½è¢«ç§»å»ï¼š</p>
<blockquote>
<p>In this sense, cutout is much closer to data augmentation than dropout, as it is not creating noise, but instead generating images that appear novel to the network</p>
</blockquote>
<p>å…¶å®åªæ˜¯å°†è¾“å…¥éšæœºdropæ‰ä¸€å—ã€‚<br><img src="/images/15455304317998.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>DropConnect</tag>
        <tag>Cutout</tag>
        <tag>Attentive Pooling</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•13</title>
    <url>/2018/12/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9513/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-flatten-list"><a href="#1ï¸âƒ£-flatten-list" class="headerlink" title="1ï¸âƒ£[flatten list]"></a>1ï¸âƒ£[flatten list]</h3><p>å¯¹äºŒç»´listè¿›è¡Œå±•å¼€ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list2d = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>], [<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"><span class="comment"># â‘ </span></span><br><span class="line">flatten = [l <span class="keyword">for</span> list <span class="keyword">in</span> list2d <span class="keyword">for</span> l <span class="keyword">in</span> list]</span><br><span class="line"><span class="comment"># â‘¡</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">merged = list(itertools.chain(*list2d))</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">merged = list(itertools.chain.from_iterable(list2d))</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†16</title>
    <url>/2018/12/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8616/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Softmax"><a href="#1ï¸âƒ£-Softmax" class="headerlink" title="1ï¸âƒ£[Softmax]"></a>1ï¸âƒ£[Softmax]</h3><p>åœ¨ä½¿ç”¨softmaxçš„æ—¶å€™ï¼Œè¦éå¸¸æ³¨æ„softmaxçš„è¡Œä¸ºã€‚åº”å°½é‡æ§åˆ¶softmaxå‰å…ƒç´ çš„è§„æ¨¡ï¼Œå¦åˆ™å®¹æ˜“å‡ºç°one-hotçš„æƒ…å†µï¼Œå¯¼è‡´è®­ç»ƒå›°éš¾ã€‚<br><img src="/images/15455275366030.jpg" width="70%" height="50%"></p>
<p>åŒæ—¶ï¼Œå¯¹å…¨-infåšsoftmaxæ˜¯æœªå®šä¹‰çš„ï¼Œå› æ­¤ä¹Ÿä¼šå‡ºç°é—®é¢˜ï¼š<br><img src="/images/15455278529550.jpg" width="40%" height="50%"></p>
<hr>
<h3 id="2ï¸âƒ£-slice"><a href="#2ï¸âƒ£-slice" class="headerlink" title="2ï¸âƒ£[slice]"></a>2ï¸âƒ£[slice]</h3><p>åœ¨å¯¹tensoræˆ–arrayæ“ä½œæ—¶ï¼Œå¦‚æœéœ€è¦å–æŸç»´çš„sliceï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">a[:,<span class="number">1</span>:<span class="number">3</span>]  <span class="comment"># å–ç¬¬1åˆ—åˆ°ç¬¬2åˆ—çš„slice</span></span><br><span class="line">a[:][<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># wrongï¼Œè·å¾—çš„æ˜¯ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„slice</span></span><br></pre></td></tr></table></figure>
<p>åŸå› æ˜¯ï¼Œ<code>a[:][1:3]</code>æ˜¯å…ˆåš<code>a[:]</code>æ“ä½œï¼Œè·å¾—äº†å…¨éƒ¨å…ƒç´ ï¼Œç„¶åå†åš<code>[1:3]</code>æ“ä½œï¼Œä¹Ÿå³è·å¾—ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„å…ƒç´ ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Python</tag>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•12</title>
    <url>/2018/12/16/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9512/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-CUDA-time"><a href="#1ï¸âƒ£-CUDA-time" class="headerlink" title="1ï¸âƒ£[CUDA time]"></a>1ï¸âƒ£[CUDA time]</h3><p>æ­£ç¡®æµ‹è¯•ä»£ç åœ¨cudaè¿è¡Œæ—¶é—´ã€‚éœ€è¦åŠ ä¸Š<code>torch.cuda.synchronize()</code>ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line">b = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">M = torch.bmm(a, b.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"bmm"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">local_a = a.unsqueeze(<span class="number">2</span>)</span><br><span class="line">local_b = b.unsqueeze(<span class="number">1</span>)</span><br><span class="line">N = (local_a*local_b).sum(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"element-wise"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"output difference (should be 0)"</span>, (N - M).abs().max())</span><br><span class="line">print(<span class="string">"In single precision this can fail because of the size of the tensors."</span>)</span><br><span class="line">print(<span class="string">"Using double should always work"</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†15</title>
    <url>/2018/12/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8615/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨0.41çš„pytorchä¸­ï¼Œbernoulliçš„é€Ÿåº¦ä¼šæ¯”éšæœºsampleçš„é€Ÿåº¦æ…¢å¾ˆå¤šï¼›<br>åœ¨1.0ä¸­ä¿®å¤äº†è¯¥bugï¼Œä½†é€Ÿåº¦ä¸Šè¿˜æ˜¯éšæœºsampleå¿«ä¸€ç‚¹ç‚¹ã€‚</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Pytorch0.41</span><br><span class="line">Bernoulli  0.430371046066</span><br><span class="line">sample  0.24411702156</span><br><span class="line"></span><br><span class="line"># Pytorch1.0</span><br><span class="line">Bernoulli  0.256921529</span><br><span class="line">sample  0.25317035184</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ä»¥ä¸‹äºŒè€…ç­‰ä»·</span></span><br><span class="line">mask = Bernoulli(gamma).sample(x.size()) <span class="comment"># slow</span></span><br><span class="line">mask = (torch.rand_like(x)&lt;gamma).float() <span class="comment"># faster</span></span><br></pre></td></tr></table></figure>
<p>Reference:<br><a href="https://github.com/pytorch/pytorch/issues/6940" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/6940</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡9</title>
    <url>/2018/12/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%879/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation"><a href="#1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation" class="headerlink" title="1ï¸âƒ£[Sentence-State LSTM for Text Representation]"></a>1ï¸âƒ£[Sentence-State LSTM for Text Representation]</h2><p>æå‡ºä¸€ç§æ–°å‹çš„encodeå¥å­çš„æ–¹æ³•ã€‚æœ‰ç‚¹ç±»ä¼¼gather-distributeçš„æƒ³æ³•ã€‚</p>
<p><img src="/images/15449283844319.jpg" width="45%" height="50%"></p>
<p>æ¯ä¸ªæ—¶é—´æ­¥tæ‰€æœ‰çš„hä¸€èµ·æ›´æ–°ã€‚æ›´æ–°æ–¹å¼æ˜¯ä¸å…¶å·¦å³çš„ç‚¹è¿›è¡Œäº¤äº’ï¼ŒåŒæ—¶ä¸ä¸€ä¸ªglobal representationè¿›è¡Œäº¤äº’ã€‚è¿™æ ·å³è€ƒè™‘äº†localçš„ä¿¡æ¯ä¹Ÿè€ƒè™‘äº†globalçš„ä¿¡æ¯ã€‚æ¯æ¬¡æ›´æ–°éƒ½å¢åŠ äº†ä¿¡æ¯äº¤äº’ï¼Œä»3gramåˆ°5gramå†åˆ°7gramâ€¦</p>
<p>å…·ä½“æ¥è¯´ï¼š<br>â‘ å¦‚ä½•æ±‚$h_i$<br><img src="/images/15449285619763.jpg" width="45%" height="50%"></p>
<p>ä»å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„$h_i$ï¼ŒåŒæ—¶è€ƒè™‘å·¦å³ä¸¤ç‚¹ï¼Œä»¥åŠglobalä¿¡æ¯$g$ï¼Œä»¥åŠè¾“å…¥$x$ã€‚</p>
<p>â‘¡å¦‚ä½•æ±‚g<br><img src="/images/15449286595709.jpg" width="50%" height="50%"></p>
<p>é€šè¿‡averageåŒæ—¶è€ƒè™‘æ‰€æœ‰çš„è¯ï¼ŒåŒæ—¶è€ƒè™‘è‡ªå·±ä¸Šä¸€ä¸ªçŠ¶æ€ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>LSTM</tag>
        <tag>Encode</tag>
      </tags>
  </entry>
  <entry>
    <title>Pythonä¸­çš„+=æ“ä½œ</title>
    <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84+=%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>å‰å‡ æ—¥åœ¨å†™ä¸€æ®µPytorchä»£ç æ—¶ï¼Œåˆä¸€æ¬¡é‡åˆ°äº†in-placeæ“ä½œçš„é—®é¢˜ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output+=pos  <span class="comment"># posæ˜¯ä¸å¯æ›´æ–°çš„tensorï¼Œoutputæ˜¯å¯æ›´æ–°çš„tensor</span></span><br></pre></td></tr></table></figure>
<p>ç¨‹åºæŠ¥é”™ï¼šâ€œone of the variables needed for gradient computation has been modified by an inplace operationâ€ã€‚</p>
<p>æ— æ„ä¸­å°†ä»£ç æ”¹æˆ<code>output=output+pos</code>ï¼Œç¨‹åºå°±ä¸ä¼šæŠ¥é”™äº†ã€‚</p>
<p>åœ¨æŸ¥é˜…äº†ç›¸å…³èµ„æ–™åï¼Œå°†æˆ‘çš„æ€è€ƒæ•´ç†ä¸‹æ¥ã€‚</p>
<p>åœ¨Pythonä¸­ï¼Œ<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ä¸åŒçš„ï¼Œå¦‚æœè¢«æ“ä½œæ•°æ²¡æœ‰éƒ¨ç½² â€™<strong>iadd</strong>â€˜æ–¹æ³•ï¼Œåˆ™<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ç­‰ä»·çš„ï¼Œâ€™+=â€˜å¹¶ä¸ä¼šäº§ç”Ÿin-placeæ“ä½œï¼›å½“è¢«æ“ä½œæ•°æœ‰éƒ¨ç½²è¯¥æ–¹æ³•ä¸”æ­£ç¡®éƒ¨ç½²ï¼Œåˆ™æ˜¯ä¼šäº§ç”Ÿin-placeæ“ä½œçš„ã€‚å½“æ²¡æœ‰in-placeæ“ä½œæ—¶ï¼Œ<code>i=i+1</code>è¡¨ç¤ºå¯¹ié‡åˆ†é…ï¼Œä¹Ÿå³iæŒ‡å‘äº†å¦ä¸€ä¸ªç©ºé—´è€Œä¸æ˜¯åŸæ¥çš„ç©ºé—´ã€‚</p>
<p>æ‰€ä»¥ï¼Œè¿™æ ·çš„ä¾‹å­å°±èƒ½è§£é‡Šæ¸…æ¥šäº†ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    a = a + <span class="number">1</span></span><br><span class="line"><span class="comment"># Aå¹¶æ²¡æœ‰è¢«æ”¹å˜</span></span><br><span class="line">B = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">    b += <span class="number">1</span></span><br><span class="line"><span class="comment"># Bè¢«æ”¹å˜äº†</span></span><br></pre></td></tr></table></figure>
<p>åœ¨Pytorchä¸­ï¼Œä¹Ÿæœ‰éƒ¨ç½²â€™<strong>iadd</strong>()â€˜æ“ä½œï¼Œæ‰€ä»¥å¯¹äº<code>output+=pos</code>ï¼Œoutputå†…éƒ¨çš„å€¼è¢«æ”¹å˜äº†ï¼Œä¹Ÿå³åœ¨è®¡ç®—å›¾ä¸­å¼•å…¥äº†ç¯ï¼Œåœ¨åå‘æ±‚å¯¼æ—¶åˆ™ä¼šå‡ºé”™ã€‚</p>
<p>å› æ­¤ï¼Œåœ¨Pytorchä¸­ï¼Œåº”å½“é¿å…in-placeçš„æ“ä½œã€‚</p>
<p>Reference:<br><a href="https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop" target="_blank" rel="noopener">https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡8</title>
    <url>/2018/12/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%878/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding"><a href="#1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding" class="headerlink" title="1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]"></a>1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]</h2><p>æå‡ºäº†ä¸¤ç§attentionæœºåˆ¶ï¼Œå³ multi-dimentional attentionå’Œdirectional self-attentionï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæå‡ºæœ‰å‘è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼ˆdirectional self-attention network)</p>
<h3 id="Multi-dimensional-Attention"><a href="#Multi-dimensional-Attention" class="headerlink" title="Multi-dimensional Attention"></a>Multi-dimensional Attention</h3><p>ä¸ä¼ ç»Ÿçš„æ–¹æ³•ä¸åŒçš„æ˜¯ï¼Œå¯¹äºæ¯ä¸ªè¯å¯¹ï¼Œattentionå‡ºæ¥çš„ä¸æ˜¯æ ‡é‡è€Œæ˜¯å‘é‡ã€‚<br><img src="/images/15443239891184.jpg" width="60%" height="50%"></p>
<p>è®¡ç®—å…¬å¼ï¼š<br><img src="/images/15443240335179.jpg" width="40%" height="50%"></p>
<p>$f$çš„ç»´åº¦ä¸$q$ç›¸åŒï¼Œæ¯ä¸€ç»´ä»£è¡¨çš„æ˜¯$x_i$åœ¨è¯¥ç»´å¯¹$q$çš„é‡è¦æ€§ã€‚ä¹Ÿå³feature-wiseçš„attentionã€‚å› æ­¤å¯¹äº$q$è€Œè¨€ï¼Œå…¶è·å¾—çš„åŠ æƒæ±‚å’Œå‘é‡ä¸ºï¼š<br><img src="/images/15443241367138.jpg" width="55%" height="50%"></p>
<p>ä½¿ç”¨feature-wiseçš„attentionèƒ½å¤Ÿè§£å†³ä¸€æ¬¡å¤šä¹‰çš„é—®é¢˜ï¼Œå› ä¸ºèƒ½å¤Ÿè®¡ç®—æ¯ä¸€ç»´çš„é‡è¦æ€§ï¼Œåœ¨ä¸åŒçš„contextä¸‹æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</p>
<p>å°†å…¶åº”ç”¨äºself-attentionä¸­ï¼Œæœ‰ä¸¤ç§å˜ä½“ï¼š<br>â‘ token2token<br><img src="/images/15443242128118.jpg" width="58%" height="50%"></p>
<p><img src="/images/15443242249947.jpg" width="20%" height="50%"></p>
<p>å› æ­¤xåœ¨äº¤äº’å®Œæœ‰ï¼š<br><img src="/images/15443242733208.jpg" width="35%" height="50%"></p>
<p>â‘¡source2token<br><img src="/images/15443243090328.jpg" width="40%" height="50%"></p>
<p>ä¹Ÿå³$x_i$æ²¡æœ‰å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ã€‚<br>å¯ç”¨ä½œè·å¾—sentence encodingï¼š<br><img src="/images/15443243968731.jpg" width="20%" height="50%"></p>
<h3 id="Directional-Self-Attention"><a href="#Directional-Self-Attention" class="headerlink" title="Directional Self-Attention"></a>Directional Self-Attention</h3><p>ä½¿ç”¨maskè¾¾åˆ°æœ‰å‘æ€§è¿™ä¸€ç›®çš„ï¼š<strong>é€šè¿‡maskçŸ©é˜µå°†ä½ç½®/æ–¹å‘ç¼–ç è¿›attentionï¼Œè§£å†³æ—¶åºä¸¢å¤±é—®é¢˜</strong>ã€‚<br>é¦–å…ˆå°†xè¿‡ä¸€å±‚è·å¾—æ–°çš„hè¡¨ç¤ºï¼š<br><img src="/images/15443244421489.jpg" width="27%" height="50%"></p>
<p>æ¥ç€ä½¿ç”¨token2tokenæ±‚attentionï¼Œè¿™é‡Œä¸ºäº†å‡å°‘å‚æ•°ä½œäº†ä¸€å®šæ”¹åŠ¨ï¼Œå°†Wæ¢æˆcï¼Œtanhæ›¿æ¢Ïƒã€‚<br><img src="/images/15443245099821.jpg" width="53%" height="50%"></p>
<p>$\textbf{1}$æ˜¯å…¨1çš„å‘é‡ã€‚Må°±æ˜¯maskçŸ©é˜µï¼Œä»£è¡¨iä¸jæ˜¯å¦è¿é€šï¼ŒMaskçŸ©é˜µæœ‰ï¼š<br><img src="/images/15443248745747.jpg" width="28%" height="50%"></p>
<p><img src="/images/15443248908199.jpg" width="31%" height="50%"></p>
<p>ä¹Ÿå³ï¼š<br><img src="/images/15443249388350.jpg" width="50%" height="50%"></p>
<p>é¦–å…ˆmaskæ‰è‡ªå·±ï¼Œç¬¬äºŒï¼šåˆ†åˆ«maskæ‰forwardå’Œbackwardï¼Œç±»ä¼¼biLSTMï¼Œåªå’Œå‰é¢æˆ–åé¢çš„äº¤äº’ã€‚</p>
<h3 id="Directional-Self-Attention-Network"><a href="#Directional-Self-Attention-Network" class="headerlink" title="Directional Self-Attention Network"></a>Directional Self-Attention Network</h3><p>åœ¨ä¸Šè¿°ä¸¤ä¸ªæ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæ­¤æ—¶å·²è·å¾—äº†ä¸Šä¸‹æ–‡ç›¸å…³çš„$s_i$ï¼Œå†å¼•å…¥fusion gateï¼š<br><img src="/images/15443250617220.jpg" width="45%" height="50%"></p>
<p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443250338890.jpg" width="50%" height="50%"></p>
<p>å°†å‰å‘å’Œåå‘çš„è¡¨ç¤ºæ‹¼æ¥èµ·æ¥ï¼Œè·å¾—æœ€ç»ˆçš„è¡¨ç¤º$[u^{fw};u^{bw}]$ï¼š<br><img src="/images/15443251919096.jpg" width="50%" height="50%"></p>
<p>å¯¹äºæ‰€è·å¾—çš„æ¯ä¸€ä¸ªè¡¨ç¤ºï¼Œé€šè¿‡source2tokenï¼Œè·å¾—æœ€ç»ˆçš„å¥å­è¡¨ç¤ºã€‚</p>
<p>è¿™ä¸€ç‚¹è®ºæ–‡ä¹Ÿæåˆ°äº†ï¼Œéå¸¸ç±»ä¼¼bi-LSTMã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Targeted-Dropout"><a href="#2ï¸âƒ£-Targeted-Dropout" class="headerlink" title="2ï¸âƒ£[Targeted Dropout]"></a>2ï¸âƒ£[Targeted Dropout]</h2><p>ä¸€ç§ç½‘ç»œå‰ªææ–¹æ³•ï¼Œæƒ³æ³•ç®€å•æ˜“å®ç°ã€‚<br>ç®€å•è¯´ï¼Œåœ¨æ¯æ¬¡æ›´æ–°æ—¶å¯¹æœ€ä¸é‡è¦çš„weightæˆ–è€…unitè¿›è¡Œéšæœºdropoutã€‚</p>
<h3 id="Targeted-Dropout"><a href="#Targeted-Dropout" class="headerlink" title="Targeted Dropout"></a>Targeted Dropout</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>ç»™å®šè¾“å…¥Xï¼Œæƒé‡Wï¼Œè¾“å‡ºY Mä¸ºdropoutçš„maskçŸ©é˜µã€‚<br>unit dropoutï¼š<br><img src="/images/15443218016315.jpg" width="22%" height="50%"></p>
<p>weight dropoutï¼š<br><img src="/images/15443218315803.jpg" width="22%" height="50%"></p>
<p>ä¹Ÿå³dropæ‰çš„æ˜¯layerä¹‹é—´çš„connectionã€‚</p>
<h4 id="Magnitude-based-pruning"><a href="#Magnitude-based-pruning" class="headerlink" title="Magnitude-based pruning"></a>Magnitude-based pruning</h4><p>å‰ªæé€šå¸¸å¯¹æƒé‡æœ€å°çš„è¿›è¡Œå‰ªæï¼Œä¹Ÿå³ä¿ç•™topkä¸ªæœ€å¤§çš„æƒé‡ã€‚</p>
<p>Unit pruningï¼šç›´æ¥å‰ªæ‰çš„æ˜¯ä¸€æ•´åˆ—ï¼Œä¹Ÿå³ä¸€ä¸ªunit<br><img src="/images/15443218793541.jpg" width="43%" height="50%"></p>
<p>Weight pruningï¼šå¯¹Wçš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå‰ªæã€‚æ³¨æ„æ˜¯å¯¹æ¯è¡Œçš„topkè¿›è¡Œä¿ç•™<br><img src="/images/15443219325533.jpg" width="58%" height="50%"></p>
<p>å¯ä»¥ç†è§£æˆå¯¹ä¸€ä¸ªunitæ¥è¯´ï¼Œä¿ç•™æœ€é«˜çš„kä¸ªconnectionã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>ç»“åˆdropoutå’Œå‰ªæã€‚<br>ä¸»è¦æ€æƒ³ï¼šé¦–å…ˆé€‰æ‹©N-kæœ€ä¸é‡è¦çš„elementï¼Œç”±äºæˆ‘ä»¬å¸Œæœ›è¿™äº›low-valueçš„å…ƒç´ æœ‰æœºä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜å¾—é‡è¦ï¼Œå› æ­¤æˆ‘ä»¬å¯¹è¿™äº›elementè¿›è¡Œéšæœºdropoutã€‚</p>
<p>å¼•å…¥targeting proportion Î³å’Œdrop probability Î±ï¼Œäº¦å³ï¼šé€‰æ‹©æœ€ä½çš„Î³|Î¸|ä¸ªweightï¼Œå†æ ¹æ®Î±è¿›è¡Œdropoutã€‚<br>è¿™æ ·åšçš„ç»“æœæ˜¯ï¼šå‡å°‘é‡è¦çš„å­ç½‘ç»œå¯¹ä¸é‡è¦çš„å­ç½‘ç»œçš„ä¾èµ–ã€‚</p>
<h3 id="é™„å½•"><a href="#é™„å½•" class="headerlink" title="é™„å½•"></a>é™„å½•</h3><p>â‘ dropoutçš„intuitionï¼šå‡å°‘unitä¹‹é—´çš„ç›¸äº’é€‚åº”ã€‚when dropout is applied to a unit, the remaining network can no longer depend on that unitâ€™s contribution to the function and must learn to propagate that unitâ€™s information through a more reliable channelã€‚<br>ä¹Ÿå¯ä»¥ç†è§£æˆï¼šä½¿å¾—unitä¹‹é—´çš„äº¤äº’ä¿¡æ¯è¾¾åˆ°æœ€å¤§ï¼Œåœ¨å¤±å»æŸä¸ªunitçš„æ—¶å€™å½±å“ä¸ä¼šé‚£ä¹ˆå¤§ã€‚</p>
<p>â‘¡targeted dropout intuitionï¼šthe important subnetwork is completely separated from the unimportant oneã€‚å‡è®¾ä¸€ä¸ªç½‘ç»œç”±ä¸¤ä¸ªä¸ç›¸äº¤çš„å­ç½‘ç»œç»„æˆï¼Œæ¯ä¸ªéƒ½èƒ½è¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œæ€»çš„ç½‘ç»œæ˜¯è¿™ä¸¤ä¸ªç½‘ç»œçš„å¹³å‡ã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸é‡è¦çš„å­ç½‘ç»œè¿›è¡Œdropoutï¼ˆä¹Ÿå³å¾€å­ç½‘ç»œé‡ŒåŠ noiseï¼Œä¼šç ´åè¯¥å­ç½‘ç»œçš„è¾“å‡ºï¼Œç”±äºé‡è¦çš„å­ç½‘ç»œå·²ç»èƒ½å¤Ÿè¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œå› æ­¤ä¸ºäº†å‡å°‘æŸå¤±ï¼Œæˆ‘ä»¬éœ€è¦å‡å°‘ä¸é‡è¦ç½‘ç»œçš„è¾“å‡ºåˆ°0ï¼Œä¹Ÿå³killæ‰è¯¥å­ç½‘ç»œï¼Œå¹¶ä¸”åŠ å¼ºè¿™ä¸¤ä¸ªç½‘ç»œçš„åˆ†ç¦»ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥èˆå¼ƒå‘¢ï¼Ÿå› ä¸ºæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ‰å¯èƒ½ä¼šæœ‰å˜åŒ–ï¼‰<br>è¿™ä¸ªè§£é‡Šè¿˜æ˜¯æ²¡å®Œå…¨æ‡‚ã€‚</p>
<hr>
<h2 id="3ï¸âƒ£-A2-Nets-Double-Attention-Networks"><a href="#3ï¸âƒ£-A2-Nets-Double-Attention-Networks" class="headerlink" title="3ï¸âƒ£[A2-Nets: Double Attention Networks]"></a>3ï¸âƒ£[A2-Nets: Double Attention Networks]</h2><p>å‘è¡¨äºNIPS2018ï¼Œä¸ªäººè®¤ä¸ºå¾ˆæœ‰å¯å‘ã€‚æå‡ºä¸€ç§æ–°çš„attentionæœºåˆ¶ï¼ŒåŸºäºâ€œæ”¶é›†-åˆ†å‘â€çš„æ€æƒ³ï¼Œèƒ½å¤Ÿè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ã€‚</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>CNNæœ¬èº«ä¸»è¦æ˜¯æ•è·å±€éƒ¨ç‰¹å¾ä¸å…³ç³»ï¼Œä½†å¯¹äºé•¿è·ç¦»ä¹‹é—´çš„å…³ç³»åªèƒ½é€šè¿‡å †å å¤šå‡ å±‚æ‰èƒ½å®ç°ã€‚ä½†è¿™æ ·éœ€è¦æ›´é«˜çš„è®¡ç®—é‡ï¼Œä¸”å®¹æ˜“è¿‡æ‹Ÿåˆï¼›åŒæ—¶ï¼Œè¿œå¤„çš„ç‰¹å¾å®é™…ä¸Šæ˜¯æ¥è‡ªå¥½å‡ å±‚çš„å»¶è¿Ÿï¼Œå¯¼è‡´æ¨ç†çš„å›°éš¾ã€‚</p>
<p>é€šè¿‡å°†featureæ”¶é›†èµ·æ¥ï¼Œç„¶ååˆ†å‘ä¸‹å»ï¼Œä½¿å¾—featureä¹‹é—´æœ‰äº¤äº’ï¼Œè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œèƒ½å¤Ÿæ•è·é•¿è·ç¦»çš„ç‰¹å¾ã€‚</p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15443223814542.jpg" width="80%" height="50%"></p>
<p>ä¹Ÿå³ï¼š<br><img src="/images/15443224194279.jpg" width="34%" height="50%"></p>
<p>Xæ˜¯æ‰€æœ‰è¾“å…¥ï¼Œ$v_iæ˜¯$local featureã€‚</p>
<h4 id="The-First-Attention-Step-Feature-Gathering"><a href="#The-First-Attention-Step-Feature-Gathering" class="headerlink" title="The First Attention Step: Feature Gathering"></a>The First Attention Step: Feature Gathering</h4><p>å¯¹äºä¸¤ä¸ªfeature map A,Bï¼Œæœ‰ï¼š<br><img src="/images/15443225280678.jpg" width="40%" height="50%"></p>
<p>å…¶ä¸­ï¼š<br><img src="/images/15443226145868.jpg" width="35%" height="50%"></p>
<p><img src="/images/15443226262919.jpg" width="35%" height="50%"></p>
<p>å¦‚æœAã€Béƒ½æ¥è‡ªåŒä¸€ä¸ªXï¼Œå°†Bå½’ä¸€åŒ–softmaxï¼Œå°±ç±»ä¼¼transformerçš„attentionã€‚å…¶ä¸­ä¸Šå¼çš„æœ€å³è¾¹æ˜¯å¤–ç§¯çš„å½¢å¼ã€‚</p>
<p>æˆ‘ä»¬å°†Gæ‹†åˆ†æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/15443226708983.jpg" width="33%" height="50%"><br>åŒæ—¶å°†Bé‡å†™æˆè¡Œå‘é‡å½¢å¼ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15443227241595.jpg" width="22%" height="50%"></p>
<p>åˆ™ä¼šæœ‰ï¼š<br><img src="/images/15443227868015.jpg" width="28%" height="50%"></p>
<p>ä¸Šå¼è®©æˆ‘ä»¬æœ‰ä¸€ä¸ªæ–°çš„ç†è§£è§’åº¦ï¼šGå®é™…ä¸Šå°±æ˜¯ a bag of visual primitivesã€‚æ¯ä¸ª$g_i$æ˜¯æ‰€æœ‰local featureåŠ æƒæ±‚å’Œï¼Œå…¶ä¸­$b_i$æ˜¯æ±‚å’Œçš„weightã€‚</p>
<p>å› æ­¤æˆ‘ä»¬å¯¹Båšsoftmaxï¼Œä¿è¯æƒé‡ä¸º1ï¼š<br><img src="/images/15443228682403.jpg" width="28%" height="50%"></p>
<h4 id="The-Second-Attention-Step-Feature-Distribution"><a href="#The-Second-Attention-Step-Feature-Distribution" class="headerlink" title="The Second Attention Step: Feature Distribution"></a>The Second Attention Step: Feature Distribution</h4><p>åœ¨è·å¾—äº†å…¨å±€çš„feature Gåï¼Œç°åœ¨æ ¹æ®local featureå»è·å–å…¨å±€featureçš„éƒ¨åˆ†ï¼Œè¿™é€šè¿‡ä¸€ä¸ªæƒé‡æ§åˆ¶ï¼Œä¹Ÿå³$v_i$ï¼ˆlocal feature)çš„æ¯ä¸€ç»´ä½œä¸ºæƒé‡ã€‚å¯ä»¥ä¸å°†local feature $v_i$å½’ä¸€åŒ–ï¼Œä½†å½’ä¸€åŒ–èƒ½æ›´å¥½åœ°convergeã€‚</p>
<h4 id="The-Double-Attention-Block"><a href="#The-Double-Attention-Block" class="headerlink" title="The Double Attention Block"></a>The Double Attention Block</h4><p>æœ€ç»ˆå¾—åˆ°double attention blockï¼š<br><img src="/images/15443230115907.jpg" width="68%" height="50%"></p>
<p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443230641691.jpg" width="80%" height="50%"></p>
<p>æ‰€ä»¥å…¶å®æ˜¯æœ‰ä¸‰ä¸ªconvolution layerã€‚</p>
<p>ä¸Šå¼è¿˜å¯ä»¥å†™æˆï¼š<br><img src="/images/15443232642402.jpg" width="70%" height="50%"><br>æ•°å­¦ä¸Šç­‰ä»·ï¼Œä½†è®¡ç®—ä¸Šå·®å¾ˆå¤šã€‚ç¬¬ä¸€ä¸ªå¼å­ä¼šæœ‰æ›´ä½çš„å¤æ‚åº¦ã€‚</p>
<h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>è™½ç„¶ç”¨äº†attentionï¼Œä½†è¿™é‡Œå’ŒTransformerè¿˜æ˜¯æœ‰éå¸¸å¤§çš„åŒºåˆ«çš„ã€‚Transformeræ¯ä¸ªå…ƒç´ éƒ½å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ï¼Œé€šè¿‡ç›´æ¥çš„è®¡ç®—å¾—åˆ°æƒé‡ã€‚è€Œè¿™è¾¹çš„æƒé‡ç”±featureæœ¬èº«æ¥å†³å®šã€‚å¹¶æ²¡æœ‰ç›´æ¥çš„äº¤äº’ã€‚</p>
<hr>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>Dropout</tag>
        <tag>DiSAN</tag>
        <tag>Targeted Dropout</tag>
        <tag>double attention</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†14</title>
    <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8614/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchçš„tensorå’ŒTensoræ˜¯æœ‰åŒºåˆ«çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯æ ‡é‡ï¼Œsizeä¸º[]</span></span><br><span class="line">b = torch.Tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯å‘é‡ï¼Œsizeä¸º[2]</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯17</title>
    <url>/2018/12/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D17/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£è™ç¾äºº"><a href="#1ï¸âƒ£è™ç¾äºº" class="headerlink" title="1ï¸âƒ£è™ç¾äºº"></a>1ï¸âƒ£è™ç¾äºº</h3><p>[å®‹] å¶æ¢¦å¾—<br>è½èŠ±å·²ä½œé£å‰èˆï¼Œåˆé€é»„æ˜é›¨ã€‚æ™“æ¥åº­é™¢åŠæ®‹çº¢ï¼ŒæƒŸæœ‰æ¸¸ä¸ï¼Œåƒä¸ˆè¢…æ™´ç©ºã€‚<br>æ®·å‹¤èŠ±ä¸‹åŒæºæ‰‹ï¼Œæ›´å°½æ¯ä¸­é…’ã€‚ç¾äººä¸ç”¨æ•›è›¾çœ‰ï¼Œ<strong>æˆ‘äº¦å¤šæƒ…ï¼Œæ— å¥ˆé…’é˜‘æ—¶</strong>ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†13</title>
    <url>/2018/12/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8613/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-attention"><a href="#1ï¸âƒ£-attention" class="headerlink" title="1ï¸âƒ£[attention]"></a>1ï¸âƒ£[attention]</h3><p>æ‰€æœ‰attentionçš„æ€»ç»“ï¼š<br><img src="/images/15437180657954.jpg" width="70%" height="50%"><br><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention!</a></p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>â‘ torch.no_gradèƒ½å¤Ÿæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œmodel.evalä¸èƒ½ã€‚å› ä¸ºevalä¸ä¼šå…³é—­å†å²è¿½è¸ªã€‚</p>
<blockquote>
<p>model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval model instead of training mode.<br>torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).</p>
</blockquote>
<p>Reference:<br><a href="https://discuss.pytorch.org/t/does-model-eval-with-torch-set-grad-enabled-is-train-have-the-same-effect-for-grad-history/17183/3" target="_blank" rel="noopener">Does model.eval() &amp; with torch.set_grad_enabled(is_train) have the same effect for grad history?</a></p>
<p><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615" target="_blank" rel="noopener">â€˜model.eval()â€™ vs â€˜with torch.no_grad()â€™</a></p>
<p>â‘¡torch.full(â€¦) returns a tensor filled with value.</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•11</title>
    <url>/2018/12/02/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9511/</url>
    <content><![CDATA[<h2 id="â‘ "><a href="#â‘ " class="headerlink" title="â‘ "></a>â‘ </h2><p>éœ€æ±‚ï¼šå¯¹äºä¸¤ä¸ªå‘é‡$a$ã€$b$ï¼Œ$a,b \in R^d$ï¼Œå®šä¹‰ä¸€ç§å‡æ³•ï¼Œæœ‰ï¼š</p>
<script type="math/tex; mode=display">a-b=M</script><p>å…¶ä¸­$M \in R^{d\times d}$ï¼Œ$M_{ij}=a_i-b_j$</p>
<p>åœ¨ä»£ç ä¸­å®é™…çš„ç»´åº¦ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.rand(batch_size,sequence_len,dim)</span><br><span class="line">b=torch.rand(batch_size,sequence_len,dim)</span><br></pre></td></tr></table></figure>
<p>æ–¹æ³•â‘ ï¼šforå¾ªç¯</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">M=torch.zeros(bz,seq_len,seq_len)</span><br><span class="line"><span class="keyword">for</span> b_i <span class="keyword">in</span> range(bz):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(seq_len):</span><br><span class="line">            M_ij=torch.norm(a[b_i][i]-b[b_i][j])</span><br><span class="line">            M[b][i][j]=M_ij</span><br></pre></td></tr></table></figure>
<p>æ–¹æ³•â‘¡ï¼šçŸ©é˜µè¿ç®—</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=a.unsqueeze(<span class="number">2</span>)  <span class="comment"># bz,seq_len,1,dim</span></span><br><span class="line">b=b.unsqueeze(<span class="number">1</span>)  <span class="comment"># bz,1,seq_lens,dim</span></span><br><span class="line">M=torch.norm(a-b,dim=<span class="number">-1</span>)   <span class="comment"># will broadcast</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="â‘¡"><a href="#â‘¡" class="headerlink" title="â‘¡"></a>â‘¡</h2><p>éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªmaskçŸ©é˜µï¼Œæ¯ä¸€è¡Œæœ‰ä¸€æ®µè¿ç»­çš„ä½ç½®å¡«å……1ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¡«å……1çš„å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®éƒ½ä¸åŒã€‚å…·ä½“æ¥è¯´ï¼Œå…ˆç”Ÿæˆä¸€ä¸ªä¸­å¿ƒä½ç½®centerï¼Œåˆ™å¼€å§‹ä½ç½®ä¸ºcenter-windowï¼›ç»“æŸä½ç½®ä¸ºcenter+windowã€‚å…¶ä¸­å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®ä¸èƒ½è¶Šç•Œï¼Œä¹Ÿå³ä¸å°äº0å’Œå¤§äºè¡Œçš„æ€»é•¿åº¦ã€‚<br>å¦‚ï¼š<br><img src="/images/15437208061953.jpg" width="25%" height="50%"></p>
<p>æ€è·¯ï¼š<br>â‘ å…ˆç”Ÿæˆnè¡Œæ¯è¡Œå¯¹åº”çš„éšæœºä¸­å¿ƒä½ç½®ï¼Œç„¶åå†è·å¾—å·¦å’Œå³è¾¹ç•Œ</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">centers=torch.randint(low=<span class="number">0</span>,high=query_len,size=(query_len,),dtype=torch.long)</span><br><span class="line"></span><br><span class="line">left=centers-self.window</span><br><span class="line">left=torch.max(left,torch.LongTensor([<span class="number">0</span>])).unsqueeze(<span class="number">1</span>)   <span class="comment"># query_len,1</span></span><br><span class="line"></span><br><span class="line">right=centers+self.window</span><br><span class="line">right=torch.min(right,torch.LongTensor([query_len<span class="number">-1</span>])).unsqueeze(<span class="number">1</span>)  <span class="comment"># query_len,1</span></span><br></pre></td></tr></table></figure>
<p>â‘¡ç”Ÿæˆä¸€ä¸ªæ¯è¡Œéƒ½ç”¨[0,n-1]å¡«å……çš„çŸ©é˜µï¼Œ[0,n-1]è¡¨ç¤ºçš„æ˜¯è¯¥å…ƒç´ çš„indexï¼Œäº¦å³ï¼š<br><img src="/images/15437212363142.jpg" width="25%" height="50%"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br></pre></td></tr></table></figure>
<p>â‘¢åˆ©ç”¨&lt;=å’Œ&gt;=è·å¾—ä¸€ä¸ªå·¦è¾¹ç•Œå’Œå³è¾¹ç•ŒçŸ©é˜µï¼Œå·¦è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å·¦è¾¹ç•Œçš„å·¦è¾¹éƒ½æ˜¯å¡«å……çš„1ï¼›å³è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å³è¾¹ç•Œå³è¾¹éƒ½æ˜¯å¡«å……çš„1ã€‚å†è¿›è¡Œå¼‚æˆ–æ“ä½œã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br><span class="line">left_matrix=range_matrix&lt;=left</span><br><span class="line">right_matrix=range_matrix&lt;=right</span><br><span class="line">final_matrix=left_matrix^right_matrix</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡7</title>
    <url>/2018/12/02/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%877/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Convolutional-Self-Attention-Network"><a href="#1ï¸âƒ£-Convolutional-Self-Attention-Network" class="headerlink" title="1ï¸âƒ£[Convolutional Self-Attention Network]"></a>1ï¸âƒ£[Convolutional Self-Attention Network]</h2><p>å¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œå¼•å…¥CNNçš„local-biasï¼Œä¹Ÿå³å¯¹queryçš„é‚»è¿‘è¯è¿›è¡Œattentionè€Œä¸æ˜¯æ‰€æœ‰è¯ï¼›å°†self-attentionæ‰©å±•åˆ°2Dï¼Œä¹Ÿå³è®©ä¸åŒçš„headä¹‹é—´ä¹Ÿæœ‰attentionäº¤äº’ã€‚</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£the normalization in Softmax may inhibits the attention to neighboring information ä¹Ÿå³é‚»å±…çš„ä¿¡æ¯æ›´é‡è¦ï¼Œè¦åŠ å¼ºé‚»å±…çš„é‡è¦æ€§</p>
<p>2ï¸âƒ£features can be better captured by modeling dependencies across different channels å¯¹äºä¸åŒçš„channel/headä¹Ÿå¢åŠ ä»–ä»¬ä¹‹é—´çš„äº¤äº’ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15437126353758.jpg" width="80%" height="50%"></p>
<p>å¯¹äº1Dçš„convolutionï¼šé€‰å–ä¸­å¿ƒè¯å‘¨å›´ä¸€ä¸ªwindowï¼š<br><img src="/images/15437128149700.jpg" width="28%" height="50%"></p>
<p>å¯¹äº2Dçš„convolutionï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15437128476725.jpg" width="45%" height="50%"></p>
<p>åœ¨å…·ä½“å®è·µä¸­ï¼Œåªå¯¹å‰ä¸‰å±‚æ·»åŠ local biasï¼Œè¿™æ˜¯å› ä¸ºmodeling localityåœ¨åº•å±‚æ›´æœ‰æ•ˆï¼Œå¯¹äºé«˜å±‚åº”è¯¥æ•è·æ›´è¿œçš„ä¿¡æ¯ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks"><a href="#2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks" class="headerlink" title="2ï¸âƒ£[Modeling Localness for Self-Attention Networks]"></a>2ï¸âƒ£[Modeling Localness for Self-Attention Networks]</h2><p>å’Œä¸Šæ–‡ä¸€æ ·ï¼Œå¼•å…¥local biaså¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œä»è€Œæå‡äº†ç¿»è¯‘è¡¨ç°ã€‚å’Œä¸Šæ–‡æ˜¯åŒä¸€ä½œè€…ï¼Œå‘åœ¨EMNLPä¸Šã€‚</p>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£self-attentionå­˜åœ¨çš„é—®é¢˜ï¼šè™½ç„¶èƒ½å¤Ÿå¢åŠ é•¿ç¨‹å…³æ³¨ï¼Œä½†å› æ­¤ä¼šå¯¼è‡´æ³¨æ„åŠ›çš„åˆ†æ•£ï¼Œå¯¹é‚»å±…çš„ä¿¡å·ä¼šå¿½ç•¥ã€‚å®è·µè¯æ˜ï¼Œå¯¹local biaså»ºæ¨¡åœ¨self-attentionæœ‰æå‡ã€‚</p>
<p>2ï¸âƒ£ä»ç›´è§‰ä¸Šæ¥è¯´ï¼Œåœ¨ç¿»è¯‘æ¨¡å‹ä¸­ï¼Œå½“ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jæœ‰å¯¹é½å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›è¯ièƒ½åŒæ—¶å¯¹è¯jå‘¨å›´çš„è¯è¿›è¡Œå¯¹é½ï¼Œä½¿å¾—èƒ½å¤Ÿæ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚phraseçš„ä¿¡æ¯ã€‚</p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åœ¨åŸæ¥çš„å…¬å¼ä¸Šæ·»åŠ Gï¼š<br><img src="/images/15437133932791.jpg" width="45%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/15437134105761.jpg" width="70%" height="50%"></p>
<p>Gæ˜¯ä¸€ä¸ªalignment position matrixï¼ˆå¯¹é½ä½ç½®çŸ©é˜µï¼‰ï¼Œå…ƒç´ ijä»£è¡¨ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jä¹‹é—´çš„ç´§å¯†ç¨‹åº¦ã€‚<br>æˆ‘ä»¬æ¯æ¬¡æ ¹æ®ç›®æ ‡è¯ié¢„æµ‹ä¸€ä¸ªæºè¯­è¨€çš„ä¸­å¿ƒè¯ï¼Œåˆ™$G_{ij}$åˆ™ä¸ºï¼š</p>
<p><img src="/images/15437135769000.jpg" width="23%" height="50%"></p>
<p>$P_i$å°±æ˜¯å¯¹äºç›®æ ‡è¯jè€Œè¨€æºè¯­è¨€çš„ä¸­å¿ƒè¯ã€‚ $\sigma$ æ‰‹åŠ¨è®¾å®šï¼Œé€šå¸¸æ˜¯$\frac{D}{2}$ï¼ŒDä»£è¡¨çª—å£å¤§å°ã€‚</p>
<p>ä¹Ÿå³æœ€ç»ˆæˆ‘ä»¬éœ€è¦è®¡ç®—çš„æ˜¯ï¼Œä¸­å¿ƒè¯$P_i$å’Œçª—å£$D$ã€‚</p>
<h4 id="è®¡ç®—-P-i"><a href="#è®¡ç®—-P-i" class="headerlink" title="è®¡ç®—$P_i$"></a>è®¡ç®—$P_i$</h4><p>åˆ©ç”¨å¯¹åº”çš„ç›®æ ‡è¯içš„queryå³å¯ï¼š<br><img src="/images/15437138514005.jpg" width="28%" height="50%"><br>$p_i$æ˜¯ä¸€ä¸ªå®æ•°ã€‚</p>
<h4 id="è®¡ç®—window-size"><a href="#è®¡ç®—window-size" class="headerlink" title="è®¡ç®—window size"></a>è®¡ç®—window size</h4><p>â‘ å›ºå®šçª—å£ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªè¶…å‚ã€‚</p>
<p>â‘¡Layer-Speciï¬c Window<br>å°†è¯¥å±‚æ‰€æœ‰çš„keyå¹³å‡ï¼Œè®¡ç®—å‡ºä¸€ä¸ªå…±äº«çš„window sizeï¼š<br><img src="/images/15437139914993.jpg" width="28%" height="50%"></p>
<p>â‘¢Query-Speciï¬c Window<br>æ¯ä¸ªqueryéƒ½æœ‰è‡ªå·±çš„window size<br><img src="/images/15437140367683.jpg" width="30%" height="50%"></p>
<h3 id="å®éªŒåˆ†æä¸ç»“è®º"><a href="#å®éªŒåˆ†æä¸ç»“è®º" class="headerlink" title="å®éªŒåˆ†æä¸ç»“è®º"></a>å®éªŒåˆ†æä¸ç»“è®º</h3><p>â‘ å°†model localityç”¨äºä½å±‚æ•ˆæœä¼šæ›´å¥½ï¼Œè¿™æ˜¯å› ä¸ºä½å±‚å¯¹ç›¸é‚»å»ºæ¨¡ï¼Œè€Œè¶Šé«˜å±‚è¶Šå…³æ³¨æ›´è¿œçš„è¯ã€‚</p>
<p><img src="/images/15437141387365.jpg" width="50%" height="50%"></p>
<p>â‘¡å°†model localityæ”¾åœ¨encoderå’Œencoder-decoderéƒ¨åˆ†ä¼šæ›´å¥½ï¼ˆtransformeræœ‰ä¸‰ä¸ªåœ°æ–¹å¯ä»¥æ”¾ï¼‰</p>
<p><img src="/images/15437141719564.jpg" width="50%" height="50%"><br>å› ä¸ºdecoderæœ¬èº«å°±å€¾å‘å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œå¦‚æœç»§ç»­è®©å…¶å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œé‚£ä¹ˆå°±éš¾ä»¥è¿›è¡Œé•¿ç¨‹å»ºæ¨¡ã€‚</p>
<p>â‘¢è¶Šé«˜å±‚ï¼Œwindow sizeï¼ˆscopeï¼‰è¶Šå¤§ã€‚</p>
<p><img src="/images/15437142078121.jpg" width="70%" height="50%"></p>
<p>ä¹Ÿå³ï¼Œåœ¨åº•å±‚æ›´å€¾å‘äºæ•è·é‚»è¿‘è¯çš„è¯­ä¹‰ï¼›è€Œé«˜å±‚å€¾å‘æ•è·é•¿ç¨‹ä¾èµ–ã€‚ä½†è¿™ä¸åŒ…æ‹¬ç¬¬ä¸€å±‚ï¼Œç¬¬ä¸€å±‚æ˜¯embeddingï¼Œè¿˜æ²¡æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤å€¾å‘äºæ•è·å…¨å±€ä¿¡æ¯ã€‚</p>
<hr>
<h2 id="3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation"><a href="#3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation" class="headerlink" title="3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]"></a>3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]</h2><p>æå‡ºä¸¤ç§attentionæœºåˆ¶çš„ç¿»è¯‘æ¨¡å‹ï¼Œglobalå’Œlocalã€‚</p>
<p>æœ¬æ–‡ä¸åŸç‰ˆçš„ç¿»è¯‘æ¨¡å‹ç•¥æœ‰ä¸åŒï¼š<br><img src="/images/15437143753188.jpg" width="40%" height="50%"><br><img src="/images/15437143893418.jpg" width="30%" height="50%"></p>
<p>cæ˜¯contextï¼Œhæ˜¯decodeçš„éšå±‚ã€‚</p>
<h3 id="global-attention"><a href="#global-attention" class="headerlink" title="global attention"></a>global attention</h3><p><img src="/images/15437144396133.jpg" width="45%" height="50%"></p>
<p>è®¡ç®—attentionåˆ†æ•°ï¼š<br><img src="/images/15437145076271.jpg" width="40%" height="50%"></p>
<p>scoreæœ‰å¤šç§é€‰æ‹©ï¼š<br><img src="/images/15437145588496.jpg" width="52%" height="50%"></p>
<p>æ³¨æ„åˆ°è¯¥æ¨¡å‹ä¸ç¬¬ä¸€ä¸ªæå‡ºattention basedçš„æ¨¡å‹ä¸åŒä¹‹å¤„ï¼š<br>$h_t -&gt; a_t -&gt; c_t -&gt; \tilde{h_t}$<br>åŸç‰ˆæ˜¯ï¼š<br>$h_{t-1} -&gt; a_t -&gt; c_t -&gt; h_t$</p>
<h3 id="local-attention"><a href="#local-attention" class="headerlink" title="local attention"></a>local attention</h3><p><img src="/images/15437147612512.jpg" width="45%" height="50%"></p>
<p>ç”±äºglobal attentionè®¡ç®—ä»£ä»·é«˜ï¼Œä¸”å¯¹äºé•¿å¥æ•ˆæœä¸å¥½ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€éƒ¨åˆ†æ¥åšattentionã€‚<br>é¦–å…ˆç”Ÿæˆä¸€ä¸ªå¯¹é½ä½ç½®$p_t$ï¼Œå†é€‰æ‹©ä¸€ä¸ªçª—å£$[p_t - D,p_t + D]$ï¼Œå…¶ä¸­Dæ˜¯è¶…å‚ã€‚</p>
<p>å¦‚ä½•è·å¾—$p_t$?<br>â‘ ç›´æ¥å‡è®¾$p_t=t$ï¼Œä¹Ÿå³sourceå’Œtargetçš„ä½ç½®å¤§è‡´ä¸€ä¸€å¯¹åº”ã€‚</p>
<p>â‘¡åšé¢„æµ‹ï¼š<br><img src="/images/15437150115321.jpg" width="43%" height="50%"><br>å…¶ä¸­Sæ˜¯sourceçš„å¥å­é•¿åº¦ã€‚</p>
<p>æ¥ç€ï¼Œä»¥$p_t$ä¸ºä¸­å¿ƒï¼Œæ·»åŠ ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚æœ€ç»ˆattentionè®¡ç®—å…¬å¼ï¼š<br><img src="/images/15437150721538.jpg" width="50%" height="50%"></p>
<p>å…¶ä¸­alignå’Œä¸Šé¢ä¸€è‡´ï¼š<br><img src="/images/15437151043916.jpg" width="45%" height="50%"></p>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå°†ä½ç½®ä¿¡æ¯ä¹Ÿè€ƒè™‘è¿›æ¥ã€‚</p>
<h3 id="Input-feeding-Approach"><a href="#Input-feeding-Approach" class="headerlink" title="Input-feeding Approach"></a>Input-feeding Approach</h3><p>motivationï¼šåœ¨ä¸‹ä¸€æ¬¡çš„alignmentï¼ˆä¹Ÿå°±æ˜¯è®¡ç®—attentionï¼‰ä¹‹å‰ï¼Œåº”å½“çŸ¥é“ä¹‹å‰çš„alignmentæƒ…å†µï¼Œæ‰€ä»¥åº”å½“ä½œä¸ºè¾“å…¥ä¿¡æ¯ä¼ è¿›ä¸‹ä¸€å±‚ï¼š<br><img src="/images/15437152269151.jpg" width="50%" height="50%"></p>
<p>æ³¨æ„è¿™é‡Œå’ŒBahdanauçš„ä¸åŒã€‚Bahdanauæ˜¯ç›´æ¥ç”¨ä¸Šä¸‹æ–‡å»æ„é€ éšå±‚ã€‚è¿™é‡Œæå‡ºçš„æ¨¡å‹ç›¸å¯¹æ›´ä¸ºé€šç”¨ï¼Œä¹Ÿå¯ä»¥è¢«åº”ç”¨äºéattentionçš„æ¨¡å‹ä¸­ï¼ˆä¹Ÿå°±æ˜¯æ¯æ¬¡å°†encoderçš„æœ€åä¸€å±‚ä½œä¸ºè¾“å…¥åœ¨æ¯ä¸ªtime stepéƒ½è¾“å…¥ï¼‰</p>
<hr>
<h2 id="4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks"><a href="#4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks" class="headerlink" title="4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]"></a>4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]</h2><p>æ€æƒ³ï¼šåˆ©ç”¨capsuleæå‰ç”Ÿæˆsource sentenceçš„å›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œåœ¨decodeçš„æ—¶å€™ç›´æ¥ä½¿ç”¨ï¼Œè€Œä¸éœ€è¦attentionï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´NMTçš„ç›®çš„ã€‚</p>
<p>Motivationï¼šattention-basedçš„NMTæ—¶é—´å¤æ‚åº¦ä¸º$|S|\times |T|$ï¼Œè€Œæœ¬æ–‡å¸Œæœ›èƒ½å¤Ÿå°†NMTå‡å°‘åˆ°çº¿æ€§æ—¶é—´ã€‚è€Œä¼ ç»Ÿä¸åŠ attentionçš„NMTé€šå¸¸ä½¿ç”¨LSTMæœ€åä¸€å±‚éšå±‚ä½œä¸ºæºè¯­è¨€çš„encodeä¿¡æ¯ä¼ å…¥decodeï¼Œä½†è¿™æ ·çš„ä¿¡æ¯å¹¶ä¸èƒ½å¾ˆå¥½åœ°ä»£è¡¨æ•´ä¸ªå¥å­ï¼Œå› æ­¤æœ¬æ–‡ä½¿ç”¨capsuleä½œä¸ºæå–source sentenceä¿¡æ¯çš„æ–¹æ³•ï¼Œåˆ©ç”¨capsuleç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºï¼Œç›´æ¥ä¼ å…¥decodeç«¯ï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´çš„ç›®çš„ã€‚</p>
<p><img src="/images/15437164176973.jpg" width="50%" height="50%"></p>
<h3 id="é—®é¢˜å®šä¹‰"><a href="#é—®é¢˜å®šä¹‰" class="headerlink" title="é—®é¢˜å®šä¹‰"></a>é—®é¢˜å®šä¹‰</h3><p>å¯¹äºembeddingï¼š<br><img src="/images/15437164440500.jpg" width="37%" height="50%"><br>å¸Œæœ›èƒ½å¤Ÿè½¬æ¢æˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºCï¼š<br><img src="/images/15437164654931.jpg" width="37%" height="50%"></p>
<p>æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¸€ä¸ªåŒå‘çš„LSTMï¼š<br><img src="/images/15437165067165.jpg" width="28%" height="50%"></p>
<p>ä¸€ç§ç®€å•çš„è·å–Cçš„æ–¹æ³•ï¼š<br><img src="/images/15437165382025.jpg" width="30%" height="50%"><br>å…¶ä¸­$h_1$å’Œ$h_L$æœ‰äº’è¡¥å…³ç³»ã€‚</p>
<p>æœ¬æ–‡ä½¿ç”¨capsuleæå–æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚</p>
<p>åœ¨decodeé˜¶æ®µï¼Œç”±äºæ‹¥æœ‰å›ºå®šè¡¨ç¤ºï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦attentionï¼š</p>
<p><img src="/images/15437166827481.jpg" width="35%" height="50%"><br><img src="/images/15437167374470.jpg" width="37%" height="50%"></p>
<p>æ€»ä½“æ¶æ„ï¼š<br><img src="/images/15437167607085.jpg" width="60%" height="50%"></p>
<h3 id="Aggregation-layers-with-Capsule-Networks"><a href="#Aggregation-layers-with-Capsule-Networks" class="headerlink" title="Aggregation layers with Capsule Networks"></a>Aggregation layers with Capsule Networks</h3><p><img src="/images/15437168111687.jpg" width="65%" height="50%"><br>å®é™…ä¸Šå°±æ˜¯dynamic routingé‚£ä¸€å¥—ï¼Œå¯¹ä¿¡æ¯è¿›è¡Œæå–ï¼ˆè®ºæ–‡å…¬å¼æœ‰è¯¯å°±ä¸è´´å›¾äº†ï¼‰</p>
<p>ç®—æ³•ï¼š<br><img src="/images/15437168668191.jpg" width="55%" height="50%"></p>
<p>æœ€ç»ˆè·å¾—äº†ï¼š<br><img src="/images/15437168888967.jpg" width="27%" height="50%"></p>
<hr>
<h2 id="5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>é‡è¯»äº†ä¸€éã€‚<br>ä»‹ç»ä¸€ç§æ–°å‹çš„dropoutï¼Œå¯ç”¨äºå·ç§¯å±‚æé«˜è¡¨ç°ã€‚é€šè¿‡å¤§é‡çš„å®éªŒå¾—å‡ºè®¸å¤šæœ‰æ„ä¹‰çš„ç»“è®ºã€‚æœ¬æ–‡å‘è¡¨äºNIPS2018ã€‚</p>
<h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><p>ç”±äºå·ç§¯å±‚çš„featureç›¸äº’ä¹‹é—´æœ‰è”ç³»ï¼Œå³ä½¿ä½¿ç”¨äº†dropoutï¼Œä¿¡æ¯ä¹Ÿèƒ½å¤Ÿæ ¹æ®å‘¨å›´çš„featureä¼ åˆ°ä¸‹ä¸€å±‚ã€‚å› æ­¤ä½¿ç”¨dropblockï¼Œä¸€æ¬¡å°†ä¸€ä¸ªæ–¹å—å†…çš„éƒ½dropæ‰ã€‚</p>
<p><img src="/images/15437170173072.jpg" width="50%" height="50%"></p>
<h3 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h3><p><img src="/images/15437170840909.jpg" width="80%" height="50%"></p>
<p>å…¶ä¸­æœ‰ä¸¤ä¸ªè¶…å‚ï¼šâ‘ block_sizeè¡¨ç¤ºå—çš„å¤§å°ï¼›Î³è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªunitè¦dropæ‰ï¼Œç­‰ä»·ä¼ ç»Ÿçš„dropoutçš„pã€‚å½“block_size=1æ—¶ç­‰ä»·dropoutï¼›å½“block size=æ•´ä¸ªfeature mapï¼Œç­‰ä»·äºspatial dropoutã€‚</p>
<p>åœ¨å®è·µä¸­ï¼Œé€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—Î³ï¼š<br><img src="/images/15437172746112.jpg" width="55%" height="50%"></p>
<p>(why? é€šè¿‡è®¡ç®—æœŸæœ›çš„æ–¹å¼å°†ä¼ ç»Ÿdropoutçš„keep_probä¸å½“å‰çš„Î³è”ç³»èµ·æ¥ï¼Œå¾—åˆ°ä¸€ä¸ªç­‰å¼ï¼Œæ•´ç†å³å¯è·å¾—ä¸Šå¼ï¼‰</p>
<p>åœ¨å®éªŒä¸­ï¼Œè¿˜å¯ä»¥é€æ¸å‡å°keep_probä½¿å¾—æ›´åŠ é²æ£’æ€§ã€‚</p>
<h3 id="å®éªŒ-amp-ç»“è®º"><a href="#å®éªŒ-amp-ç»“è®º" class="headerlink" title="å®éªŒ&amp;ç»“è®º"></a>å®éªŒ&amp;ç»“è®º</h3><p>â‘ æ•ˆæœ:dropout&lt; spatial dropout &lt; dropblock</p>
<p>â‘¡dropblockèƒ½æœ‰æ•ˆå»æ‰semantic information</p>
<p>â‘¢dropblockæ˜¯ä¸€ä¸ªæ›´åŠ å¼ºçš„regularization</p>
<p>â‘£ä½¿ç”¨dropblockçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿå­¦ä¹ æ›´å¤šçš„åŒºåŸŸï¼Œè€Œä¸æ˜¯åªä¸“æ³¨äºä¸€ä¸ªåŒºåŸŸ<br><img src="/images/15437174940381.jpg" width="70%" height="50%"></p>
<p>å¯¹äºresnetï¼Œç›´æ¥å°†dropblockåº”ç”¨äºæ·»åŠ å®Œskip connectionåçš„featureèƒ½å¤Ÿæœ‰æ›´é«˜çš„è¡¨ç°ã€‚</p>
<hr>
<h2 id="6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling"><a href="#6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling" class="headerlink" title="6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]"></a>6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]</h2><p>æå‡ºä¸€ç§å»ºç«‹åœ¨characteråŸºç¡€ä¸Šçš„æ–°å‹çš„ä¸Šä¸‹æ–‡embedding(contextualized embeddingï¼‰ã€‚ç”¨äºsequence labelingã€‚æœ¬æ–‡å‘è¡¨äºcoling2018ã€‚</p>
<h3 id="æ–¹æ³•-2"><a href="#æ–¹æ³•-2" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æ•´ä½“æ¶æ„ï¼š<br><img src="/images/15437175991019.jpg" width="100%" height="50%"></p>
<p>é¦–å…ˆå°†characterä½œä¸ºåŸºæœ¬å•ä½ï¼Œè¿‡ä¸€ä¸ªåŒå‘LSTMï¼Œè¿›è¡Œlanguage modelçš„å»ºæ¨¡ã€‚</p>
<p>å¦‚ä½•æå–ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼š<br><img src="/images/15437176650871.jpg" width="100%" height="50%"><br>æå–å‰å‘LSTMä¸­è¯¥è¯çš„æœ€åä¸€ä¸ªcharacterçš„åä¸€ä¸ªhidden stateï¼Œä»¥åŠåå‘LSTMä¸­ç¬¬ä¸€ä¸ªè¯çš„å‰ä¸€ä¸ªhidden stateï¼Œ å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚æœ€ç»ˆæ‹¼èµ·æ¥å³å¯ï¼š<br><img src="/images/15437177090697.jpg" width="28%" height="50%"><br>å› æ­¤è¯¥è¯ä¸ä»…ä¸è¯å†…éƒ¨çš„characterç›¸å…³ï¼Œè¿˜è·Ÿå…¶å‘¨å›´çš„contextæœ‰å…³ã€‚</p>
<p>sequence labelingæˆ‘ä¸æ„Ÿå…´è¶£ï¼Œè¯¥éƒ¨åˆ†æ²¡çœ‹ã€‚</p>
<h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>ç›¸æ¯”word levelçš„language modelï¼Œcharacter-levelç‹¬ç«‹äºtokenizationå’Œfixed vocabularyï¼Œæ¨¡å‹æ›´å®¹æ˜“è¢«è®­ç»ƒï¼Œå› ä¸ºè¯è¡¨å°ä¸”è®­ç»ƒæ—¶é—´çŸ­ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>capsule</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>self-attention</tag>
        <tag>locality modeling</tag>
        <tag>dropblock</tag>
        <tag>contextualized embedding</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯16</title>
    <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D16/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£è©è¨è›®"><a href="#1ï¸âƒ£è©è¨è›®" class="headerlink" title="1ï¸âƒ£è©è¨è›®"></a>1ï¸âƒ£è©è¨è›®</h3><p>[äº”ä»£åå›½] æç…œ<br>äººç”Ÿæ„æ¨ä½•èƒ½å…ï¼Œé”€é­‚ç‹¬æˆ‘æƒ…ä½•é™ï¼æ•…å›½æ¢¦é‡å½’ï¼Œè§‰æ¥åŒæ³ªå‚ã€‚<br>é«™æ¥¼è°ä¸ä¸Šï¼Ÿé•¿è®°ç§‹æ™´æœ›ã€‚<strong>å¾€äº‹å·²æˆç©ºï¼Œè¿˜å¦‚ä¸€æ¢¦ä¸­</strong>ã€‚</p>
<p>è§‰(jue)æ¥ï¼šé†’æ¥ã€‚</p>
<hr>
<h3 id="2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"><a href="#2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·" class="headerlink" title="2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"></a>2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·</h3><p>[å®‹] è‹è½¼<br>ä¸œæ­¦æœ›é¦€æ­ï¼Œäº‘æµ·å¤©æ¶¯ä¸¤æ³èŒ«ã€‚<strong>ä½•æ—¥åŠŸæˆåé‚äº†ï¼Œè¿˜ä¹¡ï¼Œé†‰ç¬‘é™ªå…¬ä¸‰ä¸‡åœº</strong>ã€‚<br><strong>ä¸ç”¨è¯‰ç¦»è§ï¼Œç—›é¥®ä»æ¥åˆ«æœ‰è‚ </strong>ã€‚ä»Šå¤œé€å½’ç¯ç«å†·ï¼Œæ²³å¡˜ï¼Œå •æ³ªç¾Šå…¬å´å§“æ¨ã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ— é¢˜</title>
    <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%BB%8F%E5%8E%86%E4%B8%96%E7%95%8C%E4%B8%8A%E6%89%80%E6%9C%89%E7%83%AD%E9%97%B9/</url>
    <content><![CDATA[<p>äººä¸å¯èƒ½ç»å†ä¸–ç•Œä¸Šæ‰€æœ‰çƒ­é—¹ï¼Œä½†å¯ä»¥ç”¨çœ¼ç›çœ‹ï¼Œç”¨å¿ƒæ„Ÿå—ï¼Œç”¨èƒ¸æ€€æ‰©å¼ ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†12</title>
    <url>/2018/11/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8612/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Transformer"><a href="#1ï¸âƒ£-Transformer" class="headerlink" title="1ï¸âƒ£[Transformer]"></a>1ï¸âƒ£[Transformer]</h3><p>å¯¹Transformeræ–°ç†è§£ï¼š</p>
<ul>
<li>å¯ä»¥å°†Transformerç†è§£æˆä¸€å¼ å…¨è¿æ¥å›¾ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä¸å…¶ä»–èŠ‚ç‚¹çš„å…³ç³»é€šè¿‡attentionæƒé‡è¡¨ç°ã€‚å›¾å…³ç³»æ˜¯åºåˆ—å…³ç³»æˆ–è€…æ ‘å…³ç³»çš„ä¸€èˆ¬åŒ–ã€‚</li>
<li>ä¸ºä»€ä¹ˆè¦æœ‰multi-headï¼Ÿä¸ä»…ä»…æ˜¯è®ºæ–‡çš„è§£é‡Šï¼Œæˆ–è®¸è¿˜å¯ä»¥ç†è§£æˆï¼Œå¯¹ä¸€ä¸ªå‘é‡çš„ä¸åŒéƒ¨åˆ†ï¼ˆå¦‚ç¬¬1ç»´åˆ°20ç»´ï¼Œç¬¬21ç»´åˆ°40ç»´ç­‰ï¼‰æ–½ä»¥ä¸åŒçš„attentionæƒé‡ï¼Œå¦‚æœä¸ä½¿ç”¨multi-headï¼Œé‚£ä¹ˆå¯¹äºä¸€ä¸ªqueryï¼Œå°±åªä¼šæœ‰ä¸€ä¸ªæƒé‡ï¼Œè€Œä¸åŒçš„ç»´åº¦æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</li>
</ul>
<hr>
<h3 id="2ï¸âƒ£-attention-amp-capsule"><a href="#2ï¸âƒ£-attention-amp-capsule" class="headerlink" title="2ï¸âƒ£[attention&amp;capsule]"></a>2ï¸âƒ£[attention&amp;capsule]</h3><p>attentionæ˜¯æ”¶ä¿¡æ¯ï¼Œqueryä»valueæŒ‰æƒé‡è·å–ä¿¡æ¯ï¼Œå…¶ä¸­æ‰€æœ‰valueçš„æƒé‡å’Œæ˜¯1ã€‚<br>capsuleæ˜¯å‘ä¿¡æ¯ï¼Œå¯¹äº$l-1$å±‚çš„ä¸€ä¸ªcapsuleæ¥è¯´ï¼Œåœ¨ä¼ å…¥åˆ°$l$å±‚çš„kä¸ªcapsuleçš„ä¿¡æ¯ï¼Œå…¶æƒé‡å’Œä¸º1ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Transformer</tag>
        <tag>attention</tag>
        <tag>capsule</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡6</title>
    <url>/2018/11/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%876/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING"><a href="#1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING" class="headerlink" title="1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]"></a>1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]</h2><p>ä»‹ç»äº†ä¸€ç§ç”Ÿæˆsentence embeddingçš„æ–¹æ³•ã€‚ä¸å…¶ä»–sentence embeddingä¸åŒçš„åœ°æ–¹åœ¨äºï¼Œç”Ÿæˆçš„æ˜¯ä¸€ä¸ªçŸ©é˜µè€Œä¸æ˜¯ä¸€ä¸ªå‘é‡ã€‚é€šè¿‡çŸ©é˜µçš„å½¢å¼ï¼Œèƒ½å¤Ÿå…³æ³¨ä¸åŒéƒ¨åˆ†çš„è¯­ä¹‰è¡¨ç¤ºï¼Œç±»ä¼¼äºTransformerçš„multi-headã€‚</p>
<p>Contribution:</p>
<ul>
<li>å°†sentence embeddingæ‰©å±•ä¸ºçŸ©é˜µå½¢å¼ï¼Œèƒ½å¤Ÿè·å¾—æ›´å¤šçš„ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥æ­£åˆ™åŒ–ï¼Œä½¿å¾—sentence matrixå…·æœ‰æ›´ä¸°å¯Œçš„å¤šæ ·æ€§ã€‚</li>
</ul>
<p><img src="/images/15425908639518.jpg" width="70%" height="50%"></p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åŒå‘LSTM+self-attentionã€‚</p>
<p>åŒå‘çš„LSTMè·å¾—ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºï¼š</p>
<p><img src="/images/15425911302081.jpg" width="27%" height="50%"></p>
<p><img src="/images/15425911849931.jpg" width="27%" height="50%"></p>
<p>å› æ­¤å¯ä»¥è·å¾—attentionæƒé‡å‘é‡ï¼š<br><img src="/images/15425912555350.jpg" width="50%" height="50%"></p>
<p>å…¶ä¸­$H:n\times2u,W_{s1}:d_a\times2u ,w_{s2}:d_a$ ï¼Œ$d_a$æ˜¯è¶…å‚ã€‚</p>
<p>ç°å°†å‘é‡$w_{s2}$æ‰©å±•ä¸ºçŸ©é˜µï¼Œäº¦å³æœ‰Multi-hop attentionï¼š<br><img src="/images/15425914364548.jpg" width="50%" height="50%"></p>
<p>$W_{s2}$ç»´åº¦ä¸º$r\times d_a$ï¼Œ$r$ä»£è¡¨äº†headçš„ä¸ªæ•°ã€‚</p>
<p>å› æ­¤æœ€ç»ˆçš„sentence embeddingçŸ©é˜µä¸ºï¼š<br><img src="/images/15425915371381.jpg" width="15%" height="50%"></p>
<h3 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h3><p>ä¸ºäº†è®©Aå°½å¯èƒ½æœ‰å¤šæ ·æ€§ï¼ˆå› ä¸ºå¦‚æœéƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œé‚£ä¹ˆåˆ™ä¼šæœ‰å†—ä½™æ€§ï¼‰ï¼Œå¼•å…¥å¦‚ä¸‹çš„æ­£åˆ™åŒ–ï¼š<br><img src="/images/15425915930785.jpg" width="28%" height="50%"></p>
<p>åŸå› ï¼š<br>å¯¹äºä¸åŒçš„head $a^i$ä¸$a^j$ï¼Œ$A A^T$æœ‰ï¼š<br><img src="/images/15425918790543.jpg" width="31%" height="50%"></p>
<p>å¦‚æœ$a^i$ä¸$a^j$å¾ˆç›¸ä¼¼é‚£ä¹ˆå°±ä¼šæ¥è¿‘äº1ï¼Œå¦‚æœéå¸¸ä¸ç›¸ä¼¼(no overlay)åˆ™ä¼šæ¥è¿‘äº0ã€‚<br>å› æ­¤æ•´ä¸ªå¼å­å°±æ˜¯:å¸Œæœ›å¯¹è§’çº¿éƒ¨åˆ†æ¥è¿‘äº0ï¼ˆå› ä¸ºå‡äº†å•ä½é˜µï¼‰ï¼Œè¿™å°±ç›¸å½“äºå°½å¯èƒ½focuså°éƒ¨åˆ†çš„è¯ï¼›åŒæ—¶å…¶ä»–éƒ¨åˆ†å°½å¯èƒ½æ¥è¿‘äº0ï¼Œä¹Ÿå³ä¸åŒçš„headä¹‹é—´æ²¡æœ‰overlapã€‚</p>
<h3 id="å¦‚ä½•ä½¿ç”¨"><a href="#å¦‚ä½•ä½¿ç”¨" class="headerlink" title="å¦‚ä½•ä½¿ç”¨"></a>å¦‚ä½•ä½¿ç”¨</h3><p>æ–‡ç« æåˆ°ï¼Œåœ¨åšåˆ†ç±»çš„æ—¶å€™å¯ä»¥ç›´æ¥å°†çŸ©é˜µMå±•å¼€ï¼Œè¿‡å…¨è¿æ¥å±‚å³å¯ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]"></a>2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]</h2><p>åœ¨å®Œå½¢å¡«ç©ºä»»åŠ¡(Cloze-style Reading Comprehension)ä¸Šæå‡ºä¸€ç§æ–°çš„attentionï¼Œå³nested-attentionã€‚</p>
<h3 id="ä»»åŠ¡æè¿°"><a href="#ä»»åŠ¡æè¿°" class="headerlink" title="ä»»åŠ¡æè¿°"></a>ä»»åŠ¡æè¿°</h3><p>ä¸‰å…ƒç»„ $ D,Q,A $ï¼Œdocumentï¼Œquestionï¼Œanswerã€‚å…¶ä¸­answerä¸€èˆ¬æ˜¯documentçš„ä¸€ä¸ªè¯ã€‚</p>
<h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æœ¬æ–‡æå‡ºçš„attentionæœºåˆ¶ï¼Œæ˜¯é€šè¿‡ä¸€ä¸ªæ–°çš„attentionå»æŒ‡ç¤ºå¦ä¸€ä¸ªattentionçš„é‡è¦ç¨‹åº¦ã€‚</p>
<p>é¦–å…ˆé€šè¿‡ä¸€å±‚å…±äº«çš„embeddingå±‚ï¼Œå°†documentå’Œqueryéƒ½encodeæˆword embeddingï¼Œç„¶åé€šè¿‡åŒå‘çš„GRUï¼Œå°†éšå±‚æ‹¼æ¥èµ·æ¥æˆä¸ºæ–°çš„è¡¨ç¤ºã€‚</p>
<p>æ¥ç€è·å¾—pair-wise matching matrixï¼š<br><img src="/images/15425993645945.jpg" width="40%" height="50%"></p>
<p>å…¶ä¸­$h$ä»£è¡¨ä¸Šè¿°æåˆ°çš„æ‹¼æ¥èµ·æ¥çš„è¡¨ç¤ºï¼Œ$M(i,j)$ä»£è¡¨äº†documentçš„è¯$i$å’Œquestionçš„è¯$j$ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚</p>
<p>æ¥ç€å¯¹<strong>column</strong>åšsoftmaxï¼š<br><img src="/images/15425994692189.jpg" width="50%" height="50%"><br>å…¶ä»£è¡¨çš„æ„ä¹‰å³query-to-document attentionï¼Œäº¦å³<strong>å¯¹äºä¸€ä¸ªqueryå†…çš„è¯ï¼Œdocumentçš„æ¯ä¸ªè¯ä¸å…¶åŒ¹é…çš„æƒé‡</strong>ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œå¯¹rowè¿›è¡Œsoftmaxæ“ä½œï¼š<br><img src="/images/15425995482827.jpg" width="50%" height="50%"><br>ä»£è¡¨çš„æ˜¯<strong>ç»™å®šä¸€ä¸ªdocumentçš„è¯ï¼Œqueryçš„å“ªä¸ªè¯æ›´ä¸ºé‡è¦</strong>ã€‚</p>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†Î²å¹³å‡èµ·æ¥ï¼Œè·å¾—ä¸€ä¸ªå‘é‡ï¼š<br><img src="/images/15425996847558.jpg" width="20%" height="50%"><br>è¿™ä¸ªå‘é‡ä»æœ‰attentionçš„æ€§è´¨ï¼Œå³æ‰€æœ‰å…ƒç´ åŠ å’Œä¸º1ã€‚ä»£è¡¨çš„æ˜¯<strong>ä»å¹³å‡æ¥çœ‹ï¼Œqueryè¯çš„é‡è¦æ€§</strong>ã€‚</p>
<p>æœ€åï¼Œæˆ‘ä»¬å¯¹Î±å’ŒÎ²åšç‚¹ç§¯ä»¥è·å¾—attended document-level attentionï¼š<br><img src="/images/15425997529193.jpg" width="13%" height="50%"></p>
<p>å…¶ä¸­$s$çš„ç»´åº¦æ˜¯$D\times 1$ã€‚sä»£è¡¨çš„æ„ä¹‰å³â€œa weighted sum of each individual document-level attention Î±(t) when looking at query word at time tâ€ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹Î±è¿›è¡ŒåŠ æƒï¼Œä»£è¡¨query wordçš„å¹³å‡é‡è¦ç¨‹åº¦ã€‚</p>
<p>æœ€ç»ˆåœ¨åšå®Œå‹å¡«ç©ºçš„é¢„æµ‹æ—¶ï¼š<br><img src="/images/15425999965777.jpg" width="38%" height="50%"></p>
<p>ä¸ªäººè§‰å¾—è¿™ç§attention-over-attentionçš„æƒ³æ³•è¿˜æ˜¯æŒºæœ‰åˆ›æ–°çš„ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>attention</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>sentence embedding</tag>
        <tag>nested attention</tag>
      </tags>
  </entry>
  <entry>
    <title>ç½‘ç»œä¼˜åŒ–ä¸æ­£åˆ™åŒ–æ€»ç»“</title>
    <url>/2018/11/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>å¤§é‡å‚è€ƒè‡ª<a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a></p>
<h1 id="ä¼˜åŒ–ç®—æ³•"><a href="#ä¼˜åŒ–ç®—æ³•" class="headerlink" title="ä¼˜åŒ–ç®—æ³•"></a>ä¼˜åŒ–ç®—æ³•</h1><p>å¯¹äºæ ‡å‡†çš„SGDï¼Œå¸¸è§çš„æ”¹è¿›ç®—æ³•ä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œï¼šå­¦ä¹ ç‡è¡°å‡&amp;æ¢¯åº¦æ–¹å‘ä¼˜åŒ–ã€‚<br>è®°$g_t$ä¸ºtæ—¶åˆ»çš„å¯¼æ•°ï¼š<br><img src="/images/2018-11-13-15421196736629.jpg" width="20%" height="50%"></p>
<h2 id="å­¦ä¹ ç‡è¡°å‡"><a href="#å­¦ä¹ ç‡è¡°å‡" class="headerlink" title="å­¦ä¹ ç‡è¡°å‡"></a>å­¦ä¹ ç‡è¡°å‡</h2><h3 id="AdaGradç®—æ³•"><a href="#AdaGradç®—æ³•" class="headerlink" title="AdaGradç®—æ³•"></a>AdaGradç®—æ³•</h3><p>é€šè¿‡è®¡ç®—å†æ¬¡çš„æ¢¯åº¦å¹³æ–¹ç´¯è®¡å€¼è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ã€‚<br>$G_t$æ˜¯ç´¯è®¡å€¼ï¼š<br><img src="/images/2018-11-13-15421189802198.jpg" width="20%" height="50%"></p>
<p>æ›´æ–°å€¼åˆ™ä¸ºï¼š<br><img src="/images/2018-11-13-15421190100615.jpg" width="30%" height="50%"></p>
<p>ç¼ºç‚¹ï¼šéšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ å­¦ä¹ ç‡é€’å‡ã€‚åœ¨ç»è¿‡ä¸€å®šæ¬¡æ•°çš„è¿­ä»£ä¾ç„¶æ²¡æœ‰æ‰¾åˆ°æœ€ä¼˜ç‚¹æ—¶ï¼Œç”±äºè¿™æ—¶çš„å­¦ä¹ ç‡å·²ç»éå¸¸å°ï¼Œå¾ˆéš¾å†ç»§ç»­æ‰¾åˆ°æœ€ä¼˜ç‚¹ã€‚</p>
<h3 id="RMSpropç®—æ³•"><a href="#RMSpropç®—æ³•" class="headerlink" title="RMSpropç®—æ³•"></a>RMSpropç®—æ³•</h3><p>å¯¹AdaGradçš„æ”¹è¿›ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äº$G_t$çš„è®¡ç®—ï¼Œå°†å†å²ä¿¡æ¯å’Œå½“å‰ä¿¡æ¯è¿›è¡Œçº¿æ€§åŠ æƒï¼Œä½¿å¾—å­¦ä¹ ç‡å¯ä»¥åŠ¨æ€æ”¹å˜è€Œä¸æ˜¯å•è°ƒé€’å‡ï¼š<br><img src="/images/2018-11-13-15421192344025.jpg" width="40%" height="50%"></p>
<p>Î²ä¸ºè¡°å‡ç‡ï¼Œé€šå¸¸å–0.9ã€‚ä¹Ÿå³å†å²ä¿¡æ¯å ä¸»å¯¼ã€‚</p>
<h3 id="AdaDeltaç®—æ³•"><a href="#AdaDeltaç®—æ³•" class="headerlink" title="AdaDeltaç®—æ³•"></a>AdaDeltaç®—æ³•</h3><p>åŒæ ·æ˜¯å¯¹AdaGradçš„æ”¹è¿›ã€‚<br>æ¯æ¬¡è®¡ç®—ï¼š<br><img src="/images/2018-11-13-15421195264173.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³å†å²æ›´æ–°å·®å’Œä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®çš„åŠ æƒï¼ˆRMSpropæ˜¯å†å²æ¢¯åº¦å’Œå½“å‰æ¢¯åº¦ï¼‰ã€‚</p>
<p>æœ€ç»ˆæ›´æ–°å·®å€¼ä¸ºï¼š<br><img src="/images/2018-11-13-15421197355615.jpg" width="30%" height="50%"></p>
<p>å…¶ä¸­$G_t$è®¡ç®—æ–¹æ³•å’ŒRMSpropä¸€è‡´ã€‚</p>
<h2 id="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"><a href="#æ¢¯åº¦æ–¹å‘ä¼˜åŒ–" class="headerlink" title="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"></a>æ¢¯åº¦æ–¹å‘ä¼˜åŒ–</h2><p>åˆ©ç”¨å†å²çš„æ¢¯åº¦ï¼ˆæ–¹å‘ï¼‰è°ƒæ•´å½“å‰æ—¶åˆ»çš„æ¢¯åº¦ã€‚</p>
<h3 id="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"><a href="#åŠ¨é‡ï¼ˆMomentumï¼‰æ³•" class="headerlink" title="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"></a>åŠ¨é‡ï¼ˆMomentumï¼‰æ³•</h3><p>åŠ¨é‡æ³•ï¼ˆMomentum Methodï¼‰æ˜¯ç”¨ä¹‹å‰ç§¯ç´¯åŠ¨é‡æ¥æ›¿ä»£çœŸæ­£çš„æ¢¯åº¦ã€‚æ¯æ¬¡è¿­ä»£çš„æ¢¯åº¦å¯ä»¥çœ‹ä½œæ˜¯åŠ é€Ÿåº¦ã€‚</p>
<p><img src="/images/2018-11-13-15421199473226.jpg" width="28%" height="50%"></p>
<p>ä¹Ÿå³ä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®å€¼å’Œå½“å‰æ¢¯åº¦å…±åŒå†³å®šå½“å‰çš„æ›´æ–°å·®å€¼ã€‚$Ï$ä¸ºåŠ¨é‡å› å­ï¼Œé€šå¸¸ä¸º0.9ã€‚ä¹Ÿå³åŠ¨é‡å äº†ä¸»å¯¼ã€‚</p>
<p>å½“æŸä¸ªå‚æ•°åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘ä¸ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å°ï¼›ç›¸åï¼Œå½“åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘éƒ½ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å¤§ï¼Œèµ·åˆ°åŠ é€Ÿä½œç”¨ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨è¿­ä»£åˆæœŸï¼Œæ¢¯åº¦æ–¹æ³•éƒ½æ¯”è¾ƒä¸€è‡´ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°åŠ é€Ÿä½œç”¨ï¼Œå¯ä»¥æ›´å¿«åœ°åˆ°è¾¾æœ€ä¼˜ç‚¹ã€‚åœ¨è¿­ä»£åæœŸï¼Œæ¢¯åº¦æ–¹æ³•ä¼šå–å†³ä¸ä¸€è‡´ï¼Œåœ¨æ”¶æ•›å€¼é™„è¿‘éœ‡è¡ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°å‡é€Ÿä½œç”¨ï¼Œå¢åŠ ç¨³å®šæ€§ã€‚</p>
<h3 id="NesterovåŠ é€Ÿæ¢¯åº¦"><a href="#NesterovåŠ é€Ÿæ¢¯åº¦" class="headerlink" title="NesterovåŠ é€Ÿæ¢¯åº¦"></a>NesterovåŠ é€Ÿæ¢¯åº¦</h3><p>åŠ¨é‡æ³•çš„æ”¹è¿›ç‰ˆæœ¬ã€‚</p>
<p>å‰é¢æåˆ°çš„åŠ¨é‡æ³•ï¼Œæ˜¯ä¸Šä¸€æ­¥çš„æ›´æ–°æ–¹å‘$\Delta \theta_{t-1}$ä¸å½“å‰æ¢¯åº¦$-g_t$çš„åŠ å’Œã€‚å› æ­¤å¯ä»¥ç†è§£æˆï¼Œå…ˆæ ¹æ®$âˆ†Î¸_{tâˆ’1}$æ›´æ–°ä¸€æ¬¡å¾—åˆ°å‚æ•°Î¸ï¼Œå†ç”¨$g_t$è¿›è¡Œæ›´æ–°ã€‚äº¦å³ï¼š<br><img src="/images/2018-11-13-15421202426163.jpg" width="27%" height="50%"><br>ä¸Šå¼çš„ç¬¬äºŒæ­¥ä¸­ï¼Œ$g_t$æ˜¯åœ¨$ \theta_{t-1}$ä¸Šçš„æ¢¯åº¦ã€‚æˆ‘ä»¬å°†è¯¥æ­¥æ”¹ä¸ºåœ¨$\theta_{t}$çš„æ¢¯åº¦ã€‚<br>å› æ­¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-13-15421203421465.jpg" width="50%" height="50%"></p>
<p>å’ŒåŠ¨é‡æ³•ç›¸æ¯”ï¼Œç›¸å½“äºæå‰èµ°äº†ä¸€æ­¥ã€‚<br><img src="/images/2018-11-13-15421203910771.jpg" width="70%" height="50%"></p>
<h3 id="Adam-amp-Nadam"><a href="#Adam-amp-Nadam" class="headerlink" title="Adam&amp;Nadam"></a>Adam&amp;Nadam</h3><p>Adamä¸€æ–¹é¢è®¡ç®—æ¢¯åº¦å¹³æ–¹çš„åŠ æƒï¼ŒåŒæ—¶è¿˜è®¡ç®—æ¢¯åº¦çš„åŠ æƒï¼š<br><img src="/images/2018-11-13-15421205162558.jpg" width="40%" height="50%"><br>é€šå¸¸$Î²_1=0.9$ï¼Œ$Î²_2=0.99$<br>ä¹Ÿå³å†å²ä¿¡æ¯å äº†ä¸»å¯¼ã€‚</p>
<p>åœ¨åˆæœŸ$M_t$ä¸$G_t$ä¼šæ¯”çœŸå®å‡å€¼å’Œæ–¹å·®è¦å°ï¼ˆæƒ³è±¡$M_0=0$ï¼Œ$G_0=0$æ—¶ï¼‰ã€‚å› æ­¤å¯¹å…¶è¿›è¡Œä¿®æ­£ï¼Œå³ï¼š<br><img src="/images/2018-11-13-15421207635850.jpg" width="18%" height="50%"><br>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-11-13-15421207966341.jpg" width="26%" height="50%"></p>
<p>åŒç†æœ‰Nadamã€‚</p>
<p>Adam = Momentum + RMSprop<br>Nadam = Nesterov + RMSprop</p>
<h3 id="æ¢¯åº¦æˆªæ–­-gradient-clipping"><a href="#æ¢¯åº¦æˆªæ–­-gradient-clipping" class="headerlink" title="æ¢¯åº¦æˆªæ–­ gradient clipping"></a>æ¢¯åº¦æˆªæ–­ gradient clipping</h3><p>åˆ†ä¸ºæŒ‰å€¼æˆªæ–­ä¸æŒ‰æ¨¡æˆªæ–­ã€‚</p>
<h1 id="å‚æ•°åˆå§‹åŒ–"><a href="#å‚æ•°åˆå§‹åŒ–" class="headerlink" title="å‚æ•°åˆå§‹åŒ–"></a>å‚æ•°åˆå§‹åŒ–</h1><p>åˆå§‹å€¼é€‰å–å¾ˆå…³é”®ã€‚å‡è®¾å…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Œåˆ™åç»­æ›´æ–°å¯¼è‡´æ‰€æœ‰çš„æ¿€æ´»å€¼ç›¸åŒï¼Œä¹Ÿå³å¯¹ç§°æƒé‡ç°è±¡ã€‚</p>
<p>åŸåˆ™ï¼šä¸èƒ½è¿‡å¤§ï¼Œå¦åˆ™æ¿€æ´»å€¼ä¼šå˜å¾—é¥±å’Œï¼Œå¦‚sigmoidï¼›ä¸èƒ½è¿‡å°ï¼Œå¦åˆ™ç»è¿‡å¤šå±‚ä¿¡å·ä¼šé€æ¸æ¶ˆå¤±ï¼Œå¹¶ä¸”å¯¼è‡´sigmoidä¸¢å¤±éçº¿æ€§çš„èƒ½åŠ›ï¼ˆåœ¨0é™„è¿‘åŸºæœ¬è¿‘ä¼¼çº¿æ€§ï¼‰ã€‚å¦‚æœä¸€ä¸ªç¥ç»å…ƒçš„è¾“å…¥è¿æ¥å¾ˆå¤šï¼Œå®ƒçš„æ¯ä¸ªè¾“å…¥è¿æ¥ä¸Šçš„æƒé‡å°±åº”è¯¥å°ä¸€äº›ï¼Œè¿™æ˜¯ä¸ºäº†é¿å…è¾“å‡ºè¿‡å¤§ã€‚</p>
<h2 id="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"><a href="#Gaussianåˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"></a>Gaussianåˆ†å¸ƒåˆå§‹åŒ–</h2><p>åŒæ—¶è€ƒè™‘è¾“å…¥è¾“å‡ºï¼Œå¯ä»¥æŒ‰ $N(0,\sqrt{\frac{2}{n_{in} + n_{out}}})$ é«˜æ–¯åˆ†å¸ƒæ¥åˆå§‹åŒ–ã€‚</p>
<h2 id="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"><a href="#å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"></a>å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–</h2><p>åœ¨$[-r,r]$åŒºé—´å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå…¶ä¸­rå¯ä»¥æŒ‰ç…§ç¥ç»å…ƒæ•°é‡è‡ªé€‚åº”è°ƒæ•´ã€‚</p>
<h3 id="Xavieråˆå§‹åŒ–æ–¹æ³•"><a href="#Xavieråˆå§‹åŒ–æ–¹æ³•" class="headerlink" title="Xavieråˆå§‹åŒ–æ–¹æ³•"></a>Xavieråˆå§‹åŒ–æ–¹æ³•</h3><p>è‡ªåŠ¨è®¡ç®—è¶…å‚rã€‚rçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-11-14-15421648119504.jpg" width="22%" height="50%"><br>å…¶ä¸­$n^l$ä»£è¡¨ç¬¬$l$å±‚çš„ç¥ç»å…ƒä¸ªæ•°ã€‚</p>
<p>ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªå¼å­ï¼ˆæ¨å¯¼è§å‚è€ƒèµ„æ–™ï¼‰ï¼šç»¼åˆè€ƒè™‘äº†â‘ è¾“å…¥è¾“å‡ºçš„æ–¹å·®è¦ä¸€è‡´ï¼›â‘¡åå‘ä¼ æ’­ä¸­è¯¯å·®ä¿¡å·çš„æ–¹å·®ä¸è¢«æ”¾å¤§æˆ–ç¼©å°ã€‚</p>
<h1 id="å½’ä¸€åŒ–"><a href="#å½’ä¸€åŒ–" class="headerlink" title="å½’ä¸€åŒ–"></a>å½’ä¸€åŒ–</h1><p>å°†æ•°æ®åˆ†å¸ƒå½’ä¸€åŒ–ï¼Œä½¿å¾—åˆ†å¸ƒä¿æŒç¨³å®šã€‚<br><img src="/images/2018-11-14-15421656553319.jpg" width="100%" height="50%"><br>å‡è®¾æ•°æ®æœ‰å››ç»´(N,C,H,W)ã€‚Nä»£è¡¨batchï¼›Cä»£è¡¨channelï¼›H,Wä»£è¡¨heightå’Œwidthã€‚</p>
<h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>æ²¿ç€é€šé“è¿›è¡Œå½’ä¸€åŒ–ï¼Œäº¦å³æ¯ä¸ªé€šé“éƒ½æœ‰è‡ªå·±çš„å‡å€¼å’Œæ–¹å·®ã€‚<br><img src="/images/2018-11-14-15421657694248.jpg" width="70%" height="50%"><br>å…¶ä¸­ç¼©æ”¾å¹³ç§»å˜é‡æ˜¯å¯å­¦ä¹ çš„ã€‚</p>
<p>ç¼ºç‚¹ï¼š<br>â‘ å¯¹batch sizeæ•æ„Ÿï¼Œbatch sizeå¤ªå°åˆ™æ–¹å·®å‡å€¼ä¸è¶³ä»¥ä»£è¡¨æ•°æ®åˆ†å¸ƒ<br>â‘¡å¯¹äºä¸ç­‰é•¿çš„è¾“å…¥å¦‚RNNæ¥è¯´ï¼Œæ¯ä¸€ä¸ªtimestepéƒ½éœ€è¦ä¿å­˜ä¸åŒçš„ç‰¹å¾ã€‚</p>
<h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>å¯¹ä¸€ä¸ªè¾“å…¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œäº¦å³æ¯ä¸ªè¾“å…¥éƒ½æœ‰è‡ªå·±çš„æ–¹å·®ã€å‡å€¼ã€‚è¿™æ ·ä¸ä¾èµ–äºbatchå¤§å°å’Œè¾“å…¥sequenceçš„æ·±åº¦ã€‚</p>
<p>å¯¹RNNæ•ˆæœæ¯”è¾ƒæ˜æ˜¾ï¼Œä½†CNNä¸­ä¸å¦‚BN</p>
<h2 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a>Instance Normalization</h2><p>å¯¹HWè¿›è¡Œå½’ä¸€åŒ–</p>
<h2 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h2><p>å°†channelåˆ†ä¸ºå¤šä¸ªgroupï¼Œæ¯ä¸ªgroupå†…åšå½’ä¸€åŒ–</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a><br><a href="https://blog.csdn.net/liuxiao214/article/details/81037416" target="_blank" rel="noopener">https://blog.csdn.net/liuxiao214/article/details/81037416</a></p>
]]></content>
      <tags>
        <tag>æ·±åº¦å­¦ä¹ ğŸ¤–</tag>
        <tag>ä¼˜åŒ–ç®—æ³•</tag>
        <tag>å‚æ•°åˆå§‹åŒ–</tag>
        <tag>Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•10</title>
    <url>/2018/11/11/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9510/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-get-sinusoid-encoding-table"><a href="#1ï¸âƒ£-get-sinusoid-encoding-table" class="headerlink" title="1ï¸âƒ£[get_sinusoid_encoding_table]"></a>1ï¸âƒ£[get_sinusoid_encoding_table]</h3><p>Transformerç»å¯¹ä½ç½®ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sinusoid_encoding_table</span><span class="params">(n_position, d_hid, padding_idx=None)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_angle</span><span class="params">(position, hid_idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> position / np.power(<span class="number">10000</span>, <span class="number">2</span> * (hid_idx // <span class="number">2</span>) / d_hid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_posi_angle_vec</span><span class="params">(position)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [cal_angle(position, hid_j) <span class="keyword">for</span> hid_j <span class="keyword">in</span> range(d_hid)]</span><br><span class="line"></span><br><span class="line">    sinusoid_table = np.array([get_posi_angle_vec(pos_i) <span class="keyword">for</span> pos_i <span class="keyword">in</span> range(n_position)])</span><br><span class="line"></span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.cos(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        sinusoid_table[padding_idx] = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(sinusoid_table)  <span class="comment"># n_position,embed_dim</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†11</title>
    <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8611/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Optimizer"><a href="#1ï¸âƒ£-Optimizer" class="headerlink" title="1ï¸âƒ£[Optimizer]"></a>1ï¸âƒ£[Optimizer]</h3><p><a href="https://zhuanlan.zhihu.com/p/32262540" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32262540</a><br><a href="https://zhuanlan.zhihu.com/p/32338983" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32338983</a></p>
<p>Adamç­‰è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•å¯¹äºç¨€ç–æ•°æ®å…·æœ‰ä¼˜åŠ¿ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¾ˆå¿«ï¼›ä½†ç²¾è°ƒå‚æ•°çš„SGDï¼ˆ+Momentumï¼‰å¾€å¾€èƒ½å¤Ÿå–å¾—æ›´å¥½çš„æœ€ç»ˆç»“æœã€‚</p>
<p>å»ºè®®ï¼š<br>å‰æœŸç”¨Adamï¼Œäº«å—Adamå¿«é€Ÿæ”¶æ•›çš„ä¼˜åŠ¿ï¼›åæœŸåˆ‡æ¢åˆ°SGDï¼Œæ…¢æ…¢å¯»æ‰¾æœ€ä¼˜è§£ã€‚<br>ä»€ä¹ˆæ—¶å€™ä»Adamåˆ‡æ¢åˆ°SGDï¼Ÿå½“SGDçš„ç›¸åº”å­¦ä¹ ç‡çš„ç§»åŠ¨å¹³å‡å€¼åŸºæœ¬ä¸å˜çš„æ—¶å€™ã€‚</p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>LongTensoré™¤ä»¥æµ®ç‚¹æ•°ï¼Œä¼šå¯¹é™¤æ•°è¿›è¡Œå–æ•´ï¼Œå†åšé™¤æ³•ã€‚<br><img src="/images/2018-11-11-15419055399325.jpg" width="30%" height="50%"></p>
<hr>
<h3 id="3ï¸âƒ£-Pytorch"><a href="#3ï¸âƒ£-Pytorch" class="headerlink" title="3ï¸âƒ£[Pytorch]"></a>3ï¸âƒ£[Pytorch]</h3><p>ä½¿ç”¨Pytorchçš„DataParallel</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda:'</span> + str(</span><br><span class="line">    config.CUDA_VISIBLE_DEVICES[<span class="number">0</span>]) <span class="keyword">if</span> config.use_cuda <span class="keyword">else</span> <span class="string">'cpu'</span>)   <span class="comment"># æŒ‡å®šç¬¬ä¸€ä¸ªè®¾å¤‡</span></span><br><span class="line"></span><br><span class="line">model = ClassifyModel(</span><br><span class="line">    vocab_size=len(vocab), max_seq_len=config.max_sent_len,</span><br><span class="line">    embed_dim=config.embed_dim, n_layers=config.n_layers,</span><br><span class="line">    n_head=config.n_head, d_k=config.d_k,</span><br><span class="line">    d_v=config.d_v,</span><br><span class="line">    d_model=config.d_model, d_inner=config.d_inner_hid,</span><br><span class="line">    n_label=config.n_label,</span><br><span class="line">    dropout=config.dropout</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">model = DataParallel(model, device_ids=config.CUDA_VISIBLE_DEVICES)  <span class="comment"># æ˜¾å¼å®šä¹‰device_ids</span></span><br></pre></td></tr></table></figure>
<p>æ³¨æ„åˆ°ï¼šdevice_idsçš„èµ·å§‹ç¼–å·è¦ä¸ä¹‹å‰å®šä¹‰çš„deviceä¸­çš„â€œcuda:0â€ç›¸ä¸€è‡´ï¼Œä¸ç„¶ä¼šæŠ¥é”™ã€‚</p>
<p>å¦‚æœä¸æ˜¾å¼åœ¨ä»£ç ä¸­çš„DataParallelæŒ‡å®šè®¾å¤‡ï¼Œé‚£ä¹ˆéœ€è¦åœ¨å‘½ä»¤è¡Œå†…æŒ‡å®šã€‚å¦‚æœæ˜¯åœ¨å‘½ä»¤è¡Œé‡Œé¢è¿è¡Œçš„ï¼Œä¸”deviceä¸æ˜¯ä»0å¼€å§‹ï¼Œåº”å½“æ˜¾å¼è®¾ç½®GPU_idï¼Œå¦åˆ™ä¼šå‡ºé”™â€˜AssertionError: Invalid device idâ€™ï¼Œæ­£ç¡®çš„å‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=4,5Â  python -u classify_main.py --gpu_id 0,1</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Optimizer</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºsparse gradient</title>
    <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8Esparse%20gradient/</url>
    <content><![CDATA[<p>å‰å‡ å¤©åœ¨çœ‹AllenAIåœ¨EMNLPçš„pptæ—¶ï¼Œæœ‰ä¸€é¡µå†™é“ï¼š<br><img src="/images/2018-11-11-15419037448379.jpg" width="70%" height="50%"></p>
<p>ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µï¼Ÿ</p>
<p>Embeddingæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„çŸ©é˜µï¼Œæ¯ä¸€æ¬¡å…¶å®éƒ½åªæœ‰ä¸€ä¸ªå°éƒ¨åˆ†è¿›è¡Œäº†æ›´æ–°ï¼Œå¯¹äºä¸€äº›è¯æ¥è¯´ï¼Œå‡ºç°çš„é¢‘ç‡ä¸é«˜ï¼Œæˆ–è€…è¯´ï¼Œå…¶å®å¤§éƒ¨åˆ†çš„è¯åœ¨ä¸€ä¸ªloop/epochä¸­ï¼Œè¢«æ›´æ–°çš„æ¬¡æ•°æ˜¯è¾ƒå°‘çš„ã€‚ä½†æ˜¯ï¼Œæ³¨æ„åˆ°ä¸€èˆ¬çš„optimizerç®—æ³•ï¼Œæ˜¯ä»¥matrixä¸ºå•ä½è¿›è¡Œæ›´æ–°çš„ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€æ¬¡éƒ½æ˜¯$W^{t+1}=W^{t}-\eta \frac{\partial L}{\partial{W}}$</p>
<p>è€ŒAdamç®—æ³•ï¼š<br><img src="/images/2018-11-11-15419038346958.jpg" width="70%" height="50%"></p>
<p>åŠ¨é‡å äº†ä¸»å¯¼ã€‚ä½†è¿™æ ·ï¼Œæ¯æ¬¡batchæ›´æ–°ï¼Œé‚£äº›æ²¡è¢«æ›´æ–°çš„è¯ï¼ˆä¹Ÿå³gradient=0ï¼‰çš„åŠ¨é‡ä»ç„¶ä¼šè¢«è¡°å‡ï¼Œæ‰€ä»¥è¿™æ ·å½“åˆ°è¿™ä¸ªè¯æ›´æ–°çš„æ—¶å€™ï¼Œä»–çš„åŠ¨é‡å·²ç»è¢«è¡°å‡å®Œäº†ï¼Œæ‰€ä»¥æ›´æ–°çš„gradientå°±å¾ˆå°ã€‚</p>
<p>è§£å†³æ–¹æ¡ˆï¼š</p>
<p>â‘ åœ¨PyTorchä¸­ï¼ŒEmbeddingçš„APIï¼š<br><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False, _weight=None)</code></p>
<p>å…¶ä¸­sparse (bool, optional) â€“ if True, gradient w.r.t. weight matrix will be a sparse tensor.</p>
<p>å°†sparseè®¾ä¸ºTrueå³å¯ã€‚</p>
<p>â‘¡é’ˆå¯¹sparseçŸ©é˜µï¼Œä½¿ç”¨ä¸åŒçš„optimizerï¼Œå¦‚torch.optim.SparseAdamï¼š</p>
<blockquote>
<p>Implements lazy version of Adam algorithm suitable for sparse tensors.<br>In this variant, only moments that show up in the gradient get updated, and only those portions of the gradient get applied to the parameters.</p>
</blockquote>
]]></content>
      <tags>
        <tag>sparse gradient</tag>
        <tag>ä»£ç å®è·µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡5</title>
    <url>/2018/11/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%875/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Neural-Turing-Machine"><a href="#1ï¸âƒ£-Neural-Turing-Machine" class="headerlink" title="1ï¸âƒ£[Neural Turing Machine]"></a>1ï¸âƒ£[Neural Turing Machine]</h2><p>é€šè¿‡æ¨¡ä»¿å†¯è¯ºä¾æ›¼æœºï¼Œå¼•å…¥å¤–éƒ¨å†…å­˜(externel memory)ã€‚<br><img src="/images/2018-11-10-15418626837026.jpg" width="70%" height="50%"></p>
<p>å’Œæ™®é€šç¥ç»ç½‘ç»œä¸€æ ·ï¼Œä¸å¤–ç•Œäº¤äº’ï¼Œè·å¾—ä¸€ä¸ªè¾“å…¥ï¼Œäº§ç”Ÿä¸€ä¸ªè¾“å‡ºã€‚ä½†ä¸åŒçš„æ˜¯ï¼Œå†…éƒ¨è¿˜æœ‰ä¸€ä¸ªmemoryè¿›è¡Œè¯»å†™ã€‚<br>å‡è®¾memoryæ˜¯ä¸€ä¸ªN Ã— Mçš„çŸ©é˜µï¼ŒNæ˜¯å†…å­˜çš„ä½ç½®æ•°é‡ã€‚</p>
<h3 id="è¯»å†™memory"><a href="#è¯»å†™memory" class="headerlink" title="è¯»å†™memory"></a>è¯»å†™memory</h3><p>â‘ è¯»<br><img src="/images/2018-11-10-15418627403268.jpg" width="25%" height="50%"><br>å…¶ä¸­è¯»çš„æ—¶å€™å¯¹å„å†…å­˜ä½ç½®çº¿æ€§åŠ æƒã€‚wæ˜¯å½’ä¸€åŒ–æƒé‡ã€‚</p>
<p>â‘¡å†™<br>$e_t$æ˜¯æ“¦é™¤å‘é‡ï¼ˆerase vectorï¼‰<br><img src="/images/2018-11-10-15418627941358.jpg" width="35%" height="50%"></p>
<p>$a_t$æ˜¯åŠ å’Œå‘é‡(add vector)<br><img src="/images/2018-11-10-15418628323343.jpg" width="30%" height="50%"></p>
<p>å…·ä½“å¦‚ä½•è·å¾—æƒé‡å°±ä¸è¯´äº†ã€‚</p>
<h3 id="Controller-network"><a href="#Controller-network" class="headerlink" title="Controller network"></a>Controller network</h3><p>ä¸­é—´çš„controller networkå¯ä»¥æ˜¯ä¸€ä¸ªæ™®é€šçš„feed forwardæˆ–è€…RNNã€‚</p>
<p>åœ¨å®é™…ä¸­NTMç”¨å¾—å¹¶ä¸å¤šã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling"><a href="#2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling" class="headerlink" title="2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]"></a>2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]</h2><p>ELMoçš„ç²¾ç®€ç‰ˆï¼Œé€šè¿‡å³æ’å³ç”¨çš„æ–¹æ³•æ¥å‹ç¼©è¯­è¨€æ¨¡å‹ï¼Œå¯¹ç‰¹å®šä»»åŠ¡å‰ªæä¸åŒçš„å±‚ï¼Œä½¿å¾—èƒ½å¤Ÿå‡å°‘inferenceçš„æ—¶é—´ã€‚<br>è¿™ç¯‡çš„ideaæŒºæœ‰åˆ›æ–°çš„ï¼Œä½†ä¼¼ä¹æœ‰äº›trivialçš„æ„Ÿè§‰ã€‚</p>
<p><img src="/images/2018-11-11-15418977712883.jpg" width="70%" height="50%"></p>
<h3 id="RNN-and-Dense-Connectivity"><a href="#RNN-and-Dense-Connectivity" class="headerlink" title="RNN and Dense Connectivity"></a>RNN and Dense Connectivity</h3><p>æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¼šä¼ åˆ°æ‰€æœ‰å±‚ä½œä¸ºè¾“å…¥ï¼Œå› æ­¤å¯¹äºLå±‚çš„è¾“å…¥ï¼š<br><img src="/images/2018-11-11-15418979328482.jpg" width="35%" height="50%"></p>
<p>è¿™æ ·æˆ‘ä»¬å°±èƒ½å¤Ÿéšæ„åœ°å»æ‰ä»»æ„ä¸­é—´å±‚äº†ã€‚åŒæ—¶ä¸€äº›è¯­è¨€ä¿¡æ¯ä¹Ÿåˆ†æ•£åˆ°å„ä¸ªå±‚ï¼Œå³ä½¿å»æ‰æŸäº›å±‚ä¹Ÿæ²¡æœ‰å…³ç³»ã€‚</p>
<p>åˆ™æœ€ç»ˆçš„outputä¸ºï¼š<br><img src="/images/2018-11-11-15418991345288.jpg" width="33%" height="50%"></p>
<p>æœ€ç»ˆä½œprojectionåˆ°æ­£å¸¸ç»´åº¦ï¼ˆåœ¨æ¯å±‚éƒ½ä¼šè¿™ä¹ˆåšï¼Œå°†è¾“å…¥é™ç»´åˆ°æ­£å¸¸ç»´åº¦å†è¾“å…¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418992517849.jpg" width="37%" height="50%"></p>
<p>å†åšä¸€ä¸ªsoftmaxï¼š<br><img src="/images/2018-11-11-15418993146246.jpg" width="32%" height="50%"></p>
<p>ç”±äº $h^{â€»}$ ç”¨äºsoftmaxï¼Œæ‰€ä»¥å¯èƒ½å’Œtarget wordï¼Œä¹Ÿå³ä¸‹ä¸€ä¸ªè¯æ¯”è¾ƒç›¸ä¼¼ï¼Œ<strong>å› æ­¤å¯èƒ½æ²¡æœ‰å¾ˆå¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯</strong>ã€‚</p>
<p>æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬ä½¿ç”¨$h_t$ï¼Œä»¥åŠåå‘çš„$h_t^r$ï¼Œå†è¿‡ä¸€å±‚çº¿æ€§å±‚è·å¾—æœ€ç»ˆçš„embeddingï¼ˆå’ŒELMoæœ‰äº›ä¸åŒï¼ŒELMoæ˜¯ç›´æ¥æ‹¼èµ·æ¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418994541442.jpg" width="40%" height="50%"></p>
<h3 id="Layer-Selection"><a href="#Layer-Selection" class="headerlink" title="Layer Selection"></a>Layer Selection</h3><p>æˆ‘ä»¬åœ¨æ¯å±‚çš„outputéƒ½åŠ ä¸€ä¸ªæƒé‡ç³»æ•°ã€‚<br><img src="/images/2018-11-11-15418996081852.jpg" width="30%" height="50%"></p>
<p>æˆ‘ä»¬å¸Œæœ›åœ¨target taskä¸Šç”¨çš„æ—¶å€™ï¼Œéƒ¨åˆ†zèƒ½å¤Ÿå˜æˆ0ï¼Œè¾¾åˆ°layer selectionçš„æ•ˆæœï¼ŒåŠ å¿«inferenceçš„é€Ÿåº¦ã€‚</p>
<p>äº¦å³ï¼š<br><img src="/images/2018-11-11-15418996697208.jpg" width="20%" height="50%"></p>
<p>ä¸€ç§ç†æƒ³çš„æ–¹æ³•æ˜¯L0æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997294756.jpg" width="17%" height="50%"></p>
<p>ä½†ç”±äºæ²¡åŠæ³•æ±‚å¯¼ï¼Œå› æ­¤ï¼Œé‡‡ç”¨L1æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997747882.jpg" width="15%" height="50%"><br>ä½†ä½¿ç”¨L1æ­£åˆ™åŒ–æœ‰ä¸€å®šçš„é£é™©ï¼Œå› ä¸ºå¦‚æœè®©æ‰€æœ‰zéƒ½è¿œç¦»1ï¼Œé‚£ä¹ˆä¼šå½±å“performanceã€‚</p>
<p>å¼•å…¥æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•$R_2 =\delta(|z|_0&gt;\lambda_1) |z|_1$<br>äº¦å³ï¼Œåªæœ‰åœ¨éé›¶zçš„ä¸ªæ•°å¤§äºæŸä¸ªé˜ˆå€¼æ—¶ï¼Œæ‰èƒ½æœ‰æ­£åˆ™åŒ–æ•ˆæœï¼Œä¿è¯éé›¶çš„ä¸ªæ•°ã€‚â€™it can be â€œturned-offâ€ after achieving a satisfying sparsityâ€™.</p>
<p>è¿›ä¸€æ­¥å¼•å…¥$R_3=\delta(|z|_0&gt;\lambda_1) |z|_1 + |z(1-z)|_1$<br>å…¶ä¸­ç¬¬äºŒé¡¹ä¸ºäº†é¼“åŠ±zå‘0æˆ–1èµ°ã€‚</p>
<h3 id="Layer-wise-Dropout"><a href="#Layer-wise-Dropout" class="headerlink" title="Layer-wise Dropout"></a>Layer-wise Dropout</h3><p>éšæœºåˆ é™¤éƒ¨åˆ†layerï¼Œè¿™äº›layerçš„è¾“å‡ºä¸ä¼šä¼ å…¥ä¹‹åçš„å±‚ï¼Œä½†ä»ç„¶ä¼šå‚ä¸æœ€åçš„representationè®¡ç®—ã€‚<br><img src="/images/2018-11-11-15419000928057.jpg" width="70%" height="50%"></p>
<p>è¿™ç§dropoutä¼šè®©perplexityæ›´é«˜ï¼Œä½†å¯¹ç”Ÿæˆæ›´å¥½çš„representationæœ‰å¸®åŠ©ã€‚</p>
<hr>
<h2 id="3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder"><a href="#3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder" class="headerlink" title="3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]"></a>3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]</h2><p>å…¶ä¸­çš„positional encodingæˆ‘æ¯”è¾ƒæ„Ÿå…´è¶£ã€‚<br>åŸç‰ˆçš„positional encodingæ˜¯ç›´æ¥å’Œembeddingç›¸åŠ çš„ã€‚<br>äº¦å³ï¼š<br><img src="/images/2018-11-11-15419002563338.jpg" width="22%" height="50%"><br>é‚£ä¹ˆåœ¨selt-attentionæ—¶ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-11-15419002855901.jpg" width="45%" height="50%"><br>è¿™æ ·ä¼šæœ‰äº¤å‰é¡¹ï¼š<br><img src="/images/2018-11-11-15419003111684.jpg" width="13%" height="50%"><br>è¯¥é¡¹æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ï¼Œä¸”å¯èƒ½ä¼šå¸¦æ¥è¿‡æ‹Ÿåˆã€‚</p>
<p>å› æ­¤åœ¨è¿™è¾¹å°†positional encodingå’Œembeddingæ‹¼èµ·æ¥ï¼Œäº¦å³ï¼š<br><img src="/images/2018-11-11-15419003740409.jpg" width="23%" height="50%"></p>
<p>å¹¶ä¸”ï¼Œåœ¨è¿›å…¥multi-headæ—¶çš„çº¿æ€§å±‚ä¹Ÿåšæ”¹å˜ï¼š<br><img src="/images/2018-11-11-15419004269693.jpg" width="24%" height="50%"></p>
<p>è¿™æ ·åœ¨ç›¸ä¹˜çš„æ—¶å€™å°±ä¸ä¼šæœ‰äº¤å‰é¡¹äº†ã€‚</p>
<p>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰ä¸€å®šçš„æå‡ã€‚</p>
<hr>
<h2 id="4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>å¤§è‡´ç¿»äº†ä¸€ä¸‹ã€‚<br>Motivation:åœ¨CNNä¸­ï¼Œdropoutå¯¹convolutional layerçš„ä½œç”¨ä¸å¤§ï¼Œä¸€èˆ¬éƒ½åªç”¨åœ¨å…¨è¿æ¥å±‚ã€‚ä½œè€…æ¨æµ‹ï¼Œå› ä¸ºæ¯ä¸ªfeature mapéƒ½æœ‰ä¸€ä¸ªæ„Ÿå—é‡èŒƒå›´ï¼Œä»…ä»…å¯¹å•ä¸ªåƒç´ è¿›è¡Œdropoutå¹¶ä¸èƒ½é™ä½feature mapå­¦ä¹ çš„ç‰¹å¾èŒƒå›´ï¼Œäº¦å³ç½‘ç»œä»å¯ä»¥é€šè¿‡è¯¥ä½ç½®çš„ç›¸é‚»ä½ç½®å…ƒç´ å»å­¦ä¹ å¯¹åº”çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¹Ÿå°±ä¸ä¼šä¿ƒä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ã€‚</p>
<p>å› æ­¤ä½œè€…çš„åšæ³•æ˜¯ï¼Œdropoutä¸€æ•´å—ä½ç½®ã€‚<br><img src="/images/2018-11-11-15419007355875.jpg" width="80%" height="50%"></p>
<hr>
<h2 id="5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network"><a href="#5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network" class="headerlink" title="5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]"></a>5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]</h2><p>æå‡ºäº†AAN(average attention network)ï¼Œå¯¹transformerç¿»è¯‘æ¨¡å‹çš„decodeéƒ¨åˆ†è¿›è¡Œæ”¹è¿›ï¼ŒåŠ é€Ÿäº†è¿‡ç¨‹ã€‚</p>
<p>ç”±äºTransformeråœ¨decodeé˜¶æ®µéœ€è¦ç”¨åˆ°å‰é¢æ‰€æœ‰çš„yï¼Œä¹Ÿå³è‡ªå›å½’(auto-regressive)çš„æ€§è´¨ï¼Œæ‰€ä»¥æ— æ³•å¹¶è¡Œï¼š</p>
<p><img src="/images/2018-11-11-15419009098650.jpg" width="50%" height="50%"></p>
<h3 id="è¿‡ç¨‹"><a href="#è¿‡ç¨‹" class="headerlink" title="è¿‡ç¨‹"></a>è¿‡ç¨‹</h3><p>ç»™å®šyï¼š<br><img src="/images/2018-11-11-15419010325049.jpg" width="27%" height="50%"></p>
<p>é¦–å…ˆå°†ä»–ä»¬åŠ èµ·æ¥ï¼Œè¿‡ä¸€å±‚å…¨è¿æ¥ï¼š<br><img src="/images/2018-11-11-15419010603010.jpg" width="27%" height="50%"><br>è¿™ä¹Ÿç›¸å½“äºå°±æ˜¯è®©æ‰€æœ‰çš„yæœ‰ç›¸åŒçš„æƒé‡ï¼Œæ­¤æ—¶gå°±æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡¨ç¤ºã€‚</p>
<p>æ¥ä¸‹æ¥æ·»åŠ ä¸€ä¸ªgatingï¼š<br><img src="/images/2018-11-11-15419011154221.jpg" width="27%" height="50%"><br>æ§åˆ¶äº†ä»è¿‡å»ä¿å­˜å¤šå°‘ä¿¡æ¯å’Œè·å–å¤šå°‘æ–°çš„ä¿¡æ¯ã€‚</p>
<p>å’ŒTransformeråŸç‰ˆè®ºæ–‡ä¸€æ ·ï¼Œæ·»åŠ ä¸€ä¸ªresidual connectionï¼š<br><img src="/images/2018-11-11-15419011595237.jpg" width="30%" height="50%"></p>
<p>å¦‚å›¾æ•´ä¸ªè¿‡ç¨‹ï¼š<br><img src="/images/2018-11-11-15419011840751.jpg" width="55%" height="50%"></p>
<p>æ€»ç»“ï¼šAAN=average layer+gating layer</p>
<h3 id="åŠ é€Ÿ"><a href="#åŠ é€Ÿ" class="headerlink" title="åŠ é€Ÿ"></a>åŠ é€Ÿ</h3><p>â‘ è€ƒè™‘åˆ°åŠ å’Œæ“ä½œæ˜¯åºåˆ—åŒ–çš„ï¼Œåªèƒ½ä¸€ä¸ªä¸€ä¸ªæ¥ï¼Œä¸èƒ½å¹¶è¡Œï¼Œåœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªmaskçš„trickï¼Œä½¿å¾—åœ¨è®­ç»ƒæ—¶ä¹Ÿèƒ½å¤Ÿå¹¶è¡Œï¼š<br><img src="/images/2018-11-11-15419013219526.jpg" width="60%" height="50%"></p>
<p>â‘¡åœ¨inferenceæ—¶çš„åŠ é€Ÿï¼š<br><img src="/images/2018-11-11-15419019335926.jpg" width="20%" height="50%"></p>
<p>è¿™æ ·Transformerå°±èƒ½å¤Ÿç±»ä¼¼RNNï¼Œåªè€ƒè™‘å‰ä¸€ä¸ªçš„stateï¼Œè€Œä¸æ˜¯å‰é¢æ‰€æœ‰çš„stateã€‚</p>
<p>æœ€ç»ˆçš„æ¨¡å‹ï¼š<br><img src="/images/2018-11-11-15419023032628.jpg" width="60%" height="50%"></p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>dropout</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>self-attention</tag>
        <tag>NTM</tag>
        <tag>ELMo</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯15</title>
    <url>/2018/11/10/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D15/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£èœ€ç›¸"><a href="#1ï¸âƒ£èœ€ç›¸" class="headerlink" title="1ï¸âƒ£èœ€ç›¸"></a>1ï¸âƒ£èœ€ç›¸</h3><p>[å”] æœç”«<br>ä¸ç›¸ç¥ å ‚ä½•å¤„å¯»ï¼Œé”¦å®˜åŸå¤–æŸæ£®æ£®ã€‚<br>æ˜ é˜¶ç¢§è‰è‡ªæ˜¥è‰²ï¼Œéš”å¶é»„é¹‚ç©ºå¥½éŸ³ã€‚<br>ä¸‰é¡¾é¢‘çƒ¦å¤©ä¸‹è®¡ï¼Œä¸¤æœå¼€æµè€è‡£å¿ƒã€‚<br><strong>å‡ºå¸ˆæœªæ·èº«å…ˆæ­»ï¼Œé•¿ä½¿è‹±é›„æ³ªæ»¡è¥Ÿ</strong>ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡4</title>
    <url>/2018/11/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%874/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention"><a href="#1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention" class="headerlink" title="1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]"></a>1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]</h2><p>å°†transformerç”¨äºcharacter-levelçš„è¯­è¨€æ¨¡å‹ä¸­ï¼Œé€šè¿‡æ·»åŠ å¤šä¸ªlossæ¥æé«˜å…¶è¡¨ç°ä»¥åŠåŠ å¿«æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶åŠ æ·±transformerçš„å±‚æ•°ï¼Œæå¤§æå‡è¡¨ç°ï¼Œ12å±‚çš„transformer layerèƒ½è¾¾åˆ°SOTAï¼Œè€Œ64å±‚åˆ™æœ‰æ›´å¤šçš„æå‡ã€‚</p>
<p>æ™®é€šRNNç”¨äºcharacter-level language modelï¼š<br>å°†å¥å­æŒ‰characterä¸ºå•ä½ç»„æˆå¤šä¸ªbatchï¼Œæ¯ä¸ªbatché¢„æµ‹æœ€åä¸€ä¸ªè¯ï¼Œç„¶åå°†è¯¥batchçš„éšçŠ¶æ€ä¼ å…¥ä¸‹ä¸€ä¸ªbatchã€‚ä¹Ÿå³â€œtruncated backpropagation through timeâ€ (TBTT)ã€‚</p>
<p>å¦‚æœç”¨åœ¨Transformerï¼Œå¦‚ä¸‹å›¾ï¼Œæˆ‘ä»¬åªé¢„æµ‹$t_4$ã€‚<br><img src="/images/2018-11-04-15412915431327.jpg" width="90%" height="50%"></p>
<p>æœ¬æ–‡çš„ä¸€å¤§è´¡çŒ®æ˜¯å¤šåŠ äº†ä¸‰ç§lossï¼Œå¹¶ä¸”æœ‰äº›lossçš„æƒå€¼ä¼šéšç€è®­ç»ƒçš„è¿‡ç¨‹è€Œé€æ¸å‡å°ï¼Œæ¯ä¸ªlosséƒ½ä¼šè‡ªå·±çš„scheduleã€‚è¿™äº›lossåŠ å¿«äº†æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶ä¹Ÿæå‡äº†è¡¨ç°ã€‚</p>
<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><h4 id="Multiple-Positions"><a href="#Multiple-Positions" class="headerlink" title="Multiple Positions"></a>Multiple Positions</h4><p>å¯¹äºbatchå†…è€Œè¨€ï¼Œæ¯ä¸ªæ—¶é—´æ­¥téƒ½è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚<br><img src="/images/2018-11-04-15412916429104.jpg" width="90%" height="50%"></p>
<h4 id="Intermediate-Layer-Losses"><a href="#Intermediate-Layer-Losses" class="headerlink" title="Intermediate Layer Losses"></a>Intermediate Layer Losses</h4><p>è¦æ±‚ä¸­é—´å±‚ä¹Ÿåšå‡ºé¢„æµ‹ï¼š<br><img src="/images/2018-11-04-15412916704097.jpg" width="95%" height="50%"></p>
<p>åœ¨è¿™é‡Œï¼Œè¶Šåº•å±‚çš„layerå…¶lossæƒå€¼è¶Šä½ã€‚</p>
<h4 id="Multiple-Targets"><a href="#Multiple-Targets" class="headerlink" title="Multiple Targets"></a>Multiple Targets</h4><p>æ¯ä¸€ä¸ªpositionï¼Œä¸ä»…ä»…è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿˜è¦é¢„æµ‹ä¸‹å‡ ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å’Œé¢„æµ‹ä¸‹å‡ ä¸ªè¯çš„åˆ†ç±»å™¨æ˜¯ç‹¬ç«‹çš„ã€‚</p>
<p><img src="/images/2018-11-04-15412917374689.jpg" width="70%" height="50%"></p>
<h3 id="Positional-embedding"><a href="#Positional-embedding" class="headerlink" title="Positional embedding"></a>Positional embedding</h3><p>æ¯ä¸€å±‚çš„éƒ½æ·»åŠ ä¸€ä¸ªä¸å…±äº«çš„å¯å­¦ä¹ çš„positional embeddingã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations"><a href="#2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations" class="headerlink" title="2ï¸âƒ£[Self-Attention with Relative Position Representations]"></a>2ï¸âƒ£[Self-Attention with Relative Position Representations]</h2><p>æå‡ºä½¿ç”¨ç›¸å¯¹ä½ç½®æ›¿ä»£Transformerçš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¹¶åœ¨NMTä¸Šæœ‰ä¸€å®šçš„æå‡ã€‚</p>
<p>åˆ†è§£ï¼š<br>åœ¨åŸå…ˆçš„self-attentionä¸­ï¼Œè¾“å‡ºä¸ºï¼š<br><img src="/images/2018-11-04-15412923510664.jpg" width="25%" height="50%"></p>
<p>å…¶ä¸­ï¼š<br><img src="/images/2018-11-04-15412923744647.jpg" width="25%" height="50%"><br><img src="/images/2018-11-04-15412923773686.jpg" width="25%" height="50%"></p>
<p>ç°åœ¨æˆ‘ä»¬è€ƒè™‘æ·»åŠ ç›¸å¯¹ä½ç½®ï¼Œå…¶ä¸­ç›¸å¯¹ä½ç½®ä¿¡æ¯åœ¨å„å±‚éƒ½æ˜¯å…±äº«çš„ï¼š<br><img src="/images/2018-11-04-15412924279426.jpg" width="30%" height="50%"><br><img src="/images/2018-11-04-15412924396468.jpg" width="30%" height="50%"></p>
<p>$a_{ij}^K$çš„å…·ä½“å½¢å¼ï¼š<br><img src="/images/2018-11-04-15412925792994.jpg" width="40%" height="50%"><br><img src="/images/2018-11-04-15412925910424.jpg" width="55%" height="50%"><br>ä¸Šå¼ä¸ºäº†é™ä½å¤æ‚åº¦ï¼Œä¸è€ƒè™‘é•¿äºkçš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p>
<p>è€ƒè™‘åˆ°transformerçš„å¹¶è¡Œæ€§ï¼Œä¸ºäº†å¹¶è¡Œæ€§ï¼Œæˆ‘ä»¬è€ƒè™‘å¦‚ä¸‹å¼å­ï¼š<br><img src="/images/2018-11-04-15412926687951.jpg" width="50%" height="50%"><br>å…¶ä¸­ï¼Œç¬¬ä¸€é¡¹å’ŒåŸæ¥çš„Transformerä¸€è‡´ï¼›ç¬¬äºŒé¡¹ï¼Œé€šè¿‡reshapeå¯ä»¥è¾¾åˆ°å¹¶è¡Œçš„æ•ˆæœï¼Œç„¶åä¸¤é¡¹ç›´æ¥åŠ èµ·æ¥ã€‚</p>
<p>å®éªŒè¯æ˜ï¼Œä½¿ç”¨ç›¸å¯¹ä½ç½®æ•ˆæœæ˜¯æœ‰ä¸€å®šçš„æå‡çš„ï¼Œè€ŒåŒæ—¶ä½¿ç”¨ç»å¯¹ä½ç½®å’Œç›¸å¯¹ä½ç½®å¹¶æ²¡æœ‰æå‡ã€‚<br><img src="/images/2018-11-04-15412930642978.jpg" width="90%" height="50%"></p>
<hr>
<h2 id="3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION"><a href="#3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION" class="headerlink" title="3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]"></a>3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]</h2><p>è¿™ç¯‡è¢«ICLRæ‹’äº†ï¼Œä½†æœ‰å®¡ç¨¿äººæ‰“äº†9åˆ†çš„é«˜åˆ†ã€‚</p>
<p>å¯¹Transformerè¿›è¡Œæ”¹è¿›ï¼Œæ‹¥æœ‰æ›´å¥½çš„æ•ˆæœå’Œæ›´å°çš„è®¡ç®—ä»£ä»·ã€‚</p>
<p>ä¼ ç»Ÿçš„Transformerï¼š</p>
<script type="math/tex; mode=display">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V</script><script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">MultiHead(Q,K,V)=Concat_i (head_i)W^O</script><script type="math/tex; mode=display">FFN(x)=max(0,xW_1+b_1)W_2 + b_2</script><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå…ˆå¯¹headè¿›è¡Œå‡ç»´å¹¶ä¹˜ä»¥æƒé‡ï¼Œè¿‡äº†FNNåï¼Œå†ä¹˜ä»¥å¦ä¸€ä¸ªæƒé‡ã€‚å…¶ä¸­æƒé‡$\alpha$ $ \kappa$ä¸ºå¯å­¦ä¹ å‚æ•°ï¼š</p>
<script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">\overline{head_i}=head_i W^{O_i} \times \kappa_i</script><script type="math/tex; mode=display">BranchedAttention(Q,K,V)=\sum_{i=1}^{M} \alpha_i FFN(\overline{head}_i)</script><p>å…¶ä¸­è¦æ±‚æƒé‡ä¹‹å’Œä¸º1ã€‚å³$\sum_{i=1}^{M}\alpha_i=1$,$\sum_{i=1}^{M}\kappa_i=1$ã€‚</p>
<p><img src="/images/2018-11-04-15412939412047.jpg" width="90%" height="50%"></p>
<p>æ–‡ä¸­å¯¹$\kappa$å’Œ$\alpha$ä½œäº†è§£é‡Šã€‚</p>
<blockquote>
<p>Îº can be interpreted as a learned concatenation weight and Î± as the learned addition weight</p>
</blockquote>
<p>é€šè¿‡å®éªŒï¼Œå‘ç°è¯¥æ¨¡å‹ä¼šæœ‰æ›´å¥½çš„æ­£åˆ™åŒ–ç‰¹æ€§ã€‚åŒæ—¶æ•ˆæœä¹Ÿæœ‰ä¸€å®šæå‡ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼š<br><img src="/images/2018-11-04-15412940966579.jpg" width="80%" height="50%"></p>
<hr>
<h2 id="4ï¸âƒ£-You-May-Not-Need-Attention"><a href="#4ï¸âƒ£-You-May-Not-Need-Attention" class="headerlink" title="4ï¸âƒ£[You May Not Need Attention]"></a>4ï¸âƒ£[You May Not Need Attention]</h2><p>ç²—ç•¥åœ°è¿‡äº†ä¸€éï¼Œä¸€äº›ç»†èŠ‚æ²¡æœ‰å¼„æ˜ç™½ã€‚</p>
<p>æå‡ºä¸€ç§å°†encoder-decoderèåˆèµ·æ¥çš„æ¨¡å‹ï¼Œä¹Ÿå³eager translation modelï¼Œä¸éœ€è¦attentionï¼Œèƒ½å¤Ÿå®ç°å³æ—¶çš„ç¿»è¯‘ï¼Œä¹Ÿå³è¯»å…¥ä¸€ä¸ªè¯å°±èƒ½ç¿»è¯‘ä¸€ä¸ªè¯ï¼ŒåŒæ—¶ä¸éœ€è¦è®°å½•encoderçš„æ‰€æœ‰è¾“å‡ºï¼Œå› æ­¤éœ€è¦å¾ˆå°‘çš„å†…å­˜ã€‚</p>
<p><img src="/images/2018-11-04-15412942175720.jpg" width="50%" height="50%"></p>
<p>åˆ†ä¸ºä¸‰æ­¥ï¼š<br>â‘ pre-processing<br>è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿å¾—æºå¥å­å’Œç›®æ ‡å¥å­æ»¡è¶³<strong>eager feasible</strong> for every aligned pair of words $(s_i , t_j ), i â‰¤ j$ã€‚</p>
<p>é¦–å…ˆé€šè¿‡ç°æˆçš„å·¥å…·è¿›è¡Œå¯¹é½æ“ä½œ(alignment)ï¼Œç„¶åå¯¹äºé‚£äº›ä¸ç¬¦åˆeager feasibleçš„æœ‰å…·ä½“ç®—æ³•ï¼ˆæ²¡è®¤çœŸçœ‹ï¼‰è¿›è¡Œè¡¥paddingã€‚å¦‚å›¾<br><img src="/images/2018-11-04-15412945231042.jpg" width="60%" height="50%"></p>
<p>æˆ‘ä»¬è¿˜å¯ä»¥åœ¨target sentenceçš„å¼€å¤´æ·»åŠ bä¸ªpaddingï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¼€å§‹é¢„æµ‹ä¹‹å‰è·å–æ›´å¤šçš„source sentenceçš„è¯ã€‚</p>
<p>â‘¡æ¨¡å‹<br>ä¸¤å±‚çš„LSTMï¼Œè¾“å…¥æ˜¯ä¸Šä¸€æ¬¡çš„yå’Œå½“å‰çš„xæ‹¼æ¥èµ·æ¥ç›´æ¥ä¼ è¿›å»ã€‚</p>
<p>â‘¢post processing<br>åœ¨æœ€ç»ˆç»“æœä¹‹å‰ï¼Œå°†paddingå»æ‰ã€‚</p>
<p>åœ¨inferenceï¼ˆä¹Ÿå³beam searchï¼‰æ—¶ï¼Œè¿˜æœ‰å‡ ä¸ªæ“ä½œ/trickï¼š</p>
<ul>
<li>Padding limit</li>
<li>Source padding injection SPI</li>
</ul>
<p>å®éªŒè¡¨æ˜ï¼Œeager modelåœ¨é•¿çš„å¥å­è¡¨ç°è¶…è¿‡ä¼ ç»Ÿå¸¦attentionçš„NMTï¼Œè€Œé•¿å¥å­çš„å»ºæ¨¡æ­£æ˜¯attention-based çš„æ¨¡å‹çš„ä¸€å¤§æŒ‘æˆ˜ï¼›è€Œåœ¨çŸ­å¥å­ä¸Šå°±ä¸å¦‚attention-basedçš„NMTã€‚<br><img src="/images/2018-11-04-15412946442983.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>NMT</tag>
        <tag>Language Modeling</tag>
        <tag>self-attention</tag>
        <tag>relative position</tag>
        <tag>positional encoding</tag>
        <tag>eager translation model</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯14</title>
    <url>/2018/11/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D14/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£é¹¤å†²å¤©"><a href="#1ï¸âƒ£é¹¤å†²å¤©" class="headerlink" title="1ï¸âƒ£é¹¤å†²å¤©"></a>1ï¸âƒ£é¹¤å†²å¤©</h3><p>[å®‹] æŸ³æ°¸<br>é»„é‡‘æ¦œä¸Šï¼Œå¶å¤±é¾™å¤´æœ›ã€‚æ˜ä»£æš‚é—è´¤ï¼Œå¦‚ä½•å‘ï¼Ÿæœªé‚é£äº‘ä¾¿ï¼Œäº‰ä¸æ£æ¸¸ç‹‚è¡ã€‚ä½•é¡»è®ºå¾—ä¸§ï¼Ÿæ‰å­è¯äººï¼Œè‡ªæ˜¯ç™½è¡£å¿ç›¸ã€‚<br>çƒŸèŠ±å··é™Œï¼Œä¾çº¦ä¸¹é‘å±›éšœã€‚å¹¸æœ‰æ„ä¸­äººï¼Œå ªå¯»è®¿ã€‚ä¸”æåçº¢å€šç¿ ï¼Œé£æµäº‹ï¼Œå¹³ç”Ÿç•…ã€‚é‘æ˜¥éƒ½ä¸€é¥·ã€‚<strong>å¿æŠŠæµ®åï¼Œæ¢äº†æµ…æ–Ÿä½å”±</strong>ï¼</p>
<p>æ£ï¼ˆzÃ¬ï¼‰ï¼šæ”¾çºµï¼Œéšå¿ƒæ‰€æ¬²ã€‚<br>æï¼ˆnÃ¨nï¼‰ï¼šå¦‚æ­¤ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•9</title>
    <url>/2018/11/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%959/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-collate-fn"><a href="#1ï¸âƒ£-collate-fn" class="headerlink" title="1ï¸âƒ£[collate_fn]"></a>1ï¸âƒ£[collate_fn]</h3><p>å°†ä¸ç­‰é•¿å¥å­ç»„åˆæˆbatchã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(insts)</span>:</span></span><br><span class="line">    <span class="string">''' Pad the instance to the max seq length in batch '''</span></span><br><span class="line"></span><br><span class="line">    max_len = max(len(inst) <span class="keyword">for</span> inst <span class="keyword">in</span> insts)</span><br><span class="line"></span><br><span class="line">    batch_seq = np.array([</span><br><span class="line">        inst + [Constants.PAD] * (max_len - len(inst))</span><br><span class="line">        <span class="keyword">for</span> inst <span class="keyword">in</span> insts])</span><br><span class="line"></span><br><span class="line">    batch_pos = np.array([</span><br><span class="line">        [pos_i + <span class="number">1</span> <span class="keyword">if</span> w_i != Constants.PAD <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">         <span class="keyword">for</span> pos_i, w_i <span class="keyword">in</span> enumerate(inst)] <span class="keyword">for</span> inst <span class="keyword">in</span> batch_seq]) <span class="comment"># ä½ç½®ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line">    batch_seq = torch.LongTensor(batch_seq)</span><br><span class="line">    batch_pos = torch.LongTensor(batch_pos)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_seq, batch_pos</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>â€œè±æ–¯æ¯â€æŒ‘æˆ˜èµ›æœ‰æ„Ÿ</title>
    <url>/2018/10/30/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E2%80%9C%E8%8E%B1%E6%96%AF%E6%9D%AF%E2%80%9D%E6%8C%91%E6%88%98%E8%B5%9B%E6%9C%89%E6%84%9F/</url>
    <content><![CDATA[<p>å†æ—¶ä¸‰ä¸ªæœˆçš„â€œè±æ–¯æ¯â€å…¨å›½ç¬¬ä¸€å±Šâ€œå†›äº‹æ™ºèƒ½Â·æœºå™¨é˜…è¯»â€æŒ‘æˆ˜èµ›ç»ˆäºè½ä¸‹å¸·å¹•ï¼Œå‰å‡ æ—¥ï¼ˆ10.26-10.28ï¼‰æœ‰å¹¸åœ¨å—äº¬é’æ—…å®¾é¦†å‚ä¸å†³èµ›ï¼Œä½“éªŒå¤šå¤šï¼Œæ”¶è·æ»¡æ»¡ï¼Œå¿ƒä¸­äº¦æœ‰ä¸€äº›æ„Ÿæƒ³ã€‚</p>
<p>ä¸€ä¸ªæ˜¯å—äº¬æ€»å¸¦ç»™æˆ‘ä¸€ç§å›å®¶çš„æ„Ÿè§‰ï¼Œå¯¹å—äº¬çš„äº‹ç‰©æ€»æœ‰äº²åˆ‡æ„Ÿã€‚ç¬¬ä¸€æ¬¡æ¥å—äº¬æ˜¯ä¸€å¹´åŠå‰ï¼Œä¹Ÿæ˜¯æ¥å‚åŠ æ¯”èµ›ã€‚å‘¨äº”æ™šä¸Šçš„å¤œæ¸¸ç§¦æ·®ï¼Œè®©æˆ‘æ„Ÿå—åˆ°è®¸ä¹…æœªæ›¾æ„Ÿå—åˆ°çš„çƒŸç«æ°”æ¯ã€‚</p>
<p><img src="/images/2018-10-30-511540860855_.pic_hd.jpg" width="90%" height="50%"></p>
<p>ç¬¬äºŒä¸ªæ˜¯æ­¤æ¬¡ä¸»åŠæ–¹æä¾›çš„é£Ÿå®¿ä»¤äººæƒŠå–œã€‚ä¸€å¼€å§‹å¬åˆ°é’æ—…å®¾é¦†ï¼Œæˆ‘å·²ç»åšå¥½äº†è‰°è‹¦å¥‹æˆ˜çš„å‡†å¤‡äº†ï¼Œç„¶è€Œé…’åº—æ˜¯æ˜Ÿçº§é…’åº—çš„ï¼Œåƒæ–¹é¢ç›´æ¥åˆ°æ¥¼ä¸‹çš„è‡ªåŠ©ã€‚å¯ä»¥çœ‹å‡ºä¸»åŠæ–¹æ­¤æ¬¡ç¡®å®ç”¨å¿ƒåœ¨ä¸¾åŠè¿™æ¬¡æ¯”èµ›ã€‚</p>
<p><img src="/images/2018-10-30-15408644190676.jpg" width="100%" height="50%"></p>
<p>ç¬¬ä¸‰ç‚¹æ˜¯å…³äºæ¯”èµ›çš„ï¼Œå…³äºæ¯”èµ›çš„æ•´ä¸ªå†ç¨‹æˆ‘è¿˜æ˜¯é¢‡æœ‰æ„Ÿè§¦ã€‚<br>æˆ‘ä»¬æ˜¯ä»¥ç¬¬9åçš„æˆç»©æŒºè¿›å†³èµ›ï¼Œå…¶å®åœ¨åæœŸæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬éƒ½æœ‰æ‰€æ‡ˆæ€ äº†ï¼Œå‡ ä¹æ²¡æœ‰èŠ±æ—¶é—´åœ¨è¿™ä¸Šé¢ï¼Œ10æœˆåˆå‘å¸ƒå†³èµ›çš„æ•°æ®é›†ï¼Œè€Œæˆ‘ä»¬åœ¨10æœˆ20æ—¥æ‰å¾—çŸ¥è¿™ä¸€äº‹æƒ…ï¼Œæ­¤æ—¶ç¦»å†³èµ›åªå‰©ä¸€å‘¨æ—¶é—´ã€‚å› æ­¤æˆ‘ä»¬ç¡®å®å‡†å¤‡ä¸è¶³ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿæ²¡æœ‰é¢„æ–™åˆ°æˆ‘ä»¬çš„å†³èµ›æˆç»©ä¼šè¿™ä¹ˆé å‰ï¼Œå¦åˆ™æˆ‘ä»¬è‚¯å®šä¼šæ›´åŠ å……åˆ†å»å‡†å¤‡ã€‚è¿™ç¡®å®æ˜¯æˆ‘ä»¬çš„å¤±è¯¯ã€‚</p>
<p>æˆ‘ä»¬åœ¨æ¯”èµ›è¿‡ç¨‹ä¸­ï¼Œä¸€ç›´å°è¯•åœ¨ä½¿ç”¨ELMoï¼Œè¿™æ­£æ˜¯æˆ‘è´Ÿè´£çš„éƒ¨åˆ†ã€‚ä¸€å¼€å§‹ä½¿ç”¨å®˜æ–¹TensorFlowçš„ä»£ç ï¼Œè´¹äº†ä¹ç‰›äºŒè™ä¹‹åŠ›æˆ‘æ‰è·‘é€šä»£ç ï¼Œä½†å› ä¸ºé˜Ÿé•¿ä½¿ç”¨çš„æ˜¯pytorchï¼Œè€ŒäºŒè€…åœ¨cudaç‰ˆæœ¬ä¸Šä¸å…¼å®¹ï¼Œå› æ­¤åœ¨åˆèµ›æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ELMoã€‚è€Œåœ¨æœ€åå‡ å¤©ï¼Œæˆ‘å°è¯•ä½¿ç”¨å“ˆå·¥å¤§çš„pytorchè®­ç»ƒä»£ç ï¼Œä½†å› ä¸ºinferenceé€Ÿåº¦å®åœ¨å¤ªæ…¢ï¼Œæˆ‘ä»¬æœ€ç»ˆè¿˜æ˜¯å¼ƒç”¨äº†è¿™ä¸ªæ–¹æ¡ˆã€‚è€Œåœ¨å†³èµ›ç°åœºï¼Œæˆ‘ä»¬å‘ç°ä¹Ÿç¡®å®æ˜¯å› ä¸ºé€Ÿåº¦å’Œèµ„æºçš„åŸå› ï¼Œå¤§å®¶éƒ½æ²¡æœ‰ä½¿ç”¨ELMoï¼Œé™¤äº†ä¸€ç»„ã€‚è¯¥ç»„æ­£æ˜¯å‡­å€Ÿäº†ELMoå¼¯é“è¶…è½¦ä»ç¬¬7å‡åˆ°äº†ç¬¬ä¸€ï¼Œæ‹¿èµ°äº†20ä¸‡å¤§å¥–ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬éå¸¸é—æ†¾çš„ä¸€ä¸ªåœ°æ–¹ï¼Œæˆ‘ä»¬åœ¨é‡åˆ°å›°éš¾æ—¶æ²¡æœ‰å°è¯•è§£å†³ï¼Œè€Œæ˜¯ç›´æ¥å¼ƒç”¨ï¼Œæœ€ç»ˆæ²¡æœ‰å–å¾—æ›´å¥½çš„æˆç»©ã€‚</p>
<p>æ­¤æ¬¡æˆ‘ä»¬çš„æˆç»©æ’åç¬¬4(ä¸‰ç­‰å¥–)ï¼Œæ˜¯æœ‰ä¸€å®šçš„è¿›æ­¥çš„ï¼Œä½†æœ‰ä¸€ç‚¹é—æ†¾çš„æ˜¯ï¼Œæˆ‘ä»¬ä»…å·®0.18ç™¾åˆ†ç‚¹ï¼Œå°±èƒ½è¶…è¿‡ç¬¬ä¸‰åæ‹¿åˆ°5ä¸‡çš„å¥–é‡‘äº†ã€‚åé¢æˆ‘ä»¬åˆ†æäº†ä¸€ä¸‹ï¼Œè¿˜æ˜¯å› ä¸ºæˆ‘ä»¬å¯¹æ¯”èµ›æ‡ˆæ€ çš„æ€åº¦ï¼Œå…¶ä»–ç»„éƒ½å¯¹æ•°æ®è¿›è¡Œäº†åˆ†æå¹¶æœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ï¼Œè€Œæˆ‘ä»¬å¹¶æ²¡æœ‰åšè¿™ä¸€æ­¥ã€‚</p>
<p>Anywayï¼Œç¬¬ä¸€æ¬¡ç»„é˜Ÿå‚åŠ æ¯”èµ›å°±æœ‰æ”¶è·ï¼Œå¢é•¿äº†è§è¯†ï¼Œä»äº¤æµä¸­ä¹Ÿè·å¾—äº†è®¸å¤šã€‚è¿™ä¸ªæ¯”èµ›ä¹‹åï¼Œå°±å¾—å¥½å¥½çœ‹paperäº†ã€‚ __(:Ğ·ã€âˆ )_</p>
<p><img src="/images/2018-10-30-521540861008_.pic_hd.jpg" width="80%" height="50%"></p>
]]></content>
      <tags>
        <tag>æœ‰æ„Ÿ</tag>
        <tag>è±æ–¯æ¯</tag>
        <tag>æ¯”èµ›</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯13</title>
    <url>/2018/10/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D13/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"><a href="#1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–" class="headerlink" title="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"></a>1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–</h3><p>[å”] æç™½<br>ã€å…¶ä¸€ã€‘<br>é‡‘æ¨½æ¸…é…’æ–—ååƒï¼Œç‰ç›˜çç¾ç›´ä¸‡é’±ã€‚<br><strong>åœæ¯æŠ•ç®¸ä¸èƒ½é£Ÿï¼Œæ‹”å‰‘å››é¡¾å¿ƒèŒ«ç„¶</strong>ã€‚<br>æ¬²æ¸¡é»„æ²³å†°å¡å·ï¼Œå°†ç™»å¤ªè¡Œé›ªæ»¡å±±ã€‚<br>é—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚<br>è¡Œè·¯éš¾ï¼Œè¡Œè·¯éš¾ï¼Œå¤šæ­§è·¯ï¼Œä»Šå®‰åœ¨ï¼Ÿ<br><strong>é•¿é£ç ´æµªä¼šæœ‰æ—¶ï¼Œç›´æŒ‚äº‘å¸†æµæ²§æµ·</strong>ï¼</p>
<p><strong>æ³¨é‡Š</strong>ï¼š<br>ã€Œé—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚ã€å¥ï¼šæš—ç”¨å…¸æ•…ï¼šå§œå¤ªå…¬å•å°šæ›¾åœ¨æ¸­æ°´çš„ç£»æºªä¸Šé’“é±¼ï¼Œå¾—é‡å‘¨æ–‡ç‹ï¼ŒåŠ©å‘¨ç­å•†ï¼›ä¼Šå°¹æ›¾æ¢¦è§è‡ªå·±ä¹˜èˆ¹ä»æ—¥æœˆæ—è¾¹ç»è¿‡ï¼Œåè¢«å•†æ±¤è˜è¯·ï¼ŒåŠ©å•†ç­å¤ã€‚è¿™ä¸¤å¥è¡¨ç¤ºè¯—äººè‡ªå·±å¯¹ä»æ”¿ä»æœ‰æ‰€æœŸå¾…ã€‚ç¢§ï¼Œä¸€ä½œã€Œåã€ã€‚</p>
<hr>
<h3 id="2ï¸âƒ£ç™»ç§‘å"><a href="#2ï¸âƒ£ç™»ç§‘å" class="headerlink" title="2ï¸âƒ£ç™»ç§‘å"></a>2ï¸âƒ£ç™»ç§‘å</h3><p>[å”] å­ŸéƒŠ<br>æ˜”æ—¥é¾Œé¾Šä¸è¶³å¤¸ï¼Œä»Šæœæ”¾è¡æ€æ— æ¶¯ã€‚<br><strong>æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±</strong>ã€‚</p>
<p><strong>æ³¨é‡Š</strong>ï¼š<br>é¾Œé¾Šï¼ˆwÃ² chuÃ²ï¼‰ï¼šåŸæ„æ˜¯è‚®è„ï¼Œè¿™é‡ŒæŒ‡ä¸å¦‚æ„çš„å¤„å¢ƒã€‚ä¸è¶³å¤¸ï¼šä¸å€¼å¾—æèµ·ã€‚<br>æ”¾è¡ï¼ˆdÃ ngï¼‰ï¼šè‡ªç”±è‡ªåœ¨ï¼Œä¸å—çº¦æŸã€‚<br>æ€æ— æ¶¯ï¼šå…´è‡´é«˜æ¶¨ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡3</title>
    <url>/2018/10/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%873/</url>
    <content><![CDATA[<h2 id="1ï¸âƒ£-A-Neural-Probabilistic-Language-Model"><a href="#1ï¸âƒ£-A-Neural-Probabilistic-Language-Model" class="headerlink" title="1ï¸âƒ£[A Neural Probabilistic Language Model]"></a>1ï¸âƒ£[A Neural Probabilistic Language Model]</h2><p>ç¬¬ä¸€ç¯‡ä½¿ç”¨ç¥ç»ç½‘ç»œè·å¾—è¯å‘é‡çš„paperã€‚</p>
<p>é€šè¿‡å¯¹language modelå»ºæ¨¡ï¼Œå°†è¯æ˜ å°„åˆ°ä½ç»´è¡¨ç¤ºï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶è®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥åŠæ¯ä¸ªè¯çš„è¯å‘é‡ã€‚</p>
<p><img src="/images/2018-10-29-15407808716787.jpg" width="50%" height="50%"></p>
<p>å°†ä¸­å¿ƒè¯çš„å‰nä¸ªæ‹¼æ¥èµ·æ¥ $x=(C(w_{t-1},C(w_{t-2}),â€¦,C(w_{t-n+1}))$<br>å°†$x$é€å…¥ç¥ç»ç½‘ç»œä¸­è·å¾—$y=b+Wx+Utanh(d+Hx)$ï¼Œæœ€ååšä¸€ä¸ªsoftmaxå³å¯ã€‚</p>
<hr>
<h2 id="2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks"><a href="#2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks" class="headerlink" title="2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]"></a>2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]</h2><p>ä¸€ç§å…è®¸RNNåŠ¨æ€å †å å±‚æ•°çš„ç®—æ³•ã€‚</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>è¯æ®è¯æ˜ï¼ŒRNNçš„å †å å±‚æ•°å¤šï¼Œæ•ˆæœä¼šæœ‰æå‡ã€‚ä½†æ˜¯ï¼Œå¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œè¦æ±‚ä¸åŒçš„è®¡ç®—å¤æ‚åº¦ã€‚æˆ‘ä»¬éœ€è¦å…ˆéªŒæ¥å†³å®šç‰¹å®šä»»åŠ¡çš„è®¡ç®—å¤æ‚åº¦ã€‚å½“ç„¶æˆ‘ä»¬å¯ä»¥ç²—æš´åœ°ç›´æ¥å †å æ·±å±‚çš„ç½‘ç»œã€‚ACT(Adaptive Computation Time)èƒ½å¤ŸåŠ¨æ€å†³å®šæ¯ä¸ªè¾“å…¥tæ‰€éœ€çš„è®¡ç®—æ¬¡æ•°ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å°†RNNæ¯ä¸€æ­¥çš„è¾“å‡ºè¿‡ä¸€ä¸ªç½‘ç»œ+sigmoidå±‚ï¼Œè·å¾—ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå³ä»€ä¹ˆæ—¶å€™åº”å½“åœæ­¢ä¸å†ç»§ç»­å¾€ä¸Šå †å ï¼Œç›´åˆ°æ¦‚ç‡åŠ å’Œä¸º1ã€‚åŒæ—¶ä¸ºäº†å°½å¯èƒ½æŠ‘åˆ¶å±‚æ•°çš„æ— é™å¢é•¿ï¼Œåœ¨lossæ·»åŠ ä¸€é¡¹æƒ©ç½šã€‚</p>
<h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p>å¯¹äºæ™®é€šçš„RNNï¼š<br><img src="/images/2018-10-29-15408103221289.jpg" width="30%" height="50%"></p>
<p>sæ˜¯éšè—å±‚ï¼›yæ˜¯è¾“å‡ºã€‚</p>
<p>å¯¹äºACTçš„RNNï¼Œæœ‰ï¼š<br><img src="/images/2018-10-29-15408103823681.jpg" width="40%" height="50%"></p>
<p>ä¸Šæ ‡næ˜¯æŒ‡çš„tæ—¶åˆ»çš„å±‚æ•°ï¼›å…¶ä¸­ï¼š<br><img src="/images/2018-10-29-15408104201718.jpg" width="20%" height="50%"></p>
<p>$Î´$æ˜¯flatï¼ŒæŒ‡ç¤ºxæ˜¯ç¬¬å‡ æ¬¡è¾“å…¥ã€‚</p>
<p>å¼•å…¥æ–°çš„ç½‘ç»œï¼Œè¾“å…¥æ—¶éšçŠ¶æ€ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼š<br><img src="/images/2018-10-29-15408105451770.jpg" width="30%" height="50%"></p>
<p>é‚£ä¹ˆæ¯ä¸€å±‚çš„æ¦‚ç‡æ˜¯ï¼š<br><img src="/images/2018-10-29-15408105687677.jpg" width="35%" height="50%"></p>
<p>å…¶ä¸­$R(t)$æ˜¯åœ¨æ¯ä¸€å±‚æ¦‚ç‡æ±‚å’Œè¶…è¿‡1æ—¶çš„å‰©ä½™æ¦‚ç‡ï¼ˆä¸ºäº†ä¿è¯æ¦‚ç‡å’Œä¸º1ï¼Œå¯ä»¥è¯•ç€ä¸¾ä¸€ä¸ªä¾‹å­æ¥è¯æ˜ï¼‰<br><img src="/images/2018-10-29-15408106099743.jpg" width="45%" height="50%"></p>
<p><img src="/images/2018-10-29-15408106125837.jpg" width="25%" height="50%"></p>
<p>Îµæ˜¯ä¸ºäº†è§£å†³ç¬¬ä¸€æ¬¡è¾“å‡ºæ—¶å°±è¶…è¿‡1-Îµçš„æƒ…å†µï¼ŒÎµä¸€èˆ¬å–å¾ˆå°ã€‚</p>
<p>æœ€ç»ˆï¼ŒåŠ æƒæ±‚å’Œï¼Œä½œä¸ºæœ€ç»ˆçš„ç»“æœï¼Œä¼ å…¥ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼š<br><img src="/images/2018-10-29-15408106649319.jpg" width="45%" height="50%"></p>
<p>æ™®é€šRNNä¸ACTçš„RNNå¯¹æ¯”ï¼š<br><img src="/images/2018-10-29-15408106950342.jpg" width="90%" height="50%"></p>
<h4 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h4><p>ä¸ºäº†é˜²æ­¢æ¨¡å‹å±‚æ•°æ— é™å¢é•¿ï¼Œæ·»åŠ ä¸€é¡¹æƒ©ç½šé¡¹ä»¥æŠ‘åˆ¶ã€‚</p>
<p>è®°æ¯ä¸€æ­¥çš„æƒ©ç½šé¡¹ä¸ºï¼š<br><img src="/images/2018-10-29-15408107184035.jpg" width="23%" height="50%"></p>
<p>æ€»çš„æƒ©ç½šé¡¹åˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408107351871.jpg" width="19%" height="50%"></p>
<p>Loss functionåˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408108024183.jpg" width="35%" height="50%"></p>
<p>å› ä¸ºN(t)æ˜¯ä¸å¯å¯¼çš„ï¼Œæˆ‘ä»¬åœ¨å®é™…è¿‡ç¨‹ä¸­åªå»æœ€å°åŒ–R(t)  ï¼ˆ<del>æˆ‘è§‰å¾—ä¸ç”šåˆç†</del>ï¼Œä¸€ç§è§£è¯»æ˜¯å¦‚æœæˆ‘ä»¬ä¸æ–­æœ€å°åŒ–R(t)ç›´åˆ°å˜æˆ0ï¼Œé‚£ä¹ˆç›¸å½“äºN(t)å°‘äº†ä¸€å±‚ï¼Œæ¥ç€R(t)å°±ä¼šå˜å¾—å¾ˆå¤§ï¼Œç„¶ååˆç»§ç»­æœ€å°åŒ–R(t)â€¦ï¼‰</p>
<hr>
<h2 id="3ï¸âƒ£-Universal-Transformers"><a href="#3ï¸âƒ£-Universal-Transformers" class="headerlink" title="3ï¸âƒ£[Universal Transformers]"></a>3ï¸âƒ£[Universal Transformers]</h2><p>æå‡ºä¸€ç§æ–°å‹é€šç”¨çš„transformerã€‚</p>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>Transformerçš„é—®é¢˜ï¼šRNNçš„å½’çº³åç½®(inductive bias)åœ¨ä¸€äº›ä»»åŠ¡ä¸Šå¾ˆé‡è¦ï¼Œä¹Ÿå³RNNçš„å¾ªç¯å­¦ä¹ çš„è¿‡ç¨‹ï¼›Transformeråœ¨ä¸€äº›é—®é¢˜ä¸Šè¡¨ç°ä¸å¥½ï¼Œå¯èƒ½æ˜¯å½’çº³åç½®çš„åŸå› ã€‚</p>
<blockquote>
<p>Notably, however, the Transformer foregoes the RNNâ€™s inductive bias towards learning iterative or recursive transformations.Our experiments indicate that this inductive bias may be crucial for several algorithmic and language understanding tasks of varying complexity: in contrast to models such as the Neural Turing Machine [13], the Neural GPU [17] or Stack RNNs [16], the Transformer does not generalize well to input lengths not encountered during training.</p>
</blockquote>
<p>å› æ­¤åœ¨Transformerå†…å¼•å…¥å½’çº³åç½®</p>
<h3 id="ç‰¹ç‚¹"><a href="#ç‰¹ç‚¹" class="headerlink" title="ç‰¹ç‚¹"></a>ç‰¹ç‚¹</h3><ul>
<li>æ¯ä¸€å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³multi-headä¸Šçš„æƒé‡ä»¥åŠtransition functionåœ¨æ¯ä¸€å±‚æ˜¯ä¸€è‡´çš„ã€‚è¿™ä¸€ç‚¹å’ŒRNNã€CNNä¸€è‡´ã€‚</li>
<li>åŠ¨æ€å±‚æ•°ï¼ˆACT mechanism ï¼‰ï¼šå¯¹äºæ¯ä¸ªè¯éƒ½ä¼šæœ‰ä¸åŒçš„å¾ªç¯æ¬¡æ•°ï¼›ä¹Ÿå³æœ‰äº›è¯éœ€è¦æ›´å¤šçš„refineï¼›è€Œæœ‰äº›è¯ä¸éœ€è¦ã€‚å’Œå›ºå®šå±‚æ•°çš„transformerç›¸æ¯”ï¼Œä¼šæœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li>
</ul>
<h3 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><h4 id="æ€»ä½“æ¶æ„"><a href="#æ€»ä½“æ¶æ„" class="headerlink" title="æ€»ä½“æ¶æ„"></a>æ€»ä½“æ¶æ„</h4><p><img src="/images/2018-10-29-15408125098915.jpg" width="90%" height="50%"></p>
<p>è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-29-15408125469899.jpg" width="45%" height="50%"></p>
<p><img src="/images/2018-10-29-15408125685038.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-10-29-15408125974795.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-10-29-15408126143943.jpg" width="60%" height="50%"></p>
<p>å’Œæ™®é€šTransformerä¸åŒçš„åœ°æ–¹åœ¨äºï¼š</p>
<ul>
<li>åŠ äº†ä¸€å±‚Transitionå±‚ï¼ŒTransitionå¯ä»¥æ˜¯depth-wise separable convolutionï¼ˆ<a href="https://www.cnblogs.com/adong7639/p/7918527.html" target="_blank" rel="noopener">æ˜¯ä»€ä¹ˆï¼Ÿ</a>ï¼‰æˆ–è€…å…¨è¿æ¥å±‚ã€‚</li>
<li>æ¯å±‚éƒ½æ·»åŠ äº†position embeddingï¼›ä»¥åŠtimestep embeddingï¼Œç”¨ä»¥æŒ‡ç¤ºå±‚æ•°ã€‚</li>
</ul>
<h4 id="ACT"><a href="#ACT" class="headerlink" title="ACT"></a>ACT</h4><p>ç”±äºä¸€ä¸ªå¥å­ä¸­é—´ï¼Œæœ‰äº›è¯æ¯”å…¶ä»–è¯æ›´éš¾å­¦ä¼šï¼Œéœ€è¦æ›´å¤šè®¡ç®—é‡ï¼Œä½†å †å å¤ªå¤šå±‚ä¼šå¤§å¤§å¢åŠ è®¡ç®—é‡ï¼Œä¸ºäº†èŠ‚çœè®¡ç®—é‡ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥ACTæ¥åŠ¨æ€åˆ†é…è®¡ç®—é‡ã€‚</p>
<p>ACTåŸæ¥ç”¨äºRNNï¼Œåœ¨Transformerä¸­ï¼Œå½“halting unitæŒ‡ç¤ºè¯tåº”å½“åœæ­¢æ—¶ï¼Œç›´æ¥è®²è¯¥è¯çš„çŠ¶æ€å¤åˆ¶åˆ°ä¸‹ä¸€ä¸ªtime stepï¼Œç›´åˆ°æ‰€æœ‰çš„è¯éƒ½åœæ­¢ã€‚</p>
]]></content>
      <tags>
        <tag>Embedding</tag>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>ACT</tag>
        <tag>Language Modeling</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯12</title>
    <url>/2018/10/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D12/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£æœ›æµ·æ½®"><a href="#1ï¸âƒ£æœ›æµ·æ½®" class="headerlink" title="1ï¸âƒ£æœ›æµ·æ½®"></a>1ï¸âƒ£æœ›æµ·æ½®</h3><p>[å®‹] æŸ³æ°¸<br>ä¸œå—å½¢èƒœï¼Œä¸‰å´éƒ½ä¼šï¼Œé’±å¡˜è‡ªå¤ç¹åã€‚çƒŸæŸ³ç”»æ¡¥ï¼Œé£å¸˜ç¿ å¹•ï¼Œå‚å·®åä¸‡äººå®¶ã€‚äº‘æ ‘ç»•å ¤æ²™ï¼Œæ€’æ¶›å·éœœé›ªï¼Œå¤©å ‘æ— æ¶¯ã€‚å¸‚åˆ—ç ç‘ï¼Œæˆ·ç›ˆç½—ç»®ï¼Œç«è±ªå¥¢ã€‚<br>é‡æ¹–å å·˜æ¸…å˜‰ï¼Œæœ‰ä¸‰ç§‹æ¡‚å­ï¼Œåé‡Œè·èŠ±ã€‚ç¾Œç®¡å¼„æ™´ï¼Œè±æ­Œæ³›å¤œï¼Œå¬‰å¬‰é’“åŸè²å¨ƒã€‚åƒéª‘æ‹¥é«˜ç‰™ï¼Œä¹˜é†‰å¬ç®«é¼“ï¼ŒåŸèµçƒŸéœã€‚å¼‚æ—¥å›¾å°†å¥½æ™¯ï¼Œå½’å»å‡¤æ± å¤¸ã€‚</p>
<p>å å·˜ï¼ˆyÇnï¼‰ï¼šå±‚å±‚å å çš„å±±å³¦ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b318228ac247005f2223db" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b318228ac247005f2223db</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•8</title>
    <url>/2018/10/21/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%958/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-batchify"><a href="#1ï¸âƒ£-batchify" class="headerlink" title="1ï¸âƒ£[batchify]"></a>1ï¸âƒ£[batchify]</h3><p>å¿«é€Ÿå°†æ•°æ®åˆ†æˆbatchã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchify</span><span class="params">(data, bsz)</span>:</span></span><br><span class="line">    <span class="comment"># Work out how cleanly we can divide the dataset into bsz parts.</span></span><br><span class="line">    nbatch = data.size(<span class="number">0</span>) // bsz</span><br><span class="line">    <span class="comment"># Trim off any extra elements that wouldn't cleanly fit (remainders).</span></span><br><span class="line">    data = data.narrow(<span class="number">0</span>, <span class="number">0</span>, nbatch * bsz)</span><br><span class="line">    <span class="comment"># Evenly divide the data across the bsz batches.</span></span><br><span class="line">    data = data.view(bsz, <span class="number">-1</span>).t().contiguous()</span><br><span class="line">    <span class="keyword">return</span> data.to(device)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>PRMLç¬¬å››ç«  åˆ†ç±»çš„çº¿æ€§æ¨¡å‹</title>
    <url>/2018/10/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%88%86%E7%B1%BB%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="åˆ¤åˆ«å‡½æ•°"><a href="#åˆ¤åˆ«å‡½æ•°" class="headerlink" title="åˆ¤åˆ«å‡½æ•°"></a>åˆ¤åˆ«å‡½æ•°</h1><p><img src="/images/2018-10-21-Xnip2018-10-21_09-26-42.jpg" alt="0"></p>
<hr>
<p><img src="/images/2018-10-21-Xnip2018-10-21_09-27-57.jpg" alt="1"></p>
<p>â€”-æœªå®Œâ€”-</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>PRML</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡2</title>
    <url>/2018/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%872/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling"><a href="#1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling" class="headerlink" title="1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]"></a>1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]</h3><p>æœ¬æ–‡è´¡çŒ®ï¼šæå‡ºä¸€ç§æ–°çš„æ¨¡å‹<strong>TCNï¼ˆTemporal Convolutional Networksï¼‰</strong>è¿›è¡Œlanguage modelå»ºæ¨¡ã€‚</p>
<h4 id="Dilated-convolution"><a href="#Dilated-convolution" class="headerlink" title="Dilated convolution"></a>Dilated convolution</h4><p>æ¯ä¸€å±‚çš„æ„Ÿå—é‡éƒ½å¯ä»¥æ˜¯ä¸åŒçš„ï¼Œä¹Ÿå³ï¼ŒåŒæ ·çš„kernel sizeï¼Œé«˜å±‚çš„å¯ä»¥è·³ç€çœ‹ã€‚<br><img src="/images/2018-10-20-15400016170606.jpg" width="60%" height="50%"></p>
<p>æ¯å±‚çš„dé€æ¸å¢å¤§ï¼ˆä¹Ÿå³è·³çš„æ­¥æ•°ï¼‰ï¼Œä¸€èˆ¬æŒ‰æŒ‡æ•°å¢å¤§ã€‚ï¼ˆæˆ‘è§‰å¾—è¿™æ ·å¾ˆæœ‰é“ç†ï¼Œå¦‚æœæ¯ä¸€å±‚çš„déƒ½æ˜¯ä¸€æ ·çš„ï¼Œé‚£captureåˆ°çš„ä¿¡æ¯å°±ä¼šæœ‰é‡å¤ï¼Œèƒ½çœ‹åˆ°çš„è§†é‡ä¹Ÿä¸å¦‚é€æ¸å¢å¤§çš„å¤šï¼‰</p>
<h4 id="Residual-block"><a href="#Residual-block" class="headerlink" title="Residual block"></a>Residual block</h4><p><img src="/images/2018-10-20-15400017320092.jpg" width="70%" height="50%"></p>
<p>è¿™è¾¹çš„residual blockæ¯”è¾ƒå¤æ‚ï¼›ä¸€ä¸ªå€¼å¾—ä¸»æ„çš„ç»†èŠ‚æ˜¯ï¼Œå› ä¸ºæ„Ÿå—é‡çš„ä¸åŒï¼Œä¸Šå±‚çš„æ„Ÿå—é‡æ€»æ˜¯æ¯”ä¸‹å±‚çš„å¤§å¾ˆå¤šï¼Œå› æ­¤ä¸åº”è¯¥ç›´æ¥å°†ä¸‹å±‚çš„åŠ åˆ°ä¸Šå±‚ï¼Œè€Œæ˜¯å¯ä»¥ä½¿ç”¨ä¸€ä¸ª1*1çš„convolutionå¯¹ä¸‹å±‚çš„xè¿›è¡Œå·ç§¯ï¼Œè¿™å°±ç±»ä¼¼scaleå¯¹è¾“å…¥è¿›è¡Œæ”¾ç¼©ã€‚</p>
<hr>
<h3 id="2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation"><a href="#2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation" class="headerlink" title="2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]"></a>2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]</h3><p>ä¸€ç¯‡åˆ†æçš„æ–‡ç« ã€‚ELMoä½œè€…çš„åˆä¸€ç¯‡æ–‡ç« ã€‚</p>
<p>å¯¹æ¯”ä¸‰ç§ä¸åŒçš„å»ºæ¨¡æ–¹å¼ï¼ˆLSTM/GCNN/Transformerï¼‰è·å¾—çš„è¯å‘é‡ï¼Œä»¥åŠåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼›ä»¥åŠä¸åŒå±‚è·å¾—çš„ä¸åŒä¿¡æ¯â€¦è·å¾—äº†ä¸åŒçš„ç»“è®ºã€‚</p>
<p>â‘ biLM ä¸“æ³¨äºword morphologyè¯çš„å½¢æ€ï¼›åº•å±‚çš„LMå…³æ³¨local syntaxï¼›è€Œé«˜å±‚çš„LMå…³æ³¨semantic contentï¼›</p>
<p>â‘¡ä¸åŒçš„ä»»åŠ¡ä¼šæœ‰ä¸åŒçš„æ­£åˆ™åŒ–sçš„å€¾å‘ã€‚</p>
<hr>
<h3 id="3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency"><a href="#3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency" class="headerlink" title="3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]"></a>3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]</h3><p>åˆ©ç”¨Transformerè¿›è¡Œlanguage modelï¼Œä¸æ™®é€šçš„Transformerå»ºæ¨¡ä¸åŒçš„æ˜¯ï¼ŒTransformer-XLæ·»åŠ äº†å†å²ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¡¨ç°ã€‚è¿™ç¯‡è¿˜åœ¨ICLR2019å®¡ç¨¿ä¸­ã€‚</p>
<p>è´¡çŒ®ï¼šæœ¬æ–‡æå‡ºäº†èƒ½å¤Ÿè¿›è¡Œé•¿ç¨‹ä¾èµ–çš„åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹ Transformer-XLï¼›å¼•å…¥ç›¸å¯¹ä½ç½®çš„positional encodingã€‚</p>
<h4 id="ç»“æ„"><a href="#ç»“æ„" class="headerlink" title="ç»“æ„"></a>ç»“æ„</h4><p>åŸå…ˆçš„transformer language modelæ˜¯å°†å¥å­åˆ†ä¸ºä¸€ä¸ªä¸€ä¸ªsegmentã€‚segmentä¹‹é—´æ˜¯æ²¡æœ‰è”ç³»çš„ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥æŒ‰åŸç‰ˆçš„Transformeré‚£æ ·æ‰€æœ‰çš„è¯éƒ½ç›¸äº’åšself-attentionï¼Ÿå› ä¸ºè€ƒè™‘åˆ°æ•ˆç‡é—®é¢˜ï¼Œå¥å­é•¿åº¦å¯èƒ½ä¼šå¾ˆé•¿ï¼‰</p>
<p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400023645268.jpg" width="35%" height="50%"></p>
<p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¯æ¬¡å‘å³æ»‘åŠ¨ä¸€æ ¼ï¼š<br><img src="/images/2018-10-20-15400024115822.jpg" width="80%" height="50%"><br>è¿™æ ·æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½è¦é‡æ–°è®¡ç®—ä¸€éï¼Œå†å²ä¿¡æ¯æ²¡æœ‰åˆ©ç”¨åˆ°ã€‚æ˜¾ç„¶é€Ÿåº¦å¾ˆæ…¢ã€‚</p>
<p>åœ¨Transformerå¼•å…¥recurrenceï¼Œä¹Ÿå³å¼•å…¥å†å²ä¿¡æ¯ã€‚åŸºäºè¿™æ ·çš„æƒ³æ³•ï¼Œæå‡ºçš„æ–°æ¨¡å‹Transformer-XLã€‚åœ¨ç»“æ„ä¸ŠåŒæ ·åˆ†ä¸ºæ¯ä¸ªsegmentï¼Œä½†åœ¨æ¯ä¸ªé˜¶æ®µéƒ½æ¥æ”¶ä¸Šä¸€ä¸ªï¼ˆç”šè‡³ä¸ŠLä¸ªï¼‰å†å²ä¿¡æ¯ã€‚</p>
<p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400026059113.jpg" width="80%" height="50%"></p>
<p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼ŒåŒæ ·åˆ†ä¸ºsegmentï¼Œä½†å› ä¸ºæ¥æ”¶äº†å†å²ä¿¡æ¯ï¼Œä¸éœ€è¦æ¯æ¬¡æ»‘åŠ¨ä¸€æ ¼ä¹Ÿèƒ½è·å¾—å¤§é‡ä¿¡æ¯ã€‚<br><img src="/images/2018-10-20-15400027040526.jpg" width="45%" height="50%"></p>
<p>å…·ä½“æ¥è¯´ï¼š<br><img src="/images/2018-10-20-15400027302545.jpg" width="120%" height="50%"><br>SGä»£è¡¨stop gradientï¼Œå’Œè¯¥é˜¶æ®µçš„hidden stateè¿›è¡Œæ‹¼æ¥ã€‚</p>
<h4 id="RELATIVE-POSITIONAL-ENCODINGS"><a href="#RELATIVE-POSITIONAL-ENCODINGS" class="headerlink" title="RELATIVE POSITIONAL ENCODINGS"></a>RELATIVE POSITIONAL ENCODINGS</h4><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨äº†absolute positional encodingsï¼ˆä¹Ÿå³åŸç‰ˆçš„positional encodingsï¼‰é‚£ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µ</p>
<p><img src="/images/2018-10-20-15400027991211.jpg" width="70%" height="50%"></p>
<p>åœ¨åŒä¸€å±‚ä¹‹é—´çš„å‰ä¸€ä¸ªsegmentå’Œåä¸€ä¸ªsegmentä½¿ç”¨äº†åŒæ ·çš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¯¹äºå½“å‰segmentçš„é«˜å±‚ï¼Œå¯¹äºåŒä¸€ä¸ªä½ç½®iï¼Œæ— æ³•åŒºåˆ†è¯¥ä½ç½®ä¿¡æ¯æ˜¯æ¥è‡ªå½“å‰segmentçš„è¿˜æ˜¯ä¸Šä¸€ä¸ªsegmentçš„ï¼ˆå› ä¸ºéƒ½æ˜¯åŒæ ·çš„ç»å¯¹ä½ç½®ï¼‰ã€‚</p>
<p>å› æ­¤æˆ‘ä»¬å¼•å…¥ç›¸å¯¹ä½ç½®ä¿¡æ¯Rï¼Œå…¶ä¸­ç¬¬iè¡Œä»£è¡¨ç›¸å¯¹è·ç¦»içš„encodingã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼š</p>
<p>é¦–å…ˆæˆ‘ä»¬åœ¨ä¼ ç»Ÿçš„è®¡ç®—$query_i$å’Œ$key_j$çš„attentionåˆ†æ•°æ—¶ï¼Œå¯ä»¥æ‹†è§£æˆï¼š</p>
<p><img src="/images/2018-10-20-15400030310583.jpg" width="80%" height="50%"><br>ï¼ˆå› ä¸ºquery=(embedding E +positional embedding Uï¼‰ï¼Œkeyä¹Ÿä¸€æ ·ï¼Œå°†å¼å­æ‹†å¼€å°±èƒ½è·å¾—ä¸Šè¿°å¼å­)</p>
<p>æˆ‘ä»¬å°†è¯¥å¼å­è¿›è¡Œä¿®æ”¹ï¼š</p>
<p><img src="/images/2018-10-20-15400031662378.jpg" width="80%" height="50%"></p>
<p>ç¬¬ä¸€ï¼Œå°†å‡ºç°äº†absolute positional embedding $U$çš„åœ°æ–¹ï¼Œç»Ÿç»Ÿæ”¹æˆ$R_{i-j}$ï¼Œä¹Ÿå³åœ¨bå’Œdé¡¹ã€‚å…¶ä¸­è¿™é‡Œçš„Rå’ŒåŸç‰ˆçš„Transformerçš„ä½ç½®è®¡ç®—å…¬å¼ç›¸åŒã€‚</p>
<p>ç¬¬äºŒï¼Œåœ¨cé¡¹ä¸­ï¼Œä½¿ç”¨ä¸€ä¸ª$u$æ›¿ä»£äº†$U_i W_q$ï¼Œè¿™ä¸€é¡¹åŸæœ¬çš„æ„ä¹‰åœ¨äºï¼Œ$query_i$çš„positional encodingå¯¹$key_j$çš„embeddingè¿›è¡Œattentionï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¯¥é¡¹è¡¨ç°äº†$query_i$ä½ç½®å¯¹å“ªäº›$key_j$çš„å†…å®¹æœ‰å…´è¶£ï¼Œä½œè€…è®¤ä¸ºqueryä¸ç®¡åœ¨å“ªä¸ªä½ç½®ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´queryçš„ä½ç½®ä¿¡æ¯åº”å½“æ²¡å½±å“ï¼Œæ‰€ä»¥ç»Ÿç»Ÿæ›¿æ¢æˆä¸€ä¸ªå¯å­¦ä¹ çš„$u$ã€‚åŸºäºç±»ä¼¼çš„ç†ç”±dé¡¹æ¢æˆäº†$v$ã€‚</p>
<p>ç¬¬ä¸‰ï¼Œå°†$W_k$ç»†åˆ†æˆäº†ä¸¤ä¸ª$W_{k,E}$å’Œ$W_{k,R}$ã€‚è¿™æ˜¯æ ¹æ®queryæ˜¯Embeddingè¿˜æ˜¯positional encodingæ¥åŒºåˆ†çš„ã€‚for producing the content-based key vectors and location-based key vectors respectively</p>
<p>æ¯ä¸€é¡¹ç°åœ¨éƒ½æœ‰äº†ä¸åŒçš„æ„ä¹‰ï¼š</p>
<blockquote>
<p>Under the new parameterization, each term has an intuitive meaning: term (a) represents contentbased addressing, term (b) captures a content-dependent positional bias, term (c) governs a global content bias, and (d) encodes a global positional bias.</p>
</blockquote>
<p>æœ€åæ€»ç»“ä¸€ä¸‹æ•´ä¸ªç»“æ„ï¼š</p>
<p><img src="/images/2018-10-20-15400040342520.jpg" width="120%" height="50%"></p>
<p>ä¸åŸç‰ˆTransformerä¸åŒçš„æ˜¯ï¼ŒTransformer-XLåœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†ä½ç½®ä¿¡æ¯ã€‚</p>
<hr>
<h3 id="4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling"><a href="#4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling" class="headerlink" title="4ï¸âƒ£[Trellis Networks for Sequence Modeling]"></a>4ï¸âƒ£[Trellis Networks for Sequence Modeling]</h3><p>ä¸€ç§ç»“åˆRNNå’ŒCNNçš„è¯­è¨€å»ºæ¨¡æ–¹å¼ã€‚</p>
<p>æœ€å°çš„å•å…ƒç»“æ„ï¼š</p>
<p><img src="/images/2018-10-21-15400858162232.jpg" width="40%" height="50%"></p>
<p>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-21-15400860605560.jpg" width="40%" height="50%"></p>
<p>æ¥ä¸‹æ¥å†å¤„ç†éçº¿æ€§ï¼š<br><img src="/images/2018-10-21-15400861618655.jpg" width="30%" height="50%"></p>
<p>å› ä¸ºæ¯å±‚éƒ½è¦è¾“å…¥xï¼Œä¸”Wæ˜¯å…±äº«çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æå‰è®¡ç®—å¥½è¿™ä¸€é¡¹ï¼Œåé¢ç›´æ¥ç”¨å³å¯ã€‚<br><img src="/images/2018-10-21-15400861870898.jpg" width="35%" height="50%"></p>
<p>æœ€ç»ˆåœ¨å®ç°çš„æ—¶å€™æ˜¯ï¼š<br><img src="/images/2018-10-21-15400862184335.jpg" width="40%" height="50%"></p>
<p><img src="/images/2018-10-21-15400862303741.jpg" width="40%" height="50%"></p>
<p>æ€»ä½“æ¡†æ¶ï¼š<br><img src="/images/2018-10-21-15400874987498.jpg" width="70%" height="50%"></p>
<p>ä¸TCNï¼ˆtemporal convolution networkï¼‰ä¸åŒä¹‹å¤„ï¼šâ‘ filter weightä¸ä»…åœ¨time stepä¹‹é—´å…±äº«ï¼Œåœ¨ä¸åŒå±‚ä¹‹é—´ä¹Ÿå…±äº«ï¼›â‘¡åœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†è¾“å…¥</p>
<p>ä¼˜ç‚¹ï¼šå…±äº«äº†Wï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°ï¼›â€˜Weight tying can be viewed as a form of regularization that can stabilize trainingâ€™</p>
<p>æˆ‘ä»¬è¿˜å¯ä»¥æ‰©å±•è¯¥ç½‘ç»œï¼Œå¼•å…¥gateï¼š<br><img src="/images/2018-10-21-15400875805208.jpg" width="40%" height="50%"></p>
<hr>
<h3 id="5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation"><a href="#5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation" class="headerlink" title="5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]"></a>5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]</h3><p>ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„paperã€‚ç”¨äºNMT decodeçš„inferenceé˜¶æ®µã€‚è¿™ç¯‡æœ‰ä¸€å®šçš„éš¾åº¦ï¼Œä»¥ä¸‹åªæ˜¯æˆ‘çš„ç†è§£ã€‚</p>
<h4 id="æ€æƒ³"><a href="#æ€æƒ³" class="headerlink" title="æ€æƒ³"></a>æ€æƒ³</h4><p>Motivationï¼š<br>NMTä¸­çš„decode inferenceé˜¶æ®µï¼Œé€šå¸¸éƒ½æ˜¯ä»å·¦åˆ°å³çš„ï¼Œè¿™æ ·æœ‰ä¸ªç¼ºç‚¹ï¼Œå°±æ˜¯æ•´ä½“çš„targetä¹‹é—´çš„ä¾èµ–æ˜¯æ²¡æœ‰è¢«å……åˆ†åˆ©ç”¨åˆ°çš„ï¼Œæ¯”å¦‚è¯´ç”Ÿæˆçš„è¯çš„å³è¾¹æ˜¯æ²¡æœ‰ç”¨åˆ°çš„ã€‚é‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆä¸ç›´æ¥å…¨éƒ¨ç”Ÿæˆå‘¢ï¼Ÿç„¶åä¸æ–­æ›´æ–°ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å°†ç¦»æ•£ï¼ˆdiscreteï¼‰çš„decodeè¿‡ç¨‹å˜æˆä¸€ä¸ªè¿ç»­çš„è¿‡ç¨‹ï¼ˆcontinuous optimizationï¼‰ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½æ¨¡å‹ï¼Œç»™å®šä¸€ä¸ªå¥å­ï¼Œæˆ‘ä»¬è¦ç¿»è¯‘æˆç›®æ ‡å¥å­ï¼Œä¸”å‡è®¾æˆ‘ä»¬å·²çŸ¥è¦ç”Ÿæˆçš„å¥å­é•¿åº¦æ˜¯lï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ï¼š<br><img src="/images/2018-10-21-15400876953609.jpg" width="45%" height="50%"><br>æˆ‘ä»¬è¦æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„åºåˆ—$y$ï¼Œä½¿å¾—$-log$æœ€å°ã€‚</p>
<p>ç­‰ä»·äºï¼š<br><img src="/images/2018-10-21-15400877226851.jpg" width="55%" height="50%"><br>å…¶ä¸­$\widetilde{y}_i$æ˜¯one-hotã€‚å…¶å®è¿™é‡Œå°±æ˜¯å‡è®¾æœ‰è¿™ä¹ˆä¸€ä¸ªground truthï¼Œä½†å®é™…ä¸Šæ˜¯æ²¡æœ‰çš„ã€‚</p>
<p>æˆ‘ä»¬å°†$\widetilde{y}_i$æ˜¯one-hotè¿™ä¸ªæ¡ä»¶æ”¾å®½ä¸€äº›ï¼Œå˜æˆæ˜¯ä¸€ä¸ªæ¦‚ç‡å•çº¯å‹ï¼ˆå…¶å®å°±æ˜¯æ‰€æœ‰å…ƒç´ åŠ èµ·æ¥æ˜¯1ï¼Œä¸”éƒ½å¤§äºç­‰äº0ï¼‰ã€‚</p>
<p>é‚£ä¹ˆå°±å˜æˆäº†ï¼š<br><img src="/images/2018-10-21-15400879019592.jpg" width="50%" height="50%"></p>
<p>è¿™ä¸ªæ”¹å˜çš„æœ¬è´¨æ˜¯ï¼š<br><img src="/images/2018-10-21-15400879379023.jpg" width="50%" height="50%"></p>
<p>å°±æ˜¯è¯´åŸæ¥one-hotçš„$\widetilde{y}_i$ç”Ÿæˆåä¸¢åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå–äº†ä¸€ä¸ªè¯å‘é‡ï¼Œæ¥ç€è®¡ç®—ã€‚ç°åœ¨æ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ$\hat{y}_i$ä¸¢è¿›æ¥ï¼Œå°±ç›¸å½“äºå–äº†å¤šä¸ªè¯å‘é‡çš„åŠ æƒæ±‚å’Œã€‚</p>
<p>åœ¨åˆ©ç”¨ä¸‹è¿°çš„æ›´æ–°ç®—æ³•æ›´æ–°å®Œ$\hat{y}_i$ä¹‹åï¼Œå¯¹äºæ¯ä¸ªæ—¶é—´æ­¥tï¼Œæˆ‘ä»¬æ‰¾$\hat{y}_i$ä¸­å…ƒç´ æœ€å¤§çš„å€¼å¯¹åº”çš„è¯ä½œä¸ºç”Ÿæˆçš„è¯ã€‚</p>
<p>æœ‰ä¸¤ç§æ–¹æ³•Exponentiated Gradient å’Œ SGDã€‚å®é™…ä¸Šæ–¹æ³•å€’åœ¨å…¶æ¬¡äº†ï¼Œä¸»è¦æ˜¯å‰é¢æ‰€è¿°çš„continuous optimizationè¿™ç§æ€æƒ³ã€‚</p>
<h4 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h4><h5 id="Exponentiated-Gradient"><a href="#Exponentiated-Gradient" class="headerlink" title="Exponentiated Gradient"></a>Exponentiated Gradient</h5><p><img src="/images/2018-10-21-15400881918713.jpg" width="80%" height="50%"><br>å…·ä½“è§è®ºæ–‡</p>
<h5 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h5><p>å› ä¸ºæˆ‘ä»¬è¦ä¿è¯å•çº¯å½¢çš„çº¦æŸä¸å˜ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªrï¼Œç„¶ååšä¸€ä¸ªsoftmax<br><img src="/images/2018-10-21-15400882306948.jpg" width="80%" height="50%"></p>
<h4 id="åº”ç”¨"><a href="#åº”ç”¨" class="headerlink" title="åº”ç”¨"></a>åº”ç”¨</h4><p>è¿™ç§è¿ç»­decodeå¯ä»¥ç”¨åœ¨å“ªï¼Ÿ</p>
<h5 id="Bidirectional-Ensemble"><a href="#Bidirectional-Ensemble" class="headerlink" title="Bidirectional Ensemble"></a>Bidirectional Ensemble</h5><p>å¯ä»¥å¾ˆæ–¹ä¾¿åœ°è¿›è¡ŒåŒå‘çš„ç”Ÿæˆï¼š</p>
<p><img src="/images/2018-10-21-15400883321474.jpg" width="45%" height="50%"><br>è€Œåœ¨ä¼ ç»Ÿçš„æ–¹æ³•ä¸­æ²¡åŠæ³•ï¼ˆå¾ˆéš¾ï¼‰åšåˆ°</p>
<h5 id="Bilingual-Ensemble"><a href="#Bilingual-Ensemble" class="headerlink" title="Bilingual Ensemble"></a>Bilingual Ensemble</h5><p>æˆ‘ä»¬å¸Œæœ›æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€å’Œç›®æ ‡åˆ°æºè¯­è¨€éƒ½ç”Ÿæˆå¾—å¥½</p>
<p><img src="/images/2018-10-21-15400883583228.jpg" width="50%" height="50%"></p>
<h4 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h4><p>$\hat{y}_i$çš„åˆå§‹åŒ–å¾ˆé‡è¦ï¼Œä¸€ä¸å°å¿ƒå°±ä¼šé™·å…¥local minimaï¼›ç”Ÿæˆçš„é€Ÿåº¦æ…¢</p>
<hr>
<h3 id="6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation"><a href="#6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation" class="headerlink" title="6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]"></a>6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]</h3><p>å’ŒELMoã€OpenAI GPTä¸€æ ·ï¼Œéƒ½æ˜¯é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼ˆè¿™é‡Œæ˜¯åˆ†ç±»ä»»åŠ¡ï¼‰ã€‚å¯ä»¥åœ¨éå¸¸å°çš„æ•°æ®é›†ä¸Šæœ‰å¾ˆå¥½çš„æ•ˆæœã€‚</p>
<p>è´¡çŒ®ï¼š</p>
<ol>
<li>è¿ç§»å­¦ä¹ æ¨¡å‹ULMFiT</li>
<li>æå‡ºå‡ ç§trickï¼šdiscriminative ï¬ne-tuning, slanted triangular learning rates,gradual unfreezing ï¼Œæœ€å¤§ä¿è¯çŸ¥è¯†çš„ä¿ç•™ã€‚</li>
</ol>
<h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p><img src="/images/2018-10-21-15401043145373.jpg" width="90%" height="50%"></p>
<p>ä¸‰éƒ¨æ›²ï¼š</p>
<ol>
<li>é€šç”¨è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ</li>
<li>ç›®æ ‡ä»»åŠ¡çš„è¯­è¨€æ¨¡å‹fine-tuning</li>
<li>ç›®æ ‡ä»»åŠ¡çš„åˆ†ç±»fine-tuning</li>
</ol>
<h4 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h4><h5 id="Discriminative-ï¬ne-tuning"><a href="#Discriminative-ï¬ne-tuning" class="headerlink" title="Discriminative ï¬ne-tuning"></a>Discriminative ï¬ne-tuning</h5><p>Motivationï¼šä¸åŒå±‚æœ‰ä¸åŒçš„ä¿¡æ¯ï¼›åº”å½“fine-tune ä¸åŒç¨‹åº¦ï¼Œä¹Ÿå³ä½¿ç”¨ä¸åŒçš„learning rateã€‚</p>
<p><img src="/images/2018-10-21-15401044160803.jpg" width="35%" height="50%"></p>
<p>ä½œè€…å‘ç°ä¸Šä¸€å±‚çš„å­¦ä¹ ç‡æ˜¯ä¸‹ä¸€å±‚çš„2.6å€æ—¶æ•ˆæœæ¯”è¾ƒå¥½ã€‚</p>
<h5 id="Slanted-triangular-learning-rates-STLR"><a href="#Slanted-triangular-learning-rates-STLR" class="headerlink" title="Slanted triangular learning rates (STLR)"></a>Slanted triangular learning rates (STLR)</h5><p><img src="/images/2018-10-21-15401045153164.jpg" width="60%" height="50%"></p>
<p>å…·ä½“å…¬å¼ï¼š<br><img src="/images/2018-10-21-15401045316305.jpg" width="50%" height="50%"></p>
<h5 id="Gradual-unfreezing"><a href="#Gradual-unfreezing" class="headerlink" title="Gradual unfreezing"></a>Gradual unfreezing</h5><p>ä»é¡¶å±‚åˆ°åº•å±‚ï¼Œä¸€æ­¥ä¸€æ­¥unfreezeï¼Œä¹Ÿå³ä»ä¸Šåˆ°ä¸‹fine-tuneã€‚è¿™æ˜¯å› ä¸ºæœ€ä¸Šä¸€å±‚æœ‰æœ€å°‘çš„general knowledgeã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>TCN</tag>
        <tag>Transformer-XL</tag>
        <tag>Trellis Networks</tag>
        <tag>continuous decoding</tag>
        <tag>ULMFiT</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è®ºæ–‡1</title>
    <url>/2018/10/14/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%871/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors"><a href="#1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors" class="headerlink" title="1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]"></a>1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]</h3><p>CoVeæ˜¯ç¬¬ä¸€ä¸ªå¼•å…¥åŠ¨æ€è¯å‘é‡çš„æ¨¡å‹ã€‚<br>Motivationï¼šç¿»è¯‘æ¨¡å‹èƒ½å¤Ÿä¿å­˜æœ€å¤šçš„ä¿¡æ¯ï¼Œå› ä¸ºå¦‚æœä¿å­˜ä¿¡æ¯ä¸å¤Ÿå¤šï¼Œdecoderæ¥æ”¶åˆ°çš„ä¿¡æ¯ä¸è¶³ï¼Œç¿»è¯‘æ•ˆæœå°±ä¸ä¼šå¥½ã€‚ï¼ˆä½†å®é™…ä¸Šï¼Œæˆ‘ä¸ªäººè®¤ä¸ºï¼Œdecoderçš„è¡¨ç°è¿˜å’Œlanguage modelæœ‰å…³ï¼Œå¦‚æœdecoderæ˜¯ä¸€ä¸ªå¥½çš„language modelï¼Œä¹Ÿæœ‰å¯èƒ½ç¿»è¯‘å‡ºä¸é”™çš„ç»“æœï¼‰</p>
<p>åšæ³•ï¼šä½¿ç”¨ä¼ ç»ŸNMTçš„encoder-decoderçš„åšæ³•ç¿»è¯‘æ¨¡å‹ï¼Œåªæ˜¯å°†(bi)LSTMæ‰€å¾—åˆ°çš„éšå±‚çŠ¶æ€è¡¨ç¤ºå–å‡ºæ¥å’Œembeddingæ‹¼æ¥èµ·æ¥ï¼Œä½œä¸ºä¸€ä¸ªè¯çš„è¡¨ç¤ºï¼š</p>
<script type="math/tex; mode=display">w=[GloVe(w); CoVe(w)]</script><hr>
<h3 id="2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks"><a href="#2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]"></a>2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]</h3><p>ä½¿ç”¨CNNå¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå»ºæ¨¡ï¼Œæé«˜å¹¶è¡Œæ€§ã€‚</p>
<p>è´¡çŒ®ï¼šä½¿ç”¨äº†CNNè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›æå‡ºäº†ç®€åŒ–ç‰ˆçš„gateæœºåˆ¶åº”ç”¨åœ¨CNNä¸­ã€‚</p>
<p>åšæ³•ï¼š<br><img src="/images/2018-10-14-15394870930257.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªè¾“å…¥ä¸¤ä¸ªfilterï¼Œå·ç§¯å‡ºæ¥çš„åšä¸€ä¸ªgateçš„æ“ä½œ$H_0 = AâŠ—Ïƒ(B)$ï¼Œæ§åˆ¶æµå‘ä¸‹ä¸€å±‚çš„æ•°æ®ã€‚</p>
<p>ä¸€ä¸ªå°ç»†èŠ‚æ˜¯ï¼Œä¸ºäº†ä¸è®©language modelçœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œæ¯ä¸€å±‚åœ¨å¼€å§‹å·ç§¯çš„æ—¶å€™ä¼šåœ¨å·¦è¾¹æ·»åŠ kernel_size-1ä¸ªpaddingã€‚</p>
<p>æ‰©å±•ï¼šå› ä¸ºCNNçš„å¹¶è¡Œæ€§é«˜ï¼Œå¯ä»¥ä½¿ç”¨CNNæ¥å¯¹language modelå»ºæ¨¡æ›¿ä»£ELMoï¼ŒåŒæ ·å¯ä»¥è·å¾—åŠ¨æ€è¯å‘é‡ã€‚è¿™ä¸ªæƒ³æ³•å·²ç»ç”±æå‡ºELMoçš„å›¢é˜Ÿåšå‡ºæ¥å¹¶è¿›è¡Œå¯¹æ¯”äº†ã€‚è®ºæ–‡ï¼šDissecting Contextual Word Embeddings: Architecture and Representation</p>
<p>ç›®å‰æ­£åœ¨<a href="https://github.com/linzehui/Gated-Convolutional-Networks" target="_blank" rel="noopener">å¤ç°</a>è¯¥è®ºæ–‡ ã€‚</p>
<hr>
<h3 id="3ï¸âƒ£-Attention-is-All-you-need"><a href="#3ï¸âƒ£-Attention-is-All-you-need" class="headerlink" title="3ï¸âƒ£[Attention is All you need]"></a>3ï¸âƒ£[Attention is All you need]</h3><p>éå¸¸ç»å…¸çš„è®ºæ–‡ã€‚æå‡ºäº†Transformerã€‚ä¸ºäº†è¯»BERTé‡æ¸©äº†ä¸€éã€‚<br><img src="/images/2018-10-14-15394876881322.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-10-14-15394877200390.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-10-14-15394877478814.jpg" width="70%" height="50%"></p>
<hr>
<h3 id="4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training"><a href="#4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training" class="headerlink" title="4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]"></a>4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]</h3><p>BERTå°±æ˜¯followè¿™ç¯‡æ–‡ç« çš„å·¥ä½œã€‚<br>ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p>
<p>è®­ç»ƒè¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼šâ‘ ä½¿ç”¨æœªæ ‡è®°æ•°æ®è®­ç»ƒlanguage modelï¼›â‘¡ä½¿ç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œfine-tune</p>
<p>Motivationï¼šELMoæ˜¯è®­ç»ƒå¥½language modelï¼Œç„¶åè·å¾—åŠ¨æ€è¯å‘é‡å†ç”¨åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼Œè¿™æ ·å°±ä¼šå¤šäº†å¾ˆå¤šå‚æ•°ã€‚å’ŒELMoä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªTransformeræ¨¡å‹è§£å†³å¤šç§ä»»åŠ¡ï¼ˆåˆ©ç”¨è¿ç§»å­¦ä¹ ï¼‰ã€‚</p>
<p>è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›å°è¯•åˆ©ç”¨language modelè¿›è¡Œè¿ç§»å­¦ä¹ è€Œä¸æ˜¯å¦ä¸€ç§æ€è·¯ï¼ˆELMoï¼‰åªæå–è¯å‘é‡ã€‚</p>
<p>â‘ æ— ç›‘ç£å­¦ä¹ language model<br><img src="/images/2018-10-14-15395044176746.jpg" width="40%" height="50%"></p>
<p>å…·ä½“åˆ°Transformerå°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395044608239.jpg" width="50%" height="50%"></p>
<p>â‘¡ç›‘ç£å­¦ä¹ ï¼ˆfine-tuneï¼‰<br>æ ¹æ®è¾“å…¥é¢„æµ‹æ ‡ç­¾<br><img src="/images/2018-10-14-15395045508824.jpg" width="35%" height="50%"></p>
<p>å…·ä½“å°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395045734859.jpg" width="40%" height="50%"></p>
<p>å°†ä¸¤ä¸ªä»»åŠ¡ä¸€èµ·è®­ç»ƒï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-10-14-15395045932795.jpg" width="30%" height="50%"></p>
<p>å¯¹äºä¸åŒä»»åŠ¡ï¼Œå¯¹è¾“å…¥è¿›è¡Œä¸€å®šçš„æ”¹åŠ¨ä»¥é€‚åº”Transformerç»“æ„ï¼š<br><img src="/images/2018-10-14-15395046364928.jpg" width="90%" height="50%"></p>
<hr>
<h3 id="5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]"></a>5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]</h3><p>åˆ·çˆ†å„æ¦œå•çš„ä¸€ç¯‡ç¥æ–‡ã€‚ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p>
<p>Motivationï¼šä¹‹å‰çš„language modelåªèƒ½æ ¹æ®å‰é¢çš„è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªï¼ˆå³ä½¿ELMoæ˜¯åŒå‘çš„LSTMï¼Œä¹Ÿæ˜¯åˆ†åˆ«è®­ç»ƒä¸€ä¸ªå‰å‘å’Œä¸€ä¸ªåå‘çš„ï¼‰ï¼Œé™åˆ¶äº†åŒå‘çš„contextï¼›å› æ­¤æå‡ºäº†åŒå‘çš„language modelã€‚</p>
<h4 id="åšæ³•ï¼š"><a href="#åšæ³•ï¼š" class="headerlink" title="åšæ³•ï¼š"></a>åšæ³•ï¼š</h4><p>æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š<br>â‘ masked LMï¼šå› ä¸ºä½¿ç”¨äº†ä¸¤è¾¹çš„contextï¼Œè€Œlanguage modelçš„ç›®çš„æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿™æ ·æ¨¡å‹ä¼šæå‰çœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œè®­ç»ƒçš„æ—¶å€™è®²éƒ¨åˆ†è¯maskæ‰ï¼Œæœ€ç»ˆåªé¢„æµ‹è¢«maskæ‰çš„è¯ã€‚</p>
<p>â‘¡Next Sentence Predictionï¼šéšæœº50%ç”Ÿæˆä¸¤ä¸ªå¥å­æ˜¯æœ‰ä¸Šä¸‹å¥å…³ç³»çš„ï¼Œ50%ä¸¤ä¸ªå¥å­æ˜¯æ²¡æœ‰å…³ç³»çš„ï¼Œç„¶ååšåˆ†ç±»ï¼›å…·ä½“æ¥è¯´æ˜¯æ‹¿ç¬¬ä¸€ä¸ªè¯[CLS]ï¼ˆè¿™æ˜¯æ‰‹åŠ¨æ·»åŠ çš„ï¼‰çš„è¡¨ç¤ºï¼Œè¿‡ä¸€ä¸ªsoftmaxå±‚å¾—åˆ°ã€‚<br><img src="/images/2018-10-14-15394891973653.jpg" width="50%" height="50%"></p>
<p>è”åˆè®­ç»ƒè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚</p>
<p>æ¥ä¸‹æ¥æ˜¯é€šè¿‡å…·ä½“çš„ä»»åŠ¡è¿›è¡Œfine-tuneã€‚ä¸€ä¸ªæ¨¡å‹è§£å†³å¤šç§é—®é¢˜ï¼š<br><img src="/images/2018-10-14-15395038593955.jpg" width="80%" height="50%"></p>
<p>æœ¬æ–‡è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡ŒåŒå‘çš„language modelå»ºæ¨¡ã€‚è®ºæ–‡æåˆ°çš„ä¸€äº›ç»†èŠ‚/trickséå¸¸å€¼å¾—è®¨è®ºï¼Œæ¯”å¦‚å¯¹token embeddingæ·»åŠ äº†è®¸å¤šä¿¡æ¯ï¼Œéå¸¸ç®€å•ç²—æš´ã€‚</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Transformer</tag>
        <tag>æ¯å‘¨è®ºæ–‡é˜…è¯»</tag>
        <tag>CoVe</tag>
        <tag>GCNN</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 18:Deep Reinforcement Learning</title>
    <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/</url>
    <content><![CDATA[<p>è®°å·ï¼š $a$æ˜¯actionï¼Œ$s$å³å¤–éƒ¨çŠ¶æ€stateï¼Œ$\pi_{\theta}(s)$ä¹Ÿå³ä»$s$æ˜ å°„åˆ°$a$çš„å‡½æ•°ï¼›$r$æ˜¯rewardï¼Œæ¯é‡‡å–ä¸€ä¸ªåŠ¨ä½œï¼Œä¼šæœ‰ä¸€ä¸ªrewardï¼Œåˆ™æ€»çš„rewardä¸º</p>
<script type="math/tex; mode=display">R_\theta = \sum_{t=1}^{T} r_t</script><p>æˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ‹Ÿåˆ$\pi$ï¼Œä¸€ä¸ªeposide $\tau$æ˜¯ä¸€ä¸ªæµç¨‹ä¸‹æ¥çš„çš„æ‰€æœ‰stateã€actionå’Œrewardçš„é›†åˆã€‚</p>
<script type="math/tex; mode=display">\tau = \{s_1,a_1,r_1,s_2,a_2,r_2,...,s_T,a_T,r_T \}</script><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„actorè¿è¡Œnæ¬¡ï¼Œåˆ™æ¯ä¸ª$\tau$ä¼šæœ‰ä¸€å®šçš„æ¦‚ç‡è¢«é‡‡æ ·åˆ°ï¼Œé‡‡æ ·æ¦‚ç‡è®°ä¸º$P(\tau|\theta)$ï¼Œåˆ™æˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·çš„æ–¹å¼æ¥å¯¹æœŸæœ›rewardè¿›è¡Œä¼°è®¡ï¼š</p>
<script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n)</script><p>é‚£ä¹ˆæˆ‘ä»¬æ¥ä¸‹æ¥çš„<strong>ç›®æ ‡</strong>å°±æ˜¯æœ€å¤§åŒ–æœŸæœ›rewardï¼Œå…¶ä¸­æœŸæœ›rewardæ˜¯ï¼š</p>
<script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta)</script><p>æˆ‘ä»¬åŒæ ·ä½¿ç”¨æ¢¯åº¦ä¸Šå‡ï¼šå…¶ä¸­ä¸$Î¸$ç›¸å…³çš„æ˜¯$P$ï¼Œåˆ™å¯ä»¥å†™æˆï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) \nabla P(\tau|\theta)= \sum_\tau R(\tau) P(\tau|\theta) \frac{\nabla P(\tau|\theta)}{P(\tau|\theta)}</script><p>ç”±äº$\dfrac {d\log \left( f\left( x\right) \right) }{dx}=\dfrac {1}{f\left( x\right) }\dfrac {df(x)}{dx}$ï¼Œåˆ™å‰å¼å¯å†™æˆï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) \nabla log P(\tau | \theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n) log P(\tau ^n| \theta)</script><p>å¦‚ä½•æ±‚æ¢¯åº¦ï¼Ÿ<br>ç”±äºï¼š</p>
<script type="math/tex; mode=display">P(\tau | \theta)=p(s_1)p(a_1|s_1,\theta)p(r_1,s_2|s_1,a_1)p(a_2|s_2,\theta)p(r_2,s_3|s_2,a_2)...
\\=p(s_1)\prod_{t=1}^{T}p(a_t|s_t,\theta)p(r_t , s_{t+1}| s_t,a_t)</script><p>å®é™…ä¸Šï¼Œå…¶ä¸­ä¸æ¢¯åº¦ç›¸å…³çš„åªæœ‰ä¸­é—´é¡¹$p(a_t|s_t,\theta)$ï¼Œè¯¥é¡¹ä¹Ÿå³$Ï€$å‡½æ•°ï¼Œä»stateåˆ°actionçš„æ˜ å°„ã€‚<br>å–logå¹¶æ±‚å¯¼ï¼Œæœ‰ï¼š</p>
<script type="math/tex; mode=display">\nabla log P(\tau | \theta)= \sum_{t=1}^{T} \nabla log p(a_t|s_t,\theta)</script><p>ä»£å›ï¼Œå› æ­¤æœ€ç»ˆ$\overline{R}_\theta$çš„æ¢¯åº¦ä¸ºï¼š</p>
<script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} R(\tau^n) \nabla log p(a_{t}^n | s_t^n,\theta)</script><p>æ³¨æ„åˆ°è¯¥å¼å­å‘Šè¯‰æˆ‘ä»¬ï¼Œåº”è€ƒè™‘æ•´ä½“çš„rewardè€Œä¸åº”è¯¥åªè€ƒè™‘æ¯ä¸€æ­¥çš„rewardï¼›å¹¶ä¸”å–logçš„åŸå› å¯ä»¥ç†è§£æˆæ˜¯å¯¹actionå–å½’ä¸€åŒ–ï¼Œå› ä¸ºï¼š</p>
<script type="math/tex; mode=display">\frac{\nabla p(a_t^n | s_t^n,\theta)}{p(a_t^n | s_t^n,\theta)}</script><p>ä¹Ÿå°±æ˜¯è¯´å¯¹äºé‚£äº›å‡ºç°æ¬¡æ•°è¾ƒå¤šçš„actionï¼Œè¦è¡¡é‡ä»–ä»¬å¯¹rewardçš„çœŸæ­£å½±å“ï¼Œåº”å½“å¯¹ä»–ä»¬å½’ä¸€åŒ–ã€‚</p>
<p>ä¸ºäº†è®©é‚£äº›å‡ºç°å¯èƒ½æ€§è¾ƒä½çš„actionä¸ä¼šå› ä¸ºæ²¡è¢«sampleåˆ°è€Œåœ¨æ›´æ–°åè¢«é™ä½ä»–ä»¬çš„æ¦‚ç‡ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ªbaselineï¼Œåªæœ‰è¶…è¿‡$b$çš„rewardæ‰ä¼šå¢åŠ ä»–ä»¬å‡ºç°çš„æ¦‚ç‡ã€‚</p>
<script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} (R(\tau^n)-b) \nabla log p(a_{t}^n | s_t^n,\theta)</script>]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 17:Ensemble</title>
    <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2017:%20Ensemble/</url>
    <content><![CDATA[<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>å¯¹äºå¤æ‚æ¨¡å‹ï¼Œå¾€å¾€varianceä¼šå¤§ï¼Œé€šè¿‡å¯¹å¤šä¸ªæ¨¡å‹çš„å¹³å‡ï¼Œèƒ½å¤Ÿå‡å°varianceï¼š<br><img src="/images/2018-10-14-15394832736339.jpg" width="50%" height="50%"></p>
<p>baggingçš„æ€æƒ³æ˜¯å¤šæ¬¡æœ‰æ”¾å›åœ°é‡‡æ ·Nâ€™ä¸ªç‚¹ï¼ˆé€šå¸¸Nâ€™=Nï¼‰ï¼Œç„¶åå¯¹é‡‡æ ·çš„å‡ ä¸ªæ•°æ®é›†åˆ†åˆ«è®­ç»ƒä¸€ä¸ªæ¨¡å‹<br><img src="/images/2018-10-14-15394833007835.jpg" width="50%" height="50%"></p>
<p>æµ‹è¯•çš„æ—¶å€™å†å¯¹å‡ ä¸ªæ¨¡å‹è¿›è¡Œå¹³å‡æˆ–æŠ•ç¥¨<br><img src="/images/2018-10-14-15394833255306.jpg" width="50%" height="50%"></p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>åŸºæœ¬æ€æƒ³æ˜¯å¯¹å‡ ä¸ªå¼±åˆ†ç±»å™¨çº¿æ€§åŠ æƒï¼Œå¾—åˆ°å¼ºåˆ†ç±»å™¨ã€‚åˆ†ç±»å™¨æŒ‰å…ˆåé¡ºåºè®­ç»ƒï¼Œæ¯æ¬¡è®­ç»ƒå®Œï¼Œå¯¹æ–°æ¨¡å‹åˆ†ç±»é”™è¯¯çš„æ•°æ®è¿›è¡Œè°ƒé«˜æƒé‡ï¼Œè€Œæ­£ç¡®çš„æ•°æ®åˆ™é™ä½æƒé‡ã€‚</p>
<p>å¯ä»¥ä¿è¯ï¼šåªè¦åˆ†ç±»å™¨çš„é”™è¯¯ç‡å°äº50%ï¼Œåœ¨boostingåèƒ½å¤Ÿæœ‰100%çš„æ­£ç¡®ç‡ï¼ˆåœ¨è®­ç»ƒé›†ï¼‰ã€‚</p>
<p>è¯æ˜è¿‡ç¨‹ç•¥ã€‚</p>
<h2 id="Ensemble-Stacking"><a href="#Ensemble-Stacking" class="headerlink" title="Ensemble: Stacking"></a>Ensemble: Stacking</h2><p>åŸºæœ¬æ€æƒ³ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®è®­ç»ƒå¤šä¸ªåˆçº§åˆ†ç±»å™¨ï¼Œå°†åˆçº§åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸ºæ¬¡çº§åˆ†ç±»å™¨çš„è¾“å…¥ï¼Œè·å¾—æœ€ç»ˆçš„è¾“å‡ºã€‚æˆ‘ä»¬åº”å½“ä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒæ¬¡çº§åˆ†ç±»å™¨<br><img src="/images/2018-10-14-15394833971028.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Ensemble</tag>
      </tags>
  </entry>
  <entry>
    <title>æµ…è°ˆmaskçŸ©é˜µ</title>
    <url>/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/</url>
    <content><![CDATA[<p>ä¸ªäººç›®å‰å¯¹maskçŸ©é˜µçš„ä¸€ç‚¹ç†è§£ã€‚</p>
<hr>
<h2 id="æ˜¯ä»€ä¹ˆ"><a href="#æ˜¯ä»€ä¹ˆ" class="headerlink" title="æ˜¯ä»€ä¹ˆ"></a>æ˜¯ä»€ä¹ˆ</h2><p>maskçŸ©é˜µæ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ä¸€ä¸ªç”±0å’Œ1ç»„æˆçš„çŸ©é˜µã€‚ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä¸­ï¼Œå¥å­çš„é•¿åº¦æ˜¯ä¸ç­‰é•¿çš„ï¼Œä½†å› ä¸ºæˆ‘ä»¬ç»å¸¸å°†å¥å­ç»„æˆmini-batchç”¨ä»¥è®­ç»ƒï¼Œå› æ­¤é‚£äº›é•¿åº¦è¾ƒçŸ­çš„å¥å­éƒ½ä¼šåœ¨å¥å°¾è¿›è¡Œå¡«å……0ï¼Œä¹Ÿå³paddingçš„æ“ä½œã€‚ä¸€ä¸ªmaskçŸ©é˜µå³ç”¨ä»¥æŒ‡ç¤ºå“ªäº›æ˜¯çœŸæ­£çš„æ•°æ®ï¼Œå“ªäº›æ˜¯paddingã€‚å¦‚ï¼š<br><img src="/images/2018-10-12-15393574958961.jpg" width="50%" height="50%"><br>å›¾ç‰‡æ¥æºï¼š<a href="https://www.cnblogs.com/neopenx/p/4806006.html" target="_blank" rel="noopener">Theanoï¼šLSTMæºç è§£æ</a></p>
<p>å…¶ä¸­maskçŸ©é˜µä¸­1ä»£è¡¨çœŸå®æ•°æ®ï¼›0ä»£è¡¨paddingæ•°æ®ã€‚</p>
<h2 id="ä¸ºä»€ä¹ˆ"><a href="#ä¸ºä»€ä¹ˆ" class="headerlink" title="ä¸ºä»€ä¹ˆ"></a>ä¸ºä»€ä¹ˆ</h2><p>ä¸ºä»€ä¹ˆè¦ä½¿ç”¨maskçŸ©é˜µï¼Ÿä½¿ç”¨maskçŸ©é˜µæ˜¯ä¸ºäº†è®©é‚£äº›è¢«maskæ‰çš„tensorä¸ä¼šè¢«æ›´æ–°ã€‚è€ƒè™‘ä¸€ä¸ªtensor Tçš„size(a,b)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œç›¸ä¹˜åï¼Œåœ¨åå‘å›ä¼ çš„æ—¶å€™åœ¨Tå¯¹åº”maskä¸º0çš„åœ°æ–¹ï¼Œ0çš„æ¢¯åº¦ä»ä¸º0ã€‚å› æ­¤ä¸ä¼šè¢«æ›´æ–°ã€‚</p>
<h2 id="æ€ä¹ˆåš"><a href="#æ€ä¹ˆåš" class="headerlink" title="æ€ä¹ˆåš"></a>æ€ä¹ˆåš</h2><p>æ¥ä¸‹æ¥ä»‹ç»å‡ ç§ï¼ˆå¯èƒ½ä¸å…¨ï¼‰ä½¿ç”¨maskçš„åœºæ™¯ã€‚</p>
<h3 id="å¯¹è¾“å…¥è¿›è¡Œmask"><a href="#å¯¹è¾“å…¥è¿›è¡Œmask" class="headerlink" title="å¯¹è¾“å…¥è¿›è¡Œmask"></a>å¯¹è¾“å…¥è¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­å¸¸è§çš„å¥å­ä¸ç­‰é•¿çš„æƒ…å†µã€‚è®¾æˆ‘ä»¬çš„è¾“å…¥çš„batch I:(batch_size,max_seqlen)ï¼Œæˆ‘ä»¬åœ¨è¿‡ä¸€å±‚Embeddingå±‚ä¹‹å‰ï¼Œ<br>åœ¨è¿‡äº†ä¸€å±‚Embeddingå±‚ï¼Œåˆ™æœ‰ E:(batch_size,max_seqlen,embed_dim)ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›Embeddingæ˜¯æ›´æ–°çš„(æ¯”å¦‚æˆ‘ä»¬çš„Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œé‚£å½“ç„¶Embeddingéœ€è¦æ›´æ–°)ï¼Œä½†æˆ‘ä»¬åˆä¸å¸Œæœ›paddingæ›´æ–°ã€‚<br>ä¸€ç§æ–¹æ³•å³ä»¤Eä¸Mç›¸ä¹˜ã€‚å…¶ä¸­Mæ˜¯maskçŸ©é˜µ(batch_size,max_seqlen,1) (1æ˜¯å› ä¸ºè¦broadcastï¼‰ï¼Œè¿™æ ·åœ¨Embeddingæ›´æ–°æ¢¯åº¦æ—¶ï¼Œå› ä¸ºmaskçŸ©é˜µçš„å…³ç³»ï¼Œpaddingä½ç½®ä¸Šçš„æ¢¯åº¦å°±æ˜¯0ã€‚<br>å½“ç„¶åœ¨Pytorchä¸­è¿˜å¯ä»¥ç›´æ¥æ˜¾å¼åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>è€Œæ­¤æ—¶åº”å½“å°†paddingæ˜¾å¼æ·»åŠ åˆ°è¯å…¸çš„ç¬¬ä¸€ä¸ªã€‚</p>
<h3 id="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"><a href="#å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask" class="headerlink" title="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"></a>å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask</h3><p>ä¸€ä¸ªå¾ˆç»å…¸çš„åœºæ™¯å°±æ˜¯dropoutã€‚<br>å¯¹äºå‚æ•°çŸ©é˜µW:(h,w)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ä»¤Wâ€™=W*Mï¼Œåˆ™åœ¨åå‘ä¼ æ’­æ—¶ï¼ŒMä¸­ä¸º0çš„éƒ¨åˆ†ä¸è¢«æ›´æ–°ã€‚<br>å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨PyTorchä¸­çš„åŒ…<code>nn.Dropout()</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line">input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line">output = m(input)</span><br></pre></td></tr></table></figure>
<h3 id="å¯¹lossè¿›è¡Œmask"><a href="#å¯¹lossè¿›è¡Œmask" class="headerlink" title="å¯¹lossè¿›è¡Œmask"></a>å¯¹lossè¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­çš„language modelï¼Œæ¯ä¸ªè¯éƒ½éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œåœ¨ä¸€ä¸ªbatchä¸­å¥å­æ€»æ˜¯æœ‰é•¿æœ‰çŸ­ï¼Œå¯¹äºä¸€ä¸ªçŸ­å¥ï¼Œæ­¤æ—¶åœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œä¼šå‡ºç°è¿™æ ·çš„åœºæ™¯ï¼š<code>&lt;pad&gt;</code>è¯è¦é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>è¯ã€‚ä¸¾ä¸ªä¾‹å­ï¼šä¸‰ä¸ªå¥å­[a,b,c,d],[e,f,g],[h,i]ï¼Œåœ¨ç»„æˆbatchåï¼Œä¼šå˜æˆ<br>Xï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>b</td>
<td>c</td>
<td>d</td>
</tr>
<tr>
<td>e</td>
<td>f</td>
<td>g</td>
<td><code>&lt;pad&gt;</code></td>
</tr>
<tr>
<td>h</td>
<td>i</td>
<td><code>&lt;pad&gt;</code></td>
<td><code>&lt;pad&gt;</code></td>
</tr>
</tbody>
</table>
</div>
<p>Yï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>b</td>
<td>c</td>
<td>d</td>
<td><code>&lt;pad&gt;</code></td>
</tr>
<tr>
<td>f</td>
<td>g</td>
<td><code>&lt;eos&gt;</code></td>
<td><code>&lt;pad&gt;</code></td>
</tr>
<tr>
<td>i</td>
<td><code>&lt;eos&gt;</code></td>
<td><code>&lt;pad&gt;</code></td>
<td><code>&lt;pad&gt;</code></td>
</tr>
</tbody>
</table>
</div>
<p>Xæ˜¯è¾“å…¥ï¼ŒYæ˜¯é¢„æµ‹ã€‚é‚£ä¹ˆä»ç¬¬ä¸‰è¡Œå¯ä»¥çœ‹å‡ºï¼Œ<code>&lt;pad&gt;</code>åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>ã€‚è¿™æ˜¾ç„¶æ˜¯æœ‰é—®é¢˜çš„ã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆå°±æ˜¯ä½¿ç”¨maskçŸ©é˜µï¼Œåœ¨lossçš„è®¡ç®—æ—¶ï¼Œå°†é‚£äº›æœ¬ä¸åº”è¯¥è®¡ç®—çš„maskæ‰ï¼Œä½¿å¾—å…¶lossä¸º0ï¼Œè¿™æ ·å°±ä¸ä¼šåå‘å›ä¼ äº†ã€‚<br>å…·ä½“å®è·µï¼šåœ¨PyTorchä¸­ï¼Œä»¥CrossEntropyä¸ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">nn</span>.<span class="title">CrossEntropyLoss</span><span class="params">(weight=None, size_average=None, ignore_index=<span class="number">-100</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">reduce=None, reduction=â€™elementwise_meanâ€™</span></span></span><br></pre></td></tr></table></figure>
<p>å¦‚æœ<code>reduction=None</code>åˆ™ä¼šè¿”å›ä¸€ä¸ªä¸è¾“å…¥åŒæ ·å¤§å°çš„çŸ©é˜µã€‚åœ¨ä¸maskçŸ©é˜µç›¸ä¹˜åï¼Œå†å¯¹æ–°çŸ©é˜µè¿›è¡Œmeanæ“ä½œã€‚<br>åœ¨PyTorchå®è·µä¸Šè¿˜å¯ä»¥å¯ä»¥è¿™ä¹ˆå†™ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">masked_outputs = torch.masked_select(dec_outputs, mask)</span><br><span class="line">masked_targets = torch.masked_select(targets, mask)</span><br><span class="line">loss = my_criterion(masked_outputs, masked_targets)</span><br></pre></td></tr></table></figure>
<p>å¦ä¸€ç§æ›´ä¸ºç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œç›´æ¥åœ¨CrossEntropyä¸­è®¾<code>ignore_index=0</code>ï¼Œè¿™æ ·ï¼Œåœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œå‘ç°target=0æ—¶ï¼Œä¼šè‡ªåŠ¨ä¸å¯¹å…¶è¿›è¡Œlossçš„è®¡ç®—ã€‚å…¶æœ¬è´¨å’ŒmaskçŸ©é˜µæ˜¯ä¸€è‡´çš„ã€‚</p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>maskçŸ©é˜µå¯ä»¥ç”¨åœ¨ä»»ä½•åœ°æ–¹ï¼Œåªè¦å¸Œæœ›ä¸ä¹‹ç›¸ä¹˜çš„tensorç›¸å¯¹åº”çš„åœ°æ–¹ä¸æ›´æ–°å°±å¯ä»¥è¿›è¡Œmaskæ“ä½œã€‚</p>
]]></content>
      <tags>
        <tag>ä»£ç å®è·µ</tag>
        <tag>maskçŸ©é˜µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ·±åº¦ç‚¼ä¸¹tricksåˆé›†</title>
    <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E7%82%BC%E4%B8%B9tricks%E5%90%88%E9%9B%86/</url>
    <content><![CDATA[<p>â€”-Deprecatedâ€”-</p>
<h2 id="è°ƒå‚æŠ€å·§"><a href="#è°ƒå‚æŠ€å·§" class="headerlink" title="è°ƒå‚æŠ€å·§"></a>è°ƒå‚æŠ€å·§</h2><h3 id="æ•°æ®å¢å¼º"><a href="#æ•°æ®å¢å¼º" class="headerlink" title="æ•°æ®å¢å¼º"></a>æ•°æ®å¢å¼º</h3><h3 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h3><h4 id="1ï¸âƒ£zero-center"><a href="#1ï¸âƒ£zero-center" class="headerlink" title="1ï¸âƒ£zero-center"></a>1ï¸âƒ£zero-center</h4><p>[9]å°†æ•°æ®ä¸­å¿ƒåŒ–</p>
<h3 id="åˆå§‹åŒ–"><a href="#åˆå§‹åŒ–" class="headerlink" title="åˆå§‹åŒ–"></a>åˆå§‹åŒ–</h3><h4 id="1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•"><a href="#1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•" class="headerlink" title="1ï¸âƒ£Xavier initialization[7]æ–¹æ³•"></a>1ï¸âƒ£Xavier initialization[7]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºæ™®é€šæ¿€æ´»å‡½æ•°(tanh,sigmoid)ï¼šscale = np.sqrt(3/n)</p>
<h4 id="2ï¸âƒ£He-initialization-8-æ–¹æ³•"><a href="#2ï¸âƒ£He-initialization-8-æ–¹æ³•" class="headerlink" title="2ï¸âƒ£He initialization[8]æ–¹æ³•"></a>2ï¸âƒ£He initialization[8]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºReLUï¼šscale = np.sqrt(6/n)</p>
<h4 id="3ï¸âƒ£Batch-normalization-10"><a href="#3ï¸âƒ£Batch-normalization-10" class="headerlink" title="3ï¸âƒ£Batch normalization[10]"></a>3ï¸âƒ£Batch normalization[10]</h4><h4 id="4ï¸âƒ£RNN-LSTM-init-hidden-state"><a href="#4ï¸âƒ£RNN-LSTM-init-hidden-state" class="headerlink" title="4ï¸âƒ£RNN/LSTM init hidden state"></a>4ï¸âƒ£RNN/LSTM init hidden state</h4><p>Hinton[3]æåˆ°å°†RNN/LSTMçš„åˆå§‹hidden stateè®¾ç½®ä¸ºå¯å­¦ä¹ çš„weight</p>
<h3 id="è®­ç»ƒæŠ€å·§"><a href="#è®­ç»ƒæŠ€å·§" class="headerlink" title="è®­ç»ƒæŠ€å·§"></a>è®­ç»ƒæŠ€å·§</h3><h4 id="1ï¸âƒ£Gradient-Clipping-5-6"><a href="#1ï¸âƒ£Gradient-Clipping-5-6" class="headerlink" title="1ï¸âƒ£Gradient Clipping[5,6]"></a>1ï¸âƒ£Gradient Clipping[5,6]</h4><h4 id="2ï¸âƒ£learning-rate"><a href="#2ï¸âƒ£learning-rate" class="headerlink" title="2ï¸âƒ£learning rate"></a>2ï¸âƒ£learning rate</h4><p>åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚<br>[1]Time/Drop-based/Cyclical Learning Rate</p>
<h4 id="3ï¸âƒ£batch-size"><a href="#3ï¸âƒ£batch-size" class="headerlink" title="3ï¸âƒ£batch size"></a>3ï¸âƒ£batch size</h4><p>[2]ä¸­è¯¦ç»†è®ºè¿°äº†å¢åŠ batch sizeè€Œä¸æ˜¯å‡å°learning rateèƒ½å¤Ÿæå‡æ¨¡å‹è¡¨ç°ã€‚ä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">How to make your model happy againâ€Šâ€”â€Špart 1</a></p>
<p>[2]<a href="https://arxiv.org/abs/1711.00489" target="_blank" rel="noopener">Donâ€™t Decay the Learning Rate, Increase the Batch Size</a></p>
<p>[3]<a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">CSC2535 2013: Advanced Machine Learning Lecture 10 Recurrent neural networks</a></p>
<p>[4]<a href="https://zhuanlan.zhihu.com/p/25110150" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110150</a></p>
<p>[5]<a href="https://arxiv.org/abs/1211.5063" target="_blank" rel="noopener">On the difficulty of training Recurrent Neural Networks
</a></p>
<p>[6]<a href="https://arxiv.org/abs/1612.08083" target="_blank" rel="noopener">Language Modeling with Gated Convolutional Networks
</a></p>
<p>[7]<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Understanding the difficulty of training deep feedforward neural networks</a></p>
<p>[8]<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></p>
<p>[9]<a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">çŸ¥ä¹ï¼šä½ æœ‰å“ªäº›deep learningï¼ˆrnnã€cnnï¼‰è°ƒå‚çš„ç»éªŒï¼Ÿ</a></p>
<p>[10]<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>
]]></content>
      <tags>
        <tag>è°ƒå‚</tag>
        <tag>tricks</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯11</title>
    <url>/2018/10/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D11/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"><a href="#1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«" class="headerlink" title="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"></a>1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«</h3><p>[å”] ç™½å±…æ˜“<br>ç¦»ç¦»åŸä¸Šè‰ï¼Œä¸€å²ä¸€æ¯è£ã€‚<br><strong>é‡ç«çƒ§ä¸å°½ï¼Œæ˜¥é£å¹åˆç”Ÿ</strong>ã€‚<br>è¿œèŠ³ä¾µå¤é“ï¼Œæ™´ç¿ æ¥è’åŸã€‚<br>åˆé€ç‹å­™å»ï¼Œè‹è‹æ»¡åˆ«æƒ…ã€‚</p>
<p>è‹è‹ï¼ˆqÄ«ï¼‰ï¼šå½¢å®¹è‰æœ¨é•¿å¾—èŒ‚ç››çš„æ ·å­ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>PRMLç¬¬ä¸‰ç«  å›å½’çš„çº¿æ€§æ¨¡å‹</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%9B%9E%E5%BD%92%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"><a href="#çº¿æ€§åŸºå‡½æ•°æ¨¡å‹" class="headerlink" title="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"></a>çº¿æ€§åŸºå‡½æ•°æ¨¡å‹</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-51-50.jpg" alt="0"></p>
<p><img src="/images/2018-10-07-Xnip2018-10-07_15-53-54.jpg" alt="1"></p>
<h1 id="åç½®-â½…å·®åˆ†è§£"><a href="#åç½®-â½…å·®åˆ†è§£" class="headerlink" title="åç½®-â½…å·®åˆ†è§£"></a>åç½®-â½…å·®åˆ†è§£</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-56-30.jpg" alt="0"></p>
<h1 id="è´å¶æ–¯çº¿æ€§å›å½’"><a href="#è´å¶æ–¯çº¿æ€§å›å½’" class="headerlink" title="è´å¶æ–¯çº¿æ€§å›å½’"></a>è´å¶æ–¯çº¿æ€§å›å½’</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_16-13-57.jpg" alt="1"></p>
<h1 id="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"><a href="#è´å¶æ–¯æ¨¡å‹â½è¾ƒ" class="headerlink" title="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"></a>è´å¶æ–¯æ¨¡å‹â½è¾ƒ</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_23-30-33.jpg" alt="1"></p>
<h1 id="è¯æ®è¿‘ä¼¼"><a href="#è¯æ®è¿‘ä¼¼" class="headerlink" title="è¯æ®è¿‘ä¼¼"></a>è¯æ®è¿‘ä¼¼</h1><p><img src="/images/2018-10-09-Xnip2018-10-09_22-06-22.jpg" alt="1"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>PRML</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 16:SVM</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2016:%20SVM/</url>
    <content><![CDATA[<p><strong>Hinge Loss+kernel method = SVM</strong></p>
<h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><p>SVMä¸logistic regressionçš„åŒºåˆ«å³åœ¨äºloss functionçš„ä¸åŒï¼Œlogisticæ˜¯cross entropyï¼Œè€ŒSVMæ˜¯hinge loss<br><img src="/images/2018-10-07-15388878731499.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³å¦‚æœåˆ†ç±»é—´éš”å¤§äº1ï¼Œåˆ™ $L(m_i)=max(0,1âˆ’m_i(w))$ï¼Œåˆ™æŸå¤±ä¸º0ã€‚å› æ­¤SVMæ›´å…·é²æ£’æ€§ï¼Œå› ä¸ºå¯¹ç¦»ç¾¤ç‚¹ä¸æ•æ„Ÿã€‚</p>
<p>å¯¹äºlinear SVMï¼š</p>
<ul>
<li>å®šä¹‰å‡½æ•° $f(x)=\sum_i w_i x_i +b=w^T x$</li>
<li>å®šä¹‰æŸå¤±å‡½æ•°  $L(f)=\sum_n l(f(x^n),\hat{y}^n)+\lambda ||w||_2$ï¼Œå…¶ä¸­$l(f(x^n),\hat{y}^n)=max(0,1-\hat{y}^n f(x))$</li>
<li><p>æ¢¯åº¦ä¸‹é™æ±‚è§£ï¼ˆçœç•¥äº†æ­£åˆ™åŒ–ï¼‰</p>
<script type="math/tex; mode=display">\frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{w_i}}=
  \frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{f(x^n)}}  \frac{\partial{f(x^n)}}{\partial{w_i}} x_i^n</script><p>  è€Œ</p>
<script type="math/tex; mode=display">f(x^n)=w^T \cdot x^n</script></li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial{max(0,1-\hat{y}^n f(x^n)})}{\partial{f(x^n)}}=
\left\{  
             \begin{array}{**lr**}  
              -\hat{y}^n & if  \hat{y}^n f(x^n)<1 \\  
               0  & otherwise &    
             \end{array}  
\right.</script><p>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388891611785.jpg" width="55%" height="50%"><br>æˆ‘ä»¬æ¥ä¸‹æ¥ç”¨$c^n(w)$æ›¿ä»£$-\delta(\hat{y}^n f(x^n)&lt;1) \hat{y}^n$</p>
<h3 id="Kernel-Method"><a href="#Kernel-Method" class="headerlink" title="Kernel Method"></a>Kernel Method</h3><p>ä¸€ä¸ªäº‹å®ï¼š$w$æ˜¯$x$çš„çº¿æ€§åŠ å’Œï¼Œå…¶ä¸­$Î±$ä¸ç­‰äº0å¯¹åº”çš„$x$å°±æ˜¯support vectors</p>
<p>è¯æ˜ï¼š<br>æˆ‘ä»¬å‰é¢è¯´è¿‡ï¼Œæ›´æ–°è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-07-15388894194698.jpg" width="30%" height="50%"></p>
<p>å°†å…¶ç»„ç»‡æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/2018-10-07-15388894627632.jpg" width="25%" height="50%"></p>
<p><strong>å¦‚æœæˆ‘ä»¬å°†$w$åˆå§‹åŒ–æˆ0å‘é‡</strong>ï¼Œé‚£ä¹ˆ$w$æœ€ç»ˆå°±æ˜¯$x$çš„çº¿æ€§ç»„åˆã€‚è¯æ¯•</p>
<p>å› ä¸º$c(w)$æ˜¯hinge lossï¼Œå› æ­¤å¤§å¤šæ•°çš„å€¼æ˜¯0ï¼Œä¼šé€ æˆ$Î±$ç¨€ç–ã€‚<br>å¦‚æœæˆ‘ä»¬å°†è®­ç»ƒæ•°æ®$x$ç»„ç»‡æˆä¸€ä¸ªçŸ©é˜µï¼Œé‚£ä¹ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388895570090.jpg" width="25%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-07-15388895870336.jpg" width="40%" height="50%"></p>
<p>æ‰€ä»¥å¯¹äº$f(x)$ï¼Œæœ‰ï¼š<br><img src="/images/2018-10-07-15388896378645.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Š$X^Tx$å°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®å’Œ$x$è¿›è¡Œç‚¹ç§¯çš„ç»“æœï¼Œä½†å®é™…ä¸Šçº¿æ€§å‡½æ•°å¾€å¾€è¡¨è¾¾èƒ½åŠ›ä¸å¼ºï¼Œæˆ‘ä»¬å¸Œæœ›$x$èƒ½å¤Ÿå˜æˆéçº¿æ€§çš„ã€‚å¦‚æœæˆ‘ä»¬å¼•å…¥kernelï¼Œå°†ç‚¹ç§¯æ¢æˆkernelï¼Œåˆ™ä¼šæœ‰ï¼š</p>
<script type="math/tex; mode=display">f(x)=\sum_n \alpha_n (x_n\cdot x)=\sum_n \alpha_n K(x_n,x)</script><p>æ‰€ä»¥æˆ‘ä»¬çš„é—®é¢˜å°±å˜æˆäº†ï¼š</p>
<ul>
<li>å®šä¹‰å‡½æ•° $f(x)=\sum_n \alpha_n K(x_n,x)$</li>
<li>æ‰¾åˆ°æœ€ä½³çš„Î±ï¼Œæœ€å°åŒ–loss functionï¼š$L(f)=\sum_n l(f(x^n),\hat{y}^n)=\sum_n l(\sum_{nâ€™} \alpha_{nâ€™} K(x^{n^{â€˜}},x^n),\hat{y}^n)$</li>
</ul>
<p>å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦çœŸçš„çŸ¥é“$x$çš„éçº¿æ€§çš„å…·ä½“å½¢å¼ï¼Œæˆ‘ä»¬åªéœ€è¦ä¼šç®—$K$å°±è¡Œï¼Œè¿™ç§ç»•è¿‡$x$çš„å…·ä½“å½¢å¼çš„æ–¹æ³•å°±æ˜¯<strong>kernel trick</strong>ã€‚ç›´æ¥è®¡ç®—$K$ï¼Œæ¯”å…ˆå°†$x$éçº¿æ€§è½¬åŒ–å†åšç‚¹ç§¯æ¥å¾—é«˜æ•ˆã€‚ç”šè‡³æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å¯¹$x$åšçš„éçº¿æ€§æ˜¯æ— ç©·å¤šç»´çš„ï¼Œæ˜¯æ— æ³•ç›´æ¥åšéçº¿æ€§åŒ–çš„ã€‚æ¯”å¦‚RBFæ ¸:</p>
<script type="math/tex; mode=display">K(x,z)=exp(-\frac{1}{2}||x-z||_2)</script><p>é€šè¿‡æ³°å‹’å±•å¼€å¯ä»¥çŸ¥é“ï¼ŒRBFæ ¸æ˜¯æ— ç©·ç»´çš„ã€‚</p>
<p>å¦ä¸€ä¸ªkernelçš„ä¾‹å­æ˜¯sigmoid kernelï¼š</p>
<script type="math/tex; mode=display">K(x,z)=tanh(x\cdot z)</script><p>å½“æˆ‘ä»¬ä½¿ç”¨sigmoid kernelæ—¶ï¼Œå°±ç›¸å½“äºä¸€å±‚hidden layerçš„ç¥ç»ç½‘ç»œï¼Œå¦‚å›¾ï¼š<br><img src="/images/2018-10-07-15388901736757.jpg" width="40%" height="50%"></p>
<p>ç»™å®šä¸€ä¸ªè¾“å…¥ï¼Œå…±æœ‰nä¸ªneuronï¼Œå…¶ä¸­çš„weightå°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®çš„å‘é‡å€¼ï¼Œç„¶åå†å°†è¿™äº›neuronåŠ å’Œå¾—åˆ°è¾“å‡ºã€‚å½“ç„¶å¤§éƒ¨åˆ†çš„Î±çš„å€¼æ˜¯0ï¼Œå› æ­¤å®è´¨ä¸Šç¥ç»å…ƒçš„ä¸ªæ•°å’Œsupport vectorçš„ä¸ªæ•°ä¸€è‡´ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥ç›´æ¥è®¾è®¡kernelï¼Œè€Œä¸éœ€è¦è€ƒè™‘xçš„éçº¿æ€§å˜æ¢çš„å½¢å¼ï¼Œåªè¦kernelç¬¦åˆmercerâ€™s theoryå³å¯ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 15:Transfer Learning</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2015:%20Transfer%20Learning/</url>
    <content><![CDATA[<h3 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h3><p>å‡è®¾æˆ‘ä»¬æœ‰å¾ˆå¤šçš„source data $(x^s,y^s )$ï¼Œä¸ä»»åŠ¡ç›¸å…³çš„target data $(x^t,y^t )$  å¾ˆå°‘ã€‚<br>æˆ‘ä»¬åˆ©ç”¨source dataè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åç”¨target dataæ¥fine tuneæ¨¡å‹ã€‚</p>
<h4 id="conservative-training"><a href="#conservative-training" class="headerlink" title="conservative training"></a>conservative training</h4><p><img src="/images/2018-10-07-15388871902739.jpg" width="50%" height="50%"></p>
<p>æˆ‘ä»¬å¯ä»¥ç”¨source dataè®­ç»ƒå¥½çš„æ¨¡å‹çš„weightä½œä¸ºæ–°çš„æ¨¡å‹çš„weightï¼Œç„¶åè®¾å®šä¸€äº›é™åˆ¶ï¼Œæ¯”å¦‚source dataä½œä¸ºè¾“å…¥çš„outputåº”å’Œtarget dataä½œä¸ºè¾“å…¥çš„outputå°½é‡ç›¸ä¼¼ï¼Œæˆ–è€…å‚æ•°å°½é‡ç›¸ä¼¼ç­‰ã€‚</p>
<h4 id="layer-transfer"><a href="#layer-transfer" class="headerlink" title="layer transfer"></a>layer transfer</h4><p>ä¹Ÿå°±æ˜¯æ–°æ¨¡å‹æœ‰å‡ å±‚æ˜¯ç›´æ¥copyæ—§æ¨¡å‹çš„ï¼Œåªè®­ç»ƒå…¶å®ƒå±‚ã€‚æ³¨æ„åˆ°ä¸åŒä»»åŠ¡æ‰€åº”copyçš„å±‚æ˜¯ä¸åŒçš„ï¼Œè¯­éŸ³ä»»åŠ¡æœ€åå‡ å±‚æ•ˆæœå¥½ï¼Œå›¾åƒè¯†åˆ«å‰é¢å‡ å±‚æ•ˆæœå¥½</p>
<h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p>ä¸åŒä»»åŠ¡ä¹‹é—´å…±äº«ç›¸åŒçš„ä¸­é—´å±‚ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388872452545.jpg" width="30%" height="50%"><br><img src="/images/2018-10-07-15388872627707.jpg" width="30%" height="50%"></p>
<p>è¿˜æœ‰ä¸€ç§progressive neural networksï¼š<br><img src="/images/2018-10-07-15388872920224.jpg" width="50%" height="50%"><br>é¦–å…ˆè®­ç»ƒå¥½ç¬¬ä¸€ä¸ªä»»åŠ¡çš„æ¨¡å‹ï¼Œç„¶ååœ¨è®­ç»ƒç¬¬äºŒä¸ªæ¨¡å‹çš„æ—¶å€™å°†ç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬äºŒä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼›è®­ç»ƒç¬¬ä¸‰ä¸ªæ¨¡å‹åˆ™å°†ç¬¬äºŒä¸ªå’Œç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬ä¸‰ä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼Œä»¥æ­¤ç±»æ¨</p>
<h3 id="Domain-adversarial-training"><a href="#Domain-adversarial-training" class="headerlink" title="Domain-adversarial training"></a>Domain-adversarial training</h3><p>source dataæ˜¯æœ‰æ ‡ç­¾çš„ï¼Œè€Œtarget dataæ˜¯æ— æ ‡ç­¾çš„ï¼Œéƒ½å±äºåŒä¸€ä¸ªä»»åŠ¡ï¼Œä½†æ•°æ®æ˜¯mismatchçš„ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388873325090.jpg" width="50%" height="50%"></p>
<p>å› ä¸ºNNçš„éšå±‚å¯ä»¥ç†è§£æˆæ˜¯åœ¨æŠ½å–å›¾åƒçš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿåœ¨è®­ç»ƒNNçš„è¿‡ç¨‹ä¸­å»æ‰source dataçš„ä¸€äº›domain specificçš„ç‰¹æ€§ï¼Œè¿™æ ·å°±å¯ä»¥ç”¨åœ¨target dataä¸Šäº†ã€‚å› æ­¤æˆ‘ä»¬åœ¨feature exactoråé¢è¿æ¥ä¸¤ä¸ªæ¨¡å—ï¼š<br><img src="/images/2018-10-07-15388873772888.jpg" width="50%" height="50%"></p>
<p>ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›æŠ½å–çš„ç‰¹å¾èƒ½å¤Ÿä½¿å¾—åˆ†ç±»å™¨æ­£ç¡®åœ°åˆ†ç±»ï¼Œå¦ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›è¿™äº›ç‰¹å¾èƒ½å¤Ÿè®©domain classifierèƒ½å¤Ÿæ— æ³•è¯†åˆ«ç‰¹å¾æ˜¯ä»å“ªäº›dataæŠ½å–å¾—åˆ°çš„ï¼Œè¿™æ ·å¾—åˆ°çš„ç‰¹å¾å°±æ˜¯è¢«å»æ‰domain specificç‰¹å¾çš„ã€‚</p>
<p>å…·ä½“è®­ç»ƒï¼š<br><img src="/images/2018-10-07-15388874447304.jpg" width="50%" height="50%"></p>
<h3 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h3><p>source dataæœ‰æ ‡ç­¾ï¼Œtarget dataæ— æ ‡ç­¾ï¼Œä½†ä»»åŠ¡ä¸åŒï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388874838165.jpg" width="50%" height="50%"></p>
<h4 id="Representing-each-class-by-its-attributes"><a href="#Representing-each-class-by-its-attributes" class="headerlink" title="Representing each class by its attributes"></a>Representing each class by its attributes</h4><p>ä¸€ç§æ–¹æ³•æ˜¯å°†æ¯ä¸€ä¸ªç±»éƒ½ç”¨ç‰¹å¾è¡¨ç¤ºï¼Œä½†ç‰¹å¾è¦è¶³å¤Ÿä¸°å¯Œï¼š<br><img src="/images/2018-10-07-15388875088114.jpg" width="50%" height="50%"></p>
<p>åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å…¥æ˜¯å›¾ç‰‡ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™äº›ç‰¹å¾ï¼š<br><img src="/images/2018-10-07-15388875558853.jpg" width="40%" height="50%"><br>è¿™æ ·åœ¨å°†target dataæ”¾å…¥è®­ç»ƒå¥½çš„NNåä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªè¿™æ ·çš„attributeï¼ŒæŸ¥è¡¨å³å¯æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ç‰¹å¾å¯¹åº”çš„ç±»ã€‚</p>
<h4 id="Attribute-embedding"><a href="#Attribute-embedding" class="headerlink" title="Attribute embedding"></a>Attribute embedding</h4><p>å¦‚æœç‰¹å¾ç»´åº¦å¤ªé«˜ï¼Œä¹Ÿå¯ä»¥å°†ç‰¹å¾å‹ç¼©æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œè¿™æ ·åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™æ ·çš„å‘é‡ç‰¹å¾ï¼Œè¾“å…¥target dataï¼Œè¾“å‡ºå‘é‡ç‰¹å¾ï¼Œæ‰¾åˆ°æœ€è¿‘çš„ç‰¹å¾å¯¹åº”çš„ç±»å³å¯<br><img src="/images/2018-10-07-15388875888699.jpg" width="50%" height="50%"></p>
<h4 id="Attribute-embedding-word-embedding"><a href="#Attribute-embedding-word-embedding" class="headerlink" title="Attribute embedding + word embedding"></a>Attribute embedding + word embedding</h4><p>å¦‚æœæ²¡æœ‰attributeæ•°æ®ï¼Œåˆ©ç”¨word embeddingä¹Ÿå¯ä»¥è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚<br>åœ¨zero-shot learningä¸­ï¼Œå…‰æ˜¯è®©ç›¸åŒç±»çš„få’Œgç›¸ä¼¼æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜åº”è¯¥è®©ä¸åŒçš„få’Œgå°½é‡è¿œã€‚</p>
<script type="math/tex; mode=display">f^âˆ—,g^âˆ—=arg min_{(f,g)}â¡âˆ‘_nmax(0,kâˆ’f(x^n )\cdot g(y^n )+max_{(mâ‰ n)} â¡f(x^m )\cdot g(x^m ) )</script>]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Transfer Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 14:Unsupervised Learning:Generation</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2014:%20Unsupervised%20Learning:%20Generation/</url>
    <content><![CDATA[<h3 id="Component-by-component"><a href="#Component-by-component" class="headerlink" title="Component-by-component"></a>Component-by-component</h3><p>å¯¹äºå›¾åƒæ¥è¯´ï¼Œæ¯æ¬¡ç”Ÿæˆä¸€ä¸ªpixelï¼šPixelRNN</p>
<h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>æ¶æ„ï¼š<br><img src="/images/2018-10-07-15388837191574.jpg" width="50%" height="50%"></p>
<p>å…¶ä¸­eæ˜¯å™ªå£°ï¼ŒÏƒæ˜¯æ–¹å·®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–reconstruction errorï¼Œä»¥åŠä¸€ä¸ªé™åˆ¶ã€‚è¯¥é™åˆ¶çš„ç›®çš„å³é˜²æ­¢Ïƒ=0ï¼Œmæ˜¯æ­£åˆ™åŒ–é¡¹ã€‚</p>
<p><del>ä¸­é—´çš„æ¨å¯¼ä»¥åŠä¸ºä»€ä¹ˆæ˜¯è¿™æ ·çš„æ¶æ„æˆ‘è¿˜ä¸æ˜¯å¾ˆæ‡‚ï¼Œä¹‹åå†æ›´æ–°ã€‚</del><br>å®é™…ä¸Šå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œæœ‰å‡ ä¸ªè¦ç‚¹ï¼š</p>
<ul>
<li>é¦–å…ˆæˆ‘ä»¬æ˜¯åŸºäºè¿™ä¹ˆä¸€ä¸ªå‡è®¾ï¼šä¸­é—´çš„codeåº”å½“æ˜¯æœä»æ­£æ€åˆ†å¸ƒçš„ï¼Œè€Œencoderçš„ä½œç”¨å³åœ¨äºæ‹Ÿåˆè¯¥æ­£æ€åˆ†å¸ƒçš„å‡å€¼ä¸æ–¹å·®çš„å¯¹æ•°ï¼ˆå› ä¸ºæ–¹å·®åº”å½“æ’ä¸ºæ­£ï¼Œä½†ç¥ç»ç½‘ç»œçš„è¾“å‡ºå¯èƒ½æœ‰æ­£æœ‰è´Ÿï¼‰</li>
<li>å¦‚æœç”Ÿæˆå‡ºæ¥çš„codeä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œä¼šæœ‰ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œä¹Ÿå°±æ˜¯ä¸Šå›¾çš„constraintï¼ˆå¯ä»¥é€šè¿‡KLæ•£åº¦æ¨å¯¼è·å¾—ï¼‰</li>
<li>æŒ‰ç†è¯´ï¼Œåº”å½“æ˜¯åœ¨ç”Ÿæˆäº†å‡å€¼å’Œæ–¹å·®åï¼Œå®šä¹‰å¥½è¯¥æ­£æ€åˆ†å¸ƒï¼Œç„¶åå†ä»ä¸­é‡‡æ ·ï¼Œä½†æ˜¯è¿™æ ·æ²¡åŠæ³•å›ä¼ æ›´æ–°æ¢¯åº¦ï¼Œå› æ­¤è¿™é‡Œä½¿ç”¨é‡å‚æ•°æŠ€å·§(Reparameterization Trick)ï¼Œä¹Ÿå³ä»$N(\mu,\sigma^2)$ä¸­é‡‡æ ·$Z$ï¼Œç›¸å½“äºä»$N(0,I)$ä¸­é‡‡æ ·$\varepsilon$ï¼Œç„¶åè®©$Z=\mu + \varepsilon \times \mu$</li>
</ul>
<p><img src="/images/2018-10-08-15389638077301.jpg" width="70%" height="50%"></p>
<p><strong>Reference</strong>:<br><a href="https://www.sohu.com/a/226209674_500659" target="_blank" rel="noopener">https://www.sohu.com/a/226209674_500659</a></p>
<p>VAEçš„ä¸»è¦é—®é¢˜åœ¨äºï¼Œç½‘ç»œåªè¯•å›¾å»è®°ä½è§è¿‡çš„å›¾åƒï¼Œä½†æ²¡æ³•çœŸæ­£å»ç”Ÿæˆæ²¡è§è¿‡çš„å›¾åƒã€‚</p>
<h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network (GAN)"></a>Generative Adversarial Network (GAN)</h3><p>GANåŒ…å«ä¸€ä¸ªdiscriminatorå’Œä¸€ä¸ªgeneratorï¼Œgeneratorè¯•å›¾ç”Ÿæˆèƒ½å¤Ÿéª—è¿‡discriminatorçš„æ ·æœ¬ï¼Œè€Œgeneratorè¯•å›¾èƒ½å¤Ÿå°†generatorç”Ÿæˆçš„æ ·æœ¬å’ŒçœŸå®çš„æ ·æœ¬åŒºåˆ†ã€‚</p>
<p>ä¹‹åä¼šæœ‰è¯¦ç»†çš„ä»‹ç»ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Unsupervised Learning</tag>
        <tag>Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 13:Unsupervised Learning:Auto-encoder</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2013:%20Unsupervised%20Learning:%20Auto-encoder/</url>
    <content><![CDATA[<h3 id="Auto-encoder"><a href="#Auto-encoder" class="headerlink" title="Auto-encoder"></a>Auto-encoder</h3><p>ç”±ä¸€ä¸ªencoderå’Œä¸€ä¸ªdecoderç»„æˆï¼Œencoderè´Ÿè´£å°†è¾“å…¥è½¬æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼ˆç»´åº¦é€šå¸¸å°äºè¾“å…¥ï¼‰ï¼Œdecoderè´Ÿè´£å°†è¿™æ®µå‘é‡è¡¨ç¤ºæ¢å¤æˆåŸæ¥çš„è¾“å…¥ã€‚é‚£ä¹ˆä¸­é—´çš„codeå°±å¯ä»¥ä½œä¸ºè¾“å…¥çš„ä¸€ä¸ªä½ç»´è¡¨ç¤ºï¼š<br><img src="/images/2018-10-07-15388832782913.jpg" width="50%" height="50%"></p>
<h3 id="Auto-encoder-for-CNN"><a href="#Auto-encoder-for-CNN" class="headerlink" title="Auto-encoder for CNN"></a>Auto-encoder for CNN</h3><p><img src="/images/2018-10-07-15388833149617.jpg" width="50%" height="50%"></p>
<h4 id="Unpooling"><a href="#Unpooling" class="headerlink" title="Unpooling"></a>Unpooling</h4><p>æœ‰ä¸¤ç§æ–¹æ³•ï¼Œä¸€ç§åœ¨poolingçš„æ—¶å€™è®°å½•æœ€å¤§å€¼çš„ä½ç½®ï¼Œåœ¨unpoolingæ—¶åœ¨ç›¸å¯¹ä½ç½®å¡«å……æœ€å¤§å€¼ï¼Œå…¶ä»–ä½ç½®å¡«å……0ï¼›å¦ä¸€ç§ä¸è®°å½•æœ€å¤§å€¼ä½ç½®ï¼Œç›´æ¥åœ¨poolingåŒºåŸŸå…¨éƒ¨å¡«å……æœ€å¤§å€¼ã€‚<br><img src="/images/2018-10-07-15388833530548.jpg" width="50%" height="50%"></p>
<h4 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h4><p>å…¶å®æœ¬è´¨å°±æ˜¯convolutionã€‚</p>
<p>è¿™æ˜¯convolution:</p>
<p><img src="/images/2018-10-07-15388834044149.jpg" width="10%" height="50%"></p>
<p>æˆ‘ä»¬æœŸå¾…çš„convolutionï¼š<br><img src="/images/2018-10-07-15388834434741.jpg" width="15%" height="50%"></p>
<p>å®é™…ä¸Šå°±ç­‰ä»·åœ¨ä¸¤è¾¹åšpaddingï¼Œç„¶åç›´æ¥convolutionï¼š<br><img src="/images/2018-10-07-15388834751493.jpg" width="15%" height="50%"></p>
<h3 id="Auto-encoderçš„ç”¨å¤„"><a href="#Auto-encoderçš„ç”¨å¤„" class="headerlink" title="Auto-encoderçš„ç”¨å¤„"></a>Auto-encoderçš„ç”¨å¤„</h3><p>å¯ä»¥é¢„è®­ç»ƒæ¯ä¸€å±‚çš„DNNï¼š<br><img src="/images/2018-10-07-15388835335550.jpg" width="50%" height="50%"></p>
<p>åŒç†å…¶å®ƒå±‚ä¹Ÿæ˜¯ä¸€æ ·ï¼Œæ¯æ¬¡fixä½å…¶ä»–å±‚ç„¶ååšAuto-encoderã€‚é‚£ä¹ˆåœ¨bpçš„æ—¶å€™åªéœ€è¦fine-tuneå°±è¡Œã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Unsupervised Learning</tag>
        <tag>Auto-encoder</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 12:Unsupervised Learning:Neighbor Embedding</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2012:%20Unsupervised%20Learning:%20Neighbor%20Embedding/</url>
    <content><![CDATA[<h3 id="Locally-Linear-Embedding-LLE"><a href="#Locally-Linear-Embedding-LLE" class="headerlink" title="Locally Linear Embedding (LLE)"></a>Locally Linear Embedding (LLE)</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>æ€æƒ³ï¼šå‡è®¾æ¯ä¸ªç‚¹å¯ä»¥ç”±å…¶å‘¨å›´çš„ç‚¹æ¥è¡¨ç¤º<br><img src="/images/2018-10-07-15388822769215.jpg" width="25%" height="50%"></p>
<p>æˆ‘ä»¬éœ€è¦æ‰¾åˆ°è¿™æ ·çš„$w_{ij}$ï¼Œä½¿å¾—ï¼š</p>
<script type="math/tex; mode=display">âˆ‘_iâ€–x^iâˆ’âˆ‘_j w_{ij} x^j â€–_2</script><p>è¿™æ ·åœ¨é™ç»´çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä»ç„¶ä¿æŒxä¹‹é—´çš„è¿™æ ·çš„å…³ç³»:<br><img src="/images/2018-10-07-15388823792351.jpg" width="50%" height="50%"></p>
<h3 id="Laplacian-Eigenmaps"><a href="#Laplacian-Eigenmaps" class="headerlink" title="Laplacian Eigenmaps"></a>Laplacian Eigenmaps</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>åŸºæœ¬æ€æƒ³ï¼šå¦‚æœ$x^1$ä¸$x^2$åœ¨é«˜ç»´ç©ºé—´ä¸­ç›¸è¿‘ï¼Œåˆ™é™ç»´åä¹Ÿåº”è¯¥æ¥è¿‘ï¼š</p>
<script type="math/tex; mode=display">S=1/2 âˆ‘_{i,j} w_{i,j} (z^iâˆ’z^j )^2</script><p>å…¶ä¸­ï¼š<br><img src="/images/2018-10-07-15388824984809.jpg" width="30%" height="50%"></p>
<p>å¦‚æœå°†zå…¨è®¾ä¸º0ï¼Œæ˜¾ç„¶Sæœ€å°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ç»™zä¸€ä¸ªé™åˆ¶ï¼šzåº”å½“å……æ»¡ç©ºé—´ï¼Œä¹Ÿå³å‡å¦‚zæ˜¯Mç»´ï¼Œé‚£ä¹ˆ$\{z^1,z^2â€¦,z^N\}$çš„ç§©åº”è¯¥ç­‰äºM</p>
<h3 id="T-distributed-Stochastic-Neighbor-Embedding-t-SNE"><a href="#T-distributed-Stochastic-Neighbor-Embedding-t-SNE" class="headerlink" title="T-distributed Stochastic Neighbor Embedding (t-SNE)"></a>T-distributed Stochastic Neighbor Embedding (t-SNE)</h3><p>ä¹Ÿæ˜¯ä¸€ç§é™ç»´æ–¹æ³•<br>å‰é¢æåˆ°çš„æ–¹æ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼šåŒä¸€ç±»çš„ç‚¹ç¡®å®èšåœ¨ä¸€èµ·ï¼Œä½†ä¸åŒç±»çš„ç‚¹å¹¶æ²¡æœ‰å°½é‡åˆ†å¼€<br><img src="/images/2018-10-07-15388826477983.jpg" width="50%" height="50%"></p>
<p>t-SNEçš„ä¸»è¦æ€æƒ³ï¼šå°†æ•°æ®ç‚¹æ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¸Œæœ›é™ç»´å‰å’Œé™ç»´åï¼Œæ•°æ®åˆ†å¸ƒçš„æ¦‚ç‡åº”å½“å°½å¯èƒ½ä¸€è‡´ã€‚<br>t-SNEæ„å»ºä¸€ä¸ªé«˜ç»´å¯¹è±¡ä¹‹é—´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—ç›¸ä¼¼çš„å¯¹è±¡æœ‰æ›´é«˜çš„æ¦‚ç‡è¢«é€‰æ‹©ï¼Œè€Œä¸ç›¸ä¼¼çš„å¯¹è±¡æœ‰è¾ƒä½çš„æ¦‚ç‡è¢«é€‰æ‹©ã€‚t-SNEåœ¨ä½ç»´ç©ºé—´é‡Œåœ¨æ„å»ºè¿™äº›ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—è¿™ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´å°½å¯èƒ½çš„ç›¸ä¼¼ã€‚</p>
<p>å¦‚ä½•åšï¼Ÿ<br>åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰ï¼š</p>
<script type="math/tex; mode=display">P(x^j |x^i )=\frac{S(x^i,x^j )}{âˆ‘_{kâ‰ i}S(x^i,x^k )}</script><p>å…¶ä¸­Sè¡¨ç¤ºiä¸jä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</p>
<p>åœ¨ä½ç»´ç©ºé—´ä¸­ï¼ŒåŒæ ·æœ‰ï¼š</p>
<script type="math/tex; mode=display">Q(z^j |z^i )=\frac{Sâ€²(z^i,z^j )}{âˆ‘_{kâ‰ i}Sâ€²(z^i,z^k )}</script><p>ä½¿ç”¨KLæ•£åº¦å»è®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼š</p>
<script type="math/tex; mode=display">L=âˆ‘_i KL(P(âˆ—|x^i )||Q(âˆ—|z^i )) =âˆ‘_iâˆ‘_j P(x^j |x^i )\frac{log P(x^j |x^i )}{Q(z^j |z^i )}</script><p>t-SNEä¸­ï¼Œé«˜ç»´ç©ºé—´å’Œä½ç»´ç©ºé—´è®¡ç®—ç›¸ä¼¼åº¦çš„å…¬å¼ä¸å¤§ä¸€æ ·ï¼š</p>
<script type="math/tex; mode=display">S(x^i,x^j )=exp(âˆ’â€–x^iâˆ’x^j â€–_2 )</script><script type="math/tex; mode=display">Sâ€²(z^i,z^j )=\frac{1}{(1+â€–z^iâˆ’z^j â€–_2)}</script><p>ä¸¤ä¸ªå…¬å¼çš„å›¾ç¤ºï¼š<br><img src="/images/2018-10-07-15388830652023.jpg" width="70%" height="50%"></p>
<p>ä¹Ÿå³<strong>ä½ç»´ç©ºé—´ä¼šæ‹‰é•¿è·ç¦»ï¼Œä½¿å¾—è·ç¦»è¿œçš„ç‚¹å°½å¯èƒ½è¢«æ‹‰å¼€</strong>ã€‚</p>
<p>t-SNEçš„é—®é¢˜åœ¨äºï¼št-SNEæ— æ³•å¯¹æ–°çš„æ•°æ®ç‚¹è¿›è¡Œé™ç»´ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Unsupervised Learning</tag>
        <tag>Neighbor Embedding</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 11:Unsupervised Learning:Linear Dimension Reduction</title>
    <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2011:%20Unsupervised%20Learning:%20Linear%20Dimension%20Reduction/</url>
    <content><![CDATA[<h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>ç®—æ³•æ­¥éª¤ï¼š<br><img src="/images/2018-10-07-15388800377875.jpg" width="70%" height="50%"></p>
<p>è¿­ä»£æ›´æ–°ä½¿å¾—æœ€åèšç±»ä¸­å¿ƒæ”¶æ•›ã€‚ä½†äº‹å…ˆéœ€è¦å®šå¥½æœ‰å¤šå°‘ç±»ã€‚</p>
<h3 id="Hierarchical-Agglomerative-Clustering-HAC"><a href="#Hierarchical-Agglomerative-Clustering-HAC" class="headerlink" title="Hierarchical Agglomerative Clustering (HAC)"></a>Hierarchical Agglomerative Clustering (HAC)</h3><p>è‡ªä¸‹è€Œä¸Šï¼Œæ¯æ¬¡é€‰ä¸¤ä¸ªæœ€è¿‘çš„èšä¸ºä¸€ç±»ï¼Œç›´åˆ°æ‰€æœ‰çš„éƒ½åˆ†æˆä¸€ç±»<br>æœ€åé€‰æ‹©ä¸€ä¸ªé˜ˆå€¼åˆ’åˆ†ï¼Œå¦‚è“è‰²ç»¿è‰²å’Œçº¢è‰²çš„çº¿<br><img src="/images/2018-10-07-15388801021791.jpg" width="50%" height="50%"></p>
<h2 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h2><p>æ‰¾åˆ°ä¸€ä¸ªæ˜ å°„ï¼Œä½¿å¾—xèƒ½å¤Ÿæ˜ å°„åˆ°ä½ç»´z</p>
<h3 id="Principle-Component-Analysis-PCA"><a href="#Principle-Component-Analysis-PCA" class="headerlink" title="Principle Component Analysis (PCA)"></a>Principle Component Analysis (PCA)</h3><p>ç›®çš„æ˜¯æ‰¾åˆ°ä¸€ä¸ªç»´åº¦ï¼Œä½¿å¾—æŠ•å½±å¾—åˆ°çš„varianceæœ€å¤§ï¼Œä¹Ÿå³æœ€å¤§ç¨‹åº¦ä¿ç•™æ•°æ®çš„å·®å¼‚æ€§ã€‚<br><img src="/images/2018-10-07-15388801830659.jpg" width="50%" height="50%"></p>
<p>å½¢å¼åŒ–å¯ä»¥å†™æˆï¼ˆä¸€ç»´æƒ…å½¢ï¼‰ï¼š</p>
<script type="math/tex; mode=display">Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2</script><p>å…¶ä¸­ï¼š</p>
<script type="math/tex; mode=display">â€–w^1 â€–_2=1</script><script type="math/tex; mode=display">z_1=w^1 \cdot x</script><p>$\overline{z_1}$è¡¨ç¤ºzçš„å‡å€¼</p>
<p>å‡å¦‚æˆ‘ä»¬è¦æŠ•å½±åˆ°å¤šç»´ï¼Œå…¶ä»–ç»´åº¦ä¹Ÿæœ‰åŒæ ·çš„ç›®æ ‡ã€‚å…¶ä¸­æ¯ä¸ªç»´åº¦ä¹‹é—´éƒ½åº”è¯¥æ˜¯ç›¸äº’æ­£äº¤çš„ã€‚<br><img src="/images/2018-10-07-15388804752506.jpg" width="20%" height="50%"></p>
<h4 id="å¦‚ä½•åšï¼Ÿ"><a href="#å¦‚ä½•åšï¼Ÿ" class="headerlink" title="å¦‚ä½•åšï¼Ÿ"></a>å¦‚ä½•åšï¼Ÿ</h4><p>æ‰¾åˆ°$ \frac{1}{N}âˆ‘(xâˆ’\overline{x} ) (xâˆ’\overline{x})^T$çš„å‰kä¸ªæœ€å¤§çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ï¼Œç»„åˆèµ·æ¥å³æ˜¯æˆ‘ä»¬è¦æ‰¾çš„$W$</p>
<h4 id="è¯æ˜"><a href="#è¯æ˜" class="headerlink" title="è¯æ˜"></a>è¯æ˜</h4><p>â€”-Warning of Mathâ€”-<br>ç›®çš„ï¼š$Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2 $<br>å…¶ä¸­ $\overline{z_1} =\frac{1}{N} âˆ‘{z_1} = \frac{1}{N} âˆ‘ w^1 \cdot x=w^1\cdot \overline{x}$</p>
<p>æ¨å¯¼ï¼š<br><img src="/images/2018-10-07-15388811276042.jpg" width="35%" height="50%"><br>æ”¹å˜ç¬¦å· $S=Cov(x)$</p>
<p>åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œæœ‰ï¼š<br>$Sw^1=Î±w^1$<br>ç­‰å¼ä¸¤è¾¹å„å·¦ä¹˜$(w^1)^T$ï¼Œæœ‰ï¼š<br>$(w^1 )^T Sw^1=Î±(w^1 )^T w^1=Î±$</p>
<p>ä¹Ÿå³ï¼Œ$Î±$æ˜¯$S$çš„ç‰¹å¾å€¼ï¼Œé€‰æ‹©æœ€å¤§çš„ç‰¹å¾å€¼ï¼Œå°±èƒ½å¤Ÿæœ€å¤§åŒ–æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
<p>åŒç†ï¼Œæˆ‘ä»¬è¦æ‰¾$w^2$ï¼Œæœ€å¤§åŒ–$(w^2 )^T Sw^2$ï¼Œå…¶ä¸­æœ‰ï¼š<br>$(w^2 )^T w^2=1$<br>$(w^2 )^T w^1=0$ ï¼ˆä¸ç¬¬ä¸€ç»´æ­£äº¤ï¼‰</p>
<p>å› æ­¤åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼š</p>
<script type="math/tex; mode=display">g(w^2 )= (w^2 )^T Sw^2âˆ’Î±((w^2 )^T w^2âˆ’1)âˆ’Î²((w^2 )^T w^1âˆ’0)</script><p>æœ€ç»ˆå¾—åˆ°ï¼Œw2å¯¹åº”ç¬¬äºŒå¤§çš„ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ã€‚</p>
<p>ä»¥æ­¤ç±»æ¨ï¼Œå…¶ä»–ç»´ä¹ŸåŒç†ã€‚<br>â€”-End of Mathâ€”-</p>
<h4 id="PCAçš„å…¶ä»–"><a href="#PCAçš„å…¶ä»–" class="headerlink" title="PCAçš„å…¶ä»–"></a>PCAçš„å…¶ä»–</h4><p>å®é™…ä¸Šæœ€ç»ˆå¾—åˆ°çš„zï¼Œæ¯ä¸€ç»´ä¹‹é—´çš„åæ–¹å·®éƒ½ä¸º0<br><img src="/images/2018-10-07-15388815546680.jpg" width="50%" height="50%"></p>
<p>è¯æ˜å¦‚ä¸‹ï¼š<br><img src="/images/2018-10-07-15388815837458.jpg" width="50%" height="50%"></p>
<p>PCAä¹Ÿå¯ä»¥ç”¨SVDæ¥åšï¼š<br><img src="/images/2018-10-07-15388816250075.jpg" width="60%" height="50%"></p>
<p>Uä¸­ä¿å­˜äº†Kä¸ªç‰¹å¾å‘é‡ã€‚</p>
<p>ä»å¦ä¸€ç§è§’åº¦ç†è§£PCAï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºPCAæ˜¯ä¸€ç§autoencoderï¼š<br><img src="/images/2018-10-07-15388816896369.jpg" width="50%" height="50%"></p>
<h4 id="PCAçš„é—®é¢˜"><a href="#PCAçš„é—®é¢˜" class="headerlink" title="PCAçš„é—®é¢˜"></a>PCAçš„é—®é¢˜</h4><p>PCAæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œå¦‚æœæœ‰æ ‡ç­¾ï¼Œåˆ™æ— æ³•æŒ‰ç…§ç±»åˆ«æ¥è¿›è¡Œæ­£ç¡®é™ç»´ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388817393283.jpg" width="30%" height="50%"></p>
<p>ç¬¬äºŒå°±æ˜¯PCAæ˜¯çº¿æ€§å˜æ¢ï¼Œå¯¹äºä¸€äº›éœ€è¦éçº¿æ€§å˜æ¢çš„æ— èƒ½ä¸ºåŠ›<br><img src="/images/2018-10-07-15388817566149.jpg" width="28%" height="50%"></p>
<h3 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h3><p>å®šä¹‰ï¼šçŸ©é˜µåˆ†è§£ï¼Œå°±æ˜¯å°†ä¸€ä¸ªçŸ©é˜µDåˆ†è§£ä¸ºUå’ŒVçš„ä¹˜ç§¯ï¼Œå³å¯¹äºä¸€ä¸ªç‰¹å®šçš„è§„æ¨¡ä¸ºm*nçš„çŸ©é˜µDï¼Œä¼°è®¡å‡ºè§„æ¨¡åˆ†åˆ«ä¸ºm*kå’Œn*kçš„çŸ©é˜µUå’ŒVï¼Œä½¿å¾—$UV^T$çš„å€¼å°½å¯èƒ½é€¼è¿‘çŸ©é˜µDã€‚å¸¸ç”¨äºæ¨èç³»ç»Ÿã€‚</p>
<p>æ€æƒ³ï¼š<br>å‡å¦‚æœ‰ä¸€ä¸ªçŸ©é˜µï¼š<br><img src="/images/2018-10-07-15388819053983.jpg" width="60%" height="50%"></p>
<p>å‡è®¾æ¨ªè½´å’Œçºµè½´æ¯ä¸€ç»´éƒ½æœ‰ä¸€ä¸ªå‘é‡ä»£è¡¨è¯¥ç»´ï¼ŒçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å°±æ˜¯æ¨ªè½´å’Œçºµè½´å¯¹åº”ç»´çš„ç‚¹ç§¯ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯å°½å¯èƒ½å‡å°ï¼š</p>
<script type="math/tex; mode=display">L=\sum_{(i,j)} (r^i \cdot r^j -n_{ij})^2</script><p>å…¶ä¸­$r_i$ $r_j$å°±æ˜¯å‘é‡è¡¨ç¤ºï¼Œ$n_{ij}$å°±æ˜¯çŸ©é˜µçš„å†…å®¹ã€‚</p>
<p>å¯ä»¥ä½¿ç”¨SVDæ±‚è§£ä¸Šå¼ï¼š<br><img src="/images/2018-10-07-15388820642382.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Šï¼Œè€ƒè™‘æ¯ä¸€è¡Œæˆ–åˆ—æœ¬èº«çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬å¯¹Lossè¿›è¡Œæ‰©å±•ï¼š</p>
<script type="math/tex; mode=display">Minimizing \ \ L=\sum_{(i,j)} (r^i \cdot r^j +b_i+b_j-n_{ij})^2</script><p>ä½¿ç”¨SGDå¯ä»¥æ±‚è§£ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Unsupervised Learning</tag>
        <tag>Linear Dimension Reduction</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸çš„æ¨å¯¼</title>
    <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%8E%A8%E5%AF%BC/</url>
    <content><![CDATA[<p> è®°RNNä¸­æ¯ä¸€æ­¥çš„æŸå¤±ä¸º$E_t$ï¼Œåˆ™æŸå¤±å¯¹$h_{t-1}$çš„æƒé‡$W$çš„å¯¼æ•°æœ‰ï¼š</p>
<script type="math/tex; mode=display">\frac{\partial{E_t}}{\partial{W}}=\sum_{k=1}^{t}
    \frac{\partial{E_t}}{\partial{y_t}} \frac{\partial{y_t}}{\partial{h_t}} \frac{\partial{h_t}}{\partial{h_k}} \frac{\partial{h_k}}{\partial{W}}</script><p>å…¶ä¸­$\frac{\partial{h_t}}{\partial{h_k}}$ä½¿ç”¨é“¾å¼æ³•åˆ™æœ‰ï¼š</p>
<script type="math/tex; mode=display">\frac{\partial{h_t}}{\partial{h_k}} = 
    \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} =
    \prod_{j=k+1}^{t} W^T \times diag[f^{\prime}(h_{j-1})]</script><p>å…¶ä¸­$\frac{\partial{h_j}}{\partial{h_{j-1}}}$ æ˜¯é›…å…‹æ¯”çŸ©é˜µã€‚å¯¹å…¶å–æ¨¡(norm)ï¼Œæœ‰ï¼š</p>
<script type="math/tex; mode=display">\rVert \frac{\partial{h_j}}{\partial{h_{j-1}}}\rVert â‰¤ 
\rVert W^T \rVert \rVert diag[f^{\prime}(h_{j-1})] \rVert 
â‰¤ \beta_W \beta_h</script><p>å½“$f$ä¸ºsigmoidæ—¶ï¼Œ$f^{\prime}(h_{j-1})$æœ€å¤§å€¼ä¸º1ã€‚</p>
<p>æœ€ç»ˆæˆ‘ä»¬æœ‰ï¼š</p>
<script type="math/tex; mode=display">\rVert \frac{\partial{h_t}}{\partial{h_{k}}}\rVert â‰¤ 
\rVert \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} \rVert 
â‰¤ (\beta_W \beta_h)^{t-k}</script><p>ä»ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“t-kè¶³å¤Ÿå¤§æ—¶ï¼Œå¦‚æœ$(\beta_W \beta_h)$å°äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å°ï¼Œç›¸åï¼Œè‹¥$(\beta_W \beta_h)$å¤§äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å¤§ã€‚</p>
<p>åœ¨è®¡ç®—æœºä¸­ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå¤§æ—¶ï¼Œä¼šé€ æˆä¸Šæº¢(NaN)ï¼Œä¹Ÿå³æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå°æ—¶ï¼Œä¼šå˜æˆ0ï¼Œä¹Ÿå³æ¢¯åº¦æ¶ˆå¤±ã€‚æ³¨æ„åˆ°ï¼Œt-kçš„æŸå¤±å®é™…ä¸Šè¯„ä¼°çš„æ˜¯ä¸€ä¸ªè¾ƒè¿œçš„è¯å¯¹å½“å‰tçš„è´¡çŒ®ï¼Œæ¢¯åº¦æ¶ˆå¤±ä¹Ÿå³æ„å‘³ç€å¯¹å½“å‰çš„è´¡çŒ®æ¶ˆå¤±ã€‚</p>
<p>Reference:<br>CS224d: Deep Learning for NLP Lecture4</p>
]]></content>
      <tags>
        <tag>æ¢¯åº¦æ¶ˆå¤±</tag>
        <tag>æ¢¯åº¦çˆ†ç‚¸</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†10</title>
    <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8610/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ"><a href="#1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ" class="headerlink" title="1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]"></a>1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]</h3><p>é«˜ç»´æ­£æ€åˆ†å¸ƒæ˜¯ä»ä¸€ç»´å‘å±•è€Œæ¥çš„ï¼š<br><img src="/images/2018-10-07-15388761009977.jpg" width="70%" height="50%"></p>
<p><a href="https://www.zhihu.com/question/36339816" target="_blank" rel="noopener">https://www.zhihu.com/question/36339816</a></p>
<hr>
<h3 id="2ï¸âƒ£-RNN"><a href="#2ï¸âƒ£-RNN" class="headerlink" title="2ï¸âƒ£[RNN]"></a>2ï¸âƒ£[RNN]</h3><p>from <a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf</a></p>
<p>é€šå¸¸è€Œè¨€ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†RNNçš„initial stateè®¾ä¸ºå…¨0ï¼Œä½†åœ¨Hintonçš„slideä¸­æåˆ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆå§‹çŠ¶æ€ä½œä¸ºå¯å­¦ä¹ çš„å˜é‡ï¼Œå’Œæˆ‘ä»¬åœ¨å­¦ä¹ æƒé‡çŸ©é˜µä¸€æ ·ã€‚</p>
<p><img src="/images/2018-10-07-15388770544817.jpg" width="80%" height="50%"></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>æ­£æ€åˆ†å¸ƒ</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>PRMLç¬¬äºŒç«  æ¦‚ç‡åˆ†å¸ƒ</title>
    <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<h1 id="äºŒå…ƒå˜é‡"><a href="#äºŒå…ƒå˜é‡" class="headerlink" title="äºŒå…ƒå˜é‡"></a>äºŒå…ƒå˜é‡</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-25-21.jpg" alt="äºŒå…ƒå˜é‡1"></p>
<p><img src="/images/2018-09-30-Xnip2018-09-30_14-26-46.jpg" alt="è´å¡”åˆ†å¸ƒ"></p>
<h1 id="å¤šé¡¹å¼åˆ†å¸ƒ"><a href="#å¤šé¡¹å¼åˆ†å¸ƒ" class="headerlink" title="å¤šé¡¹å¼åˆ†å¸ƒ"></a>å¤šé¡¹å¼åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-31-55.jpg" alt="å¤šé¡¹å¼åˆ†å¸ƒ"></p>
<h1 id="é«˜æ–¯åˆ†å¸ƒ"><a href="#é«˜æ–¯åˆ†å¸ƒ" class="headerlink" title="é«˜æ–¯åˆ†å¸ƒ"></a>é«˜æ–¯åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-40-32.jpg" alt="é«˜æ–¯åˆ†å¸ƒ"></p>
<p><img src="/images/2018-09-30-Xnip2018-09-30_14-43-09.jpg" alt="2"></p>
<p><img src="/images/2018-09-30-Xnip2018-09-30_14-45-15.jpg" alt="3"></p>
<p><img src="/images/2018-09-30-Xnip2018-09-30_14-48-58.jpg" alt="4"></p>
<h1 id="æŒ‡æ•°æ—åˆ†å¸ƒ"><a href="#æŒ‡æ•°æ—åˆ†å¸ƒ" class="headerlink" title="æŒ‡æ•°æ—åˆ†å¸ƒ"></a>æŒ‡æ•°æ—åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-51-25.jpg" alt="1"></p>
<p><img src="/images/2018-10-03-Xnip2018-10-03_10-03-54.jpg" alt="2"></p>
<h1 id="éå‚æ•°ä¼˜åŒ–"><a href="#éå‚æ•°ä¼˜åŒ–" class="headerlink" title="éå‚æ•°ä¼˜åŒ–"></a>éå‚æ•°ä¼˜åŒ–</h1><p><img src="/images/2018-10-03-Xnip2018-10-03_10-05-24.jpg" alt="1"></p>
<p><img src="/images/2018-10-03-Xnip2018-10-03_10-06-55.jpg" alt="2"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>PRML</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 10:Semi-supervised learning</title>
    <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2010:%20Semi-supervised/</url>
    <content><![CDATA[<p>ä»€ä¹ˆæ˜¯semi-supervised learning</p>
<p>ç»™å®šæ•°æ®${(x^r,\hat{y}^r)}_{r=1}^{R},{(x_u)}_{u=R}^{R+U}$ï¼Œå…¶ä¸­æœªæ ‡è®°æ•°æ®è¿œè¿œå¤šäºæ ‡è®°æ•°æ® $U&gt;&gt;R$</p>
<p>ä¸ºä»€ä¹ˆåŠç›‘ç£å­¦ä¹ æœ‰ç”¨ï¼Ÿ<br>å› ä¸ºæœªæ ‡è®°æ•°æ®çš„åˆ†å¸ƒå¯èƒ½èƒ½å¤Ÿç»™æˆ‘ä»¬ä¸€äº›ä¿¡æ¯ã€‚</p>
<h3 id="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "><a href="#ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ " class="headerlink" title="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "></a>ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ </h3><p>ç»™å®šä¸¤ç±»$C_1$ã€$C_2$ï¼Œè¦æ±‚å¾—åˆ°åéªŒæ¦‚ç‡åˆ†å¸ƒ</p>
<script type="math/tex; mode=display">P(C_1 |x)=\frac{P(x|C_1 )P(C_1 )}{(P(x|C_1 )P(C_1 )+P(x|C_2 )P(C_2 ) )}</script><p>å…¶ä¸­è”åˆæ¦‚ç‡åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒã€‚æœªæ ‡è®°æ•°æ®æ­¤æ—¶çš„ä½œç”¨å³å¸®æˆ‘ä»¬é‡æ–°ä¼°è®¡$P(C_1),P(C_2),\mu,\Sigma$</p>
<p><img src="/images/2018-09-30-15382829251218.jpg" width="50%" height="50%"></p>
<p>å¦‚ä½•åš?<br>å…ˆåˆå§‹åŒ–$P(C_1),P(C_2),\mu,\Sigma$ï¼Œé€šå¸¸å¯ä»¥å…ˆç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œä¼°è®¡</p>
<ol>
<li>è®¡ç®—æ¯ä¸ªæœªæ ‡è®°æ•°æ®çš„åéªŒæ¦‚ç‡åˆ†å¸ƒ</li>
<li>ä»¥è¯¥æ¦‚ç‡åˆ†å¸ƒæ›´æ–°æ¨¡å‹<br>ä¸æ–­é‡å¤ç›´è‡³æ‹Ÿåˆ</li>
</ol>
<p><img src="/images/2018-09-30-15382829987091.jpg" width="70%" height="50%"></p>
<p>åŸå› ï¼š<br>å½“æˆ‘ä»¬åœ¨åšç›‘ç£å­¦ä¹ æ—¶ï¼Œä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ±‚è§£ï¼š</p>
<script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{x^r,\hat{y}^r} logP_Î¸ (x^r |\hat{y}^r )</script><p>åŠ ä¸Šäº†æœªæ ‡è®°æ•°æ®åï¼ŒåŒæ ·ä¹Ÿè¦åšæœ€å¤§ä¼¼ç„¶ï¼š</p>
<script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{(x^r,\hat{y}^r)} logP_Î¸ (x^r |\hat{y}^r )+âˆ‘_{x^u} logP_Î¸ (x^u)</script><h3 id="Low-density-Separation"><a href="#Low-density-Separation" class="headerlink" title="Low-density Separation"></a>Low-density Separation</h3><p>å‡è®¾ä¸åŒç±»åˆ«ä¹‹é—´æœ‰ä¸€æ¡æ˜æ˜¾çš„åˆ†ç•Œçº¿ï¼Œä¹Ÿå³å­˜åœ¨ä¸€ä¸ªåŒºåŸŸï¼Œå…¶å¯†åº¦æ¯”å…¶ä»–åŒºåŸŸå°</p>
<h4 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h4><p>å¦‚ä½•åš?</p>
<ol>
<li>å…ˆç”¨æœ‰æ ‡ç­¾æ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹$f$ï¼›</li>
<li>åˆ©ç”¨æ¨¡å‹å¯¹æœªæ ‡è®°æ•°æ®è¿›è¡Œæ ‡è®°ï¼Œè¿™äº›æ ‡ç­¾ç§°ä¸ºä¼ªæ ‡ç­¾ï¼ˆpseudo-labelï¼‰</li>
<li>å°†éƒ¨åˆ†æœ‰ä¼ªæ ‡ç­¾çš„æ•°æ®æ”¾å…¥æœ‰æ ‡ç­¾æ•°æ®ä¸­ï¼Œé‡æ–°è®­ç»ƒ<br>é‡å¤ç›´åˆ°æ‹Ÿåˆ</li>
</ol>
<p>è¿™ç§æ–¹å¼å’Œç”Ÿæˆæ¨¡å‹çš„åŒºåˆ«ï¼šè¯¥æ–¹æ³•ä½¿ç”¨çš„æ˜¯hard labelè€Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨çš„æ˜¯soft label</p>
<h4 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h4><p>å°†æœªæ ‡è®°æ•°æ®å……å½“æ­£åˆ™åŒ–çš„æ•ˆæœï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹é¢„æµ‹æ ‡ç­¾çš„æ¦‚ç‡è¾ƒä¸ºé›†ä¸­ï¼Œä¹Ÿå³ç†µåº”è¯¥å°½å¯èƒ½å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœªæ ‡è®°æ•°æ®ä½¿å¾—åˆ†ç±»è¾¹ç•Œå°½å¯èƒ½åˆ’åœ¨ä½å¯†åº¦åŒºåŸŸã€‚<br><img src="/images/2018-09-30-15382837957204.jpg" width="30%" height="50%"></p>
<h3 id="Smoothness-Assumption"><a href="#Smoothness-Assumption" class="headerlink" title="Smoothness Assumption"></a>Smoothness Assumption</h3><p>å‡è®¾ï¼šä½äºç¨ å¯†æ•°æ®åŒºåŸŸçš„ä¸¤ä¸ªè·ç¦»å¾ˆè¿‘çš„æ ·ä¾‹çš„ç±»æ ‡ç­¾ç›¸ä¼¼ï¼Œé€šè¿‡high density pathè¿æ¥ã€‚</p>
<p><img src="/images/2018-09-30-15382840889274.jpg" width="40%" height="50%"><br>x1ä¸x2ä¹‹é—´è¾ƒä¸ºç¨ å¯†ï¼Œå› æ­¤x2ä¸x1æ¯”x2ä¸x3æ›´ä¸ºæ¥è¿‘ã€‚</p>
<p><strong>å¦‚ä½•çŸ¥é“x1ä¸x2é€šè¿‡high density pathè¿æ¥ï¼Ÿ</strong><br><img src="/images/2018-09-30-15382841851160.jpg" width="50%" height="50%"></p>
<p>åŸºäºå›¾çš„æ–¹æ³•ï¼š</p>
<ol>
<li>å®šä¹‰xiä¸xjä¹‹é—´çš„ç›¸ä¼¼åº¦$s(x^i,x^j)$</li>
<li>æ·»åŠ è¾¹ï¼Œæœ‰ä¸¤ç§é€‰æ‹©<ol>
<li>k nearest neighbor</li>
<li>e-neighborhood<br><img src="/images/2018-09-30-15382842669412.jpg" width="50%" height="50%"></li>
</ol>
</li>
<li>è¾¹ä¹‹é—´çš„æƒé‡é€šè¿‡ç›¸ä¼¼åº¦æ¥è¡¡é‡ã€‚å¦‚ï¼š $s(x^i,x^j )=exp(âˆ’Î³â€–x^iâˆ’x^jâ€–^2)$</li>
</ol>
<p>è¯¥æ–¹æ³•æœ¬è´¨å³åˆ©ç”¨æœ‰æ ‡ç­¾æ•°æ®å»å½±å“æœªæ ‡è®°æ•°æ®ï¼Œé€šè¿‡å›¾çš„ä¼ æ’­ã€‚ä½†ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚æœæ•°æ®ä¸å¤Ÿå¤šï¼Œå°±å¯èƒ½æ²¡åŠæ³•ä¼ æ’­ã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382844101208.jpg" width="30%" height="50%"></p>
<p>åœ¨å»ºç«‹å¥½å›¾åï¼Œå¦‚ä½•ä½¿ç”¨?</p>
<ul>
<li>å®šä¹‰å›¾çš„å¹³æ»‘ç¨‹åº¦ï¼Œ$y$è¡¨ç¤ºæ ‡ç­¾ã€‚$S$è¶Šå°è¡¨ç¤ºè¶Šå¹³æ»‘ã€‚<script type="math/tex; mode=display">S=1/2âˆ‘_{i,j} w_{i,j} (y^iâˆ’y^j )^2=y^T Ly</script><script type="math/tex; mode=display">y=[â‹¯y^iâ‹¯y^jâ‹¯]^T</script><script type="math/tex; mode=display">L=Dâˆ’W</script></li>
</ul>
<p>Dæ˜¯é‚»æ¥çŸ©é˜µï¼Œç¬¬ijä¸ªå…ƒç´ å³xiä¸xjä¹‹é—´çš„weightï¼ŒWæ˜¯å¯¹è§’çŸ©é˜µï¼Œiiä¸ªå…ƒç´ æ˜¯Dçš„ç¬¬iè¡Œçš„åŠ å’Œï¼›Lç§°ä¸ºGraph Laplacian<br><img src="/images/2018-09-30-15382847006975.jpg" width="50%" height="50%"></p>
<ul>
<li>æˆ‘ä»¬æœ€ç»ˆåœ¨è®¡ç®—Lossçš„æ—¶å€™è¦åŠ ä¸Šè¿™é¡¹æ­£åˆ™é¡¹<script type="math/tex; mode=display">L=âˆ‘_{x^r}C(y^r,\hat{y}^r ) +Î»S</script></li>
</ul>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>Semi-supervised learning</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 7:Tips for DL</title>
    <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%207:%20Tips%20for%20DL/</url>
    <content><![CDATA[<p>å¤§çº²<br><img src="/images/2018-09-30-15382757690955.jpg" width="50%" height="50%"></p>
<h2 id="new-activation-function"><a href="#new-activation-function" class="headerlink" title="new activation function"></a>new activation function</h2><p>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šç”±äºsigmoidä¼šå°†å€¼å‹ç¼©ï¼Œæ‰€ä»¥åœ¨åå‘ä¼ æ’­æ—¶ï¼Œè¶Šåˆ°åé¢å€¼è¶Šå°ã€‚</p>
<p><img src="/images/2018-09-30-15382758841507.jpg" width="30%" height="50%"><br>æ‰€ä»¥åå±‚çš„æ›´æ–°ä¼šæ¯”å‰å±‚çš„æ›´æ–°æ›´å¿«ï¼Œå¯¼è‡´å‰å±‚è¿˜æ²¡convergeï¼Œåå±‚å°±æ ¹æ®å‰å±‚çš„æ•°æ®ï¼ˆrandomï¼‰è¾¾åˆ°convergeäº†</p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p><img src="/images/2018-09-30-15382759503401.jpg" width="30%" height="50%"><br>èƒ½å¤Ÿå¿«é€Ÿè®¡ç®—ï¼Œä¸”èƒ½å¤Ÿè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</p>
<p>å› ä¸ºä¼šæœ‰éƒ¨åˆ†neuronçš„å€¼æ˜¯0ï¼Œæ‰€ä»¥ç›¸å½“äºæ¯æ¬¡è®­ç»ƒä¸€ä¸ªç˜¦é•¿çš„ç¥ç»ç½‘ç»œã€‚<br><img src="/images/2018-09-30-15382760030965.jpg" width="50%" height="50%"></p>
<h4 id="ReLUçš„å˜ä½“"><a href="#ReLUçš„å˜ä½“" class="headerlink" title="ReLUçš„å˜ä½“"></a>ReLUçš„å˜ä½“</h4><p><img src="/images/2018-09-30-15382928024258.jpg" width="50%" height="50%"></p>
<h3 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h3><p>é¦–å…ˆå°†å‡ ä¸ªneuronå½’ä¸ºä¸€ç»„ï¼Œç„¶åæ¯æ¬¡å‰å‘ä¼ æ’­æ—¶å–æœ€å¤§çš„ä½œä¸ºè¾“å‡ºã€‚<br><img src="/images/2018-09-30-15382761367509.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸ŠReLUæ˜¯maxoutçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼š<br><img src="/images/2018-09-30-15382761741870.jpg" width="40%" height="50%"></p>
<p>æ›´ä¸€èˆ¬çš„ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-30-15382762237369.jpg" width="40%" height="50%"></p>
<p>å› ä¸ºwå’Œbçš„å˜åŒ–ï¼Œæ‰€ä»¥è¯¥activation functionå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªlearnable activation function</p>
<p>è¿™æ ·ä¸€ä¸ªlearnable activation functionæœ‰è¿™æ ·çš„ç‰¹ç‚¹ï¼š</p>
<blockquote>
<p>Activation function in maxout network can be any piecewise linear convex function<br>How many pieces depending on how many elements in a group</p>
</blockquote>
<p>å¦‚ï¼š<br><img src="/images/2018-09-30-15382763537888.jpg" width="60%" height="50%"></p>
<p>maxoutåº”å¦‚ä½•è®­ç»ƒï¼Ÿ</p>
<p><img src="/images/2018-09-30-15382764343880.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªæ™®é€šçš„ç˜¦é•¿networkï¼Œå¸¸è§„è®­ç»ƒå³å¯ã€‚<br><img src="/images/2018-09-30-15382764564859.jpg" width="50%" height="50%"></p>
<h2 id="Adaptive-learning-rate"><a href="#Adaptive-learning-rate" class="headerlink" title="Adaptive learning rate"></a>Adaptive learning rate</h2><p>åœ¨adagradä¸­:<br><img src="/images/2018-09-30-15382765516383.jpg" width="30%" height="50%"></p>
<p>è¶Šåˆ°åé¢learning rateè¶Šæ¥è¶Šå°ï¼Œä½†å®é™…ä¸Šåœ¨dlé‡Œé¢ï¼Œerror surfaceæ˜¯éå¸¸å¤æ‚çš„ï¼Œè¶Šæ¥è¶Šå°çš„learning rateå¯èƒ½ä¸é€‚ç”¨äºdlã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382765821828.jpg" width="50%" height="50%"></p>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p><img src="/images/2018-09-30-15382766372355.jpg" width="60%" height="50%"><br>$Ïƒ^t$æ˜¯å†å²ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯è¯´$Ïƒ^t$å‚è€ƒäº†è¿‡å»çš„æ¢¯åº¦å’Œå½“å‰çš„æ¢¯åº¦è·å¾—ä¸€ä¸ªæ–°çš„æ”¾ç¼©å¤§å°</p>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>å¼•å…¥æƒ¯æ€§ä½œä¸ºå‚è€ƒï¼Œä¹Ÿå³å‚è€ƒäº†ä¸Šä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘ã€‚å¼•å…¥æƒ¯æ€§åï¼Œå¯èƒ½æœ‰æœºä¼šè¶Šè¿‡local minimumã€‚<br>æ™®é€šçš„gradient descent:<br><img src="/images/2018-09-30-15382769712428.jpg" width="40%" height="50%"><br>æ¯æ¬¡æœç€æ¢¯åº¦çš„åæ–¹å‘èµ°ã€‚</p>
<p>Momentum:<br><img src="/images/2018-09-30-15382770120104.jpg" width="40%" height="50%"></p>
<p>è€ƒè™‘äº†ä¸Šä¸€æ­¥èµ°çš„æ–¹å‘ã€‚</p>
<p>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382771516587.jpg" width="30%" height="50%"></p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>ç»“åˆäº†RMSpropå’ŒMomentumï¼Œä¹Ÿå³ç»¼åˆè€ƒè™‘äº†å†å²ä¿¡æ¯å†³å®šå½“å‰æ­¥é•¿ï¼›è€ƒè™‘äº†ä¸Šä¸€æ­¥çš„æ–¹å‘å†³å®šå½“å‰èµ°çš„æ–¹å‘ã€‚<br>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382772986250.jpg" width="60%" height="50%"></p>
<h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h2><p>å°±æ˜¯åœ¨validation setçš„lossä¸å†å‡å°æ—¶åœæ­¢<br><img src="/images/2018-09-30-15382814784406.jpg" width="50%" height="50%"></p>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="L2æ­£åˆ™åŒ–"><a href="#L2æ­£åˆ™åŒ–" class="headerlink" title="L2æ­£åˆ™åŒ–"></a>L2æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382815175056.jpg" width="50%" height="50%"><br>å…¶ä¸­<br><img src="/images/2018-09-30-15382815336088.jpg" width="30%" height="50%"><br>å› æ­¤æ›´æ–°å…¬å¼ä¸ºï¼š<br>    <img src="/images/2018-09-30-15382815641437.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³æ¯æ¬¡ä»¥$1-\eta \lambda$å¯¹wè¿›è¡Œæ”¾ç¼©ï¼Œä½¿wæ›´æ¥è¿‘0<br>æ­£åˆ™åŒ–åœ¨DLä¸­ä¹Ÿç§°ä¸ºweight decay</p>
<h3 id="L1æ­£åˆ™åŒ–"><a href="#L1æ­£åˆ™åŒ–" class="headerlink" title="L1æ­£åˆ™åŒ–"></a>L1æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382816962676.jpg" width="25%" height="50%"></p>
<p><img src="/images/2018-09-30-15382817122102.jpg" width="25%" height="50%"><br><img src="/images/2018-09-30-15382817409633.jpg" width="25%" height="50%"></p>
<p>åˆ™æ›´æ–°å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-30-15382817897319.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³æ¯æ¬¡ä»¥$Î·Î»sgn(w)$ ä½¿wå¾€0é ï¼ˆsgnè¡¨ç¤ºç¬¦å·å‡½æ•°ï¼‰</p>
<p>å¯ä»¥çœ‹å‡ºï¼ŒL1æ¯æ¬¡éƒ½åŠ å‡ç›¸åŒçš„å€¼ï¼Œè€ŒL2æŒ‰æ¯”ä¾‹è¿›è¡Œç¼©æ”¾ã€‚å› æ­¤L1æ›´ä¸ºç¨€ç–(sparse)ã€‚</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>è®­ç»ƒçš„æ—¶å€™æ¯ä¸€å±‚é‡‡æ ·p%çš„ç¥ç»å…ƒè®¾ä¸º0ï¼Œè®©å…¶ä¸å·¥ä½œ<br><img src="/images/2018-09-30-15382819376579.jpg" width="50%" height="50%"></p>
<p>å®é™…ä¸Šå°±æ˜¯æ¯ä¸ªbatchæ”¹å˜äº†ç½‘ç»œç»“æ„ï¼Œä½¿å¾—ç½‘ç»œæ›´ç»†é•¿<br><img src="/images/2018-09-30-15382819772611.jpg" width="50%" height="50%"></p>
<p>æµ‹è¯•çš„æ—¶å€™æ‰€æœ‰çš„weightéƒ½ä¹˜ä»¥1-p%</p>
<p>ä»ensembleçš„è§’åº¦çœ‹å¾…dropoutï¼š<br>åœ¨è®­ç»ƒçš„æ—¶å€™è®­ç»ƒä¸€å †ä¸åŒç»“æ„çš„networkï¼Œæœ€å¤šæœ‰$2^N$ç§ç»„åˆï¼ŒNä¸ºneuronä¸ªæ•°ï¼Œå¯ä»¥ç§°ä¸ºç»ˆæçš„ensembleæ–¹æ³•äº†ã€‚è€Œåœ¨æµ‹è¯•çš„æ—¶å€™å¯¹è¿™äº›ä¸åŒçš„ç½‘ç»œè¿›è¡Œå¹³å‡ã€‚</p>
<p><img src="/images/2018-09-30-15382821089494.jpg" width="50%" height="50%"></p>
<p><img src="/images/2018-09-30-15382821379688.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Tips for DL</tag>
      </tags>
  </entry>
  <entry>
    <title>é‡‡æ ·æµ…æ</title>
    <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E9%87%87%E6%A0%B7%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<p>æ€»ç»“åœ¨NLPä¸­çš„é‡‡æ ·æ–¹æ³•ï¼ˆæŒç»­æ›´æ–°ï¼‰ã€‚</p>
<h2 id="é‡‡æ ·æ–¹æ³•"><a href="#é‡‡æ ·æ–¹æ³•" class="headerlink" title="é‡‡æ ·æ–¹æ³•"></a>é‡‡æ ·æ–¹æ³•</h2><h3 id="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling"><a href="#1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling" class="headerlink" title="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)"></a>1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥ä»»æ„æ¦‚ç‡åˆ†å¸ƒçš„<strong>ç´¯ç§¯åˆ†å¸ƒå‡½æ•°</strong>æ—¶ï¼Œç”¨äºä»è¯¥åˆ†å¸ƒä¸­ç”Ÿæˆéšæœºæ ·æœ¬ã€‚</p>
<p>â€”-ä»€ä¹ˆæ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°(CDF)â€”-<br>æ˜¯æ¦‚ç‡å¯†åº¦å‡½æ•°(PDF)çš„ç§¯åˆ†ï¼Œå®šä¹‰ï¼š</p>
<script type="math/tex; mode=display">F_X(x)=P(Xâ‰¤x)=\int_{-âˆ}^{x}f_X(t)dt</script><p>â€”-ENDâ€”-</p>
<p>æƒ³è±¡æˆ‘ä»¬çŸ¥é“é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•é‡‡æ ·ï¼Ÿæœ¬è´¨ä¸Šæˆ‘ä»¬åªèƒ½å¯¹å‡åŒ€åˆ†å¸ƒè¿›è¡Œç›´æ¥é‡‡æ ·ï¼ˆé«˜æ–¯åˆ†å¸ƒæœ‰<a href="https://www.zhihu.com/question/29971598" target="_blank" rel="noopener">ç®—æ³•</a>å¯ä»¥ç”Ÿæˆé‡‡æ ·ï¼Œä½†æ— æ³•ä¸€èˆ¬åŒ–ï¼‰ã€‚å¯¹äºè¿™ç§è¿ç»­çš„éšæœºå˜é‡ï¼Œæˆ‘ä»¬åªèƒ½é€šè¿‡é—´æ¥çš„æ–¹æ³•è¿›è¡Œé‡‡æ ·ã€‚</p>
<p>é€†å˜æ¢é‡‡æ ·å³æ˜¯é€šè¿‡ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„åå‡½æ•°æ¥é‡‡æ ·ã€‚å› ä¸ºç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„å€¼åŸŸä¸º$[0,1]$ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡åœ¨$[0,1]$ä¸Šè¿›è¡Œé‡‡æ ·ï¼Œå†æ˜ å°„åˆ°åŸåˆ†å¸ƒã€‚<br>ä¾‹å­:<br><img src="/images/2018-09-30-15382714567064.jpg" width="80%" height="50%"><br>æ˜ å°„å…³ç³»å¦‚å›¾ï¼š<br><img src="/images/2018-09-30-15382715821631.jpg" width="50%" height="50%"></p>
<h3 id="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling"><a href="#2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling" class="headerlink" title="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)"></a>2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥æŸä¸ªåˆ†å¸ƒ$P$ï¼Œå¸Œæœ›èƒ½ä¼°è®¡$f(x)$çš„æœŸæœ›ã€‚äº¦å³ï¼š</p>
<script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)</script><p>å…¶ä¸­$x\sim p$ã€‚<br>å‡è®¾$p(x)$çš„åˆ†å¸ƒå¤æ‚æˆ–æ ·æœ¬ä¸å¥½ç”Ÿæˆï¼Œå¦ä¸€åˆ†å¸ƒ$q(x)$æ–¹ä¾¿ç”Ÿæˆæ ·æœ¬ã€‚å› æ­¤æˆ‘ä»¬å¼•å…¥$q(x)$å¯¹åŸå…ˆåˆ†å¸ƒè¿›è¡Œä¼°è®¡ã€‚</p>
<script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dx=\int_{x}f(x)\frac{p(x)}{q(x)}q(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)\frac{p(x_i)}{q(x_i)}</script><p>å…¶ä¸­ï¼Œ$x \sim q$ã€‚$w(x)=\frac{p(x)}{q(x)}$ç§°ä¸ºImportance Weight</p>
<p>æ ¹æ®ä¸Šå¼ï¼Œå®é™…ä¸Šå°±æ˜¯æ¯æ¬¡é‡‡æ ·çš„åŠ æƒæ±‚å’Œã€‚</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>é€†å˜æ¢é‡‡æ ·<br><a href="https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7</a></p>
<p>é‡è¦æ€§é‡‡æ ·<br><a href="https://www.youtube.com/watch?v=S3LAOZxGcnk" target="_blank" rel="noopener">https://www.youtube.com/watch?v=S3LAOZxGcnk</a></p>
<p>â€”â€”æŒç»­æ›´æ–°â€”â€”</p>
]]></content>
      <tags>
        <tag>é‡‡æ ·</tag>
        <tag>sampling</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†9</title>
    <url>/2018/09/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%869/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ä¿å­˜checkpointæ˜¯ä¸€ä¸ªdictå½¢å¼ï¼Œå¯ä»¥ä¿å­˜ä»»æ„å¤šä¸ªæ¨¡å‹åˆ°ä¸€ä¸ªcheckpointä¸­ã€‚<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#save</span></span><br><span class="line">torch.save(&#123;            <span class="string">'epoch'</span>: epoch,            <span class="string">'model_state_dict'</span>: model.state_dict(),            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),            <span class="string">'loss'</span>: loss,            ...            &#125;, PATH)</span><br><span class="line"><span class="comment">#load</span></span><br><span class="line">model = TheModelClass(*args, **kwargs)optimizer = TheOptimizerClass(*args, **kwargs)</span><br><span class="line">checkpoint = torch.load(PATH)model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])epoch = checkpoint[<span class="string">'epoch'</span>]loss = checkpoint[<span class="string">'loss'</span>]</span><br><span class="line">model.eval()<span class="comment"># - or -</span>model.train()</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>Pytorchå¯ä»¥loadéƒ¨åˆ†æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯åªloadè¿›æ¥éƒ¨åˆ†æˆ‘ä»¬éœ€è¦çš„å±‚ï¼Œè¿™åœ¨transfer learningä¸­ç”¨åˆ°ã€‚<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">torch.save(modelA.state_dict(), PATH)</span><br><span class="line">modelB = TheModelBClass(*args, **kwargs)modelB.load_state_dict(torch.load(PATH), strict=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>no title</title>
    <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%9C%89%E5%8A%9B%E9%87%8F%E7%9A%84%E6%96%87%E5%AD%97/</url>
    <content><![CDATA[<p>æ¯å½“æˆ‘é‡åˆ°è‡ªå·±ä¸æ•¢ç›´è§†çš„å›°éš¾æ—¶ï¼Œæˆ‘å°±ä¼šé—­ä¸ŠåŒçœ¼ï¼Œæƒ³è±¡è‡ªå·±æ˜¯ä¸€ä¸ª80å²çš„è€äººï¼Œä¸ºäººç”Ÿä¸­æ›¾æ”¾å¼ƒå’Œé€ƒé¿è¿‡çš„æ— æ•°å›°éš¾è€Œæ‡Šæ‚”ä¸å·²ï¼Œæˆ‘ä¼šå¯¹è‡ªå·±è¯´ï¼Œèƒ½å†å¹´è½»ä¸€æ¬¡è¯¥æœ‰å¤šå¥½ï¼Œç„¶åæˆ‘çå¼€çœ¼ç›ï¼šç °ï¼æˆ‘åˆå¹´è½»ä¸€æ¬¡äº†ï¼</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯10</title>
    <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D10/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"><a href="#1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹" class="headerlink" title="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"></a>1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹</h3><p>[å”] ç‹æ¹¾<br>å®¢è·¯é’å±±å¤–ï¼Œè¡ŒèˆŸç»¿æ°´å‰ã€‚<br>æ½®å¹³ä¸¤å²¸é˜”ï¼Œé£æ­£ä¸€å¸†æ‚¬ã€‚<br><strong>æµ·æ—¥ç”Ÿæ®‹å¤œï¼Œæ±Ÿæ˜¥å…¥æ—§å¹´ã€‚</strong><br>ä¹¡ä¹¦ä½•å¤„è¾¾ï¼Œå½’é›æ´›é˜³è¾¹ã€‚</p>
<p>æ¬¡ï¼šæ—…é€”ä¸­æš‚æ—¶åœå®¿ï¼Œè¿™é‡Œæ˜¯åœæ³Šçš„æ„æ€ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e</a></p>
<hr>
<h3 id="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"><a href="#2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ" class="headerlink" title="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"></a>2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ</h3><p>[å”] æœç‰§<br>æ¸…æ—¶æœ‰å‘³æ˜¯æ— èƒ½ï¼Œé—²çˆ±å­¤äº‘é™çˆ±åƒ§ã€‚<br><strong>æ¬²æŠŠä¸€éº¾æ±Ÿæµ·å»ï¼Œä¹æ¸¸åŸä¸Šæœ›æ˜­é™µã€‚</strong></p>
<p>æ— èƒ½ï¼šæ— æ‰€ä½œä¸ºã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b99db9165abd005a6da742" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b99db9165abd005a6da742</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>PRMLç¬¬ä¸€ç«  ç»ªè®º</title>
    <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<p>è®°å½•PRMLå­¦ä¹ è¿‡ç¨‹ã€‚<br>ç¬”è®°å…±äº«é“¾æ¥ï¼š<a href="https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg" target="_blank" rel="noopener">https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg</a></p>
<hr>
<h1 id="æ¦‚ç‡è®º"><a href="#æ¦‚ç‡è®º" class="headerlink" title="æ¦‚ç‡è®º"></a>æ¦‚ç‡è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-27-21.jpg" alt="æ¦‚ç‡è®º"></p>
<h1 id="å†³ç­–è®º"><a href="#å†³ç­–è®º" class="headerlink" title="å†³ç­–è®º"></a>å†³ç­–è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-36-52.jpg" alt="å†³ç­–è®º"></p>
<h1 id="ä¿¡æ¯è®º"><a href="#ä¿¡æ¯è®º" class="headerlink" title="ä¿¡æ¯è®º"></a>ä¿¡æ¯è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-38-46.jpg" alt="ä¿¡æ¯è®º"></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>PRML</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 6:Backpropagation</title>
    <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%206:%20Backpropagation/</url>
    <content><![CDATA[<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><p>åŸºæœ¬å…¬å¼<br><img src="/images/2018-09-23-15376684598125.jpg" width="50%" height="50%"><br><img src="/images/2018-09-23-15376684674095.jpg" width="50%" height="50%"></p>
<h3 id="forward-passå’Œbackward-pass"><a href="#forward-passå’Œbackward-pass" class="headerlink" title="forward passå’Œbackward pass"></a>forward passå’Œbackward pass</h3><p>å¯ä»¥å°†backpropagationåˆ†ä¸ºä¸¤æ­¥</p>
<h4 id="forward-pass"><a href="#forward-pass" class="headerlink" title="forward pass"></a>forward pass</h4><p>åœ¨å‰å‘ä¼ æ’­çš„æ—¶å€™æå‰è®¡ç®—/ä¿å­˜å¥½ï¼Œå› ä¸ºè¯¥æ¢¯åº¦å¾ˆç®€å•<br><img src="/images/2018-09-23-15376686358832.jpg" width="50%" height="50%"></p>
<p>æ¯”å¦‚zå¯¹w1çš„æ¢¯åº¦å°±æ˜¯x1ï¼Œå°±æ˜¯å’Œw1ç›¸è¿çš„é¡¹<br><img src="/images/2018-09-23-15376687025289.jpg" width="20%" height="50%"></p>
<h4 id="backward-pass"><a href="#backward-pass" class="headerlink" title="backward pass"></a>backward pass</h4><p>å›ä¼ çš„æ—¶å€™é€å±‚ç›¸ä¹˜ä¸‹å»ï¼Œç±»ä¼¼åŠ¨æ€è§„åˆ’ï¼Œè·å¾—äº†åä¸€å±‚çš„æ¢¯åº¦æ‰èƒ½æ±‚å‡ºå‰ä¸€å±‚çš„æ¢¯åº¦ã€‚<br><img src="/images/2018-09-23-15376687488493.jpg" width="50%" height="50%"></p>
<h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><p><img src="/images/2018-09-23-15376687824826.jpg" width="50%" height="50%"></p>
<p>å…ˆå‰å‘ï¼Œæå‰ç®—å‡ºæœ€é‚»è¿‘çš„æ¢¯åº¦ï¼Œç›´åˆ°output layerï¼Œè®¡ç®—å®Œè¯¥æ¢¯åº¦ï¼Œå†ä¸æ–­å›ä¼ é€å±‚ç›¸ä¹˜è·å¾—outputå¯¹å„å±‚çš„æ¢¯åº¦ã€‚</p>
<h3 id="ä»£ç å®ç°ä¾‹å­"><a href="#ä»£ç å®ç°ä¾‹å­" class="headerlink" title="ä»£ç å®ç°ä¾‹å­"></a>ä»£ç å®ç°ä¾‹å­</h3><p>reluå®ç°forward passå’Œbackward pass<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Backpropagation</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 5:Classification:Logistic Regression</title>
    <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%205%20Classification:%20Logistic%20Regression/</url>
    <content><![CDATA[<h3 id="logistic-regressionå¦‚ä½•åšï¼Ÿ"><a href="#logistic-regressionå¦‚ä½•åšï¼Ÿ" class="headerlink" title="logistic regressionå¦‚ä½•åšï¼Ÿ"></a>logistic regressionå¦‚ä½•åšï¼Ÿ</h3><p>step1: å®šä¹‰function set<br><img src="/images/2018-09-23-15376666391912.jpg" width="30%" height="50%"></p>
<p>step2: æ›´æ–°<br>ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ›´æ–°</p>
<script type="math/tex; mode=display">L(w,b)=f_{w,b}(x^1 )f_{w,b}(x^2 )(1âˆ’f_{w,b} (x^3 ))â‹¯f_{w,b} (x^N )</script><p>æ‰¾åˆ°wï¼Œbä½¿å¾—Læœ€å¤§</p>
<p>å¯¹ä¼¼ç„¶å‡½æ•°å–è´Ÿå¯¹æ•°ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-09-23-15376667791380.jpg" width="60%" height="50%"></p>
<p>å°†å¼å­çš„æ¯ä¸ªå…ƒç´ å†™æˆä¼¯åŠªåˆ©åˆ†å¸ƒå½¢å¼ï¼š<br><img src="/images/2018-09-23-15376669013511.jpg" width="60%" height="50%"></p>
<p>ä¸Šå¼å°±æ˜¯cross-entropyæŸå¤±å‡½æ•°ã€‚</p>
<p>æ±‚å¯¼è¯¥å¼å­å¯å¾—ï¼š<br><img src="/images/2018-09-23-15376669743224.jpg" width="30%" height="50%"><br>æ›´æ–°å…¬å¼ï¼š<br><img src="/images/2018-09-23-15376669980138.jpg" width="40%" height="50%"><br>å¯ä»¥çœ‹å‡ºä¸Šå¼å¾ˆç›´è§‚ï¼šå’Œç­”æ¡ˆå·®è·è¶Šå¤§ï¼Œæ›´æ–°æ­¥ä¼è¶Šå¤§ã€‚</p>
<p>åŒæ—¶å‘ç°ä¸Šå¼å’Œlinear regressionçš„æ›´æ–°å…¬å¼æ˜¯ä¸€è‡´çš„ã€‚</p>
<h3 id="ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ</h3><p>å‡è®¾æˆ‘ä»¬ä½¿ç”¨square lossï¼Œåˆ™æ±‚å¯¼å¾—åˆ°çš„æ¢¯åº¦ï¼š<br><img src="/images/2018-09-23-15376671202521.jpg" width="50%" height="50%"><br>ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“æ¥è¿‘targetæ—¶ï¼Œæ¢¯åº¦å°ï¼›è¿œç¦»targetæ—¶ï¼Œæ¢¯åº¦ä¹Ÿå°ã€‚éš¾ä»¥è¾¾åˆ°å…¨å±€æœ€å°<br><img src="/images/2018-09-23-15376672527230.jpg" width="60%" height="50%"></p>
<p>ä¸‹å›¾æ˜¯cross entropyå’Œsquare errorçš„å›¾åƒç¤ºæ„ï¼š<br><img src="/images/2018-09-23-15376672892502.jpg" width="60%" height="50%"></p>
<p>å¦‚å›¾ï¼Œsquare losséš¾ä»¥åˆ°è¾¾å…¨å±€æœ€å°ã€‚</p>
<h3 id="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"><a href="#ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«" class="headerlink" title="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"></a>ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«</h3><p>ç”Ÿæˆå¼å¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œå†é€šè¿‡è´å¶æ–¯å®šç†è·å¾—åéªŒæ¦‚ç‡ï¼›è€Œåˆ¤åˆ«å¼æ¨¡å‹ç›´æ¥å¯¹åéªŒæ¦‚ç‡å»ºæ¨¡ã€‚<br><img src="/images/2018-09-23-15376674213503.jpg" width="60%" height="50%"><br>äºŒè€…æ‰€å®šä¹‰çš„function setæ˜¯ä¸€è‡´çš„ï¼Œä½†åŒä¸€ç»„æ•°æ®å¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„wå’Œbã€‚</p>
<p>äºŒè€…ä¼˜åŠ£å¯¹æ¯”ï¼š</p>
<ul>
<li>æ•°æ®é‡å¤šæ—¶ï¼Œä¸€èˆ¬æ¥è¯´åˆ¤åˆ«å¼æ¨¡å‹ä¼šæ›´å¥½ã€‚å› ä¸ºåˆ¤åˆ«å¼æ¨¡å‹æ²¡æœ‰å…ˆéªŒå‡è®¾ï¼Œå®Œå…¨ä¾èµ–äºæ•°æ®ã€‚ä½†å¦‚æœæ•°æ®æœ‰å™ªå£°ï¼Œå®¹æ˜“å—å½±å“ã€‚</li>
<li>ç”Ÿæˆå¼æ¨¡å‹æ˜¯æœ‰ä¸€å®šçš„å‡è®¾çš„ï¼Œå½“å‡è®¾é”™è¯¯ï¼Œä¼šå½±å“åˆ†ç±»æ•ˆæœã€‚</li>
<li>æ­£å› ä¸ºæœ‰ä¸€å®šçš„å…ˆéªŒå‡è®¾ï¼Œå½“æ•°æ®é‡å¾ˆå°‘æ—¶ï¼Œå¯èƒ½æ•ˆæœä¼šä¸é”™ï¼›å¯¹äºå™ªå£°æ›´å…·æœ‰é²æ£’æ€§ã€‚</li>
<li>å…ˆéªŒå¯ä»¥ä»å…¶ä»–æ•°æ®æºè·å¾—æ¥å¸®åŠ©ç‰¹å®šä»»åŠ¡ï¼Œå¦‚è¯­éŸ³è¯†åˆ«é—®é¢˜ã€‚</li>
</ul>
<h3 id="logisticçš„å±€é™"><a href="#logisticçš„å±€é™" class="headerlink" title="logisticçš„å±€é™"></a>logisticçš„å±€é™</h3><p>æœ¬è´¨ä»æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ²¡åŠæ³•åˆ†ç±»éçº¿æ€§çš„æ•°æ®ã€‚<br>å¦‚ä½•è§£å†³è¯¥é—®é¢˜?<br><strong>å°†logistic regression modelæ‹¼æ¥èµ·æ¥</strong>ï¼Œå‰é¢çš„modelå¯¹æ•°æ®è¿›è¡Œfeature transformationï¼Œç„¶åå†å¯¹æ–°çš„featureè¿›è¡Œåˆ†ç±»ã€‚<br><img src="/images/2018-09-23-15376677559470.jpg" width="70%" height="50%"></p>
<p>logisticä¸deep learningçš„è”ç³»ï¼š<br>å¦‚æœå°†logistic regressionçš„ä¸€ä¸ªå•å…ƒç§°ä¸ºneuronï¼Œæ‹¼èµ·æ¥å°±æ˜¯neural networkäº†ï¼ï¼ï¼</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Classification</tag>
        <tag>Logistic Regression</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†8</title>
    <url>/2018/09/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%868/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>torch.max()æœ‰ä¸¤ç§ä¸åŒå†™æ³•ã€‚<br>torch.max(input) â†’ Tensor è¿”å›å…¶ä¸­æœ€å¤§çš„å…ƒç´ <br>torch.max(input, dim, keepdim=False, out=None) â†’ (Tensor, LongTensor) è¿”å›è¯¥ç»´åº¦ä¸Šæœ€å¤§å€¼ï¼Œä»¥åŠå¯¹åº”çš„index</p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>å°†æ¨¡å‹åŒæ—¶éƒ¨ç½²åˆ°å¤šå¼ å¡ä¸Šè®­ç»ƒï¼Œæœ¬è´¨å°±æ˜¯å°†ä¸€ä¸ªbatchçš„æ•°æ®splitï¼Œé€åˆ°å„ä¸ªmodelï¼Œç„¶ååˆå¹¶ç»“æœã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="3ï¸âƒ£-æ±‚å¯¼"><a href="#3ï¸âƒ£-æ±‚å¯¼" class="headerlink" title="3ï¸âƒ£[æ±‚å¯¼]"></a>3ï¸âƒ£[æ±‚å¯¼]</h3><p>æ ‡é‡ã€å‘é‡ã€çŸ©é˜µä¹‹é—´çš„æ±‚å¯¼æœ‰ä¸¤ç§å¸ƒå±€ï¼Œå³åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€ã€‚åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€åªå·®ä¸€ä¸ªè½¬ç½®ã€‚<br>æˆ‘çš„è®°æ³•ï¼šåœ¨æ±‚å¯¼è¿‡ç¨‹ä¸­ï¼Œå‡è®¾åˆ†æ¯ä¸ºm*nï¼Œåˆ†å­ä¸º k*nï¼Œåˆ™å¯¼æ•°çŸ©é˜µåº”è¯¥ä¸º k*m ã€‚ä¸€äº›ç‰¹æ®Šçš„å¦‚æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼ç­‰é™¤å¤–ã€‚<br>å…·ä½“ç›´æ¥æŸ¥è¡¨ï¼š<a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a></p>
<p>æŒ‰ä½è®¡ç®—æ±‚å¯¼ï¼š<br>å‡è®¾ä¸€ä¸ªå‡½æ•°$f(x)$çš„è¾“å…¥æ˜¯æ ‡é‡$x$ã€‚å¯¹äºä¸€ç»„Kä¸ªæ ‡é‡$x_1,Â·Â·Â· ,x_K$ï¼Œæˆ‘ä»¬<br>å¯ä»¥é€šè¿‡$f(x)$å¾—åˆ°å¦å¤–ä¸€ç»„Kä¸ªæ ‡é‡$z_1,Â·Â·Â· ,z_K$ï¼Œ<br>$z_k = f(x_k),âˆ€k = 1,Â·Â·Â· ,K$<br>å…¶ä¸­ï¼Œ$f(x)$æ˜¯æŒ‰ä½è¿ç®—çš„ï¼Œå³$[f(x)]_i = f(x_i)$<br>å…¶å¯¼æ•°æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼š<br><img src="/images/2018-09-23-15376727095200.jpg" width="50%" height="50%"></p>
<p><strong>Reference</strong>ï¼š<br><a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a><br><a href="https://blog.csdn.net/uncle_gy/article/details/78879131" target="_blank" rel="noopener">https://blog.csdn.net/uncle_gy/article/details/78879131</a><br><a href="https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf" target="_blank" rel="noopener">https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>æ±‚å¯¼</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•7</title>
    <url>/2018/09/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%957/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£softmaxçš„numpyå®ç°"><a href="#1ï¸âƒ£softmaxçš„numpyå®ç°" class="headerlink" title="1ï¸âƒ£softmaxçš„numpyå®ç°"></a>1ï¸âƒ£softmaxçš„numpyå®ç°</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x,axis=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Compute softmax values for each sets of scores in x."""</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / np.sum(np.exp(x), axis=axis)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu"><a href="#2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu" class="headerlink" title="2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu"></a>2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="3ï¸âƒ£Pytorchå®ç°relu"><a href="#3ï¸âƒ£Pytorchå®ç°relu" class="headerlink" title="3ï¸âƒ£Pytorchå®ç°relu"></a>3ï¸âƒ£Pytorchå®ç°relu</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"><a href="#4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²" class="headerlink" title="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"></a>4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>å¬è¾¾è§‚æ¯ç°åœºç­”è¾©æœ‰æ„Ÿ</title>
    <url>/2018/09/19/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E5%90%AC%E8%BE%BE%E8%A7%82%E6%9D%AF%E7%8E%B0%E5%9C%BA%E7%AD%94%E8%BE%A9%E6%9C%89%E6%84%9F/</url>
    <content><![CDATA[<p>å‰å‡ æ—¥ï¼ˆå‘¨æ—¥ï¼‰å»äº†è¾¾è§‚æ¯ç­”è¾©ç°åœºå¬äº†å‰10ååšäº†æŠ¥å‘Šï¼Œæœ‰äº†ä¸€äº›æ„Ÿæƒ³ï¼Œä½†ä¸€ç›´æ²¡æœ‰æŠ½å‡ºæ—¶é—´å†™ä¸€ä¸‹è‡ªå·±çš„æ„Ÿæƒ³ï¼ˆæ‡’ï¼‰ã€‚</p>
<p>è‡ªå·±å¤§æ¦‚èŠ±äº†åæ¥å¤©åšäº†ä¸€ä¸‹æ¯”èµ›ï¼Œå®é™…ä¸Šä¹Ÿå°±æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»çš„<a href="http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html" target="_blank" rel="noopener">æ¯”èµ›</a>ï¼Œå› ä¸ºæ²¡æœ‰æ¯”èµ›ç»éªŒçš„ç¼˜æ•…ï¼Œèµ°äº†å¾ˆå¤šå¼¯è·¯ã€‚ä¸è¿‡ä¹Ÿå­¦åˆ°äº†ä¸€äº›ä¸œè¥¿ã€‚</p>
<p>ç°è®°å½•å‰ååçš„ä¸€äº›idea/trickï¼š</p>
<ul>
<li>æ•°æ®å¢å¼º<ul>
<li>å› ä¸ºç»™çš„å¥å­é•¿åº¦å¾ˆé•¿ï¼Œå› æ­¤åœ¨åšæˆªæ–­çš„æ—¶å€™åé¢çš„å°±æ²¡æ³•è®­ç»ƒåˆ°äº†ï¼Œå¯ä»¥å°†æ–‡æœ¬å€’åºä½œä¸ºæ–°çš„æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚å¯ä»¥å……åˆ†åˆ©ç”¨åˆ°æ•°æ®</li>
<li>å°†æ•°æ®æ‰“ä¹±ã€éšæœºåˆ é™¤ï¼Œå®é™…ä¸Šå°±æ˜¯å¯¹ä¸€ä¸ªå¥å­çš„è¯è¿›è¡Œsampleå†ç»„åˆ</li>
<li>æ‰“ä¹±è¯åºä»¥å¢åŠ æ•°æ®é‡</li>
<li>ä½¿ç”¨pseudo labelingï¼Œä½†æœ‰çš„é˜Ÿä¼ä½¿ç”¨è¿™ä¸ªåšå‡ºæ•ˆæœäº†ï¼Œä½†æœ‰çš„æ²¡æœ‰</li>
</ul>
</li>
<li>ç‰¹å¾å·¥ç¨‹<ul>
<li>å‡è®¾å¼€å¤´ä¸­é—´ç»“å°¾çš„ä¿¡æ¯å¯¹åˆ†ç±»æœ‰å¸®åŠ©ï¼Œå› æ­¤æˆªå–è¯¥éƒ¨åˆ†ä¿¡æ¯åšè®­ç»ƒ</li>
<li>æ”¹è¿›baselineçš„tfidfçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºç†µçš„è¯æƒé‡è®¡ç®—</li>
<li>é™ç»´ï¼Œç•™ä¸‹æœ€é‡è¦çš„ç‰¹å¾ã€‚å…ˆç”¨å¡æ–¹åˆ†å¸ƒé™åˆ°20ä¸‡ï¼Œå†ç”¨SVDé™åˆ°8000</li>
<li>å°†word2vecå’ŒGloVeæ‹¼æ¥èµ·æ¥ä½œä¸ºdeep learningæ¨¡å‹çš„è¾“å…¥</li>
<li>å°†æ–‡ç« åˆ†æ®µï¼Œæ¯æ®µå–å‰20å20æ‹¼èµ·æ¥</li>
</ul>
</li>
<li>æ¨¡å‹èåˆ<br>  æ‰€æœ‰é˜Ÿä¼éƒ½æ— ä¸€ä¾‹å¤–ä½¿ç”¨äº†æ¨¡å‹èåˆï¼Œstackingæˆ–è€…ç®€å•çš„æŠ•ç¥¨<ul>
<li>DL+ML â€”&gt; lgbm model â€”&gt; voting</li>
<li>æ·±åº¦æ¨¡å‹+ä¼ ç»Ÿæ¨¡å‹ï¼Œåœ¨æ·±åº¦æ¨¡å‹æœ€åä¸€å±‚åŠ å…¥ä¼ ç»Ÿæ¨¡å‹çš„ä¿¡æ¯/feature</li>
<li>åå‘é€‰æ‹©å‰”é™¤å†—ä½™æ¨¡å‹</li>
</ul>
</li>
<li>DL&amp;å…¶ä»–<ul>
<li>HANï¼Œé€‰æ‹©10ä¸ªattention vector</li>
<li>å¯¹æ˜“é”™ç±»å¢åŠ æƒé‡ï¼Œé€šè¿‡æ”¹å˜æŸå¤±å‡½æ•°æ¥å¢åŠ æƒé‡</li>
<li>CNN, [1,2,3,4,5,6]*600</li>
<li>æå‡ºæ–°çš„æ¨¡å‹ï¼ˆç¬¬ä¸€åï¼‰</li>
</ul>
</li>
</ul>
<p>å…¶å®é™¤äº†ä¸€äº›trickï¼Œæˆ‘è¿˜æ˜¯æœ‰äº›å¤±æœ›çš„ï¼Œå› ä¸ºéƒ½æ˜¯ç”¨æ¨¡å‹èåˆå †å‡ºæ¥çš„ï¼Œè¿™ä¹Ÿè®©æˆ‘å¯¹æ¯”èµ›å¤±å»äº†ä¸€äº›å…´è¶£ã€‚è™½ç„¶èƒ½ç†è§£ç°åœ¨çš„æ¯”èµ›éƒ½æ˜¯è¿™æ ·çš„ï¼Œä½†æ„Ÿè§‰å®åœ¨å¤ªæš´åŠ›äº†ã€‚<br>å½“ç„¶ï¼Œå…¶ä¸­è¿˜æ˜¯æœ‰ä¸€äº›äº®ç‚¹çš„ï¼Œæœ‰ä¸€æ”¯é˜Ÿä¼ç«‹æ„å¾ˆé«˜ï¼Œä»ç†è§£ä¸šåŠ¡çš„è§’åº¦å‡ºå‘è€Œä¸æ˜¯å †æ¨¡å‹ï¼Œä¹Ÿå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼›è¿˜æœ‰ä¸€ä¸ªä½¿ç”¨äº†æœ€æ–°è®ºæ–‡ä¸­çš„ç‰¹å¾å·¥ç¨‹æ”¹è¿›æ–¹æ³•ï¼Œä»¤æˆ‘è€³ç›®ä¸€æ–°ï¼›ä»¥åŠç¬¬ä¸€ååœ¨æ¯”èµ›è¿‡ç¨‹ä¸­æå‡ºæ¥ä¸‰ä¸ªæ–°çš„æ¨¡å‹ã€‚</p>
<p>Anywayï¼Œæˆ‘ç›®å‰è¿˜æ˜¯å¤ªèœäº†ï¼Œè¿˜æ˜¯å®‰å¿ƒæç§‘ç ”å§ã€‚_(:Ğ·ã€âˆ )</p>
]]></content>
      <tags>
        <tag>æœ‰æ„Ÿ</tag>
        <tag>æ¯”èµ›</tag>
        <tag>è¾¾è§‚æ¯</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†7</title>
    <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%867/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œå¯ç”¨.item()æ¥è·å–å…ƒç´ </p>
<p>tensor &lt;â€”&gt; numpy ç›¸äº’è½¬åŒ–ä¼šå…±äº«å†…éƒ¨æ•°æ®ï¼Œå› æ­¤æ”¹å˜å…¶ä¸­ä¸€ä¸ªä¼šæ”¹å˜å¦ä¸€ä¸ª</p>
<p>å¯ç”¨ä½¿ç”¨ .to æ¥ç§»åŠ¨åˆ°è®¾å¤‡<br><img src="/images/2018-09-16-15370671350548.jpg" alt=""></p>
<p>.detech()  detach it from the computation history, and to prevent future computation from being tracked. å°†å…¶ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œå˜ä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”requires_grad=False</p>
<p>Function è®°å½•äº†è¿™ä¸ªtensoræ˜¯æ€ä¹ˆæ¥çš„ï¼Œæ‰€æœ‰çš„tensoréƒ½æœ‰ï¼Œé™¤éæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„ï¼š<br><img src="/images/2018-09-16-15370672806253.jpg" width="65%" height="50%"></p>
<hr>
<h3 id="2ï¸âƒ£-åæ–¹å·®"><a href="#2ï¸âƒ£-åæ–¹å·®" class="headerlink" title="2ï¸âƒ£[åæ–¹å·®]"></a>2ï¸âƒ£[åæ–¹å·®]</h3><p>å…³äºåæ–¹å·®çš„ç†è§£ï¼Œxä¸yå…³äºæŸä¸ªè‡ªå˜é‡çš„å˜åŒ–ç¨‹åº¦ï¼Œå³åº¦é‡äº†xä¸yä¹‹é—´çš„è”ç³»ã€‚<br><a href="https://www.zhihu.com/question/20852004" target="_blank" rel="noopener">https://www.zhihu.com/question/20852004</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>åæ–¹å·®</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 4:Classification:Probabilistic Generative Model</title>
    <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%204%20Classification%20%20Probabilistic%20Generative%20Model/</url>
    <content><![CDATA[<h3 id="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ</h3><p>1ï¸âƒ£å¦‚æœä½¿ç”¨regressionçš„æ€æƒ³æ¥åˆ†ç±»ï¼Œä¼šå¯¹ç¦»è¾¹ç•Œè¾ƒè¿œçš„ç‚¹è¿›è¡Œæƒ©ç½šï¼š<br><img src="/images/2018-09-16-15370662150910.jpg" width="70%" height="50%"></p>
<p>2ï¸âƒ£å¦‚æœå¤šåˆ†ç±»ä½¿ç”¨regressionï¼Œå¦‚class 1, class 2, class 3ï¼›åˆ™éšå¼åœ°å‡è®¾äº†class 1 å’Œ class 2è¾ƒä¸ºæ¥è¿‘ï¼Œå¦‚æœæ²¡æœ‰è¿™ç§æ¥è¿‘å…³ç³»ï¼Œåˆ™åˆ†ç±»ä¼šä¸æ­£ç¡®ã€‚</p>
<h3 id="é—®é¢˜æè¿°ä¸å®šä¹‰"><a href="#é—®é¢˜æè¿°ä¸å®šä¹‰" class="headerlink" title="é—®é¢˜æè¿°ä¸å®šä¹‰"></a>é—®é¢˜æè¿°ä¸å®šä¹‰</h3><p><img src="/images/2018-09-16-15370662762802.jpg" width="70%" height="50%"></p>
<p>å½“På¤§äº0.5åˆ™æ˜¯C1ç±»ï¼Œåä¹‹æ˜¯C2ç±»<br>å…ˆéªŒP(C1)å’ŒP(C2)éƒ½å¥½è®¡ç®—ï¼Œè®¡ç®—C1å æ€»çš„æ¯”ä¾‹å³å¯<br>å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—çš„å°±æ˜¯p(x|C)</p>
<p>è¿™ä¸€æƒ³æ³•ï¼Œæœ¬è´¨æ˜¯å¾—åˆ°äº†ç”Ÿæˆå¼æ¨¡å‹ï¼š<br><img src="/images/2018-09-16-15370663099515.jpg" width="70%" height="50%"></p>
<h3 id="åŸç†æ¦‚è¿°"><a href="#åŸç†æ¦‚è¿°" class="headerlink" title="åŸç†æ¦‚è¿°"></a>åŸç†æ¦‚è¿°</h3><p>ç°<strong>å‡è®¾è®­ç»ƒæ•°æ®ç‚¹çš„åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒ</strong>ï¼šï¼ˆæ˜¾ç„¶å¯ä»¥è‡ªå·±è®¾ä»»ä½•åˆ†å¸ƒï¼‰<br>å³æ•°æ®ä»é«˜æ–¯åˆ†å¸ƒé‡‡æ ·å¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370663870205.jpg" width="55%" height="50%"></p>
<p>æ ¹æ®æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå¯ä»¥è·å¾—æ¯ä¸ªç±»åˆ«çš„Î¼å’ŒÎ£ï¼š<br><img src="/images/2018-09-16-15370664041246.jpg" width="70%" height="50%"></p>
<p>å¾—åˆ°äº†å‚æ•°åï¼Œå³å¯ä»£å…¥å¾—åˆ°P(C|x) ï¼š<br><img src="/images/2018-09-16-15370664355955.jpg" width="80%" height="50%"></p>
<p>åˆšåˆšå‡è®¾$Î£$å¯¹äºä¸åŒç±»åˆ«ä¸åŒï¼Œç°æˆ‘ä»¬<strong>ä»¤ä¸åŒç±»åˆ«å…±äº«ç›¸åŒ$Î£$</strong>ï¼š<br>ï¼ˆå› ä¸ºåæ–¹å·®ä»£è¡¨çš„æ˜¯ä¸åŒfeatureä¹‹é—´çš„è”ç³»ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯å’Œç±»åˆ«æ— å…³çš„ï¼‰</p>
<p>$Î£$çš„è®¡ç®—å…¬å¼æ˜¯åŠ æƒæ±‚å’Œï¼š<br><img src="/images/2018-09-16-15370665362081.jpg" width="24%" height="50%"></p>
<p>åœ¨ä½¿ç”¨äº†ç›¸åŒçš„åæ–¹å·®çŸ©é˜µåï¼Œè¾¹ç•Œå°±æ˜¯çº¿æ€§çš„ï¼ˆåé¢ä¼šæåˆ°ä¸ºä»€ä¹ˆæ˜¯è¿™æ ·ï¼‰ï¼š<br><img src="/images/2018-09-16-15370665553962.jpg" alt=""></p>
<p> æ€»ç»“ï¼š<br> ä¸‰æ­¥èµ°ï¼Œå®šä¹‰function setï¼Œè®¡ç®—Î¼å’Œåæ–¹å·®çŸ©é˜µï¼Œå¾—åˆ°best functionï¼š<br><img src="/images/2018-09-16-15370665888683.jpg" width="60%" height="50%"></p>
<p>æ³¨æ„åˆ°ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºï¼Œä¸åŒfeatureä¹‹é—´æ²¡æœ‰å…³ç³»ï¼Œæ¯ä¸ªfeatureç¬¦åˆç‰¹å®šçš„é«˜æ–¯åˆ†å¸ƒï¼Œåˆ™è¯¥åˆ†ç±»å™¨åˆ™æ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼š<br><img src="/images/2018-09-16-15370666092459.jpg" width="60%" height="50%"></p>
<h3 id="åˆ†ç±»ä¸logistics-regression"><a href="#åˆ†ç±»ä¸logistics-regression" class="headerlink" title="åˆ†ç±»ä¸logistics regression"></a>åˆ†ç±»ä¸logistics regression</h3><p>ç°æ¨å¯¼ï¼Œè¯¥åˆ†ç±»é—®é¢˜ä¸logistics regressionä¹‹é—´çš„è”ç³»ï¼š<br>å³ï¼š<br><img src="/images/2018-09-16-15370666567324.jpg" width="60%" height="50%"></p>
<h4 id="å‡è®¾"><a href="#å‡è®¾" class="headerlink" title="å‡è®¾"></a>å‡è®¾</h4><p>æ•°æ®æœä»é«˜æ–¯åˆ†å¸ƒï¼Œå…±äº«$Î£$</p>
<h4 id="æ¨å¯¼"><a href="#æ¨å¯¼" class="headerlink" title="æ¨å¯¼"></a>æ¨å¯¼</h4><p>â‘ æ€»æ¡†æ¶ï¼š<br><img src="/images/2018-09-16-15370667000974.jpg" width="50%" height="50%"></p>
<p>ä»¤<br><img src="/images/2018-09-16-15370667135868.jpg" width="24%" height="50%"></p>
<p>åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370667376312.jpg" width="50%" height="50%"></p>
<p>â‘¡zçš„è¿›ä¸€æ­¥æ¨å¯¼ä¸ç®€åŒ–ï¼š<br><img src="/images/2018-09-16-15370667582564.jpg" width="30%" height="50%"></p>
<p>å°†zå±•å¼€ï¼š<br><img src="/images/2018-09-16-15370667763267.jpg" width="50%" height="50%"></p>
<p>è€Œç¬¬ä¸€éƒ¨åˆ†æœ‰ï¼š<br><img src="/images/2018-09-16-15370667880942.jpg" width="50%" height="50%"></p>
<p>ç¬¬ä¸€éƒ¨åˆ†ç›¸é™¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668274551.jpg" width="50%" height="50%"></p>
<p>å†è¿›è¡Œå±•å¼€ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668394919.jpg" width="50%" height="50%"></p>
<p>æœ€ç»ˆzçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-16-15370668522531.jpg" width="50%" height="50%"></p>
<p>ç”±äºå…±äº«åæ–¹å·®çŸ©é˜µï¼Œåˆ™å¯ä»¥æ¶ˆå»éƒ¨åˆ†ï¼Œå¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370668957564.jpg" width="50%" height="50%"></p>
<p>æ›¿æ¢æˆwå’Œbï¼š<br><img src="/images/2018-09-16-15370669103562.jpg" width="50%" height="50%"></p>
<p>â‘¢æœ€ç»ˆï¼Œå°†zå¸¦å›åˆ°åŸå¼ï¼š<br><img src="/images/2018-09-16-15370669221472.jpg" width="25%" height="50%"></p>
<p>æ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦å†ä¼°è®¡N1,N2,Î¼å’ŒÎ£ï¼Œç›´æ¥è®¡ç®—wå’Œbå³å¯ã€‚ä¹Ÿå› æ­¤ï¼Œåˆ†ç•Œçº¿æ˜¯çº¿æ€§çš„ã€‚</p>
<p>å…¨è¿‡ç¨‹ï¼š<br><img src="/images/2018-09-16-15370669594744.jpg" alt=""></p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Classification</tag>
        <tag>Probabilistic Generative Model</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 3:Gradient Descent</title>
    <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%203%20Gradient%20Descent/</url>
    <content><![CDATA[<h2 id="Gradient-Descent-tips"><a href="#Gradient-Descent-tips" class="headerlink" title="Gradient Descent tips"></a>Gradient Descent tips</h2><h3 id="tip-1ï¼šAdaptive-Learning-Rates"><a href="#tip-1ï¼šAdaptive-Learning-Rates" class="headerlink" title="tip 1ï¼šAdaptive Learning Rates"></a>tip 1ï¼šAdaptive Learning Rates</h3><h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><h5 id="åŸºæœ¬æ€æƒ³"><a href="#åŸºæœ¬æ€æƒ³" class="headerlink" title="åŸºæœ¬æ€æƒ³"></a>åŸºæœ¬æ€æƒ³</h5><p><img src="/images/2018-09-16-15370654467771.jpg" width="30%" height="50%"></p>
<p><img src="/images/2018-09-16-15370654502774.jpg" width="20%" height="50%"></p>
<p>å…¶ä¸­Ïƒæ˜¯ä¹‹å‰æ‰€æœ‰çš„æ¢¯åº¦çš„å¹³æ–¹æ ¹<br><img src="/images/2018-09-16-15370654728457.jpg" width="30%" height="50%"></p>
<p>åŒ–ç®€å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370654853172.jpg" width="50%" height="50%"></p>
<h5 id="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"></a>ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ</h5><p>è€ƒè™‘ä¸€ä¸ªå¼€å£å‘ä¸Šçš„äºŒæ¬¡å‡½æ•°<br><img src="/images/2018-09-16-15370655091732.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå³ï¼Œæœ€å¥½çš„æ­¥é•¿æ˜¯ä¸€æ¬¡å¯¼é™¤ä»¥äºŒæ¬¡å¯¼ï¼Œä½†äºŒæ¬¡å¯¼è®¡ç®—é‡å¤§ï¼Œå› æ­¤ä½¿ç”¨è¿‘ä¼¼çš„æ–¹å¼ï¼š<br><strong>å¯¹ä¸€æ¬¡å¯¼ä½œå¤šæ¬¡çš„sample</strong>ã€‚<br>ä¸‹å›¾æ˜¾ç¤ºï¼Œå¦‚æœäºŒæ¬¡å¯¼å°ï¼Œé‚£ä¹ˆå¤šæ¬¡sampleè·å¾—çš„ä¸€æ¬¡å¯¼ä¹Ÿå°ï¼Œåä¹‹åˆ™å¤§ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€æ¬¡å¯¼åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥åæ˜ äºŒæ¬¡å¯¼çš„å¤§å°ï¼Œæ‰€ä»¥ç›´æ¥ç”¨ä¸€æ¬¡å¯¼è¿‘ä¼¼ï¼Œå¯ä»¥å‡å°‘è®¡ç®—é‡ã€‚</p>
<p><img src="/images/2018-09-16-15370655850876.jpg" width="50%" height="50%"></p>
<h3 id="tip-2ï¼šfeature-scaling"><a href="#tip-2ï¼šfeature-scaling" class="headerlink" title="tip 2ï¼šfeature scaling"></a>tip 2ï¼šfeature scaling</h3><p><img src="/images/2018-09-16-15370656836724.jpg" width="50%" height="50%"></p>
<p>èƒ½å¤Ÿæ”¹å˜lossçš„åˆ†å¸ƒï¼Œä¸Šå›¾1ä¸­w2å¯¹lossçš„å½±å“è¾ƒå¤§ï¼Œåˆ™è¾ƒé™¡å³­ï¼Œå‚æ•°æ›´æ–°å°±è¾ƒå›°éš¾ï¼Œéœ€è¦adaptive learning rateï¼›å¦‚æœè¿›è¡Œfeature scalingï¼Œèƒ½å¤Ÿæ›´å¥½è¾¾åˆ°local optimal</p>
<h2 id="Gradient-Descent-Theory"><a href="#Gradient-Descent-Theory" class="headerlink" title="Gradient Descent Theory"></a>Gradient Descent Theory</h2><p>å¦ä¸€ç§è§’åº¦çœ‹gradient descentï¼š</p>
<p>åŸºæœ¬æ€æƒ³ï¼š<br>æˆ‘ä»¬å¸Œæœ›æ¯ä¸€æ¬¡éƒ½åœ¨å½“å‰ç‚¹é™„è¿‘æ‰¾åˆ°ä¸€ä¸ªæœ€å°çš„ç‚¹ï¼Œå³åœ¨ä¸€ä¸ªèŒƒå›´å†…ï¼š<br><img src="/images/2018-09-16-15370657785697.jpg" width="40%" height="50%"></p>
<p>åº”è¯¥å¦‚ä½•æ‰¾åˆ°è¯¥æœ€å°ç‚¹ï¼Ÿ</p>
<p>æˆ‘ä»¬çŸ¥é“ï¼Œæ³°å‹’çº§æ•°çš„å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370658066669.jpg" width="50%" height="50%"></p>
<p>å½“xæ¥è¿‘x0æ—¶ï¼Œä¼šæœ‰å¦‚ä¸‹è¿‘ä¼¼ï¼š<br><img src="/images/2018-09-16-15370658167935.jpg" width="30%" height="50%"></p>
<p>æ¨å¹¿åˆ°å¤šå…ƒæ³°å‹’çº§æ•°åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370658315314.jpg" width="60%" height="50%"></p>
<p>é‚£ä¹ˆï¼Œå¦‚å‰æ‰€è¿°ï¼Œxæ¥è¿‘x0ï¼Œå¯¹äºå›¾ä¸­ï¼Œå³åœ†åœˆè¶³å¤Ÿå°æ—¶ï¼š<br><img src="/images/2018-09-16-15370658494091.jpg" width="50%" height="50%"></p>
<p>ç®€åŒ–ç¬¦å·ï¼š<br><img src="/images/2018-09-16-15370658736683.jpg" width="12%" height="50%"></p>
<p><img src="/images/2018-09-16-15370658623258.jpg" width="30%" height="50%"></p>
<p>æ‰€ä»¥å¯ä»¥ç®€å†™æˆï¼š<br><img src="/images/2018-09-16-15370658855882.jpg" width="30%" height="50%"></p>
<p>ç”±äºs,u,véƒ½æ˜¯å¸¸æ•°ï¼Œåœ¨åœ†åœˆèŒƒå›´å†…å¯»æ‰¾æœ€å°å€¼å¯¹åº”çš„å‚æ•°å¯ä»¥ç®€åŒ–æˆï¼š<br><img src="/images/2018-09-16-15370658981519.jpg" width="40%" height="50%"></p>
<p><img src="/images/2018-09-16-15370659061025.jpg" width="30%" height="50%"></p>
<p>å†åº¦ç®€åŒ–ï¼Œå¯ä»¥è¡¨è¾¾æˆï¼š<br><img src="/images/2018-09-16-15370659680601.jpg" width="40%" height="50%"></p>
<p><img src="/images/2018-09-16-15370659747339.jpg" width="30%" height="50%"></p>
<p>åœ¨å›¾ä¸­å¯ä»¥ç”»ä¸ºä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯<br><img src="/images/2018-09-16-15370660126195.jpg" width="40%" height="50%"></p>
<p>æ˜¾ç„¶ï¼Œå½“åæ–¹å‘æ—¶ï¼Œæœ€å°ï¼š<br><img src="/images/2018-09-16-15370660243469.jpg" width="40%" height="50%"></p>
<p>ä¹Ÿå³ï¼š<br><img src="/images/2018-09-16-15370660628961.jpg" width="50%" height="50%"></p>
<p>æœ€ç»ˆå®Œæ•´çš„å¼å­ï¼š<br><img src="/images/2018-09-16-15370660794436.jpg" width="55%" height="50%"></p>
<p>å› æ­¤ï¼Œå½“learning rateä¸å¤Ÿå°æ—¶ï¼Œæ˜¯ä¸æ»¡è¶³æ³°å‹’çº§æ•°è¿‘ä¼¼çš„ã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>Gradient Descent</tag>
      </tags>
  </entry>
  <entry>
    <title>Lecture 2:Bias and Variance</title>
    <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%202%20Bias%20and%20Variance/</url>
    <content><![CDATA[<h3 id="å¦‚ä½•ç†è§£bias-amp-variance"><a href="#å¦‚ä½•ç†è§£bias-amp-variance" class="headerlink" title="å¦‚ä½•ç†è§£bias&amp;variance"></a>å¦‚ä½•ç†è§£bias&amp;variance</h3><p><img src="/images/2018-09-16-15370650140053.jpg" width="40%" height="50%"><br>biasæ˜¯function spaceä¸­å¿ƒç¦»optimal modelçš„å·®è·ï¼Œvarianceæ˜¯æŸæ¬¡å®éªŒæ‰€å¾—æ¨¡å‹ç¦»function spaceä¸­å¿ƒçš„è·ç¦»ã€‚</p>
<p>æ¯”å¦‚è¯´ï¼Œç®€å•åœ°æ¨¡å‹çš„function spaceå°ï¼Œéšæœºæ€§å°ï¼Œå› æ­¤varianceå°ï¼Œä½†ä¹Ÿå› ä¸ºfunction spaceå°ï¼Œè¡¨ç¤ºèƒ½åŠ›æœ‰é™ï¼Œå› æ­¤biaså¤§ã€‚</p>
<p>å¦‚å›¾ï¼š<br><img src="/images/2018-09-16-15370651353167.jpg" width="70%" height="50%"><br>è¯¥å›¾ä¸­è“è‰²åœˆä»£è¡¨æ¨¡å‹æ‰€èƒ½è¡¨è¾¾çš„èŒƒå›´ã€‚</p>
<h3 id="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"><a href="#å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜" class="headerlink" title="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"></a>å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜</h3><p>â‘ æ›´å¤šçš„data<br>â‘¡regularizationï¼šå¼ºè¿«functionæ›´å¹³æ»‘ï¼Œå› æ­¤å‡å°varianceï¼Œä½†å› ä¸ºè°ƒæ•´äº†function spaceï¼Œå¯èƒ½ä¼šå¢åŠ biasã€‚</p>
]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ ğŸ¤–</tag>
        <tag>æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹</tag>
        <tag>bias&amp;variance</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯9</title>
    <url>/2018/09/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D9/</url>
    <content><![CDATA[<h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€</strong>ã€‚<br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„ã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p>
<hr>
<h3 id="ç»å‘½è¯—"><a href="#ç»å‘½è¯—" class="headerlink" title="ç»å‘½è¯—"></a>ç»å‘½è¯—</h3><p>è°­å—£åŒ<br>æœ›é—¨æŠ•æ­¢æ€å¼ ä¿­ï¼Œ<br>å¿æ­»é¡»è‡¾å¾…æœæ ¹ã€‚<br><strong>æˆ‘è‡ªæ¨ªåˆ€å‘å¤©ç¬‘ï¼Œ<br>å»ç•™è‚èƒ†ä¸¤æ˜†ä»‘ï¼</strong></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch backward()æµ…æ</title>
    <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Pytorch%20backward()%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<p>æœ€è¿‘åœ¨çœ‹pytorchæ–‡æ¡£çš„æ—¶å€™ï¼Œçœ‹åˆ°backwardå†…æœ‰ä¸€ä¸ªå‚æ•°gradientï¼Œåœ¨ç»è¿‡æŸ¥é˜…äº†ç›¸å…³èµ„æ–™å’Œè¿›è¡Œäº†å®éªŒåï¼Œå¯¹backwardæœ‰äº†æ›´æ·±çš„è®¤è¯†ã€‚</p>
<h2 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h2><p>1ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¦‚ï¼š<code>loss.backward()</code><br>åˆ™gradientä¸éœ€è¦æ‰‹åŠ¨ä¼ å…¥ï¼Œä¼šè‡ªåŠ¨æ±‚å¯¼ã€‚<br>ä¾‹å­:<br>$a=[x_1,x_2],b=\frac{x_1+x_2}{2}$<br>åˆ™bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b}{\partial x_{1}}=\frac{1}{2}ï¼Œ\dfrac {\partial b}{\partial x_{2}}=\frac{1}{2}$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.Tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.mean(a)  <span class="comment">#tensor(2.5000, grad_fn=&lt;MeanBackward1&gt;)</span></span><br><span class="line">b.backward()</span><br><span class="line">a.grad   <span class="comment">#tensor([0.5000, 0.5000])</span></span><br></pre></td></tr></table></figure>
<p>gradientæ­¤æ—¶åªæ˜¯åœ¨ç¼©æ”¾åŸgradçš„å¤§å°ï¼Œä¹Ÿå³ä¸æŒ‡å®šgradientå’Œgradient=1æ˜¯ç­‰ä»·çš„</p>
<p>å½“ç„¶ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šgradientï¼Œå…¶ä¸­æŒ‡å®šgradientçš„shapeå¿…é¡»å’Œbçš„ç»´åº¦ç›¸åŒ<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gradient=torch.tensor(<span class="number">10.0</span>)</span><br><span class="line">b.backward(gradient)</span><br><span class="line">a.grad   <span class="comment">#tensor([5., 5.])</span></span><br></pre></td></tr></table></figure></p>
<p>2ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªå‘é‡<br>ä¾‹å­ï¼š<br>$a=[x_1,x_2],b=[b_1,b_2]$, å…¶ä¸­ $b_1=x_1+x_2,b_2=x_1*x_2$<br>bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b_1}{\partial x_{1}}=1,\dfrac {\partial b_1}{\partial x_{2}}=1$</p>
<p>$\dfrac {\partial b_2}{\partial x_{1}}=x_2,\dfrac {\partial b_2}{\partial x_{2}}=x_1$</p>
<p>åœ¨backwardçš„æ—¶å€™åˆ™å¿…é¡»æŒ‡å®šgradientã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.FloatTensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.zeros(<span class="number">2</span>)</span><br><span class="line">b[<span class="number">0</span>]=a[<span class="number">0</span>]+a[<span class="number">1</span>]</span><br><span class="line">b[<span class="number">1</span>]=a[<span class="number">0</span>]*a[<span class="number">1</span>]    <span class="comment"># b=tensor([5., 6.], grad_fn=&lt;CopySlices&gt;)</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">0.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment">#tensor([1., 1.])ï¼Œè¯´æ˜æ˜¯å¯¹b_1è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()  <span class="comment">#å°†æ¢¯åº¦æ¸…ç©ºï¼Œå¦åˆ™ä¼šå åŠ </span></span><br><span class="line"><span class="comment">#-------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">0.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad  <span class="comment"># tensor([3., 2.])ï¼Œè¯´æ˜å¯¹b_2è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()</span><br><span class="line"><span class="comment"># ------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment"># tensor([4., 3.])ï¼Œå³b_1,b_2çš„å¯¼æ•°çš„å åŠ </span></span><br><span class="line">a.grad.zero_()</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„åˆ°b.backward()æ—¶éœ€è¦retain_graphè®¾ä¸ºTrueï¼Œå¦åˆ™åœ¨è®¡ç®—å®Œåä¼šè‡ªåŠ¨é‡Šæ”¾è®¡ç®—å›¾çš„å†…å­˜ï¼Œè¿™æ ·å°±æ²¡æ³•è¿›è¡ŒäºŒæ¬¡åå‘ä¼ æ’­äº†ã€‚</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.pytorchtutorial.com/pytorch-backward/" target="_blank" rel="noopener">https://www.pytorchtutorial.com/pytorch-backward/</a></p>
]]></content>
      <tags>
        <tag>Pytorch</tag>
        <tag>backward</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯8</title>
    <url>/2018/09/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D8/</url>
    <content><![CDATA[<h3 id="æœ›æœˆæ€€è¿œ"><a href="#æœ›æœˆæ€€è¿œ" class="headerlink" title="æœ›æœˆæ€€è¿œ"></a>æœ›æœˆæ€€è¿œ</h3><p>[å”] å¼ ä¹é¾„<br><strong>æµ·ä¸Šç”Ÿæ˜æœˆï¼Œå¤©æ¶¯å…±æ­¤æ—¶ã€‚</strong><br>æƒ…äººæ€¨é¥å¤œï¼Œç«Ÿå¤•èµ·ç›¸æ€ã€‚<br>ç­çƒ›æ€œå…‰æ»¡ï¼ŒæŠ«è¡£è§‰éœ²æ»‹ã€‚<br>ä¸å ªç›ˆæ‰‹èµ ï¼Œè¿˜å¯æ¢¦ä½³æœŸã€‚</p>
<p>é¥å¤œï¼Œé•¿å¤œã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57aca120a341310060e2a09f" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aca120a341310060e2a09f</a></p>
<hr>
<h3 id="æ— é¢˜"><a href="#æ— é¢˜" class="headerlink" title="æ— é¢˜"></a>æ— é¢˜</h3><p>è¨é•‡å†°<br>äº”åä¸ƒè½½çŠ¹å¦‚æ¢¦ï¼Œä¸¾å›½æ²¦äº¡ç¼˜æ±‰åŸã€‚<br><strong>é¾™æ¸¸æµ…æ°´å‹¿è‡ªå¼ƒï¼Œç»ˆæœ‰æ‰¬çœ‰åæ°”å¤©ã€‚</strong></p>
<p>1951å¹´ï¼Œä¸­å›½äººæ°‘å¿—æ„¿å†›åœ¨æŠ—ç¾æ´æœæˆ˜äº‰ç¬¬ä¸‰æ¬¡æˆ˜å½¹åæ‰“è¿›äº†æ±‰åŸï¼Œè¨é•‡å†°å¾—çŸ¥æ­¤äº‹ï¼Œå›æƒ³èµ·57å¹´å‰çš„ç”²åˆæ‚²æ­Œï¼Œå½“å³ä½œè¯—ä¸€é¦–ã€‚</p>
<hr>
<h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€ã€‚</strong><br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„</strong>ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯7</title>
    <url>/2018/09/02/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D7/</url>
    <content><![CDATA[<h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„é£ã€‚çˆ½ç±å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éã€‚ç¢å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼›é‚ºæ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ã€‚å››ç¾å…·ï¼ŒäºŒéš¾å¹¶ã€‚ç©·ç‡çœ„äºä¸­å¤©ï¼Œæå¨±æ¸¸äºæš‡æ—¥ã€‚å¤©é«˜åœ°è¿¥ï¼Œè§‰å®‡å®™ä¹‹æ— ç©·ï¼›å…´å°½æ‚²æ¥ï¼Œè¯†ç›ˆè™šä¹‹æœ‰æ•°ã€‚æœ›é•¿å®‰äºæ—¥ä¸‹ï¼Œç›®å´ä¼šäºäº‘é—´ã€‚åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œã€‚å…³å±±éš¾è¶Šï¼Œè°æ‚²å¤±è·¯ä¹‹äººï¼›èæ°´ç›¸é€¢ï¼Œå°½æ˜¯ä»–ä¹¡ä¹‹å®¢ã€‚æ€€å¸é˜è€Œä¸è§ï¼Œå¥‰å®£å®¤ä»¥ä½•å¹´ï¼Ÿ</p>
<hr>
<p><strong>æ³¨é‡Šï¼š</strong><br>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„ï¼ˆchuÃ¡nï¼‰é£ï¼šç™»é«˜æœ›è¿œçš„èƒ¸æ€€é¡¿æ—¶èˆ’ç•…ï¼Œé£˜æ¬²è„±ä¿—çš„å…´è‡´æ²¹ç„¶è€Œç”Ÿã€‚</p>
<p>çˆ½ç±ï¼ˆlÃ iï¼‰å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éï¼šå®´ä¼šä¸Šï¼Œæ’ç®«å“èµ·ï¼Œå¥½åƒæ¸…é£æ‹‚æ¥ï¼›æŸ”ç¾çš„æ­Œå£°ç¼­ç»•ä¸æ•£ï¼Œéæ­¢äº†ç™½äº‘é£åŠ¨ã€‚çˆ½ï¼šå½¢å®¹ç±çš„å‘éŸ³æ¸…è„†ã€‚ç±ï¼šæ’ç®«ï¼Œä¸€ç§ç”±å¤šæ ¹ç«¹ç®¡ç¼–æ’è€Œæˆçš„ç®¡ä¹å™¨ã€‚</p>
<p>ç¢ï¼ˆsuÄ«ï¼‰å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼šä»Šæ—¥çš„å®´ä¼šï¼Œå¥½æ¯”å½“å¹´ç¢å›­ç«¹æ—çš„èšä¼šï¼Œåœ¨åº§çš„æ–‡äººé›…å£«ï¼Œè±ªçˆ½å–„é¥®çš„æ°”æ¦‚è¶…è¿‡äº†é™¶æ¸Šæ˜ã€‚ç¢å›­ï¼šè¥¿æ±‰æ¢å­ç‹åœ¨ç¢æ°´æ—ä¿®å»ºçš„ç«¹å›­ï¼Œä»–å¸¸å’Œä¸€äº›æ–‡äººåœ¨æ­¤é¥®é…’èµ‹è¯—ã€‚</p>
<p>é‚ºï¼ˆyÃ¨ï¼‰æ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ï¼šè¿™æ˜¯å€Ÿè¯—äººæ›¹æ¤ã€è°¢çµè¿æ¥æ¯”æ‹Ÿå‚åŠ å®´ä¼šçš„æ–‡äººã€‚é‚ºï¼šä»Šæ²³åŒ—ä¸´æ¼³ï¼Œæ˜¯æ›¹é­å…´èµ·çš„åœ°æ–¹ã€‚æ›¹æ¤æ›¾åœ¨è¿™é‡Œä½œè¿‡ã€Šå…¬å®´è¯—ã€‹ï¼Œè¯—ä¸­æœ‰â€œæœ±åå†’ç»¿æ± â€çš„å¥å­ã€‚ä¸´å·ä¹‹ç¬”ï¼šæŒ‡è°¢çµè¿ï¼Œä»–æ›¾ä»»ä¸´å·ï¼ˆä»Šå±æ±Ÿè¥¿ï¼‰å†…å²ã€‚</p>
<p>å››ç¾ï¼šæŒ‡è‰¯è¾°ã€ç¾æ™¯ã€èµå¿ƒã€ä¹äº‹ã€‚</p>
<p>äºŒéš¾ï¼šè´¤ä¸»ã€å˜‰å®¾ã€‚</p>
<p>åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œï¼šåœ°åŠ¿åè¿œï¼Œå—æµ·æ·±é‚ƒï¼›å¤©æŸ±é«˜è€¸ï¼ŒåŒ—ææ˜Ÿè¿œæ‚¬ã€‚</p>
<p>å¸é˜ï¼ˆhÅ«nï¼‰ï¼šåŸæŒ‡å¤©å¸çš„å®ˆé—¨è€…ã€‚è¿™é‡ŒæŒ‡çš‡å¸çš„å®«é—¨ã€‚</p>
<p>å¥‰å®£å®¤ä»¥ä½•å¹´ï¼šä»€ä¹ˆæ—¶å€™æ‰èƒ½åƒè´¾è°Šé‚£æ ·å»ä¾å¥‰å›ç‹å‘¢</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†6</title>
    <url>/2018/09/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%866/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-dropout"><a href="#1ï¸âƒ£-dropout" class="headerlink" title="1ï¸âƒ£[dropout]"></a>1ï¸âƒ£[dropout]</h3><p>dropoutå½¢å¼:<br><img src="/images/2018-09-02-15358857481798.jpg" width="70%" height="50%"><br>RNNçš„å½¢å¼æœ‰å¤šç§ï¼š</p>
<ul>
<li><p>recurrent dropout<br>RNN: $h_t=f(W_h âŠ™ [x_t,h_{t-1}]+b_h)$<br>åŠ ä¸Šdropoutçš„RNNï¼š$h_t=f(W_h âŠ™ [x_t,d(h_{t-1})]+b_h)$ï¼Œå…¶ä¸­$d(\cdot)$ä¸ºdropoutå‡½æ•°<br>åŒç†ï¼š<br>LSTM:$c_t=f_t âŠ™c_{t-1} + i_t âŠ™ d(g_t)$<br>GRU:$h_t=(1-z_t)âŠ™c_{t-1}+z_tâŠ™d(g_t)$</p>
</li>
<li><p>å‚ç›´è¿æ¥çš„dropout<br>dropoutçš„ä½œç”¨å³æ˜¯å¦å…è®¸Lå±‚æŸä¸ªLSTMå•å…ƒçš„éšçŠ¶æ€ä¿¡æ¯æµå…¥L+1å±‚å¯¹åº”å•å…ƒã€‚<br><img src="/images/2018-09-02-15358866404870.jpg" width="50%" height="50%"></p>
</li>
</ul>
<p>Reference:<br><a href="https://blog.csdn.net/falianghuang/article/details/72910161" target="_blank" rel="noopener">https://blog.csdn.net/falianghuang/article/details/72910161</a></p>
<hr>
<h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>pack_padded_sequenceç”¨äºRNNä¸­ï¼Œå°†paddingçŸ©é˜µå‹ç¼©:<br><img src="/images/2018-09-02-15358868858836.jpg" width="60%" height="50%"><br>è¿™æ ·å°±å¯ä»¥å®ç°åœ¨RNNä¼ è¾“è¿‡ç¨‹ä¸­çŸ­å¥æå‰ç»“æŸã€‚</p>
<p>pad_packed_sequenceæ˜¯pack_padded_sequenceçš„é€†è¿ç®—ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>dropout</tag>
      </tags>
  </entry>
  <entry>
    <title>æˆ‘æ²¡æœ‰è¯´è¯</title>
    <url>/2018/08/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%88%91%E6%B2%A1%E6%9C%89%E8%AF%B4%E8%AF%9D/</url>
    <content><![CDATA[<p>ã€Šæˆ‘æ²¡æœ‰è¯´è¯ã€‹</p>
<p>çº³ç²¹æ€å…±äº§å…šæ—¶ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å…±äº§å…šå‘˜ï¼›<br>æ¥ç€ä»–ä»¬è¿«å®³çŠ¹å¤ªäººï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯çŠ¹å¤ªäººï¼›<br>ç„¶åä»–ä»¬æ€å·¥ä¼šæˆå‘˜ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å·¥ä¼šæˆå‘˜ï¼›<br>åæ¥ä»–ä»¬è¿«å®³å¤©ä¸»æ•™å¾’ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘æ˜¯æ–°æ•™å¾’ï¼›<br>æœ€åå½“ä»–ä»¬å¼€å§‹å¯¹ä»˜æˆ‘çš„æ—¶å€™ï¼Œ<br>å·²ç»æ²¡æœ‰äººèƒ½ç«™å‡ºæ¥ä¸ºæˆ‘å‘å£°äº†</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning NLP best practicesç¬”è®°</title>
    <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Deep%20Learning%20NLP%20best%20practices%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>åšå®¢åœ°å€ï¼š<a href="http://ruder.io/deep-learning-nlp-best-practices/index.html" target="_blank" rel="noopener">http://ruder.io/deep-learning-nlp-best-practices/index.html</a><br>ä¸ªäººè§‰å¾—è¿™ç¯‡æ–‡ç« å†™å¾—å¾ˆå¥½ï¼Œæœ‰è®¸å¤šå®è·µå¾—åˆ°çš„ç»éªŒï¼Œé€šè¿‡è¿™ç¯‡å¯ä»¥é¿å…èµ°ä¸€äº›å¼¯è·¯ã€‚</p>
<h2 id="Practices"><a href="#Practices" class="headerlink" title="Practices"></a>Practices</h2><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><blockquote>
<p>The optimal dimensionality of word embeddings is mostly task-dependent: a smaller dimensionality works better for more syntactic tasks such as named entity recognition or part-of-speech (POS) tagging, while a larger dimensionality is more useful for more semantic tasks such as sentiment analysis.</p>
</blockquote>
<p>å¯¹äºåå‘è¯­æ³•çš„ï¼Œä½¿ç”¨ç»´åº¦ä½ä¸€äº›çš„è¯å‘é‡ï¼›è€Œå¯¹äºåå‘è¯­ä¹‰å†…å®¹çš„ï¼Œä½¿ç”¨ç»´åº¦å¤§ä¸€äº›çš„è¯å‘é‡ï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€‚</p>
<h3 id="LSTM-Depth"><a href="#LSTM-Depth" class="headerlink" title="LSTM Depth"></a>LSTM Depth</h3><blockquote>
<p>performance improvements of making the model deeper than 2 layers are minimal </p>
</blockquote>
<p>LSTMæ·±åº¦æœ€å¥½ä¸è¦è¶…è¿‡ä¸¤å±‚ã€‚</p>
<h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><blockquote>
<p>It is often thought that Adam clearly outperforms vanilla stochastic gradient descent (SGD). However, while it converges much faster than SGD, it has been observed that SGD with learning rate annealing slightly outperforms Adam. Recent work furthermore shows that SGD with properly tuned momentum outperforms Adam .</p>
</blockquote>
<p>Adamå¯ä»¥æ›´æ—©æ‹Ÿåˆï¼Œè€ŒSGDæ•ˆæœå¯èƒ½ä¼šæ›´å¥½ä¸€äº›ã€‚</p>
<p>å¯ä»¥é‡‡ç”¨ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨Adamè®­ç»ƒç›´åˆ°æ‹Ÿåˆï¼Œç„¶åå°†å­¦ä¹ ç‡å‡åŠï¼Œå¹¶é‡æ–°å¯¼å…¥ä¹‹å‰è®­ç»ƒå¥½çš„æœ€å¥½çš„æ¨¡å‹ã€‚è¿™æ ·Adamèƒ½å¤Ÿå¿˜è®°ä¹‹å‰çš„ä¿¡æ¯å¹¶é‡æ–°å¼€å§‹è®­ç»ƒã€‚</p>
<blockquote>
<p>Denkowski &amp; Neubig (2017) show that Adam with 2 restarts and learning rate annealing is faster and performs better than SGD with annealing</p>
</blockquote>
<h3 id="Ensembling"><a href="#Ensembling" class="headerlink" title="Ensembling"></a>Ensembling</h3><blockquote>
<p>Combining multiple models into an ensemble by averaging their predictions is a proven strategy to improve model performance.</p>
</blockquote>
<p>Ensemblingå¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯éœ€è¦ä¿è¯å¤šæ ·æ€§ï¼š</p>
<blockquote>
<p>Ensembling is an important way to ensure that results are still reliable if the diversity of the evaluated models increases (Denkowski &amp; Neubig, 2017). While ensembling different checkpoints of a model has been shown to be effective (Jean et al., 2015; Sennrich et al., 2016) [51, 52], it comes at the cost of model diversity. Cyclical learning rates can help to mitigate this effect</p>
</blockquote>
<h3 id="LSTM-tricks"><a href="#LSTM-tricks" class="headerlink" title="LSTM tricks"></a>LSTM tricks</h3><ul>
<li><p>åœ¨initial stateä¸­æˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨å…¨0å‘é‡ï¼Œå®é™…ä¸Šå¯ä»¥å°†å…¶ä½œä¸ºå‚æ•°å­¦ä¹ ã€‚</p>
<blockquote>
<p>Instead of fixing the initial state, we can learn it like any other parameter, which can improve performance</p>
</blockquote>
</li>
<li><p>å°†inputå’Œoutput embeddingçš„å‚æ•°å…±äº«ï¼Œå¦‚æœæ˜¯åšlanguage modelæˆ–è€…æœºå™¨ç¿»è¯‘ä¹‹ç±»çš„ï¼Œå¯ä»¥è®©ä»–ä»¬å…±äº«ã€‚</p>
</li>
<li><p>Gradient Norm Clipping</p>
<blockquote>
<p>Rather than clipping each gradient independently, clipping the global norm of the gradient yields more significant improvements</p>
</blockquote>
</li>
</ul>
<p>è¿™ç‚¹æˆ‘æ²¡çœ‹æ‡‚ã€‚</p>
<h3 id="Classification-practices"><a href="#Classification-practices" class="headerlink" title="Classification practices"></a>Classification practices</h3><p>å…³äºCNN</p>
<blockquote>
<p>CNN filters:Combining filter sizes near the optimal filter size, e.g. (3,4,5) performs best (Kim, 2014; Kim et al., 2016). The optimal number of feature maps is in the range of 50-600 (Zhang &amp; Wallace, 2015) [59].</p>
<p>Aggregation function:1-max-pooling outperforms average-pooling and k-max pooling (Zhang &amp; Wallace, 2015).</p>
</blockquote>
<p>è¿™åœ¨æˆ‘ä¹‹å‰çš„å…³äºCNNæ–‡æœ¬åˆ†ç±»æŒ‡å—ä¸­æœ‰æ›´è¯¦å°½çš„åˆ†æã€‚</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>è¿™æ˜¯ä¸€ç¯‡å¹²è´§æ»¡æ»¡çš„åšå®¢ï¼Œå®é™…ä¸Šæˆ‘è¿˜æ˜¯æœ‰è®¸å¤šåœ°æ–¹æ²¡æœ‰è¯»æ‡‚ï¼Œè¿™é€‚åˆå¤šçœ‹å‡ éï¼Œæ…¢æ…¢ç†è§£ã€‚</p>
]]></content>
      <tags>
        <tag>æŒ‡å—</tag>
        <tag>è°ƒå‚</tag>
        <tag>NLPğŸ¤–</tag>
        <tag>ç¬”è®°ğŸ“’</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†5</title>
    <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%865/</url>
    <content><![CDATA[<p>1ï¸âƒ£[Paper]<br>Joint Embeddings of Chinese Words, Characters, and Fine-grained Subcharacter Components</p>
<p>åŸºæœ¬æ¡†æ¶å’ŒCBOWä¸€è‡´ï¼Œä¸»è¦è´¡çŒ®åœ¨äºé’ˆå¯¹ä¸­æ–‡è¯å‘é‡æ·»åŠ äº†åæ—ã€å­—çš„ç»„ä»¶ä½œä¸ºè®­ç»ƒä¿¡æ¯ã€‚</p>
<p><img src="/images/2018-08-26-15352530482345.jpg" width="50%" height="50%"></p>
<hr>
<p>2ï¸âƒ£[Paper]<br>Highway Networks</p>
<p>ä¸ºäº†è§£å†³ç¥ç»ç½‘ç»œæ·±åº¦è¿‡æ·±æ—¶å¯¼è‡´çš„åå‘ä¼ æ’­å›°éš¾çš„é—®é¢˜ã€‚<br>å‰å‘ä¼ æ’­çš„å…¬å¼ï¼š</p>
<script type="math/tex; mode=display">y=H(x,W_H)</script><p>è€Œè®ºæ–‡æ‰€åšçš„æ”¹è¿›ï¼š</p>
<script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot C(x,W_C)</script><p>å…¶ä¸­$T$æ˜¯transform gateï¼Œ$C$æ˜¯carry gateã€‚æ–¹ä¾¿èµ·è§ï¼Œå¯ä»¥å°† $C=1-T$ï¼Œæœ€ç»ˆæœ‰ï¼š</p>
<script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot (1-T(x,W_T))</script><p>å¯ä»¥çœ‹å‡ºæ€æƒ³å’ŒLSTMå¾ˆç±»ä¼¼ï¼Œéƒ½æ˜¯gateçš„æ€æƒ³ã€‚</p>
<hr>
<p>3ï¸âƒ£[è°ƒå‚æ–¹æ³•]<br>åšå®¢ï¼š<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41</a></p>
<ul>
<li><strong>å­¦ä¹ ç‡</strong>ï¼š</li>
</ul>
<p>ä¸€æ¡åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚</p>
<p>å¦‚ä½•å‡å°‘ï¼Ÿ</p>
<p><img src="/images/2018-08-26-15352871548330.jpg" width="50%" height="50%"></p>
<p>æˆ–è€…ï¼š</p>
<p><img src="/images/2018-08-26-15352873283890.jpg" width="50%" height="50%"><br>è®¾å®šä¸€å®šçš„epochä½œä¸ºä¸€ä¸ªstepsizeï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çº¿æ€§å¢åŠ å­¦ä¹ ç‡ï¼Œç„¶ååœ¨åˆ°è¾¾æœ€å¤§å€¼åå†çº¿æ€§å‡å°ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ–¹æ³•å¯ä»¥åœ¨ä¸€åŠçš„epochå†…è¾¾åˆ°ç›¸åŒçš„æ•ˆæœã€‚</p>
<ul>
<li><strong>batch size</strong>ï¼š</li>
</ul>
<p><img src="/images/2018-08-26-15352891425729.jpg" width="50%" height="50%"></p>
<p>ç”±äºbatch sizeå’Œå­¦ä¹ ç‡çš„å¼ºç›¸å…³æ€§ï¼Œ<a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">ç›¸å…³è®ºæ–‡</a>æå‡ºæé«˜batch sizeè€Œä¸æ˜¯é™ä½å­¦ä¹ ç‡çš„æ–¹æ³•æ¥æå‡æ¨¡å‹è¡¨ç°ã€‚</p>
<blockquote>
<p>increasing the batch size during training, instead of decaying learning rate.â€Šâ€”â€ŠL. Smith<br><a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.00489.pdf</a></p>
</blockquote>
<p>ä¸€ä¸ªtrickï¼šä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Paper</tag>
        <tag>è°ƒå‚æ–¹æ³•</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•6</title>
    <url>/2018/08/26/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB6/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"><a href="#1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch" class="headerlink" title="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"></a>1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_iter_batch</span><span class="params">(paras,labels,batch_size,shuffle=True)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param paras:</span></span><br><span class="line"><span class="string">    :param labels:</span></span><br><span class="line"><span class="string">    :param batch_size:</span></span><br><span class="line"><span class="string">    :param shuffle:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> len(paras)==len(labels)</span><br><span class="line">    paras_size=len(paras)</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        indices=np.arange(paras_size)</span><br><span class="line">        np.random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> range(<span class="number">0</span>,paras_size-batch_size+<span class="number">1</span>,batch_size):</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            excerpt=indices[start_idx:start_idx+batch_size]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            excerpt=slice(start_idx,start_idx+batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> paras[excerpt],labels[excerpt]</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯6</title>
    <url>/2018/08/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D6/</url>
    <content><![CDATA[<p>1ï¸âƒ£</p>
<h3 id="æˆä¸ºå…­ç»å¥"><a href="#æˆä¸ºå…­ç»å¥" class="headerlink" title="æˆä¸ºå…­ç»å¥"></a>æˆä¸ºå…­ç»å¥</h3><p>[å”] æœç”«<br>ã€å…¶äºŒã€‘<br>ç‹æ¨å¢éª†å½“æ—¶ä½“ï¼Œè½»è–„ä¸ºæ–‡å“‚æœªä¼‘ã€‚<br><strong>å°”æ›¹èº«ä¸åä¿±ç­ï¼Œä¸åºŸæ±Ÿæ²³ä¸‡å¤æµ</strong>ã€‚</p>
<p>å“‚ï¼ˆshÄ›nï¼‰ï¼šè®¥ç¬‘ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>CNNæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—</title>
    <url>/2018/08/25/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/CNN%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>æœ€è¿‘å› ä¸ºæ¯”èµ›çš„ç¼˜æ•…å¯¹æ–‡æœ¬åˆ†ç±»æœ‰ä¸€å®šçš„äº†è§£ã€‚å…¶ä¸­ä½¿ç”¨CNNæ–¹æ³•åšæƒ…æ„Ÿåˆ†æä»»åŠ¡å­˜åœ¨ç€è®¸å¤šä¼˜åŠ¿ã€‚è™½ç„¶æ¨¡å‹ç®€å•ï¼Œä½†å¦‚ä½•è®¾ç½®è¶…å‚æœ‰æ—¶å€™å¯¹ç»“æœæœ‰å¾ˆå¤§çš„å½±å“ã€‚æœ¬æ–‡è®°å½•äº†å…³äºCNNæ–‡æœ¬åˆ†ç±»çš„ä¸€äº›å­¦ä¹ å†ç¨‹å’ŒæŒ‡å—ï¼ŒåŸºæœ¬å‚è€ƒäº†è®ºæ–‡ã€‚</p>
<h2 id="åšæ³•"><a href="#åšæ³•" class="headerlink" title="åšæ³•"></a>åšæ³•</h2><p>åŸºæœ¬ä¸Šç›®å‰è¾ƒä¸ºæµ…å±‚çš„CNNæ–‡æœ¬åˆ†ç±»çš„åšæ³•éƒ½æ˜¯å¦‚ä¸‹å›¾ï¼š<br><img src="/images/2018-08-25-15351860103617.jpg" alt=""></p>
<p>å°†è¯å‘é‡å †ç§¯æˆä¸ºäºŒç»´çš„çŸ©é˜µï¼Œé€šè¿‡CNNçš„å·ç§¯å•å…ƒå¯¹çŸ©é˜µè¿›è¡Œå·ç§¯å¤„ç†ï¼ŒåŒæ—¶ä½¿ç”¨poolingï¼ˆé€šå¸¸æ˜¯1max-poolingï¼‰æ“ä½œï¼Œå°†ä¸ç­‰é•¿çš„å·ç§¯ç»“æœå˜ä¸ºç­‰é•¿ï¼Œå¯¹ä¸åŒçš„å·ç§¯å•å…ƒçš„ç»“æœè¿›è¡Œæ‹¼æ¥åç”Ÿæˆå•ä¸ªå‘é‡ï¼Œæœ€åå†é€šè¿‡çº¿æ€§å±‚è½¬åŒ–æˆç±»åˆ«æ¦‚ç‡åˆ†å¸ƒã€‚</p>
<p>å¦ä¸€å¼ å›¾ä¹Ÿè¯´æ˜äº†è¯¥æµç¨‹ã€‚</p>
<p><img src="/images/2018-08-25-15351863867337.jpg" alt=""></p>
<h2 id="å»ºè®®ä¸æŒ‡å¯¼"><a href="#å»ºè®®ä¸æŒ‡å¯¼" class="headerlink" title="å»ºè®®ä¸æŒ‡å¯¼"></a>å»ºè®®ä¸æŒ‡å¯¼</h2><h3 id="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"><a href="#è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“" class="headerlink" title="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"></a>è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“</h3><p>æ¥ä¸‹æ¥çš„å†…å®¹å‚è€ƒäº†è®ºæ–‡<a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p>
<p>CNNæ–‡æœ¬åˆ†ç±»çš„è¶…å‚ï¼š</p>
<ul>
<li>è¾“å…¥å‘é‡</li>
<li>å·ç§¯å¤§å°</li>
<li>è¾“å‡ºé€šé“ï¼ˆfeature mapsï¼‰</li>
<li>æ¿€æ´»å‡½æ•°</li>
<li>æ± åŒ–ç­–ç•¥</li>
<li>æ­£åˆ™åŒ–</li>
</ul>
<h4 id="è¾“å…¥å‘é‡çš„å½±å“"><a href="#è¾“å…¥å‘é‡çš„å½±å“" class="headerlink" title="è¾“å…¥å‘é‡çš„å½±å“"></a>è¾“å…¥å‘é‡çš„å½±å“</h4><p>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨word2vecå’ŒGloVeä¸åˆ†ä¼¯ä»²ï¼Œä½†å°†word2vecå’ŒGloVeç®€å•æ‹¼æ¥åœ¨ä¸€èµ·å¹¶ä¸èƒ½å¸¦æ¥æå‡ã€‚</p>
<blockquote>
<p>unfortunately, simply concatenating these representations does necessarily seem helpful</p>
</blockquote>
<p>å½“å¥å­é•¿åº¦å¾ˆé•¿ï¼ˆdocument classificationï¼‰æ—¶ï¼Œä½¿ç”¨one-hotå¯èƒ½ä¼šæœ‰æ•ˆæœï¼Œä½†åœ¨å¥å­é•¿åº¦ä¸æ˜¯å¾ˆé•¿æ—¶ï¼Œæ•ˆæœä¸å¥½ã€‚</p>
<h5 id="å»ºè®®"><a href="#å»ºè®®" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>å¯¹äºæ–°ä»»åŠ¡ï¼Œå¯ä»¥word2vecæˆ–GloVeæˆ–è€…å…¶ä»–è¯å‘é‡éƒ½è¯•ä¸€ä¸‹ï¼Œå¦‚æœå¥å­é•¿ï¼Œå¯ä»¥è¯•ç€ä½¿ç”¨one-hotã€‚</p>
<h4 id="å·ç§¯å¤§å°"><a href="#å·ç§¯å¤§å°" class="headerlink" title="å·ç§¯å¤§å°"></a>å·ç§¯å¤§å°</h4><p>ç”±äºå·ç§¯çš„é•¿åº¦æ˜¯å›ºå®šçš„ï¼Œä¹Ÿå°±æ˜¯è¯å‘é‡çš„é•¿åº¦ï¼Œå› æ­¤åªéœ€è®¨è®ºå®½åº¦ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä¸åŒçš„æ•°æ®é›†ä¼šæœ‰ä¸åŒçš„æœ€ä½³å¤§å°ï¼Œä½†ä¼¼ä¹å¯¹äºé•¿åº¦è¶Šé•¿çš„å¥å­ï¼Œæœ€ä½³å¤§å°æœ‰è¶Šå¤§çš„è¶‹åŠ¿ã€‚</p>
<blockquote>
<p>However, for datasets comprising longer sentences, such as CR (maximum sentence length is 105, whereas it ranges from 36-56 on the other sentiment datasets used here), the optimal region size may be larger.</p>
</blockquote>
<p>åŒæ—¶ï¼Œå½“å¢åŠ ä¸åŒå·ç§¯å¤§å°ä½œä¸ºç»„åˆæ—¶ï¼Œå¦‚æœç»„åˆçš„å·ç§¯æ ¸å¤§å°æ¥è¿‘äºæœ€ä½³å¤§å°ï¼ˆoptimal region sizeï¼‰ï¼Œæœ‰åŠ©äºç»“æœçš„æå‡ï¼›ç›¸åï¼Œå¦‚æœå·ç§¯æ ¸å¤§å°ç¦»æœ€ä½³å¤§å°å¾ˆè¿œæ—¶ï¼Œåè€Œä¼šäº§ç”Ÿè´Ÿé¢å½±å“ã€‚</p>
<h5 id="å»ºè®®-1"><a href="#å»ºè®®-1" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>é¦–å…ˆè¯•ç€æ‰¾åˆ°æœ€ä¼˜çš„å·ç§¯æ ¸å¤§å°ï¼Œç„¶ååœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ å’Œè¯¥å·ç§¯æ ¸å¤§å°ç±»ä¼¼çš„å·ç§¯æ ¸ã€‚</p>
<h4 id="feature-maps"><a href="#feature-maps" class="headerlink" title="feature maps"></a>feature maps</h4><p>ä¹Ÿå°±æ˜¯è¾“å‡ºé€šé“ï¼ˆout channelï¼‰ï¼Œè¡¨æ˜è¯¥å·ç§¯æ ¸å¤§å°çš„å·ç§¯æ ¸æœ‰å¤šå°‘ä¸ªã€‚</p>
<p>å®éªŒè¡¨æ˜ï¼Œæœ€ä½³çš„feature mapså’Œæ•°æ®é›†ç›¸å…³ï¼Œä½†ä¸€èˆ¬ä¸è¶…è¿‡600ã€‚</p>
<blockquote>
<p>it would seem that increasing the number of maps beyond 600 yields at best very marginal returns, and often hurts performance.</p>
</blockquote>
<h5 id="å»ºè®®-2"><a href="#å»ºè®®-2" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>åœ¨600å†…æœç´¢æœ€ä¼˜ï¼Œå¦‚æœåœ¨600çš„è¾¹ç¼˜è¿˜æ²¡æœ‰æ˜æ˜¾çš„æ•ˆæœä¸‹é™ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•å¤§äº600çš„feature mapsã€‚</p>
<h4 id="æ¿€æ´»å‡½æ•°"><a href="#æ¿€æ´»å‡½æ•°" class="headerlink" title="æ¿€æ´»å‡½æ•°"></a>æ¿€æ´»å‡½æ•°</h4><p>å®éªŒç»“æœï¼š<br><img src="/images/2018-08-25-15351889835594.jpg" alt=""></p>
<p>ç»“æœè¡¨æ˜ï¼Œtanhã€ReLUå’Œä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°æ•ˆæœè¾ƒå¥½ã€‚tanhçš„ä¼˜ç‚¹æ˜¯ä»¥0ä¸ºä¸­å¿ƒï¼ŒReLUèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œè‡³äºä¸ºä»€ä¹ˆä¸ä½¿ç”¨çš„æ•ˆæœä¼šå¥½ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹è¾ƒä¸ºç®€å•ï¼š</p>
<blockquote>
<p>This indicates that on some datasets, a linear transformation is enough to capture the<br>correlation between the word embedding and the output label.</p>
</blockquote>
<h5 id="å»ºè®®-3"><a href="#å»ºè®®-3" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>ä½¿ç”¨tanhã€ReLUæˆ–è€…å¹²è„†ä¸ä½¿ç”¨ã€‚ä½†å¦‚æœæ¨¡å‹æ›´ä¸ºå¤æ‚ï¼Œæœ‰å¤šå±‚çš„ç»“æ„ï¼Œè¿˜æ˜¯éœ€è¦ä½¿ç”¨æ¿€æ´»å‡½æ•°çš„ã€‚</p>
<h4 id="poolingç­–ç•¥"><a href="#poolingç­–ç•¥" class="headerlink" title="poolingç­–ç•¥"></a>poolingç­–ç•¥</h4><p>æ‰€æœ‰çš„å®éªŒéƒ½è¡¨æ˜äº†ï¼Œ1-max poolingçš„æ•ˆæœæ¯”å…¶ä»–å¥½ï¼Œå¦‚k-max poolingã€‚åœ¨poolingè¿™ä¸€æ­¥å¯ä»¥ç›´æ¥é€‰æ‹©1-max poolingã€‚</p>
<blockquote>
<p>This may be because the location of predictive contexts does not matter, and certain n-grams in the sentence can be more predictive on their own than the entire sentence considered jointly.</p>
</blockquote>
<h4 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h4><p>ä¸»è¦æ˜¯dropoutå’Œl2 norm constraintã€‚<br>dropoutå°±æ˜¯éšæœºå°†ä¸€äº›ç¥ç»å…ƒç½®ä¸º0ï¼Œl2 norm constraintæ˜¯å¯¹å‚æ•°çŸ©é˜µWè¿›è¡Œæ•´ä½“ç¼©æ”¾ï¼Œä½¿å…¶ä¸è¶…è¿‡ä¸€å®šé˜ˆå€¼ã€‚ï¼ˆä¸é€šå¸¸çš„l2 regularizationä¸åŒï¼Œæœ€æ—©å¯è¿½æº¯åˆ°Hintonçš„<a href="https://arxiv.org/pdf/1207.0580.pdf" target="_blank" rel="noopener">Improving neural networks by preventing<br>co-adaptation of feature detectors</a>ï¼‰</p>
<blockquote>
<p>the l2 norm of a weight vector is linearly scaled to a constraint c when it exceeds this threshold, so a smaller c implies stronger regularization</p>
</blockquote>
<p>å®éªŒè¡¨æ˜ï¼Œdropoutèµ·çš„ä½œç”¨å¾ˆå°ï¼Œl2 normæ²¡æœ‰æå‡ç”šè‡³è¿˜ä¼šå¯¼è‡´ä¸‹é™ã€‚å¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å‚æ•°ä¸å¤šï¼Œå› æ­¤è¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§è¾ƒä½ã€‚</p>
<h5 id="å»ºè®®-4"><a href="#å»ºè®®-4" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>è®¾ç½®è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„l2 normï¼Œå½“feature mapså¢å¤§æ—¶ï¼Œå¯ä»¥è¯•ç€è°ƒèŠ‚è¾ƒå¤§çš„dropoutä»¥é¿å…è¿‡æ‹Ÿåˆã€‚</p>
<h3 id="å»ºè®®åŠç»“è®º"><a href="#å»ºè®®åŠç»“è®º" class="headerlink" title="å»ºè®®åŠç»“è®º"></a>å»ºè®®åŠç»“è®º</h3><ul>
<li>åˆšå¼€å§‹çš„ä½¿ç”¨ä½¿ç”¨word2vecæˆ–è€…GloVeï¼Œå¦‚æœæ•°æ®é‡å¤Ÿå¤§ï¼Œå¯ä»¥å°è¯•one-hot</li>
<li>çº¿æ€§æœç´¢æœ€ä½³çš„å·ç§¯æ ¸å¤§å°ï¼Œå¦‚æœå¥å­å¤Ÿé•¿ï¼Œé‚£ä¹ˆå¯ä»¥æ‰©å¤§æœç´¢èŒƒå›´ã€‚ä¸€æ—¦ç¡®å®šäº†æœ€ä½³å·ç§¯æ ¸å¤§å°ï¼Œå°è¯•åœ¨è¯¥å·ç§¯æ ¸å¤§å°çš„é™„è¿‘è¿›è¡Œç»„åˆï¼Œå¦‚æœ€ä½³å·ç§¯æ ¸å®½åº¦æ˜¯5ï¼Œé‚£ä¹ˆå°è¯•[3,4,5]æˆ–è€…[2,3,4,5]ç­‰</li>
<li>ä½¿ç”¨è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„max norm constraintï¼Œç„¶ååœ¨[100,600]èŒƒå›´å†…æœç´¢feature mapsï¼Œå¦‚æœæœ€ä½³çš„feature mapsåœ¨600é™„è¿‘ï¼Œå¯ä»¥è¯•ç€é€‰æ‹©æ¯”600æ›´å¤§çš„èŒƒå›´</li>
<li>å°è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸tanhå’ŒReLUæ˜¯è¾ƒå¥½çš„ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•ä»€ä¹ˆéƒ½ä¸åŠ ã€‚</li>
<li>ä½¿ç”¨1-max poolingã€‚</li>
<li>å¦‚æœæ¨¡å‹å¤æ‚ï¼Œæ¯”å¦‚feature mapså¾ˆå¤§ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•æ›´ä¸ºä¸¥æ ¼çš„æ­£åˆ™åŒ–ï¼Œå¦‚æ›´å¤§çš„dropout rateå’Œè¾ƒå°çš„max norm constraintã€‚</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://www.aclweb.org/anthology/D14-1181" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></p>
<p><a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p>
]]></content>
      <tags>
        <tag>CNN</tag>
        <tag>æƒ…æ„Ÿåˆ†æ</tag>
        <tag>æŒ‡å—</tag>
        <tag>è°ƒå‚</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­çš„inplaceçš„æ“ä½œ</title>
    <url>/2018/08/20/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADin-place%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>æœ€è¿‘åœ¨å†™Hierarchical attention networkçš„æ—¶å€™é‡åˆ°äº†å¦‚ä¸‹çš„bugï¼š</p>
<blockquote>
<p>one of the variables needed for gradient computation has been modified by an inplace operation</p>
</blockquote>
<p>åœ¨æŸ¥é˜…äº†æ–‡æ¡£å’Œè¯·æ•™äº†å…¶ä»–äººä¹‹åï¼Œæœ€ç»ˆæ‰¾åˆ°äº†bugã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze_(<span class="number">1</span>)  <span class="comment"># take in-place opt may cause an error</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure>
<p>è¿™æ˜¯æˆ‘åŸæ¥çš„é€»è¾‘ï¼Œæˆ‘åœ¨æ— æ„ä¸­åšäº†inplaceæ“ä½œï¼Œå¯¼è‡´äº†bugçš„å‘ç”Ÿã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    <span class="comment"># a_i = attn_weights[i].unsqueeze_(1)  # take in-place opt may cause an error</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze(<span class="number">1</span>)  <span class="comment"># batch,1</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure>
<p>å®é™…ä¸Šï¼Œåœ¨å®è·µè¿‡ç¨‹ä¸­åº”å½“å°½é‡é¿å…inplaceæ“ä½œï¼Œåœ¨å®˜æ–¹æ–‡æ¡£ä¸­ä¹Ÿæåˆ°äº†ï¼ˆå­˜ç–‘ï¼‰è¿™ç‚¹ï¼Œè™½ç„¶æä¾›äº†inplaceæ“ä½œï¼Œä½†å¹¶ä¸æ¨èä½¿ç”¨ã€‚</p>
<p>å…·ä½“çš„åŸå› æ˜¯ï¼Œåœ¨Pytorchæ„å»ºè®¡ç®—å›¾çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®°å½•æ¯ä¸ªèŠ‚ç‚¹æ˜¯æ€ä¹ˆæ¥çš„ï¼Œä½†inplaceä¼šç ´åè¿™ç§å…³ç³»ï¼Œä½¿å¾—åœ¨å›ä¼ çš„æ—¶å€™æ²¡æ³•æ­£å¸¸æ±‚å¯¼ã€‚</p>
<p>ç‰¹åˆ«åœ°ï¼Œæœ‰ä¸¤ç§æƒ…å†µä¸åº”è¯¥ä½¿ç”¨inplaceæ“ä½œï¼ˆæ‘˜è‡ªçŸ¥ä¹ï¼‰ï¼š</p>
<ol>
<li>å¯¹äºrequires_grad=Trueçš„å¶å­å¼ é‡(leaf tensor)ä¸èƒ½ä½¿ç”¨inplace operation</li>
<li>å¯¹äºåœ¨æ±‚æ¢¯åº¦é˜¶æ®µéœ€è¦ç”¨åˆ°çš„å¼ é‡ä¸èƒ½ä½¿ç”¨inplace operation</li>
</ol>
<p>Reference:<br><a href="https://zhuanlan.zhihu.com/p/38475183" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38475183</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”</title>
    <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%84%BF%E4%B8%AD%E5%9B%BD%E9%9D%92%E5%B9%B4%E9%83%BD%E6%91%86%E8%84%B1%E5%86%B7%E6%B0%94/</url>
    <content><![CDATA[<p>è¿‘æœŸçš„æ–°é—»å¸¸è®©äººæ„Ÿåˆ°æ„¤æ€’ä»¥è‡´ç»æœ›â€¦</p>
<hr>
<p>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”ï¼Œåªæ˜¯å‘ä¸Šèµ°ï¼Œä¸å¿…å¬è‡ªæš´è‡ªå¼ƒè€…æµçš„è¯ã€‚èƒ½åšäº‹çš„åšäº‹ï¼Œèƒ½å‘å£°çš„å‘å£°ã€‚æœ‰ä¸€åˆ†çƒ­ï¼Œå‘ä¸€åˆ†å…‰ã€‚å°±ä»¤è¤ç«ä¸€èˆ¬ï¼Œä¹Ÿå¯ä»¥åœ¨é»‘æš—é‡Œå‘ä¸€ç‚¹å…‰ï¼Œä¸å¿…ç­‰å€™ç‚¬ç«ã€‚</p>
<p>â€”é²è¿…ã€Šçƒ­é£ã€‹</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•5</title>
    <url>/2018/08/19/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB5/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"><a href="#1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤" class="headerlink" title="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"></a>1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">clf = svm.SVC()</span><br><span class="line">clf.fit(X, y)  </span><br><span class="line">clf.fit(train_X,train_y)</span><br><span class="line">joblib.dump(clf, <span class="string">"train_model.m"</span>)</span><br><span class="line">clf = joblib.load(<span class="string">"train_model.m"</span>)</span><br><span class="line">clf.predit(test_X)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£Dictionaryç±»"><a href="#2ï¸âƒ£Dictionaryç±»" class="headerlink" title="2ï¸âƒ£Dictionaryç±»"></a>2ï¸âƒ£Dictionaryç±»</h3><p>åœ¨æ„é€ å­—å…¸æ—¶éœ€è¦ç”¨åˆ°<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)</span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_word</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            self.idx2word.append(word)</span><br><span class="line">            self.word2idx[word] = self.__vocab_size</span><br><span class="line">            self.__vocab_size += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_index</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[word]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[<span class="string">'&lt;UNK&gt;'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_word</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.idx2word[idx]</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"><a href="#3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"></a>3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d=&#123;<span class="string">'apple'</span>:<span class="number">10</span>,<span class="string">'orange'</span>:<span class="number">20</span>,<span class="string">'banana'</span>:<span class="number">5</span>,<span class="string">'watermelon'</span>:<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line">print(sorted(d.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"></span><br><span class="line">print(sorted(d.items(),key=itemgetter(<span class="number">1</span>))) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"></span><br><span class="line">print(sorted(d,key=d.get))  <span class="comment">#['watermelon', 'banana', 'apple', 'orange'] æ²¡æœ‰valueäº†</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"><a href="#4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"></a>4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1=&#123;<span class="string">'a'</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d2=&#123;<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d=&#123;**d1,**d2&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd=dict(d1.items()|d2.items())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1.update(d2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"><a href="#5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index" class="headerlink" title="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"></a>5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lst = [<span class="number">40</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> min(range(len(lst)),key=lst.__getitem__)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> max(range(len(lst)),key=lst.__getitem__)</span><br><span class="line">    </span><br><span class="line">print(minIndex(lst))</span><br><span class="line">print(maxIndex(lst))</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­çš„Embedding padding</title>
    <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADEmbedding%E7%9A%84padding/</url>
    <content><![CDATA[<p>åœ¨Pytorchä¸­ï¼Œnn.Embedding()ä»£è¡¨embeddingçŸ©é˜µï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªå‚æ•°<code>padding_idx</code>æŒ‡å®šç”¨ä»¥paddingçš„ç´¢å¼•ä½ç½®ã€‚æ‰€è°“paddingï¼Œå°±æ˜¯åœ¨å°†ä¸ç­‰é•¿çš„å¥å­ç»„æˆä¸€ä¸ªbatchæ—¶ï¼Œå¯¹é‚£äº›ç©ºç¼ºçš„ä½ç½®è¡¥0ï¼Œä»¥å½¢æˆä¸€ä¸ªç»Ÿä¸€çš„çŸ©é˜µã€‚</p>
<p>ç”¨æ³•ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>) <span class="comment">#ä¹Ÿå¯ä»¥æ˜¯åˆ«çš„æ•°å€¼</span></span><br></pre></td></tr></table></figure></p>
<p>åœ¨æ˜¾å¼è®¾å®š<code>padding_idx=0</code>åï¼Œåœ¨è‡ªå®šä¹‰çš„è¯å…¸å†…ä¹Ÿåº”å½“åœ¨ç›¸åº”ä½ç½®æ·»åŠ <code>&lt;pad&gt;</code>ä½œä¸ºä¸€ä¸ªè¯ã€‚å¦‚ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)  <span class="comment"># should add &lt;pad&gt; first</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br></pre></td></tr></table></figure>
<p>é‚£ä¹ˆå¯¹äº<code>padding_idx</code>ï¼Œå†…éƒ¨æ˜¯å¦‚ä½•æ“ä½œçš„å‘¢ï¼Ÿ</p>
<p>åœ¨æŸ¥çœ‹äº†Embeddingçš„æºç åï¼Œå‘ç°è®¾ç½®äº†<code>padding_idx</code>ï¼Œç±»å†…éƒ¨ä¼šæœ‰å¦‚ä¸‹æ“ä½œï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-----Embedding __init__ å†…éƒ¨--------------</span></span><br><span class="line"><span class="keyword">if</span> _weight <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">    self.weight = Parameter(torch.Tensor(num_embeddings, embedding_dim))</span><br><span class="line">    self.reset_parameters()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#---------reset_parameters()--------</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_parameters</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.weight.data.normal_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> self.padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        self.weight.data[self.padding_idx].fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„çŸ©é˜µæ—¶ï¼Œä¼šå¯¹<code>padding_idx</code>æ‰€åœ¨çš„è¡Œè¿›è¡Œå¡«0ã€‚ä¿è¯äº†paddingè¡Œä¸ºçš„æ­£ç¡®æ€§ã€‚</p>
<p>é‚£ä¹ˆï¼Œè¿˜éœ€è¦ä¿è¯ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨åå‘å›ä¼ çš„æ—¶å€™ï¼Œ<code>padding_idx</code>æ˜¯ä¸ä¼šæ›´æ–°çš„.</p>
<p>åœ¨æŸ¥çœ‹äº†æºç åå‘ç°åœ¨Embeddingç±»å†…æœ‰å¦‚ä¸‹æ³¨é‡Šï¼š</p>
<blockquote>
<p>.. note::<br>        With :attr:<code>padding_idx</code> set, the embedding vector at<br>        :attr:<code>padding_idx</code> is initialized to all zeros. However, note that this<br>        vector can be modified afterwards, e.g., using a customized<br>        initialization method, and thus changing the vector used to pad the<br>        output. The gradient for this vector from :class:<code>~torch.nn.Embedding</code><br>        is always zero.</p>
</blockquote>
<p>å¹¶ä¸”åœ¨æŸ¥é˜…äº†å…¶ä»–èµ„æ–™åï¼Œå‘ç°è¯¥è¡Œç¡®å®ä¼šä¸æ›´æ–°ã€‚æœ‰æ„æ€çš„æ˜¯ï¼ŒæŸ¥é˜…æºç å¹¶æ²¡æœ‰æ‰¾åˆ°å¦‚ä½•ä½¿å…¶ä¸æ›´æ–°çš„æœºåˆ¶ï¼Œå› ä¸ºåœ¨F.embeddingå‡½æ•°ä¸­ï¼Œè¿”å›ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure>
<p>ä½†æˆ‘å¹¶ä¸èƒ½è·³è½¬åˆ°torch.embeddingä¸­ï¼Œå¤§æ¦‚æ˜¯å› ä¸ºè¿™éƒ¨åˆ†è¢«éšè—äº†å§ã€‚æˆ‘ä¹Ÿæ²¡æœ‰å†æ·±ç©¶ä¸‹å»ã€‚æˆ‘çŒœæµ‹æœ‰å¯èƒ½æ˜¯åœ¨autogradå†…éƒ¨æœ‰å¯¹è¯¥éƒ¨åˆ†è¿›è¡Œå•ç‹¬çš„å¤„ç†ï¼Œç”¨maskå±è”½è¿™éƒ¨åˆ†çš„æ›´æ–°ï¼›æˆ–è€…ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•ï¼Œå°±æ˜¯ä»»å…¶æ›´æ–°ï¼Œä½†æ¯ä¸€æ¬¡éƒ½resetï¼Œå°†ç¬¬ä¸€è¡Œæ‰‹åŠ¨è®¾ä¸ºå…¨0ã€‚</p>
<p><strong>é™„è®°</strong>ï¼š</p>
<p>å‡å¦‚è¯´æ²¡æœ‰æ˜¾å¼è®¾ç½®è¯¥è¡Œï¼Œæ˜¯å¦paddingå°±æ²¡æœ‰æ•ˆæœå‘¢ï¼Ÿ<br>æˆ‘è®¤ä¸ºæ˜¯çš„ã€‚</p>
<p>ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬éƒ½æ˜¯ä»¥0ä½œä¸ºpaddingçš„å¡«å……ï¼Œå¦‚ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>12</td>
<td>44</td>
<td>22</td>
<td>67</td>
<td>85</td>
</tr>
<tr>
<td>12</td>
<td>13</td>
<td>534</td>
<td>31</td>
<td>0</td>
</tr>
<tr>
<td>87</td>
<td>23</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªå¥å­ï¼Œå…¶ä¸­0ä½œä¸ºå¡«å……ã€‚ç„¶åå°†è¯¥çŸ©é˜µé€å…¥åˆ°embedding_lookupä¸­ï¼Œè·å¾—ä¸‰ç»´çš„tensorï¼Œé‚£ä¹ˆ0å¡«å……çš„éƒ¨åˆ†ï¼Œæ‰€è·å¾—çš„embeddingè¡¨ç¤ºåº”å½“æ˜¯è¦å…¨0ã€‚</p>
<p>å‡å¦‚ä¸æ˜¾å¼è®¾ç½®<code>padding_idx=0</code>ï¼Œå°±å¯èƒ½ä¼šå‡ºç°ä¸¤ä¸ªç»“æœï¼ˆä¸ªäººæ¨æµ‹)ï¼š</p>
<p>â‘ æœ¬åº”è¯¥å…¨0çš„åœ°æ–¹ï¼Œè¢«è¯å…¸ä¸­ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡è¡¨ç¤ºç»™æ›¿ä»£äº†ï¼Œå› ä¸ºå°†0ä½œä¸ºç´¢å¼•å»embeddingçŸ©é˜µè·å–åˆ°çš„è¯å‘é‡ï¼Œå°±æ˜¯ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼Œè€Œè¯¥è¯å¹¶ä¸å…¨0ã€‚</p>
<p>â‘¡è¯å…¸çš„æœ€åä¸€ä¸ªè¯è¢«å…¨0è¦†ç›–ã€‚F.embeddingä¸­æœ‰å¦‚ä¸‹ç‰‡æ®µï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    <span class="keyword">if</span> padding_idx &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &lt; weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">    <span class="keyword">elif</span> padding_idx &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &gt;= -weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">        padding_idx = weight.size(<span class="number">0</span>) + padding_idx</span><br><span class="line"><span class="keyword">elif</span> padding_idx <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        padding_idx = <span class="number">-1</span></span><br></pre></td></tr></table></figure>
<p>ä¸Šé¢ç‰‡æ®µæ˜¾ç¤ºï¼Œ<code>padding_idx</code>è¢«è®¾ç½®ä¸º-1ï¼Œä¹Ÿå°±æ˜¯æœ€åä¸€ä¸ªå•è¯ã€‚åšå®Œè¿™æ­¥ç´§æ¥ç€å°±è¿”å›ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure>
<p>è¿˜æ˜¯ç”±äºtorch.embeddingæ— æ³•æŸ¥çœ‹çš„åŸå› ï¼Œæˆ‘ä¸çŸ¥é“å†…éƒ¨æ˜¯å¦‚ä½•å®ç°çš„ï¼Œä½†åº”è¯¥æ¥è¯´ï¼Œæœ€åä¸€ä¸ªè¯å°±æ˜¯è¢«è¦†ç›–äº†ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Embedding</tag>
        <tag>padding</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Tricks[è½¬]</title>
    <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%20Tricks%5B%E8%BD%AC%5D/</url>
    <content><![CDATA[<p>åŸæ–‡åœ°å€:<a href="https://hackernoon.com/python-tricks-101-2836251922e0" target="_blank" rel="noopener">https://hackernoon.com/python-tricks-101-2836251922e0</a></p>
<p>æˆ‘è§‰å¾—è¿™ä¸ªä»‹ç»Pythonä¸€äº›tricksçš„æ–‡ç« å¾ˆå¥½ï¼Œèƒ½å¤Ÿæ›´åŠ ç†Ÿæ‚‰Pythonçš„ä¸€äº›éå¸¸æ–¹ä¾¿çš„ç”¨æ³•ã€‚<br>ä»¥ä¸‹æ˜¯æˆ‘è§‰å¾—æœ‰ç”¨çš„å‡ ä¸ªç‚¹ã€‚</p>
<p>1ï¸âƒ£Reverse a String/List</p>
<p><img src="/images/2018-08-19-15346465152976.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-08-19-15346467215597.jpg" width="70%" height="50%"></p>
<p>[::-1]è§£é‡Šï¼š<br>[:]è¡¨ç¤ºå–æ‰€æœ‰çš„å…ƒç´ ï¼Œ-1è¡¨ç¤ºæ­¥è¿›ã€‚[1:5:2]è¡¨ç¤ºçš„å°±æ˜¯ä»å…ƒç´ 1åˆ°å…ƒç´ 5ï¼Œæ¯2ä¸ªè·ç¦»å–ä¸€ä¸ªã€‚</p>
<hr>
<p>2ï¸âƒ£transpose 2d array</p>
<p><img src="/images/2018-08-19-15346470165919.jpg" width="70%" height="50%"></p>
<p>zip()ç›¸å½“äºå‹ç¼©ï¼Œzip(*)ç›¸å½“äºè§£å‹ã€‚</p>
<hr>
<p>3ï¸âƒ£Chained function call</p>
<p><img src="/images/2018-08-19-15346471756442.jpg" width="70%" height="50%"></p>
<p>éå¸¸ç®€æ´çš„å†™æ³•ã€‚</p>
<hr>
<p>4ï¸âƒ£Copy List</p>
<p><img src="/images/2018-08-19-15346472744350.jpg" width="50%" height="50%"></p>
<p>ä¹‹å‰è°ˆè¿‡çš„Pythonçš„èµ‹å€¼ã€æµ…æ‹·è´ã€æ·±æ‹·è´ã€‚</p>
<hr>
<p>5ï¸âƒ£Dictionary get</p>
<p><img src="/images/2018-08-19-15346473929918.jpg" width="70%" height="50%"></p>
<p>é¿å…äº†dictä¸å­˜åœ¨è¯¥å…ƒç´ çš„é—®é¢˜ã€‚</p>
<hr>
<p>6ï¸âƒ£âœ¨Sort Dictionary by Value</p>
<p><img src="/images/2018-08-19-15346475170316.jpg" width="90%" height="50%"></p>
<p>å…¶ä¸­ç¬¬ä¸‰ç§è¿”å›çš„æ˜¯[â€˜watermelonâ€™, â€˜bananaâ€™, â€˜appleâ€™, â€˜orangeâ€™]ï¼Œæ²¡æœ‰valueäº†ã€‚</p>
<hr>
<p>7ï¸âƒ£Forâ€¦else</p>
<p><img src="/images/2018-08-19-15346481408714.jpg" width="90%" height="50%"></p>
<p>æ³¨æ„åˆ°å¦‚æœforåœ¨ä¸­é€”breakäº†ï¼Œå°±ä¸ä¼šè¿›å…¥åˆ°elseäº†ï¼›åªæœ‰é¡ºåˆ©å¾ªç¯å®Œæ‰ä¼šè¿›å…¥åˆ°elseã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> e==<span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span><span class="comment">#ä»€ä¹ˆéƒ½æ²¡æœ‰print</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    print(e)</span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure>
<hr>
<p>8ï¸âƒ£Merge dictâ€™s</p>
<p><img src="/images/2018-08-19-15346483785515.jpg" width="90%" height="50%"></p>
<p>åˆå¹¶dictçš„æ–¹æ³•ã€‚</p>
<hr>
<p>9ï¸âƒ£Min and Max index in List</p>
<p><img src="/images/2018-08-19-15346487918895.jpg" width="80%" height="50%"></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Python</tag>
        <tag>Python tricks</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†4</title>
    <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%864/</url>
    <content><![CDATA[<p>1ï¸âƒ£[æ¦‚ç‡æ ¡å‡†(Probability Calibration)]<br>ä¸€ç§å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¾“å‡ºç»“æœçš„æ ¡å‡†ï¼Œé€šè¿‡å‡ ä¸ªå®éªŒå¯ä»¥å‘ç°ï¼Œæ¦‚ç‡æ ¡å‡†èƒ½å¤Ÿä¸€å®šç¨‹åº¦æé«˜è¡¨ç°ã€‚<br>å‡ ä¸ªå‚è€ƒèµ„æ–™ï¼š<br>ç›´è§‚ç†è§£:  <a href="http://www.bubuko.com/infodetail-2133893.html" target="_blank" rel="noopener">http://www.bubuko.com/infodetail-2133893.html</a><br>SVCçš„æ¦‚ç‡æ ¡å‡†åœ¨sklearnä¸Šçš„åº”ç”¨: <a href="https://blog.csdn.net/ericcchen/article/details/79337716" target="_blank" rel="noopener">https://blog.csdn.net/ericcchen/article/details/79337716</a><br>âœ¨å®Œå…¨æ‰‹å†Œ: <a href="http://users.dsic.upv.es/~flip/papers/BFHRHandbook2010.pdf" target="_blank" rel="noopener">Calibration of Machine Learning Models</a></p>
<hr>
<p>2ï¸âƒ£[Paper]<br><a href="https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf" target="_blank" rel="noopener">Hierarchical Attention Networks for Document Classification</a></p>
<p>äº®ç‚¹åœ¨ä½¿ç”¨å±‚æ¬¡çš„RNNç»“æ„ï¼Œä»¥åŠä½¿ç”¨äº†attentionæ–¹æ³•ã€‚<br><img src="/images/2018-08-19-15346447273228.jpg" width="50%" height="50%"></p>
<p>å‚è€ƒäº†å…¶ä»–äººçš„ä»£ç è‡ªå·±ä¹Ÿè¯•ç€å®ç°äº†ä¸€ä¸ªï¼ŒGitHubåœ°å€ï¼š<a href="https://github.com/linzehui/pytorch-hierarchical-attention-network" target="_blank" rel="noopener">https://github.com/linzehui/pytorch-hierarchical-attention-network</a></p>
<hr>
<p>3ï¸âƒ£[XGBoost]<br>kaggleç¥å™¨XGBoostï¼Œä¸€ç¯‡åŸç†çš„è¯¦ç»†ä»‹ç»ï¼š<br><a href="http://www.cnblogs.com/willnote/p/6801496.html" target="_blank" rel="noopener">http://www.cnblogs.com/willnote/p/6801496.html</a><br>è™½ç„¶è¿˜æ˜¯æœ‰å¥½äº›åœ°æ–¹æ²¡ææ‡‚ï¼Œæœ‰å¿…è¦ä»å¤´å­¦èµ·ã€‚</p>
<hr>
<p>4ï¸âƒ£[Python]<br>å…³äºå‡½æ•°åˆ—è¡¨ä¸­å•æ˜Ÿå·(*)å’ŒåŒæ˜Ÿå·(**)<br>å•æ˜Ÿå·ï¼š</p>
<ul>
<li>ä»£è¡¨æ¥æ”¶ä»»æ„å¤šä¸ªéå…³é”®å­—å‚æ•°ï¼Œå°†å…¶è½¬æ¢æˆå…ƒç»„ï¼š</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one</span><span class="params">(a,*b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šä¼ å…¥å‚æ•°ï¼Œ*bæ˜¯ä¸€ä¸ªéå…³é”®å­—æ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">one(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="comment">#è¾“å‡ºï¼š(2, 3, 4, 5, 6)</span></span><br></pre></td></tr></table></figure>
<ul>
<li>å¯¹ä¸€ä¸ªæ™®é€šå˜é‡ä½¿ç”¨å•æ˜Ÿå·ï¼Œè¡¨ç¤ºå¯¹è¯¥å˜é‡æ‹†åˆ†æˆå•ä¸ªå…ƒç´ </li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    print(a,b)</span><br><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">fun(*l)  <span class="comment">#è¾“å‡º 1,2</span></span><br></pre></td></tr></table></figure>
<p>åŒæ˜Ÿå·ï¼š</p>
<ul>
<li>è·å¾—å­—å…¸å€¼</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two</span><span class="params">(a=<span class="number">1</span>,**b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šå…³é”®å­—å‚æ•°ï¼Œ**bæ˜¯ä¸€ä¸ªå…³é”®å­—åŒæ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">two(a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>,d=<span class="number">4</span>,e=<span class="number">5</span>,f=<span class="number">6</span>)  <span class="comment">#è¾“å‡º&#123;'b': 2, 'c': 3, 'e': 5, 'f': 6, 'd': 4&#125;</span></span><br></pre></td></tr></table></figure>
<hr>
<p>5ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œåªè¦ä¸€ä¸ªtensorçš„requires_gradæ˜¯trueï¼Œé‚£ä¹ˆä¸¤ä¸ªtensorçš„åŠ å‡ä¹˜é™¤åçš„ç»“æœçš„requires_gradä¹Ÿä¼šæ˜¯trueã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
        <tag>Paper</tag>
        <tag>æ¦‚ç‡æ ¡å‡†</tag>
        <tag>Probability Calibration</tag>
        <tag>HAN</tag>
        <tag>XGBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯5</title>
    <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D5/</url>
    <content><![CDATA[<p>æœ¬å‘¨å¤ªå¿™äº†ï¼Œæ²¡èƒŒä»€ä¹ˆè¯—è¯ï¼ŒåªèƒŒï¼ˆå¤ä¹ ï¼‰äº†éƒ¨åˆ†çš„ã€Šæ»•ç‹é˜åºã€‹ã€‚</p>
<p>1ï¸âƒ£</p>
<h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>å—Ÿä¹ï¼æ—¶è¿ä¸é½ï¼Œå‘½é€”å¤šèˆ›ã€‚å†¯å”æ˜“è€ï¼Œæå¹¿éš¾å°ã€‚å±ˆè´¾è°Šäºé•¿æ²™ï¼Œéæ— åœ£ä¸»ï¼›çªœæ¢é¸¿äºæµ·æ›²ï¼Œå²‚ä¹æ˜æ—¶ï¼Ÿæ‰€èµ–<strong>å›å­è§æœºï¼Œè¾¾äººçŸ¥å‘½</strong>ã€‚è€å½“ç›Šå£®ï¼Œå®ç§»ç™½é¦–ä¹‹å¿ƒï¼Ÿ<strong>ç©·ä¸”ç›Šåšï¼Œä¸å é’äº‘ä¹‹å¿—</strong>ã€‚é…Œè´ªæ³‰è€Œè§‰çˆ½ï¼Œå¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ã€‚<strong>åŒ—æµ·è™½èµŠï¼Œæ‰¶æ‘‡å¯æ¥ï¼›ä¸œéš…å·²é€ï¼Œæ¡‘æ¦†éæ™šã€‚</strong>å­Ÿå°é«˜æ´ï¼Œç©ºé¦€æŠ¥å›½ä¹‹æƒ…ï¼›é˜®ç±çŒ–ç‹‚ï¼Œå²‚æ•ˆç©·é€”ä¹‹å“­ï¼</p>
<p>å‹ƒï¼Œä¸‰å°ºå¾®å‘½ï¼Œä¸€ä»‹ä¹¦ç”Ÿã€‚æ— è·¯è¯·ç¼¨ï¼Œç­‰ç»ˆå†›ä¹‹å¼±å† ï¼›æœ‰æ€€æŠ•ç¬”ï¼Œæ…•å®—æ…¤ä¹‹é•¿é£ã€‚èˆç°ªç¬äºç™¾é¾„ï¼Œå¥‰æ™¨æ˜äºä¸‡é‡Œã€‚éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ã€‚ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼›ä»Šå…¹æ§è¢‚ï¼Œå–œæ‰˜é¾™é—¨ã€‚æ¨æ„ä¸é€¢ï¼ŒæŠšå‡Œäº‘è€Œè‡ªæƒœï¼›é”ºæœŸæ—¢é‡ï¼Œå¥æµæ°´ä»¥ä½•æƒ­ï¼Ÿ</p>
<hr>
<p><strong>æ³¨é‡Šï¼š</strong><br>å†¯å”ï¼šè¥¿æ±‰äººï¼Œæœ‰æ‰èƒ½å´ä¸€ç›´ä¸å—é‡ç”¨ã€‚æ±‰æ­¦å¸æ—¶é€‰æ±‚è´¤è‰¯ï¼Œæœ‰äººä¸¾èå†¯å”ï¼Œå¯æ˜¯ä»–å·²ä¹åå¤šå²ï¼Œéš¾å†åšå®˜äº†ã€‚æå¹¿ï¼šæ±‰æ­¦å¸æ—¶çš„åå°†ï¼Œå¤šå¹´æŠ—å‡»åŒˆå¥´ï¼Œå†›åŠŸå¾ˆå¤§ï¼Œå´ç»ˆèº«æ²¡æœ‰å°ä¾¯ã€‚</p>
<p>è´¾è°Šï¼šæ±‰æ–‡å¸æœ¬æƒ³ä»»è´¾è°Šä¸ºå…¬å¿ï¼Œä½†å› æœä¸­æƒè´µåå¯¹ï¼Œå°±ç–è¿œäº†è´¾è°Šï¼Œä»»ä»–ä¸ºé•¿æ²™ç‹å¤ªå‚…ã€‚æ¢é¸¿ï¼šä¸œæ±‰äººï¼Œå› ä½œè¯—è®½åˆºå›ç‹ï¼Œå¾—ç½ªäº†æ±‰ç« å¸ï¼Œè¢«è¿«é€ƒåˆ°é½é²ä¸€å¸¦èº²é¿ã€‚</p>
<p>é…Œï¼ˆzhuÃ³ï¼‰è´ªæ³‰è€Œè§‰çˆ½ï¼šå–ä¸‹è´ªæ³‰çš„æ°´ï¼Œä»è§‰å¾—å¿ƒå¢ƒæ¸…çˆ½ã€‚å¤ä»£ä¼ è¯´å¹¿å·æœ‰æ°´åè´ªæ³‰ï¼Œäººå–äº†è¿™é‡Œçš„æ°´å°±ä¼šå˜å¾—è´ªå©ªã€‚è¿™å¥æ˜¯è¯´æœ‰å¾·è¡Œçš„äººåœ¨æ±¡æµŠçš„ç¯å¢ƒä¸­ä¹Ÿèƒ½ä¿æŒçº¯æ­£ï¼Œä¸è¢«æ±¡æŸ“ã€‚å¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ï¼šå¤„åœ¨å¥„å¥„å¾…æ¯™çš„æ—¶å€™ï¼Œä»ç„¶ä¹è§‚å¼€æœ—ã€‚å¤„æ²³è¾™ï¼šåŸæŒ‡é²‹é±¼å¤„åœ¨å¹²æ¶¸çš„è½¦è¾™æ—¦ã€‚æ¯”å–»äººé™·å…¥å±æ€¥ä¹‹ä¸­ã€‚</p>
<p>å­Ÿå°ï¼šä¸œæ±‰äººï¼Œä¸ºå®˜æ¸…æ­£è´¤èƒ½ï¼Œä½†ä¸è¢«é‡ç”¨ï¼Œåæ¥å½’ç”°ã€‚é˜®ç±ï¼šä¸‰å›½é­è¯—äººï¼Œä»–æœ‰æ—¶ç‹¬è‡ªé©¾è½¦å‡ºè¡Œï¼Œåˆ°æ— è·¯å¤„ä¾¿æ¸å“­è€Œè¿”ï¼Œå€Ÿæ­¤å®£æ³„ä¸æ»¡äºç°å®çš„è‹¦é—·å¿ƒæƒ…ã€‚</p>
<p>ç»ˆå†›ï¼šã€Šæ±‰ä¹¦Â·ç»ˆå†›ä¼ ã€‹è®°è½½ï¼Œæ±‰æ­¦å¸æƒ³è®©å—è¶Šï¼ˆä»Šå¹¿ä¸œã€å¹¿è¥¿ä¸€å¸¦ï¼‰ç‹å½’é¡ºï¼Œæ´¾ç»ˆå†›å‰å¾€åŠè¯´ï¼Œç»ˆå†›è¯·æ±‚ç»™ä»–é•¿ç¼¨ï¼Œå¿…ç¼šä½å—è¶Šç‹ï¼Œå¸¦å›åˆ°çš‡å®«é—¨å‰ï¼ˆæ„æ€æ˜¯ä¸€å®šå®Œæˆä½¿å‘½ï¼‰ã€‚åæ¥ç”¨â€œè¯·ç¼¨â€æŒ‡æŠ•å†›æŠ¥å›½ã€‚</p>
<p>å®—æ‚«ï¼ˆquÃ¨ï¼‰ï¼šå—æœå®‹äººï¼Œå°‘å¹´æ—¶å¾ˆæœ‰æŠ±è´Ÿï¼Œè¯´â€œæ„¿ä¹˜é•¿é£ç ´ä¸‡é‡Œæµªâ€ã€‚</p>
<p>ç°ªï¼ˆzÄnï¼‰ç¬ï¼ˆhÃ¹ï¼‰ï¼šè¿™é‡Œä»£æŒ‡å®˜èŒã€‚æ™¨æ˜ï¼šæ™¨æ˜å®šçœï¼Œå‡ºè‡ª ã€Šç¤¼è®°Â·æ›²ç¤¼ä¸Šã€‹ï¼Œé‡Šä¹‰ä¸ºæ—§æ—¶ä¾å¥‰çˆ¶æ¯çš„æ—¥å¸¸ç¤¼èŠ‚ã€‚</p>
<p>éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè‡ªå·±å¹¶ä¸æ˜¯åƒè°¢ç„é‚£æ ·å‡ºè‰²çš„äººæ‰ï¼Œå´èƒ½åœ¨ä»Šæ—¥çš„å®´ä¼šä¸Šç»“è¯†å„ä½åå£«ã€‚è°¢å®¶ä¹‹å®æ ‘ï¼šæŒ‡è°¢ç„ã€‚ã€Šæ™‹ä¹¦Â·è°¢ç„ä¼ ã€‹è®°è½½ï¼Œæ™‹æœè°¢å®‰æ›¾é—®å­ä¾„ä»¬ï¼šä¸ºä»€ä¹ˆäººä»¬æ€»å¸Œæœ›è‡ªå·±çš„å­å¼Ÿå¥½ï¼Ÿä¾„å­è°¢ç„å›ç­”ï¼šâ€œè­¬å¦‚èŠå…°ç‰æ ‘ï¼Œæ¬²ä½¿å…¶ç”Ÿäºåº­é˜¶è€³ã€‚â€åæ¥å°±ç§°è°¢ç„ä¸ºè°¢å®¶å®æ ‘ã€‚å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè¿™é‡Œå€Ÿå­Ÿå­çš„æ¯äº²ä¸ºå¯»æ‰¾é‚»å±…è€Œä¸‰æ¬¡æ¬å®¶çš„æ•…äº‹ï¼Œæ¥æŒ‡èµ´å®´çš„å˜‰å®¾ã€‚</p>
<p>ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼šè¿‡äº›æ—¶å€™è‡ªå·±å°†åˆ°çˆ¶äº²é‚£é‡Œé™ªä¾å’Œè†å¬æ•™è¯²ã€‚è¶‹åº­ï¼šå¿«æ­¥èµ°è¿‡åº­é™¢ï¼Œè¿™æ˜¯è¡¨ç¤ºå¯¹é•¿è¾ˆçš„æ­æ•¬ã€‚å¨ï¼šæƒ­æ„§åœ°æ‰¿å—ï¼Œè¡¨ç¤ºè‡ªè°¦ã€‚é²¤å¯¹ï¼šå­”é²¤æ˜¯å­”å­çš„å„¿å­ï¼Œé²¤å¯¹æŒ‡æ¥å—çˆ¶äº²æ•™è¯²ã€‚äº‹è§ã€Šè®ºè¯­Â·å­£æ°ã€‹ï¼šï¼ˆå­”å­ï¼‰å°ç‹¬ç«‹ï¼Œï¼ˆå­”ï¼‰é²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦è¯—ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€œæœªä¹Ÿã€‚â€â€œä¸å­¦è¯—ï¼Œæ— ä»¥è¨€ã€‚â€é²¤é€€è€Œå­¦è¯—ã€‚ä»–æ—¥ï¼Œåˆç‹¬ç«‹ï¼Œé²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦ç¤¼ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€˜æœªä¹Ÿã€‚â€â€œä¸å­¦ç¤¼ï¼Œæ— ä»¥ç«‹ã€‚â€é²¤é€€è€Œå­¦ç¤¼ã€‚</p>
<p>æ§è¢‚ï¼ˆmÃ¨iï¼‰ï¼šä¸¾èµ·åŒè¢–ä½œæ–ï¼ŒæŒ‡è°’è§é˜å…¬ã€‚å–œæ‰˜é¾™é—¨ï¼šï¼ˆå—åˆ°é˜å…¬çš„æ¥å¾…ï¼‰ååˆ†é«˜å…´ï¼Œå¥½åƒç™»ä¸Šé¾™é—¨ä¸€æ ·ã€‚</p>
<p>æ¨æ„ï¼šå³èœ€äººæ¨å¾—æ„ï¼Œä»»æŒç®¡å¤©å­çŒçŠ¬çš„å®˜ï¼Œè¥¿æ±‰è¾èµ‹å®¶å¸é©¬ç›¸å¦‚æ˜¯ç”±ä»–æ¨èç»™æ±‰æ­¦å¸çš„ã€‚å‡Œäº‘ï¼šè¿™é‡ŒæŒ‡å¸é©¬ç›¸å¦‚çš„èµ‹ï¼Œã€Šå²è®°Â·å¸é©¬ç›¸å¦‚ä¼ ã€‹è¯´ï¼Œç›¸å¦‚çŒ®ã€Šå¤§äººèµ‹ã€‹ï¼Œâ€œå¤©å­å¤§æ‚¦ï¼Œé£˜é£˜æœ‰å‡Œäº‘ä¹‹æ°”ï¼Œä¼¼æ¸¸å¤©åœ°ä¹‹é—´â€ã€‚é’ŸæœŸï¼šå³é’Ÿå­æœŸã€‚</p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>Pythonä¸­çš„æ‹·è´</title>
    <url>/2018/08/18/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84%E6%8B%B7%E8%B4%9D/</url>
    <content><![CDATA[<p>Pythonçš„æ‹·è´å’ŒC/C++çš„å·®åˆ«å¾ˆå¤§ï¼Œå¾ˆç»å¸¸å°±å®¹æ˜“ææ··ï¼Œå› æ­¤è®°å½•ä¸€ä¸‹ã€‚</p>
<h3 id="èµ‹å€¼ã€æ‹·è´"><a href="#èµ‹å€¼ã€æ‹·è´" class="headerlink" title="èµ‹å€¼ã€æ‹·è´"></a>èµ‹å€¼ã€æ‹·è´</h3><ul>
<li>èµ‹å€¼ï¼šå®é™…ä¸Šå°±æ˜¯å¯¹è±¡çš„å¼•ç”¨ï¼Œæ²¡æœ‰å¼€è¾Ÿæ–°çš„å†…å­˜ç©ºé—´<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lst=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">l=lst</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>æµ…æ‹·è´:åˆ›å»ºäº†æ–°å¯¹è±¡ï¼Œä½†æ˜¯<strong>å†…å®¹æ˜¯å¯¹åŸå¯¹è±¡çš„å¼•ç”¨</strong>ï¼Œæœ‰ä¸‰ç§å½¢å¼</p>
<ol>
<li><p>åˆ‡ç‰‡  </p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l=lst[:]</span><br><span class="line">l=[i <span class="keyword">for</span> i <span class="keyword">in</span> lst]</span><br></pre></td></tr></table></figure>
</li>
<li><p>å·¥å‚</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l=list(lst)</span><br></pre></td></tr></table></figure>
</li>
<li><p>copy </p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.copy(lst)</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p>æ·±æ‹·è´:copyä¸­çš„deepcopyï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„å¯¹è±¡ï¼Œä¸åŸæ¥çš„å¯¹è±¡æ— å…³</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.deepcopy(lst)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="ä¾‹å­"><a href="#ä¾‹å­" class="headerlink" title="ä¾‹å­"></a>ä¾‹å­</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### å¼•ç”¨https://www.cnblogs.com/huangbiquan/p/7795152.html çš„ä¾‹å­###</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> copy</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,[<span class="string">'a'</span>,<span class="string">'b'</span>]] <span class="comment">#å®šä¹‰ä¸€ä¸ªåˆ—è¡¨a</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a <span class="comment">#èµ‹å€¼</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = copy.copy(a) <span class="comment">#æµ…æ‹·è´</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = copy.deepcopy(a) <span class="comment">#æ·±æ‹·è´</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.append(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#aæ·»åŠ ä¸€ä¸ªå…ƒç´ 5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ 5 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#cä¿æŒä¸å˜</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">4</span>].append(<span class="string">'c'</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#aä¸­çš„list(å³a[4])æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]] <span class="comment">#cè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#è¯´æ˜å¦‚ä¸‹ï¼š</span></span><br><span class="line"><span class="comment">#1.å¤–å±‚æ·»åŠ å…ƒç´ æ—¶ï¼Œ æµ…æ‹·è´cä¸ä¼šéšåŸåˆ—è¡¨aå˜åŒ–è€Œå˜åŒ–ï¼›å†…å±‚listæ·»åŠ å…ƒç´ æ—¶ï¼Œæµ…æ‹·è´cæ‰ä¼šå˜åŒ–ã€‚</span></span><br><span class="line"><span class="comment">#2.æ— è®ºåŸåˆ—è¡¨aå¦‚ä½•å˜åŒ–ï¼Œæ·±æ‹·è´déƒ½ä¿æŒä¸å˜ã€‚</span></span><br><span class="line"><span class="comment">#3.èµ‹å€¼å¯¹è±¡éšç€åŸåˆ—è¡¨ä¸€èµ·å˜åŒ–</span></span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/huangbiquan/p/7795152.html" target="_blank" rel="noopener">https://www.cnblogs.com/huangbiquan/p/7795152.html</a><br><a href="https://www.cnblogs.com/xueli/p/4952063.html" target="_blank" rel="noopener">https://www.cnblogs.com/xueli/p/4952063.html</a></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Python</tag>
        <tag>æ‹·è´</tag>
      </tags>
  </entry>
  <entry>
    <title>å¦‚ä½•å°†ELMoè¯å‘é‡ç”¨äºä¸­æ–‡</title>
    <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E5%B0%86ELMo%E8%AF%8D%E5%90%91%E9%87%8F%E7%94%A8%E4%BA%8E%E4%B8%AD%E6%96%87/</url>
    <content><![CDATA[<p>10.10æ›´æ–°ï¼šELMoå·²ç»ç”±å“ˆå·¥å¤§ç»„ç”¨PyTorché‡å†™äº†ï¼Œå¹¶ä¸”æä¾›äº†ä¸­æ–‡çš„é¢„è®­ç»ƒå¥½çš„language modelï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚</p>
<p>2019.4.7æ›´æ–°ï¼šå¹´ä»£è¿‡äºä¹…è¿œï¼Œæœ¬äººäºç»†èŠ‚æ–¹é¢æ—©å·²è®°ä¸å¤§æ¸…æ¥šäº†ã€‚é‡åˆ°bugæˆ–é—®é¢˜çƒ¦è¯·è‡ªè¡ŒæŸ¥é˜…è§£å†³ï¼Œè¯·ä¸å¿…åœ¨è¯„è®ºåŒºæé—®æˆ–é‚®ä»¶æé—®ï¼Œä¸ä¼šå†å›å¤ã€‚</p>
<hr>
<p>ELMoäºä»Šå¹´äºŒæœˆç”±AllenNLPæå‡ºï¼Œä¸word2vecæˆ–GloVeä¸åŒçš„æ˜¯å…¶åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œå…¶æœ¬è´¨å³é€šè¿‡è®­ç»ƒlanguage modelï¼Œå¯¹äºä¸€å¥è¯è¿›å…¥åˆ°language modelè·å¾—ä¸åŒçš„è¯å‘é‡ã€‚æ ¹æ®å®éªŒå¯å¾—ï¼Œä½¿ç”¨äº†Elmoè¯å‘é‡ä¹‹åï¼Œè®¸å¤šNLPä»»åŠ¡éƒ½æœ‰äº†å¤§å¹…çš„æé«˜ã€‚</p>
<p>è®ºæ–‡:<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">Deep contextualized word representations</a></p>
<p>AllenNLPä¸€å…±releaseäº†ä¸¤ä»½ELMoçš„ä»£ç ï¼Œä¸€ä»½æ˜¯Pytorchç‰ˆæœ¬çš„ï¼Œå¦ä¸€ä»½æ˜¯Tensorflowç‰ˆæœ¬çš„ã€‚Pytorchç‰ˆæœ¬çš„åªå¼€æ”¾äº†ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡çš„æ¥å£ï¼Œä½†æ²¡æœ‰ç»™å‡ºè‡ªå·±è®­ç»ƒçš„æ¥å£ï¼Œå› æ­¤æ— æ³•ä½¿ç”¨åˆ°ä¸­æ–‡è¯­æ–™ä¸­ã€‚Tensorflowç‰ˆæœ¬æœ‰æä¾›è®­ç»ƒçš„ä»£ç ï¼Œå› æ­¤æœ¬æ–‡è®°å½•å¦‚ä½•å°†ELMoç”¨äºä¸­æ–‡è¯­æ–™ä¸­ï¼Œä½†æœ¬æ–‡åªè®°å½•ä½¿ç”¨åˆ°çš„éƒ¨åˆ†ï¼Œè€Œä¸ä¼šåˆ†æå…¨éƒ¨çš„ä»£ç ã€‚</p>
<p>éœ€æ±‚:<br>ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡ä½œä¸ºå¥å­è¡¨ç¤ºç›´æ¥ä¼ å…¥åˆ°RNNä¸­(ä¹Ÿå°±æ˜¯ä¸ä½¿ç”¨ä»£ç ä¸­é»˜è®¤çš„å…ˆè¿‡CNN)ï¼Œåœ¨è®­ç»ƒå®Œåï¼Œå°†æ¨¡å‹ä¿å­˜ï¼Œåœ¨éœ€è¦ç”¨çš„æ—¶å€™loadè¿›æ¥ï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„å¥å­ï¼Œé¦–å…ˆå°†å…¶è½¬æ¢æˆé¢„è®­ç»ƒçš„è¯å‘é‡ï¼Œä¼ å…¥language modelä¹‹åæœ€ç»ˆå¾—åˆ°ELMoè¯å‘é‡ã€‚</p>
<p>å‡†å¤‡å·¥ä½œ:</p>
<ol>
<li>å°†ä¸­æ–‡è¯­æ–™åˆ†è¯</li>
<li>è®­ç»ƒå¥½GloVeè¯å‘é‡æˆ–è€…word2vec</li>
<li>ä¸‹è½½<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">bilm-tfä»£ç </a></li>
<li>ç”Ÿæˆè¯è¡¨ vocab_file ï¼ˆè®­ç»ƒçš„æ—¶å€™è¦ç”¨åˆ°ï¼‰</li>
<li>optional:é˜…è¯»Readme</li>
<li>optional:é€šè¯»bilm-tfçš„ä»£ç ï¼Œå¯¹ä»£ç ç»“æ„æœ‰ä¸€å®šçš„è®¤è¯†</li>
</ol>
<p>æ€è·¯:</p>
<ol>
<li>å°†é¢„è®­ç»ƒçš„è¯å‘é‡è¯»å…¥</li>
<li>ä¿®æ”¹bilm-tfä»£ç <ol>
<li>optionéƒ¨åˆ†</li>
<li>æ·»åŠ ç»™embedding weightèµ‹åˆå€¼</li>
<li>æ·»åŠ ä¿å­˜embedding weightçš„ä»£ç </li>
</ol>
</li>
<li>å¼€å§‹è®­ç»ƒï¼Œè·å¾—checkpointå’Œoptionæ–‡ä»¶</li>
<li>è¿è¡Œè„šæœ¬ï¼Œè·å¾—language modelçš„weightæ–‡ä»¶</li>
<li>å°†embedding weightä¿å­˜ä¸ºhdf5æ–‡ä»¶å½¢å¼</li>
<li>è¿è¡Œè„šæœ¬ï¼Œå°†è¯­æ–™è½¬åŒ–æˆELMo embeddingã€‚</li>
</ol>
<h3 id="è®­ç»ƒGloVeæˆ–word2vec"><a href="#è®­ç»ƒGloVeæˆ–word2vec" class="headerlink" title="è®­ç»ƒGloVeæˆ–word2vec"></a>è®­ç»ƒGloVeæˆ–word2vec</h3><p>å¯å‚è§æˆ‘ä»¥å‰çš„åšå®¢æˆ–è€…ç½‘ä¸Šçš„æ•™ç¨‹ã€‚<br>æ³¨æ„åˆ°ï¼Œå¦‚æœè¦ç”¨gensimå¯¼å…¥GloVeè®­å¥½çš„è¯å‘é‡ï¼Œéœ€è¦åœ¨å¼€å¤´æ·»åŠ num_word embedding_dimã€‚ å¦‚ï¼š<br><img src="/images/2018-08-10-15338861462682.jpg" width="70%" height="50%"></p>
<h3 id="è·å¾—vocabè¯è¡¨æ–‡ä»¶"><a href="#è·å¾—vocabè¯è¡¨æ–‡ä»¶" class="headerlink" title="è·å¾—vocabè¯è¡¨æ–‡ä»¶"></a>è·å¾—vocabè¯è¡¨æ–‡ä»¶</h3><p>æ³¨æ„åˆ°ï¼Œè¯è¡¨æ–‡ä»¶çš„å¼€å¤´å¿…é¡»è¦æœ‰<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œä¸”å¤§å°å†™æ•æ„Ÿã€‚å¹¶ä¸”åº”å½“æŒ‰ç…§å•è¯çš„è¯é¢‘é™åºæ’åˆ—ã€‚å¯ä»¥é€šè¿‡æ‰‹åŠ¨æ·»åŠ è¿™ä¸‰ä¸ªç‰¹æ®Šç¬¦å·ã€‚<br>å¦‚ï¼š<br><img src="/images/2018-08-11-15339757184030.jpg" width="10%" height="50%"></p>
<p>ä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">    fname=<span class="string">'/home/zhlin/GloVe/vectors.txt'</span>,binary=<span class="keyword">False</span></span><br><span class="line">)</span><br><span class="line">words=model.vocab</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'vocab.txt'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'&lt;S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>ï¼‰</span><br><span class="line">    f.write(<span class="string">'&lt;/S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)</span><br><span class="line">    f.write(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)    <span class="comment"># bilm-tf è¦æ±‚vocabæœ‰è¿™ä¸‰ä¸ªç¬¦å·ï¼Œå¹¶ä¸”åœ¨æœ€å‰é¢</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        f.write(word)</span><br><span class="line">        f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="ä¿®æ”¹bilm-tfä»£ç "><a href="#ä¿®æ”¹bilm-tfä»£ç " class="headerlink" title="ä¿®æ”¹bilm-tfä»£ç "></a>ä¿®æ”¹bilm-tfä»£ç </h3><p>æ³¨æ„åˆ°ï¼Œåœ¨ä½¿ç”¨è¯¥ä»£ç ä¹‹å‰ï¼Œéœ€è¦å®‰è£…å¥½ç›¸åº”çš„ç¯å¢ƒã€‚</p>
<p><img src="/images/2018-08-10-15338879402377.jpg" width="50%" height="50%"></p>
<p>å¦‚æœä½¿ç”¨çš„æ˜¯condaä½œä¸ºé»˜è®¤çš„Pythonè§£é‡Šå™¨ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨condaå®‰è£…ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°ä¸€äº›è«åçš„é”™è¯¯ã€‚<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install tensorflow-gpu=1.4</span><br><span class="line">conda install h5py</span><br><span class="line">python setup.py install <span class="comment">#åº”åœ¨bilm-tfçš„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œè¯¥æŒ‡ä»¤</span></span><br></pre></td></tr></table></figure></p>
<p>ç„¶åå†è¿è¡Œæµ‹è¯•ä»£ç ï¼Œé€šè¿‡è¯´æ˜å®‰è£…æˆåŠŸã€‚</p>
<h4 id="ä¿®æ”¹train-elmo-py"><a href="#ä¿®æ”¹train-elmo-py" class="headerlink" title="ä¿®æ”¹train_elmo.py"></a>ä¿®æ”¹train_elmo.py</h4><p>binæ–‡ä»¶å¤¹ä¸‹çš„train_elmo.pyæ˜¯ç¨‹åºçš„å…¥å£ã€‚<br>ä¸»è¦ä¿®æ”¹çš„åœ°æ–¹ï¼š</p>
<ol>
<li>load_vocabçš„ç¬¬äºŒä¸ªå‚æ•°åº”è¯¥æ”¹ä¸ºNone</li>
<li>n_gpus CUDA_VISIBLE_DEVICES æ ¹æ®è‡ªå·±éœ€æ±‚æ”¹</li>
<li>n_train_tokens å¯æ”¹å¯ä¸æ”¹ï¼Œå½±å“çš„æ˜¯è¾“å‡ºä¿¡æ¯ã€‚è¦æŸ¥çœ‹è‡ªå·±è¯­æ–™çš„è¡Œæ•°ï¼Œå¯ä»¥é€šè¿‡<code>wc -l corpus.txt</code> æŸ¥çœ‹ã€‚</li>
<li><strong>optionçš„ä¿®æ”¹</strong>ï¼Œå°†char_cnnéƒ¨åˆ†éƒ½æ³¨é‡Šæ‰ï¼Œå…¶ä»–æ ¹æ®è‡ªå·±éœ€æ±‚ä¿®æ”¹</li>
</ol>
<p>å¦‚ï¼š<br><img src="/images/2018-08-10-15338888745894.jpg" width="70%" height="50%"></p>
<h4 id="ä¿®æ”¹LanguageModelç±»"><a href="#ä¿®æ”¹LanguageModelç±»" class="headerlink" title="ä¿®æ”¹LanguageModelç±»"></a>ä¿®æ”¹LanguageModelç±»</h4><p>ç”±äºæˆ‘éœ€è¦ä¼ å…¥é¢„è®­ç»ƒå¥½çš„GloVe embeddingï¼Œé‚£ä¹ˆè¿˜éœ€è¦ä¿®æ”¹embeddingéƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†åœ¨bilmæ–‡ä»¶å¤¹ä¸‹çš„training.pyï¼Œè¿›å…¥åˆ°LanguageModelç±»ä¸­_build_word_embeddingså‡½æ•°ä¸­ã€‚æ³¨æ„åˆ°ï¼Œç”±äºå‰ä¸‰ä¸ªæ˜¯<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œè€Œè¿™ä¸‰ä¸ªå­—ç¬¦åœ¨GloVeé‡Œé¢æ˜¯æ²¡æœ‰çš„ï¼Œå› æ­¤è¿™ä¸‰ä¸ªå­—ç¬¦çš„embeddingåº”å½“åœ¨è®­ç»ƒçš„æ—¶å€™é€æ¸å­¦ä¹ åˆ°ï¼Œè€Œæ­£å› æ­¤ <code>embedding_weights</code>çš„<code>trainable</code>åº”å½“è®¾ä¸º<code>True</code></p>
<p>å¦‚:</p>
<p><img src="/images/2018-08-12-15340585073779.jpg" alt=""></p>
<h4 id="ä¿®æ”¹trainå‡½æ•°"><a href="#ä¿®æ”¹trainå‡½æ•°" class="headerlink" title="ä¿®æ”¹trainå‡½æ•°"></a>ä¿®æ”¹trainå‡½æ•°</h4><p>æ·»åŠ ä»£ç ï¼Œä½¿å¾—åœ¨trainå‡½æ•°çš„æœ€åä¿å­˜embeddingæ–‡ä»¶ã€‚<br><img src="/images/2018-08-12-15340607132103.jpg" alt=""></p>
<h3 id="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"><a href="#è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶" class="headerlink" title="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"></a>è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶</h3><p>è®­ç»ƒéœ€è¦è¯­æ–™æ–‡ä»¶corpus.txtï¼Œè¯è¡¨æ–‡ä»¶vocab.txtã€‚</p>
<h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>cdåˆ°bilm-tfæ–‡ä»¶å¤¹ä¸‹ï¼Œè¿è¡Œ<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=4</span><br><span class="line">nohup python -u bin/train_elmo.py \</span><br><span class="line">--train_prefix=<span class="string">'/home/zhlin/bilm-tf/corpus.txt'</span> \</span><br><span class="line">--vocab_file /home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try &gt;bilm_out.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>æ ¹æ®å®é™…æƒ…å†µè®¾å®šä¸åŒçš„å€¼å’Œè·¯å¾„ã€‚</p>
<p>è¿è¡Œæƒ…å†µï¼š<br><img src="/images/2018-08-10-15339015862848.jpg" width="50%" height="50%"></p>
<p>PS:è¿è¡Œè¿‡ç¨‹ä¸­å¯èƒ½ä¼šæœ‰warning:</p>
<blockquote>
<p>â€˜listâ€™ object has no attribute â€˜nameâ€™<br>WARNING:tensorflow:Error encountered when serializing lstm_output_embeddings.<br>Type is unsupported, or the types of the items donâ€™t match field type in CollectionDef.</p>
</blockquote>
<p>åº”è¯¥ä¸ç”¨æ‹…å¿ƒï¼Œè¿˜æ˜¯èƒ½å¤Ÿç»§ç»­è¿è¡Œçš„ï¼Œåé¢ä¹Ÿä¸å—å½±å“ã€‚</p>
<p>åœ¨ç­‰å¾…äº†ç›¸å½“é•¿çš„æ—¶é—´åï¼Œåœ¨save_diræ–‡ä»¶å¤¹å†…ç”Ÿæˆäº†å‡ ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­checkpointå’Œoptionsæ˜¯å…³é”®ï¼Œcheckpointèƒ½å¤Ÿè¿›ä¸€æ­¥ç”Ÿæˆlanguage modelçš„weightsæ–‡ä»¶ï¼Œè€Œoptionsè®°å½•language modelçš„å‚æ•°ã€‚</p>
<p><img src="/images/2018-08-11-15339734319058.jpg" alt=""></p>
<h4 id="è·å¾—language-modelçš„weights"><a href="#è·å¾—language-modelçš„weights" class="headerlink" title="è·å¾—language modelçš„weights"></a>è·å¾—language modelçš„weights</h4><p>æ¥ä¸‹æ¥è¿è¡Œbin/dump_weights.pyå°†checkpointè½¬æ¢æˆhdf5æ–‡ä»¶ã€‚</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nohup python -u  /home/zhlin/bilm-tf/bin/dump_weights.py  \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try  \</span><br><span class="line">--outfile /home/zhlin/bilm-tf/try/weights.hdf5 &gt;outfile.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p>å…¶ä¸­save_diræ˜¯checkpointå’Œoptionæ–‡ä»¶ä¿å­˜çš„åœ°å€ã€‚</p>
<p>æ¥ä¸‹æ¥ç­‰å¾…ç¨‹åºè¿è¡Œï¼š</p>
<p><img src="/images/2018-08-11-15339740970081.jpg" width="70%" height="50%"></p>
<p><img src="/images/2018-08-11-15339745511775.jpg" width="70%" height="50%"></p>
<p>æœ€ç»ˆè·å¾—äº†æƒ³è¦çš„weightså’Œoptionï¼š<br><img src="/images/2018-08-11-15339978499136.jpg" alt=""></p>
<h3 id="å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding"><a href="#å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding" class="headerlink" title="å°†è¯­æ–™è½¬åŒ–æˆELMo embedding"></a>å°†è¯­æ–™è½¬åŒ–æˆELMo embedding</h3><p>ç”±äºæˆ‘ä»¬æœ‰äº†vocab_fileã€ä¸vocab_fileä¸€ä¸€å¯¹åº”çš„embedding h5pyæ–‡ä»¶ã€ä»¥åŠlanguage modelçš„weights.hdf5å’Œoptions.jsonã€‚<br>æ¥ä¸‹æ¥å‚è€ƒusage_token.pyå°†ä¸€å¥è¯è½¬åŒ–æˆELMo embeddingã€‚</p>
<p>å‚è€ƒä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> bilm <span class="keyword">import</span> TokenBatcher, BidirectionalLanguageModel, weight_layers, \</span><br><span class="line">    dump_token_embeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># Our small dataset.</span></span><br><span class="line">raw_context = [</span><br><span class="line">    <span class="string">'è¿™ æ˜¯ æµ‹è¯• .'</span>,</span><br><span class="line">    <span class="string">'å¥½çš„ .'</span></span><br><span class="line">]</span><br><span class="line">tokenized_context = [sentence.split() <span class="keyword">for</span> sentence <span class="keyword">in</span> raw_context]</span><br><span class="line">tokenized_question = [</span><br><span class="line">    [<span class="string">'è¿™'</span>, <span class="string">'æ˜¯'</span>, <span class="string">'ä»€ä¹ˆ'</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">vocab_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt'</span></span><br><span class="line">options_file=<span class="string">'/home/zhlin/bilm-tf/try/options.json'</span></span><br><span class="line">weight_file=<span class="string">'/home/zhlin/bilm-tf/try/weights.hdf5'</span></span><br><span class="line">token_embedding_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab_embedding.hdf5'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Now we can do inference.</span></span><br><span class="line"><span class="comment"># Create a TokenBatcher to map text to token ids.</span></span><br><span class="line">batcher = TokenBatcher(vocab_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input placeholders to the biLM.</span></span><br><span class="line">context_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line">question_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the biLM graph.</span></span><br><span class="line">bilm = BidirectionalLanguageModel(</span><br><span class="line">    options_file,</span><br><span class="line">    weight_file,</span><br><span class="line">    use_character_inputs=<span class="keyword">False</span>,</span><br><span class="line">    embedding_weight_file=token_embedding_file</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get ops to compute the LM embeddings.</span></span><br><span class="line">context_embeddings_op = bilm(context_token_ids)</span><br><span class="line">question_embeddings_op = bilm(question_token_ids)</span><br><span class="line"></span><br><span class="line">elmo_context_input = weight_layers(<span class="string">'input'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_input = weight_layers(</span><br><span class="line">        <span class="string">'input'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">elmo_context_output = weight_layers(</span><br><span class="line">    <span class="string">'output'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_output = weight_layers(</span><br><span class="line">        <span class="string">'output'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># It is necessary to initialize variables once before running inference.</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create batches of data.</span></span><br><span class="line">    context_ids = batcher.batch_sentences(tokenized_context)</span><br><span class="line">    question_ids = batcher.batch_sentences(tokenized_question)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute ELMo representations (here for the input only, for simplicity).</span></span><br><span class="line">    elmo_context_input_, elmo_question_input_ = sess.run(</span><br><span class="line">        [elmo_context_input[<span class="string">'weighted_op'</span>], elmo_question_input[<span class="string">'weighted_op'</span>]],</span><br><span class="line">        feed_dict=&#123;context_token_ids: context_ids,</span><br><span class="line">                   question_token_ids: question_ids&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">print(elmo_context_input_,elmo_context_input_)</span><br></pre></td></tr></table></figure></p>
<p>å¯ä»¥ä¿®æ”¹ä»£ç ä»¥é€‚åº”è‡ªå·±çš„éœ€æ±‚ã€‚</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">https://github.com/allenai/bilm-tf</a></p>
]]></content>
      <tags>
        <tag>æ•™ç¨‹</tag>
        <tag>ELMo</tag>
        <tag>è¯å‘é‡</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•4</title>
    <url>/2018/08/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB4/</url>
    <content><![CDATA[<p>æœ¬å‘¨æ²¡æœ‰ä»€ä¹ˆä»£ç è¦è®°å½•çš„ã€‚</p>
<h3 id="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"><a href="#1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­" class="headerlink" title="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"></a>1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­</h3><p>ç”¨æœºå™¨å­¦ä¹ è§£å†³é—®é¢˜çš„æµç¨‹ï¼š<br>(å»æ‰éƒ¨åˆ†æ•°æ®ï¼‰â€”&gt; è·å–featureï¼ˆTf-idfç­‰ï¼‰ â€”&gt; ï¼ˆfeature selectionï¼Œchi2ã€äº’ä¿¡æ¯ç­‰ï¼‰ â€”&gt; ï¼ˆç¼©æ”¾/æ­£åˆ™åŒ–ï¼‰ â€”&gt; åˆ†ç±»å™¨ â€”&gt; GridSearch/RandomizedSearchè°ƒå‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">pipe=Pipeline([     <span class="comment">#å»ºç«‹pipeline</span></span><br><span class="line">    (<span class="string">'vect'</span>,TfidfVectorizer()),</span><br><span class="line">    (<span class="string">'select'</span>,SelectKBest(chi2),</span><br><span class="line">    (<span class="string">'norm'</span>,MaxAbsScaler()),   </span><br><span class="line">    (<span class="string">'svm'</span>,svm.LinearSVC())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">parameters=&#123;</span><br><span class="line">    <span class="string">'vect__ngram_range'</span>:[(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>)],</span><br><span class="line">    <span class="string">'vect__max_df'</span>:[<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>],</span><br><span class="line">    <span class="string">'vect__min_df'</span>:[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>],</span><br><span class="line">    <span class="string">'vect__norm'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__penalty'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__loss'</span>:[<span class="string">'squared_hinge'</span>],  </span><br><span class="line">    <span class="string">'svm__dual'</span>:[<span class="keyword">False</span>,<span class="keyword">True</span>],</span><br><span class="line">    <span class="string">'svm__tol'</span>:[<span class="number">1e-5</span>,<span class="number">1e-4</span>],</span><br><span class="line">    <span class="string">'svm__C'</span>:[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">1.0</span>,<span class="number">1.1</span>],</span><br><span class="line">    <span class="string">'svm__class_weight'</span>:[<span class="keyword">None</span>,<span class="string">'balanced'</span>],</span><br><span class="line">    <span class="string">'svm__max_iter'</span>:[<span class="number">1000</span>,<span class="number">5000</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search_model=GridSearchCV(pipe,parameters,error_score=<span class="number">0</span>,n_jobs=<span class="number">5</span>)</span><br><span class="line">grid_search_model.fit(train[column],train[<span class="string">'class'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> para_name <span class="keyword">in</span> sorted(parameters.keys()):</span><br><span class="line">    print(para_name,grid_search_model.best_params_[para_name])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"cv_result:"</span>)</span><br><span class="line">print(grid_search_model.cv_results_)</span><br></pre></td></tr></table></figure>
<hr>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†3</title>
    <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%863/</url>
    <content><![CDATA[<p>1ï¸âƒ£[Python]<br>åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç æ—¶ï¼Œå¦‚ <code>python project/folder1/a.py</code>ï¼Œå¦‚æœa.pyå¼•ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„æ¨¡å—ä½†åˆä¸åœ¨folder1å†…ï¼Œæ­¤æ—¶interpreterå°±ä¼šæŠ¥é”™ï¼Œæç¤ºæ‰¾ä¸åˆ°è¯¥æ¨¡å—ã€‚è¿™æ˜¯å› ä¸ºè§£é‡Šå™¨é»˜è®¤åªä¼šåœ¨åŒä¸€ä¸ªfolderä¸‹æŸ¥æ‰¾ã€‚è§£å†³æ–¹æ¡ˆæ˜¯åœ¨è¿è¡Œå‰æ˜¾å¼æ·»åŠ æŸ¥æ‰¾èŒƒå›´ã€‚å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONPATH=/home/zhlin/bilm-tf:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure></p>
<p>é‚£ä¹ˆpythonè§£é‡Šå™¨å°±ä¼šåˆ°è¯¥ç›®å½•ä¸‹å»æ‰¾ã€‚</p>
<hr>
<p>2ï¸âƒ£[åº¦é‡æ ‡å‡†]<br><img src="/images/2018-08-12-15340420442670.jpg" alt=""></p>
<ul>
<li>å‡†ç¡®ç‡(accuracy):  $ACC=\frac{TP+TN}{TP+TN+FP+FN}$<br> è¡¡é‡çš„æ˜¯åˆ†ç±»å™¨é¢„æµ‹å‡†ç¡®çš„æ¯”ä¾‹</li>
<li>å¬å›ç‡(recall): $Recall=\frac{TP}{TP+FN}$<br>  æ­£ä¾‹ä¸­è¢«åˆ†å¯¹çš„æ¯”ä¾‹ï¼Œè¡¡é‡äº†åˆ†ç±»å™¨å¯¹æ­£ä¾‹çš„è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>ç²¾ç¡®ç‡(Precision): $P=\frac{TP}{TP+FP}$<br>åº¦é‡äº†è¢«åˆ†ä¸ºæ­£ä¾‹çš„ç¤ºä¾‹ä¸­å®é™…ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ã€‚</li>
<li>F-Measure: $F=\frac{(\alpha^2 +1)P*R}{\alpha^2 (P+R)}$<br>  å…¶ä¸­Pæ˜¯Precision,Ræ˜¯Recallã€‚ç»¼åˆè€ƒé‡äº†ä¸¤ç§åº¦é‡ã€‚<br>  å½“$\alpha=1$æ—¶ï¼Œç§°ä¸ºF1å€¼ $F1=\frac{2PR}{P+R}$</li>
</ul>
<hr>
<p>3ï¸âƒ£[è°ƒå‚æŠ€å·§]<br>åœ¨googleå‘å¸ƒçš„ä¸€ä»½å…³äºtext-classificationçš„<a href="https://developers.google.com/machine-learning/guides/text-classification/" target="_blank" rel="noopener">guide</a>ä¸­ï¼Œæåˆ°äº†å‡ ä¸ªè°ƒå‚çš„trickã€‚</p>
<ol>
<li>åœ¨feature selectionæ­¥éª¤ä¸­ï¼Œå¡æ–¹æ£€éªŒchi2å’Œæ–¹å·®åˆ†æçš„Få€¼ f_classifçš„è¡¨ç°ç›¸å½“ï¼Œåœ¨å¤§çº¦é€‰æ‹©20kçš„featureæ—¶ï¼Œå‡†ç¡®ç‡è¾¾åˆ°é¡¶å³°ï¼Œå½“featureè¶Šå¤šï¼Œæ•ˆæœå¹¶æ²¡æœ‰æå‡ç”šè‡³ä¼šä¸‹é™ã€‚<br><img src="/images/2018-08-12-15340434326365.jpg" width="90%" height="50%"></li>
<li>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œä¼¼ä¹ä½¿ç”¨normalizationå¹¶æ²¡æœ‰å¤šå°‘ç”¨å¤„ï¼Œå»ºè®®è·³è¿‡ã€‚<blockquote>
<p>Normalization converts all feature/sample values to small and similar values. This simplifies gradient descent convergence in learning algorithms. From what we have seen, normalization during data preprocessing does not seem to add much value in text classification problems; we recommend skipping this step.</p>
</blockquote>
</li>
</ol>
<p>å®é™…ä¸Šæˆ‘ä¹Ÿæµ‹è¯•è¿‡ï¼Œå‘ç°ç¡®å®normalizationå¯¹äºå‡†ç¡®ç‡çš„æé«˜æ²¡ä»€ä¹ˆå¸®åŠ©ï¼Œç”šè‡³è¿˜æœ‰ä¸€ç‚¹ä¸‹é™ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Python</tag>
        <tag>åº¦é‡æ ‡å‡†</tag>
        <tag>è°ƒå‚æŠ€å·§</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯4</title>
    <url>/2018/08/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D4/</url>
    <content><![CDATA[<p>1ï¸âƒ£</p>
<h3 id="çä¸Šç§‹å±…"><a href="#çä¸Šç§‹å±…" class="headerlink" title="çä¸Šç§‹å±…"></a>çä¸Šç§‹å±…</h3><p>[å”] é©¬æˆ´<br>çåŸé£é›¨å®šï¼Œæ™šè§é›è¡Œé¢‘ã€‚<br>è½å¶ä»–ä¹¡æ ‘ï¼Œå¯’ç¯ç‹¬å¤œäººã€‚<br>ç©ºå›­ç™½éœ²æ»´ï¼Œå­¤å£é‡åƒ§é‚»ã€‚<br><strong>å¯„å§éƒŠæ‰‰ä¹…ï¼Œä½•å¹´è‡´æ­¤èº«ã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9</a></p>
<hr>
<p>2ï¸âƒ£</p>
<h3 id="å”å¤šä»¤"><a href="#å”å¤šä»¤" class="headerlink" title="å”å¤šä»¤"></a>å”å¤šä»¤</h3><p>[å®‹] åˆ˜è¿‡<br>èŠ¦å¶æ»¡æ±€æ´²ï¼Œå¯’æ²™å¸¦æµ…æµã€‚äºŒåå¹´é‡è¿‡å—æ¥¼ã€‚æŸ³ä¸‹ç³»èˆ¹çŠ¹æœªç¨³ï¼Œèƒ½å‡ æ—¥ï¼Œåˆä¸­ç§‹ã€‚<br>é»„é¹¤æ–­çŸ¶å¤´ï¼Œæ•…äººä»Šåœ¨å¦ï¼Ÿæ—§æ±Ÿå±±æµ‘æ˜¯æ–°æ„ã€‚<strong>æ¬²ä¹°æ¡‚èŠ±åŒè½½é…’ï¼Œç»ˆä¸ä¼¼ã€å°‘å¹´æ¸¸ã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b922e7c4c9710055904842" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b922e7c4c9710055904842</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>Vimå¸¸ç”¨å¿«æ·é”®</title>
    <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Vim%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<p>åœ¨æœåŠ¡å™¨ç»å¸¸è¦ç”¨åˆ°Vimï¼Œå› æ­¤è®°å½•å¸¸ç”¨çš„å¿«æ·é”®å¹¶ç†Ÿæ‚‰ä¹‹ã€‚</p>
<h3 id="é€€å‡º"><a href="#é€€å‡º" class="headerlink" title="é€€å‡º"></a>é€€å‡º</h3><p>:q é€€å‡º<br>:wq å†™å…¥å¹¶é€€å‡º<br>:q! é€€å‡ºå¹¶å¿½ç•¥æ‰€æœ‰æ›´æ”¹<br>:e! æ”¾å¼ƒä¿®æ”¹å¹¶æ‰“å¼€åŸæ¥çš„æ–‡ä»¶</p>
<h3 id="æ’å…¥"><a href="#æ’å…¥" class="headerlink" title="æ’å…¥"></a>æ’å…¥</h3><p>i åœ¨å½“å‰ä½ç½®å‰æ’å…¥<br>a åœ¨å½“å‰ä½ç½®åæ’å…¥</p>
<h3 id="æ’¤é”€"><a href="#æ’¤é”€" class="headerlink" title="æ’¤é”€"></a>æ’¤é”€</h3><p>:u æ’¤é”€<br>:U æ’¤é”€æ•´è¡Œæ“ä½œ<br>Ctrl+r é‡åš</p>
<h3 id="åˆ é™¤"><a href="#åˆ é™¤" class="headerlink" title="åˆ é™¤"></a>åˆ é™¤</h3><p>:md åˆ é™¤ç¬¬mè¡Œ<br>nd åˆ é™¤å½“å‰è¡Œå¼€å§‹çš„nè¡Œ(ä¸€å…±n+1è¡Œ)<br>dd åˆ é™¤å½“å‰è¡Œ<br>D åˆ é™¤å½“å‰å­—ç¬¦è‡³è¡Œå°¾<br>:m,nd åˆ é™¤ä»måˆ°nè¡Œçš„å†…å®¹ï¼Œå¦‚: <code>:100,10000d</code><br>:m,$d åˆ é™¤mè¡ŒåŠä»¥åæ‰€æœ‰çš„è¡Œ<br>:10d</p>
<h3 id="ç§»åŠ¨"><a href="#ç§»åŠ¨" class="headerlink" title="ç§»åŠ¨"></a>ç§»åŠ¨</h3><p>:n è·³è½¬åˆ°è¡Œå·  å¦‚ï¼Œ :100<br>gg è·³åˆ°è¡Œé¦–<br>G(shift+g)ç§»åŠ¨åˆ°æ–‡ä»¶å°¾</p>
<h3 id="æœç´¢"><a href="#æœç´¢" class="headerlink" title="æœç´¢"></a>æœç´¢</h3><p>/text æœç´¢textï¼Œnæœç´¢ä¸‹ä¸€ä¸ªï¼ŒNæœç´¢ä¸Šä¸€ä¸ª<br>?text åå‘æŸ¥æ‰¾<br>:set ignorecase å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>:set noignorecase ä¸å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>*æˆ–# å¯¹å…‰æ ‡å¤„çš„å•è¯æœç´¢</p>
<h3 id="å¤åˆ¶ç²˜è´´"><a href="#å¤åˆ¶ç²˜è´´" class="headerlink" title="å¤åˆ¶ç²˜è´´"></a>å¤åˆ¶ç²˜è´´</h3><p>v ä»å½“å‰ä½ç½®å¼€å§‹ï¼Œå…‰æ ‡ç»è¿‡çš„åœ°æ–¹è¢«é€‰ä¸­ï¼Œå†æŒ‰ä¸€ä¸‹vç»“æŸ</p>
<h3 id="ç¯å¢ƒè®¾ç½®"><a href="#ç¯å¢ƒè®¾ç½®" class="headerlink" title="ç¯å¢ƒè®¾ç½®"></a>ç¯å¢ƒè®¾ç½®</h3><p>:set nu æ˜¾ç¤ºè¡Œå·<br>:set nonu éšè—è¡Œå·<br>:set hlsearch è®¾ç½®æœç´¢ç»“æœé«˜äº®</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/wangrx/p/5907013.html" target="_blank" rel="noopener">https://www.cnblogs.com/wangrx/p/5907013.html</a><br><a href="https://www.cnblogs.com/yangjig/p/6014198.html" target="_blank" rel="noopener">https://www.cnblogs.com/yangjig/p/6014198.html</a></p>
]]></content>
      <tags>
        <tag>æŠ€å·§</tag>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>å¿«æ·é”®</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Pycharmå¸¸ç”¨æŠ€å·§</title>
    <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Pycharm%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>è®°å½•Pycharmçš„ä¸€äº›æŠ€å·§ï¼Œè®©Pycharmæ›´é¡ºæ‰‹</p>
<h3 id="å¿«æ·é”®"><a href="#å¿«æ·é”®" class="headerlink" title="å¿«æ·é”®"></a>å¿«æ·é”®</h3><p>0ï¸âƒ£Double Shift ä¸‡èƒ½æœç´¢<br>å¯ä»¥æœç´¢<strong>æ–‡ä»¶åã€ç±»åã€æ–¹æ³•åã€ç›®å½•å</strong>ï¼ˆåœ¨å…³é”®å­—å‰é¢åŠ / ï¼‰ï¼Œå¹¶ä¸èƒ½ç”¨æ¥æœç´¢ä»»æ„å…³é”®å­—</p>
<p>1ï¸âƒ£ Command+F åœ¨é¡µé¢æœç´¢</p>
<p>2ï¸âƒ£ Ctrl+Shift+F Find in Path åœ¨è·¯å¾„ä¸‹æœç´¢</p>
<p>3ï¸âƒ£âœ¨Command+E å¿«é€ŸæŸ¥æ‰¾æ–‡ä»¶<br>æ˜¾ç¤ºæœ€è¿‘æ‰“å¼€çš„æ–‡ä»¶</p>
<p>4ï¸âƒ£ Shift+Enter ä»»æ„ä½ç½®æ¢è¡Œ<br>æ— è®ºå…‰æ ‡åœ¨ä½•å¤„éƒ½å¯ä»¥ç›´æ¥å¦èµ·ä¸€è¡Œ</p>
<p>5ï¸âƒ£ Option+Enter è‡ªåŠ¨å¯¼å…¥æ¨¡å—ï¼›ä¸‡èƒ½æç¤ºé”®<br>è‡ªåŠ¨å¯¼å…¥å¦‚ä½•è®¾ç½®è§å°æŠ€å·§#0ï¸âƒ£</p>
<p>6ï¸âƒ£ Ctrl+F10 è¿è¡Œ<br>æˆ‘å·²ç»æ·»åŠ äº†Ctrl+Rä½œä¸ºå¦ä¸€å¯¹è¿è¡Œå¿«æ·é”®</p>
<p>7ï¸âƒ£ Command+Shift+ +/-  å±•å¼€/æ”¶ç¼©ä»£ç  </p>
<p>8ï¸âƒ£ Option+F åœ¨Dashä¸­æœç´¢</p>
<p>9ï¸âƒ£ Ctrl+J ä¸è·³è½¬æŸ¥çœ‹ä»£ç </p>
<h3 id="å°æŠ€å·§"><a href="#å°æŠ€å·§" class="headerlink" title="å°æŠ€å·§"></a>å°æŠ€å·§</h3><p>0ï¸âƒ£ Pycharmè‡ªåŠ¨å¯¼å…¥æ¨¡å—<br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a></p>
<p>1ï¸âƒ£ âœ¨è¿œç¨‹éƒ¨ç½²å·¥ç¨‹ å¼ºçƒˆæ¨è<br>ä¸¤æ­¥èµ°ï¼šé…ç½®æœåŠ¡å™¨æ˜ å°„+é…ç½®æœåŠ¡å™¨è§£é‡Šå™¨</p>
<p>2ï¸âƒ£è·³è½¬åå¦‚ä½•å›é€€<br>å¼€å¯toolbarå³å¯<br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://foofish.net/pycharm-tips.html" target="_blank" rel="noopener">https://foofish.net/pycharm-tips.html</a><br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a><br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p>
]]></content>
      <tags>
        <tag>æŠ€å·§</tag>
        <tag>Pycharm</tag>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>å¿«æ·é”®</tag>
      </tags>
  </entry>
  <entry>
    <title>æ— é¢˜</title>
    <url>/2018/08/06/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E9%A2%98/</url>
    <content><![CDATA[<p>äººè¿™è¾ˆå­ä¸€å…±ä¼šæ­»ä¸‰æ¬¡ã€‚</p>
<p>ç¬¬ä¸€æ¬¡æ˜¯ä½ çš„å¿ƒè„åœæ­¢è·³åŠ¨ï¼Œé‚£ä¹ˆä»ç”Ÿç‰©çš„è§’åº¦æ¥è¯´ï¼Œä½ æ­»äº†ï¼›</p>
<p>ç¬¬äºŒæ¬¡æ˜¯åœ¨è‘¬ç¤¼ä¸Šï¼Œè®¤è¯†ä½ çš„äººéƒ½æ¥ç¥­å¥ ï¼Œé‚£ä¹ˆä½ åœ¨ç¤¾ä¼šå…³ç³»ä¸Šçš„äº‹å®å­˜åœ¨å°±æ­»äº†ï¼›</p>
<p>ç¬¬ä¸‰æ¬¡æ˜¯åœ¨æœ€åä¸€ä¸ªè®°å¾—ä½ çš„äººæ­»åï¼Œé‚£ä½ å°±çœŸçš„æ­»äº†ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>äººå¯ä»¥å‘å¾®å¦‚å°˜åœŸ,ä¸å¯æ‰­æ›²å¦‚è›†è™«</title>
    <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E5%8F%AF%E4%BB%A5%E5%8D%91%E5%BE%AE%E5%A6%82%E5%B0%98%E5%9C%9F,%E4%B8%8D%E5%8F%AF%E6%89%AD%E6%9B%B2%E5%A6%82%E8%9B%86%E8%99%AB/</url>
    <content><![CDATA[<p>å¦‚æœå¤©æ€»ä¹Ÿä¸äº®ï¼Œé‚£å°±æ‘¸é»‘è¿‡ç”Ÿæ´»; </p>
<p>å¦‚æœå‘å‡ºå£°éŸ³æ˜¯å±é™©çš„ï¼Œé‚£å°±ä¿æŒæ²‰é»˜; </p>
<p>å¦‚æœè‡ªè§‰æ— åŠ›å‘å…‰ï¼Œé‚£å°±åˆ«å»ç…§äº®åˆ«äººã€‚ </p>
<p>ä½†æ˜¯â€”â€”ä¸è¦ä¹ æƒ¯äº†é»‘æš—å°±ä¸ºé»‘æš—è¾©æŠ¤; </p>
<p>ä¸è¦ä¸ºè‡ªå·±çš„è‹Ÿä¸”è€Œå¾—æ„æ´‹æ´‹; </p>
<p>ä¸è¦å˜²è®½é‚£äº›æ¯”è‡ªå·±æ›´å‹‡æ•¢ã€æ›´æœ‰çƒ­é‡çš„äººä»¬ã€‚ </p>
<p><strong>å¯ä»¥å‘å¾®å¦‚å°˜åœŸï¼Œä¸å¯æ‰­æ›²å¦‚è›†è™«</strong>ã€‚</p>
]]></content>
      <tags>
        <tag>ä½³å¥åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>Pythonæƒ¯ä¾‹[è½¬]</title>
    <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E6%83%AF%E4%BE%8B/</url>
    <content><![CDATA[<p>fork from <a href="https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md" target="_blank" rel="noopener">https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md</a></p>
<h2 id="Pythonæƒ¯ä¾‹"><a href="#Pythonæƒ¯ä¾‹" class="headerlink" title="Pythonæƒ¯ä¾‹"></a>Pythonæƒ¯ä¾‹</h2><p>â€œæƒ¯ä¾‹â€è¿™ä¸ªè¯æŒ‡çš„æ˜¯â€œä¹ æƒ¯çš„åšæ³•ï¼Œå¸¸è§„çš„åŠæ³•ï¼Œä¸€è´¯çš„åšæ³•â€ï¼Œä¸è¿™ä¸ªè¯å¯¹åº”çš„è‹±æ–‡å•è¯å«â€œidiomâ€ã€‚ç”±äºPythonè·Ÿå…¶ä»–å¾ˆå¤šç¼–ç¨‹è¯­è¨€åœ¨è¯­æ³•å’Œä½¿ç”¨ä¸Šè¿˜æ˜¯æœ‰æ¯”è¾ƒæ˜¾è‘—çš„å·®åˆ«ï¼Œå› æ­¤ä½œä¸ºä¸€ä¸ªPythonå¼€å‘è€…å¦‚æœä¸èƒ½æŒæ¡è¿™äº›æƒ¯ä¾‹ï¼Œå°±æ— æ³•å†™å‡ºâ€œPythonicâ€çš„ä»£ç ã€‚ä¸‹é¢æˆ‘ä»¬æ€»ç»“äº†ä¸€äº›åœ¨Pythonå¼€å‘ä¸­çš„æƒ¯ç”¨çš„ä»£ç ã€‚</p>
<ol>
<li><p>è®©ä»£ç æ—¢å¯ä»¥è¢«å¯¼å…¥åˆå¯ä»¥è¢«æ‰§è¡Œã€‚ </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br></pre></td></tr></table></figure>
</li>
<li><p>ç”¨ä¸‹é¢çš„æ–¹å¼åˆ¤æ–­é€»è¾‘â€œçœŸâ€æˆ–â€œå‡â€ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x:</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> x:</span><br></pre></td></tr></table></figure>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name <span class="keyword">and</span> fruits <span class="keyword">and</span> owners:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name != <span class="string">''</span> <span class="keyword">and</span> len(fruits) &gt; <span class="number">0</span> <span class="keyword">and</span> owners != &#123;&#125;:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>å–„äºä½¿ç”¨inè¿ç®—ç¬¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x <span class="keyword">in</span> items: <span class="comment"># åŒ…å«</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> items: <span class="comment"># è¿­ä»£</span></span><br></pre></td></tr></table></figure>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'L'</span> <span class="keyword">in</span> name:</span><br><span class="line">    print(<span class="string">'The name has an L in it.'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> name.find(<span class="string">'L'</span>) != <span class="number">-1</span>:</span><br><span class="line">    print(<span class="string">'This name has an L in it!'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>ä¸ä½¿ç”¨ä¸´æ—¶å˜é‡äº¤æ¢ä¸¤ä¸ªå€¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>ç”¨åºåˆ—æ„å»ºå­—ç¬¦ä¸²</strong>ã€‚</p>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span>.join(chars)</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> char <span class="keyword">in</span> chars:</span><br><span class="line">    name += char</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>EAFPä¼˜äºLBYL</strong>ã€‚</p>
<p>EAFP - <strong>E</strong>asier to <strong>A</strong>sk <strong>F</strong>orgiveness than <strong>P</strong>ermission.</p>
<p>LBYL - <strong>L</strong>ook <strong>B</strong>efore <strong>Y</strong>ou <strong>L</strong>eap.</p>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">except</span> (KeyError, TypeError, ValueError):</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> <span class="string">'x'</span> <span class="keyword">in</span> d <span class="keyword">and</span> isinstance(d[<span class="string">'x'</span>], str) \</span><br><span class="line">		<span class="keyword">and</span> d[<span class="string">'x'</span>].isdigit():</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ä½¿ç”¨enumerateè¿›è¡Œè¿­ä»£ã€‚</p>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line"><span class="keyword">for</span> index, fruit <span class="keyword">in</span> enumerate(fruits):</span><br><span class="line">	print(index, <span class="string">':'</span>, fruit)</span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fruit <span class="keyword">in</span> fruits:</span><br><span class="line">    print(index, <span class="string">':'</span>, fruit)</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ç”¨ç”Ÿæˆå¼ç”Ÿæˆåˆ—è¡¨ã€‚</p>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = [num * <span class="number">3</span> <span class="keyword">for</span> num <span class="keyword">in</span> data <span class="keyword">if</span> num &gt; <span class="number">10</span>]</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">        result.append(i * <span class="number">3</span>)</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ç”¨zipç»„åˆé”®å’Œå€¼æ¥åˆ›å»ºå­—å…¸ã€‚</p>
<p><strong>å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = dict(zip(keys, values))</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure>
<p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i, key <span class="keyword">in</span> enumerate(keys):</span><br><span class="line">    d[key] = values[i]</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p><strong>è¯´æ˜</strong>ï¼šè¿™ç¯‡æ–‡ç« çš„å†…å®¹æ¥è‡ªäºç½‘ç»œï¼Œæœ‰å…´è¶£çš„è¯»è€…å¯ä»¥é˜…è¯»<a href="http://safehammad.com/downloads/python-idioms-2014-01-16.pdf" target="_blank" rel="noopener">åŸæ–‡</a>ã€‚</p>
</blockquote>
<p>æ³¨ï¼š<br>è®¸å¤šåŸåˆ™æˆ‘è®¤ä¸ºéå¸¸æœ‰æ„ä¹‰ï¼Œèƒ½å¤Ÿæ‘†è„±C/C++çš„é£æ ¼ï¼ŒçœŸæ­£å†™å‡ºPythonicçš„ä»£ç ã€‚è®©æˆ‘æœ‰å¾ˆå¤§æ„Ÿè§¦çš„æ˜¯1ã€3ã€8ï¼Œèƒ½å¤Ÿå†™å‡ºéå¸¸ç®€æ´ä¼˜é›…çš„ä»£ç ã€‚åŒæ—¶6æˆ‘ä¹‹å‰ä»æ²¡æ³¨æ„è¿‡ï¼Œä¹ æƒ¯äº†C/C++é£æ ¼ä¹‹åæ€»æ˜¯ä¼šåœ¨æ‰§è¡Œä¹‹å‰è€ƒè™‘æ‰€æœ‰æƒ…å†µï¼Œä½†ç¡®å®ä¸å¤Ÿä¼˜é›…ï¼Œä»Šåå¯ä»¥å°è¯•EAFPé£æ ¼ï¼ˆ<a href="https://stackoverflow.com/questions/11360858/what-is-the-eafp-principle-in-python" target="_blank" rel="noopener">ä»€ä¹ˆæ˜¯EAFP</a>ï¼‰ã€‚</p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>å¦‚ä½•è®­ç»ƒGloVeä¸­æ–‡è¯å‘é‡</title>
    <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83GloVe%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F/</url>
    <content><![CDATA[<h3 id="å‡†å¤‡è¯­æ–™"><a href="#å‡†å¤‡è¯­æ–™" class="headerlink" title="å‡†å¤‡è¯­æ–™"></a>å‡†å¤‡è¯­æ–™</h3><p>å‡†å¤‡å¥½è‡ªå·±çš„è¯­æ–™ï¼Œä¿å­˜ä¸ºtxtï¼Œæ¯è¡Œä¸€ä¸ªå¥å­æˆ–ä¸€æ®µè¯ï¼Œæ³¨æ„è¦åˆ†å¥½è¯ã€‚</p>
<p><img src="/images/2018-08-05-15334388069130.jpg" width="60%" height="60%"></p>
<h3 id="å‡†å¤‡æºç "><a href="#å‡†å¤‡æºç " class="headerlink" title="å‡†å¤‡æºç "></a>å‡†å¤‡æºç </h3><p>ä»GitHubä¸‹è½½ä»£ç ï¼Œ<a href="https://github.com/stanfordnlp/GloVe" target="_blank" rel="noopener">https://github.com/stanfordnlp/GloVe</a><br>å°†è¯­æ–™corpus.txtæ”¾å…¥åˆ°Gloveçš„ä¸»æ–‡ä»¶å¤¹ä¸‹ã€‚</p>
<h3 id="ä¿®æ”¹bash"><a href="#ä¿®æ”¹bash" class="headerlink" title="ä¿®æ”¹bash"></a>ä¿®æ”¹bash</h3><p>æ‰“å¼€demo.shï¼Œä¿®æ”¹ç›¸åº”çš„å†…å®¹</p>
<ol>
<li>å› ä¸ºdemoé»˜è®¤æ˜¯ä¸‹è½½ç½‘ä¸Šçš„è¯­æ–™æ¥è®­ç»ƒçš„ï¼Œå› æ­¤å¦‚æœè¦è®­ç»ƒè‡ªå·±çš„è¯­æ–™ï¼Œéœ€è¦æ³¨é‡Šæ‰</li>
</ol>
<p><img src="/images/2018-08-05-15334390298383.jpg" width="70%" height="50%"></p>
<ol>
<li>ä¿®æ”¹å‚æ•°è®¾ç½®ï¼Œå°†CORPUSè®¾ç½®æˆè¯­æ–™çš„åå­—</li>
</ol>
<p><img src="/images/2018-08-05-15334391029224.jpg" width="50%" height="50%"></p>
<h3 id="æ‰§è¡Œbashæ–‡ä»¶"><a href="#æ‰§è¡Œbashæ–‡ä»¶" class="headerlink" title="æ‰§è¡Œbashæ–‡ä»¶"></a>æ‰§è¡Œbashæ–‡ä»¶</h3><p>è¿›å…¥åˆ°ä¸»æ–‡ä»¶å¤¹ä¸‹</p>
<ol>
<li>make</li>
</ol>
<p><img src="/images/2018-08-05-15334392348665.jpg" width="70%" height="50%"></p>
<ol>
<li>bash demo.sh</li>
</ol>
<p><img src="/images/2018-08-05-15334392595148.jpg" width="70%" height="70%"></p>
<p>æ³¨æ„ï¼Œå¦‚æœè®­ç»ƒæ•°æ®è¾ƒå¤§ï¼Œåˆ™è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œé‚£ä¹ˆå»ºè®®ä½¿ç”¨nohupæ¥è¿è¡Œç¨‹åº</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup bash demo.sh &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p>åç­‰è®­ç»ƒï¼Œæœ€åä¼šå¾—åˆ°vectors.txt ä»¥åŠå…¶ä»–çš„ç›¸åº”çš„æ–‡ä»¶ã€‚å¦‚æœè¦ç”¨gensimçš„word2vec loadè¿›æ¥ï¼Œé‚£ä¹ˆéœ€è¦åœ¨vectors.txtçš„ç¬¬ä¸€è¡ŒåŠ ä¸Švacob_size vector_sizeï¼Œç¬¬ä¸€ä¸ªæ•°æŒ‡æ˜ä¸€å…±æœ‰å¤šå°‘ä¸ªå‘é‡ï¼Œç¬¬äºŒä¸ªæ•°æŒ‡æ˜æ¯ä¸ªå‘é‡æœ‰å¤šå°‘ç»´ã€‚</p>
<h3 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h3><p><a href="https://www.cnblogs.com/echo-cheng/p/8561171.html" target="_blank" rel="noopener">https://www.cnblogs.com/echo-cheng/p/8561171.html</a></p>
]]></content>
      <tags>
        <tag>GloVe</tag>
        <tag>æ•™ç¨‹</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†2</title>
    <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%862/</url>
    <content><![CDATA[<p>1ï¸âƒ£[Pytorch]<br>é¿å…å†™å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Variable(torch.zeros(...), requires_grad=<span class="keyword">True</span>).cuda()</span><br></pre></td></tr></table></figure>
<p>è€Œæ˜¯åº”è¯¥è¦ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = Variable(torch.zeros(...).cuda(), requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>Reference:<br><a href="https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187" target="_blank" rel="noopener">https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187</a></p>
<hr>
<p>2ï¸âƒ£[Tf-idf]<br>æœ¬å‘¨å› ä¸ºæ¯”èµ›çš„åŸå› äº†è§£äº†ä¸€ä¸‹å„ç§æ–‡æœ¬å»ºæ¨¡çš„æ–¹æ³•ã€‚Tf-idfèƒ½å¤Ÿå–å¾—ä¸é”™çš„æˆç»©ï¼Œä½†æœ‰ä¸€å®šçš„ç¼ºé™·ã€‚</p>
<blockquote>
<p>TF-IDFç”¨äºå‘é‡ç©ºé—´æ¨¡å‹ï¼Œè¿›è¡Œæ–‡æ¡£ç›¸ä¼¼åº¦è®¡ç®—æ˜¯ç›¸å½“æœ‰æ•ˆçš„ã€‚ä½†åœ¨æ–‡æœ¬åˆ†ç±»ä¸­å•çº¯ä½¿ç”¨TF-IDFæ¥åˆ¤æ–­ä¸€ä¸ªç‰¹å¾æ˜¯å¦æœ‰åŒºåˆ†åº¦æ˜¯ä¸å¤Ÿçš„ã€‚</p>
<ol>
<li>å®ƒä»…ä»…ç»¼åˆè€ƒè™‘äº†è¯¥è¯åœ¨æ–‡æ¡£ä¸­çš„é‡è¦ç¨‹åº¦å’Œæ–‡æ¡£åŒºåˆ†åº¦ã€‚</li>
<li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»é—´çš„åˆ†å¸ƒã€‚ç‰¹å¾é€‰æ‹©æ‰€é€‰æ‹©çš„ç‰¹å¾åº”è¯¥åœ¨æŸç±»å‡ºç°å¤šï¼Œè€Œå…¶å®ƒç±»å‡ºç°å°‘ï¼Œå³è€ƒå¯Ÿå„ç±»çš„æ–‡æ¡£é¢‘ç‡çš„å·®å¼‚ã€‚å¦‚æœä¸€ä¸ªç‰¹å¾è¯ï¼Œåœ¨å„ä¸ªç±»é—´åˆ†å¸ƒæ¯”è¾ƒå‡åŒ€ï¼Œè¿™æ ·çš„è¯å¯¹åˆ†ç±»åŸºæœ¬æ²¡æœ‰è´¡çŒ®ï¼›ä½†æ˜¯å¦‚æœä¸€ä¸ªç‰¹å¾è¯æ¯”è¾ƒé›†ä¸­çš„åˆ†å¸ƒåœ¨æŸä¸ªç±»ä¸­ï¼Œè€Œåœ¨å…¶å®ƒç±»ä¸­å‡ ä¹ä¸å‡ºç°ï¼Œè¿™æ ·çš„è¯å´èƒ½å¤Ÿå¾ˆå¥½ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œè€ŒTF-IDFä¸èƒ½åŒºåˆ†è¿™ä¸¤ç§æƒ…å†µã€‚</li>
<li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»å†…éƒ¨æ–‡æ¡£ä¸­çš„åˆ†å¸ƒæƒ…å†µã€‚åœ¨ç±»å†…éƒ¨çš„æ–‡æ¡£ä¸­ï¼Œå¦‚æœç‰¹å¾è¯å‡åŒ€åˆ†å¸ƒåœ¨å…¶ä¸­ï¼Œåˆ™è¿™ä¸ªç‰¹å¾è¯èƒ½å¤Ÿå¾ˆå¥½çš„ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œå¦‚æœåªåœ¨å‡ ç¯‡æ–‡æ¡£ä¸­å‡ºç°ï¼Œè€Œåœ¨æ­¤ç±»çš„å…¶å®ƒæ–‡æ¡£ä¸­ä¸å‡ºç°ï¼Œæ˜¾ç„¶è¿™æ ·çš„ç‰¹å¾è¯ä¸èƒ½å¤Ÿä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ã€‚</li>
</ol>
</blockquote>
<p>Reference:<br><a href="https://blog.csdn.net/mmc2015/article/details/46771791" target="_blank" rel="noopener">https://blog.csdn.net/mmc2015/article/details/46771791</a></p>
<hr>
<p>3ï¸âƒ£[å¡æ–¹æ£€éªŒCHI]<br>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œç”¨äºé€‰æ‹©æœ€ç›¸å…³çš„ç‰¹å¾ã€‚</p>
<p>Reference:<br><a href="https://blog.csdn.net/blockheadls/article/details/49977361" target="_blank" rel="noopener">https://blog.csdn.net/blockheadls/article/details/49977361</a></p>
<hr>
<p>4ï¸âƒ£[æ–‡æœ¬åˆ†ç±»]<br>å„ç§æ–‡æœ¬åˆ†ç±»æ–¹æ³•çš„ç®€å•ä»‹ç»ã€‚</p>
<p>Reference:<br><a href="https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md" target="_blank" rel="noopener">https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md</a></p>
<hr>
<p>5ï¸âƒ£[Python]<br>collectionsçš„ä¸¤ä¸ªæœ‰ç”¨çš„ç±»</p>
<ol>
<li>named_tupleï¼šå¿«é€Ÿå»ºç«‹ä¸€ä¸ªç±»ï¼Œä½¿å¾—å¯ä»¥ä½¿ç”¨å±æ€§æ¥è®¿é—®è€Œéç´¢å¼•ï¼Œæé«˜äº†ä»£ç å¯è¯»æ€§</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line">Point = namedtuple(<span class="string">'Point'</span>,[<span class="string">'x'</span>,<span class="string">'y'</span>])</span><br><span class="line">p = Point(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">print(p.x)  <span class="comment"># 1</span></span><br><span class="line">print(p.y)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure>
<ol>
<li>Counterï¼šç»Ÿè®¡å­—ç¬¦å‡ºç°çš„æ¬¡æ•°</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">count = Counter([...]).most_commom()  <span class="comment">#ä¼šæŒ‰ç…§å‡ºç°çš„æ¬¡æ•°æ’åºï¼Œé€šå¸¸å¯ç”¨äºæ„å»ºè¯å…¸</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> count:     <span class="comment"># cæ˜¯ä¸€ä¸ªtupleï¼Œc[0]æ˜¯è¯ï¼Œc[1]æ˜¯é¢‘ç‡</span></span><br><span class="line">    <span class="keyword">if</span> c[<span class="number">1</span>]&gt;= threshold:</span><br><span class="line">        vocab.add_word(c[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Counterç”¨æ³•ï¼š<br><a href="https://blog.csdn.net/u014755493/article/details/69812244" target="_blank" rel="noopener">https://blog.csdn.net/u014755493/article/details/69812244</a></p>
<hr>
<p>6ï¸âƒ£[nohup]<br>æœ¬å‘¨åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç çš„æ—¶å€™é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨nohupæ‰§è¡Œpythonç¨‹åºæ—¶ï¼Œå‘ç°è¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ˜¾ç¤ºã€‚ä»¥ä¸ºæ˜¯ä»£ç çš„é—®é¢˜ï¼Œä½†ç»è¿‡æ’æŸ¥å¹¶éæ˜¯ä»£ç çš„é—®é¢˜ã€‚é€šè¿‡æŸ¥é˜…èµ„æ–™ï¼Œå‘ç°é—®é¢˜æ‰€åœ¨ï¼š<br>å› ä¸ºpythonè¾“å‡ºæœ‰ç¼“å†²ï¼Œå¯¼è‡´outputä¸èƒ½<strong>é©¬ä¸Š</strong>çœ‹åˆ°è¾“å‡ºã€‚å®é™…ä¸Šï¼Œåœ¨ç­‰å¾…äº†ä¸€æ®µæ—¶é—´åï¼Œè¾“å‡ºæ–‡ä»¶ç»ˆäºæ˜¾ç¤ºå‡ºæ¥äº†ã€‚</p>
<p>è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨pythonçš„å‚æ•° -u ä½¿å¾—pythonä¸å¯ç”¨ç¼“å†²ã€‚</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<p>Reference:<br><a href="https://blog.csdn.net/sunlylorn/article/details/19127107" target="_blank" rel="noopener">https://blog.csdn.net/sunlylorn/article/details/19127107</a></p>
<hr>
<p>7ï¸âƒ£[hexoé…ç½®]</p>
<ol>
<li>mathjaxé…ç½®: <a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">https://www.jianshu.com/p/7ab21c7f0674</a></li>
<li>é…ç½®åŸŸå:<a href="https://www.zhihu.com/question/31377141" target="_blank" rel="noopener">https://www.zhihu.com/question/31377141</a></li>
<li>é…ç½®sitemap:<a href="http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/" target="_blank" rel="noopener">http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/</a></li>
</ol>
<hr>
<p>8ï¸âƒ£[Paper]<br><a href="http://aclweb.org/anthology/D17-1025" target="_blank" rel="noopener">Learning Chinese Word Representations From Glyphs Of Characters</a></p>
<p>ä½¿ç”¨å›¾åƒçš„å·ç§¯æ¥ç”Ÿæˆè¯å‘é‡:<br><img src="/images/2018-08-05-15334453515509.jpg" width="60%" height="50%"></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>hexo</tag>
        <tag>Pytorch</tag>
        <tag>Paper</tag>
        <tag>Tf-idf</tag>
        <tag>æ–‡æœ¬åˆ†ç±»</tag>
        <tag>nohup</tag>
        <tag>CHI</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•3</title>
    <url>/2018/08/05/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB3/</url>
    <content><![CDATA[<p>æœ¬å‘¨åªæœ‰ç®€å•çš„ä»£ç ã€‚</p>
<h3 id="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"><a href="#1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec" class="headerlink" title="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"></a>1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line">sentences=word2vec.Text8Corpus(<span class="string">u'åˆ†è¯åçš„çˆ½è‚¤æ°´è¯„è®º.txt'</span>)   <span class="comment">#sentence:[ [ a b ],[c d]... ]</span></span><br><span class="line">model=word2vec.Word2Vec(sentences, size=<span class="number">50</span>)  <span class="comment">#size:dim </span></span><br><span class="line"></span><br><span class="line">y2=model.similarity(<span class="string">u"å¥½"</span>, <span class="string">u"è¿˜è¡Œ"</span>)  <span class="comment">#è®¡ç®—ç›¸ä¼¼åº¦</span></span><br><span class="line">print(y2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> model.most_similar(<span class="string">u"æ»‹æ¶¦"</span>):</span><br><span class="line">    <span class="keyword">print</span> i[<span class="number">0</span>],i[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment">#ä¿å­˜</span></span><br><span class="line">model.save(<span class="string">'/model/word2vec_model'</span>)</span><br><span class="line"></span><br><span class="line">new_model=gensim.models.Word2Vec.load(<span class="string">'/model/word2vec_model'</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"><a href="#2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"></a>2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dict</span><span class="params">(dataset,min_freq=<span class="number">5</span>)</span>:</span></span><br><span class="line">    dictionary=Dictionary() </span><br><span class="line">    count=Counter(flat(dataset)).most_common()  </span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> count:</span><br><span class="line">        <span class="keyword">if</span> c[<span class="number">1</span>]&gt;=min_freq:</span><br><span class="line">            dictionary.add_word(c[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> dictionary</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯3</title>
    <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D3/</url>
    <content><![CDATA[<p>æœ¬å‘¨èƒŒçš„éƒ½æ˜¯æ¯”è¾ƒç®€å•çš„ã€‚</p>
<p>1ï¸âƒ£</p>
<h3 id="æŠŠé…’é—®æœˆ"><a href="#æŠŠé…’é—®æœˆ" class="headerlink" title="æŠŠé…’é—®æœˆ"></a>æŠŠé…’é—®æœˆ</h3><p>[å”] æç™½<br>é’å¤©æœ‰æœˆæ¥å‡ æ—¶ï¼Ÿæˆ‘ä»Šåœæ¯ä¸€é—®ä¹‹ã€‚<br>äººæ”€æ˜æœˆä¸å¯å¾—ï¼Œæœˆè¡Œå´ä¸äººç›¸éšã€‚<br>çšå¦‚é£é•œä¸´ä¸¹é˜™ï¼Œç»¿çƒŸç­å°½æ¸…è¾‰å‘ã€‚<br>ä½†è§å®µä»æµ·ä¸Šæ¥ï¼Œå®çŸ¥æ™“å‘äº‘é—´æ²¡ã€‚<br>ç™½å…”æ£è¯ç§‹å¤æ˜¥ï¼Œå«¦å¨¥å­¤æ –ä¸è°é‚»ï¼Ÿ<br><strong>ä»Šäººä¸è§å¤æ—¶æœˆï¼Œä»Šæœˆæ›¾ç»ç…§å¤äººã€‚<br>å¤äººä»Šäººè‹¥æµæ°´ï¼Œå…±çœ‹æ˜æœˆçš†å¦‚æ­¤ã€‚</strong><br><strong>å”¯æ„¿å½“æ­Œå¯¹é…’æ—¶ï¼Œæœˆå…‰é•¿ç…§é‡‘æ¨½é‡Œã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13</a></p>
<hr>
<p>2ï¸âƒ£</p>
<h3 id="é‡‘ç¼•è¡£"><a href="#é‡‘ç¼•è¡£" class="headerlink" title="é‡‘ç¼•è¡£"></a>é‡‘ç¼•è¡£</h3><p>[å”] æœç§‹å¨˜<br>åŠå›è«æƒœé‡‘ç¼•è¡£ï¼ŒåŠå›æƒœå–å°‘å¹´æ—¶ã€‚<br><strong>èŠ±å¼€å ªæŠ˜ç›´é¡»æŠ˜ï¼Œè«å¾…æ— èŠ±ç©ºæŠ˜æã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e</a></p>
<hr>
<p>3ï¸âƒ£</p>
<h3 id="åŒ—é’è"><a href="#åŒ—é’è" class="headerlink" title="åŒ—é’è"></a>åŒ—é’è</h3><p>[å”] æå•†éš<br>æ®‹é˜³è¥¿å…¥å´¦ï¼ŒèŒ…å±‹è®¿å­¤åƒ§ã€‚<br>è½å¶äººä½•åœ¨ï¼Œå¯’äº‘è·¯å‡ å±‚ã€‚<br>ç‹¬æ•²åˆå¤œç£¬ï¼Œé—²å€šä¸€æè—¤ã€‚<br><strong>ä¸–ç•Œå¾®å°˜é‡Œï¼Œå¾å®çˆ±ä¸æ†ã€‚</strong></p>
<p>å´¦ï¼ˆyÄnï¼‰ï¼šå³â€œå´¦åµ«ï¼ˆzÄ«ï¼‰â€ï¼Œå±±åï¼Œåœ¨ç”˜è‚ƒã€‚å¤æ—¶å¸¸ç”¨æ¥æŒ‡å¤ªé˜³è½å±±çš„åœ°æ–¹ã€‚<br><strong>ç£¬ï¼ˆqÃ¬ngï¼‰</strong>ï¼šå¤ä»£æ‰“å‡»ä¹å™¨ï¼Œå½¢çŠ¶åƒæ›²å°ºï¼Œç”¨ç‰ã€çŸ³åˆ¶æˆï¼Œå¯æ‚¬æŒ‚ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e</a></p>
<hr>
<p>4ï¸âƒ£</p>
<h3 id="å¤æ—¥ç»å¥"><a href="#å¤æ—¥ç»å¥" class="headerlink" title="å¤æ—¥ç»å¥"></a>å¤æ—¥ç»å¥</h3><p>[å®‹] ææ¸…ç…§<br>ç”Ÿå½“ä½œäººæ°ï¼Œæ­»äº¦ä¸ºé¬¼é›„ã€‚<br><strong>è‡³ä»Šæ€é¡¹ç¾½ï¼Œä¸è‚¯è¿‡æ±Ÿä¸œã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e</a></p>
<hr>
<p>5ï¸âƒ£</p>
<h3 id="é›¨éœ–é“ƒ"><a href="#é›¨éœ–é“ƒ" class="headerlink" title="é›¨éœ–é“ƒ"></a>é›¨éœ–é“ƒ</h3><p>[å®‹] æŸ³æ°¸<br>å¯’è‰å‡„åˆ‡ï¼Œå¯¹é•¿äº­æ™šï¼Œéª¤é›¨åˆæ­‡ã€‚éƒ½é—¨å¸é¥®æ— ç»ªï¼Œç•™æ‹å¤„ï¼Œå…°èˆŸå‚¬å‘ã€‚æ‰§æ‰‹ç›¸çœ‹æ³ªçœ¼ï¼Œç«Ÿæ— è¯­å‡å™ã€‚å¿µå»å»ï¼Œåƒé‡ŒçƒŸæ³¢ï¼Œæš®éœ­æ²‰æ²‰æ¥šå¤©é˜”ã€‚<br><strong>å¤šæƒ…è‡ªå¤ä¼¤ç¦»åˆ«</strong>ï¼Œæ›´é‚£å ªã€å†·è½æ¸…ç§‹èŠ‚ã€‚ä»Šå®µé…’é†’ä½•å¤„ï¼Ÿæ¨æŸ³å²¸ï¼Œæ™“é£æ®‹æœˆã€‚æ­¤å»ç»å¹´ï¼Œåº”æ˜¯è‰¯è¾°å¥½æ™¯è™šè®¾ã€‚<strong>ä¾¿çºµæœ‰åƒç§é£æƒ…ï¼Œæ›´ä¸ä½•äººè¯´</strong>ï¼Ÿ</p>
<p><a href="http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºPytorchä¸­gradçš„ç†è§£</title>
    <url>/2018/08/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADgrad%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>äº‹æƒ…èµ·æºäºæˆ‘å†™äº†ä¸€ä¸ªCNNç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œä½†lossä¸€ç›´æ²¡é™ï¼Œå› æ­¤æˆ‘å°è¯•<code>print(loss.grad)</code>çš„gradï¼Œå‘ç°ç¥å¥‡çš„æ˜¯loss gradæ˜¾ç¤ºä¸ºNoneï¼Œæ¥ç€å°è¯•<code>print(y_pred.grad)</code>ï¼ŒåŒæ ·æ˜¯Noneï¼Œä½†å†print losså’Œy_predçš„requires_gradå‘ç°æ˜¯æ­£å¸¸çš„Trueã€‚</p>
<p>åœ¨æŸ¥é˜…äº†èµ„æ–™ï¼Œä»¥åŠé—®äº†å­¦é•¿ä¹‹åå‘ç°åŸæ¥å¹¶ä¸æ˜¯bugï¼Œè€Œæ˜¯å› ä¸ºï¼ŒPytorché»˜è®¤ä¸ä¼šä¿å­˜ä¸­é—´èŠ‚ç‚¹(intermediate variable)çš„gradï¼Œæ­¤ä¸¾æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜ã€‚</p>
<blockquote>
<p>By default, gradients are only retained for leaf variables. non-leaf variablesâ€™ gradients are not retained to be inspected later. This was done by design, to save memory.</p>
</blockquote>
<p><a href="https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94" target="_blank" rel="noopener">https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94</a></p>
<p>å®é™…ä¸Šå¯ä»¥é€šè¿‡retain_grad()æˆ–è€…hookæ¥æŸ¥çœ‹ä¸­é—´èŠ‚ç‚¹çš„gradã€‚</p>
<p>æˆ‘åé¢å°è¯•printäº†å¶å­èŠ‚ç‚¹ï¼Œå¦‚ <code>print(CNN_model.fc.weight.grad)</code>ï¼Œæœ€ç»ˆè·å¾—äº†æ­£ç¡®çš„gradã€‚</p>
<p>psï¼šæ‰€è°“ä¸­é—´èŠ‚ç‚¹ï¼Œæ˜¯<strong>ç”±å…¶ä»–èŠ‚ç‚¹è®¡ç®—æ‰€å¾—</strong>çš„tensorï¼Œè€Œå¶å­èŠ‚ç‚¹åˆ™æ˜¯<strong>è‡ªå·±å®šä¹‰</strong>å‡ºæ¥çš„ã€‚</p>
<p>æœ€åæˆ‘å‘ç°ï¼ŒåŸæ¥lossä¸€ç›´æ²¡é™çš„åŸå› æ˜¯å› ä¸ºæˆ‘å®šä¹‰çš„CNNè¿‡äºå¤æ‚ï¼Œå¹¶ä¸”æ•°æ®é›†åå°ï¼Œæ— æ³•å¿«é€Ÿæ”¶æ•›å¯¼è‡´çš„ã€‚</p>
]]></content>
      <tags>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Pytorch</tag>
        <tag>grad</tag>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxå¸¸ç”¨å‘½ä»¤</title>
    <url>/2018/08/03/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h3 id="å‘½ä»¤"><a href="#å‘½ä»¤" class="headerlink" title="å‘½ä»¤"></a>å‘½ä»¤</h3><p>è®°å½•è‡ªå·±å¸¸ç”¨çš„å‘½ä»¤ã€‚</p>
<p>1ï¸âƒ£lsï¼šæ˜¾å¼å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å’Œç›®å½•<br>    -a åŒ…æ‹¬éšè—æ–‡ä»¶<br>    -h å°†æ–‡ä»¶çš„å®¹é‡ä»¥æ˜“è¯»æ–¹å¼åˆ—å‡ºï¼ˆé…åˆ-sä½¿ç”¨ï¼‰<br>    -s ä»¥å—æ•°å½¢å¼æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶åˆ†é…çš„å°ºå¯¸<br>    -l ä»¥è¾ƒé•¿æ ¼å¼åˆ—å‡ºä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥å†™æˆ <code>ll</code><br><img src="/images/2018-08-10-15339070264416.jpg" width="70%" height="50%"></p>
<hr>
<p>2ï¸âƒ£cd åˆ°è¾¾æŒ‡å®šåœ°å€</p>
<hr>
<p>3ï¸âƒ£kill æ€æ­»ç¨‹åº<br>    -l ä¿¡æ¯ç¼–å·ã€‚<strong>å½“l=9æ—¶ï¼Œæ— æ¡ä»¶ç»ˆæ­¢ï¼Œå…¶ä»–ä¿¡å·å¯èƒ½å¿½ç•¥</strong><br>    killall -u <user_name> æ€æ­»è¯¥ç”¨æˆ·å…¨éƒ¨è¿›ç¨‹</user_name></p>
<p><img src="/images/2018-08-03-15332830170623.jpg" width="50%" height="50%"></p>
<hr>
<p>4ï¸âƒ£ps æŠ¥å‘Šå½“å‰ç³»ç»Ÿçš„è¿›ç¨‹çŠ¶æ€<br>    -a æ‰€æœ‰<br>    -p æŒ‡å®šç¨‹åº<br>    -u æŒ‡å®šç”¨æˆ·<br>    -x åˆ—å‡ºè¯¥ç”¨æˆ·çš„è¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯(æˆ‘çš„ç†è§£åº”è¯¥æ˜¯)<br>    å¦‚ï¼š<br><img src="/images/2018-08-10-15339036207642.jpg" width="70%" height="50%"></p>
<hr>
<p>5ï¸âƒ£htop æ¯”topæ›´ä¼˜ï¼Œäº¤äº’æ›´å¥½ï¼ŒåŒæ—¶å¯ä»¥ç›´è§‚çœ‹åˆ°èµ„æºå ç”¨æƒ…å†µ<br>åŸºæœ¬å‘½ä»¤ä¸topä¸€è‡´<br><img src="/images/2018-08-04-15333484387393.jpg" width="70%" height="50%"></p>
<hr>
<p>6ï¸âƒ£topï¼šåŠ¨æ€æŸ¥çœ‹ç³»ç»Ÿè¿è¡ŒçŠ¶æ€<br>    -u æŒ‡å®šç”¨æˆ·å<br>    -p æŒ‡å®šè¿›ç¨‹</p>
<p>7ï¸âƒ£nvidia-smi æŸ¥çœ‹æ˜¾å¡çŠ¶æ€<br>watch nvidia-smi å®æ—¶æŸ¥çœ‹æ˜¾å¡çŠ¶æ€ï¼Œå®šæ—¶åˆ·æ–°</p>
<hr>
<p>8ï¸âƒ£tail æ˜¾ç¤ºæŒ‡å®šæ–‡ä»¶çš„æœ«å°¾è‹¥å¹²è¡Œ<br>    -f æ˜¾ç¤ºæ–‡ä»¶æœ€æ–°è¿½åŠ çš„å†…å®¹<br>    -n æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨nè¡Œå†…å®¹<br>    -c æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨æœ€åcä¸ªå­—ç¬¦</p>
<p>å¦‚ï¼š</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tail file æ˜¾ç¤ºæœ€å10è¡Œ</span><br><span class="line">tail -n +20 file æ˜¾ç¤ºä»ç¬¬20è¡Œè‡³æœ«å°¾</span><br><span class="line">tail -c 10 file æ˜¾ç¤ºæ–‡ä»¶fileçš„æœ€å10ä¸ªå­—ç¬¦</span><br></pre></td></tr></table></figure>
<pre><code>-------
</code></pre><p>9ï¸âƒ£echo ç”¨äºæ‰“å°æŒ‡å®šçš„å­—ç¬¦ä¸²<br><img src="/images/2018-08-04-15333497266470.jpg" width="50%" height="50%"></p>
<hr>
<p>ğŸ”Ÿwhich ç”¨äºæŸ¥æ‰¾å¹¶æ˜¾ç¤ºç»™å®šå‘½ä»¤çš„ç»å¯¹è·¯å¾„ï¼ŒwhichæŒ‡ä»¤ä¼šåœ¨ç¯å¢ƒå˜é‡$PATHè®¾ç½®çš„ç›®å½•é‡ŒæŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚ä½¿ç”¨whichå‘½ä»¤ï¼Œå¯ä»¥çœ‹åˆ°æŸä¸ªç³»ç»Ÿå‘½ä»¤æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ‰§è¡Œçš„æ˜¯å“ªä¸ªä½ç½®çš„å‘½ä»¤ã€‚å¦‚ï¼š</p>
<p><img src="/images/2018-08-04-15333500837235.jpg" width="50%" height="50%"></p>
<hr>
<p>1ï¸âƒ£1ï¸âƒ£nohup å°†ç¨‹åºä»¥å¿½ç•¥æŒ‚èµ·ä¿¡å·çš„æ–¹å¼è¿è¡Œï¼Œç»å¸¸ç”¨äºåœ¨æœåŠ¡å™¨è·‘ä»£ç <br>å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nohup python xxx.py &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>å³ï¼Œå°†è¾“å‡ºé‡å®šå‘åˆ°output.txt ï¼›æœ€åä¸€ä¸ª<code>&amp;</code>è¡¨ç¤ºåå°æŒ‚èµ·</p>
<hr>
<p>1ï¸âƒ£2ï¸âƒ£cp å¤åˆ¶æ–‡ä»¶   cp [æ–‡ä»¶] [ç›®æ ‡æ–‡ä»¶å¤¹]<br>    -r é€’å½’å¤åˆ¶ï¼Œç”¨äºç›®å½•çš„å¤åˆ¶</p>
<hr>
<p>1ï¸âƒ£3ï¸âƒ£mv ç§»åŠ¨æ–‡ä»¶ã€ç›®å½•æˆ–æ›´å  mv [æ–‡ä»¶/æ–‡ä»¶å¤¹] [æ–‡ä»¶å¤¹]<br>    -f å¼ºåˆ¶ï¼Œå½“ç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†ç›–<br>    -i ä¼šè¯¢é—®</p>
<hr>
<p>1ï¸âƒ£4ï¸âƒ£rm åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•<br>    -f å¼ºåˆ¶åˆ é™¤<br>    -r é€’å½’åˆ é™¤ï¼Œç”¨äºç›®å½•åˆ é™¤</p>
<hr>
<p>1ï¸âƒ£5ï¸âƒ£file ç”¨äºåˆ¤æ–­æ–‡ä»¶çš„åŸºæœ¬æ•°æ®<br>å¦‚ï¼š</p>
<p><img src="/images/2018-08-05-15334547949248.jpg" width="80%" height="50%"></p>
<hr>
<p>1ï¸âƒ£6ï¸âƒ£tar å¯¹æ–‡ä»¶æ‰“åŒ…/å‹ç¼©<br>    -t æŸ¥çœ‹æ‰“åŒ…æ–‡ä»¶çš„å†…å®¹å«æœ‰å“ªäº›æ–‡ä»¶å<br>    -x è§£å‹ç¼©<br>    -c æ–°å»ºæ‰“åŒ…æ–‡ä»¶<br>    -C æŒ‡å®šå‹ç¼©/è§£å‹ç›®å½•<br>    -v è§£å‹/å‹ç¼©è¿‡ç¨‹ä¸­å°†å¤„ç†çš„æ–‡ä»¶åæ˜¾ç¤ºå‡ºæ¥<br>å¸¸ç”¨çš„ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">å‹ç¼©ï¼štar -jcv -f filename.tar.bz2 è¦è¢«å¤„ç†çš„æ–‡ä»¶æˆ–ç›®å½•åç§°</span><br><span class="line">æŸ¥è¯¢ï¼štar -jtv -f filename.tar.bz2</span><br><span class="line">è§£å‹ï¼štar -jxv -f filename.tar.bz2 -C æ¬²è§£å‹ç¼©çš„ç›®å½•</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£7ï¸âƒ£wc word count ç»Ÿè®¡æ–‡ä»¶å†…å®¹ä¿¡æ¯ï¼Œå¦‚è¡Œæ•°ã€å­—ç¬¦æ•°<br>    -l æ˜¾ç¤ºæ–‡ä»¶è¡Œæ•°<br>    -c æ˜¾ç¤ºå­—èŠ‚æ•°<br>    -m æ˜¾ç¤ºå­—ç¬¦æ•°<br>    -w æ˜¾ç¤ºå­—æ•°  å­—è¢«å®šä¹‰ä¸ºç”±ç©ºç™½ã€è·³æ ¼ã€æ¢è¡Œå­—ç¬¦åˆ†éš”çš„å­—ç¬¦ä¸²<br>    -L æ˜¾ç¤ºæœ€é•¿è¡Œçš„é•¿åº¦<br>    ä¸åŠ å‚æ•°ï¼Œæ‰€æœ‰çš„éƒ½æ˜¾ç¤ºï¼Œä¾æ¬¡æ˜¯è¡Œæ•°ã€å•è¯æ•°ã€å­—èŠ‚æ•°ã€æ–‡ä»¶å</p>
<hr>
<p>1ï¸âƒ£8ï¸âƒ£df æ˜¾ç¤ºç£ç›˜ç›¸å…³ä¿¡æ¯<br>    -h ä»¥å¯è¯»æ€§è¾ƒé«˜çš„æ–¹å¼æ˜¾ç¤ºä¿¡æ¯</p>
<hr>
<p>1ï¸âƒ£9ï¸âƒ£scp æœåŠ¡å™¨ä¹‹é—´çš„æ–‡ä»¶å¤åˆ¶<br>    å¦‚:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -r /test1 zhlin@123.12.1.12:/home/zhlin</span><br></pre></td></tr></table></figure>
<h3 id="âœ¨å¿«æ·é”®"><a href="#âœ¨å¿«æ·é”®" class="headerlink" title="âœ¨å¿«æ·é”®"></a>âœ¨å¿«æ·é”®</h3><p>Ctrl+a è·³åˆ°è¡Œé¦–<br>Ctrl+c é€€å‡ºå½“å‰è¿›ç¨‹<br>Ctrl+e è·³åˆ°é¡µå°¾<br>Ctrl+k åˆ é™¤å½“å‰å…‰æ ‡åé¢çš„æ–‡å­—<br>Ctrl+l æ¸…å±ï¼Œç­‰ä»·äºclear<br>Ctrl+r æœç´¢ä¹‹å‰æ‰“è¿‡çš„å‘½ä»¤<br>Ctrl+u åˆ é™¤å½“å‰å…‰æ ‡å‰é¢çš„æ–‡å­—<br>âœ¨Ctrl+å·¦å³é”® å•è¯ä¹‹é—´è·³è½¬ åœ¨Macä¸Šå¯ä»¥ä½¿ç”¨option+å·¦å³é”®<br>Ctrl+y è¿›è¡Œæ¢å¤åˆ é™¤<br>Ctrl+z å°†å½“å‰è¿›ç¨‹è½¬åˆ°åå°ï¼Œä½¿ç”¨fgæ¢å¤</p>
<hr>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/leo_618/article/details/53003111" target="_blank" rel="noopener">https://blog.csdn.net/leo_618/article/details/53003111</a></p>
<p>â€”â€”â€”-æŒç»­æ›´æ–°â€”â€”â€”-</p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>æŠ€å·§</tag>
      </tags>
  </entry>
  <entry>
    <title>ä¸€ä¸ªå…³äºyieldçš„é‡æ–°è®¤è¯†</title>
    <url>/2018/07/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Eyield%E7%9A%84%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86/</url>
    <content><![CDATA[<p>ä»Šå¤©é‡åˆ°äº†ä¸€ä¸ªç¥å¥‡çš„â€bugâ€ï¼Œè®©æˆ‘å¯¹yieldçš„ç†è§£æ›´æ·±ä¸€æ­¥ã€‚</p>
<p>è¿™æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæˆ‘æœ¬æ¥æ‰“ç®—è¯•ç€printä¸€ä¸‹lineå†…éƒ¨çš„æ ¼å¼å’Œå†…å®¹ã€‚<br><img src="/images/2018-07-31-15330184801079.jpg" width="40%" height="40%"></p>
<p>è¿™æ˜¯è°ƒç”¨çš„ä¸»å‡½æ•°ï¼š<br><img src="/images/2018-07-31-15330185414299.jpg" width="50%" height="50%"></p>
<p>ç»“æœè·‘å‡ºçš„ç»“æœæ˜¯ï¼š<br><img src="/images/2018-07-31-15330185762441.jpg" width="90%" height="90%"></p>
<p>ï¼Ÿï¼Ÿï¼Ÿ<br><img src="/images/2018-07-31-15330186003254.jpg" alt=""></p>
<p>æˆ‘å°è¯•åœ¨å‡½æ•°çš„å¼€å¤´æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330186689312.jpg" width="40%" height="50%"></p>
<p>ç»“æœä»ç„¶æ²¡æœ‰ä»»ä½•çš„è¾“å‡ºã€‚</p>
<p>æˆ‘è¯•ç€åœ¨mainå‡½æ•°æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330187249603.jpg" width="50%" height="50%"></p>
<p>ç»“æœï¼š</p>
<p><img src="/images/2018-07-31-15330187445810.jpg" width="50%" height="50%"></p>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œæ ¹æœ¬æ²¡æœ‰è¿›å…¥åˆ°get_dataset_from_txtå‡½æ•°å•Šã€‚</p>
<p>æˆ‘ä»¥ä¸ºæ˜¯pycharmçš„é—®é¢˜è¿˜é‡å¯äº†ä¸€éï¼Œç„¶è€Œå¹¶æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚é—®äº†å…¶ä»–äººï¼Œä»–ä»¬ä¹Ÿè§‰å¾—å¾ˆç¥å¥‡ã€‚æœ€åä¸€ä¸ªåŒå­¦çœ‹äº†ä¸€ä¸‹å‡½æ•°ï¼Œå‘ç°äº†é—®é¢˜æ‰€åœ¨ï¼š<strong>yield</strong></p>
<p>æˆ‘çªç„¶æƒ³èµ·æ¥ï¼Œ<strong>yieldè¿”å›çš„æ˜¯ä¸€ä¸ªgeneratorï¼Œåªæœ‰åœ¨å¯¹generatorè¿›è¡Œéå†æ—¶ï¼Œæ‰ä¼šå¼€å§‹è¿è¡Œ</strong>â€¦</p>
<p>äºæ˜¯ï¼Œæˆ‘è¯•ç€è¿™ä¹ˆå†™ï¼Œè¯•ç€å¯¹generatoréå†ï¼š</p>
<p><img src="/images/2018-07-31-15330189280379.jpg" width="50%" height="50%"></p>
<p>è™½ç„¶æŠ¥é”™äº†ï¼Œä½†å‡½æ•°ç»ˆäºæ˜¯è¿›å»äº†â€¦</p>
<p><img src="/images/2018-07-31-15330189613535.jpg" width="70%" height="50%"></p>
<p><strong>ç»“è®ºï¼šæœ‰yieldçš„å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªgeneratorï¼Œå½“å¯¹å…¶è¿›è¡Œéå†æ—¶ï¼Œå‡½æ•°æ‰ä¼šå¼€å§‹è¿è¡Œã€‚</strong></p>
]]></content>
      <tags>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>Python</tag>
        <tag>yield</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•2</title>
    <url>/2018/07/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB2/</url>
    <content><![CDATA[<p>æœ¬å‘¨ä¸»è¦çœ‹äº†<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">AllenNLP/ELMO</a>çš„ä»£ç ï¼Œä½†å¹¶æ²¡æœ‰æ‰¾åˆ°å¾ˆå¤šå¯å¤ç”¨çš„ä»£ç ã€‚æœ¬å‘¨ä¹Ÿæ²¡æœ‰æ¯”è¾ƒæœ‰æ„ä¹‰çš„ä»£ç ã€‚</p>
<hr>
<h3 id="1ï¸âƒ£get-time-diff"><a href="#1ï¸âƒ£get-time-diff" class="headerlink" title="1ï¸âƒ£get_time_diff"></a>1ï¸âƒ£get_time_diff</h3><p>è·å–å·²ä½¿ç”¨çš„æ—¶é—´<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line">start_time=time.time()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time_dif</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    <span class="string">"""è·å–å·²ä½¿ç”¨æ—¶é—´"""</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    time_dif = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=int(round(time_dif)))</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="2ï¸âƒ£parserä½¿ç”¨"><a href="#2ï¸âƒ£parserä½¿ç”¨" class="headerlink" title="2ï¸âƒ£parserä½¿ç”¨"></a>2ï¸âƒ£parserä½¿ç”¨</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--save_dir'</span>, help=<span class="string">'Location of checkpoint files'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--vocab_file'</span>, help=<span class="string">'Vocabulary file'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--train_prefix'</span>, help=<span class="string">'Prefix for train files'</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">    </span><br><span class="line">main(args)   <span class="comment">#ä½¿ç”¨</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†1</title>
    <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%861/</url>
    <content><![CDATA[<p>1ï¸âƒ£[Python]<br>assertç”¨æ³•ï¼š</p>
<p><code>assert expression</code><br>ç­‰ä»·äº<br><code>if not expression: raise AssertionError</code></p>
<hr>
<p>2ï¸âƒ£[Pytorch]<br>Pytorch viewï¼š<br>åˆ›å»ºä¸€ä¸ªæ–°çš„tensorï¼Œä½†ä»–ä»¬çš„<strong>dataæ˜¯å…±äº«çš„</strong>ã€‚</p>
<p><img src="/images/2018-07-29-15328360404485.jpg" width="50%" height="50%"></p>
<hr>
<p>3ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œembeddingçš„indexæ˜¯ä¸èƒ½requires_grad=Trueçš„ï¼Œå¦åˆ™ä¼šå‡ºé”™ã€‚<br><a href="https://github.com/pytorch/pytorch/issues/7021" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/7021</a></p>
<p>ä¹‹å‰çœ‹è¿‡ä¸€ä»½ä»£ç ï¼Œè®¾ç½®volatile=falseä½†æ²¡æœ‰å‡ºé”™ï¼Œæ˜¯å› ä¸ºåœ¨Pytorch0.4ä¹‹åvolatileå·²ç»è¢«å¼ƒç”¨äº†ï¼Œå› æ­¤volatile=falseä¸èµ·ä½œç”¨ï¼Œè€Œé»˜è®¤requires_grad=false</p>
<hr>
<p>4ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œ<code>nn.Linear(self.hidden_dim,self.vocab_size)</code>çš„ç»´åº¦æ˜¯vocab_size<em>hidden_dimï¼Œä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚<br>å› ä¸ºnn.Linearçš„<em>*ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºè¾“å…¥ç»´åº¦ï¼Œç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºè¾“å‡ºç»´åº¦</em></em></p>
<hr>
<p>5ï¸âƒ£[Pytorch]<br>Pytorchä¸­ï¼Œä½¿ç”¨viewä¸€èˆ¬æ¥è¯´å¿…é¡»è¦ç”¨ .contiguous()ã€‚ä¹Ÿå³ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch.view(batch_size, <span class="number">-1</span>).t().contiguous()</span><br></pre></td></tr></table></figure>
<p>contiguous()çš„å®˜æ–¹è§£é‡Šï¼š<br><a href="https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930" target="_blank" rel="noopener">https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930</a></p>
<blockquote>
<p>It means that your tensor is not a single block of memory, but a block with holes. view can be only used with contiguous tensors, so if you need to use it here, just call .contiguous() before.</p>
</blockquote>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œcontiguousä¼šå°†æ•°æ®å­˜åˆ°ä¸€ä¸ªè¿ç»­çš„ç©ºé—´å†…ï¼ˆblockï¼‰ã€‚</p>
<hr>
<p>6ï¸âƒ£[Pytorch]<br>è°ƒç”¨Cross_entropyæ—¶ï¼ŒPytorchä¼šå¸®åŠ©ä½ åŠ logå’Œsoftmaxã€‚</p>
<p><img src="/images/2018-07-29-15328370301774.jpg" alt=""></p>
<hr>
<p>7ï¸âƒ£[Paper]<br><a href="https://arxiv.org/abs/1807.02291" target="_blank" rel="noopener">Sliced_RNN</a></p>
<p>å°†RNNåˆ†å—ä»¥æé«˜å¹¶è¡Œæ€§ï¼Œç”šè‡³æ¯å±‚çš„RNNéƒ½å¯ä»¥ä¸ä¸€æ ·ï¼Œè¾¾åˆ°æŠ½å–ä¸åŒç¨‹åº¦çš„æŠ½è±¡è¯­ä¹‰ä¿¡æ¯çš„ç›®çš„ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ä¸åŒä»»åŠ¡ä¸Šéƒ½æœ‰ä¸€å®šçš„æå‡ï¼Œä½†é€Ÿåº¦çš„æå‡å¾ˆå¤§ã€‚</p>
<p><img src="/images/2018-07-29-15328372609264.jpg" width="50%" height="50%"></p>
<hr>
<p>8ï¸âƒ£[Tf-idf]<br>è®¡ç®—è¯è¯­å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦</p>
<p><a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Tf-idf</a></p>
<p>tfæ˜¯è¯é¢‘ï¼Œidfæ˜¯é€†å‘æ–‡ä»¶é¢‘ç‡ã€‚ä¹Ÿå³å¦‚æœè¯åœ¨è¯¥å¥å‡ºç°çš„æ¬¡æ•°è¶Šå¤šï¼Œåœ¨æ‰€æœ‰æ–‡æœ¬çš„å‡ºç°æ¬¡æ•°è¶Šå°‘ï¼Œåˆ™è¯å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦è¶Šé«˜ã€‚</p>
<hr>
<p>9ï¸âƒ£[Numpy]<br>åœ¨Numpyä¸­ï¼Œä¸€ä¸ªåˆ—è¡¨è™½ç„¶æ˜¯æ¨ªç€è¡¨ç¤ºçš„ï¼Œä½†å®ƒæ˜¯åˆ—å‘é‡ã€‚æˆ‘ä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚</p>
<p><img src="/images/2018-07-29-15328375536418.jpg" width="50%" height="50%"></p>
]]></content>
      <tags>
        <tag>ç¢ç‰‡çŸ¥è¯†</tag>
        <tag>Pytorch</tag>
        <tag>Python</tag>
        <tag>Paper</tag>
        <tag>Tf-idf</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Macé…ç½®å¤æ—¦æœ‰çº¿ç½‘</title>
    <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E9%85%8D%E7%BD%AE%E5%A4%8D%E6%97%A6%E6%9C%89%E7%BA%BF%E7%BD%91/</url>
    <content><![CDATA[<h3 id="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"><a href="#é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨" class="headerlink" title="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"></a>é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨</h3><p>æœ‰çº¿ä¼¼ä¹ä¸æ”¯æŒDHCPï¼Œå› æ­¤åªå¥½è‡ªå·±è®¾ç½®ã€‚<br>é¦–å…ˆè¿æ¥ä¸Šæœ‰çº¿ï¼Œå°†é…ç½®iPv4é€‰ä¸ºæ‰‹åŠ¨ã€‚é—®å®éªŒå®¤çš„å­¦é•¿å…·ä½“çš„ipåœ°å€ã€å­ç½‘æ©ç ã€è·¯ç”±å™¨ã€DNSæœåŠ¡å™¨ã€‚å…¶ä¸­ipåœ°å€æœ€åä¸‰ä½è¦è‡ªå·±è®¾å®šï¼Œåªè¦ä¸å’Œå…¶ä»–äººå†²çªå°±å¥½ã€‚</p>
<p><img src="/images/2018-07-29-15328333841584.jpg" width="50%" height="50%"></p>
<p><img src="/images/2018-07-29-15328335236981.jpg" width="50%" height="50%"></p>
<h3 id="æ‰‹åŠ¨è®¤è¯"><a href="#æ‰‹åŠ¨è®¤è¯" class="headerlink" title="æ‰‹åŠ¨è®¤è¯"></a>æ‰‹åŠ¨è®¤è¯</h3><p>åˆ°è®¤è¯å¹³å°ï¼Œä¸‹è½½Macå®¢æˆ·ç«¯ï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ª.shæ–‡ä»¶ï¼š<br><a href="http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1" target="_blank" rel="noopener">http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1</a></p>
<p><img src="/images/2018-07-29-15328336395029.jpg" width="30%" height="30%"></p>
<p>ç„¶åï¼Œæ‰“å¼€æ–‡ä»¶é…ç½®ç”¨æˆ·åå¯†ç ï¼Œæ³¨æ„åˆ°ç­‰å·åé¢è¦æœ‰åŒå¼•å·ï¼š</p>
<p><img src="/images/2018-07-29-15328337135244.jpg" width="50%" height="50%"></p>
<p>ä¿å­˜å¹¶æ”¾å…¥ç»ˆç«¯è¿è¡Œï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥ä½¿ç”¨æœ‰çº¿ç½‘äº†ã€‚</p>
<h3 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h3><p>ä¼¼ä¹ï¼Œæ¯æ¬¡é‡æ–°è¿æ¥éƒ½è¦è¿™æ ·é…ç½®ï¼Œæˆ‘æ²¡æœ‰è¯•è¿‡ä¸æ¸…æ¥šï¼›<br>æœ‰çº¿ç½‘å¥½åƒä¹Ÿæ²¡æœ‰æ¯”æ— çº¿ç½‘å¿«å¤šå°‘ï¼Œä½†åº”è¯¥ä¼šç¨³å®šä¸€äº›ã€‚</p>
]]></content>
      <tags>
        <tag>ç½‘ç»œ</tag>
        <tag>é…ç½®</tag>
      </tags>
  </entry>
  <entry>
    <title>sshå¿«é€Ÿç™»å½•é…ç½®</title>
    <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/ssh%E5%BF%AB%E9%80%9F%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>åˆ†é…äº†æœåŠ¡å™¨ä¹‹åï¼Œæ¯æ¬¡è¦sshè¿›å…¥éƒ½å¾ˆéº»çƒ¦ï¼š<code>ssh user_name@ip_address</code> ç„¶åè¿˜è¦è¾“å…¥å¯†ç ã€‚</p>
<p>ç‰¹åˆ«æ˜¯å¦‚æœåˆ†é…äº†å¤šä¸ªæœåŠ¡å™¨ï¼Œé‚£æœ‰æ—¶å€™è¿˜å®¹æ˜“å¿˜è®°ipåœ°å€ã€‚å› æ­¤å¦‚æœèƒ½å¤Ÿä¸€æ¡å‘½ä»¤å°±è¿›å…¥æœåŠ¡å™¨èƒ½å¤Ÿå‡å°‘éº»çƒ¦ã€‚<br>ä¸»è¦æœ‰ä¸‰ç‚¹ï¼š</p>
<ol>
<li>åˆ›å»ºrsa key</li>
<li>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</li>
<li>è®¾ç½®alias</li>
</ol>
<h1 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h1><h2 id="åˆ›å»ºrsa-key"><a href="#åˆ›å»ºrsa-key" class="headerlink" title="åˆ›å»ºrsa key"></a>åˆ›å»ºrsa key</h2><p>åœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤ï¼š</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p>å½“ç„¶å¦‚æœä»¥å‰æœ‰åˆ›å»ºè¿‡çš„å¯ä»¥ä¸ç”¨ã€‚</p>
<p>ç»“æœï¼š</p>
<p><img src="/images/2018-07-29-Xnip2018-07-29_10-43-15.jpg" width="50%" height="50%"></p>
<h2 id="ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨"><a href="#ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨" class="headerlink" title="ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨"></a>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</h2><p>ä½¿ç”¨å‘½ä»¤ï¼š<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub user@127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>è¾“å…¥å¯†ç å³å¯</p>
<p>ç»“æœï¼š</p>
<p><img src="/images/2018-07-29-15328324683354.jpg" width="60%" height="60%"></p>
<h2 id="è®¾ç½®alias"><a href="#è®¾ç½®alias" class="headerlink" title="è®¾ç½®alias"></a>è®¾ç½®alias</h2><p>å®Œæˆä»¥ä¸Šæ­¥éª¤å°±å¯ä»¥ä¸è¾“å…¥å¯†ç ç™»å½•ï¼Œä½†è¿˜æ˜¯éœ€è¦è¾“å…¥ipåœ°å€å’Œç”¨æˆ·åï¼Œä¸ºäº†æ›´ç®€åŒ–æ“ä½œï¼Œç»™å‘½ä»¤èµ·ä¸ªåˆ«åã€‚éœ€è¦é…ç½® .bash_profileæ–‡ä»¶ã€‚<br>è¾“å…¥å‘½ä»¤:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>åœ¨æ–‡ä»¶åé¢æ·»åŠ ä»¥ä¸‹æ–‡å­—ï¼š</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># alias </span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br></pre></td></tr></table></figure>
<p>å…¶ä¸­ Ã—Ã—Ã—æ˜¯ä½ è‡ªå·±èµ·çš„åå­—ï¼Œå¯ä»¥æ˜¯æœåŠ¡å™¨çš„åå­—ï¼Œuser_nameå’Œip_addressæ˜¯è‡ªå·±æœåŠ¡å™¨çš„ç”¨æˆ·åå’Œåœ°å€ã€‚ä¿å­˜æ›´æ”¹é€€å‡ºã€‚</p>
<p>ç„¶åè¿˜è¦ä½¿å…¶ç”Ÿæ•ˆ:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>è¿™æ ·ï¼Œè¾“å…¥åˆ«åï¼Œå°±å¯ä»¥ç›´æ¥ç™»å½•äº†ï¼š</p>
<p><img src="/images/2018-07-29-15328329815456.jpg" width="50%" height="50%"></p>
<h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><p><a href="https://www.jianshu.com/p/66d658c7cb9e" target="_blank" rel="noopener">https://www.jianshu.com/p/66d658c7cb9e</a></p>
]]></content>
      <tags>
        <tag>é…ç½®</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>å…³äºå›°æƒ‘åº¦</title>
    <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E%E5%9B%B0%E6%83%91%E5%BA%A6/</url>
    <content><![CDATA[<p>å‰å‡ å¤©åœ¨å†™æ–°æ‰‹ä»»åŠ¡<a href="https://github.com/FudanNLP/nlp-beginner" target="_blank" rel="noopener">task3</a>çš„æ—¶å€™ï¼Œå‚è€ƒäº†Pytorchå®˜æ–¹exampleçš„word language modelï¼Œå®˜æ–¹exampleåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—å›°æƒ‘åº¦æ˜¯è¿™æ ·çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">math.exp(cur_loss)</span><br></pre></td></tr></table></figure>
<p>å…¶ä¸­ï¼Œcur_lossè¡¨ç¤ºäº¤å‰ç†µçš„lossï¼Œå³ $-P(\hat{x})logP(x)$ï¼Œ$\hat{x}$è¡¨ç¤ºground truthã€‚</p>
<p>ç„¶è€Œï¼Œåœ¨æŸ¥é˜…äº†å›°æƒ‘åº¦ç›¸å…³èµ„æ–™åï¼Œæˆ‘å‘ç°ï¼Œå›°æƒ‘åº¦çš„å®šä¹‰æ˜¯è¿™æ ·çš„ï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned}
PP(S)= &{P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\
= &\sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\
= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }
\end{aligned}</script><p>è¿™æ˜¯å¦ä¸€ç§å½¢å¼:</p>
<script type="math/tex; mode=display">
\begin{aligned}
Perplexity (W)=& 2^{H(W)} \\
= & {P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\
= & \sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\
= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }
\end{aligned}</script><p>å¯ä»¥çœ‹åˆ°ï¼ŒäºŒè€…æœ¬è´¨æ˜¯ä¸€æ ·çš„ã€‚</p>
<p><strong>é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆåœ¨ä»£ç ä¸­ä»¥eä¸ºåº•å»è®¡ç®—å›°æƒ‘åº¦ï¼Œè€Œä¸æ˜¯2å‘¢?</strong></p>
<p>å®é™…ä¸Šï¼Œæ˜¯å› ä¸ºåœ¨ä¸Šè¿°å…¬å¼ä¸­ï¼Œlogæ˜¯ä»¥2ä¸ºåº•çš„ï¼Œä½†åœ¨Pytorchä¸­ï¼Œlogé»˜è®¤æ˜¯ä»¥eä¸ºåº•çš„ã€‚å› æ­¤åœ¨ä»£ç ä¸­ï¼Œéœ€è¦ç”¨eä½œä¸ºæŒ‡æ•°çš„åº•æ¥è¿˜åŸæˆå›°æƒ‘åº¦çš„åŸæœ¬å½¢å¼ï¼š </p>
<script type="math/tex; mode=display">
\begin{aligned}
\sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }
\end{aligned}</script><p>æœ€åè¿™æ˜¯perplexityçš„æ•°å­¦æ¨å¯¼ï¼š<br><a href="https://www.zhihu.com/question/58482430" target="_blank" rel="noopener">https://www.zhihu.com/question/58482430</a></p>
]]></content>
      <tags>
        <tag>å›°æƒ‘åº¦</tag>
        <tag>perplexity</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯2</title>
    <url>/2018/07/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D2/</url>
    <content><![CDATA[<p>æœ¬å‘¨çš„è¯—è¯æœ‰ä¸¤ç¯‡æ˜¯å·²ç»èƒŒè¿‡çš„ï¼Œæƒå½“æ˜¯å¤ä¹ äº†ä¸€éã€‚</p>
<hr>
<p>1ï¸âƒ£</p>
<h3 id="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"><a href="#ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’" class="headerlink" title="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"></a>ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’</h3><p>[å”] æç™½<br>æš®ä»ç¢§å±±ä¸‹ï¼Œå±±æœˆéšäººå½’ã€‚<br>å´é¡¾æ‰€æ¥å¾„ï¼Œè‹è‹æ¨ªç¿ å¾®ã€‚<br>ç›¸æºåŠç”°å®¶ï¼Œç«¥ç¨šå¼€è†æ‰‰ã€‚<br>ç»¿ç«¹å…¥å¹½å¾„ï¼Œé’èæ‹‚è¡Œè¡£ã€‚<br>æ¬¢è¨€å¾—æ‰€æ†©ï¼Œç¾é…’èŠå…±æŒ¥ã€‚<br>é•¿æ­ŒåŸæ¾é£ï¼Œæ›²å°½æ²³æ˜Ÿç¨€ã€‚<br>æˆ‘é†‰å›å¤ä¹ï¼Œé™¶ç„¶å…±å¿˜æœºã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b900307db2a20054269a2a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b900307db2a20054269a2a</a></p>
<hr>
<p>2ï¸âƒ£</p>
<h3 id="é€¢å…¥äº¬ä½¿"><a href="#é€¢å…¥äº¬ä½¿" class="headerlink" title="é€¢å…¥äº¬ä½¿"></a>é€¢å…¥äº¬ä½¿</h3><p>[å”] å²‘å‚<br>æ•…å›­ä¸œæœ›è·¯æ¼«æ¼«ï¼ŒåŒè¢–é¾™é’Ÿæ³ªä¸ä¹¾ã€‚<br><strong>é©¬ä¸Šç›¸é€¢æ— çº¸ç¬”ï¼Œå‡­å›ä¼ è¯­æŠ¥å¹³å®‰ã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b92218df0eea006335f923" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92218df0eea006335f923</a></p>
<hr>
<p>3ï¸âƒ£</p>
<h3 id="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"><a href="#å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤" class="headerlink" title="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"></a>å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤</h3><p>[å®‹] è‹è½¼<br>å¤§æ±Ÿä¸œå»ï¼Œæµªæ·˜å°½ã€åƒå¤é£æµäººç‰©ã€‚æ•…å’è¥¿è¾¹ï¼Œäººé“æ˜¯ã€ä¸‰å›½å‘¨éƒèµ¤å£ã€‚ä¹±çŸ³ç©¿ç©ºï¼ŒæƒŠæ¶›æ‹å²¸ï¼Œå·èµ·åƒå †é›ªã€‚æ±Ÿå±±å¦‚ç”»ï¼Œä¸€æ—¶å¤šå°‘è±ªæ°ã€‚<br>é¥æƒ³å…¬ç‘¾å½“å¹´ï¼Œå°ä¹”åˆå«äº†ï¼Œé›„å§¿è‹±å‘ã€‚ç¾½æ‰‡çº¶å·¾ï¼Œè°ˆç¬‘é—´ï¼Œæ¨¯æ©¹ç°é£çƒŸç­ã€‚æ•…å›½ç¥æ¸¸ï¼Œå¤šæƒ…åº”ç¬‘æˆ‘ï¼Œæ—©ç”Ÿåå‘ã€‚<strong>äººç”Ÿå¦‚æ¢¦ï¼Œä¸€å°Šè¿˜é…¹æ±Ÿæœˆã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>ä»£ç ç‰‡æ®µè®°å½•1</title>
    <url>/2018/07/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB1/</url>
    <content><![CDATA[<h3 id="1ï¸âƒ£-get-batch"><a href="#1ï¸âƒ£-get-batch" class="headerlink" title="1ï¸âƒ£ get_batch"></a>1ï¸âƒ£ get_batch</h3><p>æ³¨æ„åˆ°shuffleçš„æ ‡å‡†åšæ³•</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self,data,batch_size=<span class="number">32</span>,is_shuffle)</span>:</span></span><br><span class="line">  N=len(data)  <span class="comment">#è·å¾—æ•°æ®çš„é•¿åº¦</span></span><br><span class="line">  <span class="keyword">if</span> is_shuffle <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">    r=random.Random()</span><br><span class="line">    r.seed()</span><br><span class="line">    r.shuffle(data) <span class="comment">#å¦‚æœis_shuffleä¸ºçœŸåˆ™æ‰“ä¹±</span></span><br><span class="line">  <span class="comment">#å¼€å§‹è·å¾—batchï¼Œä½¿ç”¨[ for in ]</span></span><br><span class="line">  batch=[data[k:k+batch_size] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,N,batch_size)]</span><br><span class="line">  <span class="keyword">if</span> N%batch_size!=<span class="number">0</span>:  <span class="comment">#å¤„ç†ä¸æ•´é™¤é—®é¢˜ï¼Œå¦‚æœæœ‰æ˜¾å¼è¦æ±‚ä¸¢æ‰åˆ™ä¸éœ€è¦å¤„ç†ï¼Œè¿™é‡Œé»˜è®¤å¤„ç†</span></span><br><span class="line">    remainder=N-N%batch_size  <span class="comment">#å‰©ä¸‹çš„éƒ¨åˆ†</span></span><br><span class="line">    batch.append(data[temp:N])</span><br><span class="line">  <span class="keyword">return</span> batch</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"><a href="#2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"></a>2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥</h3><p>å®é™…ä¸Šè¿™ä»½ä»£ç æœ‰ç‚¹é—®é¢˜ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå‘ç°gloveæ–‡ä»¶éœ€è¦æ”¾åœ¨gensimçš„æ–‡ä»¶å¤¹ä¸‹æ‰èƒ½è¢«è¯»åˆ°(7.20 updated,åº”è¯¥ä½¿ç”¨ç»å¯¹åœ°å€)ï¼Œå¹¶ä¸å¥½ã€‚</p>
<p>æ•™ç¨‹åœ°å€ï¼š<a href="https://radimrehurek.com/gensim/scripts/glove2word2vec.html" target="_blank" rel="noopener">gensim: scripts.glove2word2vec â€“ Convert glove format to word2vec</a><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1. ä½¿ç”¨gensimè¯»å…¥word2vec</span></span><br><span class="line"></span><br><span class="line">model = gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">        fname=<span class="string">'GoogleNews-vectors-negative300-SLIM.bin'</span>, binary=<span class="keyword">True</span>)</span><br><span class="line">words = model.vocab  <span class="comment">#è·å¾—è¯è¡¨</span></span><br><span class="line">vector= model[word]  <span class="comment">#wordæ˜¯wordsé‡Œé¢çš„å…ƒç´ </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. ä½¿ç”¨gensimè¯»å…¥glove</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> datapath, get_tmpfile</span><br><span class="line"><span class="keyword">from</span> gensim.scripts.glove2word2vec <span class="keyword">import</span> glove2word2vec</span><br><span class="line">glove_file=datapath(<span class="string">'glove.txt'</span>)  <span class="comment">#æœ€å¥½ä½¿ç”¨ç»å¯¹åœ°å€</span></span><br><span class="line">tmp_file=get_tmpfile(<span class="string">'word2vec.txt'</span>)</span><br><span class="line">glove2word2vec(glove_file,tmp_file)</span><br><span class="line">model=KeyedVectors.load_word2vec_format(tmp_file)</span><br><span class="line"><span class="comment">#æ¥ä¸‹æ¥ä½¿ç”¨çš„æ–¹æ³•æ˜¯ä¸€æ ·çš„</span></span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="3ï¸âƒ£data-splitæ–¹æ³•"><a href="#3ï¸âƒ£data-splitæ–¹æ³•" class="headerlink" title="3ï¸âƒ£data_splitæ–¹æ³•"></a>3ï¸âƒ£data_splitæ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span><span class="params">(seed=<span class="number">1</span>, proportion=<span class="number">0.7</span>)</span>:</span> </span><br><span class="line">    data = list(iter_corpus())</span><br><span class="line">    ids = list(range(len(data)))</span><br><span class="line"></span><br><span class="line">    N = int(len(ids) * proportion)  <span class="comment"># number of training data</span></span><br><span class="line"></span><br><span class="line">    rng = random.Random(seed)</span><br><span class="line">    rng.shuffle(ids)</span><br><span class="line">    test_ids = set(ids[N:])</span><br><span class="line">    train_data = []</span><br><span class="line">    test_data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> x[<span class="number">1</span>] <span class="keyword">in</span> test_ids:  <span class="comment"># x[1]: sentence id</span></span><br><span class="line">            test_data.append(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_data.append(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_data, test_data</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"><a href="#4ï¸âƒ£å¯¹stringé¢„å¤„ç†" class="headerlink" title="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"></a>4ï¸âƒ£å¯¹stringé¢„å¤„ç†</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_str</span><span class="params">(string)</span>:</span></span><br><span class="line">    string = re.sub(<span class="string">r"[^A-Za-z0-9()!?\'\`]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'s"</span>, <span class="string">" \'s"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'m"</span>, <span class="string">" \'m"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ve"</span>, <span class="string">" \'ve"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"n\'t"</span>, <span class="string">" n\'t"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'re"</span>, <span class="string">" \'re"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'d"</span>, <span class="string">" \'d"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ll"</span>, <span class="string">" \'ll"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r","</span>, <span class="string">" , "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"!"</span>, <span class="string">" ! "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\("</span>, <span class="string">" \( "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\)"</span>, <span class="string">" \) "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\?"</span>, <span class="string">" \? "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\s&#123;2,&#125;"</span>, <span class="string">" "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\@.*?[\s\n]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"https*://.+[\s]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    <span class="keyword">return</span> string.strip().lower()</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="5ï¸âƒ£collate-fn-batchï¼‰"><a href="#5ï¸âƒ£collate-fn-batchï¼‰" class="headerlink" title="5ï¸âƒ£collate_fn(batchï¼‰"></a>5ï¸âƒ£collate_fn(batchï¼‰</h3><p>é‡å†™collate_fnç»„å»ºmini-batchï¼Œåœ¨NLPä¸­å¸¸ç”¨ï¼Œå¥å­çš„ä¸ç­‰é•¿æ€§<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span>  <span class="comment"># rewrite collate_fn to form a mini-batch</span></span><br><span class="line">    lengths = np.array([len(data[<span class="string">'sentence'</span>]) <span class="keyword">for</span> data <span class="keyword">in</span> batch])</span><br><span class="line">    sorted_index = np.argsort(-lengths)</span><br><span class="line">    lengths = lengths[sorted_index]  <span class="comment"># descend order</span></span><br><span class="line"></span><br><span class="line">    max_length = lengths[<span class="number">0</span>]</span><br><span class="line">    batch_size = len(batch)</span><br><span class="line">    sentence_tensor = torch.LongTensor(batch_size, int(max_length)).zero_()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> enumerate(sorted_index):</span><br><span class="line">        sentence_tensor[i][:lengths[i]] = torch.LongTensor(batch[index][<span class="string">'sentence'</span>][:max_length])</span><br><span class="line"></span><br><span class="line">    sentiments = torch.autograd.Variable(torch.LongTensor([batch[i][<span class="string">'sentiment'</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_index]))</span><br><span class="line">    <span class="keyword">if</span> config.use_cuda:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()).cuda(), lengths)  <span class="comment">#remember to transpose</span></span><br><span class="line">        sentiments = sentiments.cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()),lengths)  <span class="comment"># remember to transpose</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'sentence'</span>: packed_sequences, <span class="string">'sentiment'</span>: sentiments&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## é‡å†™collate_fn(batch)ä»¥ç”¨äºdataloaderä½¿ç”¨ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š</span></span><br><span class="line"></span><br><span class="line">train_dataloader=DataLoader(train_data,batch_size=<span class="number">32</span>,shuffle=<span class="keyword">True</span>,collate_fn=collate_fn)</span><br><span class="line">â€‹</span><br><span class="line"><span class="comment">## å…¶ä¸­ï¼Œtrain_dataloaderå¯å¾ªç¯éå†â€‹â€‹ã€‚</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"><a href="#6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator" class="headerlink" title="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"></a>6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator</h3><p>yieldçš„ç”¨æ³•<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span><span class="params">(txt_file)</span>:</span>     <span class="comment"># return generator</span></span><br><span class="line">    <span class="keyword">with</span> open(txt_file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">if</span> len(line.strip())==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            sentence=list(line.strip())+[<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            <span class="keyword">yield</span> sentence</span><br><span class="line">            </span><br><span class="line"><span class="comment">#åœ¨ä½¿ç”¨çš„æ—¶å€™ï¼š</span></span><br><span class="line">dataset=get_dataset(txt_file)</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#å¦‚æœéœ€è¦è¿˜å¯ä»¥æ”¹æˆlistå½¢å¼</span></span><br><span class="line">dataset=list(get_dataset(txt_file))</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"><a href="#7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹" class="headerlink" title="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"></a>7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹</h3><p>æ ¹æ®rnn_typeåŠ¨æ€åˆ›å»ºå¯¹è±¡å®ä¾‹ï¼Œä½¿ç”¨äº†getattr<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rnn in ['GRU','LSTM','RNN']</span></span><br><span class="line"></span><br><span class="line">self.rnn = getattr(nn, self.rnn_type)(self.embedding_dim, self.hidden_dim, self.num_layers, dropout=self.dropout)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>code snippets</tag>
        <tag>ä»£ç ç‰‡æ®µ</tag>
      </tags>
  </entry>
  <entry>
    <title>æ¯å‘¨è¯—è¯1</title>
    <url>/2018/07/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D1/</url>
    <content><![CDATA[<p>æœ¬å‘¨èƒŒäº†å››ç¯‡ã€‚</p>
<hr>
<p>1ï¸âƒ£</p>
<h3 id="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"><a href="#ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹" class="headerlink" title="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"></a>ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹</h3><p>[å®‹] è‹è½¼<br>å¤œé¥®ä¸œå¡é†’å¤é†‰ï¼Œå½’æ¥å½·å½¿ä¸‰æ›´ã€‚å®¶ç«¥é¼»æ¯å·²é›·é¸£ï¼Œæ•²é—¨éƒ½ä¸åº”ï¼Œå€šæ–å¬æ±Ÿå£°ã€‚<br><strong>é•¿æ¨æ­¤èº«éæˆ‘æœ‰ï¼Œä½•æ—¶å¿˜å´è¥è¥ï¼Ÿ</strong>å¤œé˜‘é£é™ç¸ çº¹å¹³ï¼Œå°èˆŸä»æ­¤é€ï¼Œæ±Ÿæµ·å¯„é¦€ç”Ÿã€‚</p>
<p>ç¸ ï¼ˆhÃºï¼‰çº¹<br>çš‹ï¼ˆgaoï¼‰<br><a href="http://m.xichuangzhu.com/work/57ae79400a2b580063150e39" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ae79400a2b580063150e39</a></p>
<hr>
<p>2ï¸âƒ£</p>
<h3 id="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"><a href="#è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦" class="headerlink" title="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"></a>è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦</h3><p>[æ¸…] ç‹å›½ç»´<br>é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦ã€‚ä¸é“å½’æ¥ï¼Œé›¶è½èŠ±å¦‚è®¸ã€‚èŠ±åº•ç›¸çœ‹æ— ä¸€è¯­ï¼Œç»¿çª—æ˜¥ä¸å¤©ä¿±è«ã€‚<br>å¾…æŠŠç›¸æ€ç¯ä¸‹è¯‰ã€‚ä¸€ç¼•æ–°æ¬¢ï¼Œæ—§æ¨åƒåƒç¼•ã€‚<strong>æœ€æ˜¯äººé—´ç•™ä¸ä½ï¼Œæœ±é¢œè¾é•œèŠ±è¾æ ‘ã€‚</strong></p>
<p><a href="http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17</a></p>
<hr>
<p>3ï¸âƒ£</p>
<h3 id="é€å‹äºº"><a href="#é€å‹äºº" class="headerlink" title="é€å‹äºº"></a>é€å‹äºº</h3><p>[å”] æç™½<br>é’å±±æ¨ªåŒ—éƒ­ï¼Œç™½æ°´ç»•ä¸œåŸã€‚<br>æ­¤åœ°ä¸€ä¸ºåˆ«ï¼Œå­¤è“¬ä¸‡é‡Œå¾ã€‚<br><strong>æµ®äº‘æ¸¸å­æ„ï¼Œè½æ—¥æ•…äººæƒ…ã€‚</strong><br>æŒ¥æ‰‹è‡ªå…¹å»ï¼Œè§è§ç­é©¬é¸£ã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4</a></p>
<hr>
<p>4ï¸âƒ£</p>
<h3 id="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"><a href="#é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ" class="headerlink" title="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"></a>é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ</h3><p>[å”] æç™½<br>æ•…äººè¥¿è¾é»„é¹¤æ¥¼ï¼ŒçƒŸèŠ±ä¸‰æœˆä¸‹æ‰¬å·ã€‚<br>å­¤å¸†è¿œå½±ç¢§ç©ºå°½ï¼Œå”¯è§é•¿æ±Ÿå¤©é™…æµã€‚</p>
<p><a href="http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8</a></p>
]]></content>
      <tags>
        <tag>è¯—è¯</tag>
        <tag>è¯—è¯åˆ†äº«</tag>
      </tags>
  </entry>
  <entry>
    <title>å®‰è£…condaé”™è¯¯</title>
    <url>/2018/07/23/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%AE%89%E8%A3%85conda%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<p>åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…condaçš„æ—¶å€™ï¼Œä¸€å¼€å§‹ä½¿ç”¨äº†pipå®‰è£…<br><code>pip install conda</code><br>åœ¨å®‰è£…å¥½condaä¹‹åæƒ³è¦ä½¿ç”¨condaå‘½ä»¤ï¼Œå‡ºç°ï¼š</p>
<p>ERROR: The install method you used for condaâ€”probably either <code>pip install conda</code> or <code>easy_install conda</code>â€”is not compatible with using conda as an application. If your intention is to install conda as a standalone application, currently supported install methods include the Anaconda installer and the miniconda installer. You can download the miniconda installer from <a href="https://conda.io/miniconda.html" target="_blank" rel="noopener">https://conda.io/miniconda.html</a>.</p>
<p><img src="/images/2018-07-23-15323331261104.jpg" alt=""></p>
<p>ç„¶ååˆ°å®˜ç½‘ä¸‹è½½.shæ–‡ä»¶å¹¶bashå®‰è£…ï¼Œä»ç„¶æ²¡æœ‰è§£å†³è¯¥é—®é¢˜ï¼›æ¥ç€å°è¯•pip uninstall condaï¼Œå‡ºç°<br><img src="/images/2018-07-23-15323337042406.jpg" alt=""></p>
<p>æœ€ååœ¨æŸ¥é˜…äº†ç½‘ä¸Šä¹‹åï¼Œä½¿ç”¨ <code>which conda</code>æ‰¾åˆ°condaçš„åœ°å€ï¼Œå¹¶åˆ é™¤<code>rm Ã—Ã—Ã—</code><br><img src="/images/2018-07-23-15323337894186.jpg" alt=""></p>
<p>æœ€åé‡æ–°bashå®‰è£…å³å¯ã€‚</p>
]]></content>
      <tags>
        <tag>æ‚ä¸ƒæ‚å…«</tag>
        <tag>é‡åˆ°çš„é—®é¢˜</tag>
        <tag>conda</tag>
      </tags>
  </entry>
</search>
