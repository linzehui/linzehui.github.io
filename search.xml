<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>å…³äºPytorchä¸­index_copy_åŠå…¶æ€è€ƒ</title>
      <link href="/2018/12/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADindex_copy_%E5%8F%8A%E5%85%B6%E6%80%9D%E8%80%83/"/>
      <url>/2018/12/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADindex_copy_%E5%8F%8A%E5%85%B6%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥å› ä¸ºin-placeæ“ä½œçš„é—®é¢˜ï¼Œdebugäº†å¥½å‡ å¤©ï¼Œæœ€ç»ˆæ‰å‘ç°é—®é¢˜ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure><p>å› ä¸ºPytorchä¸­pack_sequenceéœ€è¦å°†batchæŒ‰é•¿åº¦æ’åˆ—ï¼Œæˆ‘åœ¨è¿‡å®ŒGRUåéœ€è¦å°†å…¶é¡ºåºè¿˜åŸï¼Œåœ¨è¿™è¾¹sorted_indexå³æ˜¯è®°å½•åŸæ¥indexæ˜ å°„ã€‚</p><p>ç„¶è€Œæˆ‘åœ¨å†™çš„æ—¶å€™ï¼Œå‚è€ƒçš„æ˜¯å®˜æ–¹çš„exampleï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.float)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([<span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.index_copy_(<span class="number">0</span>, index, t)</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>]])</span><br></pre></td></tr></table></figure><p>å› æ­¤æˆ‘ä¹Ÿä¸å‡æ€ç´¢åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy_(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure></p><p>å°±å› ä¸ºå¤šäº†ä¸€ä¸ª_ï¼Œå¯¼è‡´é€»è¾‘å’Œæˆ‘æƒ³è±¡ä¸­çš„ä¸ä¸€æ ·ã€‚</p><p>ä¸€ä¸ªç®€å•çš„ä¾‹å­å±•ç¤ºä¸ºä»€ä¹ˆè¿™ä¹ˆæ˜¯é”™çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.Tensor([<span class="number">21</span>,<span class="number">42</span>,<span class="number">45</span>,<span class="number">59</span>])</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 42., 45., 59.])</span></span><br><span class="line"></span><br><span class="line">index=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">x=x.index_copy_(<span class="number">0</span>,index,x)</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 21., 21., 59.])</span></span><br></pre></td></tr></table></figure><p>ç”±äºæ˜¯in-placeæ“ä½œï¼Œç¬¬ä¸€æ­¥ï¼Œå°†index=0çš„æ•°å€¼ï¼ˆä¹Ÿå³21ï¼‰å¤åˆ¶åˆ°index=1çš„åœ°æ–¹ï¼Œæ­¤æ—¶å˜æˆ[21,21,45,59]ï¼›æ¥ç€å°†index=1çš„æ•°å€¼å¤åˆ¶åˆ°index=2çš„ä½ç½®ä¸Šï¼Œæ³¨æ„åˆ°ä¹‹å‰å·²ç»æ˜¯in-placeæ“ä½œï¼Œå› æ­¤æ­¤æ—¶å–çš„ä¸æ˜¯æƒ³è±¡ä¸­çš„42ï¼Œè€Œæ˜¯å·²ç»è¢«æ›¿æ¢çš„21ã€‚åé¢çš„ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p><p>æ­£ç¡®çš„åšæ³•åªéœ€è¦å»æ‰in-placeå³å¯ã€‚</p><hr><p>å·²ç»å¥½å‡ æ¬¡é‡åˆ°in-placeçš„é—®é¢˜äº†ï¼Œåœ¨æ¯æ¬¡åšin-placeæ“ä½œæ—¶ï¼Œéƒ½è¦è­¦æƒ•ã€‚åº”å°½å¯èƒ½é¿å…in-placeæ“ä½œã€‚å®é™…ä¸ŠPytorchå®˜æ–¹ä¹Ÿä¸å»ºè®®ä½¿ç”¨in-placeæ“ä½œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> index_coopy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•14</title>
      <link href="/2018/12/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9514/"/>
      <url>/2018/12/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9514/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-shuffle-list"><a href="#1ï¸âƒ£-shuffle-list" class="headerlink" title="1ï¸âƒ£[shuffle list]"></a>1ï¸âƒ£[shuffle list]</h3><p>shuffle listå¯ä»¥ä½¿ç”¨randomçš„shuffleå‡½æ•°ï¼Œäº¦å³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">shuffle(l)  <span class="comment"># in place operation</span></span><br></pre></td></tr></table></figure><p>è€Œæƒ³è¦shuffleä¸¤ä¸ªå¯¹åº”listï¼Œä¹Ÿå³ç­‰é•¿ä¸”ä¸€ä¸€å¯¹åº”çš„listï¼Œåˆ™å¯ä»¥ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># borrow from stackoverflow</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(a) == len(b)</span><br><span class="line">    start_state = random.getstate()</span><br><span class="line">    random.shuffle(a)</span><br><span class="line">    random.setstate(start_state)</span><br><span class="line">    random.shuffle(b)</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br><span class="line">b = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">19</span>]</span><br><span class="line">shuffle(a,b)</span><br><span class="line">print(a) <span class="comment"># [9, 7, 3, 1, 2, 5, 4, 8, 6]</span></span><br><span class="line">print(b) <span class="comment"># [19, 17, 13, 11, 12, 15, 14, 18, 16]</span></span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£-inverse-tensor"><a href="#2ï¸âƒ£-inverse-tensor" class="headerlink" title="2ï¸âƒ£[inverse tensor]"></a>2ï¸âƒ£[inverse tensor]</h3><p>Pytorchç›®å‰è¿˜ä¸æ”¯æŒæ­¥è¿›ä¸ºè´Ÿçš„æƒ…å†µï¼Œå› æ­¤ä¸èƒ½ä½¿ç”¨ç±»ä¼¼Pythonçš„<code>l[::-1]</code>çš„æ–¹æ³•reverse tensorã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">inv_idx = torch.arange(tensor.size(<span class="number">0</span>)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>).long()</span><br><span class="line"><span class="comment"># or equivalently torch.range(tensor.size(0)-1, 0, -1).long()</span></span><br><span class="line">inv_tensor = tensor.index_select(<span class="number">0</span>, inv_idx)</span><br><span class="line"><span class="comment"># or equivalently</span></span><br><span class="line">inv_tensor = tensor[inv_idx]</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£-GRU-initialization"><a href="#3ï¸âƒ£-GRU-initialization" class="headerlink" title="3ï¸âƒ£[GRU initialization]"></a>3ï¸âƒ£[GRU initialization]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gru_init</span><span class="params">(self)</span>:</span>   <span class="comment"># use orthogonal seems better</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_ih_l0.data)  <span class="comment">#æ²¡æœ‰dataä¸è¡Œï¼Œä¼šæŠ¥leaf variable in-placeé”™è¯¯ï¼Œå¯èƒ½weight_ih_l0ä¸æ˜¯parameter</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_hh_l0.data)</span><br><span class="line">    self.word_RNN.bias_ih_l0.data.zero_()</span><br><span class="line">    self.word_RNN.bias_hh_l0.data.zero_()</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£-sort-counter"><a href="#4ï¸âƒ£-sort-counter" class="headerlink" title="4ï¸âƒ£[sort counter]"></a>4ï¸âƒ£[sort counter]</h3><p>éœ€æ±‚ï¼šç»Ÿè®¡documentçš„å¥å­ä¸ªæ•°çš„åˆ†å¸ƒï¼Œå¹¶æŒ‰ç…§é•¿åº¦é¡ºåºæ’åˆ—ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_sents=[len(sentences) <span class="keyword">for</span> sentences <span class="keyword">in</span> documents]</span><br><span class="line">n_lengths=Counter(n_sents)</span><br><span class="line">n_lengths=sorted(n_lengths.items())</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†17</title>
      <link href="/2018/12/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8617/"/>
      <url>/2018/12/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8617/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨æœ‰RNNçš„ä»£ç ä¸­ï¼Œå¦‚æœå‡ºç°</p><blockquote><p>Cuda Error : RuntimeError: CUDNN_STATUS_EXECUTION_FAILED</p></blockquote><p>é‚£ä¹ˆå¯èƒ½çš„å‡ºé”™åŸå› æ˜¯æ²¡æœ‰å°†init stateæ”¾å…¥cudaä¸­ã€‚</p><p>Reference: <a href="https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625" target="_blank" rel="noopener">https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>clone() â†’ Tensor<br>Returns a copy of the self tensor. The copy has the same size and data type as self.<br><strong>Unlike copy_(), this function is recorded in the computation graph. Gradients propagating to the cloned tensor will propagate to the original tensor.</strong></p><p>å¦‚æœéœ€è¦å¦ä¸€ä¸ªç›¸åŒçš„tensoråšå…¶ä»–è®¡ç®—ï¼Œåˆ™ä½¿ç”¨clone()è€Œä¸æ˜¯copy_()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">forward_vec=sent_vec</span><br><span class="line"><span class="comment"># backward_vec=sent_vec   wrong</span></span><br><span class="line">backward_vec=sent_vec.clone()</span><br></pre></td></tr></table></figure><p>å½“ç„¶ä¹Ÿä¸èƒ½ç›´æ¥èµ‹å€¼ï¼Œå› ä¸ºèµ‹çš„åªæ˜¯æŒ‡é’ˆï¼Œæ”¹å˜backward_vecä¹Ÿä¼šæ”¹å˜åŸæ¥çš„å€¼ã€‚</p><hr><h3 id="3ï¸âƒ£-Python"><a href="#3ï¸âƒ£-Python" class="headerlink" title="3ï¸âƒ£[Python]"></a>3ï¸âƒ£[Python]</h3><p>Pythonä¸­<code>==</code>å’Œ<code>is</code>çš„åŒºåˆ«ï¼š<br>isè¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªobjectï¼›è€Œ==è¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªå€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str=<span class="string">'GRU'</span></span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str=str.upper()</span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># False</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£-RNN"><a href="#4ï¸âƒ£-RNN" class="headerlink" title="4ï¸âƒ£[RNN]"></a>4ï¸âƒ£[RNN]</h3><p>åœ¨RNNçš„åˆå§‹åŒ–ä¸­ï¼Œä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ä¼šæ¯”å…¶ä»–æ–¹æ³•å¥½ä¸€äº›ï¼ˆå¾…å¯¹æ¯”å®éªŒæµ‹éªŒï¼‰ã€‚<br>Reference: <a href="https://smerity.com/articles/2016/orthogonal_init.html" target="_blank" rel="noopener">https://smerity.com/articles/2016/orthogonal_init.html</a></p><hr><h3 id="5ï¸âƒ£-Pytorch"><a href="#5ï¸âƒ£-Pytorch" class="headerlink" title="5ï¸âƒ£[Pytorch]"></a>5ï¸âƒ£[Pytorch]</h3><p>åœ¨æä¾›é¢„è®­ç»ƒembeddingä½œä¸ºåˆå§‹åŒ–æ—¶ï¼Œæ­£ç¡®åšæ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> pretrained_matrix <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    pretrained_matrix=torch.from_numpy(pretrained_matrix).type(torch.FloatTensor)</span><br><span class="line">    self.embedding.weight= nn.Parameter(pretrained_matrix,</span><br><span class="line">                                                requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>å¿…é¡»è¦æœ‰<code>.type(torch.FloatTensor)</code>ï¼Œå¦åˆ™ä¼šå‡ºé”™ï¼šCuDNN error: CUDNN_STATUS_EXECUTION_FAILED</p><hr><h3 id="6ï¸âƒ£-Pytorch"><a href="#6ï¸âƒ£-Pytorch" class="headerlink" title="6ï¸âƒ£[Pytorch]"></a>6ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ï¼Œå°†åˆå§‹hidden stateä½œä¸ºå¯å­¦ä¹ å‚æ•°å®è·µï¼š<br><a href="https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9" target="_blank" rel="noopener">https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9</a><br><a href="https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7" target="_blank" rel="noopener">https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>A Day with Google</title>
      <link href="/2018/12/23/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/A%20Day%20with%20Google/"/>
      <url>/2018/12/23/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/A%20Day%20with%20Google/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨ä¸€ä¹¡ä¸‹äººç»ˆäºå†æ¬¡è¿›åŸäº†ğŸ™ˆ<br><img src="/images/IMG_2243.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_8631.jpg" width="70%" height="50%"></p><p>æœ¬æ¬¡çš„ç›®çš„æ˜¯æ¥å‚è§‚Googleã€‚</p><p>é«˜æ¥¼æ—ç«‹ï¼š<br><img src="/images/IMG_2273.jpg" width="70%" height="50%"></p><p>Here We are:<br><img src="/images/IMG_9209-1.jpg" width="70%" height="50%"></p><p>å’•æœæ˜¯ä»€ä¹ˆé¬¼ï¼Ÿ<br><img src="/images/IMG_3389.jpg" width="70%" height="50%"></p><p>å®£è®²ï¼š<br><img src="/images/IMG_1782.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_1075.jpg" width="70%" height="50%"></p><p>ä¸å¾—ä¸æ„Ÿæ…¨é£Ÿå ‚çœŸå¥½ğŸ¦†ï¼Œè¿˜æœ‰ä¸“é—¨åƒé¢çš„é£Ÿå ‚ã€‚è€Œä¸”è¿˜éƒ½ä¸ç”¨é’±ğŸ™‰ï¼Œå¯¹æ¯”å¼ æ±Ÿçš„é£Ÿå ‚ğŸ™‰ï¼š</p><p><img src="/images/IMG_0546.jpg" width="70%" height="50%"></p><p>æºœäº†æºœäº†ï¼š<br><img src="/images/IMG_1255.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_1256.jpg" width="70%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Google </tag>
            
            <tag> æ´»åŠ¨ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡10</title>
      <link href="/2018/12/23/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8710/"/>
      <url>/2018/12/23/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8710/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect"><a href="#1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect" class="headerlink" title="1ï¸âƒ£[Regularization of Neural Networks using DropConnect]"></a>1ï¸âƒ£[Regularization of Neural Networks using DropConnect]</h2><p>åœ¨dropoutçš„åŸºç¡€ä¸Šæå‡ºdropconnectã€‚ä¸dropoutä¸åŒçš„æ˜¯ï¼Œdropconnectå¯¹weightè¿›è¡Œdropè€Œä¸æ˜¯å¯¹layerè¿›è¡Œdropã€‚</p><p>åˆ›æ–°ä¹‹å¤„åœ¨äºinferenceçš„æ—¶å€™å’Œdropoutä¸åŒã€‚</p><h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><p><img src="/images/15455297378934.jpg" width="50%" height="50%"></p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><img src="/images/15455297645976.jpg" width="50%" height="50%"></p><p>åœ¨inferenceçš„æ—¶å€™é€šè¿‡é«˜æ–¯é‡‡æ ·çš„æ–¹æ³•å»æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚<br><strong>intuition</strong>ï¼š<br>æœ¬æ–‡å¯¹dropoutåœ¨inferenceç®€å•å¯¹unitè¿›è¡Œç¼©æ”¾è¿›è¡Œåæ€ï¼Œè®¤ä¸ºè¿™åœ¨æ•°å­¦ä¸Šå¹¶ä¸åˆç†ï¼Œå› æ­¤æå‡ºç”¨é«˜æ–¯åˆ†å¸ƒå»é‡‡æ ·ã€‚<br><img src="/images/15455299241433.jpg" width="50%" height="50%"></p><p><img src="/images/15455299403032.jpg" width="50%" height="50%"></p><p><img src="/images/15455299548705.jpg" width="50%" height="50%"></p><hr><h2 id="2ï¸âƒ£-Attentive-Pooling-Networks"><a href="#2ï¸âƒ£-Attentive-Pooling-Networks" class="headerlink" title="2ï¸âƒ£[Attentive Pooling Networks]"></a>2ï¸âƒ£[Attentive Pooling Networks]</h2><p>æå‡ºattentive poolingæœºåˆ¶ï¼Œç”¨ä»¥answer selectionã€‚<br>ï¼ˆä»€ä¹ˆæ˜¯answer selectionï¼šç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œç»™å®šå¤šä¸ªç­”æ¡ˆå€™é€‰ï¼Œè¦ä»ç­”æ¡ˆé€‰é¡¹ä¸­é€‰æ‹©æ­£ç¡®çš„ç­”æ¡ˆã€‚ï¼‰</p><p>ä¼ ç»Ÿanswer selectionï¼š<br><img src="/images/15455301265939.jpg" width="35%" height="50%"><br>é¦–å…ˆå°†è¯è½¬åŒ–æˆè¯å‘é‡ï¼Œæ¥ç€é€šè¿‡bi-LSTMæˆ–CNNè·å¾—ä¸€ä¸ªçŸ©é˜µè¡¨ç¤ºï¼Œæ¥ä¸‹æ¥å¯¹Qå’ŒAåˆ†åˆ«è¿›è¡Œmax-poolingè·å¾—å›ºå®šè¡¨ç¤ºï¼Œæœ€åé€šè¿‡cosè·ç¦»åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ˜¯æ­£ç¡®ç­”æ¡ˆï¼Œä»ç­”æ¡ˆå€™é€‰ä¸­é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ã€‚</p><p>ä½†è¿™æ ·çš„é—®é¢˜åœ¨äºQå’ŒAä¹‹é—´æ²¡æœ‰äº¤äº’ã€‚</p><p>æœ¬æ–‡åˆ©ç”¨attentionä½œä¸ºQå’ŒAçš„äº¤äº’ã€‚<br><img src="/images/15455301891043.jpg" width="39%" height="50%"></p><p>è·å¾—Qå’ŒAçŸ©é˜µçš„æ–¹å¼æ˜¯ä¸€è‡´çš„ã€‚<br>æ¥ä¸‹æ¥ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªGçŸ©é˜µï¼Œé€šè¿‡åŒçº¿æ€§attentionå…¬å¼è·å¾—ï¼š<br><img src="/images/15455302279543.jpg" width="20%" height="50%"></p><p>Gæ‰€ä»£è¡¨çš„æ„ä¹‰æ˜¯Qå’ŒAçš„æ¯ä¸ªè¯ä¹‹é—´çš„å¯¹é½ï¼šå¯¹äºç¬¬iè¡Œæ¥è¯´ï¼Œä»£è¡¨Qçš„ç¬¬iä¸ªè¯å’ŒAä¸­æ‰€æœ‰è¯çš„ä¸€ä¸ªåˆ†æ•°ï¼›å¯¹äºç¬¬jåˆ—æ¥è¯´ï¼Œä»£è¡¨ç¬¬jä¸ªè¯å’ŒQä¸­æ‰€æœ‰è¯çš„åˆ†æ•°ã€‚</p><p>æ¥ä¸‹æ¥å¯¹Gçš„è¡Œå’Œåˆ—åˆ†åˆ«è¿›è¡Œmax-poolingæ“ä½œï¼š<br><img src="/images/15455303089243.jpg" width="25%" height="50%"></p><p>æ­¤æ­¥ä»£è¡¨é€‰æ‹©ä¸æŸè¯å…³ç³»æœ€é‡è¦çš„è¯ã€‚</p><p>æ¥ä¸‹æ¥å¯¹gåˆ†åˆ«è¿›è¡Œsoftmaxï¼Œå†åˆ†åˆ«è¿›è¡Œç‚¹ç§¯ä»¥è·å¾—æœ€ç»ˆå‘é‡è¡¨ç¤ºï¼š<br><img src="/images/15455303516483.jpg" width="13%" height="50%"></p><p>åŒæ ·ï¼Œæœ€ç»ˆä½¿ç”¨cosè·ç¦»è®¡ç®—ç›¸ä¼¼åº¦ã€‚</p><hr><h2 id="3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout"><a href="#3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout" class="headerlink" title="3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]"></a>3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]</h2><p>æ˜¯ä»æ•°æ®å¢å¼ºå’Œdropoutçš„è§’åº¦ï¼š</p><blockquote><p>dropout in convolutional layers simply acts to increase robustness to noisy inputs, rather than having the same model averaging effect that is observed in fully-connected layers</p></blockquote><p>æŸä¸ªè¾“å…¥è¢«ç§»å»ï¼Œæ‰€æœ‰åé¢ç›¸å…³çš„çš„feature mapéƒ½è¢«ç§»å»ï¼š</p><blockquote><p>In this sense, cutout is much closer to data augmentation than dropout, as it is not creating noise, but instead generating images that appear novel to the network</p></blockquote><p>å…¶å®åªæ˜¯å°†è¾“å…¥éšæœºdropæ‰ä¸€å—ã€‚<br><img src="/images/15455304317998.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•13</title>
      <link href="/2018/12/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9513/"/>
      <url>/2018/12/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9513/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-flatten-list"><a href="#1ï¸âƒ£-flatten-list" class="headerlink" title="1ï¸âƒ£[flatten list]"></a>1ï¸âƒ£[flatten list]</h3><p>å¯¹äºŒç»´listè¿›è¡Œå±•å¼€ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list2d = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>], [<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"><span class="comment"># â‘ </span></span><br><span class="line">flatten = [l <span class="keyword">for</span> list <span class="keyword">in</span> list2d <span class="keyword">for</span> l <span class="keyword">in</span> list]</span><br><span class="line"><span class="comment"># â‘¡</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">merged = list(itertools.chain(*list2d))</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">merged = list(itertools.chain.from_iterable(list2d))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†16</title>
      <link href="/2018/12/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8616/"/>
      <url>/2018/12/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8616/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Softmax"><a href="#1ï¸âƒ£-Softmax" class="headerlink" title="1ï¸âƒ£[Softmax]"></a>1ï¸âƒ£[Softmax]</h3><p>åœ¨ä½¿ç”¨softmaxçš„æ—¶å€™ï¼Œè¦éå¸¸æ³¨æ„softmaxçš„è¡Œä¸ºã€‚åº”å°½é‡æ§åˆ¶softmaxå‰å…ƒç´ çš„è§„æ¨¡ï¼Œå¦åˆ™å®¹æ˜“å‡ºç°one-hotçš„æƒ…å†µï¼Œå¯¼è‡´è®­ç»ƒå›°éš¾ã€‚<br><img src="/images/15455275366030.jpg" width="70%" height="50%"></p><p>åŒæ—¶ï¼Œå¯¹å…¨-infåšsoftmaxæ˜¯æœªå®šä¹‰çš„ï¼Œå› æ­¤ä¹Ÿä¼šå‡ºç°é—®é¢˜ï¼š<br><img src="/images/15455278529550.jpg" width="40%" height="50%"></p><hr><h3 id="2ï¸âƒ£-slice"><a href="#2ï¸âƒ£-slice" class="headerlink" title="2ï¸âƒ£[slice]"></a>2ï¸âƒ£[slice]</h3><p>åœ¨å¯¹tensoræˆ–arrayæ“ä½œæ—¶ï¼Œå¦‚æœéœ€è¦å–æŸç»´çš„sliceï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">a[:,<span class="number">1</span>:<span class="number">3</span>]  <span class="comment"># å–ç¬¬1åˆ—åˆ°ç¬¬2åˆ—çš„slice</span></span><br><span class="line">a[:][<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># wrongï¼Œè·å¾—çš„æ˜¯ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„slice</span></span><br></pre></td></tr></table></figure><p>åŸå› æ˜¯ï¼Œ<code>a[:][1:3]</code>æ˜¯å…ˆåš<code>a[:]</code>æ“ä½œï¼Œè·å¾—äº†å…¨éƒ¨å…ƒç´ ï¼Œç„¶åå†åš<code>[1:3]</code>æ“ä½œï¼Œä¹Ÿå³è·å¾—ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„å…ƒç´ ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Softmax </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•12</title>
      <link href="/2018/12/16/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9512/"/>
      <url>/2018/12/16/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9512/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-CUDA-time"><a href="#1ï¸âƒ£-CUDA-time" class="headerlink" title="1ï¸âƒ£[CUDA time]"></a>1ï¸âƒ£[CUDA time]</h3><p>æ­£ç¡®æµ‹è¯•ä»£ç åœ¨cudaè¿è¡Œæ—¶é—´ã€‚éœ€è¦åŠ ä¸Š<code>torch.cuda.synchronize()</code>ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line">b = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">M = torch.bmm(a, b.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"bmm"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">local_a = a.unsqueeze(<span class="number">2</span>)</span><br><span class="line">local_b = b.unsqueeze(<span class="number">1</span>)</span><br><span class="line">N = (local_a*local_b).sum(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"element-wise"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"output difference (should be 0)"</span>, (N - M).abs().max())</span><br><span class="line">print(<span class="string">"In single precision this can fail because of the size of the tensors."</span>)</span><br><span class="line">print(<span class="string">"Using double should always work"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†15</title>
      <link href="/2018/12/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8615/"/>
      <url>/2018/12/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8615/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨0.41çš„pytorchä¸­ï¼Œbernoulliçš„é€Ÿåº¦ä¼šæ¯”éšæœºsampleçš„é€Ÿåº¦æ…¢å¾ˆå¤šï¼›<br>åœ¨1.0ä¸­ä¿®å¤äº†è¯¥bugï¼Œä½†é€Ÿåº¦ä¸Šè¿˜æ˜¯éšæœºsampleå¿«ä¸€ç‚¹ç‚¹ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Pytorch0.41</span><br><span class="line">Bernoulli  0.430371046066</span><br><span class="line">sample  0.24411702156</span><br><span class="line"></span><br><span class="line"># Pytorch1.0</span><br><span class="line">Bernoulli  0.256921529</span><br><span class="line">sample  0.25317035184</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»¥ä¸‹äºŒè€…ç­‰ä»·</span></span><br><span class="line">mask = Bernoulli(gamma).sample(x.size()) <span class="comment"># slow</span></span><br><span class="line">mask = (torch.rand_like(x)&lt;gamma).float() <span class="comment"># faster</span></span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://github.com/pytorch/pytorch/issues/6940" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/6940</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡9</title>
      <link href="/2018/12/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%879/"/>
      <url>/2018/12/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%879/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation"><a href="#1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation" class="headerlink" title="1ï¸âƒ£[Sentence-State LSTM for Text Representation]"></a>1ï¸âƒ£[Sentence-State LSTM for Text Representation]</h2><p>æå‡ºä¸€ç§æ–°å‹çš„encodeå¥å­çš„æ–¹æ³•ã€‚æœ‰ç‚¹ç±»ä¼¼gather-distributeçš„æƒ³æ³•ã€‚</p><p><img src="/images/15449283844319.jpg" width="45%" height="50%"></p><p>æ¯ä¸ªæ—¶é—´æ­¥tæ‰€æœ‰çš„hä¸€èµ·æ›´æ–°ã€‚æ›´æ–°æ–¹å¼æ˜¯ä¸å…¶å·¦å³çš„ç‚¹è¿›è¡Œäº¤äº’ï¼ŒåŒæ—¶ä¸ä¸€ä¸ªglobal representationè¿›è¡Œäº¤äº’ã€‚è¿™æ ·å³è€ƒè™‘äº†localçš„ä¿¡æ¯ä¹Ÿè€ƒè™‘äº†globalçš„ä¿¡æ¯ã€‚æ¯æ¬¡æ›´æ–°éƒ½å¢åŠ äº†ä¿¡æ¯äº¤äº’ï¼Œä»3gramåˆ°5gramå†åˆ°7gramâ€¦</p><p>å…·ä½“æ¥è¯´ï¼š<br>â‘ å¦‚ä½•æ±‚$h_i$<br><img src="/images/15449285619763.jpg" width="45%" height="50%"></p><p>ä»å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„$h_i$ï¼ŒåŒæ—¶è€ƒè™‘å·¦å³ä¸¤ç‚¹ï¼Œä»¥åŠglobalä¿¡æ¯$g$ï¼Œä»¥åŠè¾“å…¥$x$ã€‚</p><p>â‘¡å¦‚ä½•æ±‚g<br><img src="/images/15449286595709.jpg" width="50%" height="50%"></p><p>é€šè¿‡averageåŒæ—¶è€ƒè™‘æ‰€æœ‰çš„è¯ï¼ŒåŒæ—¶è€ƒè™‘è‡ªå·±ä¸Šä¸€ä¸ªçŠ¶æ€ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> Encode </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonä¸­çš„+=æ“ä½œ</title>
      <link href="/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84+=%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84+=%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥åœ¨å†™ä¸€æ®µPytorchä»£ç æ—¶ï¼Œåˆä¸€æ¬¡é‡åˆ°äº†in-placeæ“ä½œçš„é—®é¢˜ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output+=pos  <span class="comment"># posæ˜¯ä¸å¯æ›´æ–°çš„tensorï¼Œoutputæ˜¯å¯æ›´æ–°çš„tensor</span></span><br></pre></td></tr></table></figure><p>ç¨‹åºæŠ¥é”™ï¼šâ€œone of the variables needed for gradient computation has been modified by an inplace operationâ€ã€‚</p><p>æ— æ„ä¸­å°†ä»£ç æ”¹æˆ<code>output=output+pos</code>ï¼Œç¨‹åºå°±ä¸ä¼šæŠ¥é”™äº†ã€‚</p><p>åœ¨æŸ¥é˜…äº†ç›¸å…³èµ„æ–™åï¼Œå°†æˆ‘çš„æ€è€ƒæ•´ç†ä¸‹æ¥ã€‚</p><p>åœ¨Pythonä¸­ï¼Œ<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ä¸åŒçš„ï¼Œå¦‚æœè¢«æ“ä½œæ•°æ²¡æœ‰éƒ¨ç½² â€™<strong>iadd</strong>â€˜æ–¹æ³•ï¼Œåˆ™<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ç­‰ä»·çš„ï¼Œâ€™+=â€˜å¹¶ä¸ä¼šäº§ç”Ÿin-placeæ“ä½œï¼›å½“è¢«æ“ä½œæ•°æœ‰éƒ¨ç½²è¯¥æ–¹æ³•ä¸”æ­£ç¡®éƒ¨ç½²ï¼Œåˆ™æ˜¯ä¼šäº§ç”Ÿin-placeæ“ä½œçš„ã€‚å½“æ²¡æœ‰in-placeæ“ä½œæ—¶ï¼Œ<code>i=i+1</code>è¡¨ç¤ºå¯¹ié‡åˆ†é…ï¼Œä¹Ÿå³iæŒ‡å‘äº†å¦ä¸€ä¸ªç©ºé—´è€Œä¸æ˜¯åŸæ¥çš„ç©ºé—´ã€‚</p><p>æ‰€ä»¥ï¼Œè¿™æ ·çš„ä¾‹å­å°±èƒ½è§£é‡Šæ¸…æ¥šäº†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    a = a + <span class="number">1</span></span><br><span class="line"><span class="comment"># Aå¹¶æ²¡æœ‰è¢«æ”¹å˜</span></span><br><span class="line">B = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">    b += <span class="number">1</span></span><br><span class="line"><span class="comment"># Bè¢«æ”¹å˜äº†</span></span><br></pre></td></tr></table></figure><p>åœ¨Pytorchä¸­ï¼Œä¹Ÿæœ‰éƒ¨ç½²â€™<strong>iadd</strong>()â€˜æ“ä½œï¼Œæ‰€ä»¥å¯¹äº<code>output+=pos</code>ï¼Œoutputå†…éƒ¨çš„å€¼è¢«æ”¹å˜äº†ï¼Œä¹Ÿå³åœ¨è®¡ç®—å›¾ä¸­å¼•å…¥äº†ç¯ï¼Œåœ¨åå‘æ±‚å¯¼æ—¶åˆ™ä¼šå‡ºé”™ã€‚</p><p>å› æ­¤ï¼Œåœ¨Pytorchä¸­ï¼Œåº”å½“é¿å…in-placeçš„æ“ä½œã€‚</p><p>Reference:<br><a href="https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop" target="_blank" rel="noopener">https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡8</title>
      <link href="/2018/12/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%878/"/>
      <url>/2018/12/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%878/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding"><a href="#1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding" class="headerlink" title="1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]"></a>1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]</h2><p>æå‡ºäº†ä¸¤ç§attentionæœºåˆ¶ï¼Œå³ multi-dimentional attentionå’Œdirectional self-attentionï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæå‡ºæœ‰å‘è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼ˆdirectional self-attention network)</p><h3 id="Multi-dimensional-Attention"><a href="#Multi-dimensional-Attention" class="headerlink" title="Multi-dimensional Attention"></a>Multi-dimensional Attention</h3><p>ä¸ä¼ ç»Ÿçš„æ–¹æ³•ä¸åŒçš„æ˜¯ï¼Œå¯¹äºæ¯ä¸ªè¯å¯¹ï¼Œattentionå‡ºæ¥çš„ä¸æ˜¯æ ‡é‡è€Œæ˜¯å‘é‡ã€‚<br><img src="/images/15443239891184.jpg" width="60%" height="50%"></p><p>è®¡ç®—å…¬å¼ï¼š<br><img src="/images/15443240335179.jpg" width="40%" height="50%"></p><p>$f$çš„ç»´åº¦ä¸$q$ç›¸åŒï¼Œæ¯ä¸€ç»´ä»£è¡¨çš„æ˜¯$x_i$åœ¨è¯¥ç»´å¯¹$q$çš„é‡è¦æ€§ã€‚ä¹Ÿå³feature-wiseçš„attentionã€‚å› æ­¤å¯¹äº$q$è€Œè¨€ï¼Œå…¶è·å¾—çš„åŠ æƒæ±‚å’Œå‘é‡ä¸ºï¼š<br><img src="/images/15443241367138.jpg" width="55%" height="50%"></p><p>ä½¿ç”¨feature-wiseçš„attentionèƒ½å¤Ÿè§£å†³ä¸€æ¬¡å¤šä¹‰çš„é—®é¢˜ï¼Œå› ä¸ºèƒ½å¤Ÿè®¡ç®—æ¯ä¸€ç»´çš„é‡è¦æ€§ï¼Œåœ¨ä¸åŒçš„contextä¸‹æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</p><p>å°†å…¶åº”ç”¨äºself-attentionä¸­ï¼Œæœ‰ä¸¤ç§å˜ä½“ï¼š<br>â‘ token2token<br><img src="/images/15443242128118.jpg" width="58%" height="50%"></p><p><img src="/images/15443242249947.jpg" width="20%" height="50%"></p><p>å› æ­¤xåœ¨äº¤äº’å®Œæœ‰ï¼š<br><img src="/images/15443242733208.jpg" width="35%" height="50%"></p><p>â‘¡source2token<br><img src="/images/15443243090328.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³$x_i$æ²¡æœ‰å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ã€‚<br>å¯ç”¨ä½œè·å¾—sentence encodingï¼š<br><img src="/images/15443243968731.jpg" width="20%" height="50%"></p><h3 id="Directional-Self-Attention"><a href="#Directional-Self-Attention" class="headerlink" title="Directional Self-Attention"></a>Directional Self-Attention</h3><p>ä½¿ç”¨maskè¾¾åˆ°æœ‰å‘æ€§è¿™ä¸€ç›®çš„ï¼š<strong>é€šè¿‡maskçŸ©é˜µå°†ä½ç½®/æ–¹å‘ç¼–ç è¿›attentionï¼Œè§£å†³æ—¶åºä¸¢å¤±é—®é¢˜</strong>ã€‚<br>é¦–å…ˆå°†xè¿‡ä¸€å±‚è·å¾—æ–°çš„hè¡¨ç¤ºï¼š<br><img src="/images/15443244421489.jpg" width="27%" height="50%"></p><p>æ¥ç€ä½¿ç”¨token2tokenæ±‚attentionï¼Œè¿™é‡Œä¸ºäº†å‡å°‘å‚æ•°ä½œäº†ä¸€å®šæ”¹åŠ¨ï¼Œå°†Wæ¢æˆcï¼Œtanhæ›¿æ¢Ïƒã€‚<br><img src="/images/15443245099821.jpg" width="53%" height="50%"></p><p>$\textbf{1}$æ˜¯å…¨1çš„å‘é‡ã€‚Må°±æ˜¯maskçŸ©é˜µï¼Œä»£è¡¨iä¸jæ˜¯å¦è¿é€šï¼ŒMaskçŸ©é˜µæœ‰ï¼š<br><img src="/images/15443248745747.jpg" width="28%" height="50%"></p><p><img src="/images/15443248908199.jpg" width="31%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/15443249388350.jpg" width="50%" height="50%"></p><p>é¦–å…ˆmaskæ‰è‡ªå·±ï¼Œç¬¬äºŒï¼šåˆ†åˆ«maskæ‰forwardå’Œbackwardï¼Œç±»ä¼¼biLSTMï¼Œåªå’Œå‰é¢æˆ–åé¢çš„äº¤äº’ã€‚</p><h3 id="Directional-Self-Attention-Network"><a href="#Directional-Self-Attention-Network" class="headerlink" title="Directional Self-Attention Network"></a>Directional Self-Attention Network</h3><p>åœ¨ä¸Šè¿°ä¸¤ä¸ªæ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæ­¤æ—¶å·²è·å¾—äº†ä¸Šä¸‹æ–‡ç›¸å…³çš„$s_i$ï¼Œå†å¼•å…¥fusion gateï¼š<br><img src="/images/15443250617220.jpg" width="45%" height="50%"></p><p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443250338890.jpg" width="50%" height="50%"></p><p>å°†å‰å‘å’Œåå‘çš„è¡¨ç¤ºæ‹¼æ¥èµ·æ¥ï¼Œè·å¾—æœ€ç»ˆçš„è¡¨ç¤º$[u^{fw};u^{bw}]$ï¼š<br><img src="/images/15443251919096.jpg" width="50%" height="50%"></p><p>å¯¹äºæ‰€è·å¾—çš„æ¯ä¸€ä¸ªè¡¨ç¤ºï¼Œé€šè¿‡source2tokenï¼Œè·å¾—æœ€ç»ˆçš„å¥å­è¡¨ç¤ºã€‚</p><p>è¿™ä¸€ç‚¹è®ºæ–‡ä¹Ÿæåˆ°äº†ï¼Œéå¸¸ç±»ä¼¼bi-LSTMã€‚</p><hr><h2 id="2ï¸âƒ£-Targeted-Dropout"><a href="#2ï¸âƒ£-Targeted-Dropout" class="headerlink" title="2ï¸âƒ£[Targeted Dropout]"></a>2ï¸âƒ£[Targeted Dropout]</h2><p>ä¸€ç§ç½‘ç»œå‰ªææ–¹æ³•ï¼Œæƒ³æ³•ç®€å•æ˜“å®ç°ã€‚<br>ç®€å•è¯´ï¼Œåœ¨æ¯æ¬¡æ›´æ–°æ—¶å¯¹æœ€ä¸é‡è¦çš„weightæˆ–è€…unitè¿›è¡Œéšæœºdropoutã€‚</p><h3 id="Targeted-Dropout"><a href="#Targeted-Dropout" class="headerlink" title="Targeted Dropout"></a>Targeted Dropout</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>ç»™å®šè¾“å…¥Xï¼Œæƒé‡Wï¼Œè¾“å‡ºY Mä¸ºdropoutçš„maskçŸ©é˜µã€‚<br>unit dropoutï¼š<br><img src="/images/15443218016315.jpg" width="22%" height="50%"></p><p>weight dropoutï¼š<br><img src="/images/15443218315803.jpg" width="22%" height="50%"></p><p>ä¹Ÿå³dropæ‰çš„æ˜¯layerä¹‹é—´çš„connectionã€‚</p><h4 id="Magnitude-based-pruning"><a href="#Magnitude-based-pruning" class="headerlink" title="Magnitude-based pruning"></a>Magnitude-based pruning</h4><p>å‰ªæé€šå¸¸å¯¹æƒé‡æœ€å°çš„è¿›è¡Œå‰ªæï¼Œä¹Ÿå³ä¿ç•™topkä¸ªæœ€å¤§çš„æƒé‡ã€‚</p><p>Unit pruningï¼šç›´æ¥å‰ªæ‰çš„æ˜¯ä¸€æ•´åˆ—ï¼Œä¹Ÿå³ä¸€ä¸ªunit<br><img src="/images/15443218793541.jpg" width="43%" height="50%"></p><p>Weight pruningï¼šå¯¹Wçš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå‰ªæã€‚æ³¨æ„æ˜¯å¯¹æ¯è¡Œçš„topkè¿›è¡Œä¿ç•™<br><img src="/images/15443219325533.jpg" width="58%" height="50%"></p><p>å¯ä»¥ç†è§£æˆå¯¹ä¸€ä¸ªunitæ¥è¯´ï¼Œä¿ç•™æœ€é«˜çš„kä¸ªconnectionã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>ç»“åˆdropoutå’Œå‰ªæã€‚<br>ä¸»è¦æ€æƒ³ï¼šé¦–å…ˆé€‰æ‹©N-kæœ€ä¸é‡è¦çš„elementï¼Œç”±äºæˆ‘ä»¬å¸Œæœ›è¿™äº›low-valueçš„å…ƒç´ æœ‰æœºä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜å¾—é‡è¦ï¼Œå› æ­¤æˆ‘ä»¬å¯¹è¿™äº›elementè¿›è¡Œéšæœºdropoutã€‚</p><p>å¼•å…¥targeting proportion Î³å’Œdrop probability Î±ï¼Œäº¦å³ï¼šé€‰æ‹©æœ€ä½çš„Î³|Î¸|ä¸ªweightï¼Œå†æ ¹æ®Î±è¿›è¡Œdropoutã€‚<br>è¿™æ ·åšçš„ç»“æœæ˜¯ï¼šå‡å°‘é‡è¦çš„å­ç½‘ç»œå¯¹ä¸é‡è¦çš„å­ç½‘ç»œçš„ä¾èµ–ã€‚</p><h3 id="é™„å½•"><a href="#é™„å½•" class="headerlink" title="é™„å½•"></a>é™„å½•</h3><p>â‘ dropoutçš„intuitionï¼šå‡å°‘unitä¹‹é—´çš„ç›¸äº’é€‚åº”ã€‚when dropout is applied to a unit, the remaining network can no longer depend on that unitâ€™s contribution to the function and must learn to propagate that unitâ€™s information through a more reliable channelã€‚<br>ä¹Ÿå¯ä»¥ç†è§£æˆï¼šä½¿å¾—unitä¹‹é—´çš„äº¤äº’ä¿¡æ¯è¾¾åˆ°æœ€å¤§ï¼Œåœ¨å¤±å»æŸä¸ªunitçš„æ—¶å€™å½±å“ä¸ä¼šé‚£ä¹ˆå¤§ã€‚</p><p>â‘¡targeted dropout intuitionï¼šthe important subnetwork is completely separated from the unimportant oneã€‚å‡è®¾ä¸€ä¸ªç½‘ç»œç”±ä¸¤ä¸ªä¸ç›¸äº¤çš„å­ç½‘ç»œç»„æˆï¼Œæ¯ä¸ªéƒ½èƒ½è¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œæ€»çš„ç½‘ç»œæ˜¯è¿™ä¸¤ä¸ªç½‘ç»œçš„å¹³å‡ã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸é‡è¦çš„å­ç½‘ç»œè¿›è¡Œdropoutï¼ˆä¹Ÿå³å¾€å­ç½‘ç»œé‡ŒåŠ noiseï¼Œä¼šç ´åè¯¥å­ç½‘ç»œçš„è¾“å‡ºï¼Œç”±äºé‡è¦çš„å­ç½‘ç»œå·²ç»èƒ½å¤Ÿè¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œå› æ­¤ä¸ºäº†å‡å°‘æŸå¤±ï¼Œæˆ‘ä»¬éœ€è¦å‡å°‘ä¸é‡è¦ç½‘ç»œçš„è¾“å‡ºåˆ°0ï¼Œä¹Ÿå³killæ‰è¯¥å­ç½‘ç»œï¼Œå¹¶ä¸”åŠ å¼ºè¿™ä¸¤ä¸ªç½‘ç»œçš„åˆ†ç¦»ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥èˆå¼ƒå‘¢ï¼Ÿå› ä¸ºæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ‰å¯èƒ½ä¼šæœ‰å˜åŒ–ï¼‰<br>è¿™ä¸ªè§£é‡Šè¿˜æ˜¯æ²¡å®Œå…¨æ‡‚ã€‚</p><hr><h2 id="3ï¸âƒ£-A2-Nets-Double-Attention-Networks"><a href="#3ï¸âƒ£-A2-Nets-Double-Attention-Networks" class="headerlink" title="3ï¸âƒ£[A2-Nets: Double Attention Networks]"></a>3ï¸âƒ£[A2-Nets: Double Attention Networks]</h2><p>å‘è¡¨äºNIPS2018ï¼Œä¸ªäººè®¤ä¸ºå¾ˆæœ‰å¯å‘ã€‚æå‡ºä¸€ç§æ–°çš„attentionæœºåˆ¶ï¼ŒåŸºäºâ€œæ”¶é›†-åˆ†å‘â€çš„æ€æƒ³ï¼Œèƒ½å¤Ÿè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>CNNæœ¬èº«ä¸»è¦æ˜¯æ•è·å±€éƒ¨ç‰¹å¾ä¸å…³ç³»ï¼Œä½†å¯¹äºé•¿è·ç¦»ä¹‹é—´çš„å…³ç³»åªèƒ½é€šè¿‡å †å å¤šå‡ å±‚æ‰èƒ½å®ç°ã€‚ä½†è¿™æ ·éœ€è¦æ›´é«˜çš„è®¡ç®—é‡ï¼Œä¸”å®¹æ˜“è¿‡æ‹Ÿåˆï¼›åŒæ—¶ï¼Œè¿œå¤„çš„ç‰¹å¾å®é™…ä¸Šæ˜¯æ¥è‡ªå¥½å‡ å±‚çš„å»¶è¿Ÿï¼Œå¯¼è‡´æ¨ç†çš„å›°éš¾ã€‚</p><p>é€šè¿‡å°†featureæ”¶é›†èµ·æ¥ï¼Œç„¶ååˆ†å‘ä¸‹å»ï¼Œä½¿å¾—featureä¹‹é—´æœ‰äº¤äº’ï¼Œè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œèƒ½å¤Ÿæ•è·é•¿è·ç¦»çš„ç‰¹å¾ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15443223814542.jpg" width="80%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/15443224194279.jpg" width="34%" height="50%"></p><p>Xæ˜¯æ‰€æœ‰è¾“å…¥ï¼Œ$v_iæ˜¯$local featureã€‚</p><h4 id="The-First-Attention-Step-Feature-Gathering"><a href="#The-First-Attention-Step-Feature-Gathering" class="headerlink" title="The First Attention Step: Feature Gathering"></a>The First Attention Step: Feature Gathering</h4><p>å¯¹äºä¸¤ä¸ªfeature map A,Bï¼Œæœ‰ï¼š<br><img src="/images/15443225280678.jpg" width="40%" height="50%"></p><p>å…¶ä¸­ï¼š<br><img src="/images/15443226145868.jpg" width="35%" height="50%"></p><p><img src="/images/15443226262919.jpg" width="35%" height="50%"></p><p>å¦‚æœAã€Béƒ½æ¥è‡ªåŒä¸€ä¸ªXï¼Œå°†Bå½’ä¸€åŒ–softmaxï¼Œå°±ç±»ä¼¼transformerçš„attentionã€‚å…¶ä¸­ä¸Šå¼çš„æœ€å³è¾¹æ˜¯å¤–ç§¯çš„å½¢å¼ã€‚</p><p>æˆ‘ä»¬å°†Gæ‹†åˆ†æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/15443226708983.jpg" width="33%" height="50%"><br>åŒæ—¶å°†Bé‡å†™æˆè¡Œå‘é‡å½¢å¼ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15443227241595.jpg" width="22%" height="50%"></p><p>åˆ™ä¼šæœ‰ï¼š<br><img src="/images/15443227868015.jpg" width="28%" height="50%"></p><p>ä¸Šå¼è®©æˆ‘ä»¬æœ‰ä¸€ä¸ªæ–°çš„ç†è§£è§’åº¦ï¼šGå®é™…ä¸Šå°±æ˜¯ a bag of visual primitivesã€‚æ¯ä¸ª$g_i$æ˜¯æ‰€æœ‰local featureåŠ æƒæ±‚å’Œï¼Œå…¶ä¸­$b_i$æ˜¯æ±‚å’Œçš„weightã€‚</p><p>å› æ­¤æˆ‘ä»¬å¯¹Båšsoftmaxï¼Œä¿è¯æƒé‡ä¸º1ï¼š<br><img src="/images/15443228682403.jpg" width="28%" height="50%"></p><h4 id="The-Second-Attention-Step-Feature-Distribution"><a href="#The-Second-Attention-Step-Feature-Distribution" class="headerlink" title="The Second Attention Step: Feature Distribution"></a>The Second Attention Step: Feature Distribution</h4><p>åœ¨è·å¾—äº†å…¨å±€çš„feature Gåï¼Œç°åœ¨æ ¹æ®local featureå»è·å–å…¨å±€featureçš„éƒ¨åˆ†ï¼Œè¿™é€šè¿‡ä¸€ä¸ªæƒé‡æ§åˆ¶ï¼Œä¹Ÿå³$v_i$ï¼ˆlocal feature)çš„æ¯ä¸€ç»´ä½œä¸ºæƒé‡ã€‚å¯ä»¥ä¸å°†local feature $v_i$å½’ä¸€åŒ–ï¼Œä½†å½’ä¸€åŒ–èƒ½æ›´å¥½åœ°convergeã€‚</p><h4 id="The-Double-Attention-Block"><a href="#The-Double-Attention-Block" class="headerlink" title="The Double Attention Block"></a>The Double Attention Block</h4><p>æœ€ç»ˆå¾—åˆ°double attention blockï¼š<br><img src="/images/15443230115907.jpg" width="68%" height="50%"></p><p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443230641691.jpg" width="80%" height="50%"></p><p>æ‰€ä»¥å…¶å®æ˜¯æœ‰ä¸‰ä¸ªconvolution layerã€‚</p><p>ä¸Šå¼è¿˜å¯ä»¥å†™æˆï¼š<br><img src="/images/15443232642402.jpg" width="70%" height="50%"><br>æ•°å­¦ä¸Šç­‰ä»·ï¼Œä½†è®¡ç®—ä¸Šå·®å¾ˆå¤šã€‚ç¬¬ä¸€ä¸ªå¼å­ä¼šæœ‰æ›´ä½çš„å¤æ‚åº¦ã€‚</p><h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>è™½ç„¶ç”¨äº†attentionï¼Œä½†è¿™é‡Œå’ŒTransformerè¿˜æ˜¯æœ‰éå¸¸å¤§çš„åŒºåˆ«çš„ã€‚Transformeræ¯ä¸ªå…ƒç´ éƒ½å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ï¼Œé€šè¿‡ç›´æ¥çš„è®¡ç®—å¾—åˆ°æƒé‡ã€‚è€Œè¿™è¾¹çš„æƒé‡ç”±featureæœ¬èº«æ¥å†³å®šã€‚å¹¶æ²¡æœ‰ç›´æ¥çš„äº¤äº’ã€‚</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> DiSAN </tag>
            
            <tag> Dropout </tag>
            
            <tag> Targeted Dropout </tag>
            
            <tag> double attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†14</title>
      <link href="/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8614/"/>
      <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8614/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchçš„tensorå’ŒTensoræ˜¯æœ‰åŒºåˆ«çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯æ ‡é‡ï¼Œsizeä¸º[]</span></span><br><span class="line">b = torch.Tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯å‘é‡ï¼Œsizeä¸º[2]</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯17</title>
      <link href="/2018/12/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D17/"/>
      <url>/2018/12/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D17/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è™ç¾äºº"><a href="#1ï¸âƒ£è™ç¾äºº" class="headerlink" title="1ï¸âƒ£è™ç¾äºº"></a>1ï¸âƒ£è™ç¾äºº</h3><p>[å®‹] å¶æ¢¦å¾—<br>è½èŠ±å·²ä½œé£å‰èˆï¼Œåˆé€é»„æ˜é›¨ã€‚æ™“æ¥åº­é™¢åŠæ®‹çº¢ï¼ŒæƒŸæœ‰æ¸¸ä¸ï¼Œåƒä¸ˆè¢…æ™´ç©ºã€‚<br>æ®·å‹¤èŠ±ä¸‹åŒæºæ‰‹ï¼Œæ›´å°½æ¯ä¸­é…’ã€‚ç¾äººä¸ç”¨æ•›è›¾çœ‰ï¼Œ<strong>æˆ‘äº¦å¤šæƒ…ï¼Œæ— å¥ˆé…’é˜‘æ—¶</strong>ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†13</title>
      <link href="/2018/12/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8613/"/>
      <url>/2018/12/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8613/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-attention"><a href="#1ï¸âƒ£-attention" class="headerlink" title="1ï¸âƒ£[attention]"></a>1ï¸âƒ£[attention]</h3><p>æ‰€æœ‰attentionçš„æ€»ç»“ï¼š<br><img src="/images/15437180657954.jpg" width="70%" height="50%"><br><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention!</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>â‘ torch.no_gradèƒ½å¤Ÿæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œmodel.evalä¸èƒ½ã€‚å› ä¸ºevalä¸ä¼šå…³é—­å†å²è¿½è¸ªã€‚</p><blockquote><p>model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval model instead of training mode.<br>torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).</p></blockquote><p>Reference:<br><a href="https://discuss.pytorch.org/t/does-model-eval-with-torch-set-grad-enabled-is-train-have-the-same-effect-for-grad-history/17183/3" target="_blank" rel="noopener">Does model.eval() &amp; with torch.set_grad_enabled(is_train) have the same effect for grad history?</a></p><p><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615" target="_blank" rel="noopener">â€˜model.eval()â€™ vs â€˜with torch.no_grad()â€™</a></p><p>â‘¡torch.full(â€¦) returns a tensor filled with value.</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•11</title>
      <link href="/2018/12/02/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9511/"/>
      <url>/2018/12/02/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9511/</url>
      
        <content type="html"><![CDATA[<h2 id="â‘ "><a href="#â‘ " class="headerlink" title="â‘ "></a>â‘ </h2><p>éœ€æ±‚ï¼šå¯¹äºä¸¤ä¸ªå‘é‡$a$ã€$b$ï¼Œ$a,b \in R^d$ï¼Œå®šä¹‰ä¸€ç§å‡æ³•ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">a-b=M</script><p>å…¶ä¸­$M \in R^{d\times d}$ï¼Œ$M_{ij}=a_i-b_j$</p><p>åœ¨ä»£ç ä¸­å®é™…çš„ç»´åº¦ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(batch_size,sequence_len,dim)</span><br><span class="line">b=torch.rand(batch_size,sequence_len,dim)</span><br></pre></td></tr></table></figure><p>æ–¹æ³•â‘ ï¼šforå¾ªç¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">M=torch.zeros(bz,seq_len,seq_len)</span><br><span class="line"><span class="keyword">for</span> b_i <span class="keyword">in</span> range(bz):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(seq_len):</span><br><span class="line">            M_ij=torch.norm(a[b_i][i]-b[b_i][j])</span><br><span class="line">            M[b][i][j]=M_ij</span><br></pre></td></tr></table></figure><p>æ–¹æ³•â‘¡ï¼šçŸ©é˜µè¿ç®—</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=a.unsqueeze(<span class="number">2</span>)  <span class="comment"># bz,seq_len,1,dim</span></span><br><span class="line">b=b.unsqueeze(<span class="number">1</span>)  <span class="comment"># bz,1,seq_lens,dim</span></span><br><span class="line">M=torch.norm(a-b,dim=<span class="number">-1</span>)   <span class="comment"># will broadcast</span></span><br></pre></td></tr></table></figure><hr><h2 id="â‘¡"><a href="#â‘¡" class="headerlink" title="â‘¡"></a>â‘¡</h2><p>éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªmaskçŸ©é˜µï¼Œæ¯ä¸€è¡Œæœ‰ä¸€æ®µè¿ç»­çš„ä½ç½®å¡«å……1ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¡«å……1çš„å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®éƒ½ä¸åŒã€‚å…·ä½“æ¥è¯´ï¼Œå…ˆç”Ÿæˆä¸€ä¸ªä¸­å¿ƒä½ç½®centerï¼Œåˆ™å¼€å§‹ä½ç½®ä¸ºcenter-windowï¼›ç»“æŸä½ç½®ä¸ºcenter+windowã€‚å…¶ä¸­å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®ä¸èƒ½è¶Šç•Œï¼Œä¹Ÿå³ä¸å°äº0å’Œå¤§äºè¡Œçš„æ€»é•¿åº¦ã€‚<br>å¦‚ï¼š<br><img src="/images/15437208061953.jpg" width="25%" height="50%"></p><p>æ€è·¯ï¼š<br>â‘ å…ˆç”Ÿæˆnè¡Œæ¯è¡Œå¯¹åº”çš„éšæœºä¸­å¿ƒä½ç½®ï¼Œç„¶åå†è·å¾—å·¦å’Œå³è¾¹ç•Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">centers=torch.randint(low=<span class="number">0</span>,high=query_len,size=(query_len,),dtype=torch.long)</span><br><span class="line"></span><br><span class="line">left=centers-self.window</span><br><span class="line">left=torch.max(left,torch.LongTensor([<span class="number">0</span>])).unsqueeze(<span class="number">1</span>)   <span class="comment"># query_len,1</span></span><br><span class="line"></span><br><span class="line">right=centers+self.window</span><br><span class="line">right=torch.min(right,torch.LongTensor([query_len<span class="number">-1</span>])).unsqueeze(<span class="number">1</span>)  <span class="comment"># query_len,1</span></span><br></pre></td></tr></table></figure><p>â‘¡ç”Ÿæˆä¸€ä¸ªæ¯è¡Œéƒ½ç”¨[0,n-1]å¡«å……çš„çŸ©é˜µï¼Œ[0,n-1]è¡¨ç¤ºçš„æ˜¯è¯¥å…ƒç´ çš„indexï¼Œäº¦å³ï¼š<br><img src="/images/15437212363142.jpg" width="25%" height="50%"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br></pre></td></tr></table></figure><p>â‘¢åˆ©ç”¨&lt;=å’Œ&gt;=è·å¾—ä¸€ä¸ªå·¦è¾¹ç•Œå’Œå³è¾¹ç•ŒçŸ©é˜µï¼Œå·¦è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å·¦è¾¹ç•Œçš„å·¦è¾¹éƒ½æ˜¯å¡«å……çš„1ï¼›å³è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å³è¾¹ç•Œå³è¾¹éƒ½æ˜¯å¡«å……çš„1ã€‚å†è¿›è¡Œå¼‚æˆ–æ“ä½œã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br><span class="line">left_matrix=range_matrix&lt;=left</span><br><span class="line">right_matrix=range_matrix&lt;=right</span><br><span class="line">final_matrix=left_matrix^right_matrix</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡7</title>
      <link href="/2018/12/02/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%877/"/>
      <url>/2018/12/02/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%877/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Convolutional-Self-Attention-Network"><a href="#1ï¸âƒ£-Convolutional-Self-Attention-Network" class="headerlink" title="1ï¸âƒ£[Convolutional Self-Attention Network]"></a>1ï¸âƒ£[Convolutional Self-Attention Network]</h2><p>å¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œå¼•å…¥CNNçš„local-biasï¼Œä¹Ÿå³å¯¹queryçš„é‚»è¿‘è¯è¿›è¡Œattentionè€Œä¸æ˜¯æ‰€æœ‰è¯ï¼›å°†self-attentionæ‰©å±•åˆ°2Dï¼Œä¹Ÿå³è®©ä¸åŒçš„headä¹‹é—´ä¹Ÿæœ‰attentionäº¤äº’ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£the normalization in Softmax may inhibits the attention to neighboring information ä¹Ÿå³é‚»å±…çš„ä¿¡æ¯æ›´é‡è¦ï¼Œè¦åŠ å¼ºé‚»å±…çš„é‡è¦æ€§</p><p>2ï¸âƒ£features can be better captured by modeling dependencies across different channels å¯¹äºä¸åŒçš„channel/headä¹Ÿå¢åŠ ä»–ä»¬ä¹‹é—´çš„äº¤äº’ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15437126353758.jpg" width="80%" height="50%"></p><p>å¯¹äº1Dçš„convolutionï¼šé€‰å–ä¸­å¿ƒè¯å‘¨å›´ä¸€ä¸ªwindowï¼š<br><img src="/images/15437128149700.jpg" width="28%" height="50%"></p><p>å¯¹äº2Dçš„convolutionï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15437128476725.jpg" width="45%" height="50%"></p><p>åœ¨å…·ä½“å®è·µä¸­ï¼Œåªå¯¹å‰ä¸‰å±‚æ·»åŠ local biasï¼Œè¿™æ˜¯å› ä¸ºmodeling localityåœ¨åº•å±‚æ›´æœ‰æ•ˆï¼Œå¯¹äºé«˜å±‚åº”è¯¥æ•è·æ›´è¿œçš„ä¿¡æ¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks"><a href="#2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks" class="headerlink" title="2ï¸âƒ£[Modeling Localness for Self-Attention Networks]"></a>2ï¸âƒ£[Modeling Localness for Self-Attention Networks]</h2><p>å’Œä¸Šæ–‡ä¸€æ ·ï¼Œå¼•å…¥local biaså¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œä»è€Œæå‡äº†ç¿»è¯‘è¡¨ç°ã€‚å’Œä¸Šæ–‡æ˜¯åŒä¸€ä½œè€…ï¼Œå‘åœ¨EMNLPä¸Šã€‚</p><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£self-attentionå­˜åœ¨çš„é—®é¢˜ï¼šè™½ç„¶èƒ½å¤Ÿå¢åŠ é•¿ç¨‹å…³æ³¨ï¼Œä½†å› æ­¤ä¼šå¯¼è‡´æ³¨æ„åŠ›çš„åˆ†æ•£ï¼Œå¯¹é‚»å±…çš„ä¿¡å·ä¼šå¿½ç•¥ã€‚å®è·µè¯æ˜ï¼Œå¯¹local biaså»ºæ¨¡åœ¨self-attentionæœ‰æå‡ã€‚</p><p>2ï¸âƒ£ä»ç›´è§‰ä¸Šæ¥è¯´ï¼Œåœ¨ç¿»è¯‘æ¨¡å‹ä¸­ï¼Œå½“ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jæœ‰å¯¹é½å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›è¯ièƒ½åŒæ—¶å¯¹è¯jå‘¨å›´çš„è¯è¿›è¡Œå¯¹é½ï¼Œä½¿å¾—èƒ½å¤Ÿæ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚phraseçš„ä¿¡æ¯ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åœ¨åŸæ¥çš„å…¬å¼ä¸Šæ·»åŠ Gï¼š<br><img src="/images/15437133932791.jpg" width="45%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/15437134105761.jpg" width="70%" height="50%"></p><p>Gæ˜¯ä¸€ä¸ªalignment position matrixï¼ˆå¯¹é½ä½ç½®çŸ©é˜µï¼‰ï¼Œå…ƒç´ ijä»£è¡¨ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jä¹‹é—´çš„ç´§å¯†ç¨‹åº¦ã€‚<br>æˆ‘ä»¬æ¯æ¬¡æ ¹æ®ç›®æ ‡è¯ié¢„æµ‹ä¸€ä¸ªæºè¯­è¨€çš„ä¸­å¿ƒè¯ï¼Œåˆ™$G_{ij}$åˆ™ä¸ºï¼š</p><p><img src="/images/15437135769000.jpg" width="23%" height="50%"></p><p>$P_i$å°±æ˜¯å¯¹äºç›®æ ‡è¯jè€Œè¨€æºè¯­è¨€çš„ä¸­å¿ƒè¯ã€‚ $\sigma$ æ‰‹åŠ¨è®¾å®šï¼Œé€šå¸¸æ˜¯$\frac{D}{2}$ï¼ŒDä»£è¡¨çª—å£å¤§å°ã€‚</p><p>ä¹Ÿå³æœ€ç»ˆæˆ‘ä»¬éœ€è¦è®¡ç®—çš„æ˜¯ï¼Œä¸­å¿ƒè¯$P_i$å’Œçª—å£$D$ã€‚</p><h4 id="è®¡ç®—-P-i"><a href="#è®¡ç®—-P-i" class="headerlink" title="è®¡ç®—$P_i$"></a>è®¡ç®—$P_i$</h4><p>åˆ©ç”¨å¯¹åº”çš„ç›®æ ‡è¯içš„queryå³å¯ï¼š<br><img src="/images/15437138514005.jpg" width="28%" height="50%"><br>$p_i$æ˜¯ä¸€ä¸ªå®æ•°ã€‚</p><h4 id="è®¡ç®—window-size"><a href="#è®¡ç®—window-size" class="headerlink" title="è®¡ç®—window size"></a>è®¡ç®—window size</h4><p>â‘ å›ºå®šçª—å£ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªè¶…å‚ã€‚</p><p>â‘¡Layer-Speciï¬c Window<br>å°†è¯¥å±‚æ‰€æœ‰çš„keyå¹³å‡ï¼Œè®¡ç®—å‡ºä¸€ä¸ªå…±äº«çš„window sizeï¼š<br><img src="/images/15437139914993.jpg" width="28%" height="50%"></p><p>â‘¢Query-Speciï¬c Window<br>æ¯ä¸ªqueryéƒ½æœ‰è‡ªå·±çš„window size<br><img src="/images/15437140367683.jpg" width="30%" height="50%"></p><h3 id="å®éªŒåˆ†æä¸ç»“è®º"><a href="#å®éªŒåˆ†æä¸ç»“è®º" class="headerlink" title="å®éªŒåˆ†æä¸ç»“è®º"></a>å®éªŒåˆ†æä¸ç»“è®º</h3><p>â‘ å°†model localityç”¨äºä½å±‚æ•ˆæœä¼šæ›´å¥½ï¼Œè¿™æ˜¯å› ä¸ºä½å±‚å¯¹ç›¸é‚»å»ºæ¨¡ï¼Œè€Œè¶Šé«˜å±‚è¶Šå…³æ³¨æ›´è¿œçš„è¯ã€‚</p><p><img src="/images/15437141387365.jpg" width="50%" height="50%"></p><p>â‘¡å°†model localityæ”¾åœ¨encoderå’Œencoder-decoderéƒ¨åˆ†ä¼šæ›´å¥½ï¼ˆtransformeræœ‰ä¸‰ä¸ªåœ°æ–¹å¯ä»¥æ”¾ï¼‰</p><p><img src="/images/15437141719564.jpg" width="50%" height="50%"><br>å› ä¸ºdecoderæœ¬èº«å°±å€¾å‘å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œå¦‚æœç»§ç»­è®©å…¶å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œé‚£ä¹ˆå°±éš¾ä»¥è¿›è¡Œé•¿ç¨‹å»ºæ¨¡ã€‚</p><p>â‘¢è¶Šé«˜å±‚ï¼Œwindow sizeï¼ˆscopeï¼‰è¶Šå¤§ã€‚</p><p><img src="/images/15437142078121.jpg" width="70%" height="50%"></p><p>ä¹Ÿå³ï¼Œåœ¨åº•å±‚æ›´å€¾å‘äºæ•è·é‚»è¿‘è¯çš„è¯­ä¹‰ï¼›è€Œé«˜å±‚å€¾å‘æ•è·é•¿ç¨‹ä¾èµ–ã€‚ä½†è¿™ä¸åŒ…æ‹¬ç¬¬ä¸€å±‚ï¼Œç¬¬ä¸€å±‚æ˜¯embeddingï¼Œè¿˜æ²¡æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤å€¾å‘äºæ•è·å…¨å±€ä¿¡æ¯ã€‚</p><hr><h2 id="3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation"><a href="#3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation" class="headerlink" title="3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]"></a>3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]</h2><p>æå‡ºä¸¤ç§attentionæœºåˆ¶çš„ç¿»è¯‘æ¨¡å‹ï¼Œglobalå’Œlocalã€‚</p><p>æœ¬æ–‡ä¸åŸç‰ˆçš„ç¿»è¯‘æ¨¡å‹ç•¥æœ‰ä¸åŒï¼š<br><img src="/images/15437143753188.jpg" width="40%" height="50%"><br><img src="/images/15437143893418.jpg" width="30%" height="50%"></p><p>cæ˜¯contextï¼Œhæ˜¯decodeçš„éšå±‚ã€‚</p><h3 id="global-attention"><a href="#global-attention" class="headerlink" title="global attention"></a>global attention</h3><p><img src="/images/15437144396133.jpg" width="45%" height="50%"></p><p>è®¡ç®—attentionåˆ†æ•°ï¼š<br><img src="/images/15437145076271.jpg" width="40%" height="50%"></p><p>scoreæœ‰å¤šç§é€‰æ‹©ï¼š<br><img src="/images/15437145588496.jpg" width="52%" height="50%"></p><p>æ³¨æ„åˆ°è¯¥æ¨¡å‹ä¸ç¬¬ä¸€ä¸ªæå‡ºattention basedçš„æ¨¡å‹ä¸åŒä¹‹å¤„ï¼š<br>$h_t -&gt; a_t -&gt; c_t -&gt; \tilde{h_t}$<br>åŸç‰ˆæ˜¯ï¼š<br>$h_{t-1} -&gt; a_t -&gt; c_t -&gt; h_t$</p><h3 id="local-attention"><a href="#local-attention" class="headerlink" title="local attention"></a>local attention</h3><p><img src="/images/15437147612512.jpg" width="45%" height="50%"></p><p>ç”±äºglobal attentionè®¡ç®—ä»£ä»·é«˜ï¼Œä¸”å¯¹äºé•¿å¥æ•ˆæœä¸å¥½ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€éƒ¨åˆ†æ¥åšattentionã€‚<br>é¦–å…ˆç”Ÿæˆä¸€ä¸ªå¯¹é½ä½ç½®$p_t$ï¼Œå†é€‰æ‹©ä¸€ä¸ªçª—å£$[p_t - D,p_t + D]$ï¼Œå…¶ä¸­Dæ˜¯è¶…å‚ã€‚</p><p>å¦‚ä½•è·å¾—$p_t$?<br>â‘ ç›´æ¥å‡è®¾$p_t=t$ï¼Œä¹Ÿå³sourceå’Œtargetçš„ä½ç½®å¤§è‡´ä¸€ä¸€å¯¹åº”ã€‚</p><p>â‘¡åšé¢„æµ‹ï¼š<br><img src="/images/15437150115321.jpg" width="43%" height="50%"><br>å…¶ä¸­Sæ˜¯sourceçš„å¥å­é•¿åº¦ã€‚</p><p>æ¥ç€ï¼Œä»¥$p_t$ä¸ºä¸­å¿ƒï¼Œæ·»åŠ ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚æœ€ç»ˆattentionè®¡ç®—å…¬å¼ï¼š<br><img src="/images/15437150721538.jpg" width="50%" height="50%"></p><p>å…¶ä¸­alignå’Œä¸Šé¢ä¸€è‡´ï¼š<br><img src="/images/15437151043916.jpg" width="45%" height="50%"></p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå°†ä½ç½®ä¿¡æ¯ä¹Ÿè€ƒè™‘è¿›æ¥ã€‚</p><h3 id="Input-feeding-Approach"><a href="#Input-feeding-Approach" class="headerlink" title="Input-feeding Approach"></a>Input-feeding Approach</h3><p>motivationï¼šåœ¨ä¸‹ä¸€æ¬¡çš„alignmentï¼ˆä¹Ÿå°±æ˜¯è®¡ç®—attentionï¼‰ä¹‹å‰ï¼Œåº”å½“çŸ¥é“ä¹‹å‰çš„alignmentæƒ…å†µï¼Œæ‰€ä»¥åº”å½“ä½œä¸ºè¾“å…¥ä¿¡æ¯ä¼ è¿›ä¸‹ä¸€å±‚ï¼š<br><img src="/images/15437152269151.jpg" width="50%" height="50%"></p><p>æ³¨æ„è¿™é‡Œå’ŒBahdanauçš„ä¸åŒã€‚Bahdanauæ˜¯ç›´æ¥ç”¨ä¸Šä¸‹æ–‡å»æ„é€ éšå±‚ã€‚è¿™é‡Œæå‡ºçš„æ¨¡å‹ç›¸å¯¹æ›´ä¸ºé€šç”¨ï¼Œä¹Ÿå¯ä»¥è¢«åº”ç”¨äºéattentionçš„æ¨¡å‹ä¸­ï¼ˆä¹Ÿå°±æ˜¯æ¯æ¬¡å°†encoderçš„æœ€åä¸€å±‚ä½œä¸ºè¾“å…¥åœ¨æ¯ä¸ªtime stepéƒ½è¾“å…¥ï¼‰</p><hr><h2 id="4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks"><a href="#4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks" class="headerlink" title="4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]"></a>4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]</h2><p>æ€æƒ³ï¼šåˆ©ç”¨capsuleæå‰ç”Ÿæˆsource sentenceçš„å›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œåœ¨decodeçš„æ—¶å€™ç›´æ¥ä½¿ç”¨ï¼Œè€Œä¸éœ€è¦attentionï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´NMTçš„ç›®çš„ã€‚</p><p>Motivationï¼šattention-basedçš„NMTæ—¶é—´å¤æ‚åº¦ä¸º$|S|\times |T|$ï¼Œè€Œæœ¬æ–‡å¸Œæœ›èƒ½å¤Ÿå°†NMTå‡å°‘åˆ°çº¿æ€§æ—¶é—´ã€‚è€Œä¼ ç»Ÿä¸åŠ attentionçš„NMTé€šå¸¸ä½¿ç”¨LSTMæœ€åä¸€å±‚éšå±‚ä½œä¸ºæºè¯­è¨€çš„encodeä¿¡æ¯ä¼ å…¥decodeï¼Œä½†è¿™æ ·çš„ä¿¡æ¯å¹¶ä¸èƒ½å¾ˆå¥½åœ°ä»£è¡¨æ•´ä¸ªå¥å­ï¼Œå› æ­¤æœ¬æ–‡ä½¿ç”¨capsuleä½œä¸ºæå–source sentenceä¿¡æ¯çš„æ–¹æ³•ï¼Œåˆ©ç”¨capsuleç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºï¼Œç›´æ¥ä¼ å…¥decodeç«¯ï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´çš„ç›®çš„ã€‚</p><p><img src="/images/15437164176973.jpg" width="50%" height="50%"></p><h3 id="é—®é¢˜å®šä¹‰"><a href="#é—®é¢˜å®šä¹‰" class="headerlink" title="é—®é¢˜å®šä¹‰"></a>é—®é¢˜å®šä¹‰</h3><p>å¯¹äºembeddingï¼š<br><img src="/images/15437164440500.jpg" width="37%" height="50%"><br>å¸Œæœ›èƒ½å¤Ÿè½¬æ¢æˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºCï¼š<br><img src="/images/15437164654931.jpg" width="37%" height="50%"></p><p>æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¸€ä¸ªåŒå‘çš„LSTMï¼š<br><img src="/images/15437165067165.jpg" width="28%" height="50%"></p><p>ä¸€ç§ç®€å•çš„è·å–Cçš„æ–¹æ³•ï¼š<br><img src="/images/15437165382025.jpg" width="30%" height="50%"><br>å…¶ä¸­$h_1$å’Œ$h_L$æœ‰äº’è¡¥å…³ç³»ã€‚</p><p>æœ¬æ–‡ä½¿ç”¨capsuleæå–æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚</p><p>åœ¨decodeé˜¶æ®µï¼Œç”±äºæ‹¥æœ‰å›ºå®šè¡¨ç¤ºï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦attentionï¼š</p><p><img src="/images/15437166827481.jpg" width="35%" height="50%"><br><img src="/images/15437167374470.jpg" width="37%" height="50%"></p><p>æ€»ä½“æ¶æ„ï¼š<br><img src="/images/15437167607085.jpg" width="60%" height="50%"></p><h3 id="Aggregation-layers-with-Capsule-Networks"><a href="#Aggregation-layers-with-Capsule-Networks" class="headerlink" title="Aggregation layers with Capsule Networks"></a>Aggregation layers with Capsule Networks</h3><p><img src="/images/15437168111687.jpg" width="65%" height="50%"><br>å®é™…ä¸Šå°±æ˜¯dynamic routingé‚£ä¸€å¥—ï¼Œå¯¹ä¿¡æ¯è¿›è¡Œæå–ï¼ˆè®ºæ–‡å…¬å¼æœ‰è¯¯å°±ä¸è´´å›¾äº†ï¼‰</p><p>ç®—æ³•ï¼š<br><img src="/images/15437168668191.jpg" width="55%" height="50%"></p><p>æœ€ç»ˆè·å¾—äº†ï¼š<br><img src="/images/15437168888967.jpg" width="27%" height="50%"></p><hr><h2 id="5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>é‡è¯»äº†ä¸€éã€‚<br>ä»‹ç»ä¸€ç§æ–°å‹çš„dropoutï¼Œå¯ç”¨äºå·ç§¯å±‚æé«˜è¡¨ç°ã€‚é€šè¿‡å¤§é‡çš„å®éªŒå¾—å‡ºè®¸å¤šæœ‰æ„ä¹‰çš„ç»“è®ºã€‚æœ¬æ–‡å‘è¡¨äºNIPS2018ã€‚</p><h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><p>ç”±äºå·ç§¯å±‚çš„featureç›¸äº’ä¹‹é—´æœ‰è”ç³»ï¼Œå³ä½¿ä½¿ç”¨äº†dropoutï¼Œä¿¡æ¯ä¹Ÿèƒ½å¤Ÿæ ¹æ®å‘¨å›´çš„featureä¼ åˆ°ä¸‹ä¸€å±‚ã€‚å› æ­¤ä½¿ç”¨dropblockï¼Œä¸€æ¬¡å°†ä¸€ä¸ªæ–¹å—å†…çš„éƒ½dropæ‰ã€‚</p><p><img src="/images/15437170173072.jpg" width="50%" height="50%"></p><h3 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h3><p><img src="/images/15437170840909.jpg" width="80%" height="50%"></p><p>å…¶ä¸­æœ‰ä¸¤ä¸ªè¶…å‚ï¼šâ‘ block_sizeè¡¨ç¤ºå—çš„å¤§å°ï¼›Î³è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªunitè¦dropæ‰ï¼Œç­‰ä»·ä¼ ç»Ÿçš„dropoutçš„pã€‚å½“block_size=1æ—¶ç­‰ä»·dropoutï¼›å½“block size=æ•´ä¸ªfeature mapï¼Œç­‰ä»·äºspatial dropoutã€‚</p><p>åœ¨å®è·µä¸­ï¼Œé€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—Î³ï¼š<br><img src="/images/15437172746112.jpg" width="55%" height="50%"></p><p>(why? é€šè¿‡è®¡ç®—æœŸæœ›çš„æ–¹å¼å°†ä¼ ç»Ÿdropoutçš„keep_probä¸å½“å‰çš„Î³è”ç³»èµ·æ¥ï¼Œå¾—åˆ°ä¸€ä¸ªç­‰å¼ï¼Œæ•´ç†å³å¯è·å¾—ä¸Šå¼ï¼‰</p><p>åœ¨å®éªŒä¸­ï¼Œè¿˜å¯ä»¥é€æ¸å‡å°keep_probä½¿å¾—æ›´åŠ é²æ£’æ€§ã€‚</p><h3 id="å®éªŒ-amp-ç»“è®º"><a href="#å®éªŒ-amp-ç»“è®º" class="headerlink" title="å®éªŒ&amp;ç»“è®º"></a>å®éªŒ&amp;ç»“è®º</h3><p>â‘ æ•ˆæœ:dropout&lt; spatial dropout &lt; dropblock</p><p>â‘¡dropblockèƒ½æœ‰æ•ˆå»æ‰semantic information</p><p>â‘¢dropblockæ˜¯ä¸€ä¸ªæ›´åŠ å¼ºçš„regularization</p><p>â‘£ä½¿ç”¨dropblockçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿå­¦ä¹ æ›´å¤šçš„åŒºåŸŸï¼Œè€Œä¸æ˜¯åªä¸“æ³¨äºä¸€ä¸ªåŒºåŸŸ<br><img src="/images/15437174940381.jpg" width="70%" height="50%"></p><p>å¯¹äºresnetï¼Œç›´æ¥å°†dropblockåº”ç”¨äºæ·»åŠ å®Œskip connectionåçš„featureèƒ½å¤Ÿæœ‰æ›´é«˜çš„è¡¨ç°ã€‚</p><hr><h2 id="6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling"><a href="#6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling" class="headerlink" title="6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]"></a>6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]</h2><p>æå‡ºä¸€ç§å»ºç«‹åœ¨characteråŸºç¡€ä¸Šçš„æ–°å‹çš„ä¸Šä¸‹æ–‡embedding(contextualized embeddingï¼‰ã€‚ç”¨äºsequence labelingã€‚æœ¬æ–‡å‘è¡¨äºcoling2018ã€‚</p><h3 id="æ–¹æ³•-2"><a href="#æ–¹æ³•-2" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æ•´ä½“æ¶æ„ï¼š<br><img src="/images/15437175991019.jpg" width="100%" height="50%"></p><p>é¦–å…ˆå°†characterä½œä¸ºåŸºæœ¬å•ä½ï¼Œè¿‡ä¸€ä¸ªåŒå‘LSTMï¼Œè¿›è¡Œlanguage modelçš„å»ºæ¨¡ã€‚</p><p>å¦‚ä½•æå–ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼š<br><img src="/images/15437176650871.jpg" width="100%" height="50%"><br>æå–å‰å‘LSTMä¸­è¯¥è¯çš„æœ€åä¸€ä¸ªcharacterçš„åä¸€ä¸ªhidden stateï¼Œä»¥åŠåå‘LSTMä¸­ç¬¬ä¸€ä¸ªè¯çš„å‰ä¸€ä¸ªhidden stateï¼Œ å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚æœ€ç»ˆæ‹¼èµ·æ¥å³å¯ï¼š<br><img src="/images/15437177090697.jpg" width="28%" height="50%"><br>å› æ­¤è¯¥è¯ä¸ä»…ä¸è¯å†…éƒ¨çš„characterç›¸å…³ï¼Œè¿˜è·Ÿå…¶å‘¨å›´çš„contextæœ‰å…³ã€‚</p><p>sequence labelingæˆ‘ä¸æ„Ÿå…´è¶£ï¼Œè¯¥éƒ¨åˆ†æ²¡çœ‹ã€‚</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>ç›¸æ¯”word levelçš„language modelï¼Œcharacter-levelç‹¬ç«‹äºtokenizationå’Œfixed vocabularyï¼Œæ¨¡å‹æ›´å®¹æ˜“è¢«è®­ç»ƒï¼Œå› ä¸ºè¯è¡¨å°ä¸”è®­ç»ƒæ—¶é—´çŸ­ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> capsule </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> self-attention </tag>
            
            <tag> NMT </tag>
            
            <tag> locality modeling </tag>
            
            <tag> dropblock </tag>
            
            <tag> contextualized embedding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯16</title>
      <link href="/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D16/"/>
      <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D16/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è©è¨è›®"><a href="#1ï¸âƒ£è©è¨è›®" class="headerlink" title="1ï¸âƒ£è©è¨è›®"></a>1ï¸âƒ£è©è¨è›®</h3><p>[äº”ä»£åå›½] æç…œ<br>äººç”Ÿæ„æ¨ä½•èƒ½å…ï¼Œé”€é­‚ç‹¬æˆ‘æƒ…ä½•é™ï¼æ•…å›½æ¢¦é‡å½’ï¼Œè§‰æ¥åŒæ³ªå‚ã€‚<br>é«™æ¥¼è°ä¸ä¸Šï¼Ÿé•¿è®°ç§‹æ™´æœ›ã€‚<strong>å¾€äº‹å·²æˆç©ºï¼Œè¿˜å¦‚ä¸€æ¢¦ä¸­</strong>ã€‚</p><p>è§‰(jue)æ¥ï¼šé†’æ¥ã€‚</p><hr><h3 id="2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"><a href="#2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·" class="headerlink" title="2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"></a>2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·</h3><p>[å®‹] è‹è½¼<br>ä¸œæ­¦æœ›é¦€æ­ï¼Œäº‘æµ·å¤©æ¶¯ä¸¤æ³èŒ«ã€‚<strong>ä½•æ—¥åŠŸæˆåé‚äº†ï¼Œè¿˜ä¹¡ï¼Œé†‰ç¬‘é™ªå…¬ä¸‰ä¸‡åœº</strong>ã€‚<br><strong>ä¸ç”¨è¯‰ç¦»è§ï¼Œç—›é¥®ä»æ¥åˆ«æœ‰è‚ </strong>ã€‚ä»Šå¤œé€å½’ç¯ç«å†·ï¼Œæ²³å¡˜ï¼Œå •æ³ªç¾Šå…¬å´å§“æ¨ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%BB%8F%E5%8E%86%E4%B8%96%E7%95%8C%E4%B8%8A%E6%89%80%E6%9C%89%E7%83%AD%E9%97%B9/"/>
      <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%BB%8F%E5%8E%86%E4%B8%96%E7%95%8C%E4%B8%8A%E6%89%80%E6%9C%89%E7%83%AD%E9%97%B9/</url>
      
        <content type="html"><![CDATA[<p>äººä¸å¯èƒ½ç»å†ä¸–ç•Œä¸Šæ‰€æœ‰çƒ­é—¹ï¼Œä½†å¯ä»¥ç”¨çœ¼ç›çœ‹ï¼Œç”¨å¿ƒæ„Ÿå—ï¼Œç”¨èƒ¸æ€€æ‰©å¼ ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†12</title>
      <link href="/2018/11/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8612/"/>
      <url>/2018/11/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8612/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Transformer"><a href="#1ï¸âƒ£-Transformer" class="headerlink" title="1ï¸âƒ£[Transformer]"></a>1ï¸âƒ£[Transformer]</h3><p>å¯¹Transformeræ–°ç†è§£ï¼š</p><ul><li>å¯ä»¥å°†Transformerç†è§£æˆä¸€å¼ å…¨è¿æ¥å›¾ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä¸å…¶ä»–èŠ‚ç‚¹çš„å…³ç³»é€šè¿‡attentionæƒé‡è¡¨ç°ã€‚å›¾å…³ç³»æ˜¯åºåˆ—å…³ç³»æˆ–è€…æ ‘å…³ç³»çš„ä¸€èˆ¬åŒ–ã€‚</li><li>ä¸ºä»€ä¹ˆè¦æœ‰multi-headï¼Ÿä¸ä»…ä»…æ˜¯è®ºæ–‡çš„è§£é‡Šï¼Œæˆ–è®¸è¿˜å¯ä»¥ç†è§£æˆï¼Œå¯¹ä¸€ä¸ªå‘é‡çš„ä¸åŒéƒ¨åˆ†ï¼ˆå¦‚ç¬¬1ç»´åˆ°20ç»´ï¼Œç¬¬21ç»´åˆ°40ç»´ç­‰ï¼‰æ–½ä»¥ä¸åŒçš„attentionæƒé‡ï¼Œå¦‚æœä¸ä½¿ç”¨multi-headï¼Œé‚£ä¹ˆå¯¹äºä¸€ä¸ªqueryï¼Œå°±åªä¼šæœ‰ä¸€ä¸ªæƒé‡ï¼Œè€Œä¸åŒçš„ç»´åº¦æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</li></ul><hr><h3 id="2ï¸âƒ£-attention-amp-capsule"><a href="#2ï¸âƒ£-attention-amp-capsule" class="headerlink" title="2ï¸âƒ£[attention&amp;capsule]"></a>2ï¸âƒ£[attention&amp;capsule]</h3><p>attentionæ˜¯æ”¶ä¿¡æ¯ï¼Œqueryä»valueæŒ‰æƒé‡è·å–ä¿¡æ¯ï¼Œå…¶ä¸­æ‰€æœ‰valueçš„æƒé‡å’Œæ˜¯1ã€‚<br>capsuleæ˜¯å‘ä¿¡æ¯ï¼Œå¯¹äº$l-1$å±‚çš„ä¸€ä¸ªcapsuleæ¥è¯´ï¼Œåœ¨ä¼ å…¥åˆ°$l$å±‚çš„kä¸ªcapsuleçš„ä¿¡æ¯ï¼Œå…¶æƒé‡å’Œä¸º1ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Transformer </tag>
            
            <tag> attention </tag>
            
            <tag> capsule </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡6</title>
      <link href="/2018/11/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%876/"/>
      <url>/2018/11/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%876/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING"><a href="#1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING" class="headerlink" title="1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]"></a>1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]</h2><p>ä»‹ç»äº†ä¸€ç§ç”Ÿæˆsentence embeddingçš„æ–¹æ³•ã€‚ä¸å…¶ä»–sentence embeddingä¸åŒçš„åœ°æ–¹åœ¨äºï¼Œç”Ÿæˆçš„æ˜¯ä¸€ä¸ªçŸ©é˜µè€Œä¸æ˜¯ä¸€ä¸ªå‘é‡ã€‚é€šè¿‡çŸ©é˜µçš„å½¢å¼ï¼Œèƒ½å¤Ÿå…³æ³¨ä¸åŒéƒ¨åˆ†çš„è¯­ä¹‰è¡¨ç¤ºï¼Œç±»ä¼¼äºTransformerçš„multi-headã€‚</p><p>Contribution:</p><ul><li>å°†sentence embeddingæ‰©å±•ä¸ºçŸ©é˜µå½¢å¼ï¼Œèƒ½å¤Ÿè·å¾—æ›´å¤šçš„ä¿¡æ¯ã€‚</li><li>å¼•å…¥æ­£åˆ™åŒ–ï¼Œä½¿å¾—sentence matrixå…·æœ‰æ›´ä¸°å¯Œçš„å¤šæ ·æ€§ã€‚</li></ul><p><img src="/images/15425908639518.jpg" width="70%" height="50%"></p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åŒå‘LSTM+self-attentionã€‚</p><p>åŒå‘çš„LSTMè·å¾—ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºï¼š</p><p><img src="/images/15425911302081.jpg" width="27%" height="50%"></p><p><img src="/images/15425911849931.jpg" width="27%" height="50%"></p><p>å› æ­¤å¯ä»¥è·å¾—attentionæƒé‡å‘é‡ï¼š<br><img src="/images/15425912555350.jpg" width="50%" height="50%"></p><p>å…¶ä¸­$H:n\times2u,W_{s1}:d_a\times2u ,w_{s2}:d_a$ ï¼Œ$d_a$æ˜¯è¶…å‚ã€‚</p><p>ç°å°†å‘é‡$w_{s2}$æ‰©å±•ä¸ºçŸ©é˜µï¼Œäº¦å³æœ‰Multi-hop attentionï¼š<br><img src="/images/15425914364548.jpg" width="50%" height="50%"></p><p>$W_{s2}$ç»´åº¦ä¸º$r\times d_a$ï¼Œ$r$ä»£è¡¨äº†headçš„ä¸ªæ•°ã€‚</p><p>å› æ­¤æœ€ç»ˆçš„sentence embeddingçŸ©é˜µä¸ºï¼š<br><img src="/images/15425915371381.jpg" width="15%" height="50%"></p><h3 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h3><p>ä¸ºäº†è®©Aå°½å¯èƒ½æœ‰å¤šæ ·æ€§ï¼ˆå› ä¸ºå¦‚æœéƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œé‚£ä¹ˆåˆ™ä¼šæœ‰å†—ä½™æ€§ï¼‰ï¼Œå¼•å…¥å¦‚ä¸‹çš„æ­£åˆ™åŒ–ï¼š<br><img src="/images/15425915930785.jpg" width="28%" height="50%"></p><p>åŸå› ï¼š<br>å¯¹äºä¸åŒçš„head $a^i$ä¸$a^j$ï¼Œ$A A^T$æœ‰ï¼š<br><img src="/images/15425918790543.jpg" width="31%" height="50%"></p><p>å¦‚æœ$a^i$ä¸$a^j$å¾ˆç›¸ä¼¼é‚£ä¹ˆå°±ä¼šæ¥è¿‘äº1ï¼Œå¦‚æœéå¸¸ä¸ç›¸ä¼¼(no overlay)åˆ™ä¼šæ¥è¿‘äº0ã€‚<br>å› æ­¤æ•´ä¸ªå¼å­å°±æ˜¯:å¸Œæœ›å¯¹è§’çº¿éƒ¨åˆ†æ¥è¿‘äº0ï¼ˆå› ä¸ºå‡äº†å•ä½é˜µï¼‰ï¼Œè¿™å°±ç›¸å½“äºå°½å¯èƒ½focuså°éƒ¨åˆ†çš„è¯ï¼›åŒæ—¶å…¶ä»–éƒ¨åˆ†å°½å¯èƒ½æ¥è¿‘äº0ï¼Œä¹Ÿå³ä¸åŒçš„headä¹‹é—´æ²¡æœ‰overlapã€‚</p><h3 id="å¦‚ä½•ä½¿ç”¨"><a href="#å¦‚ä½•ä½¿ç”¨" class="headerlink" title="å¦‚ä½•ä½¿ç”¨"></a>å¦‚ä½•ä½¿ç”¨</h3><p>æ–‡ç« æåˆ°ï¼Œåœ¨åšåˆ†ç±»çš„æ—¶å€™å¯ä»¥ç›´æ¥å°†çŸ©é˜µMå±•å¼€ï¼Œè¿‡å…¨è¿æ¥å±‚å³å¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]"></a>2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]</h2><p>åœ¨å®Œå½¢å¡«ç©ºä»»åŠ¡(Cloze-style Reading Comprehension)ä¸Šæå‡ºä¸€ç§æ–°çš„attentionï¼Œå³nested-attentionã€‚</p><h3 id="ä»»åŠ¡æè¿°"><a href="#ä»»åŠ¡æè¿°" class="headerlink" title="ä»»åŠ¡æè¿°"></a>ä»»åŠ¡æè¿°</h3><p>ä¸‰å…ƒç»„ $ D,Q,A $ï¼Œdocumentï¼Œquestionï¼Œanswerã€‚å…¶ä¸­answerä¸€èˆ¬æ˜¯documentçš„ä¸€ä¸ªè¯ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æœ¬æ–‡æå‡ºçš„attentionæœºåˆ¶ï¼Œæ˜¯é€šè¿‡ä¸€ä¸ªæ–°çš„attentionå»æŒ‡ç¤ºå¦ä¸€ä¸ªattentionçš„é‡è¦ç¨‹åº¦ã€‚</p><p>é¦–å…ˆé€šè¿‡ä¸€å±‚å…±äº«çš„embeddingå±‚ï¼Œå°†documentå’Œqueryéƒ½encodeæˆword embeddingï¼Œç„¶åé€šè¿‡åŒå‘çš„GRUï¼Œå°†éšå±‚æ‹¼æ¥èµ·æ¥æˆä¸ºæ–°çš„è¡¨ç¤ºã€‚</p><p>æ¥ç€è·å¾—pair-wise matching matrixï¼š<br><img src="/images/15425993645945.jpg" width="40%" height="50%"></p><p>å…¶ä¸­$h$ä»£è¡¨ä¸Šè¿°æåˆ°çš„æ‹¼æ¥èµ·æ¥çš„è¡¨ç¤ºï¼Œ$M(i,j)$ä»£è¡¨äº†documentçš„è¯$i$å’Œquestionçš„è¯$j$ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚</p><p>æ¥ç€å¯¹<strong>column</strong>åšsoftmaxï¼š<br><img src="/images/15425994692189.jpg" width="50%" height="50%"><br>å…¶ä»£è¡¨çš„æ„ä¹‰å³query-to-document attentionï¼Œäº¦å³<strong>å¯¹äºä¸€ä¸ªqueryå†…çš„è¯ï¼Œdocumentçš„æ¯ä¸ªè¯ä¸å…¶åŒ¹é…çš„æƒé‡</strong>ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œå¯¹rowè¿›è¡Œsoftmaxæ“ä½œï¼š<br><img src="/images/15425995482827.jpg" width="50%" height="50%"><br>ä»£è¡¨çš„æ˜¯<strong>ç»™å®šä¸€ä¸ªdocumentçš„è¯ï¼Œqueryçš„å“ªä¸ªè¯æ›´ä¸ºé‡è¦</strong>ã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†Î²å¹³å‡èµ·æ¥ï¼Œè·å¾—ä¸€ä¸ªå‘é‡ï¼š<br><img src="/images/15425996847558.jpg" width="20%" height="50%"><br>è¿™ä¸ªå‘é‡ä»æœ‰attentionçš„æ€§è´¨ï¼Œå³æ‰€æœ‰å…ƒç´ åŠ å’Œä¸º1ã€‚ä»£è¡¨çš„æ˜¯<strong>ä»å¹³å‡æ¥çœ‹ï¼Œqueryè¯çš„é‡è¦æ€§</strong>ã€‚</p><p>æœ€åï¼Œæˆ‘ä»¬å¯¹Î±å’ŒÎ²åšç‚¹ç§¯ä»¥è·å¾—attended document-level attentionï¼š<br><img src="/images/15425997529193.jpg" width="13%" height="50%"></p><p>å…¶ä¸­$s$çš„ç»´åº¦æ˜¯$D\times 1$ã€‚sä»£è¡¨çš„æ„ä¹‰å³â€œa weighted sum of each individual document-level attention Î±(t) when looking at query word at time tâ€ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹Î±è¿›è¡ŒåŠ æƒï¼Œä»£è¡¨query wordçš„å¹³å‡é‡è¦ç¨‹åº¦ã€‚</p><p>æœ€ç»ˆåœ¨åšå®Œå‹å¡«ç©ºçš„é¢„æµ‹æ—¶ï¼š<br><img src="/images/15425999965777.jpg" width="38%" height="50%"></p><p>ä¸ªäººè§‰å¾—è¿™ç§attention-over-attentionçš„æƒ³æ³•è¿˜æ˜¯æŒºæœ‰åˆ›æ–°çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> sentence embedding </tag>
            
            <tag> nested attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç½‘ç»œä¼˜åŒ–ä¸æ­£åˆ™åŒ–æ€»ç»“</title>
      <link href="/2018/11/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%BB%E7%BB%93/"/>
      <url>/2018/11/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>å¤§é‡å‚è€ƒè‡ª<a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a></p><h1 id="ä¼˜åŒ–ç®—æ³•"><a href="#ä¼˜åŒ–ç®—æ³•" class="headerlink" title="ä¼˜åŒ–ç®—æ³•"></a>ä¼˜åŒ–ç®—æ³•</h1><p>å¯¹äºæ ‡å‡†çš„SGDï¼Œå¸¸è§çš„æ”¹è¿›ç®—æ³•ä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œï¼šå­¦ä¹ ç‡è¡°å‡&amp;æ¢¯åº¦æ–¹å‘ä¼˜åŒ–ã€‚<br>è®°$g_t$ä¸ºtæ—¶åˆ»çš„å¯¼æ•°ï¼š<br><img src="/images/2018-11-13-15421196736629.jpg" width="20%" height="50%"></p><h2 id="å­¦ä¹ ç‡è¡°å‡"><a href="#å­¦ä¹ ç‡è¡°å‡" class="headerlink" title="å­¦ä¹ ç‡è¡°å‡"></a>å­¦ä¹ ç‡è¡°å‡</h2><h3 id="AdaGradç®—æ³•"><a href="#AdaGradç®—æ³•" class="headerlink" title="AdaGradç®—æ³•"></a>AdaGradç®—æ³•</h3><p>é€šè¿‡è®¡ç®—å†æ¬¡çš„æ¢¯åº¦å¹³æ–¹ç´¯è®¡å€¼è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ã€‚<br>$G_t$æ˜¯ç´¯è®¡å€¼ï¼š<br><img src="/images/2018-11-13-15421189802198.jpg" width="20%" height="50%"></p><p>æ›´æ–°å€¼åˆ™ä¸ºï¼š<br><img src="/images/2018-11-13-15421190100615.jpg" width="30%" height="50%"></p><p>ç¼ºç‚¹ï¼šéšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ å­¦ä¹ ç‡é€’å‡ã€‚åœ¨ç»è¿‡ä¸€å®šæ¬¡æ•°çš„è¿­ä»£ä¾ç„¶æ²¡æœ‰æ‰¾åˆ°æœ€ä¼˜ç‚¹æ—¶ï¼Œç”±äºè¿™æ—¶çš„å­¦ä¹ ç‡å·²ç»éå¸¸å°ï¼Œå¾ˆéš¾å†ç»§ç»­æ‰¾åˆ°æœ€ä¼˜ç‚¹ã€‚</p><h3 id="RMSpropç®—æ³•"><a href="#RMSpropç®—æ³•" class="headerlink" title="RMSpropç®—æ³•"></a>RMSpropç®—æ³•</h3><p>å¯¹AdaGradçš„æ”¹è¿›ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äº$G_t$çš„è®¡ç®—ï¼Œå°†å†å²ä¿¡æ¯å’Œå½“å‰ä¿¡æ¯è¿›è¡Œçº¿æ€§åŠ æƒï¼Œä½¿å¾—å­¦ä¹ ç‡å¯ä»¥åŠ¨æ€æ”¹å˜è€Œä¸æ˜¯å•è°ƒé€’å‡ï¼š<br><img src="/images/2018-11-13-15421192344025.jpg" width="40%" height="50%"></p><p>Î²ä¸ºè¡°å‡ç‡ï¼Œé€šå¸¸å–0.9ã€‚ä¹Ÿå³å†å²ä¿¡æ¯å ä¸»å¯¼ã€‚</p><h3 id="AdaDeltaç®—æ³•"><a href="#AdaDeltaç®—æ³•" class="headerlink" title="AdaDeltaç®—æ³•"></a>AdaDeltaç®—æ³•</h3><p>åŒæ ·æ˜¯å¯¹AdaGradçš„æ”¹è¿›ã€‚<br>æ¯æ¬¡è®¡ç®—ï¼š<br><img src="/images/2018-11-13-15421195264173.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³å†å²æ›´æ–°å·®å’Œä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®çš„åŠ æƒï¼ˆRMSpropæ˜¯å†å²æ¢¯åº¦å’Œå½“å‰æ¢¯åº¦ï¼‰ã€‚</p><p>æœ€ç»ˆæ›´æ–°å·®å€¼ä¸ºï¼š<br><img src="/images/2018-11-13-15421197355615.jpg" width="30%" height="50%"></p><p>å…¶ä¸­$G_t$è®¡ç®—æ–¹æ³•å’ŒRMSpropä¸€è‡´ã€‚</p><h2 id="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"><a href="#æ¢¯åº¦æ–¹å‘ä¼˜åŒ–" class="headerlink" title="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"></a>æ¢¯åº¦æ–¹å‘ä¼˜åŒ–</h2><p>åˆ©ç”¨å†å²çš„æ¢¯åº¦ï¼ˆæ–¹å‘ï¼‰è°ƒæ•´å½“å‰æ—¶åˆ»çš„æ¢¯åº¦ã€‚</p><h3 id="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"><a href="#åŠ¨é‡ï¼ˆMomentumï¼‰æ³•" class="headerlink" title="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"></a>åŠ¨é‡ï¼ˆMomentumï¼‰æ³•</h3><p>åŠ¨é‡æ³•ï¼ˆMomentum Methodï¼‰æ˜¯ç”¨ä¹‹å‰ç§¯ç´¯åŠ¨é‡æ¥æ›¿ä»£çœŸæ­£çš„æ¢¯åº¦ã€‚æ¯æ¬¡è¿­ä»£çš„æ¢¯åº¦å¯ä»¥çœ‹ä½œæ˜¯åŠ é€Ÿåº¦ã€‚</p><p><img src="/images/2018-11-13-15421199473226.jpg" width="28%" height="50%"></p><p>ä¹Ÿå³ä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®å€¼å’Œå½“å‰æ¢¯åº¦å…±åŒå†³å®šå½“å‰çš„æ›´æ–°å·®å€¼ã€‚$Ï$ä¸ºåŠ¨é‡å› å­ï¼Œé€šå¸¸ä¸º0.9ã€‚ä¹Ÿå³åŠ¨é‡å äº†ä¸»å¯¼ã€‚</p><p>å½“æŸä¸ªå‚æ•°åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘ä¸ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å°ï¼›ç›¸åï¼Œå½“åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘éƒ½ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å¤§ï¼Œèµ·åˆ°åŠ é€Ÿä½œç”¨ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨è¿­ä»£åˆæœŸï¼Œæ¢¯åº¦æ–¹æ³•éƒ½æ¯”è¾ƒä¸€è‡´ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°åŠ é€Ÿä½œç”¨ï¼Œå¯ä»¥æ›´å¿«åœ°åˆ°è¾¾æœ€ä¼˜ç‚¹ã€‚åœ¨è¿­ä»£åæœŸï¼Œæ¢¯åº¦æ–¹æ³•ä¼šå–å†³ä¸ä¸€è‡´ï¼Œåœ¨æ”¶æ•›å€¼é™„è¿‘éœ‡è¡ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°å‡é€Ÿä½œç”¨ï¼Œå¢åŠ ç¨³å®šæ€§ã€‚</p><h3 id="NesterovåŠ é€Ÿæ¢¯åº¦"><a href="#NesterovåŠ é€Ÿæ¢¯åº¦" class="headerlink" title="NesterovåŠ é€Ÿæ¢¯åº¦"></a>NesterovåŠ é€Ÿæ¢¯åº¦</h3><p>åŠ¨é‡æ³•çš„æ”¹è¿›ç‰ˆæœ¬ã€‚</p><p>å‰é¢æåˆ°çš„åŠ¨é‡æ³•ï¼Œæ˜¯ä¸Šä¸€æ­¥çš„æ›´æ–°æ–¹å‘$\Delta \theta_{t-1}$ä¸å½“å‰æ¢¯åº¦$-g_t$çš„åŠ å’Œã€‚å› æ­¤å¯ä»¥ç†è§£æˆï¼Œå…ˆæ ¹æ®$âˆ†Î¸_{tâˆ’1}$æ›´æ–°ä¸€æ¬¡å¾—åˆ°å‚æ•°Î¸ï¼Œå†ç”¨$g_t$è¿›è¡Œæ›´æ–°ã€‚äº¦å³ï¼š<br><img src="/images/2018-11-13-15421202426163.jpg" width="27%" height="50%"><br>ä¸Šå¼çš„ç¬¬äºŒæ­¥ä¸­ï¼Œ$g_t$æ˜¯åœ¨$ \theta_{t-1}$ä¸Šçš„æ¢¯åº¦ã€‚æˆ‘ä»¬å°†è¯¥æ­¥æ”¹ä¸ºåœ¨$\theta_{t}$çš„æ¢¯åº¦ã€‚<br>å› æ­¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-13-15421203421465.jpg" width="50%" height="50%"></p><p>å’ŒåŠ¨é‡æ³•ç›¸æ¯”ï¼Œç›¸å½“äºæå‰èµ°äº†ä¸€æ­¥ã€‚<br><img src="/images/2018-11-13-15421203910771.jpg" width="70%" height="50%"></p><h3 id="Adam-amp-Nadam"><a href="#Adam-amp-Nadam" class="headerlink" title="Adam&amp;Nadam"></a>Adam&amp;Nadam</h3><p>Adamä¸€æ–¹é¢è®¡ç®—æ¢¯åº¦å¹³æ–¹çš„åŠ æƒï¼ŒåŒæ—¶è¿˜è®¡ç®—æ¢¯åº¦çš„åŠ æƒï¼š<br><img src="/images/2018-11-13-15421205162558.jpg" width="40%" height="50%"><br>é€šå¸¸$Î²_1=0.9$ï¼Œ$Î²_2=0.99$<br>ä¹Ÿå³å†å²ä¿¡æ¯å äº†ä¸»å¯¼ã€‚</p><p>åœ¨åˆæœŸ$M_t$ä¸$G_t$ä¼šæ¯”çœŸå®å‡å€¼å’Œæ–¹å·®è¦å°ï¼ˆæƒ³è±¡$M_0=0$ï¼Œ$G_0=0$æ—¶ï¼‰ã€‚å› æ­¤å¯¹å…¶è¿›è¡Œä¿®æ­£ï¼Œå³ï¼š<br><img src="/images/2018-11-13-15421207635850.jpg" width="18%" height="50%"><br>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-11-13-15421207966341.jpg" width="26%" height="50%"></p><p>åŒç†æœ‰Nadamã€‚</p><p>Adam = Momentum + RMSprop<br>Nadam = Nesterov + RMSprop</p><h3 id="æ¢¯åº¦æˆªæ–­-gradient-clipping"><a href="#æ¢¯åº¦æˆªæ–­-gradient-clipping" class="headerlink" title="æ¢¯åº¦æˆªæ–­ gradient clipping"></a>æ¢¯åº¦æˆªæ–­ gradient clipping</h3><p>åˆ†ä¸ºæŒ‰å€¼æˆªæ–­ä¸æŒ‰æ¨¡æˆªæ–­ã€‚</p><h1 id="å‚æ•°åˆå§‹åŒ–"><a href="#å‚æ•°åˆå§‹åŒ–" class="headerlink" title="å‚æ•°åˆå§‹åŒ–"></a>å‚æ•°åˆå§‹åŒ–</h1><p>åˆå§‹å€¼é€‰å–å¾ˆå…³é”®ã€‚å‡è®¾å…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Œåˆ™åç»­æ›´æ–°å¯¼è‡´æ‰€æœ‰çš„æ¿€æ´»å€¼ç›¸åŒï¼Œä¹Ÿå³å¯¹ç§°æƒé‡ç°è±¡ã€‚</p><p>åŸåˆ™ï¼šä¸èƒ½è¿‡å¤§ï¼Œå¦åˆ™æ¿€æ´»å€¼ä¼šå˜å¾—é¥±å’Œï¼Œå¦‚sigmoidï¼›ä¸èƒ½è¿‡å°ï¼Œå¦åˆ™ç»è¿‡å¤šå±‚ä¿¡å·ä¼šé€æ¸æ¶ˆå¤±ï¼Œå¹¶ä¸”å¯¼è‡´sigmoidä¸¢å¤±éçº¿æ€§çš„èƒ½åŠ›ï¼ˆåœ¨0é™„è¿‘åŸºæœ¬è¿‘ä¼¼çº¿æ€§ï¼‰ã€‚å¦‚æœä¸€ä¸ªç¥ç»å…ƒçš„è¾“å…¥è¿æ¥å¾ˆå¤šï¼Œå®ƒçš„æ¯ä¸ªè¾“å…¥è¿æ¥ä¸Šçš„æƒé‡å°±åº”è¯¥å°ä¸€äº›ï¼Œè¿™æ˜¯ä¸ºäº†é¿å…è¾“å‡ºè¿‡å¤§ã€‚</p><h2 id="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"><a href="#Gaussianåˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"></a>Gaussianåˆ†å¸ƒåˆå§‹åŒ–</h2><p>åŒæ—¶è€ƒè™‘è¾“å…¥è¾“å‡ºï¼Œå¯ä»¥æŒ‰ $N(0,\sqrt{\frac{2}{n_{in} + n_{out}}})$ é«˜æ–¯åˆ†å¸ƒæ¥åˆå§‹åŒ–ã€‚</p><h2 id="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"><a href="#å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"></a>å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–</h2><p>åœ¨$[-r,r]$åŒºé—´å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå…¶ä¸­rå¯ä»¥æŒ‰ç…§ç¥ç»å…ƒæ•°é‡è‡ªé€‚åº”è°ƒæ•´ã€‚</p><h3 id="Xavieråˆå§‹åŒ–æ–¹æ³•"><a href="#Xavieråˆå§‹åŒ–æ–¹æ³•" class="headerlink" title="Xavieråˆå§‹åŒ–æ–¹æ³•"></a>Xavieråˆå§‹åŒ–æ–¹æ³•</h3><p>è‡ªåŠ¨è®¡ç®—è¶…å‚rã€‚rçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-11-14-15421648119504.jpg" width="22%" height="50%"><br>å…¶ä¸­$n^l$ä»£è¡¨ç¬¬$l$å±‚çš„ç¥ç»å…ƒä¸ªæ•°ã€‚</p><p>ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªå¼å­ï¼ˆæ¨å¯¼è§å‚è€ƒèµ„æ–™ï¼‰ï¼šç»¼åˆè€ƒè™‘äº†â‘ è¾“å…¥è¾“å‡ºçš„æ–¹å·®è¦ä¸€è‡´ï¼›â‘¡åå‘ä¼ æ’­ä¸­è¯¯å·®ä¿¡å·çš„æ–¹å·®ä¸è¢«æ”¾å¤§æˆ–ç¼©å°ã€‚</p><h1 id="å½’ä¸€åŒ–"><a href="#å½’ä¸€åŒ–" class="headerlink" title="å½’ä¸€åŒ–"></a>å½’ä¸€åŒ–</h1><p>å°†æ•°æ®åˆ†å¸ƒå½’ä¸€åŒ–ï¼Œä½¿å¾—åˆ†å¸ƒä¿æŒç¨³å®šã€‚<br><img src="/images/2018-11-14-15421656553319.jpg" width="100%" height="50%"><br>å‡è®¾æ•°æ®æœ‰å››ç»´(N,C,H,W)ã€‚Nä»£è¡¨batchï¼›Cä»£è¡¨channelï¼›H,Wä»£è¡¨heightå’Œwidthã€‚</p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>æ²¿ç€é€šé“è¿›è¡Œå½’ä¸€åŒ–ï¼Œäº¦å³æ¯ä¸ªé€šé“éƒ½æœ‰è‡ªå·±çš„å‡å€¼å’Œæ–¹å·®ã€‚<br><img src="/images/2018-11-14-15421657694248.jpg" width="70%" height="50%"><br>å…¶ä¸­ç¼©æ”¾å¹³ç§»å˜é‡æ˜¯å¯å­¦ä¹ çš„ã€‚</p><p>ç¼ºç‚¹ï¼š<br>â‘ å¯¹batch sizeæ•æ„Ÿï¼Œbatch sizeå¤ªå°åˆ™æ–¹å·®å‡å€¼ä¸è¶³ä»¥ä»£è¡¨æ•°æ®åˆ†å¸ƒ<br>â‘¡å¯¹äºä¸ç­‰é•¿çš„è¾“å…¥å¦‚RNNæ¥è¯´ï¼Œæ¯ä¸€ä¸ªtimestepéƒ½éœ€è¦ä¿å­˜ä¸åŒçš„ç‰¹å¾ã€‚</p><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>å¯¹ä¸€ä¸ªè¾“å…¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œäº¦å³æ¯ä¸ªè¾“å…¥éƒ½æœ‰è‡ªå·±çš„æ–¹å·®ã€å‡å€¼ã€‚è¿™æ ·ä¸ä¾èµ–äºbatchå¤§å°å’Œè¾“å…¥sequenceçš„æ·±åº¦ã€‚</p><p>å¯¹RNNæ•ˆæœæ¯”è¾ƒæ˜æ˜¾ï¼Œä½†CNNä¸­ä¸å¦‚BN</p><h2 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a>Instance Normalization</h2><p>å¯¹HWè¿›è¡Œå½’ä¸€åŒ–</p><h2 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h2><p>å°†channelåˆ†ä¸ºå¤šä¸ªgroupï¼Œæ¯ä¸ªgroupå†…åšå½’ä¸€åŒ–</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a><br><a href="https://blog.csdn.net/liuxiao214/article/details/81037416" target="_blank" rel="noopener">https://blog.csdn.net/liuxiao214/article/details/81037416</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹ ğŸ¤– </tag>
            
            <tag> ä¼˜åŒ–ç®—æ³• </tag>
            
            <tag> å‚æ•°åˆå§‹åŒ– </tag>
            
            <tag> Normalization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•10</title>
      <link href="/2018/11/11/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9510/"/>
      <url>/2018/11/11/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9510/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-get-sinusoid-encoding-table"><a href="#1ï¸âƒ£-get-sinusoid-encoding-table" class="headerlink" title="1ï¸âƒ£[get_sinusoid_encoding_table]"></a>1ï¸âƒ£[get_sinusoid_encoding_table]</h3><p>Transformerç»å¯¹ä½ç½®ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sinusoid_encoding_table</span><span class="params">(n_position, d_hid, padding_idx=None)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_angle</span><span class="params">(position, hid_idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> position / np.power(<span class="number">10000</span>, <span class="number">2</span> * (hid_idx // <span class="number">2</span>) / d_hid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_posi_angle_vec</span><span class="params">(position)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [cal_angle(position, hid_j) <span class="keyword">for</span> hid_j <span class="keyword">in</span> range(d_hid)]</span><br><span class="line"></span><br><span class="line">    sinusoid_table = np.array([get_posi_angle_vec(pos_i) <span class="keyword">for</span> pos_i <span class="keyword">in</span> range(n_position)])</span><br><span class="line"></span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.cos(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        sinusoid_table[padding_idx] = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(sinusoid_table)  <span class="comment"># n_position,embed_dim</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†11</title>
      <link href="/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8611/"/>
      <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8611/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Optimizer"><a href="#1ï¸âƒ£-Optimizer" class="headerlink" title="1ï¸âƒ£[Optimizer]"></a>1ï¸âƒ£[Optimizer]</h3><p><a href="https://zhuanlan.zhihu.com/p/32262540" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32262540</a><br><a href="https://zhuanlan.zhihu.com/p/32338983" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32338983</a></p><p>Adamç­‰è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•å¯¹äºç¨€ç–æ•°æ®å…·æœ‰ä¼˜åŠ¿ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¾ˆå¿«ï¼›ä½†ç²¾è°ƒå‚æ•°çš„SGDï¼ˆ+Momentumï¼‰å¾€å¾€èƒ½å¤Ÿå–å¾—æ›´å¥½çš„æœ€ç»ˆç»“æœã€‚</p><p>å»ºè®®ï¼š<br>å‰æœŸç”¨Adamï¼Œäº«å—Adamå¿«é€Ÿæ”¶æ•›çš„ä¼˜åŠ¿ï¼›åæœŸåˆ‡æ¢åˆ°SGDï¼Œæ…¢æ…¢å¯»æ‰¾æœ€ä¼˜è§£ã€‚<br>ä»€ä¹ˆæ—¶å€™ä»Adamåˆ‡æ¢åˆ°SGDï¼Ÿå½“SGDçš„ç›¸åº”å­¦ä¹ ç‡çš„ç§»åŠ¨å¹³å‡å€¼åŸºæœ¬ä¸å˜çš„æ—¶å€™ã€‚</p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>LongTensoré™¤ä»¥æµ®ç‚¹æ•°ï¼Œä¼šå¯¹é™¤æ•°è¿›è¡Œå–æ•´ï¼Œå†åšé™¤æ³•ã€‚<br><img src="/images/2018-11-11-15419055399325.jpg" width="30%" height="50%"></p><hr><h3 id="3ï¸âƒ£-Pytorch"><a href="#3ï¸âƒ£-Pytorch" class="headerlink" title="3ï¸âƒ£[Pytorch]"></a>3ï¸âƒ£[Pytorch]</h3><p>ä½¿ç”¨Pytorchçš„DataParallel</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda:'</span> + str(</span><br><span class="line">    config.CUDA_VISIBLE_DEVICES[<span class="number">0</span>]) <span class="keyword">if</span> config.use_cuda <span class="keyword">else</span> <span class="string">'cpu'</span>)   <span class="comment"># æŒ‡å®šç¬¬ä¸€ä¸ªè®¾å¤‡</span></span><br><span class="line"></span><br><span class="line">model = ClassifyModel(</span><br><span class="line">    vocab_size=len(vocab), max_seq_len=config.max_sent_len,</span><br><span class="line">    embed_dim=config.embed_dim, n_layers=config.n_layers,</span><br><span class="line">    n_head=config.n_head, d_k=config.d_k,</span><br><span class="line">    d_v=config.d_v,</span><br><span class="line">    d_model=config.d_model, d_inner=config.d_inner_hid,</span><br><span class="line">    n_label=config.n_label,</span><br><span class="line">    dropout=config.dropout</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">model = DataParallel(model, device_ids=config.CUDA_VISIBLE_DEVICES)  <span class="comment"># æ˜¾å¼å®šä¹‰device_ids</span></span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°ï¼šdevice_idsçš„èµ·å§‹ç¼–å·è¦ä¸ä¹‹å‰å®šä¹‰çš„deviceä¸­çš„â€œcuda:0â€ç›¸ä¸€è‡´ï¼Œä¸ç„¶ä¼šæŠ¥é”™ã€‚</p><p>å¦‚æœä¸æ˜¾å¼åœ¨ä»£ç ä¸­çš„DataParallelæŒ‡å®šè®¾å¤‡ï¼Œé‚£ä¹ˆéœ€è¦åœ¨å‘½ä»¤è¡Œå†…æŒ‡å®šã€‚å¦‚æœæ˜¯åœ¨å‘½ä»¤è¡Œé‡Œé¢è¿è¡Œçš„ï¼Œä¸”deviceä¸æ˜¯ä»0å¼€å§‹ï¼Œåº”å½“æ˜¾å¼è®¾ç½®GPU_idï¼Œå¦åˆ™ä¼šå‡ºé”™â€˜AssertionError: Invalid device idâ€™ï¼Œæ­£ç¡®çš„å‘½ä»¤ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=4,5Â  python -u classify_main.py --gpu_id 0,1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Optimizer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºsparse gradient</title>
      <link href="/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8Esparse%20gradient/"/>
      <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8Esparse%20gradient/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ å¤©åœ¨çœ‹AllenAIåœ¨EMNLPçš„pptæ—¶ï¼Œæœ‰ä¸€é¡µå†™é“ï¼š<br><img src="/images/2018-11-11-15419037448379.jpg" width="70%" height="50%"></p><p>ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µï¼Ÿ</p><p>Embeddingæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„çŸ©é˜µï¼Œæ¯ä¸€æ¬¡å…¶å®éƒ½åªæœ‰ä¸€ä¸ªå°éƒ¨åˆ†è¿›è¡Œäº†æ›´æ–°ï¼Œå¯¹äºä¸€äº›è¯æ¥è¯´ï¼Œå‡ºç°çš„é¢‘ç‡ä¸é«˜ï¼Œæˆ–è€…è¯´ï¼Œå…¶å®å¤§éƒ¨åˆ†çš„è¯åœ¨ä¸€ä¸ªloop/epochä¸­ï¼Œè¢«æ›´æ–°çš„æ¬¡æ•°æ˜¯è¾ƒå°‘çš„ã€‚ä½†æ˜¯ï¼Œæ³¨æ„åˆ°ä¸€èˆ¬çš„optimizerç®—æ³•ï¼Œæ˜¯ä»¥matrixä¸ºå•ä½è¿›è¡Œæ›´æ–°çš„ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€æ¬¡éƒ½æ˜¯$W^{t+1}=W^{t}-\eta \frac{\partial L}{\partial{W}}$</p><p>è€ŒAdamç®—æ³•ï¼š<br><img src="/images/2018-11-11-15419038346958.jpg" width="70%" height="50%"></p><p>åŠ¨é‡å äº†ä¸»å¯¼ã€‚ä½†è¿™æ ·ï¼Œæ¯æ¬¡batchæ›´æ–°ï¼Œé‚£äº›æ²¡è¢«æ›´æ–°çš„è¯ï¼ˆä¹Ÿå³gradient=0ï¼‰çš„åŠ¨é‡ä»ç„¶ä¼šè¢«è¡°å‡ï¼Œæ‰€ä»¥è¿™æ ·å½“åˆ°è¿™ä¸ªè¯æ›´æ–°çš„æ—¶å€™ï¼Œä»–çš„åŠ¨é‡å·²ç»è¢«è¡°å‡å®Œäº†ï¼Œæ‰€ä»¥æ›´æ–°çš„gradientå°±å¾ˆå°ã€‚</p><p>è§£å†³æ–¹æ¡ˆï¼š</p><p>â‘ åœ¨PyTorchä¸­ï¼ŒEmbeddingçš„APIï¼š<br><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False, _weight=None)</code></p><p>å…¶ä¸­sparse (bool, optional) â€“ if True, gradient w.r.t. weight matrix will be a sparse tensor.</p><p>å°†sparseè®¾ä¸ºTrueå³å¯ã€‚</p><p>â‘¡é’ˆå¯¹sparseçŸ©é˜µï¼Œä½¿ç”¨ä¸åŒçš„optimizerï¼Œå¦‚torch.optim.SparseAdamï¼š</p><blockquote><p>Implements lazy version of Adam algorithm suitable for sparse tensors.<br>In this variant, only moments that show up in the gradient get updated, and only those portions of the gradient get applied to the parameters.</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> sparse gradient </tag>
            
            <tag> ä»£ç å®è·µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡5</title>
      <link href="/2018/11/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%875/"/>
      <url>/2018/11/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%875/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Neural-Turing-Machine"><a href="#1ï¸âƒ£-Neural-Turing-Machine" class="headerlink" title="1ï¸âƒ£[Neural Turing Machine]"></a>1ï¸âƒ£[Neural Turing Machine]</h2><p>é€šè¿‡æ¨¡ä»¿å†¯è¯ºä¾æ›¼æœºï¼Œå¼•å…¥å¤–éƒ¨å†…å­˜(externel memory)ã€‚<br><img src="/images/2018-11-10-15418626837026.jpg" width="70%" height="50%"></p><p>å’Œæ™®é€šç¥ç»ç½‘ç»œä¸€æ ·ï¼Œä¸å¤–ç•Œäº¤äº’ï¼Œè·å¾—ä¸€ä¸ªè¾“å…¥ï¼Œäº§ç”Ÿä¸€ä¸ªè¾“å‡ºã€‚ä½†ä¸åŒçš„æ˜¯ï¼Œå†…éƒ¨è¿˜æœ‰ä¸€ä¸ªmemoryè¿›è¡Œè¯»å†™ã€‚<br>å‡è®¾memoryæ˜¯ä¸€ä¸ªN Ã— Mçš„çŸ©é˜µï¼ŒNæ˜¯å†…å­˜çš„ä½ç½®æ•°é‡ã€‚</p><h3 id="è¯»å†™memory"><a href="#è¯»å†™memory" class="headerlink" title="è¯»å†™memory"></a>è¯»å†™memory</h3><p>â‘ è¯»<br><img src="/images/2018-11-10-15418627403268.jpg" width="25%" height="50%"><br>å…¶ä¸­è¯»çš„æ—¶å€™å¯¹å„å†…å­˜ä½ç½®çº¿æ€§åŠ æƒã€‚wæ˜¯å½’ä¸€åŒ–æƒé‡ã€‚</p><p>â‘¡å†™<br>$e_t$æ˜¯æ“¦é™¤å‘é‡ï¼ˆerase vectorï¼‰<br><img src="/images/2018-11-10-15418627941358.jpg" width="35%" height="50%"></p><p>$a_t$æ˜¯åŠ å’Œå‘é‡(add vector)<br><img src="/images/2018-11-10-15418628323343.jpg" width="30%" height="50%"></p><p>å…·ä½“å¦‚ä½•è·å¾—æƒé‡å°±ä¸è¯´äº†ã€‚</p><h3 id="Controller-network"><a href="#Controller-network" class="headerlink" title="Controller network"></a>Controller network</h3><p>ä¸­é—´çš„controller networkå¯ä»¥æ˜¯ä¸€ä¸ªæ™®é€šçš„feed forwardæˆ–è€…RNNã€‚</p><p>åœ¨å®é™…ä¸­NTMç”¨å¾—å¹¶ä¸å¤šã€‚</p><hr><h2 id="2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling"><a href="#2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling" class="headerlink" title="2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]"></a>2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]</h2><p>ELMoçš„ç²¾ç®€ç‰ˆï¼Œé€šè¿‡å³æ’å³ç”¨çš„æ–¹æ³•æ¥å‹ç¼©è¯­è¨€æ¨¡å‹ï¼Œå¯¹ç‰¹å®šä»»åŠ¡å‰ªæä¸åŒçš„å±‚ï¼Œä½¿å¾—èƒ½å¤Ÿå‡å°‘inferenceçš„æ—¶é—´ã€‚<br>è¿™ç¯‡çš„ideaæŒºæœ‰åˆ›æ–°çš„ï¼Œä½†ä¼¼ä¹æœ‰äº›trivialçš„æ„Ÿè§‰ã€‚</p><p><img src="/images/2018-11-11-15418977712883.jpg" width="70%" height="50%"></p><h3 id="RNN-and-Dense-Connectivity"><a href="#RNN-and-Dense-Connectivity" class="headerlink" title="RNN and Dense Connectivity"></a>RNN and Dense Connectivity</h3><p>æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¼šä¼ åˆ°æ‰€æœ‰å±‚ä½œä¸ºè¾“å…¥ï¼Œå› æ­¤å¯¹äºLå±‚çš„è¾“å…¥ï¼š<br><img src="/images/2018-11-11-15418979328482.jpg" width="35%" height="50%"></p><p>è¿™æ ·æˆ‘ä»¬å°±èƒ½å¤Ÿéšæ„åœ°å»æ‰ä»»æ„ä¸­é—´å±‚äº†ã€‚åŒæ—¶ä¸€äº›è¯­è¨€ä¿¡æ¯ä¹Ÿåˆ†æ•£åˆ°å„ä¸ªå±‚ï¼Œå³ä½¿å»æ‰æŸäº›å±‚ä¹Ÿæ²¡æœ‰å…³ç³»ã€‚</p><p>åˆ™æœ€ç»ˆçš„outputä¸ºï¼š<br><img src="/images/2018-11-11-15418991345288.jpg" width="33%" height="50%"></p><p>æœ€ç»ˆä½œprojectionåˆ°æ­£å¸¸ç»´åº¦ï¼ˆåœ¨æ¯å±‚éƒ½ä¼šè¿™ä¹ˆåšï¼Œå°†è¾“å…¥é™ç»´åˆ°æ­£å¸¸ç»´åº¦å†è¾“å…¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418992517849.jpg" width="37%" height="50%"></p><p>å†åšä¸€ä¸ªsoftmaxï¼š<br><img src="/images/2018-11-11-15418993146246.jpg" width="32%" height="50%"></p><p>ç”±äº $h^{â€»}$ ç”¨äºsoftmaxï¼Œæ‰€ä»¥å¯èƒ½å’Œtarget wordï¼Œä¹Ÿå³ä¸‹ä¸€ä¸ªè¯æ¯”è¾ƒç›¸ä¼¼ï¼Œ<strong>å› æ­¤å¯èƒ½æ²¡æœ‰å¾ˆå¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯</strong>ã€‚</p><p>æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬ä½¿ç”¨$h_t$ï¼Œä»¥åŠåå‘çš„$h_t^r$ï¼Œå†è¿‡ä¸€å±‚çº¿æ€§å±‚è·å¾—æœ€ç»ˆçš„embeddingï¼ˆå’ŒELMoæœ‰äº›ä¸åŒï¼ŒELMoæ˜¯ç›´æ¥æ‹¼èµ·æ¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418994541442.jpg" width="40%" height="50%"></p><h3 id="Layer-Selection"><a href="#Layer-Selection" class="headerlink" title="Layer Selection"></a>Layer Selection</h3><p>æˆ‘ä»¬åœ¨æ¯å±‚çš„outputéƒ½åŠ ä¸€ä¸ªæƒé‡ç³»æ•°ã€‚<br><img src="/images/2018-11-11-15418996081852.jpg" width="30%" height="50%"></p><p>æˆ‘ä»¬å¸Œæœ›åœ¨target taskä¸Šç”¨çš„æ—¶å€™ï¼Œéƒ¨åˆ†zèƒ½å¤Ÿå˜æˆ0ï¼Œè¾¾åˆ°layer selectionçš„æ•ˆæœï¼ŒåŠ å¿«inferenceçš„é€Ÿåº¦ã€‚</p><p>äº¦å³ï¼š<br><img src="/images/2018-11-11-15418996697208.jpg" width="20%" height="50%"></p><p>ä¸€ç§ç†æƒ³çš„æ–¹æ³•æ˜¯L0æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997294756.jpg" width="17%" height="50%"></p><p>ä½†ç”±äºæ²¡åŠæ³•æ±‚å¯¼ï¼Œå› æ­¤ï¼Œé‡‡ç”¨L1æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997747882.jpg" width="15%" height="50%"><br>ä½†ä½¿ç”¨L1æ­£åˆ™åŒ–æœ‰ä¸€å®šçš„é£é™©ï¼Œå› ä¸ºå¦‚æœè®©æ‰€æœ‰zéƒ½è¿œç¦»1ï¼Œé‚£ä¹ˆä¼šå½±å“performanceã€‚</p><p>å¼•å…¥æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•$R_2 =\delta(|z|_0&gt;\lambda_1) |z|_1$<br>äº¦å³ï¼Œåªæœ‰åœ¨éé›¶zçš„ä¸ªæ•°å¤§äºæŸä¸ªé˜ˆå€¼æ—¶ï¼Œæ‰èƒ½æœ‰æ­£åˆ™åŒ–æ•ˆæœï¼Œä¿è¯éé›¶çš„ä¸ªæ•°ã€‚â€™it can be â€œturned-offâ€ after achieving a satisfying sparsityâ€™.</p><p>è¿›ä¸€æ­¥å¼•å…¥$R_3=\delta(|z|_0&gt;\lambda_1) |z|_1 + |z(1-z)|_1$<br>å…¶ä¸­ç¬¬äºŒé¡¹ä¸ºäº†é¼“åŠ±zå‘0æˆ–1èµ°ã€‚</p><h3 id="Layer-wise-Dropout"><a href="#Layer-wise-Dropout" class="headerlink" title="Layer-wise Dropout"></a>Layer-wise Dropout</h3><p>éšæœºåˆ é™¤éƒ¨åˆ†layerï¼Œè¿™äº›layerçš„è¾“å‡ºä¸ä¼šä¼ å…¥ä¹‹åçš„å±‚ï¼Œä½†ä»ç„¶ä¼šå‚ä¸æœ€åçš„representationè®¡ç®—ã€‚<br><img src="/images/2018-11-11-15419000928057.jpg" width="70%" height="50%"></p><p>è¿™ç§dropoutä¼šè®©perplexityæ›´é«˜ï¼Œä½†å¯¹ç”Ÿæˆæ›´å¥½çš„representationæœ‰å¸®åŠ©ã€‚</p><hr><h2 id="3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder"><a href="#3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder" class="headerlink" title="3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]"></a>3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]</h2><p>å…¶ä¸­çš„positional encodingæˆ‘æ¯”è¾ƒæ„Ÿå…´è¶£ã€‚<br>åŸç‰ˆçš„positional encodingæ˜¯ç›´æ¥å’Œembeddingç›¸åŠ çš„ã€‚<br>äº¦å³ï¼š<br><img src="/images/2018-11-11-15419002563338.jpg" width="22%" height="50%"><br>é‚£ä¹ˆåœ¨selt-attentionæ—¶ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-11-15419002855901.jpg" width="45%" height="50%"><br>è¿™æ ·ä¼šæœ‰äº¤å‰é¡¹ï¼š<br><img src="/images/2018-11-11-15419003111684.jpg" width="13%" height="50%"><br>è¯¥é¡¹æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ï¼Œä¸”å¯èƒ½ä¼šå¸¦æ¥è¿‡æ‹Ÿåˆã€‚</p><p>å› æ­¤åœ¨è¿™è¾¹å°†positional encodingå’Œembeddingæ‹¼èµ·æ¥ï¼Œäº¦å³ï¼š<br><img src="/images/2018-11-11-15419003740409.jpg" width="23%" height="50%"></p><p>å¹¶ä¸”ï¼Œåœ¨è¿›å…¥multi-headæ—¶çš„çº¿æ€§å±‚ä¹Ÿåšæ”¹å˜ï¼š<br><img src="/images/2018-11-11-15419004269693.jpg" width="24%" height="50%"></p><p>è¿™æ ·åœ¨ç›¸ä¹˜çš„æ—¶å€™å°±ä¸ä¼šæœ‰äº¤å‰é¡¹äº†ã€‚</p><p>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰ä¸€å®šçš„æå‡ã€‚</p><hr><h2 id="4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>å¤§è‡´ç¿»äº†ä¸€ä¸‹ã€‚<br>Motivation:åœ¨CNNä¸­ï¼Œdropoutå¯¹convolutional layerçš„ä½œç”¨ä¸å¤§ï¼Œä¸€èˆ¬éƒ½åªç”¨åœ¨å…¨è¿æ¥å±‚ã€‚ä½œè€…æ¨æµ‹ï¼Œå› ä¸ºæ¯ä¸ªfeature mapéƒ½æœ‰ä¸€ä¸ªæ„Ÿå—é‡èŒƒå›´ï¼Œä»…ä»…å¯¹å•ä¸ªåƒç´ è¿›è¡Œdropoutå¹¶ä¸èƒ½é™ä½feature mapå­¦ä¹ çš„ç‰¹å¾èŒƒå›´ï¼Œäº¦å³ç½‘ç»œä»å¯ä»¥é€šè¿‡è¯¥ä½ç½®çš„ç›¸é‚»ä½ç½®å…ƒç´ å»å­¦ä¹ å¯¹åº”çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¹Ÿå°±ä¸ä¼šä¿ƒä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ã€‚</p><p>å› æ­¤ä½œè€…çš„åšæ³•æ˜¯ï¼Œdropoutä¸€æ•´å—ä½ç½®ã€‚<br><img src="/images/2018-11-11-15419007355875.jpg" width="80%" height="50%"></p><hr><h2 id="5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network"><a href="#5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network" class="headerlink" title="5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]"></a>5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]</h2><p>æå‡ºäº†AAN(average attention network)ï¼Œå¯¹transformerç¿»è¯‘æ¨¡å‹çš„decodeéƒ¨åˆ†è¿›è¡Œæ”¹è¿›ï¼ŒåŠ é€Ÿäº†è¿‡ç¨‹ã€‚</p><p>ç”±äºTransformeråœ¨decodeé˜¶æ®µéœ€è¦ç”¨åˆ°å‰é¢æ‰€æœ‰çš„yï¼Œä¹Ÿå³è‡ªå›å½’(auto-regressive)çš„æ€§è´¨ï¼Œæ‰€ä»¥æ— æ³•å¹¶è¡Œï¼š</p><p><img src="/images/2018-11-11-15419009098650.jpg" width="50%" height="50%"></p><h3 id="è¿‡ç¨‹"><a href="#è¿‡ç¨‹" class="headerlink" title="è¿‡ç¨‹"></a>è¿‡ç¨‹</h3><p>ç»™å®šyï¼š<br><img src="/images/2018-11-11-15419010325049.jpg" width="27%" height="50%"></p><p>é¦–å…ˆå°†ä»–ä»¬åŠ èµ·æ¥ï¼Œè¿‡ä¸€å±‚å…¨è¿æ¥ï¼š<br><img src="/images/2018-11-11-15419010603010.jpg" width="27%" height="50%"><br>è¿™ä¹Ÿç›¸å½“äºå°±æ˜¯è®©æ‰€æœ‰çš„yæœ‰ç›¸åŒçš„æƒé‡ï¼Œæ­¤æ—¶gå°±æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡¨ç¤ºã€‚</p><p>æ¥ä¸‹æ¥æ·»åŠ ä¸€ä¸ªgatingï¼š<br><img src="/images/2018-11-11-15419011154221.jpg" width="27%" height="50%"><br>æ§åˆ¶äº†ä»è¿‡å»ä¿å­˜å¤šå°‘ä¿¡æ¯å’Œè·å–å¤šå°‘æ–°çš„ä¿¡æ¯ã€‚</p><p>å’ŒTransformeråŸç‰ˆè®ºæ–‡ä¸€æ ·ï¼Œæ·»åŠ ä¸€ä¸ªresidual connectionï¼š<br><img src="/images/2018-11-11-15419011595237.jpg" width="30%" height="50%"></p><p>å¦‚å›¾æ•´ä¸ªè¿‡ç¨‹ï¼š<br><img src="/images/2018-11-11-15419011840751.jpg" width="55%" height="50%"></p><p>æ€»ç»“ï¼šAAN=average layer+gating layer</p><h3 id="åŠ é€Ÿ"><a href="#åŠ é€Ÿ" class="headerlink" title="åŠ é€Ÿ"></a>åŠ é€Ÿ</h3><p>â‘ è€ƒè™‘åˆ°åŠ å’Œæ“ä½œæ˜¯åºåˆ—åŒ–çš„ï¼Œåªèƒ½ä¸€ä¸ªä¸€ä¸ªæ¥ï¼Œä¸èƒ½å¹¶è¡Œï¼Œåœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªmaskçš„trickï¼Œä½¿å¾—åœ¨è®­ç»ƒæ—¶ä¹Ÿèƒ½å¤Ÿå¹¶è¡Œï¼š<br><img src="/images/2018-11-11-15419013219526.jpg" width="60%" height="50%"></p><p>â‘¡åœ¨inferenceæ—¶çš„åŠ é€Ÿï¼š<br><img src="/images/2018-11-11-15419019335926.jpg" width="20%" height="50%"></p><p>è¿™æ ·Transformerå°±èƒ½å¤Ÿç±»ä¼¼RNNï¼Œåªè€ƒè™‘å‰ä¸€ä¸ªçš„stateï¼Œè€Œä¸æ˜¯å‰é¢æ‰€æœ‰çš„stateã€‚</p><p>æœ€ç»ˆçš„æ¨¡å‹ï¼š<br><img src="/images/2018-11-11-15419023032628.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> dropout </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> self-attention </tag>
            
            <tag> NTM </tag>
            
            <tag> ELMo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯15</title>
      <link href="/2018/11/10/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D15/"/>
      <url>/2018/11/10/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D15/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£èœ€ç›¸"><a href="#1ï¸âƒ£èœ€ç›¸" class="headerlink" title="1ï¸âƒ£èœ€ç›¸"></a>1ï¸âƒ£èœ€ç›¸</h3><p>[å”] æœç”«<br>ä¸ç›¸ç¥ å ‚ä½•å¤„å¯»ï¼Œé”¦å®˜åŸå¤–æŸæ£®æ£®ã€‚<br>æ˜ é˜¶ç¢§è‰è‡ªæ˜¥è‰²ï¼Œéš”å¶é»„é¹‚ç©ºå¥½éŸ³ã€‚<br>ä¸‰é¡¾é¢‘çƒ¦å¤©ä¸‹è®¡ï¼Œä¸¤æœå¼€æµè€è‡£å¿ƒã€‚<br><strong>å‡ºå¸ˆæœªæ·èº«å…ˆæ­»ï¼Œé•¿ä½¿è‹±é›„æ³ªæ»¡è¥Ÿ</strong>ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡4</title>
      <link href="/2018/11/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%874/"/>
      <url>/2018/11/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%874/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention"><a href="#1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention" class="headerlink" title="1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]"></a>1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]</h2><p>å°†transformerç”¨äºcharacter-levelçš„è¯­è¨€æ¨¡å‹ä¸­ï¼Œé€šè¿‡æ·»åŠ å¤šä¸ªlossæ¥æé«˜å…¶è¡¨ç°ä»¥åŠåŠ å¿«æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶åŠ æ·±transformerçš„å±‚æ•°ï¼Œæå¤§æå‡è¡¨ç°ï¼Œ12å±‚çš„transformer layerèƒ½è¾¾åˆ°SOTAï¼Œè€Œ64å±‚åˆ™æœ‰æ›´å¤šçš„æå‡ã€‚</p><p>æ™®é€šRNNç”¨äºcharacter-level language modelï¼š<br>å°†å¥å­æŒ‰characterä¸ºå•ä½ç»„æˆå¤šä¸ªbatchï¼Œæ¯ä¸ªbatché¢„æµ‹æœ€åä¸€ä¸ªè¯ï¼Œç„¶åå°†è¯¥batchçš„éšçŠ¶æ€ä¼ å…¥ä¸‹ä¸€ä¸ªbatchã€‚ä¹Ÿå³â€œtruncated backpropagation through timeâ€ (TBTT)ã€‚</p><p>å¦‚æœç”¨åœ¨Transformerï¼Œå¦‚ä¸‹å›¾ï¼Œæˆ‘ä»¬åªé¢„æµ‹$t_4$ã€‚<br><img src="/images/2018-11-04-15412915431327.jpg" width="90%" height="50%"></p><p>æœ¬æ–‡çš„ä¸€å¤§è´¡çŒ®æ˜¯å¤šåŠ äº†ä¸‰ç§lossï¼Œå¹¶ä¸”æœ‰äº›lossçš„æƒå€¼ä¼šéšç€è®­ç»ƒçš„è¿‡ç¨‹è€Œé€æ¸å‡å°ï¼Œæ¯ä¸ªlosséƒ½ä¼šè‡ªå·±çš„scheduleã€‚è¿™äº›lossåŠ å¿«äº†æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶ä¹Ÿæå‡äº†è¡¨ç°ã€‚</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><h4 id="Multiple-Positions"><a href="#Multiple-Positions" class="headerlink" title="Multiple Positions"></a>Multiple Positions</h4><p>å¯¹äºbatchå†…è€Œè¨€ï¼Œæ¯ä¸ªæ—¶é—´æ­¥téƒ½è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚<br><img src="/images/2018-11-04-15412916429104.jpg" width="90%" height="50%"></p><h4 id="Intermediate-Layer-Losses"><a href="#Intermediate-Layer-Losses" class="headerlink" title="Intermediate Layer Losses"></a>Intermediate Layer Losses</h4><p>è¦æ±‚ä¸­é—´å±‚ä¹Ÿåšå‡ºé¢„æµ‹ï¼š<br><img src="/images/2018-11-04-15412916704097.jpg" width="95%" height="50%"></p><p>åœ¨è¿™é‡Œï¼Œè¶Šåº•å±‚çš„layerå…¶lossæƒå€¼è¶Šä½ã€‚</p><h4 id="Multiple-Targets"><a href="#Multiple-Targets" class="headerlink" title="Multiple Targets"></a>Multiple Targets</h4><p>æ¯ä¸€ä¸ªpositionï¼Œä¸ä»…ä»…è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿˜è¦é¢„æµ‹ä¸‹å‡ ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å’Œé¢„æµ‹ä¸‹å‡ ä¸ªè¯çš„åˆ†ç±»å™¨æ˜¯ç‹¬ç«‹çš„ã€‚</p><p><img src="/images/2018-11-04-15412917374689.jpg" width="70%" height="50%"></p><h3 id="Positional-embedding"><a href="#Positional-embedding" class="headerlink" title="Positional embedding"></a>Positional embedding</h3><p>æ¯ä¸€å±‚çš„éƒ½æ·»åŠ ä¸€ä¸ªä¸å…±äº«çš„å¯å­¦ä¹ çš„positional embeddingã€‚</p><hr><h2 id="2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations"><a href="#2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations" class="headerlink" title="2ï¸âƒ£[Self-Attention with Relative Position Representations]"></a>2ï¸âƒ£[Self-Attention with Relative Position Representations]</h2><p>æå‡ºä½¿ç”¨ç›¸å¯¹ä½ç½®æ›¿ä»£Transformerçš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¹¶åœ¨NMTä¸Šæœ‰ä¸€å®šçš„æå‡ã€‚</p><p>åˆ†è§£ï¼š<br>åœ¨åŸå…ˆçš„self-attentionä¸­ï¼Œè¾“å‡ºä¸ºï¼š<br><img src="/images/2018-11-04-15412923510664.jpg" width="25%" height="50%"></p><p>å…¶ä¸­ï¼š<br><img src="/images/2018-11-04-15412923744647.jpg" width="25%" height="50%"><br><img src="/images/2018-11-04-15412923773686.jpg" width="25%" height="50%"></p><p>ç°åœ¨æˆ‘ä»¬è€ƒè™‘æ·»åŠ ç›¸å¯¹ä½ç½®ï¼Œå…¶ä¸­ç›¸å¯¹ä½ç½®ä¿¡æ¯åœ¨å„å±‚éƒ½æ˜¯å…±äº«çš„ï¼š<br><img src="/images/2018-11-04-15412924279426.jpg" width="30%" height="50%"><br><img src="/images/2018-11-04-15412924396468.jpg" width="30%" height="50%"></p><p>$a_{ij}^K$çš„å…·ä½“å½¢å¼ï¼š<br><img src="/images/2018-11-04-15412925792994.jpg" width="40%" height="50%"><br><img src="/images/2018-11-04-15412925910424.jpg" width="55%" height="50%"><br>ä¸Šå¼ä¸ºäº†é™ä½å¤æ‚åº¦ï¼Œä¸è€ƒè™‘é•¿äºkçš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p><p>è€ƒè™‘åˆ°transformerçš„å¹¶è¡Œæ€§ï¼Œä¸ºäº†å¹¶è¡Œæ€§ï¼Œæˆ‘ä»¬è€ƒè™‘å¦‚ä¸‹å¼å­ï¼š<br><img src="/images/2018-11-04-15412926687951.jpg" width="50%" height="50%"><br>å…¶ä¸­ï¼Œç¬¬ä¸€é¡¹å’ŒåŸæ¥çš„Transformerä¸€è‡´ï¼›ç¬¬äºŒé¡¹ï¼Œé€šè¿‡reshapeå¯ä»¥è¾¾åˆ°å¹¶è¡Œçš„æ•ˆæœï¼Œç„¶åä¸¤é¡¹ç›´æ¥åŠ èµ·æ¥ã€‚</p><p>å®éªŒè¯æ˜ï¼Œä½¿ç”¨ç›¸å¯¹ä½ç½®æ•ˆæœæ˜¯æœ‰ä¸€å®šçš„æå‡çš„ï¼Œè€ŒåŒæ—¶ä½¿ç”¨ç»å¯¹ä½ç½®å’Œç›¸å¯¹ä½ç½®å¹¶æ²¡æœ‰æå‡ã€‚<br><img src="/images/2018-11-04-15412930642978.jpg" width="90%" height="50%"></p><hr><h2 id="3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION"><a href="#3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION" class="headerlink" title="3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]"></a>3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]</h2><p>è¿™ç¯‡è¢«ICLRæ‹’äº†ï¼Œä½†æœ‰å®¡ç¨¿äººæ‰“äº†9åˆ†çš„é«˜åˆ†ã€‚</p><p>å¯¹Transformerè¿›è¡Œæ”¹è¿›ï¼Œæ‹¥æœ‰æ›´å¥½çš„æ•ˆæœå’Œæ›´å°çš„è®¡ç®—ä»£ä»·ã€‚</p><p>ä¼ ç»Ÿçš„Transformerï¼š</p><script type="math/tex; mode=display">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V</script><script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">MultiHead(Q,K,V)=Concat_i (head_i)W^O</script><script type="math/tex; mode=display">FFN(x)=max(0,xW_1+b_1)W_2 + b_2</script><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå…ˆå¯¹headè¿›è¡Œå‡ç»´å¹¶ä¹˜ä»¥æƒé‡ï¼Œè¿‡äº†FNNåï¼Œå†ä¹˜ä»¥å¦ä¸€ä¸ªæƒé‡ã€‚å…¶ä¸­æƒé‡$\alpha$ $ \kappa$ä¸ºå¯å­¦ä¹ å‚æ•°ï¼š</p><script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">\overline{head_i}=head_i W^{O_i} \times \kappa_i</script><script type="math/tex; mode=display">BranchedAttention(Q,K,V)=\sum_{i=1}^{M} \alpha_i FFN(\overline{head}_i)</script><p>å…¶ä¸­è¦æ±‚æƒé‡ä¹‹å’Œä¸º1ã€‚å³$\sum_{i=1}^{M}\alpha_i=1$,$\sum_{i=1}^{M}\kappa_i=1$ã€‚</p><p><img src="/images/2018-11-04-15412939412047.jpg" width="90%" height="50%"></p><p>æ–‡ä¸­å¯¹$\kappa$å’Œ$\alpha$ä½œäº†è§£é‡Šã€‚</p><blockquote><p>Îº can be interpreted as a learned concatenation weight and Î± as the learned addition weight</p></blockquote><p>é€šè¿‡å®éªŒï¼Œå‘ç°è¯¥æ¨¡å‹ä¼šæœ‰æ›´å¥½çš„æ­£åˆ™åŒ–ç‰¹æ€§ã€‚åŒæ—¶æ•ˆæœä¹Ÿæœ‰ä¸€å®šæå‡ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼š<br><img src="/images/2018-11-04-15412940966579.jpg" width="80%" height="50%"></p><hr><h2 id="4ï¸âƒ£-You-May-Not-Need-Attention"><a href="#4ï¸âƒ£-You-May-Not-Need-Attention" class="headerlink" title="4ï¸âƒ£[You May Not Need Attention]"></a>4ï¸âƒ£[You May Not Need Attention]</h2><p>ç²—ç•¥åœ°è¿‡äº†ä¸€éï¼Œä¸€äº›ç»†èŠ‚æ²¡æœ‰å¼„æ˜ç™½ã€‚</p><p>æå‡ºä¸€ç§å°†encoder-decoderèåˆèµ·æ¥çš„æ¨¡å‹ï¼Œä¹Ÿå³eager translation modelï¼Œä¸éœ€è¦attentionï¼Œèƒ½å¤Ÿå®ç°å³æ—¶çš„ç¿»è¯‘ï¼Œä¹Ÿå³è¯»å…¥ä¸€ä¸ªè¯å°±èƒ½ç¿»è¯‘ä¸€ä¸ªè¯ï¼ŒåŒæ—¶ä¸éœ€è¦è®°å½•encoderçš„æ‰€æœ‰è¾“å‡ºï¼Œå› æ­¤éœ€è¦å¾ˆå°‘çš„å†…å­˜ã€‚</p><p><img src="/images/2018-11-04-15412942175720.jpg" width="50%" height="50%"></p><p>åˆ†ä¸ºä¸‰æ­¥ï¼š<br>â‘ pre-processing<br>è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿å¾—æºå¥å­å’Œç›®æ ‡å¥å­æ»¡è¶³<strong>eager feasible</strong> for every aligned pair of words $(s_i , t_j ), i â‰¤ j$ã€‚</p><p>é¦–å…ˆé€šè¿‡ç°æˆçš„å·¥å…·è¿›è¡Œå¯¹é½æ“ä½œ(alignment)ï¼Œç„¶åå¯¹äºé‚£äº›ä¸ç¬¦åˆeager feasibleçš„æœ‰å…·ä½“ç®—æ³•ï¼ˆæ²¡è®¤çœŸçœ‹ï¼‰è¿›è¡Œè¡¥paddingã€‚å¦‚å›¾<br><img src="/images/2018-11-04-15412945231042.jpg" width="60%" height="50%"></p><p>æˆ‘ä»¬è¿˜å¯ä»¥åœ¨target sentenceçš„å¼€å¤´æ·»åŠ bä¸ªpaddingï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¼€å§‹é¢„æµ‹ä¹‹å‰è·å–æ›´å¤šçš„source sentenceçš„è¯ã€‚</p><p>â‘¡æ¨¡å‹<br>ä¸¤å±‚çš„LSTMï¼Œè¾“å…¥æ˜¯ä¸Šä¸€æ¬¡çš„yå’Œå½“å‰çš„xæ‹¼æ¥èµ·æ¥ç›´æ¥ä¼ è¿›å»ã€‚</p><p>â‘¢post processing<br>åœ¨æœ€ç»ˆç»“æœä¹‹å‰ï¼Œå°†paddingå»æ‰ã€‚</p><p>åœ¨inferenceï¼ˆä¹Ÿå³beam searchï¼‰æ—¶ï¼Œè¿˜æœ‰å‡ ä¸ªæ“ä½œ/trickï¼š</p><ul><li>Padding limit</li><li>Source padding injection SPI</li></ul><p>å®éªŒè¡¨æ˜ï¼Œeager modelåœ¨é•¿çš„å¥å­è¡¨ç°è¶…è¿‡ä¼ ç»Ÿå¸¦attentionçš„NMTï¼Œè€Œé•¿å¥å­çš„å»ºæ¨¡æ­£æ˜¯attention-based çš„æ¨¡å‹çš„ä¸€å¤§æŒ‘æˆ˜ï¼›è€Œåœ¨çŸ­å¥å­ä¸Šå°±ä¸å¦‚attention-basedçš„NMTã€‚<br><img src="/images/2018-11-04-15412946442983.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> Language Modeling </tag>
            
            <tag> self-attention </tag>
            
            <tag> relative position </tag>
            
            <tag> positional encoding </tag>
            
            <tag> NMT </tag>
            
            <tag> eager translation model </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯14</title>
      <link href="/2018/11/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D14/"/>
      <url>/2018/11/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D14/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£é¹¤å†²å¤©"><a href="#1ï¸âƒ£é¹¤å†²å¤©" class="headerlink" title="1ï¸âƒ£é¹¤å†²å¤©"></a>1ï¸âƒ£é¹¤å†²å¤©</h3><p>[å®‹] æŸ³æ°¸<br>é»„é‡‘æ¦œä¸Šï¼Œå¶å¤±é¾™å¤´æœ›ã€‚æ˜ä»£æš‚é—è´¤ï¼Œå¦‚ä½•å‘ï¼Ÿæœªé‚é£äº‘ä¾¿ï¼Œäº‰ä¸æ£æ¸¸ç‹‚è¡ã€‚ä½•é¡»è®ºå¾—ä¸§ï¼Ÿæ‰å­è¯äººï¼Œè‡ªæ˜¯ç™½è¡£å¿ç›¸ã€‚<br>çƒŸèŠ±å··é™Œï¼Œä¾çº¦ä¸¹é‘å±›éšœã€‚å¹¸æœ‰æ„ä¸­äººï¼Œå ªå¯»è®¿ã€‚ä¸”æåçº¢å€šç¿ ï¼Œé£æµäº‹ï¼Œå¹³ç”Ÿç•…ã€‚é‘æ˜¥éƒ½ä¸€é¥·ã€‚<strong>å¿æŠŠæµ®åï¼Œæ¢äº†æµ…æ–Ÿä½å”±</strong>ï¼</p><p>æ£ï¼ˆzÃ¬ï¼‰ï¼šæ”¾çºµï¼Œéšå¿ƒæ‰€æ¬²ã€‚<br>æï¼ˆnÃ¨nï¼‰ï¼šå¦‚æ­¤ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•9</title>
      <link href="/2018/11/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%959/"/>
      <url>/2018/11/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%959/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-collate-fn"><a href="#1ï¸âƒ£-collate-fn" class="headerlink" title="1ï¸âƒ£[collate_fn]"></a>1ï¸âƒ£[collate_fn]</h3><p>å°†ä¸ç­‰é•¿å¥å­ç»„åˆæˆbatchã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(insts)</span>:</span></span><br><span class="line">    <span class="string">''' Pad the instance to the max seq length in batch '''</span></span><br><span class="line"></span><br><span class="line">    max_len = max(len(inst) <span class="keyword">for</span> inst <span class="keyword">in</span> insts)</span><br><span class="line"></span><br><span class="line">    batch_seq = np.array([</span><br><span class="line">        inst + [Constants.PAD] * (max_len - len(inst))</span><br><span class="line">        <span class="keyword">for</span> inst <span class="keyword">in</span> insts])</span><br><span class="line"></span><br><span class="line">    batch_pos = np.array([</span><br><span class="line">        [pos_i + <span class="number">1</span> <span class="keyword">if</span> w_i != Constants.PAD <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">         <span class="keyword">for</span> pos_i, w_i <span class="keyword">in</span> enumerate(inst)] <span class="keyword">for</span> inst <span class="keyword">in</span> batch_seq]) <span class="comment"># ä½ç½®ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line">    batch_seq = torch.LongTensor(batch_seq)</span><br><span class="line">    batch_pos = torch.LongTensor(batch_pos)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_seq, batch_pos</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>â€œè±æ–¯æ¯â€æŒ‘æˆ˜èµ›æœ‰æ„Ÿ</title>
      <link href="/2018/10/30/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E2%80%9C%E8%8E%B1%E6%96%AF%E6%9D%AF%E2%80%9D%E6%8C%91%E6%88%98%E8%B5%9B%E6%9C%89%E6%84%9F/"/>
      <url>/2018/10/30/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E2%80%9C%E8%8E%B1%E6%96%AF%E6%9D%AF%E2%80%9D%E6%8C%91%E6%88%98%E8%B5%9B%E6%9C%89%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<p>å†æ—¶ä¸‰ä¸ªæœˆçš„â€œè±æ–¯æ¯â€å…¨å›½ç¬¬ä¸€å±Šâ€œå†›äº‹æ™ºèƒ½Â·æœºå™¨é˜…è¯»â€æŒ‘æˆ˜èµ›ç»ˆäºè½ä¸‹å¸·å¹•ï¼Œå‰å‡ æ—¥ï¼ˆ10.26-10.28ï¼‰æœ‰å¹¸åœ¨å—äº¬é’æ—…å®¾é¦†å‚ä¸å†³èµ›ï¼Œä½“éªŒå¤šå¤šï¼Œæ”¶è·æ»¡æ»¡ï¼Œå¿ƒä¸­äº¦æœ‰ä¸€äº›æ„Ÿæƒ³ã€‚</p><p>ä¸€ä¸ªæ˜¯å—äº¬æ€»å¸¦ç»™æˆ‘ä¸€ç§å›å®¶çš„æ„Ÿè§‰ï¼Œå¯¹å—äº¬çš„äº‹ç‰©æ€»æœ‰äº²åˆ‡æ„Ÿã€‚ç¬¬ä¸€æ¬¡æ¥å—äº¬æ˜¯ä¸€å¹´åŠå‰ï¼Œä¹Ÿæ˜¯æ¥å‚åŠ æ¯”èµ›ã€‚å‘¨äº”æ™šä¸Šçš„å¤œæ¸¸ç§¦æ·®ï¼Œè®©æˆ‘æ„Ÿå—åˆ°è®¸ä¹…æœªæ›¾æ„Ÿå—åˆ°çš„çƒŸç«æ°”æ¯ã€‚</p><p><img src="/images/2018-10-30-511540860855_.pic_hd.jpg" width="90%" height="50%"></p><p>ç¬¬äºŒä¸ªæ˜¯æ­¤æ¬¡ä¸»åŠæ–¹æä¾›çš„é£Ÿå®¿ä»¤äººæƒŠå–œã€‚ä¸€å¼€å§‹å¬åˆ°é’æ—…å®¾é¦†ï¼Œæˆ‘å·²ç»åšå¥½äº†è‰°è‹¦å¥‹æˆ˜çš„å‡†å¤‡äº†ï¼Œç„¶è€Œé…’åº—æ˜¯æ˜Ÿçº§é…’åº—çš„ï¼Œåƒæ–¹é¢ç›´æ¥åˆ°æ¥¼ä¸‹çš„è‡ªåŠ©ã€‚å¯ä»¥çœ‹å‡ºä¸»åŠæ–¹æ­¤æ¬¡ç¡®å®ç”¨å¿ƒåœ¨ä¸¾åŠè¿™æ¬¡æ¯”èµ›ã€‚</p><p><img src="/images/2018-10-30-15408644190676.jpg" width="100%" height="50%"></p><p>ç¬¬ä¸‰ç‚¹æ˜¯å…³äºæ¯”èµ›çš„ï¼Œå…³äºæ¯”èµ›çš„æ•´ä¸ªå†ç¨‹æˆ‘è¿˜æ˜¯é¢‡æœ‰æ„Ÿè§¦ã€‚<br>æˆ‘ä»¬æ˜¯ä»¥ç¬¬9åçš„æˆç»©æŒºè¿›å†³èµ›ï¼Œå…¶å®åœ¨åæœŸæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬éƒ½æœ‰æ‰€æ‡ˆæ€ äº†ï¼Œå‡ ä¹æ²¡æœ‰èŠ±æ—¶é—´åœ¨è¿™ä¸Šé¢ï¼Œ10æœˆåˆå‘å¸ƒå†³èµ›çš„æ•°æ®é›†ï¼Œè€Œæˆ‘ä»¬åœ¨10æœˆ20æ—¥æ‰å¾—çŸ¥è¿™ä¸€äº‹æƒ…ï¼Œæ­¤æ—¶ç¦»å†³èµ›åªå‰©ä¸€å‘¨æ—¶é—´ã€‚å› æ­¤æˆ‘ä»¬ç¡®å®å‡†å¤‡ä¸è¶³ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿæ²¡æœ‰é¢„æ–™åˆ°æˆ‘ä»¬çš„å†³èµ›æˆç»©ä¼šè¿™ä¹ˆé å‰ï¼Œå¦åˆ™æˆ‘ä»¬è‚¯å®šä¼šæ›´åŠ å……åˆ†å»å‡†å¤‡ã€‚è¿™ç¡®å®æ˜¯æˆ‘ä»¬çš„å¤±è¯¯ã€‚</p><p>æˆ‘ä»¬åœ¨æ¯”èµ›è¿‡ç¨‹ä¸­ï¼Œä¸€ç›´å°è¯•åœ¨ä½¿ç”¨ELMoï¼Œè¿™æ­£æ˜¯æˆ‘è´Ÿè´£çš„éƒ¨åˆ†ã€‚ä¸€å¼€å§‹ä½¿ç”¨å®˜æ–¹TensorFlowçš„ä»£ç ï¼Œè´¹äº†ä¹ç‰›äºŒè™ä¹‹åŠ›æˆ‘æ‰è·‘é€šä»£ç ï¼Œä½†å› ä¸ºé˜Ÿé•¿ä½¿ç”¨çš„æ˜¯pytorchï¼Œè€ŒäºŒè€…åœ¨cudaç‰ˆæœ¬ä¸Šä¸å…¼å®¹ï¼Œå› æ­¤åœ¨åˆèµ›æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ELMoã€‚è€Œåœ¨æœ€åå‡ å¤©ï¼Œæˆ‘å°è¯•ä½¿ç”¨å“ˆå·¥å¤§çš„pytorchè®­ç»ƒä»£ç ï¼Œä½†å› ä¸ºinferenceé€Ÿåº¦å®åœ¨å¤ªæ…¢ï¼Œæˆ‘ä»¬æœ€ç»ˆè¿˜æ˜¯å¼ƒç”¨äº†è¿™ä¸ªæ–¹æ¡ˆã€‚è€Œåœ¨å†³èµ›ç°åœºï¼Œæˆ‘ä»¬å‘ç°ä¹Ÿç¡®å®æ˜¯å› ä¸ºé€Ÿåº¦å’Œèµ„æºçš„åŸå› ï¼Œå¤§å®¶éƒ½æ²¡æœ‰ä½¿ç”¨ELMoï¼Œé™¤äº†ä¸€ç»„ã€‚è¯¥ç»„æ­£æ˜¯å‡­å€Ÿäº†ELMoå¼¯é“è¶…è½¦ä»ç¬¬7å‡åˆ°äº†ç¬¬ä¸€ï¼Œæ‹¿èµ°äº†20ä¸‡å¤§å¥–ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬éå¸¸é—æ†¾çš„ä¸€ä¸ªåœ°æ–¹ï¼Œæˆ‘ä»¬åœ¨é‡åˆ°å›°éš¾æ—¶æ²¡æœ‰å°è¯•è§£å†³ï¼Œè€Œæ˜¯ç›´æ¥å¼ƒç”¨ï¼Œæœ€ç»ˆæ²¡æœ‰å–å¾—æ›´å¥½çš„æˆç»©ã€‚</p><p>æ­¤æ¬¡æˆ‘ä»¬çš„æˆç»©æ’åç¬¬4(ä¸‰ç­‰å¥–)ï¼Œæ˜¯æœ‰ä¸€å®šçš„è¿›æ­¥çš„ï¼Œä½†æœ‰ä¸€ç‚¹é—æ†¾çš„æ˜¯ï¼Œæˆ‘ä»¬ä»…å·®0.18ç™¾åˆ†ç‚¹ï¼Œå°±èƒ½è¶…è¿‡ç¬¬ä¸‰åæ‹¿åˆ°5ä¸‡çš„å¥–é‡‘äº†ã€‚åé¢æˆ‘ä»¬åˆ†æäº†ä¸€ä¸‹ï¼Œè¿˜æ˜¯å› ä¸ºæˆ‘ä»¬å¯¹æ¯”èµ›æ‡ˆæ€ çš„æ€åº¦ï¼Œå…¶ä»–ç»„éƒ½å¯¹æ•°æ®è¿›è¡Œäº†åˆ†æå¹¶æœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ï¼Œè€Œæˆ‘ä»¬å¹¶æ²¡æœ‰åšè¿™ä¸€æ­¥ã€‚</p><p>Anywayï¼Œç¬¬ä¸€æ¬¡ç»„é˜Ÿå‚åŠ æ¯”èµ›å°±æœ‰æ”¶è·ï¼Œå¢é•¿äº†è§è¯†ï¼Œä»äº¤æµä¸­ä¹Ÿè·å¾—äº†è®¸å¤šã€‚è¿™ä¸ªæ¯”èµ›ä¹‹åï¼Œå°±å¾—å¥½å¥½çœ‹paperäº†ã€‚ __(:Ğ·ã€âˆ )_</p><p><img src="/images/2018-10-30-521540861008_.pic_hd.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœ‰æ„Ÿ </tag>
            
            <tag> è±æ–¯æ¯ </tag>
            
            <tag> æ¯”èµ› </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯13</title>
      <link href="/2018/10/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D13/"/>
      <url>/2018/10/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D13/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"><a href="#1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–" class="headerlink" title="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"></a>1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–</h3><p>[å”] æç™½<br>ã€å…¶ä¸€ã€‘<br>é‡‘æ¨½æ¸…é…’æ–—ååƒï¼Œç‰ç›˜çç¾ç›´ä¸‡é’±ã€‚<br><strong>åœæ¯æŠ•ç®¸ä¸èƒ½é£Ÿï¼Œæ‹”å‰‘å››é¡¾å¿ƒèŒ«ç„¶</strong>ã€‚<br>æ¬²æ¸¡é»„æ²³å†°å¡å·ï¼Œå°†ç™»å¤ªè¡Œé›ªæ»¡å±±ã€‚<br>é—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚<br>è¡Œè·¯éš¾ï¼Œè¡Œè·¯éš¾ï¼Œå¤šæ­§è·¯ï¼Œä»Šå®‰åœ¨ï¼Ÿ<br><strong>é•¿é£ç ´æµªä¼šæœ‰æ—¶ï¼Œç›´æŒ‚äº‘å¸†æµæ²§æµ·</strong>ï¼</p><p><strong>æ³¨é‡Š</strong>ï¼š<br>ã€Œé—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚ã€å¥ï¼šæš—ç”¨å…¸æ•…ï¼šå§œå¤ªå…¬å•å°šæ›¾åœ¨æ¸­æ°´çš„ç£»æºªä¸Šé’“é±¼ï¼Œå¾—é‡å‘¨æ–‡ç‹ï¼ŒåŠ©å‘¨ç­å•†ï¼›ä¼Šå°¹æ›¾æ¢¦è§è‡ªå·±ä¹˜èˆ¹ä»æ—¥æœˆæ—è¾¹ç»è¿‡ï¼Œåè¢«å•†æ±¤è˜è¯·ï¼ŒåŠ©å•†ç­å¤ã€‚è¿™ä¸¤å¥è¡¨ç¤ºè¯—äººè‡ªå·±å¯¹ä»æ”¿ä»æœ‰æ‰€æœŸå¾…ã€‚ç¢§ï¼Œä¸€ä½œã€Œåã€ã€‚</p><hr><h3 id="2ï¸âƒ£ç™»ç§‘å"><a href="#2ï¸âƒ£ç™»ç§‘å" class="headerlink" title="2ï¸âƒ£ç™»ç§‘å"></a>2ï¸âƒ£ç™»ç§‘å</h3><p>[å”] å­ŸéƒŠ<br>æ˜”æ—¥é¾Œé¾Šä¸è¶³å¤¸ï¼Œä»Šæœæ”¾è¡æ€æ— æ¶¯ã€‚<br><strong>æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±</strong>ã€‚</p><p><strong>æ³¨é‡Š</strong>ï¼š<br>é¾Œé¾Šï¼ˆwÃ² chuÃ²ï¼‰ï¼šåŸæ„æ˜¯è‚®è„ï¼Œè¿™é‡ŒæŒ‡ä¸å¦‚æ„çš„å¤„å¢ƒã€‚ä¸è¶³å¤¸ï¼šä¸å€¼å¾—æèµ·ã€‚<br>æ”¾è¡ï¼ˆdÃ ngï¼‰ï¼šè‡ªç”±è‡ªåœ¨ï¼Œä¸å—çº¦æŸã€‚<br>æ€æ— æ¶¯ï¼šå…´è‡´é«˜æ¶¨ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡3</title>
      <link href="/2018/10/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%873/"/>
      <url>/2018/10/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%873/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-A-Neural-Probabilistic-Language-Model"><a href="#1ï¸âƒ£-A-Neural-Probabilistic-Language-Model" class="headerlink" title="1ï¸âƒ£[A Neural Probabilistic Language Model]"></a>1ï¸âƒ£[A Neural Probabilistic Language Model]</h2><p>ç¬¬ä¸€ç¯‡ä½¿ç”¨ç¥ç»ç½‘ç»œè·å¾—è¯å‘é‡çš„paperã€‚</p><p>é€šè¿‡å¯¹language modelå»ºæ¨¡ï¼Œå°†è¯æ˜ å°„åˆ°ä½ç»´è¡¨ç¤ºï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶è®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥åŠæ¯ä¸ªè¯çš„è¯å‘é‡ã€‚</p><p><img src="/images/2018-10-29-15407808716787.jpg" width="50%" height="50%"></p><p>å°†ä¸­å¿ƒè¯çš„å‰nä¸ªæ‹¼æ¥èµ·æ¥ $x=(C(w_{t-1},C(w_{t-2}),â€¦,C(w_{t-n+1}))$<br>å°†$x$é€å…¥ç¥ç»ç½‘ç»œä¸­è·å¾—$y=b+Wx+Utanh(d+Hx)$ï¼Œæœ€ååšä¸€ä¸ªsoftmaxå³å¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks"><a href="#2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks" class="headerlink" title="2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]"></a>2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]</h2><p>ä¸€ç§å…è®¸RNNåŠ¨æ€å †å å±‚æ•°çš„ç®—æ³•ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>è¯æ®è¯æ˜ï¼ŒRNNçš„å †å å±‚æ•°å¤šï¼Œæ•ˆæœä¼šæœ‰æå‡ã€‚ä½†æ˜¯ï¼Œå¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œè¦æ±‚ä¸åŒçš„è®¡ç®—å¤æ‚åº¦ã€‚æˆ‘ä»¬éœ€è¦å…ˆéªŒæ¥å†³å®šç‰¹å®šä»»åŠ¡çš„è®¡ç®—å¤æ‚åº¦ã€‚å½“ç„¶æˆ‘ä»¬å¯ä»¥ç²—æš´åœ°ç›´æ¥å †å æ·±å±‚çš„ç½‘ç»œã€‚ACT(Adaptive Computation Time)èƒ½å¤ŸåŠ¨æ€å†³å®šæ¯ä¸ªè¾“å…¥tæ‰€éœ€çš„è®¡ç®—æ¬¡æ•°ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å°†RNNæ¯ä¸€æ­¥çš„è¾“å‡ºè¿‡ä¸€ä¸ªç½‘ç»œ+sigmoidå±‚ï¼Œè·å¾—ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå³ä»€ä¹ˆæ—¶å€™åº”å½“åœæ­¢ä¸å†ç»§ç»­å¾€ä¸Šå †å ï¼Œç›´åˆ°æ¦‚ç‡åŠ å’Œä¸º1ã€‚åŒæ—¶ä¸ºäº†å°½å¯èƒ½æŠ‘åˆ¶å±‚æ•°çš„æ— é™å¢é•¿ï¼Œåœ¨lossæ·»åŠ ä¸€é¡¹æƒ©ç½šã€‚</p><h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p>å¯¹äºæ™®é€šçš„RNNï¼š<br><img src="/images/2018-10-29-15408103221289.jpg" width="30%" height="50%"></p><p>sæ˜¯éšè—å±‚ï¼›yæ˜¯è¾“å‡ºã€‚</p><p>å¯¹äºACTçš„RNNï¼Œæœ‰ï¼š<br><img src="/images/2018-10-29-15408103823681.jpg" width="40%" height="50%"></p><p>ä¸Šæ ‡næ˜¯æŒ‡çš„tæ—¶åˆ»çš„å±‚æ•°ï¼›å…¶ä¸­ï¼š<br><img src="/images/2018-10-29-15408104201718.jpg" width="20%" height="50%"></p><p>$Î´$æ˜¯flatï¼ŒæŒ‡ç¤ºxæ˜¯ç¬¬å‡ æ¬¡è¾“å…¥ã€‚</p><p>å¼•å…¥æ–°çš„ç½‘ç»œï¼Œè¾“å…¥æ—¶éšçŠ¶æ€ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼š<br><img src="/images/2018-10-29-15408105451770.jpg" width="30%" height="50%"></p><p>é‚£ä¹ˆæ¯ä¸€å±‚çš„æ¦‚ç‡æ˜¯ï¼š<br><img src="/images/2018-10-29-15408105687677.jpg" width="35%" height="50%"></p><p>å…¶ä¸­$R(t)$æ˜¯åœ¨æ¯ä¸€å±‚æ¦‚ç‡æ±‚å’Œè¶…è¿‡1æ—¶çš„å‰©ä½™æ¦‚ç‡ï¼ˆä¸ºäº†ä¿è¯æ¦‚ç‡å’Œä¸º1ï¼Œå¯ä»¥è¯•ç€ä¸¾ä¸€ä¸ªä¾‹å­æ¥è¯æ˜ï¼‰<br><img src="/images/2018-10-29-15408106099743.jpg" width="45%" height="50%"></p><p><img src="/images/2018-10-29-15408106125837.jpg" width="25%" height="50%"></p><p>Îµæ˜¯ä¸ºäº†è§£å†³ç¬¬ä¸€æ¬¡è¾“å‡ºæ—¶å°±è¶…è¿‡1-Îµçš„æƒ…å†µï¼ŒÎµä¸€èˆ¬å–å¾ˆå°ã€‚</p><p>æœ€ç»ˆï¼ŒåŠ æƒæ±‚å’Œï¼Œä½œä¸ºæœ€ç»ˆçš„ç»“æœï¼Œä¼ å…¥ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼š<br><img src="/images/2018-10-29-15408106649319.jpg" width="45%" height="50%"></p><p>æ™®é€šRNNä¸ACTçš„RNNå¯¹æ¯”ï¼š<br><img src="/images/2018-10-29-15408106950342.jpg" width="90%" height="50%"></p><h4 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h4><p>ä¸ºäº†é˜²æ­¢æ¨¡å‹å±‚æ•°æ— é™å¢é•¿ï¼Œæ·»åŠ ä¸€é¡¹æƒ©ç½šé¡¹ä»¥æŠ‘åˆ¶ã€‚</p><p>è®°æ¯ä¸€æ­¥çš„æƒ©ç½šé¡¹ä¸ºï¼š<br><img src="/images/2018-10-29-15408107184035.jpg" width="23%" height="50%"></p><p>æ€»çš„æƒ©ç½šé¡¹åˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408107351871.jpg" width="19%" height="50%"></p><p>Loss functionåˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408108024183.jpg" width="35%" height="50%"></p><p>å› ä¸ºN(t)æ˜¯ä¸å¯å¯¼çš„ï¼Œæˆ‘ä»¬åœ¨å®é™…è¿‡ç¨‹ä¸­åªå»æœ€å°åŒ–R(t)  ï¼ˆ<del>æˆ‘è§‰å¾—ä¸ç”šåˆç†</del>ï¼Œä¸€ç§è§£è¯»æ˜¯å¦‚æœæˆ‘ä»¬ä¸æ–­æœ€å°åŒ–R(t)ç›´åˆ°å˜æˆ0ï¼Œé‚£ä¹ˆç›¸å½“äºN(t)å°‘äº†ä¸€å±‚ï¼Œæ¥ç€R(t)å°±ä¼šå˜å¾—å¾ˆå¤§ï¼Œç„¶ååˆç»§ç»­æœ€å°åŒ–R(t)â€¦ï¼‰</p><hr><h2 id="3ï¸âƒ£-Universal-Transformers"><a href="#3ï¸âƒ£-Universal-Transformers" class="headerlink" title="3ï¸âƒ£[Universal Transformers]"></a>3ï¸âƒ£[Universal Transformers]</h2><p>æå‡ºä¸€ç§æ–°å‹é€šç”¨çš„transformerã€‚</p><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>Transformerçš„é—®é¢˜ï¼šRNNçš„å½’çº³åç½®(inductive bias)åœ¨ä¸€äº›ä»»åŠ¡ä¸Šå¾ˆé‡è¦ï¼Œä¹Ÿå³RNNçš„å¾ªç¯å­¦ä¹ çš„è¿‡ç¨‹ï¼›Transformeråœ¨ä¸€äº›é—®é¢˜ä¸Šè¡¨ç°ä¸å¥½ï¼Œå¯èƒ½æ˜¯å½’çº³åç½®çš„åŸå› ã€‚</p><blockquote><p>Notably, however, the Transformer foregoes the RNNâ€™s inductive bias towards learning iterative or recursive transformations.Our experiments indicate that this inductive bias may be crucial for several algorithmic and language understanding tasks of varying complexity: in contrast to models such as the Neural Turing Machine [13], the Neural GPU [17] or Stack RNNs [16], the Transformer does not generalize well to input lengths not encountered during training.</p></blockquote><p>å› æ­¤åœ¨Transformerå†…å¼•å…¥å½’çº³åç½®</p><h3 id="ç‰¹ç‚¹"><a href="#ç‰¹ç‚¹" class="headerlink" title="ç‰¹ç‚¹"></a>ç‰¹ç‚¹</h3><ul><li>æ¯ä¸€å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³multi-headä¸Šçš„æƒé‡ä»¥åŠtransition functionåœ¨æ¯ä¸€å±‚æ˜¯ä¸€è‡´çš„ã€‚è¿™ä¸€ç‚¹å’ŒRNNã€CNNä¸€è‡´ã€‚</li><li>åŠ¨æ€å±‚æ•°ï¼ˆACT mechanism ï¼‰ï¼šå¯¹äºæ¯ä¸ªè¯éƒ½ä¼šæœ‰ä¸åŒçš„å¾ªç¯æ¬¡æ•°ï¼›ä¹Ÿå³æœ‰äº›è¯éœ€è¦æ›´å¤šçš„refineï¼›è€Œæœ‰äº›è¯ä¸éœ€è¦ã€‚å’Œå›ºå®šå±‚æ•°çš„transformerç›¸æ¯”ï¼Œä¼šæœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li></ul><h3 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><h4 id="æ€»ä½“æ¶æ„"><a href="#æ€»ä½“æ¶æ„" class="headerlink" title="æ€»ä½“æ¶æ„"></a>æ€»ä½“æ¶æ„</h4><p><img src="/images/2018-10-29-15408125098915.jpg" width="90%" height="50%"></p><p>è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-29-15408125469899.jpg" width="45%" height="50%"></p><p><img src="/images/2018-10-29-15408125685038.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-29-15408125974795.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-29-15408126143943.jpg" width="60%" height="50%"></p><p>å’Œæ™®é€šTransformerä¸åŒçš„åœ°æ–¹åœ¨äºï¼š</p><ul><li>åŠ äº†ä¸€å±‚Transitionå±‚ï¼ŒTransitionå¯ä»¥æ˜¯depth-wise separable convolutionï¼ˆ<a href="https://www.cnblogs.com/adong7639/p/7918527.html" target="_blank" rel="noopener">æ˜¯ä»€ä¹ˆï¼Ÿ</a>ï¼‰æˆ–è€…å…¨è¿æ¥å±‚ã€‚</li><li>æ¯å±‚éƒ½æ·»åŠ äº†position embeddingï¼›ä»¥åŠtimestep embeddingï¼Œç”¨ä»¥æŒ‡ç¤ºå±‚æ•°ã€‚</li></ul><h4 id="ACT"><a href="#ACT" class="headerlink" title="ACT"></a>ACT</h4><p>ç”±äºä¸€ä¸ªå¥å­ä¸­é—´ï¼Œæœ‰äº›è¯æ¯”å…¶ä»–è¯æ›´éš¾å­¦ä¼šï¼Œéœ€è¦æ›´å¤šè®¡ç®—é‡ï¼Œä½†å †å å¤ªå¤šå±‚ä¼šå¤§å¤§å¢åŠ è®¡ç®—é‡ï¼Œä¸ºäº†èŠ‚çœè®¡ç®—é‡ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥ACTæ¥åŠ¨æ€åˆ†é…è®¡ç®—é‡ã€‚</p><p>ACTåŸæ¥ç”¨äºRNNï¼Œåœ¨Transformerä¸­ï¼Œå½“halting unitæŒ‡ç¤ºè¯tåº”å½“åœæ­¢æ—¶ï¼Œç›´æ¥è®²è¯¥è¯çš„çŠ¶æ€å¤åˆ¶åˆ°ä¸‹ä¸€ä¸ªtime stepï¼Œç›´åˆ°æ‰€æœ‰çš„è¯éƒ½åœæ­¢ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Embedding </tag>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> ACT </tag>
            
            <tag> Language Modeling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯12</title>
      <link href="/2018/10/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D12/"/>
      <url>/2018/10/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D12/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£æœ›æµ·æ½®"><a href="#1ï¸âƒ£æœ›æµ·æ½®" class="headerlink" title="1ï¸âƒ£æœ›æµ·æ½®"></a>1ï¸âƒ£æœ›æµ·æ½®</h3><p>[å®‹] æŸ³æ°¸<br>ä¸œå—å½¢èƒœï¼Œä¸‰å´éƒ½ä¼šï¼Œé’±å¡˜è‡ªå¤ç¹åã€‚çƒŸæŸ³ç”»æ¡¥ï¼Œé£å¸˜ç¿ å¹•ï¼Œå‚å·®åä¸‡äººå®¶ã€‚äº‘æ ‘ç»•å ¤æ²™ï¼Œæ€’æ¶›å·éœœé›ªï¼Œå¤©å ‘æ— æ¶¯ã€‚å¸‚åˆ—ç ç‘ï¼Œæˆ·ç›ˆç½—ç»®ï¼Œç«è±ªå¥¢ã€‚<br>é‡æ¹–å å·˜æ¸…å˜‰ï¼Œæœ‰ä¸‰ç§‹æ¡‚å­ï¼Œåé‡Œè·èŠ±ã€‚ç¾Œç®¡å¼„æ™´ï¼Œè±æ­Œæ³›å¤œï¼Œå¬‰å¬‰é’“åŸè²å¨ƒã€‚åƒéª‘æ‹¥é«˜ç‰™ï¼Œä¹˜é†‰å¬ç®«é¼“ï¼ŒåŸèµçƒŸéœã€‚å¼‚æ—¥å›¾å°†å¥½æ™¯ï¼Œå½’å»å‡¤æ± å¤¸ã€‚</p><p>å å·˜ï¼ˆyÇnï¼‰ï¼šå±‚å±‚å å çš„å±±å³¦ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b318228ac247005f2223db" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b318228ac247005f2223db</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•8</title>
      <link href="/2018/10/21/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%958/"/>
      <url>/2018/10/21/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%958/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-batchify"><a href="#1ï¸âƒ£-batchify" class="headerlink" title="1ï¸âƒ£[batchify]"></a>1ï¸âƒ£[batchify]</h3><p>å¿«é€Ÿå°†æ•°æ®åˆ†æˆbatchã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchify</span><span class="params">(data, bsz)</span>:</span></span><br><span class="line">    <span class="comment"># Work out how cleanly we can divide the dataset into bsz parts.</span></span><br><span class="line">    nbatch = data.size(<span class="number">0</span>) // bsz</span><br><span class="line">    <span class="comment"># Trim off any extra elements that wouldn't cleanly fit (remainders).</span></span><br><span class="line">    data = data.narrow(<span class="number">0</span>, <span class="number">0</span>, nbatch * bsz)</span><br><span class="line">    <span class="comment"># Evenly divide the data across the bsz batches.</span></span><br><span class="line">    data = data.view(bsz, <span class="number">-1</span>).t().contiguous()</span><br><span class="line">    <span class="keyword">return</span> data.to(device)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬å››ç«  åˆ†ç±»çš„çº¿æ€§æ¨¡å‹</title>
      <link href="/2018/10/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%88%86%E7%B1%BB%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2018/10/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%88%86%E7%B1%BB%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="åˆ¤åˆ«å‡½æ•°"><a href="#åˆ¤åˆ«å‡½æ•°" class="headerlink" title="åˆ¤åˆ«å‡½æ•°"></a>åˆ¤åˆ«å‡½æ•°</h1><p><img src="/images/2018-10-21-Xnip2018-10-21_09-26-42.jpg" alt="0"></p><hr><p><img src="/images/2018-10-21-Xnip2018-10-21_09-27-57.jpg" alt="1"></p><p>â€”-æœªå®Œâ€”-</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡2</title>
      <link href="/2018/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%872/"/>
      <url>/2018/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%872/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling"><a href="#1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling" class="headerlink" title="1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]"></a>1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]</h3><p>æœ¬æ–‡è´¡çŒ®ï¼šæå‡ºä¸€ç§æ–°çš„æ¨¡å‹<strong>TCNï¼ˆTemporal Convolutional Networksï¼‰</strong>è¿›è¡Œlanguage modelå»ºæ¨¡ã€‚</p><h4 id="Dilated-convolution"><a href="#Dilated-convolution" class="headerlink" title="Dilated convolution"></a>Dilated convolution</h4><p>æ¯ä¸€å±‚çš„æ„Ÿå—é‡éƒ½å¯ä»¥æ˜¯ä¸åŒçš„ï¼Œä¹Ÿå³ï¼ŒåŒæ ·çš„kernel sizeï¼Œé«˜å±‚çš„å¯ä»¥è·³ç€çœ‹ã€‚<br><img src="/images/2018-10-20-15400016170606.jpg" width="60%" height="50%"></p><p>æ¯å±‚çš„dé€æ¸å¢å¤§ï¼ˆä¹Ÿå³è·³çš„æ­¥æ•°ï¼‰ï¼Œä¸€èˆ¬æŒ‰æŒ‡æ•°å¢å¤§ã€‚ï¼ˆæˆ‘è§‰å¾—è¿™æ ·å¾ˆæœ‰é“ç†ï¼Œå¦‚æœæ¯ä¸€å±‚çš„déƒ½æ˜¯ä¸€æ ·çš„ï¼Œé‚£captureåˆ°çš„ä¿¡æ¯å°±ä¼šæœ‰é‡å¤ï¼Œèƒ½çœ‹åˆ°çš„è§†é‡ä¹Ÿä¸å¦‚é€æ¸å¢å¤§çš„å¤šï¼‰</p><h4 id="Residual-block"><a href="#Residual-block" class="headerlink" title="Residual block"></a>Residual block</h4><p><img src="/images/2018-10-20-15400017320092.jpg" width="70%" height="50%"></p><p>è¿™è¾¹çš„residual blockæ¯”è¾ƒå¤æ‚ï¼›ä¸€ä¸ªå€¼å¾—ä¸»æ„çš„ç»†èŠ‚æ˜¯ï¼Œå› ä¸ºæ„Ÿå—é‡çš„ä¸åŒï¼Œä¸Šå±‚çš„æ„Ÿå—é‡æ€»æ˜¯æ¯”ä¸‹å±‚çš„å¤§å¾ˆå¤šï¼Œå› æ­¤ä¸åº”è¯¥ç›´æ¥å°†ä¸‹å±‚çš„åŠ åˆ°ä¸Šå±‚ï¼Œè€Œæ˜¯å¯ä»¥ä½¿ç”¨ä¸€ä¸ª1*1çš„convolutionå¯¹ä¸‹å±‚çš„xè¿›è¡Œå·ç§¯ï¼Œè¿™å°±ç±»ä¼¼scaleå¯¹è¾“å…¥è¿›è¡Œæ”¾ç¼©ã€‚</p><hr><h3 id="2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation"><a href="#2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation" class="headerlink" title="2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]"></a>2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]</h3><p>ä¸€ç¯‡åˆ†æçš„æ–‡ç« ã€‚ELMoä½œè€…çš„åˆä¸€ç¯‡æ–‡ç« ã€‚</p><p>å¯¹æ¯”ä¸‰ç§ä¸åŒçš„å»ºæ¨¡æ–¹å¼ï¼ˆLSTM/GCNN/Transformerï¼‰è·å¾—çš„è¯å‘é‡ï¼Œä»¥åŠåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼›ä»¥åŠä¸åŒå±‚è·å¾—çš„ä¸åŒä¿¡æ¯â€¦è·å¾—äº†ä¸åŒçš„ç»“è®ºã€‚</p><p>â‘ biLM ä¸“æ³¨äºword morphologyè¯çš„å½¢æ€ï¼›åº•å±‚çš„LMå…³æ³¨local syntaxï¼›è€Œé«˜å±‚çš„LMå…³æ³¨semantic contentï¼›</p><p>â‘¡ä¸åŒçš„ä»»åŠ¡ä¼šæœ‰ä¸åŒçš„æ­£åˆ™åŒ–sçš„å€¾å‘ã€‚</p><hr><h3 id="3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency"><a href="#3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency" class="headerlink" title="3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]"></a>3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]</h3><p>åˆ©ç”¨Transformerè¿›è¡Œlanguage modelï¼Œä¸æ™®é€šçš„Transformerå»ºæ¨¡ä¸åŒçš„æ˜¯ï¼ŒTransformer-XLæ·»åŠ äº†å†å²ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¡¨ç°ã€‚è¿™ç¯‡è¿˜åœ¨ICLR2019å®¡ç¨¿ä¸­ã€‚</p><p>è´¡çŒ®ï¼šæœ¬æ–‡æå‡ºäº†èƒ½å¤Ÿè¿›è¡Œé•¿ç¨‹ä¾èµ–çš„åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹ Transformer-XLï¼›å¼•å…¥ç›¸å¯¹ä½ç½®çš„positional encodingã€‚</p><h4 id="ç»“æ„"><a href="#ç»“æ„" class="headerlink" title="ç»“æ„"></a>ç»“æ„</h4><p>åŸå…ˆçš„transformer language modelæ˜¯å°†å¥å­åˆ†ä¸ºä¸€ä¸ªä¸€ä¸ªsegmentã€‚segmentä¹‹é—´æ˜¯æ²¡æœ‰è”ç³»çš„ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥æŒ‰åŸç‰ˆçš„Transformeré‚£æ ·æ‰€æœ‰çš„è¯éƒ½ç›¸äº’åšself-attentionï¼Ÿå› ä¸ºè€ƒè™‘åˆ°æ•ˆç‡é—®é¢˜ï¼Œå¥å­é•¿åº¦å¯èƒ½ä¼šå¾ˆé•¿ï¼‰</p><p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400023645268.jpg" width="35%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¯æ¬¡å‘å³æ»‘åŠ¨ä¸€æ ¼ï¼š<br><img src="/images/2018-10-20-15400024115822.jpg" width="80%" height="50%"><br>è¿™æ ·æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½è¦é‡æ–°è®¡ç®—ä¸€éï¼Œå†å²ä¿¡æ¯æ²¡æœ‰åˆ©ç”¨åˆ°ã€‚æ˜¾ç„¶é€Ÿåº¦å¾ˆæ…¢ã€‚</p><p>åœ¨Transformerå¼•å…¥recurrenceï¼Œä¹Ÿå³å¼•å…¥å†å²ä¿¡æ¯ã€‚åŸºäºè¿™æ ·çš„æƒ³æ³•ï¼Œæå‡ºçš„æ–°æ¨¡å‹Transformer-XLã€‚åœ¨ç»“æ„ä¸ŠåŒæ ·åˆ†ä¸ºæ¯ä¸ªsegmentï¼Œä½†åœ¨æ¯ä¸ªé˜¶æ®µéƒ½æ¥æ”¶ä¸Šä¸€ä¸ªï¼ˆç”šè‡³ä¸ŠLä¸ªï¼‰å†å²ä¿¡æ¯ã€‚</p><p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400026059113.jpg" width="80%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼ŒåŒæ ·åˆ†ä¸ºsegmentï¼Œä½†å› ä¸ºæ¥æ”¶äº†å†å²ä¿¡æ¯ï¼Œä¸éœ€è¦æ¯æ¬¡æ»‘åŠ¨ä¸€æ ¼ä¹Ÿèƒ½è·å¾—å¤§é‡ä¿¡æ¯ã€‚<br><img src="/images/2018-10-20-15400027040526.jpg" width="45%" height="50%"></p><p>å…·ä½“æ¥è¯´ï¼š<br><img src="/images/2018-10-20-15400027302545.jpg" width="120%" height="50%"><br>SGä»£è¡¨stop gradientï¼Œå’Œè¯¥é˜¶æ®µçš„hidden stateè¿›è¡Œæ‹¼æ¥ã€‚</p><h4 id="RELATIVE-POSITIONAL-ENCODINGS"><a href="#RELATIVE-POSITIONAL-ENCODINGS" class="headerlink" title="RELATIVE POSITIONAL ENCODINGS"></a>RELATIVE POSITIONAL ENCODINGS</h4><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨äº†absolute positional encodingsï¼ˆä¹Ÿå³åŸç‰ˆçš„positional encodingsï¼‰é‚£ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µ</p><p><img src="/images/2018-10-20-15400027991211.jpg" width="70%" height="50%"></p><p>åœ¨åŒä¸€å±‚ä¹‹é—´çš„å‰ä¸€ä¸ªsegmentå’Œåä¸€ä¸ªsegmentä½¿ç”¨äº†åŒæ ·çš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¯¹äºå½“å‰segmentçš„é«˜å±‚ï¼Œå¯¹äºåŒä¸€ä¸ªä½ç½®iï¼Œæ— æ³•åŒºåˆ†è¯¥ä½ç½®ä¿¡æ¯æ˜¯æ¥è‡ªå½“å‰segmentçš„è¿˜æ˜¯ä¸Šä¸€ä¸ªsegmentçš„ï¼ˆå› ä¸ºéƒ½æ˜¯åŒæ ·çš„ç»å¯¹ä½ç½®ï¼‰ã€‚</p><p>å› æ­¤æˆ‘ä»¬å¼•å…¥ç›¸å¯¹ä½ç½®ä¿¡æ¯Rï¼Œå…¶ä¸­ç¬¬iè¡Œä»£è¡¨ç›¸å¯¹è·ç¦»içš„encodingã€‚</p><p>å…·ä½“æ¥è¯´ï¼š</p><p>é¦–å…ˆæˆ‘ä»¬åœ¨ä¼ ç»Ÿçš„è®¡ç®—$query_i$å’Œ$key_j$çš„attentionåˆ†æ•°æ—¶ï¼Œå¯ä»¥æ‹†è§£æˆï¼š</p><p><img src="/images/2018-10-20-15400030310583.jpg" width="80%" height="50%"><br>ï¼ˆå› ä¸ºquery=(embedding E +positional embedding Uï¼‰ï¼Œkeyä¹Ÿä¸€æ ·ï¼Œå°†å¼å­æ‹†å¼€å°±èƒ½è·å¾—ä¸Šè¿°å¼å­)</p><p>æˆ‘ä»¬å°†è¯¥å¼å­è¿›è¡Œä¿®æ”¹ï¼š</p><p><img src="/images/2018-10-20-15400031662378.jpg" width="80%" height="50%"></p><p>ç¬¬ä¸€ï¼Œå°†å‡ºç°äº†absolute positional embedding $U$çš„åœ°æ–¹ï¼Œç»Ÿç»Ÿæ”¹æˆ$R_{i-j}$ï¼Œä¹Ÿå³åœ¨bå’Œdé¡¹ã€‚å…¶ä¸­è¿™é‡Œçš„Rå’ŒåŸç‰ˆçš„Transformerçš„ä½ç½®è®¡ç®—å…¬å¼ç›¸åŒã€‚</p><p>ç¬¬äºŒï¼Œåœ¨cé¡¹ä¸­ï¼Œä½¿ç”¨ä¸€ä¸ª$u$æ›¿ä»£äº†$U_i W_q$ï¼Œè¿™ä¸€é¡¹åŸæœ¬çš„æ„ä¹‰åœ¨äºï¼Œ$query_i$çš„positional encodingå¯¹$key_j$çš„embeddingè¿›è¡Œattentionï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¯¥é¡¹è¡¨ç°äº†$query_i$ä½ç½®å¯¹å“ªäº›$key_j$çš„å†…å®¹æœ‰å…´è¶£ï¼Œä½œè€…è®¤ä¸ºqueryä¸ç®¡åœ¨å“ªä¸ªä½ç½®ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´queryçš„ä½ç½®ä¿¡æ¯åº”å½“æ²¡å½±å“ï¼Œæ‰€ä»¥ç»Ÿç»Ÿæ›¿æ¢æˆä¸€ä¸ªå¯å­¦ä¹ çš„$u$ã€‚åŸºäºç±»ä¼¼çš„ç†ç”±dé¡¹æ¢æˆäº†$v$ã€‚</p><p>ç¬¬ä¸‰ï¼Œå°†$W_k$ç»†åˆ†æˆäº†ä¸¤ä¸ª$W_{k,E}$å’Œ$W_{k,R}$ã€‚è¿™æ˜¯æ ¹æ®queryæ˜¯Embeddingè¿˜æ˜¯positional encodingæ¥åŒºåˆ†çš„ã€‚for producing the content-based key vectors and location-based key vectors respectively</p><p>æ¯ä¸€é¡¹ç°åœ¨éƒ½æœ‰äº†ä¸åŒçš„æ„ä¹‰ï¼š</p><blockquote><p>Under the new parameterization, each term has an intuitive meaning: term (a) represents contentbased addressing, term (b) captures a content-dependent positional bias, term (c) governs a global content bias, and (d) encodes a global positional bias.</p></blockquote><p>æœ€åæ€»ç»“ä¸€ä¸‹æ•´ä¸ªç»“æ„ï¼š</p><p><img src="/images/2018-10-20-15400040342520.jpg" width="120%" height="50%"></p><p>ä¸åŸç‰ˆTransformerä¸åŒçš„æ˜¯ï¼ŒTransformer-XLåœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†ä½ç½®ä¿¡æ¯ã€‚</p><hr><h3 id="4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling"><a href="#4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling" class="headerlink" title="4ï¸âƒ£[Trellis Networks for Sequence Modeling]"></a>4ï¸âƒ£[Trellis Networks for Sequence Modeling]</h3><p>ä¸€ç§ç»“åˆRNNå’ŒCNNçš„è¯­è¨€å»ºæ¨¡æ–¹å¼ã€‚</p><p>æœ€å°çš„å•å…ƒç»“æ„ï¼š</p><p><img src="/images/2018-10-21-15400858162232.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-21-15400860605560.jpg" width="40%" height="50%"></p><p>æ¥ä¸‹æ¥å†å¤„ç†éçº¿æ€§ï¼š<br><img src="/images/2018-10-21-15400861618655.jpg" width="30%" height="50%"></p><p>å› ä¸ºæ¯å±‚éƒ½è¦è¾“å…¥xï¼Œä¸”Wæ˜¯å…±äº«çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æå‰è®¡ç®—å¥½è¿™ä¸€é¡¹ï¼Œåé¢ç›´æ¥ç”¨å³å¯ã€‚<br><img src="/images/2018-10-21-15400861870898.jpg" width="35%" height="50%"></p><p>æœ€ç»ˆåœ¨å®ç°çš„æ—¶å€™æ˜¯ï¼š<br><img src="/images/2018-10-21-15400862184335.jpg" width="40%" height="50%"></p><p><img src="/images/2018-10-21-15400862303741.jpg" width="40%" height="50%"></p><p>æ€»ä½“æ¡†æ¶ï¼š<br><img src="/images/2018-10-21-15400874987498.jpg" width="70%" height="50%"></p><p>ä¸TCNï¼ˆtemporal convolution networkï¼‰ä¸åŒä¹‹å¤„ï¼šâ‘ filter weightä¸ä»…åœ¨time stepä¹‹é—´å…±äº«ï¼Œåœ¨ä¸åŒå±‚ä¹‹é—´ä¹Ÿå…±äº«ï¼›â‘¡åœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†è¾“å…¥</p><p>ä¼˜ç‚¹ï¼šå…±äº«äº†Wï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°ï¼›â€˜Weight tying can be viewed as a form of regularization that can stabilize trainingâ€™</p><p>æˆ‘ä»¬è¿˜å¯ä»¥æ‰©å±•è¯¥ç½‘ç»œï¼Œå¼•å…¥gateï¼š<br><img src="/images/2018-10-21-15400875805208.jpg" width="40%" height="50%"></p><hr><h3 id="5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation"><a href="#5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation" class="headerlink" title="5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]"></a>5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]</h3><p>ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„paperã€‚ç”¨äºNMT decodeçš„inferenceé˜¶æ®µã€‚è¿™ç¯‡æœ‰ä¸€å®šçš„éš¾åº¦ï¼Œä»¥ä¸‹åªæ˜¯æˆ‘çš„ç†è§£ã€‚</p><h4 id="æ€æƒ³"><a href="#æ€æƒ³" class="headerlink" title="æ€æƒ³"></a>æ€æƒ³</h4><p>Motivationï¼š<br>NMTä¸­çš„decode inferenceé˜¶æ®µï¼Œé€šå¸¸éƒ½æ˜¯ä»å·¦åˆ°å³çš„ï¼Œè¿™æ ·æœ‰ä¸ªç¼ºç‚¹ï¼Œå°±æ˜¯æ•´ä½“çš„targetä¹‹é—´çš„ä¾èµ–æ˜¯æ²¡æœ‰è¢«å……åˆ†åˆ©ç”¨åˆ°çš„ï¼Œæ¯”å¦‚è¯´ç”Ÿæˆçš„è¯çš„å³è¾¹æ˜¯æ²¡æœ‰ç”¨åˆ°çš„ã€‚é‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆä¸ç›´æ¥å…¨éƒ¨ç”Ÿæˆå‘¢ï¼Ÿç„¶åä¸æ–­æ›´æ–°ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å°†ç¦»æ•£ï¼ˆdiscreteï¼‰çš„decodeè¿‡ç¨‹å˜æˆä¸€ä¸ªè¿ç»­çš„è¿‡ç¨‹ï¼ˆcontinuous optimizationï¼‰ã€‚</p><p>å‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½æ¨¡å‹ï¼Œç»™å®šä¸€ä¸ªå¥å­ï¼Œæˆ‘ä»¬è¦ç¿»è¯‘æˆç›®æ ‡å¥å­ï¼Œä¸”å‡è®¾æˆ‘ä»¬å·²çŸ¥è¦ç”Ÿæˆçš„å¥å­é•¿åº¦æ˜¯lï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ï¼š<br><img src="/images/2018-10-21-15400876953609.jpg" width="45%" height="50%"><br>æˆ‘ä»¬è¦æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„åºåˆ—$y$ï¼Œä½¿å¾—$-log$æœ€å°ã€‚</p><p>ç­‰ä»·äºï¼š<br><img src="/images/2018-10-21-15400877226851.jpg" width="55%" height="50%"><br>å…¶ä¸­$\widetilde{y}_i$æ˜¯one-hotã€‚å…¶å®è¿™é‡Œå°±æ˜¯å‡è®¾æœ‰è¿™ä¹ˆä¸€ä¸ªground truthï¼Œä½†å®é™…ä¸Šæ˜¯æ²¡æœ‰çš„ã€‚</p><p>æˆ‘ä»¬å°†$\widetilde{y}_i$æ˜¯one-hotè¿™ä¸ªæ¡ä»¶æ”¾å®½ä¸€äº›ï¼Œå˜æˆæ˜¯ä¸€ä¸ªæ¦‚ç‡å•çº¯å‹ï¼ˆå…¶å®å°±æ˜¯æ‰€æœ‰å…ƒç´ åŠ èµ·æ¥æ˜¯1ï¼Œä¸”éƒ½å¤§äºç­‰äº0ï¼‰ã€‚</p><p>é‚£ä¹ˆå°±å˜æˆäº†ï¼š<br><img src="/images/2018-10-21-15400879019592.jpg" width="50%" height="50%"></p><p>è¿™ä¸ªæ”¹å˜çš„æœ¬è´¨æ˜¯ï¼š<br><img src="/images/2018-10-21-15400879379023.jpg" width="50%" height="50%"></p><p>å°±æ˜¯è¯´åŸæ¥one-hotçš„$\widetilde{y}_i$ç”Ÿæˆåä¸¢åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå–äº†ä¸€ä¸ªè¯å‘é‡ï¼Œæ¥ç€è®¡ç®—ã€‚ç°åœ¨æ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ$\hat{y}_i$ä¸¢è¿›æ¥ï¼Œå°±ç›¸å½“äºå–äº†å¤šä¸ªè¯å‘é‡çš„åŠ æƒæ±‚å’Œã€‚</p><p>åœ¨åˆ©ç”¨ä¸‹è¿°çš„æ›´æ–°ç®—æ³•æ›´æ–°å®Œ$\hat{y}_i$ä¹‹åï¼Œå¯¹äºæ¯ä¸ªæ—¶é—´æ­¥tï¼Œæˆ‘ä»¬æ‰¾$\hat{y}_i$ä¸­å…ƒç´ æœ€å¤§çš„å€¼å¯¹åº”çš„è¯ä½œä¸ºç”Ÿæˆçš„è¯ã€‚</p><p>æœ‰ä¸¤ç§æ–¹æ³•Exponentiated Gradient å’Œ SGDã€‚å®é™…ä¸Šæ–¹æ³•å€’åœ¨å…¶æ¬¡äº†ï¼Œä¸»è¦æ˜¯å‰é¢æ‰€è¿°çš„continuous optimizationè¿™ç§æ€æƒ³ã€‚</p><h4 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h4><h5 id="Exponentiated-Gradient"><a href="#Exponentiated-Gradient" class="headerlink" title="Exponentiated Gradient"></a>Exponentiated Gradient</h5><p><img src="/images/2018-10-21-15400881918713.jpg" width="80%" height="50%"><br>å…·ä½“è§è®ºæ–‡</p><h5 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h5><p>å› ä¸ºæˆ‘ä»¬è¦ä¿è¯å•çº¯å½¢çš„çº¦æŸä¸å˜ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªrï¼Œç„¶ååšä¸€ä¸ªsoftmax<br><img src="/images/2018-10-21-15400882306948.jpg" width="80%" height="50%"></p><h4 id="åº”ç”¨"><a href="#åº”ç”¨" class="headerlink" title="åº”ç”¨"></a>åº”ç”¨</h4><p>è¿™ç§è¿ç»­decodeå¯ä»¥ç”¨åœ¨å“ªï¼Ÿ</p><h5 id="Bidirectional-Ensemble"><a href="#Bidirectional-Ensemble" class="headerlink" title="Bidirectional Ensemble"></a>Bidirectional Ensemble</h5><p>å¯ä»¥å¾ˆæ–¹ä¾¿åœ°è¿›è¡ŒåŒå‘çš„ç”Ÿæˆï¼š</p><p><img src="/images/2018-10-21-15400883321474.jpg" width="45%" height="50%"><br>è€Œåœ¨ä¼ ç»Ÿçš„æ–¹æ³•ä¸­æ²¡åŠæ³•ï¼ˆå¾ˆéš¾ï¼‰åšåˆ°</p><h5 id="Bilingual-Ensemble"><a href="#Bilingual-Ensemble" class="headerlink" title="Bilingual Ensemble"></a>Bilingual Ensemble</h5><p>æˆ‘ä»¬å¸Œæœ›æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€å’Œç›®æ ‡åˆ°æºè¯­è¨€éƒ½ç”Ÿæˆå¾—å¥½</p><p><img src="/images/2018-10-21-15400883583228.jpg" width="50%" height="50%"></p><h4 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h4><p>$\hat{y}_i$çš„åˆå§‹åŒ–å¾ˆé‡è¦ï¼Œä¸€ä¸å°å¿ƒå°±ä¼šé™·å…¥local minimaï¼›ç”Ÿæˆçš„é€Ÿåº¦æ…¢</p><hr><h3 id="6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation"><a href="#6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation" class="headerlink" title="6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]"></a>6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]</h3><p>å’ŒELMoã€OpenAI GPTä¸€æ ·ï¼Œéƒ½æ˜¯é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼ˆè¿™é‡Œæ˜¯åˆ†ç±»ä»»åŠ¡ï¼‰ã€‚å¯ä»¥åœ¨éå¸¸å°çš„æ•°æ®é›†ä¸Šæœ‰å¾ˆå¥½çš„æ•ˆæœã€‚</p><p>è´¡çŒ®ï¼š</p><ol><li>è¿ç§»å­¦ä¹ æ¨¡å‹ULMFiT</li><li>æå‡ºå‡ ç§trickï¼šdiscriminative ï¬ne-tuning, slanted triangular learning rates,gradual unfreezing ï¼Œæœ€å¤§ä¿è¯çŸ¥è¯†çš„ä¿ç•™ã€‚</li></ol><h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p><img src="/images/2018-10-21-15401043145373.jpg" width="90%" height="50%"></p><p>ä¸‰éƒ¨æ›²ï¼š</p><ol><li>é€šç”¨è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ</li><li>ç›®æ ‡ä»»åŠ¡çš„è¯­è¨€æ¨¡å‹fine-tuning</li><li>ç›®æ ‡ä»»åŠ¡çš„åˆ†ç±»fine-tuning</li></ol><h4 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h4><h5 id="Discriminative-ï¬ne-tuning"><a href="#Discriminative-ï¬ne-tuning" class="headerlink" title="Discriminative ï¬ne-tuning"></a>Discriminative ï¬ne-tuning</h5><p>Motivationï¼šä¸åŒå±‚æœ‰ä¸åŒçš„ä¿¡æ¯ï¼›åº”å½“fine-tune ä¸åŒç¨‹åº¦ï¼Œä¹Ÿå³ä½¿ç”¨ä¸åŒçš„learning rateã€‚</p><p><img src="/images/2018-10-21-15401044160803.jpg" width="35%" height="50%"></p><p>ä½œè€…å‘ç°ä¸Šä¸€å±‚çš„å­¦ä¹ ç‡æ˜¯ä¸‹ä¸€å±‚çš„2.6å€æ—¶æ•ˆæœæ¯”è¾ƒå¥½ã€‚</p><h5 id="Slanted-triangular-learning-rates-STLR"><a href="#Slanted-triangular-learning-rates-STLR" class="headerlink" title="Slanted triangular learning rates (STLR)"></a>Slanted triangular learning rates (STLR)</h5><p><img src="/images/2018-10-21-15401045153164.jpg" width="60%" height="50%"></p><p>å…·ä½“å…¬å¼ï¼š<br><img src="/images/2018-10-21-15401045316305.jpg" width="50%" height="50%"></p><h5 id="Gradual-unfreezing"><a href="#Gradual-unfreezing" class="headerlink" title="Gradual unfreezing"></a>Gradual unfreezing</h5><p>ä»é¡¶å±‚åˆ°åº•å±‚ï¼Œä¸€æ­¥ä¸€æ­¥unfreezeï¼Œä¹Ÿå³ä»ä¸Šåˆ°ä¸‹fine-tuneã€‚è¿™æ˜¯å› ä¸ºæœ€ä¸Šä¸€å±‚æœ‰æœ€å°‘çš„general knowledgeã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> TCN </tag>
            
            <tag> Transformer-XL </tag>
            
            <tag> Trellis Networks </tag>
            
            <tag> continuous decoding </tag>
            
            <tag> ULMFiT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡1</title>
      <link href="/2018/10/14/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%871/"/>
      <url>/2018/10/14/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%871/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors"><a href="#1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors" class="headerlink" title="1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]"></a>1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]</h3><p>CoVeæ˜¯ç¬¬ä¸€ä¸ªå¼•å…¥åŠ¨æ€è¯å‘é‡çš„æ¨¡å‹ã€‚<br>Motivationï¼šç¿»è¯‘æ¨¡å‹èƒ½å¤Ÿä¿å­˜æœ€å¤šçš„ä¿¡æ¯ï¼Œå› ä¸ºå¦‚æœä¿å­˜ä¿¡æ¯ä¸å¤Ÿå¤šï¼Œdecoderæ¥æ”¶åˆ°çš„ä¿¡æ¯ä¸è¶³ï¼Œç¿»è¯‘æ•ˆæœå°±ä¸ä¼šå¥½ã€‚ï¼ˆä½†å®é™…ä¸Šï¼Œæˆ‘ä¸ªäººè®¤ä¸ºï¼Œdecoderçš„è¡¨ç°è¿˜å’Œlanguage modelæœ‰å…³ï¼Œå¦‚æœdecoderæ˜¯ä¸€ä¸ªå¥½çš„language modelï¼Œä¹Ÿæœ‰å¯èƒ½ç¿»è¯‘å‡ºä¸é”™çš„ç»“æœï¼‰</p><p>åšæ³•ï¼šä½¿ç”¨ä¼ ç»ŸNMTçš„encoder-decoderçš„åšæ³•ç¿»è¯‘æ¨¡å‹ï¼Œåªæ˜¯å°†(bi)LSTMæ‰€å¾—åˆ°çš„éšå±‚çŠ¶æ€è¡¨ç¤ºå–å‡ºæ¥å’Œembeddingæ‹¼æ¥èµ·æ¥ï¼Œä½œä¸ºä¸€ä¸ªè¯çš„è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">w=[GloVe(w); CoVe(w)]</script><hr><h3 id="2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks"><a href="#2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]"></a>2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]</h3><p>ä½¿ç”¨CNNå¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå»ºæ¨¡ï¼Œæé«˜å¹¶è¡Œæ€§ã€‚</p><p>è´¡çŒ®ï¼šä½¿ç”¨äº†CNNè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›æå‡ºäº†ç®€åŒ–ç‰ˆçš„gateæœºåˆ¶åº”ç”¨åœ¨CNNä¸­ã€‚</p><p>åšæ³•ï¼š<br><img src="/images/2018-10-14-15394870930257.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªè¾“å…¥ä¸¤ä¸ªfilterï¼Œå·ç§¯å‡ºæ¥çš„åšä¸€ä¸ªgateçš„æ“ä½œ$H_0 = AâŠ—Ïƒ(B)$ï¼Œæ§åˆ¶æµå‘ä¸‹ä¸€å±‚çš„æ•°æ®ã€‚</p><p>ä¸€ä¸ªå°ç»†èŠ‚æ˜¯ï¼Œä¸ºäº†ä¸è®©language modelçœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œæ¯ä¸€å±‚åœ¨å¼€å§‹å·ç§¯çš„æ—¶å€™ä¼šåœ¨å·¦è¾¹æ·»åŠ kernel_size-1ä¸ªpaddingã€‚</p><p>æ‰©å±•ï¼šå› ä¸ºCNNçš„å¹¶è¡Œæ€§é«˜ï¼Œå¯ä»¥ä½¿ç”¨CNNæ¥å¯¹language modelå»ºæ¨¡æ›¿ä»£ELMoï¼ŒåŒæ ·å¯ä»¥è·å¾—åŠ¨æ€è¯å‘é‡ã€‚è¿™ä¸ªæƒ³æ³•å·²ç»ç”±æå‡ºELMoçš„å›¢é˜Ÿåšå‡ºæ¥å¹¶è¿›è¡Œå¯¹æ¯”äº†ã€‚è®ºæ–‡ï¼šDissecting Contextual Word Embeddings: Architecture and Representation</p><p>ç›®å‰æ­£åœ¨<a href="https://github.com/linzehui/Gated-Convolutional-Networks" target="_blank" rel="noopener">å¤ç°</a>è¯¥è®ºæ–‡ ã€‚</p><hr><h3 id="3ï¸âƒ£-Attention-is-All-you-need"><a href="#3ï¸âƒ£-Attention-is-All-you-need" class="headerlink" title="3ï¸âƒ£[Attention is All you need]"></a>3ï¸âƒ£[Attention is All you need]</h3><p>éå¸¸ç»å…¸çš„è®ºæ–‡ã€‚æå‡ºäº†Transformerã€‚ä¸ºäº†è¯»BERTé‡æ¸©äº†ä¸€éã€‚<br><img src="/images/2018-10-14-15394876881322.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-14-15394877200390.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-14-15394877478814.jpg" width="70%" height="50%"></p><hr><h3 id="4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training"><a href="#4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training" class="headerlink" title="4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]"></a>4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]</h3><p>BERTå°±æ˜¯followè¿™ç¯‡æ–‡ç« çš„å·¥ä½œã€‚<br>ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p><p>è®­ç»ƒè¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼šâ‘ ä½¿ç”¨æœªæ ‡è®°æ•°æ®è®­ç»ƒlanguage modelï¼›â‘¡ä½¿ç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œfine-tune</p><p>Motivationï¼šELMoæ˜¯è®­ç»ƒå¥½language modelï¼Œç„¶åè·å¾—åŠ¨æ€è¯å‘é‡å†ç”¨åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼Œè¿™æ ·å°±ä¼šå¤šäº†å¾ˆå¤šå‚æ•°ã€‚å’ŒELMoä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªTransformeræ¨¡å‹è§£å†³å¤šç§ä»»åŠ¡ï¼ˆåˆ©ç”¨è¿ç§»å­¦ä¹ ï¼‰ã€‚</p><p>è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›å°è¯•åˆ©ç”¨language modelè¿›è¡Œè¿ç§»å­¦ä¹ è€Œä¸æ˜¯å¦ä¸€ç§æ€è·¯ï¼ˆELMoï¼‰åªæå–è¯å‘é‡ã€‚</p><p>â‘ æ— ç›‘ç£å­¦ä¹ language model<br><img src="/images/2018-10-14-15395044176746.jpg" width="40%" height="50%"></p><p>å…·ä½“åˆ°Transformerå°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395044608239.jpg" width="50%" height="50%"></p><p>â‘¡ç›‘ç£å­¦ä¹ ï¼ˆfine-tuneï¼‰<br>æ ¹æ®è¾“å…¥é¢„æµ‹æ ‡ç­¾<br><img src="/images/2018-10-14-15395045508824.jpg" width="35%" height="50%"></p><p>å…·ä½“å°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395045734859.jpg" width="40%" height="50%"></p><p>å°†ä¸¤ä¸ªä»»åŠ¡ä¸€èµ·è®­ç»ƒï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-10-14-15395045932795.jpg" width="30%" height="50%"></p><p>å¯¹äºä¸åŒä»»åŠ¡ï¼Œå¯¹è¾“å…¥è¿›è¡Œä¸€å®šçš„æ”¹åŠ¨ä»¥é€‚åº”Transformerç»“æ„ï¼š<br><img src="/images/2018-10-14-15395046364928.jpg" width="90%" height="50%"></p><hr><h3 id="5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]"></a>5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]</h3><p>åˆ·çˆ†å„æ¦œå•çš„ä¸€ç¯‡ç¥æ–‡ã€‚ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p><p>Motivationï¼šä¹‹å‰çš„language modelåªèƒ½æ ¹æ®å‰é¢çš„è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªï¼ˆå³ä½¿ELMoæ˜¯åŒå‘çš„LSTMï¼Œä¹Ÿæ˜¯åˆ†åˆ«è®­ç»ƒä¸€ä¸ªå‰å‘å’Œä¸€ä¸ªåå‘çš„ï¼‰ï¼Œé™åˆ¶äº†åŒå‘çš„contextï¼›å› æ­¤æå‡ºäº†åŒå‘çš„language modelã€‚</p><h4 id="åšæ³•ï¼š"><a href="#åšæ³•ï¼š" class="headerlink" title="åšæ³•ï¼š"></a>åšæ³•ï¼š</h4><p>æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š<br>â‘ masked LMï¼šå› ä¸ºä½¿ç”¨äº†ä¸¤è¾¹çš„contextï¼Œè€Œlanguage modelçš„ç›®çš„æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿™æ ·æ¨¡å‹ä¼šæå‰çœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œè®­ç»ƒçš„æ—¶å€™è®²éƒ¨åˆ†è¯maskæ‰ï¼Œæœ€ç»ˆåªé¢„æµ‹è¢«maskæ‰çš„è¯ã€‚</p><p>â‘¡Next Sentence Predictionï¼šéšæœº50%ç”Ÿæˆä¸¤ä¸ªå¥å­æ˜¯æœ‰ä¸Šä¸‹å¥å…³ç³»çš„ï¼Œ50%ä¸¤ä¸ªå¥å­æ˜¯æ²¡æœ‰å…³ç³»çš„ï¼Œç„¶ååšåˆ†ç±»ï¼›å…·ä½“æ¥è¯´æ˜¯æ‹¿ç¬¬ä¸€ä¸ªè¯[CLS]ï¼ˆè¿™æ˜¯æ‰‹åŠ¨æ·»åŠ çš„ï¼‰çš„è¡¨ç¤ºï¼Œè¿‡ä¸€ä¸ªsoftmaxå±‚å¾—åˆ°ã€‚<br><img src="/images/2018-10-14-15394891973653.jpg" width="50%" height="50%"></p><p>è”åˆè®­ç»ƒè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚</p><p>æ¥ä¸‹æ¥æ˜¯é€šè¿‡å…·ä½“çš„ä»»åŠ¡è¿›è¡Œfine-tuneã€‚ä¸€ä¸ªæ¨¡å‹è§£å†³å¤šç§é—®é¢˜ï¼š<br><img src="/images/2018-10-14-15395038593955.jpg" width="80%" height="50%"></p><p>æœ¬æ–‡è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡ŒåŒå‘çš„language modelå»ºæ¨¡ã€‚è®ºæ–‡æåˆ°çš„ä¸€äº›ç»†èŠ‚/trickséå¸¸å€¼å¾—è®¨è®ºï¼Œæ¯”å¦‚å¯¹token embeddingæ·»åŠ äº†è®¸å¤šä¿¡æ¯ï¼Œéå¸¸ç®€å•ç²—æš´ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> CoVe </tag>
            
            <tag> GCNN </tag>
            
            <tag> BERT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 18:Deep Reinforcement Learning</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/</url>
      
        <content type="html"><![CDATA[<p>è®°å·ï¼š $a$æ˜¯actionï¼Œ$s$å³å¤–éƒ¨çŠ¶æ€stateï¼Œ$\pi_{\theta}(s)$ä¹Ÿå³ä»$s$æ˜ å°„åˆ°$a$çš„å‡½æ•°ï¼›$r$æ˜¯rewardï¼Œæ¯é‡‡å–ä¸€ä¸ªåŠ¨ä½œï¼Œä¼šæœ‰ä¸€ä¸ªrewardï¼Œåˆ™æ€»çš„rewardä¸º</p><script type="math/tex; mode=display">R_\theta = \sum_{t=1}^{T} r_t</script><p>æˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ‹Ÿåˆ$\pi$ï¼Œä¸€ä¸ªeposide $\tau$æ˜¯ä¸€ä¸ªæµç¨‹ä¸‹æ¥çš„çš„æ‰€æœ‰stateã€actionå’Œrewardçš„é›†åˆã€‚</p><script type="math/tex; mode=display">\tau = \{s_1,a_1,r_1,s_2,a_2,r_2,...,s_T,a_T,r_T \}</script><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„actorè¿è¡Œnæ¬¡ï¼Œåˆ™æ¯ä¸ª$\tau$ä¼šæœ‰ä¸€å®šçš„æ¦‚ç‡è¢«é‡‡æ ·åˆ°ï¼Œé‡‡æ ·æ¦‚ç‡è®°ä¸º$P(\tau|\theta)$ï¼Œåˆ™æˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·çš„æ–¹å¼æ¥å¯¹æœŸæœ›rewardè¿›è¡Œä¼°è®¡ï¼š</p><script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n)</script><p>é‚£ä¹ˆæˆ‘ä»¬æ¥ä¸‹æ¥çš„<strong>ç›®æ ‡</strong>å°±æ˜¯æœ€å¤§åŒ–æœŸæœ›rewardï¼Œå…¶ä¸­æœŸæœ›rewardæ˜¯ï¼š</p><script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta)</script><p>æˆ‘ä»¬åŒæ ·ä½¿ç”¨æ¢¯åº¦ä¸Šå‡ï¼šå…¶ä¸­ä¸$Î¸$ç›¸å…³çš„æ˜¯$P$ï¼Œåˆ™å¯ä»¥å†™æˆï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) \nabla P(\tau|\theta)= \sum_\tau R(\tau) P(\tau|\theta) \frac{\nabla P(\tau|\theta)}{P(\tau|\theta)}</script><p>ç”±äº$\dfrac {d\log \left( f\left( x\right) \right) }{dx}=\dfrac {1}{f\left( x\right) }\dfrac {df(x)}{dx}$ï¼Œåˆ™å‰å¼å¯å†™æˆï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) \nabla log P(\tau | \theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n) log P(\tau ^n| \theta)</script><p>å¦‚ä½•æ±‚æ¢¯åº¦ï¼Ÿ<br>ç”±äºï¼š</p><script type="math/tex; mode=display">P(\tau | \theta)=p(s_1)p(a_1|s_1,\theta)p(r_1,s_2|s_1,a_1)p(a_2|s_2,\theta)p(r_2,s_3|s_2,a_2)...\\=p(s_1)\prod_{t=1}^{T}p(a_t|s_t,\theta)p(r_t , s_{t+1}| s_t,a_t)</script><p>å®é™…ä¸Šï¼Œå…¶ä¸­ä¸æ¢¯åº¦ç›¸å…³çš„åªæœ‰ä¸­é—´é¡¹$p(a_t|s_t,\theta)$ï¼Œè¯¥é¡¹ä¹Ÿå³$Ï€$å‡½æ•°ï¼Œä»stateåˆ°actionçš„æ˜ å°„ã€‚<br>å–logå¹¶æ±‚å¯¼ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">\nabla log P(\tau | \theta)= \sum_{t=1}^{T} \nabla log p(a_t|s_t,\theta)</script><p>ä»£å›ï¼Œå› æ­¤æœ€ç»ˆ$\overline{R}_\theta$çš„æ¢¯åº¦ä¸ºï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} R(\tau^n) \nabla log p(a_{t}^n | s_t^n,\theta)</script><p>æ³¨æ„åˆ°è¯¥å¼å­å‘Šè¯‰æˆ‘ä»¬ï¼Œåº”è€ƒè™‘æ•´ä½“çš„rewardè€Œä¸åº”è¯¥åªè€ƒè™‘æ¯ä¸€æ­¥çš„rewardï¼›å¹¶ä¸”å–logçš„åŸå› å¯ä»¥ç†è§£æˆæ˜¯å¯¹actionå–å½’ä¸€åŒ–ï¼Œå› ä¸ºï¼š</p><script type="math/tex; mode=display">\frac{\nabla p(a_t^n | s_t^n,\theta)}{p(a_t^n | s_t^n,\theta)}</script><p>ä¹Ÿå°±æ˜¯è¯´å¯¹äºé‚£äº›å‡ºç°æ¬¡æ•°è¾ƒå¤šçš„actionï¼Œè¦è¡¡é‡ä»–ä»¬å¯¹rewardçš„çœŸæ­£å½±å“ï¼Œåº”å½“å¯¹ä»–ä»¬å½’ä¸€åŒ–ã€‚</p><p>ä¸ºäº†è®©é‚£äº›å‡ºç°å¯èƒ½æ€§è¾ƒä½çš„actionä¸ä¼šå› ä¸ºæ²¡è¢«sampleåˆ°è€Œåœ¨æ›´æ–°åè¢«é™ä½ä»–ä»¬çš„æ¦‚ç‡ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ªbaselineï¼Œåªæœ‰è¶…è¿‡$b$çš„rewardæ‰ä¼šå¢åŠ ä»–ä»¬å‡ºç°çš„æ¦‚ç‡ã€‚</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} (R(\tau^n)-b) \nabla log p(a_{t}^n | s_t^n,\theta)</script>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 17:Ensemble</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2017:%20Ensemble/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2017:%20Ensemble/</url>
      
        <content type="html"><![CDATA[<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>å¯¹äºå¤æ‚æ¨¡å‹ï¼Œå¾€å¾€varianceä¼šå¤§ï¼Œé€šè¿‡å¯¹å¤šä¸ªæ¨¡å‹çš„å¹³å‡ï¼Œèƒ½å¤Ÿå‡å°varianceï¼š<br><img src="/images/2018-10-14-15394832736339.jpg" width="50%" height="50%"></p><p>baggingçš„æ€æƒ³æ˜¯å¤šæ¬¡æœ‰æ”¾å›åœ°é‡‡æ ·Nâ€™ä¸ªç‚¹ï¼ˆé€šå¸¸Nâ€™=Nï¼‰ï¼Œç„¶åå¯¹é‡‡æ ·çš„å‡ ä¸ªæ•°æ®é›†åˆ†åˆ«è®­ç»ƒä¸€ä¸ªæ¨¡å‹<br><img src="/images/2018-10-14-15394833007835.jpg" width="50%" height="50%"></p><p>æµ‹è¯•çš„æ—¶å€™å†å¯¹å‡ ä¸ªæ¨¡å‹è¿›è¡Œå¹³å‡æˆ–æŠ•ç¥¨<br><img src="/images/2018-10-14-15394833255306.jpg" width="50%" height="50%"></p><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>åŸºæœ¬æ€æƒ³æ˜¯å¯¹å‡ ä¸ªå¼±åˆ†ç±»å™¨çº¿æ€§åŠ æƒï¼Œå¾—åˆ°å¼ºåˆ†ç±»å™¨ã€‚åˆ†ç±»å™¨æŒ‰å…ˆåé¡ºåºè®­ç»ƒï¼Œæ¯æ¬¡è®­ç»ƒå®Œï¼Œå¯¹æ–°æ¨¡å‹åˆ†ç±»é”™è¯¯çš„æ•°æ®è¿›è¡Œè°ƒé«˜æƒé‡ï¼Œè€Œæ­£ç¡®çš„æ•°æ®åˆ™é™ä½æƒé‡ã€‚</p><p>å¯ä»¥ä¿è¯ï¼šåªè¦åˆ†ç±»å™¨çš„é”™è¯¯ç‡å°äº50%ï¼Œåœ¨boostingåèƒ½å¤Ÿæœ‰100%çš„æ­£ç¡®ç‡ï¼ˆåœ¨è®­ç»ƒé›†ï¼‰ã€‚</p><p>è¯æ˜è¿‡ç¨‹ç•¥ã€‚</p><h2 id="Ensemble-Stacking"><a href="#Ensemble-Stacking" class="headerlink" title="Ensemble: Stacking"></a>Ensemble: Stacking</h2><p>åŸºæœ¬æ€æƒ³ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®è®­ç»ƒå¤šä¸ªåˆçº§åˆ†ç±»å™¨ï¼Œå°†åˆçº§åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸ºæ¬¡çº§åˆ†ç±»å™¨çš„è¾“å…¥ï¼Œè·å¾—æœ€ç»ˆçš„è¾“å‡ºã€‚æˆ‘ä»¬åº”å½“ä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒæ¬¡çº§åˆ†ç±»å™¨<br><img src="/images/2018-10-14-15394833971028.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Ensemble </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æµ…è°ˆmaskçŸ©é˜µ</title>
      <link href="/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/"/>
      <url>/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/</url>
      
        <content type="html"><![CDATA[<p>ä¸ªäººç›®å‰å¯¹maskçŸ©é˜µçš„ä¸€ç‚¹ç†è§£ã€‚</p><hr><h2 id="æ˜¯ä»€ä¹ˆ"><a href="#æ˜¯ä»€ä¹ˆ" class="headerlink" title="æ˜¯ä»€ä¹ˆ"></a>æ˜¯ä»€ä¹ˆ</h2><p>maskçŸ©é˜µæ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ä¸€ä¸ªç”±0å’Œ1ç»„æˆçš„çŸ©é˜µã€‚ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä¸­ï¼Œå¥å­çš„é•¿åº¦æ˜¯ä¸ç­‰é•¿çš„ï¼Œä½†å› ä¸ºæˆ‘ä»¬ç»å¸¸å°†å¥å­ç»„æˆmini-batchç”¨ä»¥è®­ç»ƒï¼Œå› æ­¤é‚£äº›é•¿åº¦è¾ƒçŸ­çš„å¥å­éƒ½ä¼šåœ¨å¥å°¾è¿›è¡Œå¡«å……0ï¼Œä¹Ÿå³paddingçš„æ“ä½œã€‚ä¸€ä¸ªmaskçŸ©é˜µå³ç”¨ä»¥æŒ‡ç¤ºå“ªäº›æ˜¯çœŸæ­£çš„æ•°æ®ï¼Œå“ªäº›æ˜¯paddingã€‚å¦‚ï¼š<br><img src="/images/2018-10-12-15393574958961.jpg" width="50%" height="50%"><br>å›¾ç‰‡æ¥æºï¼š<a href="https://www.cnblogs.com/neopenx/p/4806006.html" target="_blank" rel="noopener">Theanoï¼šLSTMæºç è§£æ</a></p><p>å…¶ä¸­maskçŸ©é˜µä¸­1ä»£è¡¨çœŸå®æ•°æ®ï¼›0ä»£è¡¨paddingæ•°æ®ã€‚</p><h2 id="ä¸ºä»€ä¹ˆ"><a href="#ä¸ºä»€ä¹ˆ" class="headerlink" title="ä¸ºä»€ä¹ˆ"></a>ä¸ºä»€ä¹ˆ</h2><p>ä¸ºä»€ä¹ˆè¦ä½¿ç”¨maskçŸ©é˜µï¼Ÿä½¿ç”¨maskçŸ©é˜µæ˜¯ä¸ºäº†è®©é‚£äº›è¢«maskæ‰çš„tensorä¸ä¼šè¢«æ›´æ–°ã€‚è€ƒè™‘ä¸€ä¸ªtensor Tçš„size(a,b)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œç›¸ä¹˜åï¼Œåœ¨åå‘å›ä¼ çš„æ—¶å€™åœ¨Tå¯¹åº”maskä¸º0çš„åœ°æ–¹ï¼Œ0çš„æ¢¯åº¦ä»ä¸º0ã€‚å› æ­¤ä¸ä¼šè¢«æ›´æ–°ã€‚</p><h2 id="æ€ä¹ˆåš"><a href="#æ€ä¹ˆåš" class="headerlink" title="æ€ä¹ˆåš"></a>æ€ä¹ˆåš</h2><p>æ¥ä¸‹æ¥ä»‹ç»å‡ ç§ï¼ˆå¯èƒ½ä¸å…¨ï¼‰ä½¿ç”¨maskçš„åœºæ™¯ã€‚</p><h3 id="å¯¹è¾“å…¥è¿›è¡Œmask"><a href="#å¯¹è¾“å…¥è¿›è¡Œmask" class="headerlink" title="å¯¹è¾“å…¥è¿›è¡Œmask"></a>å¯¹è¾“å…¥è¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­å¸¸è§çš„å¥å­ä¸ç­‰é•¿çš„æƒ…å†µã€‚è®¾æˆ‘ä»¬çš„è¾“å…¥çš„batch I:(batch_size,max_seqlen)ï¼Œæˆ‘ä»¬åœ¨è¿‡ä¸€å±‚Embeddingå±‚ä¹‹å‰ï¼Œ<br>åœ¨è¿‡äº†ä¸€å±‚Embeddingå±‚ï¼Œåˆ™æœ‰ E:(batch_size,max_seqlen,embed_dim)ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›Embeddingæ˜¯æ›´æ–°çš„(æ¯”å¦‚æˆ‘ä»¬çš„Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œé‚£å½“ç„¶Embeddingéœ€è¦æ›´æ–°)ï¼Œä½†æˆ‘ä»¬åˆä¸å¸Œæœ›paddingæ›´æ–°ã€‚<br>ä¸€ç§æ–¹æ³•å³ä»¤Eä¸Mç›¸ä¹˜ã€‚å…¶ä¸­Mæ˜¯maskçŸ©é˜µ(batch_size,max_seqlen,1) (1æ˜¯å› ä¸ºè¦broadcastï¼‰ï¼Œè¿™æ ·åœ¨Embeddingæ›´æ–°æ¢¯åº¦æ—¶ï¼Œå› ä¸ºmaskçŸ©é˜µçš„å…³ç³»ï¼Œpaddingä½ç½®ä¸Šçš„æ¢¯åº¦å°±æ˜¯0ã€‚<br>å½“ç„¶åœ¨Pytorchä¸­è¿˜å¯ä»¥ç›´æ¥æ˜¾å¼åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p>è€Œæ­¤æ—¶åº”å½“å°†paddingæ˜¾å¼æ·»åŠ åˆ°è¯å…¸çš„ç¬¬ä¸€ä¸ªã€‚</p><h3 id="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"><a href="#å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask" class="headerlink" title="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"></a>å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask</h3><p>ä¸€ä¸ªå¾ˆç»å…¸çš„åœºæ™¯å°±æ˜¯dropoutã€‚<br>å¯¹äºå‚æ•°çŸ©é˜µW:(h,w)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ä»¤Wâ€™=W*Mï¼Œåˆ™åœ¨åå‘ä¼ æ’­æ—¶ï¼ŒMä¸­ä¸º0çš„éƒ¨åˆ†ä¸è¢«æ›´æ–°ã€‚<br>å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨PyTorchä¸­çš„åŒ…<code>nn.Dropout()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line">input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line">output = m(input)</span><br></pre></td></tr></table></figure><h3 id="å¯¹lossè¿›è¡Œmask"><a href="#å¯¹lossè¿›è¡Œmask" class="headerlink" title="å¯¹lossè¿›è¡Œmask"></a>å¯¹lossè¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­çš„language modelï¼Œæ¯ä¸ªè¯éƒ½éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œåœ¨ä¸€ä¸ªbatchä¸­å¥å­æ€»æ˜¯æœ‰é•¿æœ‰çŸ­ï¼Œå¯¹äºä¸€ä¸ªçŸ­å¥ï¼Œæ­¤æ—¶åœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œä¼šå‡ºç°è¿™æ ·çš„åœºæ™¯ï¼š<code>&lt;pad&gt;</code>è¯è¦é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>è¯ã€‚ä¸¾ä¸ªä¾‹å­ï¼šä¸‰ä¸ªå¥å­[a,b,c,d],[e,f,g],[h,i]ï¼Œåœ¨ç»„æˆbatchåï¼Œä¼šå˜æˆ<br>Xï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>a</td><td>b</td><td>c</td><td>d</td></tr><tr><td>e</td><td>f</td><td>g</td><td><code>&lt;pad&gt;</code></td></tr><tr><td>h</td><td>i</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table></div><p>Yï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>b</td><td>c</td><td>d</td><td><code>&lt;pad&gt;</code></td></tr><tr><td>f</td><td>g</td><td><code>&lt;eos&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr><tr><td>i</td><td><code>&lt;eos&gt;</code></td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table></div><p>Xæ˜¯è¾“å…¥ï¼ŒYæ˜¯é¢„æµ‹ã€‚é‚£ä¹ˆä»ç¬¬ä¸‰è¡Œå¯ä»¥çœ‹å‡ºï¼Œ<code>&lt;pad&gt;</code>åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>ã€‚è¿™æ˜¾ç„¶æ˜¯æœ‰é—®é¢˜çš„ã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆå°±æ˜¯ä½¿ç”¨maskçŸ©é˜µï¼Œåœ¨lossçš„è®¡ç®—æ—¶ï¼Œå°†é‚£äº›æœ¬ä¸åº”è¯¥è®¡ç®—çš„maskæ‰ï¼Œä½¿å¾—å…¶lossä¸º0ï¼Œè¿™æ ·å°±ä¸ä¼šåå‘å›ä¼ äº†ã€‚<br>å…·ä½“å®è·µï¼šåœ¨PyTorchä¸­ï¼Œä»¥CrossEntropyä¸ºä¾‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">nn</span>.<span class="title">CrossEntropyLoss</span><span class="params">(weight=None, size_average=None, ignore_index=<span class="number">-100</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">reduce=None, reduction=â€™elementwise_meanâ€™</span></span></span><br></pre></td></tr></table></figure><p>å¦‚æœ<code>reduction=None</code>åˆ™ä¼šè¿”å›ä¸€ä¸ªä¸è¾“å…¥åŒæ ·å¤§å°çš„çŸ©é˜µã€‚åœ¨ä¸maskçŸ©é˜µç›¸ä¹˜åï¼Œå†å¯¹æ–°çŸ©é˜µè¿›è¡Œmeanæ“ä½œã€‚<br>åœ¨PyTorchå®è·µä¸Šè¿˜å¯ä»¥å¯ä»¥è¿™ä¹ˆå†™ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">masked_outputs = torch.masked_select(dec_outputs, mask)</span><br><span class="line">masked_targets = torch.masked_select(targets, mask)</span><br><span class="line">loss = my_criterion(masked_outputs, masked_targets)</span><br></pre></td></tr></table></figure><p>å¦ä¸€ç§æ›´ä¸ºç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œç›´æ¥åœ¨CrossEntropyä¸­è®¾<code>ignore_index=0</code>ï¼Œè¿™æ ·ï¼Œåœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œå‘ç°target=0æ—¶ï¼Œä¼šè‡ªåŠ¨ä¸å¯¹å…¶è¿›è¡Œlossçš„è®¡ç®—ã€‚å…¶æœ¬è´¨å’ŒmaskçŸ©é˜µæ˜¯ä¸€è‡´çš„ã€‚</p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>maskçŸ©é˜µå¯ä»¥ç”¨åœ¨ä»»ä½•åœ°æ–¹ï¼Œåªè¦å¸Œæœ›ä¸ä¹‹ç›¸ä¹˜çš„tensorç›¸å¯¹åº”çš„åœ°æ–¹ä¸æ›´æ–°å°±å¯ä»¥è¿›è¡Œmaskæ“ä½œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä»£ç å®è·µ </tag>
            
            <tag> maskçŸ©é˜µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ·±åº¦ç‚¼ä¸¹tricksåˆé›†</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E7%82%BC%E4%B8%B9tricks%E5%90%88%E9%9B%86/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E7%82%BC%E4%B8%B9tricks%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>â€”-Deprecatedâ€”-</p><h2 id="è°ƒå‚æŠ€å·§"><a href="#è°ƒå‚æŠ€å·§" class="headerlink" title="è°ƒå‚æŠ€å·§"></a>è°ƒå‚æŠ€å·§</h2><h3 id="æ•°æ®å¢å¼º"><a href="#æ•°æ®å¢å¼º" class="headerlink" title="æ•°æ®å¢å¼º"></a>æ•°æ®å¢å¼º</h3><h3 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h3><h4 id="1ï¸âƒ£zero-center"><a href="#1ï¸âƒ£zero-center" class="headerlink" title="1ï¸âƒ£zero-center"></a>1ï¸âƒ£zero-center</h4><p>[9]å°†æ•°æ®ä¸­å¿ƒåŒ–</p><h3 id="åˆå§‹åŒ–"><a href="#åˆå§‹åŒ–" class="headerlink" title="åˆå§‹åŒ–"></a>åˆå§‹åŒ–</h3><h4 id="1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•"><a href="#1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•" class="headerlink" title="1ï¸âƒ£Xavier initialization[7]æ–¹æ³•"></a>1ï¸âƒ£Xavier initialization[7]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºæ™®é€šæ¿€æ´»å‡½æ•°(tanh,sigmoid)ï¼šscale = np.sqrt(3/n)</p><h4 id="2ï¸âƒ£He-initialization-8-æ–¹æ³•"><a href="#2ï¸âƒ£He-initialization-8-æ–¹æ³•" class="headerlink" title="2ï¸âƒ£He initialization[8]æ–¹æ³•"></a>2ï¸âƒ£He initialization[8]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºReLUï¼šscale = np.sqrt(6/n)</p><h4 id="3ï¸âƒ£Batch-normalization-10"><a href="#3ï¸âƒ£Batch-normalization-10" class="headerlink" title="3ï¸âƒ£Batch normalization[10]"></a>3ï¸âƒ£Batch normalization[10]</h4><h4 id="4ï¸âƒ£RNN-LSTM-init-hidden-state"><a href="#4ï¸âƒ£RNN-LSTM-init-hidden-state" class="headerlink" title="4ï¸âƒ£RNN/LSTM init hidden state"></a>4ï¸âƒ£RNN/LSTM init hidden state</h4><p>Hinton[3]æåˆ°å°†RNN/LSTMçš„åˆå§‹hidden stateè®¾ç½®ä¸ºå¯å­¦ä¹ çš„weight</p><h3 id="è®­ç»ƒæŠ€å·§"><a href="#è®­ç»ƒæŠ€å·§" class="headerlink" title="è®­ç»ƒæŠ€å·§"></a>è®­ç»ƒæŠ€å·§</h3><h4 id="1ï¸âƒ£Gradient-Clipping-5-6"><a href="#1ï¸âƒ£Gradient-Clipping-5-6" class="headerlink" title="1ï¸âƒ£Gradient Clipping[5,6]"></a>1ï¸âƒ£Gradient Clipping[5,6]</h4><h4 id="2ï¸âƒ£learning-rate"><a href="#2ï¸âƒ£learning-rate" class="headerlink" title="2ï¸âƒ£learning rate"></a>2ï¸âƒ£learning rate</h4><p>åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚<br>[1]Time/Drop-based/Cyclical Learning Rate</p><h4 id="3ï¸âƒ£batch-size"><a href="#3ï¸âƒ£batch-size" class="headerlink" title="3ï¸âƒ£batch size"></a>3ï¸âƒ£batch size</h4><p>[2]ä¸­è¯¦ç»†è®ºè¿°äº†å¢åŠ batch sizeè€Œä¸æ˜¯å‡å°learning rateèƒ½å¤Ÿæå‡æ¨¡å‹è¡¨ç°ã€‚ä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">How to make your model happy againâ€Šâ€”â€Špart 1</a></p><p>[2]<a href="https://arxiv.org/abs/1711.00489" target="_blank" rel="noopener">Donâ€™t Decay the Learning Rate, Increase the Batch Size</a></p><p>[3]<a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">CSC2535 2013: Advanced Machine Learning Lecture 10 Recurrent neural networks</a></p><p>[4]<a href="https://zhuanlan.zhihu.com/p/25110150" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110150</a></p><p>[5]<a href="https://arxiv.org/abs/1211.5063" target="_blank" rel="noopener">On the difficulty of training Recurrent Neural Networks</a></p><p>[6]<a href="https://arxiv.org/abs/1612.08083" target="_blank" rel="noopener">Language Modeling with Gated Convolutional Networks</a></p><p>[7]<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Understanding the difficulty of training deep feedforward neural networks</a></p><p>[8]<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></p><p>[9]<a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">çŸ¥ä¹ï¼šä½ æœ‰å“ªäº›deep learningï¼ˆrnnã€cnnï¼‰è°ƒå‚çš„ç»éªŒï¼Ÿ</a></p><p>[10]<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è°ƒå‚ </tag>
            
            <tag> tricks </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯11</title>
      <link href="/2018/10/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D11/"/>
      <url>/2018/10/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D11/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"><a href="#1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«" class="headerlink" title="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"></a>1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«</h3><p>[å”] ç™½å±…æ˜“<br>ç¦»ç¦»åŸä¸Šè‰ï¼Œä¸€å²ä¸€æ¯è£ã€‚<br><strong>é‡ç«çƒ§ä¸å°½ï¼Œæ˜¥é£å¹åˆç”Ÿ</strong>ã€‚<br>è¿œèŠ³ä¾µå¤é“ï¼Œæ™´ç¿ æ¥è’åŸã€‚<br>åˆé€ç‹å­™å»ï¼Œè‹è‹æ»¡åˆ«æƒ…ã€‚</p><p>è‹è‹ï¼ˆqÄ«ï¼‰ï¼šå½¢å®¹è‰æœ¨é•¿å¾—èŒ‚ç››çš„æ ·å­ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬ä¸‰ç«  å›å½’çš„çº¿æ€§æ¨¡å‹</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%9B%9E%E5%BD%92%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%9B%9E%E5%BD%92%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"><a href="#çº¿æ€§åŸºå‡½æ•°æ¨¡å‹" class="headerlink" title="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"></a>çº¿æ€§åŸºå‡½æ•°æ¨¡å‹</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-51-50.jpg" alt="0"></p><p><img src="/images/2018-10-07-Xnip2018-10-07_15-53-54.jpg" alt="1"></p><h1 id="åç½®-â½…å·®åˆ†è§£"><a href="#åç½®-â½…å·®åˆ†è§£" class="headerlink" title="åç½®-â½…å·®åˆ†è§£"></a>åç½®-â½…å·®åˆ†è§£</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-56-30.jpg" alt="0"></p><h1 id="è´å¶æ–¯çº¿æ€§å›å½’"><a href="#è´å¶æ–¯çº¿æ€§å›å½’" class="headerlink" title="è´å¶æ–¯çº¿æ€§å›å½’"></a>è´å¶æ–¯çº¿æ€§å›å½’</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_16-13-57.jpg" alt="1"></p><h1 id="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"><a href="#è´å¶æ–¯æ¨¡å‹â½è¾ƒ" class="headerlink" title="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"></a>è´å¶æ–¯æ¨¡å‹â½è¾ƒ</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_23-30-33.jpg" alt="1"></p><h1 id="è¯æ®è¿‘ä¼¼"><a href="#è¯æ®è¿‘ä¼¼" class="headerlink" title="è¯æ®è¿‘ä¼¼"></a>è¯æ®è¿‘ä¼¼</h1><p><img src="/images/2018-10-09-Xnip2018-10-09_22-06-22.jpg" alt="1"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 16:SVM</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2016:%20SVM/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2016:%20SVM/</url>
      
        <content type="html"><![CDATA[<p><strong>Hinge Loss+kernel method = SVM</strong></p><h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><p>SVMä¸logistic regressionçš„åŒºåˆ«å³åœ¨äºloss functionçš„ä¸åŒï¼Œlogisticæ˜¯cross entropyï¼Œè€ŒSVMæ˜¯hinge loss<br><img src="/images/2018-10-07-15388878731499.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³å¦‚æœåˆ†ç±»é—´éš”å¤§äº1ï¼Œåˆ™ $L(m_i)=max(0,1âˆ’m_i(w))$ï¼Œåˆ™æŸå¤±ä¸º0ã€‚å› æ­¤SVMæ›´å…·é²æ£’æ€§ï¼Œå› ä¸ºå¯¹ç¦»ç¾¤ç‚¹ä¸æ•æ„Ÿã€‚</p><p>å¯¹äºlinear SVMï¼š</p><ul><li>å®šä¹‰å‡½æ•° $f(x)=\sum_i w_i x_i +b=w^T x$</li><li>å®šä¹‰æŸå¤±å‡½æ•°  $L(f)=\sum_n l(f(x^n),\hat{y}^n)+\lambda ||w||_2$ï¼Œå…¶ä¸­$l(f(x^n),\hat{y}^n)=max(0,1-\hat{y}^n f(x))$</li><li><p>æ¢¯åº¦ä¸‹é™æ±‚è§£ï¼ˆçœç•¥äº†æ­£åˆ™åŒ–ï¼‰</p><script type="math/tex; mode=display">\frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{w_i}}=  \frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{f(x^n)}}  \frac{\partial{f(x^n)}}{\partial{w_i}} x_i^n</script><p>  è€Œ</p><script type="math/tex; mode=display">f(x^n)=w^T \cdot x^n</script></li></ul><script type="math/tex; mode=display">\frac{\partial{max(0,1-\hat{y}^n f(x^n)})}{\partial{f(x^n)}}=\left\{               \begin{array}{**lr**}                -\hat{y}^n & if  \hat{y}^n f(x^n)<1 \\                 0  & otherwise &                 \end{array}  \right.</script><p>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388891611785.jpg" width="55%" height="50%"><br>æˆ‘ä»¬æ¥ä¸‹æ¥ç”¨$c^n(w)$æ›¿ä»£$-\delta(\hat{y}^n f(x^n)&lt;1) \hat{y}^n$</p><h3 id="Kernel-Method"><a href="#Kernel-Method" class="headerlink" title="Kernel Method"></a>Kernel Method</h3><p>ä¸€ä¸ªäº‹å®ï¼š$w$æ˜¯$x$çš„çº¿æ€§åŠ å’Œï¼Œå…¶ä¸­$Î±$ä¸ç­‰äº0å¯¹åº”çš„$x$å°±æ˜¯support vectors</p><p>è¯æ˜ï¼š<br>æˆ‘ä»¬å‰é¢è¯´è¿‡ï¼Œæ›´æ–°è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-07-15388894194698.jpg" width="30%" height="50%"></p><p>å°†å…¶ç»„ç»‡æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/2018-10-07-15388894627632.jpg" width="25%" height="50%"></p><p><strong>å¦‚æœæˆ‘ä»¬å°†$w$åˆå§‹åŒ–æˆ0å‘é‡</strong>ï¼Œé‚£ä¹ˆ$w$æœ€ç»ˆå°±æ˜¯$x$çš„çº¿æ€§ç»„åˆã€‚è¯æ¯•</p><p>å› ä¸º$c(w)$æ˜¯hinge lossï¼Œå› æ­¤å¤§å¤šæ•°çš„å€¼æ˜¯0ï¼Œä¼šé€ æˆ$Î±$ç¨€ç–ã€‚<br>å¦‚æœæˆ‘ä»¬å°†è®­ç»ƒæ•°æ®$x$ç»„ç»‡æˆä¸€ä¸ªçŸ©é˜µï¼Œé‚£ä¹ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388895570090.jpg" width="25%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-07-15388895870336.jpg" width="40%" height="50%"></p><p>æ‰€ä»¥å¯¹äº$f(x)$ï¼Œæœ‰ï¼š<br><img src="/images/2018-10-07-15388896378645.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Š$X^Tx$å°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®å’Œ$x$è¿›è¡Œç‚¹ç§¯çš„ç»“æœï¼Œä½†å®é™…ä¸Šçº¿æ€§å‡½æ•°å¾€å¾€è¡¨è¾¾èƒ½åŠ›ä¸å¼ºï¼Œæˆ‘ä»¬å¸Œæœ›$x$èƒ½å¤Ÿå˜æˆéçº¿æ€§çš„ã€‚å¦‚æœæˆ‘ä»¬å¼•å…¥kernelï¼Œå°†ç‚¹ç§¯æ¢æˆkernelï¼Œåˆ™ä¼šæœ‰ï¼š</p><script type="math/tex; mode=display">f(x)=\sum_n \alpha_n (x_n\cdot x)=\sum_n \alpha_n K(x_n,x)</script><p>æ‰€ä»¥æˆ‘ä»¬çš„é—®é¢˜å°±å˜æˆäº†ï¼š</p><ul><li>å®šä¹‰å‡½æ•° $f(x)=\sum_n \alpha_n K(x_n,x)$</li><li>æ‰¾åˆ°æœ€ä½³çš„Î±ï¼Œæœ€å°åŒ–loss functionï¼š$L(f)=\sum_n l(f(x^n),\hat{y}^n)=\sum_n l(\sum_{nâ€™} \alpha_{nâ€™} K(x^{n^{â€˜}},x^n),\hat{y}^n)$</li></ul><p>å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦çœŸçš„çŸ¥é“$x$çš„éçº¿æ€§çš„å…·ä½“å½¢å¼ï¼Œæˆ‘ä»¬åªéœ€è¦ä¼šç®—$K$å°±è¡Œï¼Œè¿™ç§ç»•è¿‡$x$çš„å…·ä½“å½¢å¼çš„æ–¹æ³•å°±æ˜¯<strong>kernel trick</strong>ã€‚ç›´æ¥è®¡ç®—$K$ï¼Œæ¯”å…ˆå°†$x$éçº¿æ€§è½¬åŒ–å†åšç‚¹ç§¯æ¥å¾—é«˜æ•ˆã€‚ç”šè‡³æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å¯¹$x$åšçš„éçº¿æ€§æ˜¯æ— ç©·å¤šç»´çš„ï¼Œæ˜¯æ— æ³•ç›´æ¥åšéçº¿æ€§åŒ–çš„ã€‚æ¯”å¦‚RBFæ ¸:</p><script type="math/tex; mode=display">K(x,z)=exp(-\frac{1}{2}||x-z||_2)</script><p>é€šè¿‡æ³°å‹’å±•å¼€å¯ä»¥çŸ¥é“ï¼ŒRBFæ ¸æ˜¯æ— ç©·ç»´çš„ã€‚</p><p>å¦ä¸€ä¸ªkernelçš„ä¾‹å­æ˜¯sigmoid kernelï¼š</p><script type="math/tex; mode=display">K(x,z)=tanh(x\cdot z)</script><p>å½“æˆ‘ä»¬ä½¿ç”¨sigmoid kernelæ—¶ï¼Œå°±ç›¸å½“äºä¸€å±‚hidden layerçš„ç¥ç»ç½‘ç»œï¼Œå¦‚å›¾ï¼š<br><img src="/images/2018-10-07-15388901736757.jpg" width="40%" height="50%"></p><p>ç»™å®šä¸€ä¸ªè¾“å…¥ï¼Œå…±æœ‰nä¸ªneuronï¼Œå…¶ä¸­çš„weightå°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®çš„å‘é‡å€¼ï¼Œç„¶åå†å°†è¿™äº›neuronåŠ å’Œå¾—åˆ°è¾“å‡ºã€‚å½“ç„¶å¤§éƒ¨åˆ†çš„Î±çš„å€¼æ˜¯0ï¼Œå› æ­¤å®è´¨ä¸Šç¥ç»å…ƒçš„ä¸ªæ•°å’Œsupport vectorçš„ä¸ªæ•°ä¸€è‡´ã€‚</p><p>æˆ‘ä»¬å¯ä»¥ç›´æ¥è®¾è®¡kernelï¼Œè€Œä¸éœ€è¦è€ƒè™‘xçš„éçº¿æ€§å˜æ¢çš„å½¢å¼ï¼Œåªè¦kernelç¬¦åˆmercerâ€™s theoryå³å¯ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 15:Transfer Learning</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2015:%20Transfer%20Learning/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2015:%20Transfer%20Learning/</url>
      
        <content type="html"><![CDATA[<h3 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h3><p>å‡è®¾æˆ‘ä»¬æœ‰å¾ˆå¤šçš„source data $(x^s,y^s )$ï¼Œä¸ä»»åŠ¡ç›¸å…³çš„target data $(x^t,y^t )$  å¾ˆå°‘ã€‚<br>æˆ‘ä»¬åˆ©ç”¨source dataè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åç”¨target dataæ¥fine tuneæ¨¡å‹ã€‚</p><h4 id="conservative-training"><a href="#conservative-training" class="headerlink" title="conservative training"></a>conservative training</h4><p><img src="/images/2018-10-07-15388871902739.jpg" width="50%" height="50%"></p><p>æˆ‘ä»¬å¯ä»¥ç”¨source dataè®­ç»ƒå¥½çš„æ¨¡å‹çš„weightä½œä¸ºæ–°çš„æ¨¡å‹çš„weightï¼Œç„¶åè®¾å®šä¸€äº›é™åˆ¶ï¼Œæ¯”å¦‚source dataä½œä¸ºè¾“å…¥çš„outputåº”å’Œtarget dataä½œä¸ºè¾“å…¥çš„outputå°½é‡ç›¸ä¼¼ï¼Œæˆ–è€…å‚æ•°å°½é‡ç›¸ä¼¼ç­‰ã€‚</p><h4 id="layer-transfer"><a href="#layer-transfer" class="headerlink" title="layer transfer"></a>layer transfer</h4><p>ä¹Ÿå°±æ˜¯æ–°æ¨¡å‹æœ‰å‡ å±‚æ˜¯ç›´æ¥copyæ—§æ¨¡å‹çš„ï¼Œåªè®­ç»ƒå…¶å®ƒå±‚ã€‚æ³¨æ„åˆ°ä¸åŒä»»åŠ¡æ‰€åº”copyçš„å±‚æ˜¯ä¸åŒçš„ï¼Œè¯­éŸ³ä»»åŠ¡æœ€åå‡ å±‚æ•ˆæœå¥½ï¼Œå›¾åƒè¯†åˆ«å‰é¢å‡ å±‚æ•ˆæœå¥½</p><h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p>ä¸åŒä»»åŠ¡ä¹‹é—´å…±äº«ç›¸åŒçš„ä¸­é—´å±‚ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388872452545.jpg" width="30%" height="50%"><br><img src="/images/2018-10-07-15388872627707.jpg" width="30%" height="50%"></p><p>è¿˜æœ‰ä¸€ç§progressive neural networksï¼š<br><img src="/images/2018-10-07-15388872920224.jpg" width="50%" height="50%"><br>é¦–å…ˆè®­ç»ƒå¥½ç¬¬ä¸€ä¸ªä»»åŠ¡çš„æ¨¡å‹ï¼Œç„¶ååœ¨è®­ç»ƒç¬¬äºŒä¸ªæ¨¡å‹çš„æ—¶å€™å°†ç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬äºŒä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼›è®­ç»ƒç¬¬ä¸‰ä¸ªæ¨¡å‹åˆ™å°†ç¬¬äºŒä¸ªå’Œç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬ä¸‰ä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼Œä»¥æ­¤ç±»æ¨</p><h3 id="Domain-adversarial-training"><a href="#Domain-adversarial-training" class="headerlink" title="Domain-adversarial training"></a>Domain-adversarial training</h3><p>source dataæ˜¯æœ‰æ ‡ç­¾çš„ï¼Œè€Œtarget dataæ˜¯æ— æ ‡ç­¾çš„ï¼Œéƒ½å±äºåŒä¸€ä¸ªä»»åŠ¡ï¼Œä½†æ•°æ®æ˜¯mismatchçš„ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388873325090.jpg" width="50%" height="50%"></p><p>å› ä¸ºNNçš„éšå±‚å¯ä»¥ç†è§£æˆæ˜¯åœ¨æŠ½å–å›¾åƒçš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿåœ¨è®­ç»ƒNNçš„è¿‡ç¨‹ä¸­å»æ‰source dataçš„ä¸€äº›domain specificçš„ç‰¹æ€§ï¼Œè¿™æ ·å°±å¯ä»¥ç”¨åœ¨target dataä¸Šäº†ã€‚å› æ­¤æˆ‘ä»¬åœ¨feature exactoråé¢è¿æ¥ä¸¤ä¸ªæ¨¡å—ï¼š<br><img src="/images/2018-10-07-15388873772888.jpg" width="50%" height="50%"></p><p>ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›æŠ½å–çš„ç‰¹å¾èƒ½å¤Ÿä½¿å¾—åˆ†ç±»å™¨æ­£ç¡®åœ°åˆ†ç±»ï¼Œå¦ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›è¿™äº›ç‰¹å¾èƒ½å¤Ÿè®©domain classifierèƒ½å¤Ÿæ— æ³•è¯†åˆ«ç‰¹å¾æ˜¯ä»å“ªäº›dataæŠ½å–å¾—åˆ°çš„ï¼Œè¿™æ ·å¾—åˆ°çš„ç‰¹å¾å°±æ˜¯è¢«å»æ‰domain specificç‰¹å¾çš„ã€‚</p><p>å…·ä½“è®­ç»ƒï¼š<br><img src="/images/2018-10-07-15388874447304.jpg" width="50%" height="50%"></p><h3 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h3><p>source dataæœ‰æ ‡ç­¾ï¼Œtarget dataæ— æ ‡ç­¾ï¼Œä½†ä»»åŠ¡ä¸åŒï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388874838165.jpg" width="50%" height="50%"></p><h4 id="Representing-each-class-by-its-attributes"><a href="#Representing-each-class-by-its-attributes" class="headerlink" title="Representing each class by its attributes"></a>Representing each class by its attributes</h4><p>ä¸€ç§æ–¹æ³•æ˜¯å°†æ¯ä¸€ä¸ªç±»éƒ½ç”¨ç‰¹å¾è¡¨ç¤ºï¼Œä½†ç‰¹å¾è¦è¶³å¤Ÿä¸°å¯Œï¼š<br><img src="/images/2018-10-07-15388875088114.jpg" width="50%" height="50%"></p><p>åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å…¥æ˜¯å›¾ç‰‡ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™äº›ç‰¹å¾ï¼š<br><img src="/images/2018-10-07-15388875558853.jpg" width="40%" height="50%"><br>è¿™æ ·åœ¨å°†target dataæ”¾å…¥è®­ç»ƒå¥½çš„NNåä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªè¿™æ ·çš„attributeï¼ŒæŸ¥è¡¨å³å¯æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ç‰¹å¾å¯¹åº”çš„ç±»ã€‚</p><h4 id="Attribute-embedding"><a href="#Attribute-embedding" class="headerlink" title="Attribute embedding"></a>Attribute embedding</h4><p>å¦‚æœç‰¹å¾ç»´åº¦å¤ªé«˜ï¼Œä¹Ÿå¯ä»¥å°†ç‰¹å¾å‹ç¼©æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œè¿™æ ·åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™æ ·çš„å‘é‡ç‰¹å¾ï¼Œè¾“å…¥target dataï¼Œè¾“å‡ºå‘é‡ç‰¹å¾ï¼Œæ‰¾åˆ°æœ€è¿‘çš„ç‰¹å¾å¯¹åº”çš„ç±»å³å¯<br><img src="/images/2018-10-07-15388875888699.jpg" width="50%" height="50%"></p><h4 id="Attribute-embedding-word-embedding"><a href="#Attribute-embedding-word-embedding" class="headerlink" title="Attribute embedding + word embedding"></a>Attribute embedding + word embedding</h4><p>å¦‚æœæ²¡æœ‰attributeæ•°æ®ï¼Œåˆ©ç”¨word embeddingä¹Ÿå¯ä»¥è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚<br>åœ¨zero-shot learningä¸­ï¼Œå…‰æ˜¯è®©ç›¸åŒç±»çš„få’Œgç›¸ä¼¼æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜åº”è¯¥è®©ä¸åŒçš„få’Œgå°½é‡è¿œã€‚</p><script type="math/tex; mode=display">f^âˆ—,g^âˆ—=arg min_{(f,g)}â¡âˆ‘_nmax(0,kâˆ’f(x^n )\cdot g(y^n )+max_{(mâ‰ n)} â¡f(x^m )\cdot g(x^m ) )</script>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Transfer Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 14:Unsupervised Learning:Generation</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2014:%20Unsupervised%20Learning:%20Generation/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2014:%20Unsupervised%20Learning:%20Generation/</url>
      
        <content type="html"><![CDATA[<h3 id="Component-by-component"><a href="#Component-by-component" class="headerlink" title="Component-by-component"></a>Component-by-component</h3><p>å¯¹äºå›¾åƒæ¥è¯´ï¼Œæ¯æ¬¡ç”Ÿæˆä¸€ä¸ªpixelï¼šPixelRNN</p><h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>æ¶æ„ï¼š<br><img src="/images/2018-10-07-15388837191574.jpg" width="50%" height="50%"></p><p>å…¶ä¸­eæ˜¯å™ªå£°ï¼ŒÏƒæ˜¯æ–¹å·®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–reconstruction errorï¼Œä»¥åŠä¸€ä¸ªé™åˆ¶ã€‚è¯¥é™åˆ¶çš„ç›®çš„å³é˜²æ­¢Ïƒ=0ï¼Œmæ˜¯æ­£åˆ™åŒ–é¡¹ã€‚</p><p><del>ä¸­é—´çš„æ¨å¯¼ä»¥åŠä¸ºä»€ä¹ˆæ˜¯è¿™æ ·çš„æ¶æ„æˆ‘è¿˜ä¸æ˜¯å¾ˆæ‡‚ï¼Œä¹‹åå†æ›´æ–°ã€‚</del><br>å®é™…ä¸Šå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œæœ‰å‡ ä¸ªè¦ç‚¹ï¼š</p><ul><li>é¦–å…ˆæˆ‘ä»¬æ˜¯åŸºäºè¿™ä¹ˆä¸€ä¸ªå‡è®¾ï¼šä¸­é—´çš„codeåº”å½“æ˜¯æœä»æ­£æ€åˆ†å¸ƒçš„ï¼Œè€Œencoderçš„ä½œç”¨å³åœ¨äºæ‹Ÿåˆè¯¥æ­£æ€åˆ†å¸ƒçš„å‡å€¼ä¸æ–¹å·®çš„å¯¹æ•°ï¼ˆå› ä¸ºæ–¹å·®åº”å½“æ’ä¸ºæ­£ï¼Œä½†ç¥ç»ç½‘ç»œçš„è¾“å‡ºå¯èƒ½æœ‰æ­£æœ‰è´Ÿï¼‰</li><li>å¦‚æœç”Ÿæˆå‡ºæ¥çš„codeä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œä¼šæœ‰ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œä¹Ÿå°±æ˜¯ä¸Šå›¾çš„constraintï¼ˆå¯ä»¥é€šè¿‡KLæ•£åº¦æ¨å¯¼è·å¾—ï¼‰</li><li>æŒ‰ç†è¯´ï¼Œåº”å½“æ˜¯åœ¨ç”Ÿæˆäº†å‡å€¼å’Œæ–¹å·®åï¼Œå®šä¹‰å¥½è¯¥æ­£æ€åˆ†å¸ƒï¼Œç„¶åå†ä»ä¸­é‡‡æ ·ï¼Œä½†æ˜¯è¿™æ ·æ²¡åŠæ³•å›ä¼ æ›´æ–°æ¢¯åº¦ï¼Œå› æ­¤è¿™é‡Œä½¿ç”¨é‡å‚æ•°æŠ€å·§(Reparameterization Trick)ï¼Œä¹Ÿå³ä»$N(\mu,\sigma^2)$ä¸­é‡‡æ ·$Z$ï¼Œç›¸å½“äºä»$N(0,I)$ä¸­é‡‡æ ·$\varepsilon$ï¼Œç„¶åè®©$Z=\mu + \varepsilon \times \mu$</li></ul><p><img src="/images/2018-10-08-15389638077301.jpg" width="70%" height="50%"></p><p><strong>Reference</strong>:<br><a href="https://www.sohu.com/a/226209674_500659" target="_blank" rel="noopener">https://www.sohu.com/a/226209674_500659</a></p><p>VAEçš„ä¸»è¦é—®é¢˜åœ¨äºï¼Œç½‘ç»œåªè¯•å›¾å»è®°ä½è§è¿‡çš„å›¾åƒï¼Œä½†æ²¡æ³•çœŸæ­£å»ç”Ÿæˆæ²¡è§è¿‡çš„å›¾åƒã€‚</p><h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network (GAN)"></a>Generative Adversarial Network (GAN)</h3><p>GANåŒ…å«ä¸€ä¸ªdiscriminatorå’Œä¸€ä¸ªgeneratorï¼Œgeneratorè¯•å›¾ç”Ÿæˆèƒ½å¤Ÿéª—è¿‡discriminatorçš„æ ·æœ¬ï¼Œè€Œgeneratorè¯•å›¾èƒ½å¤Ÿå°†generatorç”Ÿæˆçš„æ ·æœ¬å’ŒçœŸå®çš„æ ·æœ¬åŒºåˆ†ã€‚</p><p>ä¹‹åä¼šæœ‰è¯¦ç»†çš„ä»‹ç»ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Generation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 13:Unsupervised Learning:Auto-encoder</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2013:%20Unsupervised%20Learning:%20Auto-encoder/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2013:%20Unsupervised%20Learning:%20Auto-encoder/</url>
      
        <content type="html"><![CDATA[<h3 id="Auto-encoder"><a href="#Auto-encoder" class="headerlink" title="Auto-encoder"></a>Auto-encoder</h3><p>ç”±ä¸€ä¸ªencoderå’Œä¸€ä¸ªdecoderç»„æˆï¼Œencoderè´Ÿè´£å°†è¾“å…¥è½¬æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼ˆç»´åº¦é€šå¸¸å°äºè¾“å…¥ï¼‰ï¼Œdecoderè´Ÿè´£å°†è¿™æ®µå‘é‡è¡¨ç¤ºæ¢å¤æˆåŸæ¥çš„è¾“å…¥ã€‚é‚£ä¹ˆä¸­é—´çš„codeå°±å¯ä»¥ä½œä¸ºè¾“å…¥çš„ä¸€ä¸ªä½ç»´è¡¨ç¤ºï¼š<br><img src="/images/2018-10-07-15388832782913.jpg" width="50%" height="50%"></p><h3 id="Auto-encoder-for-CNN"><a href="#Auto-encoder-for-CNN" class="headerlink" title="Auto-encoder for CNN"></a>Auto-encoder for CNN</h3><p><img src="/images/2018-10-07-15388833149617.jpg" width="50%" height="50%"></p><h4 id="Unpooling"><a href="#Unpooling" class="headerlink" title="Unpooling"></a>Unpooling</h4><p>æœ‰ä¸¤ç§æ–¹æ³•ï¼Œä¸€ç§åœ¨poolingçš„æ—¶å€™è®°å½•æœ€å¤§å€¼çš„ä½ç½®ï¼Œåœ¨unpoolingæ—¶åœ¨ç›¸å¯¹ä½ç½®å¡«å……æœ€å¤§å€¼ï¼Œå…¶ä»–ä½ç½®å¡«å……0ï¼›å¦ä¸€ç§ä¸è®°å½•æœ€å¤§å€¼ä½ç½®ï¼Œç›´æ¥åœ¨poolingåŒºåŸŸå…¨éƒ¨å¡«å……æœ€å¤§å€¼ã€‚<br><img src="/images/2018-10-07-15388833530548.jpg" width="50%" height="50%"></p><h4 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h4><p>å…¶å®æœ¬è´¨å°±æ˜¯convolutionã€‚</p><p>è¿™æ˜¯convolution:</p><p><img src="/images/2018-10-07-15388834044149.jpg" width="10%" height="50%"></p><p>æˆ‘ä»¬æœŸå¾…çš„convolutionï¼š<br><img src="/images/2018-10-07-15388834434741.jpg" width="15%" height="50%"></p><p>å®é™…ä¸Šå°±ç­‰ä»·åœ¨ä¸¤è¾¹åšpaddingï¼Œç„¶åç›´æ¥convolutionï¼š<br><img src="/images/2018-10-07-15388834751493.jpg" width="15%" height="50%"></p><h3 id="Auto-encoderçš„ç”¨å¤„"><a href="#Auto-encoderçš„ç”¨å¤„" class="headerlink" title="Auto-encoderçš„ç”¨å¤„"></a>Auto-encoderçš„ç”¨å¤„</h3><p>å¯ä»¥é¢„è®­ç»ƒæ¯ä¸€å±‚çš„DNNï¼š<br><img src="/images/2018-10-07-15388835335550.jpg" width="50%" height="50%"></p><p>åŒç†å…¶å®ƒå±‚ä¹Ÿæ˜¯ä¸€æ ·ï¼Œæ¯æ¬¡fixä½å…¶ä»–å±‚ç„¶ååšAuto-encoderã€‚é‚£ä¹ˆåœ¨bpçš„æ—¶å€™åªéœ€è¦fine-tuneå°±è¡Œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Auto-encoder </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 12:Unsupervised Learning:Neighbor Embedding</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2012:%20Unsupervised%20Learning:%20Neighbor%20Embedding/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2012:%20Unsupervised%20Learning:%20Neighbor%20Embedding/</url>
      
        <content type="html"><![CDATA[<h3 id="Locally-Linear-Embedding-LLE"><a href="#Locally-Linear-Embedding-LLE" class="headerlink" title="Locally Linear Embedding (LLE)"></a>Locally Linear Embedding (LLE)</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>æ€æƒ³ï¼šå‡è®¾æ¯ä¸ªç‚¹å¯ä»¥ç”±å…¶å‘¨å›´çš„ç‚¹æ¥è¡¨ç¤º<br><img src="/images/2018-10-07-15388822769215.jpg" width="25%" height="50%"></p><p>æˆ‘ä»¬éœ€è¦æ‰¾åˆ°è¿™æ ·çš„$w_{ij}$ï¼Œä½¿å¾—ï¼š</p><script type="math/tex; mode=display">âˆ‘_iâ€–x^iâˆ’âˆ‘_j w_{ij} x^j â€–_2</script><p>è¿™æ ·åœ¨é™ç»´çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä»ç„¶ä¿æŒxä¹‹é—´çš„è¿™æ ·çš„å…³ç³»:<br><img src="/images/2018-10-07-15388823792351.jpg" width="50%" height="50%"></p><h3 id="Laplacian-Eigenmaps"><a href="#Laplacian-Eigenmaps" class="headerlink" title="Laplacian Eigenmaps"></a>Laplacian Eigenmaps</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>åŸºæœ¬æ€æƒ³ï¼šå¦‚æœ$x^1$ä¸$x^2$åœ¨é«˜ç»´ç©ºé—´ä¸­ç›¸è¿‘ï¼Œåˆ™é™ç»´åä¹Ÿåº”è¯¥æ¥è¿‘ï¼š</p><script type="math/tex; mode=display">S=1/2 âˆ‘_{i,j} w_{i,j} (z^iâˆ’z^j )^2</script><p>å…¶ä¸­ï¼š<br><img src="/images/2018-10-07-15388824984809.jpg" width="30%" height="50%"></p><p>å¦‚æœå°†zå…¨è®¾ä¸º0ï¼Œæ˜¾ç„¶Sæœ€å°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ç»™zä¸€ä¸ªé™åˆ¶ï¼šzåº”å½“å……æ»¡ç©ºé—´ï¼Œä¹Ÿå³å‡å¦‚zæ˜¯Mç»´ï¼Œé‚£ä¹ˆ$\{z^1,z^2â€¦,z^N\}$çš„ç§©åº”è¯¥ç­‰äºM</p><h3 id="T-distributed-Stochastic-Neighbor-Embedding-t-SNE"><a href="#T-distributed-Stochastic-Neighbor-Embedding-t-SNE" class="headerlink" title="T-distributed Stochastic Neighbor Embedding (t-SNE)"></a>T-distributed Stochastic Neighbor Embedding (t-SNE)</h3><p>ä¹Ÿæ˜¯ä¸€ç§é™ç»´æ–¹æ³•<br>å‰é¢æåˆ°çš„æ–¹æ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼šåŒä¸€ç±»çš„ç‚¹ç¡®å®èšåœ¨ä¸€èµ·ï¼Œä½†ä¸åŒç±»çš„ç‚¹å¹¶æ²¡æœ‰å°½é‡åˆ†å¼€<br><img src="/images/2018-10-07-15388826477983.jpg" width="50%" height="50%"></p><p>t-SNEçš„ä¸»è¦æ€æƒ³ï¼šå°†æ•°æ®ç‚¹æ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¸Œæœ›é™ç»´å‰å’Œé™ç»´åï¼Œæ•°æ®åˆ†å¸ƒçš„æ¦‚ç‡åº”å½“å°½å¯èƒ½ä¸€è‡´ã€‚<br>t-SNEæ„å»ºä¸€ä¸ªé«˜ç»´å¯¹è±¡ä¹‹é—´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—ç›¸ä¼¼çš„å¯¹è±¡æœ‰æ›´é«˜çš„æ¦‚ç‡è¢«é€‰æ‹©ï¼Œè€Œä¸ç›¸ä¼¼çš„å¯¹è±¡æœ‰è¾ƒä½çš„æ¦‚ç‡è¢«é€‰æ‹©ã€‚t-SNEåœ¨ä½ç»´ç©ºé—´é‡Œåœ¨æ„å»ºè¿™äº›ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—è¿™ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´å°½å¯èƒ½çš„ç›¸ä¼¼ã€‚</p><p>å¦‚ä½•åšï¼Ÿ<br>åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰ï¼š</p><script type="math/tex; mode=display">P(x^j |x^i )=\frac{S(x^i,x^j )}{âˆ‘_{kâ‰ i}S(x^i,x^k )}</script><p>å…¶ä¸­Sè¡¨ç¤ºiä¸jä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</p><p>åœ¨ä½ç»´ç©ºé—´ä¸­ï¼ŒåŒæ ·æœ‰ï¼š</p><script type="math/tex; mode=display">Q(z^j |z^i )=\frac{Sâ€²(z^i,z^j )}{âˆ‘_{kâ‰ i}Sâ€²(z^i,z^k )}</script><p>ä½¿ç”¨KLæ•£åº¦å»è®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼š</p><script type="math/tex; mode=display">L=âˆ‘_i KL(P(âˆ—|x^i )||Q(âˆ—|z^i )) =âˆ‘_iâˆ‘_j P(x^j |x^i )\frac{log P(x^j |x^i )}{Q(z^j |z^i )}</script><p>t-SNEä¸­ï¼Œé«˜ç»´ç©ºé—´å’Œä½ç»´ç©ºé—´è®¡ç®—ç›¸ä¼¼åº¦çš„å…¬å¼ä¸å¤§ä¸€æ ·ï¼š</p><script type="math/tex; mode=display">S(x^i,x^j )=exp(âˆ’â€–x^iâˆ’x^j â€–_2 )</script><script type="math/tex; mode=display">Sâ€²(z^i,z^j )=\frac{1}{(1+â€–z^iâˆ’z^j â€–_2)}</script><p>ä¸¤ä¸ªå…¬å¼çš„å›¾ç¤ºï¼š<br><img src="/images/2018-10-07-15388830652023.jpg" width="70%" height="50%"></p><p>ä¹Ÿå³<strong>ä½ç»´ç©ºé—´ä¼šæ‹‰é•¿è·ç¦»ï¼Œä½¿å¾—è·ç¦»è¿œçš„ç‚¹å°½å¯èƒ½è¢«æ‹‰å¼€</strong>ã€‚</p><p>t-SNEçš„é—®é¢˜åœ¨äºï¼št-SNEæ— æ³•å¯¹æ–°çš„æ•°æ®ç‚¹è¿›è¡Œé™ç»´ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Neighbor Embedding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 11:Unsupervised Learning:Linear Dimension Reduction</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2011:%20Unsupervised%20Learning:%20Linear%20Dimension%20Reduction/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2011:%20Unsupervised%20Learning:%20Linear%20Dimension%20Reduction/</url>
      
        <content type="html"><![CDATA[<h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>ç®—æ³•æ­¥éª¤ï¼š<br><img src="/images/2018-10-07-15388800377875.jpg" width="70%" height="50%"></p><p>è¿­ä»£æ›´æ–°ä½¿å¾—æœ€åèšç±»ä¸­å¿ƒæ”¶æ•›ã€‚ä½†äº‹å…ˆéœ€è¦å®šå¥½æœ‰å¤šå°‘ç±»ã€‚</p><h3 id="Hierarchical-Agglomerative-Clustering-HAC"><a href="#Hierarchical-Agglomerative-Clustering-HAC" class="headerlink" title="Hierarchical Agglomerative Clustering (HAC)"></a>Hierarchical Agglomerative Clustering (HAC)</h3><p>è‡ªä¸‹è€Œä¸Šï¼Œæ¯æ¬¡é€‰ä¸¤ä¸ªæœ€è¿‘çš„èšä¸ºä¸€ç±»ï¼Œç›´åˆ°æ‰€æœ‰çš„éƒ½åˆ†æˆä¸€ç±»<br>æœ€åé€‰æ‹©ä¸€ä¸ªé˜ˆå€¼åˆ’åˆ†ï¼Œå¦‚è“è‰²ç»¿è‰²å’Œçº¢è‰²çš„çº¿<br><img src="/images/2018-10-07-15388801021791.jpg" width="50%" height="50%"></p><h2 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h2><p>æ‰¾åˆ°ä¸€ä¸ªæ˜ å°„ï¼Œä½¿å¾—xèƒ½å¤Ÿæ˜ å°„åˆ°ä½ç»´z</p><h3 id="Principle-Component-Analysis-PCA"><a href="#Principle-Component-Analysis-PCA" class="headerlink" title="Principle Component Analysis (PCA)"></a>Principle Component Analysis (PCA)</h3><p>ç›®çš„æ˜¯æ‰¾åˆ°ä¸€ä¸ªç»´åº¦ï¼Œä½¿å¾—æŠ•å½±å¾—åˆ°çš„varianceæœ€å¤§ï¼Œä¹Ÿå³æœ€å¤§ç¨‹åº¦ä¿ç•™æ•°æ®çš„å·®å¼‚æ€§ã€‚<br><img src="/images/2018-10-07-15388801830659.jpg" width="50%" height="50%"></p><p>å½¢å¼åŒ–å¯ä»¥å†™æˆï¼ˆä¸€ç»´æƒ…å½¢ï¼‰ï¼š</p><script type="math/tex; mode=display">Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2</script><p>å…¶ä¸­ï¼š</p><script type="math/tex; mode=display">â€–w^1 â€–_2=1</script><script type="math/tex; mode=display">z_1=w^1 \cdot x</script><p>$\overline{z_1}$è¡¨ç¤ºzçš„å‡å€¼</p><p>å‡å¦‚æˆ‘ä»¬è¦æŠ•å½±åˆ°å¤šç»´ï¼Œå…¶ä»–ç»´åº¦ä¹Ÿæœ‰åŒæ ·çš„ç›®æ ‡ã€‚å…¶ä¸­æ¯ä¸ªç»´åº¦ä¹‹é—´éƒ½åº”è¯¥æ˜¯ç›¸äº’æ­£äº¤çš„ã€‚<br><img src="/images/2018-10-07-15388804752506.jpg" width="20%" height="50%"></p><h4 id="å¦‚ä½•åšï¼Ÿ"><a href="#å¦‚ä½•åšï¼Ÿ" class="headerlink" title="å¦‚ä½•åšï¼Ÿ"></a>å¦‚ä½•åšï¼Ÿ</h4><p>æ‰¾åˆ°$ \frac{1}{N}âˆ‘(xâˆ’\overline{x} ) (xâˆ’\overline{x})^T$çš„å‰kä¸ªæœ€å¤§çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ï¼Œç»„åˆèµ·æ¥å³æ˜¯æˆ‘ä»¬è¦æ‰¾çš„$W$</p><h4 id="è¯æ˜"><a href="#è¯æ˜" class="headerlink" title="è¯æ˜"></a>è¯æ˜</h4><p>â€”-Warning of Mathâ€”-<br>ç›®çš„ï¼š$Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2 $<br>å…¶ä¸­ $\overline{z_1} =\frac{1}{N} âˆ‘{z_1} = \frac{1}{N} âˆ‘ w^1 \cdot x=w^1\cdot \overline{x}$</p><p>æ¨å¯¼ï¼š<br><img src="/images/2018-10-07-15388811276042.jpg" width="35%" height="50%"><br>æ”¹å˜ç¬¦å· $S=Cov(x)$</p><p>åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œæœ‰ï¼š<br>$Sw^1=Î±w^1$<br>ç­‰å¼ä¸¤è¾¹å„å·¦ä¹˜$(w^1)^T$ï¼Œæœ‰ï¼š<br>$(w^1 )^T Sw^1=Î±(w^1 )^T w^1=Î±$</p><p>ä¹Ÿå³ï¼Œ$Î±$æ˜¯$S$çš„ç‰¹å¾å€¼ï¼Œé€‰æ‹©æœ€å¤§çš„ç‰¹å¾å€¼ï¼Œå°±èƒ½å¤Ÿæœ€å¤§åŒ–æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p><p>åŒç†ï¼Œæˆ‘ä»¬è¦æ‰¾$w^2$ï¼Œæœ€å¤§åŒ–$(w^2 )^T Sw^2$ï¼Œå…¶ä¸­æœ‰ï¼š<br>$(w^2 )^T w^2=1$<br>$(w^2 )^T w^1=0$ ï¼ˆä¸ç¬¬ä¸€ç»´æ­£äº¤ï¼‰</p><p>å› æ­¤åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼š</p><script type="math/tex; mode=display">g(w^2 )= (w^2 )^T Sw^2âˆ’Î±((w^2 )^T w^2âˆ’1)âˆ’Î²((w^2 )^T w^1âˆ’0)</script><p>æœ€ç»ˆå¾—åˆ°ï¼Œw2å¯¹åº”ç¬¬äºŒå¤§çš„ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ã€‚</p><p>ä»¥æ­¤ç±»æ¨ï¼Œå…¶ä»–ç»´ä¹ŸåŒç†ã€‚<br>â€”-End of Mathâ€”-</p><h4 id="PCAçš„å…¶ä»–"><a href="#PCAçš„å…¶ä»–" class="headerlink" title="PCAçš„å…¶ä»–"></a>PCAçš„å…¶ä»–</h4><p>å®é™…ä¸Šæœ€ç»ˆå¾—åˆ°çš„zï¼Œæ¯ä¸€ç»´ä¹‹é—´çš„åæ–¹å·®éƒ½ä¸º0<br><img src="/images/2018-10-07-15388815546680.jpg" width="50%" height="50%"></p><p>è¯æ˜å¦‚ä¸‹ï¼š<br><img src="/images/2018-10-07-15388815837458.jpg" width="50%" height="50%"></p><p>PCAä¹Ÿå¯ä»¥ç”¨SVDæ¥åšï¼š<br><img src="/images/2018-10-07-15388816250075.jpg" width="60%" height="50%"></p><p>Uä¸­ä¿å­˜äº†Kä¸ªç‰¹å¾å‘é‡ã€‚</p><p>ä»å¦ä¸€ç§è§’åº¦ç†è§£PCAï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºPCAæ˜¯ä¸€ç§autoencoderï¼š<br><img src="/images/2018-10-07-15388816896369.jpg" width="50%" height="50%"></p><h4 id="PCAçš„é—®é¢˜"><a href="#PCAçš„é—®é¢˜" class="headerlink" title="PCAçš„é—®é¢˜"></a>PCAçš„é—®é¢˜</h4><p>PCAæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œå¦‚æœæœ‰æ ‡ç­¾ï¼Œåˆ™æ— æ³•æŒ‰ç…§ç±»åˆ«æ¥è¿›è¡Œæ­£ç¡®é™ç»´ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388817393283.jpg" width="30%" height="50%"></p><p>ç¬¬äºŒå°±æ˜¯PCAæ˜¯çº¿æ€§å˜æ¢ï¼Œå¯¹äºä¸€äº›éœ€è¦éçº¿æ€§å˜æ¢çš„æ— èƒ½ä¸ºåŠ›<br><img src="/images/2018-10-07-15388817566149.jpg" width="28%" height="50%"></p><h3 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h3><p>å®šä¹‰ï¼šçŸ©é˜µåˆ†è§£ï¼Œå°±æ˜¯å°†ä¸€ä¸ªçŸ©é˜µDåˆ†è§£ä¸ºUå’ŒVçš„ä¹˜ç§¯ï¼Œå³å¯¹äºä¸€ä¸ªç‰¹å®šçš„è§„æ¨¡ä¸ºm*nçš„çŸ©é˜µDï¼Œä¼°è®¡å‡ºè§„æ¨¡åˆ†åˆ«ä¸ºm*kå’Œn*kçš„çŸ©é˜µUå’ŒVï¼Œä½¿å¾—$UV^T$çš„å€¼å°½å¯èƒ½é€¼è¿‘çŸ©é˜µDã€‚å¸¸ç”¨äºæ¨èç³»ç»Ÿã€‚</p><p>æ€æƒ³ï¼š<br>å‡å¦‚æœ‰ä¸€ä¸ªçŸ©é˜µï¼š<br><img src="/images/2018-10-07-15388819053983.jpg" width="60%" height="50%"></p><p>å‡è®¾æ¨ªè½´å’Œçºµè½´æ¯ä¸€ç»´éƒ½æœ‰ä¸€ä¸ªå‘é‡ä»£è¡¨è¯¥ç»´ï¼ŒçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å°±æ˜¯æ¨ªè½´å’Œçºµè½´å¯¹åº”ç»´çš„ç‚¹ç§¯ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯å°½å¯èƒ½å‡å°ï¼š</p><script type="math/tex; mode=display">L=\sum_{(i,j)} (r^i \cdot r^j -n_{ij})^2</script><p>å…¶ä¸­$r_i$ $r_j$å°±æ˜¯å‘é‡è¡¨ç¤ºï¼Œ$n_{ij}$å°±æ˜¯çŸ©é˜µçš„å†…å®¹ã€‚</p><p>å¯ä»¥ä½¿ç”¨SVDæ±‚è§£ä¸Šå¼ï¼š<br><img src="/images/2018-10-07-15388820642382.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šï¼Œè€ƒè™‘æ¯ä¸€è¡Œæˆ–åˆ—æœ¬èº«çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬å¯¹Lossè¿›è¡Œæ‰©å±•ï¼š</p><script type="math/tex; mode=display">Minimizing \ \ L=\sum_{(i,j)} (r^i \cdot r^j +b_i+b_j-n_{ij})^2</script><p>ä½¿ç”¨SGDå¯ä»¥æ±‚è§£ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Linear Dimension Reduction </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸çš„æ¨å¯¼</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%8E%A8%E5%AF%BC/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p> è®°RNNä¸­æ¯ä¸€æ­¥çš„æŸå¤±ä¸º$E_t$ï¼Œåˆ™æŸå¤±å¯¹$h_{t-1}$çš„æƒé‡$W$çš„å¯¼æ•°æœ‰ï¼š</p><script type="math/tex; mode=display">\frac{\partial{E_t}}{\partial{W}}=\sum_{k=1}^{t}    \frac{\partial{E_t}}{\partial{y_t}} \frac{\partial{y_t}}{\partial{h_t}} \frac{\partial{h_t}}{\partial{h_k}} \frac{\partial{h_k}}{\partial{W}}</script><p>å…¶ä¸­$\frac{\partial{h_t}}{\partial{h_k}}$ä½¿ç”¨é“¾å¼æ³•åˆ™æœ‰ï¼š</p><script type="math/tex; mode=display">\frac{\partial{h_t}}{\partial{h_k}} =     \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} =    \prod_{j=k+1}^{t} W^T \times diag[f^{\prime}(h_{j-1})]</script><p>å…¶ä¸­$\frac{\partial{h_j}}{\partial{h_{j-1}}}$ æ˜¯é›…å…‹æ¯”çŸ©é˜µã€‚å¯¹å…¶å–æ¨¡(norm)ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">\rVert \frac{\partial{h_j}}{\partial{h_{j-1}}}\rVert â‰¤ \rVert W^T \rVert \rVert diag[f^{\prime}(h_{j-1})] \rVert â‰¤ \beta_W \beta_h</script><p>å½“$f$ä¸ºsigmoidæ—¶ï¼Œ$f^{\prime}(h_{j-1})$æœ€å¤§å€¼ä¸º1ã€‚</p><p>æœ€ç»ˆæˆ‘ä»¬æœ‰ï¼š</p><script type="math/tex; mode=display">\rVert \frac{\partial{h_t}}{\partial{h_{k}}}\rVert â‰¤ \rVert \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} \rVert â‰¤ (\beta_W \beta_h)^{t-k}</script><p>ä»ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“t-kè¶³å¤Ÿå¤§æ—¶ï¼Œå¦‚æœ$(\beta_W \beta_h)$å°äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å°ï¼Œç›¸åï¼Œè‹¥$(\beta_W \beta_h)$å¤§äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å¤§ã€‚</p><p>åœ¨è®¡ç®—æœºä¸­ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå¤§æ—¶ï¼Œä¼šé€ æˆä¸Šæº¢(NaN)ï¼Œä¹Ÿå³æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå°æ—¶ï¼Œä¼šå˜æˆ0ï¼Œä¹Ÿå³æ¢¯åº¦æ¶ˆå¤±ã€‚æ³¨æ„åˆ°ï¼Œt-kçš„æŸå¤±å®é™…ä¸Šè¯„ä¼°çš„æ˜¯ä¸€ä¸ªè¾ƒè¿œçš„è¯å¯¹å½“å‰tçš„è´¡çŒ®ï¼Œæ¢¯åº¦æ¶ˆå¤±ä¹Ÿå³æ„å‘³ç€å¯¹å½“å‰çš„è´¡çŒ®æ¶ˆå¤±ã€‚</p><p>Reference:<br>CS224d: Deep Learning for NLP Lecture4</p>]]></content>
      
      
      
        <tags>
            
            <tag> æ¢¯åº¦æ¶ˆå¤± </tag>
            
            <tag> æ¢¯åº¦çˆ†ç‚¸ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†10</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8610/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8610/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ"><a href="#1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ" class="headerlink" title="1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]"></a>1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]</h3><p>é«˜ç»´æ­£æ€åˆ†å¸ƒæ˜¯ä»ä¸€ç»´å‘å±•è€Œæ¥çš„ï¼š<br><img src="/images/2018-10-07-15388761009977.jpg" width="70%" height="50%"></p><p><a href="https://www.zhihu.com/question/36339816" target="_blank" rel="noopener">https://www.zhihu.com/question/36339816</a></p><hr><h3 id="2ï¸âƒ£-RNN"><a href="#2ï¸âƒ£-RNN" class="headerlink" title="2ï¸âƒ£[RNN]"></a>2ï¸âƒ£[RNN]</h3><p>from <a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf</a></p><p>é€šå¸¸è€Œè¨€ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†RNNçš„initial stateè®¾ä¸ºå…¨0ï¼Œä½†åœ¨Hintonçš„slideä¸­æåˆ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆå§‹çŠ¶æ€ä½œä¸ºå¯å­¦ä¹ çš„å˜é‡ï¼Œå’Œæˆ‘ä»¬åœ¨å­¦ä¹ æƒé‡çŸ©é˜µä¸€æ ·ã€‚</p><p><img src="/images/2018-10-07-15388770544817.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æ­£æ€åˆ†å¸ƒ </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬äºŒç«  æ¦‚ç‡åˆ†å¸ƒ</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="äºŒå…ƒå˜é‡"><a href="#äºŒå…ƒå˜é‡" class="headerlink" title="äºŒå…ƒå˜é‡"></a>äºŒå…ƒå˜é‡</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-25-21.jpg" alt="äºŒå…ƒå˜é‡1"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-26-46.jpg" alt="è´å¡”åˆ†å¸ƒ"></p><h1 id="å¤šé¡¹å¼åˆ†å¸ƒ"><a href="#å¤šé¡¹å¼åˆ†å¸ƒ" class="headerlink" title="å¤šé¡¹å¼åˆ†å¸ƒ"></a>å¤šé¡¹å¼åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-31-55.jpg" alt="å¤šé¡¹å¼åˆ†å¸ƒ"></p><h1 id="é«˜æ–¯åˆ†å¸ƒ"><a href="#é«˜æ–¯åˆ†å¸ƒ" class="headerlink" title="é«˜æ–¯åˆ†å¸ƒ"></a>é«˜æ–¯åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-40-32.jpg" alt="é«˜æ–¯åˆ†å¸ƒ"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-43-09.jpg" alt="2"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-45-15.jpg" alt="3"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-48-58.jpg" alt="4"></p><h1 id="æŒ‡æ•°æ—åˆ†å¸ƒ"><a href="#æŒ‡æ•°æ—åˆ†å¸ƒ" class="headerlink" title="æŒ‡æ•°æ—åˆ†å¸ƒ"></a>æŒ‡æ•°æ—åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-51-25.jpg" alt="1"></p><p><img src="/images/2018-10-03-Xnip2018-10-03_10-03-54.jpg" alt="2"></p><h1 id="éå‚æ•°ä¼˜åŒ–"><a href="#éå‚æ•°ä¼˜åŒ–" class="headerlink" title="éå‚æ•°ä¼˜åŒ–"></a>éå‚æ•°ä¼˜åŒ–</h1><p><img src="/images/2018-10-03-Xnip2018-10-03_10-05-24.jpg" alt="1"></p><p><img src="/images/2018-10-03-Xnip2018-10-03_10-06-55.jpg" alt="2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 10:Semi-supervised learning</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2010:%20Semi-supervised/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2010:%20Semi-supervised/</url>
      
        <content type="html"><![CDATA[<p>ä»€ä¹ˆæ˜¯semi-supervised learning</p><p>ç»™å®šæ•°æ®${(x^r,\hat{y}^r)}_{r=1}^{R},{(x_u)}_{u=R}^{R+U}$ï¼Œå…¶ä¸­æœªæ ‡è®°æ•°æ®è¿œè¿œå¤šäºæ ‡è®°æ•°æ® $U&gt;&gt;R$</p><p>ä¸ºä»€ä¹ˆåŠç›‘ç£å­¦ä¹ æœ‰ç”¨ï¼Ÿ<br>å› ä¸ºæœªæ ‡è®°æ•°æ®çš„åˆ†å¸ƒå¯èƒ½èƒ½å¤Ÿç»™æˆ‘ä»¬ä¸€äº›ä¿¡æ¯ã€‚</p><h3 id="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "><a href="#ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ " class="headerlink" title="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "></a>ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ </h3><p>ç»™å®šä¸¤ç±»$C_1$ã€$C_2$ï¼Œè¦æ±‚å¾—åˆ°åéªŒæ¦‚ç‡åˆ†å¸ƒ</p><script type="math/tex; mode=display">P(C_1 |x)=\frac{P(x|C_1 )P(C_1 )}{(P(x|C_1 )P(C_1 )+P(x|C_2 )P(C_2 ) )}</script><p>å…¶ä¸­è”åˆæ¦‚ç‡åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒã€‚æœªæ ‡è®°æ•°æ®æ­¤æ—¶çš„ä½œç”¨å³å¸®æˆ‘ä»¬é‡æ–°ä¼°è®¡$P(C_1),P(C_2),\mu,\Sigma$</p><p><img src="/images/2018-09-30-15382829251218.jpg" width="50%" height="50%"></p><p>å¦‚ä½•åš?<br>å…ˆåˆå§‹åŒ–$P(C_1),P(C_2),\mu,\Sigma$ï¼Œé€šå¸¸å¯ä»¥å…ˆç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œä¼°è®¡</p><ol><li>è®¡ç®—æ¯ä¸ªæœªæ ‡è®°æ•°æ®çš„åéªŒæ¦‚ç‡åˆ†å¸ƒ</li><li>ä»¥è¯¥æ¦‚ç‡åˆ†å¸ƒæ›´æ–°æ¨¡å‹<br>ä¸æ–­é‡å¤ç›´è‡³æ‹Ÿåˆ</li></ol><p><img src="/images/2018-09-30-15382829987091.jpg" width="70%" height="50%"></p><p>åŸå› ï¼š<br>å½“æˆ‘ä»¬åœ¨åšç›‘ç£å­¦ä¹ æ—¶ï¼Œä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ±‚è§£ï¼š</p><script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{x^r,\hat{y}^r} logP_Î¸ (x^r |\hat{y}^r )</script><p>åŠ ä¸Šäº†æœªæ ‡è®°æ•°æ®åï¼ŒåŒæ ·ä¹Ÿè¦åšæœ€å¤§ä¼¼ç„¶ï¼š</p><script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{(x^r,\hat{y}^r)} logP_Î¸ (x^r |\hat{y}^r )+âˆ‘_{x^u} logP_Î¸ (x^u)</script><h3 id="Low-density-Separation"><a href="#Low-density-Separation" class="headerlink" title="Low-density Separation"></a>Low-density Separation</h3><p>å‡è®¾ä¸åŒç±»åˆ«ä¹‹é—´æœ‰ä¸€æ¡æ˜æ˜¾çš„åˆ†ç•Œçº¿ï¼Œä¹Ÿå³å­˜åœ¨ä¸€ä¸ªåŒºåŸŸï¼Œå…¶å¯†åº¦æ¯”å…¶ä»–åŒºåŸŸå°</p><h4 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h4><p>å¦‚ä½•åš?</p><ol><li>å…ˆç”¨æœ‰æ ‡ç­¾æ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹$f$ï¼›</li><li>åˆ©ç”¨æ¨¡å‹å¯¹æœªæ ‡è®°æ•°æ®è¿›è¡Œæ ‡è®°ï¼Œè¿™äº›æ ‡ç­¾ç§°ä¸ºä¼ªæ ‡ç­¾ï¼ˆpseudo-labelï¼‰</li><li>å°†éƒ¨åˆ†æœ‰ä¼ªæ ‡ç­¾çš„æ•°æ®æ”¾å…¥æœ‰æ ‡ç­¾æ•°æ®ä¸­ï¼Œé‡æ–°è®­ç»ƒ<br>é‡å¤ç›´åˆ°æ‹Ÿåˆ</li></ol><p>è¿™ç§æ–¹å¼å’Œç”Ÿæˆæ¨¡å‹çš„åŒºåˆ«ï¼šè¯¥æ–¹æ³•ä½¿ç”¨çš„æ˜¯hard labelè€Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨çš„æ˜¯soft label</p><h4 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h4><p>å°†æœªæ ‡è®°æ•°æ®å……å½“æ­£åˆ™åŒ–çš„æ•ˆæœï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹é¢„æµ‹æ ‡ç­¾çš„æ¦‚ç‡è¾ƒä¸ºé›†ä¸­ï¼Œä¹Ÿå³ç†µåº”è¯¥å°½å¯èƒ½å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœªæ ‡è®°æ•°æ®ä½¿å¾—åˆ†ç±»è¾¹ç•Œå°½å¯èƒ½åˆ’åœ¨ä½å¯†åº¦åŒºåŸŸã€‚<br><img src="/images/2018-09-30-15382837957204.jpg" width="30%" height="50%"></p><h3 id="Smoothness-Assumption"><a href="#Smoothness-Assumption" class="headerlink" title="Smoothness Assumption"></a>Smoothness Assumption</h3><p>å‡è®¾ï¼šä½äºç¨ å¯†æ•°æ®åŒºåŸŸçš„ä¸¤ä¸ªè·ç¦»å¾ˆè¿‘çš„æ ·ä¾‹çš„ç±»æ ‡ç­¾ç›¸ä¼¼ï¼Œé€šè¿‡high density pathè¿æ¥ã€‚</p><p><img src="/images/2018-09-30-15382840889274.jpg" width="40%" height="50%"><br>x1ä¸x2ä¹‹é—´è¾ƒä¸ºç¨ å¯†ï¼Œå› æ­¤x2ä¸x1æ¯”x2ä¸x3æ›´ä¸ºæ¥è¿‘ã€‚</p><p><strong>å¦‚ä½•çŸ¥é“x1ä¸x2é€šè¿‡high density pathè¿æ¥ï¼Ÿ</strong><br><img src="/images/2018-09-30-15382841851160.jpg" width="50%" height="50%"></p><p>åŸºäºå›¾çš„æ–¹æ³•ï¼š</p><ol><li>å®šä¹‰xiä¸xjä¹‹é—´çš„ç›¸ä¼¼åº¦$s(x^i,x^j)$</li><li>æ·»åŠ è¾¹ï¼Œæœ‰ä¸¤ç§é€‰æ‹©<ol><li>k nearest neighbor</li><li>e-neighborhood<br><img src="/images/2018-09-30-15382842669412.jpg" width="50%" height="50%"></li></ol></li><li>è¾¹ä¹‹é—´çš„æƒé‡é€šè¿‡ç›¸ä¼¼åº¦æ¥è¡¡é‡ã€‚å¦‚ï¼š $s(x^i,x^j )=exp(âˆ’Î³â€–x^iâˆ’x^jâ€–^2)$</li></ol><p>è¯¥æ–¹æ³•æœ¬è´¨å³åˆ©ç”¨æœ‰æ ‡ç­¾æ•°æ®å»å½±å“æœªæ ‡è®°æ•°æ®ï¼Œé€šè¿‡å›¾çš„ä¼ æ’­ã€‚ä½†ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚æœæ•°æ®ä¸å¤Ÿå¤šï¼Œå°±å¯èƒ½æ²¡åŠæ³•ä¼ æ’­ã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382844101208.jpg" width="30%" height="50%"></p><p>åœ¨å»ºç«‹å¥½å›¾åï¼Œå¦‚ä½•ä½¿ç”¨?</p><ul><li>å®šä¹‰å›¾çš„å¹³æ»‘ç¨‹åº¦ï¼Œ$y$è¡¨ç¤ºæ ‡ç­¾ã€‚$S$è¶Šå°è¡¨ç¤ºè¶Šå¹³æ»‘ã€‚<script type="math/tex; mode=display">S=1/2âˆ‘_{i,j} w_{i,j} (y^iâˆ’y^j )^2=y^T Ly</script><script type="math/tex; mode=display">y=[â‹¯y^iâ‹¯y^jâ‹¯]^T</script><script type="math/tex; mode=display">L=Dâˆ’W</script></li></ul><p>Dæ˜¯é‚»æ¥çŸ©é˜µï¼Œç¬¬ijä¸ªå…ƒç´ å³xiä¸xjä¹‹é—´çš„weightï¼ŒWæ˜¯å¯¹è§’çŸ©é˜µï¼Œiiä¸ªå…ƒç´ æ˜¯Dçš„ç¬¬iè¡Œçš„åŠ å’Œï¼›Lç§°ä¸ºGraph Laplacian<br><img src="/images/2018-09-30-15382847006975.jpg" width="50%" height="50%"></p><ul><li>æˆ‘ä»¬æœ€ç»ˆåœ¨è®¡ç®—Lossçš„æ—¶å€™è¦åŠ ä¸Šè¿™é¡¹æ­£åˆ™é¡¹<script type="math/tex; mode=display">L=âˆ‘_{x^r}C(y^r,\hat{y}^r ) +Î»S</script></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> Semi-supervised learning </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 7:Tips for DL</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%207:%20Tips%20for%20DL/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%207:%20Tips%20for%20DL/</url>
      
        <content type="html"><![CDATA[<p>å¤§çº²<br><img src="/images/2018-09-30-15382757690955.jpg" width="50%" height="50%"></p><h2 id="new-activation-function"><a href="#new-activation-function" class="headerlink" title="new activation function"></a>new activation function</h2><p>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šç”±äºsigmoidä¼šå°†å€¼å‹ç¼©ï¼Œæ‰€ä»¥åœ¨åå‘ä¼ æ’­æ—¶ï¼Œè¶Šåˆ°åé¢å€¼è¶Šå°ã€‚</p><p><img src="/images/2018-09-30-15382758841507.jpg" width="30%" height="50%"><br>æ‰€ä»¥åå±‚çš„æ›´æ–°ä¼šæ¯”å‰å±‚çš„æ›´æ–°æ›´å¿«ï¼Œå¯¼è‡´å‰å±‚è¿˜æ²¡convergeï¼Œåå±‚å°±æ ¹æ®å‰å±‚çš„æ•°æ®ï¼ˆrandomï¼‰è¾¾åˆ°convergeäº†</p><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p><img src="/images/2018-09-30-15382759503401.jpg" width="30%" height="50%"><br>èƒ½å¤Ÿå¿«é€Ÿè®¡ç®—ï¼Œä¸”èƒ½å¤Ÿè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</p><p>å› ä¸ºä¼šæœ‰éƒ¨åˆ†neuronçš„å€¼æ˜¯0ï¼Œæ‰€ä»¥ç›¸å½“äºæ¯æ¬¡è®­ç»ƒä¸€ä¸ªç˜¦é•¿çš„ç¥ç»ç½‘ç»œã€‚<br><img src="/images/2018-09-30-15382760030965.jpg" width="50%" height="50%"></p><h4 id="ReLUçš„å˜ä½“"><a href="#ReLUçš„å˜ä½“" class="headerlink" title="ReLUçš„å˜ä½“"></a>ReLUçš„å˜ä½“</h4><p><img src="/images/2018-09-30-15382928024258.jpg" width="50%" height="50%"></p><h3 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h3><p>é¦–å…ˆå°†å‡ ä¸ªneuronå½’ä¸ºä¸€ç»„ï¼Œç„¶åæ¯æ¬¡å‰å‘ä¼ æ’­æ—¶å–æœ€å¤§çš„ä½œä¸ºè¾“å‡ºã€‚<br><img src="/images/2018-09-30-15382761367509.jpg" width="50%" height="50%"></p><p>å®é™…ä¸ŠReLUæ˜¯maxoutçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼š<br><img src="/images/2018-09-30-15382761741870.jpg" width="40%" height="50%"></p><p>æ›´ä¸€èˆ¬çš„ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-30-15382762237369.jpg" width="40%" height="50%"></p><p>å› ä¸ºwå’Œbçš„å˜åŒ–ï¼Œæ‰€ä»¥è¯¥activation functionå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªlearnable activation function</p><p>è¿™æ ·ä¸€ä¸ªlearnable activation functionæœ‰è¿™æ ·çš„ç‰¹ç‚¹ï¼š</p><blockquote><p>Activation function in maxout network can be any piecewise linear convex function<br>How many pieces depending on how many elements in a group</p></blockquote><p>å¦‚ï¼š<br><img src="/images/2018-09-30-15382763537888.jpg" width="60%" height="50%"></p><p>maxoutåº”å¦‚ä½•è®­ç»ƒï¼Ÿ</p><p><img src="/images/2018-09-30-15382764343880.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªæ™®é€šçš„ç˜¦é•¿networkï¼Œå¸¸è§„è®­ç»ƒå³å¯ã€‚<br><img src="/images/2018-09-30-15382764564859.jpg" width="50%" height="50%"></p><h2 id="Adaptive-learning-rate"><a href="#Adaptive-learning-rate" class="headerlink" title="Adaptive learning rate"></a>Adaptive learning rate</h2><p>åœ¨adagradä¸­:<br><img src="/images/2018-09-30-15382765516383.jpg" width="30%" height="50%"></p><p>è¶Šåˆ°åé¢learning rateè¶Šæ¥è¶Šå°ï¼Œä½†å®é™…ä¸Šåœ¨dlé‡Œé¢ï¼Œerror surfaceæ˜¯éå¸¸å¤æ‚çš„ï¼Œè¶Šæ¥è¶Šå°çš„learning rateå¯èƒ½ä¸é€‚ç”¨äºdlã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382765821828.jpg" width="50%" height="50%"></p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p><img src="/images/2018-09-30-15382766372355.jpg" width="60%" height="50%"><br>$Ïƒ^t$æ˜¯å†å²ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯è¯´$Ïƒ^t$å‚è€ƒäº†è¿‡å»çš„æ¢¯åº¦å’Œå½“å‰çš„æ¢¯åº¦è·å¾—ä¸€ä¸ªæ–°çš„æ”¾ç¼©å¤§å°</p><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>å¼•å…¥æƒ¯æ€§ä½œä¸ºå‚è€ƒï¼Œä¹Ÿå³å‚è€ƒäº†ä¸Šä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘ã€‚å¼•å…¥æƒ¯æ€§åï¼Œå¯èƒ½æœ‰æœºä¼šè¶Šè¿‡local minimumã€‚<br>æ™®é€šçš„gradient descent:<br><img src="/images/2018-09-30-15382769712428.jpg" width="40%" height="50%"><br>æ¯æ¬¡æœç€æ¢¯åº¦çš„åæ–¹å‘èµ°ã€‚</p><p>Momentum:<br><img src="/images/2018-09-30-15382770120104.jpg" width="40%" height="50%"></p><p>è€ƒè™‘äº†ä¸Šä¸€æ­¥èµ°çš„æ–¹å‘ã€‚</p><p>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382771516587.jpg" width="30%" height="50%"></p><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>ç»“åˆäº†RMSpropå’ŒMomentumï¼Œä¹Ÿå³ç»¼åˆè€ƒè™‘äº†å†å²ä¿¡æ¯å†³å®šå½“å‰æ­¥é•¿ï¼›è€ƒè™‘äº†ä¸Šä¸€æ­¥çš„æ–¹å‘å†³å®šå½“å‰èµ°çš„æ–¹å‘ã€‚<br>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382772986250.jpg" width="60%" height="50%"></p><h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h2><p>å°±æ˜¯åœ¨validation setçš„lossä¸å†å‡å°æ—¶åœæ­¢<br><img src="/images/2018-09-30-15382814784406.jpg" width="50%" height="50%"></p><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="L2æ­£åˆ™åŒ–"><a href="#L2æ­£åˆ™åŒ–" class="headerlink" title="L2æ­£åˆ™åŒ–"></a>L2æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382815175056.jpg" width="50%" height="50%"><br>å…¶ä¸­<br><img src="/images/2018-09-30-15382815336088.jpg" width="30%" height="50%"><br>å› æ­¤æ›´æ–°å…¬å¼ä¸ºï¼š<br>    <img src="/images/2018-09-30-15382815641437.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³æ¯æ¬¡ä»¥$1-\eta \lambda$å¯¹wè¿›è¡Œæ”¾ç¼©ï¼Œä½¿wæ›´æ¥è¿‘0<br>æ­£åˆ™åŒ–åœ¨DLä¸­ä¹Ÿç§°ä¸ºweight decay</p><h3 id="L1æ­£åˆ™åŒ–"><a href="#L1æ­£åˆ™åŒ–" class="headerlink" title="L1æ­£åˆ™åŒ–"></a>L1æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382816962676.jpg" width="25%" height="50%"></p><p><img src="/images/2018-09-30-15382817122102.jpg" width="25%" height="50%"><br><img src="/images/2018-09-30-15382817409633.jpg" width="25%" height="50%"></p><p>åˆ™æ›´æ–°å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-30-15382817897319.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³æ¯æ¬¡ä»¥$Î·Î»sgn(w)$ ä½¿wå¾€0é ï¼ˆsgnè¡¨ç¤ºç¬¦å·å‡½æ•°ï¼‰</p><p>å¯ä»¥çœ‹å‡ºï¼ŒL1æ¯æ¬¡éƒ½åŠ å‡ç›¸åŒçš„å€¼ï¼Œè€ŒL2æŒ‰æ¯”ä¾‹è¿›è¡Œç¼©æ”¾ã€‚å› æ­¤L1æ›´ä¸ºç¨€ç–(sparse)ã€‚</p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>è®­ç»ƒçš„æ—¶å€™æ¯ä¸€å±‚é‡‡æ ·p%çš„ç¥ç»å…ƒè®¾ä¸º0ï¼Œè®©å…¶ä¸å·¥ä½œ<br><img src="/images/2018-09-30-15382819376579.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯æ¯ä¸ªbatchæ”¹å˜äº†ç½‘ç»œç»“æ„ï¼Œä½¿å¾—ç½‘ç»œæ›´ç»†é•¿<br><img src="/images/2018-09-30-15382819772611.jpg" width="50%" height="50%"></p><p>æµ‹è¯•çš„æ—¶å€™æ‰€æœ‰çš„weightéƒ½ä¹˜ä»¥1-p%</p><p>ä»ensembleçš„è§’åº¦çœ‹å¾…dropoutï¼š<br>åœ¨è®­ç»ƒçš„æ—¶å€™è®­ç»ƒä¸€å †ä¸åŒç»“æ„çš„networkï¼Œæœ€å¤šæœ‰$2^N$ç§ç»„åˆï¼ŒNä¸ºneuronä¸ªæ•°ï¼Œå¯ä»¥ç§°ä¸ºç»ˆæçš„ensembleæ–¹æ³•äº†ã€‚è€Œåœ¨æµ‹è¯•çš„æ—¶å€™å¯¹è¿™äº›ä¸åŒçš„ç½‘ç»œè¿›è¡Œå¹³å‡ã€‚</p><p><img src="/images/2018-09-30-15382821089494.jpg" width="50%" height="50%"></p><p><img src="/images/2018-09-30-15382821379688.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Tips for DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>é‡‡æ ·æµ…æ</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E9%87%87%E6%A0%B7%E6%B5%85%E6%9E%90/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E9%87%87%E6%A0%B7%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>æ€»ç»“åœ¨NLPä¸­çš„é‡‡æ ·æ–¹æ³•ï¼ˆæŒç»­æ›´æ–°ï¼‰ã€‚</p><h2 id="é‡‡æ ·æ–¹æ³•"><a href="#é‡‡æ ·æ–¹æ³•" class="headerlink" title="é‡‡æ ·æ–¹æ³•"></a>é‡‡æ ·æ–¹æ³•</h2><h3 id="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling"><a href="#1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling" class="headerlink" title="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)"></a>1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥ä»»æ„æ¦‚ç‡åˆ†å¸ƒçš„<strong>ç´¯ç§¯åˆ†å¸ƒå‡½æ•°</strong>æ—¶ï¼Œç”¨äºä»è¯¥åˆ†å¸ƒä¸­ç”Ÿæˆéšæœºæ ·æœ¬ã€‚</p><p>â€”-ä»€ä¹ˆæ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°(CDF)â€”-<br>æ˜¯æ¦‚ç‡å¯†åº¦å‡½æ•°(PDF)çš„ç§¯åˆ†ï¼Œå®šä¹‰ï¼š</p><script type="math/tex; mode=display">F_X(x)=P(Xâ‰¤x)=\int_{-âˆ}^{x}f_X(t)dt</script><p>â€”-ENDâ€”-</p><p>æƒ³è±¡æˆ‘ä»¬çŸ¥é“é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•é‡‡æ ·ï¼Ÿæœ¬è´¨ä¸Šæˆ‘ä»¬åªèƒ½å¯¹å‡åŒ€åˆ†å¸ƒè¿›è¡Œç›´æ¥é‡‡æ ·ï¼ˆé«˜æ–¯åˆ†å¸ƒæœ‰<a href="https://www.zhihu.com/question/29971598" target="_blank" rel="noopener">ç®—æ³•</a>å¯ä»¥ç”Ÿæˆé‡‡æ ·ï¼Œä½†æ— æ³•ä¸€èˆ¬åŒ–ï¼‰ã€‚å¯¹äºè¿™ç§è¿ç»­çš„éšæœºå˜é‡ï¼Œæˆ‘ä»¬åªèƒ½é€šè¿‡é—´æ¥çš„æ–¹æ³•è¿›è¡Œé‡‡æ ·ã€‚</p><p>é€†å˜æ¢é‡‡æ ·å³æ˜¯é€šè¿‡ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„åå‡½æ•°æ¥é‡‡æ ·ã€‚å› ä¸ºç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„å€¼åŸŸä¸º$[0,1]$ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡åœ¨$[0,1]$ä¸Šè¿›è¡Œé‡‡æ ·ï¼Œå†æ˜ å°„åˆ°åŸåˆ†å¸ƒã€‚<br>ä¾‹å­:<br><img src="/images/2018-09-30-15382714567064.jpg" width="80%" height="50%"><br>æ˜ å°„å…³ç³»å¦‚å›¾ï¼š<br><img src="/images/2018-09-30-15382715821631.jpg" width="50%" height="50%"></p><h3 id="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling"><a href="#2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling" class="headerlink" title="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)"></a>2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥æŸä¸ªåˆ†å¸ƒ$P$ï¼Œå¸Œæœ›èƒ½ä¼°è®¡$f(x)$çš„æœŸæœ›ã€‚äº¦å³ï¼š</p><script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)</script><p>å…¶ä¸­$x\sim p$ã€‚<br>å‡è®¾$p(x)$çš„åˆ†å¸ƒå¤æ‚æˆ–æ ·æœ¬ä¸å¥½ç”Ÿæˆï¼Œå¦ä¸€åˆ†å¸ƒ$q(x)$æ–¹ä¾¿ç”Ÿæˆæ ·æœ¬ã€‚å› æ­¤æˆ‘ä»¬å¼•å…¥$q(x)$å¯¹åŸå…ˆåˆ†å¸ƒè¿›è¡Œä¼°è®¡ã€‚</p><script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dx=\int_{x}f(x)\frac{p(x)}{q(x)}q(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)\frac{p(x_i)}{q(x_i)}</script><p>å…¶ä¸­ï¼Œ$x \sim q$ã€‚$w(x)=\frac{p(x)}{q(x)}$ç§°ä¸ºImportance Weight</p><p>æ ¹æ®ä¸Šå¼ï¼Œå®é™…ä¸Šå°±æ˜¯æ¯æ¬¡é‡‡æ ·çš„åŠ æƒæ±‚å’Œã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>é€†å˜æ¢é‡‡æ ·<br><a href="https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7</a></p><p>é‡è¦æ€§é‡‡æ ·<br><a href="https://www.youtube.com/watch?v=S3LAOZxGcnk" target="_blank" rel="noopener">https://www.youtube.com/watch?v=S3LAOZxGcnk</a></p><p>â€”â€”æŒç»­æ›´æ–°â€”â€”</p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡‡æ · </tag>
            
            <tag> sampling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†9</title>
      <link href="/2018/09/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%869/"/>
      <url>/2018/09/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%869/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ä¿å­˜checkpointæ˜¯ä¸€ä¸ªdictå½¢å¼ï¼Œå¯ä»¥ä¿å­˜ä»»æ„å¤šä¸ªæ¨¡å‹åˆ°ä¸€ä¸ªcheckpointä¸­ã€‚<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#save</span></span><br><span class="line">torch.save(&#123;            <span class="string">'epoch'</span>: epoch,            <span class="string">'model_state_dict'</span>: model.state_dict(),            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),            <span class="string">'loss'</span>: loss,            ...            &#125;, PATH)</span><br><span class="line"><span class="comment">#load</span></span><br><span class="line">model = TheModelClass(*args, **kwargs)optimizer = TheOptimizerClass(*args, **kwargs)</span><br><span class="line">checkpoint = torch.load(PATH)model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])epoch = checkpoint[<span class="string">'epoch'</span>]loss = checkpoint[<span class="string">'loss'</span>]</span><br><span class="line">model.eval()<span class="comment"># - or -</span>model.train()</span><br></pre></td></tr></table></figure></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>Pytorchå¯ä»¥loadéƒ¨åˆ†æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯åªloadè¿›æ¥éƒ¨åˆ†æˆ‘ä»¬éœ€è¦çš„å±‚ï¼Œè¿™åœ¨transfer learningä¸­ç”¨åˆ°ã€‚<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">torch.save(modelA.state_dict(), PATH)</span><br><span class="line">modelB = TheModelBClass(*args, **kwargs)modelB.load_state_dict(torch.load(PATH), strict=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>no title</title>
      <link href="/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%9C%89%E5%8A%9B%E9%87%8F%E7%9A%84%E6%96%87%E5%AD%97/"/>
      <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%9C%89%E5%8A%9B%E9%87%8F%E7%9A%84%E6%96%87%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<p>æ¯å½“æˆ‘é‡åˆ°è‡ªå·±ä¸æ•¢ç›´è§†çš„å›°éš¾æ—¶ï¼Œæˆ‘å°±ä¼šé—­ä¸ŠåŒçœ¼ï¼Œæƒ³è±¡è‡ªå·±æ˜¯ä¸€ä¸ª80å²çš„è€äººï¼Œä¸ºäººç”Ÿä¸­æ›¾æ”¾å¼ƒå’Œé€ƒé¿è¿‡çš„æ— æ•°å›°éš¾è€Œæ‡Šæ‚”ä¸å·²ï¼Œæˆ‘ä¼šå¯¹è‡ªå·±è¯´ï¼Œèƒ½å†å¹´è½»ä¸€æ¬¡è¯¥æœ‰å¤šå¥½ï¼Œç„¶åæˆ‘çå¼€çœ¼ç›ï¼šç °ï¼æˆ‘åˆå¹´è½»ä¸€æ¬¡äº†ï¼</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯10</title>
      <link href="/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D10/"/>
      <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D10/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"><a href="#1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹" class="headerlink" title="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"></a>1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹</h3><p>[å”] ç‹æ¹¾<br>å®¢è·¯é’å±±å¤–ï¼Œè¡ŒèˆŸç»¿æ°´å‰ã€‚<br>æ½®å¹³ä¸¤å²¸é˜”ï¼Œé£æ­£ä¸€å¸†æ‚¬ã€‚<br><strong>æµ·æ—¥ç”Ÿæ®‹å¤œï¼Œæ±Ÿæ˜¥å…¥æ—§å¹´ã€‚</strong><br>ä¹¡ä¹¦ä½•å¤„è¾¾ï¼Œå½’é›æ´›é˜³è¾¹ã€‚</p><p>æ¬¡ï¼šæ—…é€”ä¸­æš‚æ—¶åœå®¿ï¼Œè¿™é‡Œæ˜¯åœæ³Šçš„æ„æ€ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e</a></p><hr><h3 id="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"><a href="#2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ" class="headerlink" title="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"></a>2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ</h3><p>[å”] æœç‰§<br>æ¸…æ—¶æœ‰å‘³æ˜¯æ— èƒ½ï¼Œé—²çˆ±å­¤äº‘é™çˆ±åƒ§ã€‚<br><strong>æ¬²æŠŠä¸€éº¾æ±Ÿæµ·å»ï¼Œä¹æ¸¸åŸä¸Šæœ›æ˜­é™µã€‚</strong></p><p>æ— èƒ½ï¼šæ— æ‰€ä½œä¸ºã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b99db9165abd005a6da742" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b99db9165abd005a6da742</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬ä¸€ç«  ç»ªè®º</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p>è®°å½•PRMLå­¦ä¹ è¿‡ç¨‹ã€‚<br>ç¬”è®°å…±äº«é“¾æ¥ï¼š<a href="https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg" target="_blank" rel="noopener">https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg</a></p><hr><h1 id="æ¦‚ç‡è®º"><a href="#æ¦‚ç‡è®º" class="headerlink" title="æ¦‚ç‡è®º"></a>æ¦‚ç‡è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-27-21.jpg" alt="æ¦‚ç‡è®º"></p><h1 id="å†³ç­–è®º"><a href="#å†³ç­–è®º" class="headerlink" title="å†³ç­–è®º"></a>å†³ç­–è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-36-52.jpg" alt="å†³ç­–è®º"></p><h1 id="ä¿¡æ¯è®º"><a href="#ä¿¡æ¯è®º" class="headerlink" title="ä¿¡æ¯è®º"></a>ä¿¡æ¯è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-38-46.jpg" alt="ä¿¡æ¯è®º"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 6:Backpropagation</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%206:%20Backpropagation/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%206:%20Backpropagation/</url>
      
        <content type="html"><![CDATA[<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><p>åŸºæœ¬å…¬å¼<br><img src="/images/2018-09-23-15376684598125.jpg" width="50%" height="50%"><br><img src="/images/2018-09-23-15376684674095.jpg" width="50%" height="50%"></p><h3 id="forward-passå’Œbackward-pass"><a href="#forward-passå’Œbackward-pass" class="headerlink" title="forward passå’Œbackward pass"></a>forward passå’Œbackward pass</h3><p>å¯ä»¥å°†backpropagationåˆ†ä¸ºä¸¤æ­¥</p><h4 id="forward-pass"><a href="#forward-pass" class="headerlink" title="forward pass"></a>forward pass</h4><p>åœ¨å‰å‘ä¼ æ’­çš„æ—¶å€™æå‰è®¡ç®—/ä¿å­˜å¥½ï¼Œå› ä¸ºè¯¥æ¢¯åº¦å¾ˆç®€å•<br><img src="/images/2018-09-23-15376686358832.jpg" width="50%" height="50%"></p><p>æ¯”å¦‚zå¯¹w1çš„æ¢¯åº¦å°±æ˜¯x1ï¼Œå°±æ˜¯å’Œw1ç›¸è¿çš„é¡¹<br><img src="/images/2018-09-23-15376687025289.jpg" width="20%" height="50%"></p><h4 id="backward-pass"><a href="#backward-pass" class="headerlink" title="backward pass"></a>backward pass</h4><p>å›ä¼ çš„æ—¶å€™é€å±‚ç›¸ä¹˜ä¸‹å»ï¼Œç±»ä¼¼åŠ¨æ€è§„åˆ’ï¼Œè·å¾—äº†åä¸€å±‚çš„æ¢¯åº¦æ‰èƒ½æ±‚å‡ºå‰ä¸€å±‚çš„æ¢¯åº¦ã€‚<br><img src="/images/2018-09-23-15376687488493.jpg" width="50%" height="50%"></p><h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><p><img src="/images/2018-09-23-15376687824826.jpg" width="50%" height="50%"></p><p>å…ˆå‰å‘ï¼Œæå‰ç®—å‡ºæœ€é‚»è¿‘çš„æ¢¯åº¦ï¼Œç›´åˆ°output layerï¼Œè®¡ç®—å®Œè¯¥æ¢¯åº¦ï¼Œå†ä¸æ–­å›ä¼ é€å±‚ç›¸ä¹˜è·å¾—outputå¯¹å„å±‚çš„æ¢¯åº¦ã€‚</p><h3 id="ä»£ç å®ç°ä¾‹å­"><a href="#ä»£ç å®ç°ä¾‹å­" class="headerlink" title="ä»£ç å®ç°ä¾‹å­"></a>ä»£ç å®ç°ä¾‹å­</h3><p>reluå®ç°forward passå’Œbackward pass<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Backpropagation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 5:Classification:Logistic Regression</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%205%20Classification:%20Logistic%20Regression/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%205%20Classification:%20Logistic%20Regression/</url>
      
        <content type="html"><![CDATA[<h3 id="logistic-regressionå¦‚ä½•åšï¼Ÿ"><a href="#logistic-regressionå¦‚ä½•åšï¼Ÿ" class="headerlink" title="logistic regressionå¦‚ä½•åšï¼Ÿ"></a>logistic regressionå¦‚ä½•åšï¼Ÿ</h3><p>step1: å®šä¹‰function set<br><img src="/images/2018-09-23-15376666391912.jpg" width="30%" height="50%"></p><p>step2: æ›´æ–°<br>ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ›´æ–°</p><script type="math/tex; mode=display">L(w,b)=f_{w,b}(x^1 )f_{w,b}(x^2 )(1âˆ’f_{w,b} (x^3 ))â‹¯f_{w,b} (x^N )</script><p>æ‰¾åˆ°wï¼Œbä½¿å¾—Læœ€å¤§</p><p>å¯¹ä¼¼ç„¶å‡½æ•°å–è´Ÿå¯¹æ•°ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-09-23-15376667791380.jpg" width="60%" height="50%"></p><p>å°†å¼å­çš„æ¯ä¸ªå…ƒç´ å†™æˆä¼¯åŠªåˆ©åˆ†å¸ƒå½¢å¼ï¼š<br><img src="/images/2018-09-23-15376669013511.jpg" width="60%" height="50%"></p><p>ä¸Šå¼å°±æ˜¯cross-entropyæŸå¤±å‡½æ•°ã€‚</p><p>æ±‚å¯¼è¯¥å¼å­å¯å¾—ï¼š<br><img src="/images/2018-09-23-15376669743224.jpg" width="30%" height="50%"><br>æ›´æ–°å…¬å¼ï¼š<br><img src="/images/2018-09-23-15376669980138.jpg" width="40%" height="50%"><br>å¯ä»¥çœ‹å‡ºä¸Šå¼å¾ˆç›´è§‚ï¼šå’Œç­”æ¡ˆå·®è·è¶Šå¤§ï¼Œæ›´æ–°æ­¥ä¼è¶Šå¤§ã€‚</p><p>åŒæ—¶å‘ç°ä¸Šå¼å’Œlinear regressionçš„æ›´æ–°å…¬å¼æ˜¯ä¸€è‡´çš„ã€‚</p><h3 id="ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ</h3><p>å‡è®¾æˆ‘ä»¬ä½¿ç”¨square lossï¼Œåˆ™æ±‚å¯¼å¾—åˆ°çš„æ¢¯åº¦ï¼š<br><img src="/images/2018-09-23-15376671202521.jpg" width="50%" height="50%"><br>ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“æ¥è¿‘targetæ—¶ï¼Œæ¢¯åº¦å°ï¼›è¿œç¦»targetæ—¶ï¼Œæ¢¯åº¦ä¹Ÿå°ã€‚éš¾ä»¥è¾¾åˆ°å…¨å±€æœ€å°<br><img src="/images/2018-09-23-15376672527230.jpg" width="60%" height="50%"></p><p>ä¸‹å›¾æ˜¯cross entropyå’Œsquare errorçš„å›¾åƒç¤ºæ„ï¼š<br><img src="/images/2018-09-23-15376672892502.jpg" width="60%" height="50%"></p><p>å¦‚å›¾ï¼Œsquare losséš¾ä»¥åˆ°è¾¾å…¨å±€æœ€å°ã€‚</p><h3 id="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"><a href="#ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«" class="headerlink" title="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"></a>ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«</h3><p>ç”Ÿæˆå¼å¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œå†é€šè¿‡è´å¶æ–¯å®šç†è·å¾—åéªŒæ¦‚ç‡ï¼›è€Œåˆ¤åˆ«å¼æ¨¡å‹ç›´æ¥å¯¹åéªŒæ¦‚ç‡å»ºæ¨¡ã€‚<br><img src="/images/2018-09-23-15376674213503.jpg" width="60%" height="50%"><br>äºŒè€…æ‰€å®šä¹‰çš„function setæ˜¯ä¸€è‡´çš„ï¼Œä½†åŒä¸€ç»„æ•°æ®å¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„wå’Œbã€‚</p><p>äºŒè€…ä¼˜åŠ£å¯¹æ¯”ï¼š</p><ul><li>æ•°æ®é‡å¤šæ—¶ï¼Œä¸€èˆ¬æ¥è¯´åˆ¤åˆ«å¼æ¨¡å‹ä¼šæ›´å¥½ã€‚å› ä¸ºåˆ¤åˆ«å¼æ¨¡å‹æ²¡æœ‰å…ˆéªŒå‡è®¾ï¼Œå®Œå…¨ä¾èµ–äºæ•°æ®ã€‚ä½†å¦‚æœæ•°æ®æœ‰å™ªå£°ï¼Œå®¹æ˜“å—å½±å“ã€‚</li><li>ç”Ÿæˆå¼æ¨¡å‹æ˜¯æœ‰ä¸€å®šçš„å‡è®¾çš„ï¼Œå½“å‡è®¾é”™è¯¯ï¼Œä¼šå½±å“åˆ†ç±»æ•ˆæœã€‚</li><li>æ­£å› ä¸ºæœ‰ä¸€å®šçš„å…ˆéªŒå‡è®¾ï¼Œå½“æ•°æ®é‡å¾ˆå°‘æ—¶ï¼Œå¯èƒ½æ•ˆæœä¼šä¸é”™ï¼›å¯¹äºå™ªå£°æ›´å…·æœ‰é²æ£’æ€§ã€‚</li><li>å…ˆéªŒå¯ä»¥ä»å…¶ä»–æ•°æ®æºè·å¾—æ¥å¸®åŠ©ç‰¹å®šä»»åŠ¡ï¼Œå¦‚è¯­éŸ³è¯†åˆ«é—®é¢˜ã€‚</li></ul><h3 id="logisticçš„å±€é™"><a href="#logisticçš„å±€é™" class="headerlink" title="logisticçš„å±€é™"></a>logisticçš„å±€é™</h3><p>æœ¬è´¨ä»æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ²¡åŠæ³•åˆ†ç±»éçº¿æ€§çš„æ•°æ®ã€‚<br>å¦‚ä½•è§£å†³è¯¥é—®é¢˜?<br><strong>å°†logistic regression modelæ‹¼æ¥èµ·æ¥</strong>ï¼Œå‰é¢çš„modelå¯¹æ•°æ®è¿›è¡Œfeature transformationï¼Œç„¶åå†å¯¹æ–°çš„featureè¿›è¡Œåˆ†ç±»ã€‚<br><img src="/images/2018-09-23-15376677559470.jpg" width="70%" height="50%"></p><p>logisticä¸deep learningçš„è”ç³»ï¼š<br>å¦‚æœå°†logistic regressionçš„ä¸€ä¸ªå•å…ƒç§°ä¸ºneuronï¼Œæ‹¼èµ·æ¥å°±æ˜¯neural networkäº†ï¼ï¼ï¼</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Classification </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†8</title>
      <link href="/2018/09/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%868/"/>
      <url>/2018/09/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%868/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>torch.max()æœ‰ä¸¤ç§ä¸åŒå†™æ³•ã€‚<br>torch.max(input) â†’ Tensor è¿”å›å…¶ä¸­æœ€å¤§çš„å…ƒç´ <br>torch.max(input, dim, keepdim=False, out=None) â†’ (Tensor, LongTensor) è¿”å›è¯¥ç»´åº¦ä¸Šæœ€å¤§å€¼ï¼Œä»¥åŠå¯¹åº”çš„index</p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>å°†æ¨¡å‹åŒæ—¶éƒ¨ç½²åˆ°å¤šå¼ å¡ä¸Šè®­ç»ƒï¼Œæœ¬è´¨å°±æ˜¯å°†ä¸€ä¸ªbatchçš„æ•°æ®splitï¼Œé€åˆ°å„ä¸ªmodelï¼Œç„¶ååˆå¹¶ç»“æœã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£-æ±‚å¯¼"><a href="#3ï¸âƒ£-æ±‚å¯¼" class="headerlink" title="3ï¸âƒ£[æ±‚å¯¼]"></a>3ï¸âƒ£[æ±‚å¯¼]</h3><p>æ ‡é‡ã€å‘é‡ã€çŸ©é˜µä¹‹é—´çš„æ±‚å¯¼æœ‰ä¸¤ç§å¸ƒå±€ï¼Œå³åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€ã€‚åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€åªå·®ä¸€ä¸ªè½¬ç½®ã€‚<br>æˆ‘çš„è®°æ³•ï¼šåœ¨æ±‚å¯¼è¿‡ç¨‹ä¸­ï¼Œå‡è®¾åˆ†æ¯ä¸ºm*nï¼Œåˆ†å­ä¸º k*nï¼Œåˆ™å¯¼æ•°çŸ©é˜µåº”è¯¥ä¸º k*m ã€‚ä¸€äº›ç‰¹æ®Šçš„å¦‚æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼ç­‰é™¤å¤–ã€‚<br>å…·ä½“ç›´æ¥æŸ¥è¡¨ï¼š<a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a></p><p>æŒ‰ä½è®¡ç®—æ±‚å¯¼ï¼š<br>å‡è®¾ä¸€ä¸ªå‡½æ•°$f(x)$çš„è¾“å…¥æ˜¯æ ‡é‡$x$ã€‚å¯¹äºä¸€ç»„Kä¸ªæ ‡é‡$x_1,Â·Â·Â· ,x_K$ï¼Œæˆ‘ä»¬<br>å¯ä»¥é€šè¿‡$f(x)$å¾—åˆ°å¦å¤–ä¸€ç»„Kä¸ªæ ‡é‡$z_1,Â·Â·Â· ,z_K$ï¼Œ<br>$z_k = f(x_k),âˆ€k = 1,Â·Â·Â· ,K$<br>å…¶ä¸­ï¼Œ$f(x)$æ˜¯æŒ‰ä½è¿ç®—çš„ï¼Œå³$[f(x)]_i = f(x_i)$<br>å…¶å¯¼æ•°æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼š<br><img src="/images/2018-09-23-15376727095200.jpg" width="50%" height="50%"></p><p><strong>Reference</strong>ï¼š<br><a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a><br><a href="https://blog.csdn.net/uncle_gy/article/details/78879131" target="_blank" rel="noopener">https://blog.csdn.net/uncle_gy/article/details/78879131</a><br><a href="https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf" target="_blank" rel="noopener">https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> æ±‚å¯¼ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•7</title>
      <link href="/2018/09/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%957/"/>
      <url>/2018/09/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%957/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£softmaxçš„numpyå®ç°"><a href="#1ï¸âƒ£softmaxçš„numpyå®ç°" class="headerlink" title="1ï¸âƒ£softmaxçš„numpyå®ç°"></a>1ï¸âƒ£softmaxçš„numpyå®ç°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x,axis=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Compute softmax values for each sets of scores in x."""</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / np.sum(np.exp(x), axis=axis)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu"><a href="#2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu" class="headerlink" title="2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu"></a>2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£Pytorchå®ç°relu"><a href="#3ï¸âƒ£Pytorchå®ç°relu" class="headerlink" title="3ï¸âƒ£Pytorchå®ç°relu"></a>3ï¸âƒ£Pytorchå®ç°relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"><a href="#4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²" class="headerlink" title="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"></a>4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¬è¾¾è§‚æ¯ç°åœºç­”è¾©æœ‰æ„Ÿ</title>
      <link href="/2018/09/19/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E5%90%AC%E8%BE%BE%E8%A7%82%E6%9D%AF%E7%8E%B0%E5%9C%BA%E7%AD%94%E8%BE%A9%E6%9C%89%E6%84%9F/"/>
      <url>/2018/09/19/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E5%90%AC%E8%BE%BE%E8%A7%82%E6%9D%AF%E7%8E%B0%E5%9C%BA%E7%AD%94%E8%BE%A9%E6%9C%89%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥ï¼ˆå‘¨æ—¥ï¼‰å»äº†è¾¾è§‚æ¯ç­”è¾©ç°åœºå¬äº†å‰10ååšäº†æŠ¥å‘Šï¼Œæœ‰äº†ä¸€äº›æ„Ÿæƒ³ï¼Œä½†ä¸€ç›´æ²¡æœ‰æŠ½å‡ºæ—¶é—´å†™ä¸€ä¸‹è‡ªå·±çš„æ„Ÿæƒ³ï¼ˆæ‡’ï¼‰ã€‚</p><p>è‡ªå·±å¤§æ¦‚èŠ±äº†åæ¥å¤©åšäº†ä¸€ä¸‹æ¯”èµ›ï¼Œå®é™…ä¸Šä¹Ÿå°±æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»çš„<a href="http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html" target="_blank" rel="noopener">æ¯”èµ›</a>ï¼Œå› ä¸ºæ²¡æœ‰æ¯”èµ›ç»éªŒçš„ç¼˜æ•…ï¼Œèµ°äº†å¾ˆå¤šå¼¯è·¯ã€‚ä¸è¿‡ä¹Ÿå­¦åˆ°äº†ä¸€äº›ä¸œè¥¿ã€‚</p><p>ç°è®°å½•å‰ååçš„ä¸€äº›idea/trickï¼š</p><ul><li>æ•°æ®å¢å¼º<ul><li>å› ä¸ºç»™çš„å¥å­é•¿åº¦å¾ˆé•¿ï¼Œå› æ­¤åœ¨åšæˆªæ–­çš„æ—¶å€™åé¢çš„å°±æ²¡æ³•è®­ç»ƒåˆ°äº†ï¼Œå¯ä»¥å°†æ–‡æœ¬å€’åºä½œä¸ºæ–°çš„æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚å¯ä»¥å……åˆ†åˆ©ç”¨åˆ°æ•°æ®</li><li>å°†æ•°æ®æ‰“ä¹±ã€éšæœºåˆ é™¤ï¼Œå®é™…ä¸Šå°±æ˜¯å¯¹ä¸€ä¸ªå¥å­çš„è¯è¿›è¡Œsampleå†ç»„åˆ</li><li>æ‰“ä¹±è¯åºä»¥å¢åŠ æ•°æ®é‡</li><li>ä½¿ç”¨pseudo labelingï¼Œä½†æœ‰çš„é˜Ÿä¼ä½¿ç”¨è¿™ä¸ªåšå‡ºæ•ˆæœäº†ï¼Œä½†æœ‰çš„æ²¡æœ‰</li></ul></li><li>ç‰¹å¾å·¥ç¨‹<ul><li>å‡è®¾å¼€å¤´ä¸­é—´ç»“å°¾çš„ä¿¡æ¯å¯¹åˆ†ç±»æœ‰å¸®åŠ©ï¼Œå› æ­¤æˆªå–è¯¥éƒ¨åˆ†ä¿¡æ¯åšè®­ç»ƒ</li><li>æ”¹è¿›baselineçš„tfidfçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºç†µçš„è¯æƒé‡è®¡ç®—</li><li>é™ç»´ï¼Œç•™ä¸‹æœ€é‡è¦çš„ç‰¹å¾ã€‚å…ˆç”¨å¡æ–¹åˆ†å¸ƒé™åˆ°20ä¸‡ï¼Œå†ç”¨SVDé™åˆ°8000</li><li>å°†word2vecå’ŒGloVeæ‹¼æ¥èµ·æ¥ä½œä¸ºdeep learningæ¨¡å‹çš„è¾“å…¥</li><li>å°†æ–‡ç« åˆ†æ®µï¼Œæ¯æ®µå–å‰20å20æ‹¼èµ·æ¥</li></ul></li><li>æ¨¡å‹èåˆ<br>  æ‰€æœ‰é˜Ÿä¼éƒ½æ— ä¸€ä¾‹å¤–ä½¿ç”¨äº†æ¨¡å‹èåˆï¼Œstackingæˆ–è€…ç®€å•çš„æŠ•ç¥¨<ul><li>DL+ML â€”&gt; lgbm model â€”&gt; voting</li><li>æ·±åº¦æ¨¡å‹+ä¼ ç»Ÿæ¨¡å‹ï¼Œåœ¨æ·±åº¦æ¨¡å‹æœ€åä¸€å±‚åŠ å…¥ä¼ ç»Ÿæ¨¡å‹çš„ä¿¡æ¯/feature</li><li>åå‘é€‰æ‹©å‰”é™¤å†—ä½™æ¨¡å‹</li></ul></li><li>DL&amp;å…¶ä»–<ul><li>HANï¼Œé€‰æ‹©10ä¸ªattention vector</li><li>å¯¹æ˜“é”™ç±»å¢åŠ æƒé‡ï¼Œé€šè¿‡æ”¹å˜æŸå¤±å‡½æ•°æ¥å¢åŠ æƒé‡</li><li>CNN, [1,2,3,4,5,6]*600</li><li>æå‡ºæ–°çš„æ¨¡å‹ï¼ˆç¬¬ä¸€åï¼‰</li></ul></li></ul><p>å…¶å®é™¤äº†ä¸€äº›trickï¼Œæˆ‘è¿˜æ˜¯æœ‰äº›å¤±æœ›çš„ï¼Œå› ä¸ºéƒ½æ˜¯ç”¨æ¨¡å‹èåˆå †å‡ºæ¥çš„ï¼Œè¿™ä¹Ÿè®©æˆ‘å¯¹æ¯”èµ›å¤±å»äº†ä¸€äº›å…´è¶£ã€‚è™½ç„¶èƒ½ç†è§£ç°åœ¨çš„æ¯”èµ›éƒ½æ˜¯è¿™æ ·çš„ï¼Œä½†æ„Ÿè§‰å®åœ¨å¤ªæš´åŠ›äº†ã€‚<br>å½“ç„¶ï¼Œå…¶ä¸­è¿˜æ˜¯æœ‰ä¸€äº›äº®ç‚¹çš„ï¼Œæœ‰ä¸€æ”¯é˜Ÿä¼ç«‹æ„å¾ˆé«˜ï¼Œä»ç†è§£ä¸šåŠ¡çš„è§’åº¦å‡ºå‘è€Œä¸æ˜¯å †æ¨¡å‹ï¼Œä¹Ÿå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼›è¿˜æœ‰ä¸€ä¸ªä½¿ç”¨äº†æœ€æ–°è®ºæ–‡ä¸­çš„ç‰¹å¾å·¥ç¨‹æ”¹è¿›æ–¹æ³•ï¼Œä»¤æˆ‘è€³ç›®ä¸€æ–°ï¼›ä»¥åŠç¬¬ä¸€ååœ¨æ¯”èµ›è¿‡ç¨‹ä¸­æå‡ºæ¥ä¸‰ä¸ªæ–°çš„æ¨¡å‹ã€‚</p><p>Anywayï¼Œæˆ‘ç›®å‰è¿˜æ˜¯å¤ªèœäº†ï¼Œè¿˜æ˜¯å®‰å¿ƒæç§‘ç ”å§ã€‚_(:Ğ·ã€âˆ )</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœ‰æ„Ÿ </tag>
            
            <tag> æ¯”èµ› </tag>
            
            <tag> è¾¾è§‚æ¯ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†7</title>
      <link href="/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%867/"/>
      <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%867/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œå¯ç”¨.item()æ¥è·å–å…ƒç´ </p><p>tensor &lt;â€”&gt; numpy ç›¸äº’è½¬åŒ–ä¼šå…±äº«å†…éƒ¨æ•°æ®ï¼Œå› æ­¤æ”¹å˜å…¶ä¸­ä¸€ä¸ªä¼šæ”¹å˜å¦ä¸€ä¸ª</p><p>å¯ç”¨ä½¿ç”¨ .to æ¥ç§»åŠ¨åˆ°è®¾å¤‡<br><img src="/images/2018-09-16-15370671350548.jpg" alt=""></p><p>.detech()  detach it from the computation history, and to prevent future computation from being tracked. å°†å…¶ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œå˜ä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”requires_grad=False</p><p>Function è®°å½•äº†è¿™ä¸ªtensoræ˜¯æ€ä¹ˆæ¥çš„ï¼Œæ‰€æœ‰çš„tensoréƒ½æœ‰ï¼Œé™¤éæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„ï¼š<br><img src="/images/2018-09-16-15370672806253.jpg" width="65%" height="50%"></p><hr><h3 id="2ï¸âƒ£-åæ–¹å·®"><a href="#2ï¸âƒ£-åæ–¹å·®" class="headerlink" title="2ï¸âƒ£[åæ–¹å·®]"></a>2ï¸âƒ£[åæ–¹å·®]</h3><p>å…³äºåæ–¹å·®çš„ç†è§£ï¼Œxä¸yå…³äºæŸä¸ªè‡ªå˜é‡çš„å˜åŒ–ç¨‹åº¦ï¼Œå³åº¦é‡äº†xä¸yä¹‹é—´çš„è”ç³»ã€‚<br><a href="https://www.zhihu.com/question/20852004" target="_blank" rel="noopener">https://www.zhihu.com/question/20852004</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> åæ–¹å·® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 4:Classification:Probabilistic Generative Model</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%204%20Classification%20%20Probabilistic%20Generative%20Model/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%204%20Classification%20%20Probabilistic%20Generative%20Model/</url>
      
        <content type="html"><![CDATA[<h3 id="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ</h3><p>1ï¸âƒ£å¦‚æœä½¿ç”¨regressionçš„æ€æƒ³æ¥åˆ†ç±»ï¼Œä¼šå¯¹ç¦»è¾¹ç•Œè¾ƒè¿œçš„ç‚¹è¿›è¡Œæƒ©ç½šï¼š<br><img src="/images/2018-09-16-15370662150910.jpg" width="70%" height="50%"></p><p>2ï¸âƒ£å¦‚æœå¤šåˆ†ç±»ä½¿ç”¨regressionï¼Œå¦‚class 1, class 2, class 3ï¼›åˆ™éšå¼åœ°å‡è®¾äº†class 1 å’Œ class 2è¾ƒä¸ºæ¥è¿‘ï¼Œå¦‚æœæ²¡æœ‰è¿™ç§æ¥è¿‘å…³ç³»ï¼Œåˆ™åˆ†ç±»ä¼šä¸æ­£ç¡®ã€‚</p><h3 id="é—®é¢˜æè¿°ä¸å®šä¹‰"><a href="#é—®é¢˜æè¿°ä¸å®šä¹‰" class="headerlink" title="é—®é¢˜æè¿°ä¸å®šä¹‰"></a>é—®é¢˜æè¿°ä¸å®šä¹‰</h3><p><img src="/images/2018-09-16-15370662762802.jpg" width="70%" height="50%"></p><p>å½“På¤§äº0.5åˆ™æ˜¯C1ç±»ï¼Œåä¹‹æ˜¯C2ç±»<br>å…ˆéªŒP(C1)å’ŒP(C2)éƒ½å¥½è®¡ç®—ï¼Œè®¡ç®—C1å æ€»çš„æ¯”ä¾‹å³å¯<br>å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—çš„å°±æ˜¯p(x|C)</p><p>è¿™ä¸€æƒ³æ³•ï¼Œæœ¬è´¨æ˜¯å¾—åˆ°äº†ç”Ÿæˆå¼æ¨¡å‹ï¼š<br><img src="/images/2018-09-16-15370663099515.jpg" width="70%" height="50%"></p><h3 id="åŸç†æ¦‚è¿°"><a href="#åŸç†æ¦‚è¿°" class="headerlink" title="åŸç†æ¦‚è¿°"></a>åŸç†æ¦‚è¿°</h3><p>ç°<strong>å‡è®¾è®­ç»ƒæ•°æ®ç‚¹çš„åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒ</strong>ï¼šï¼ˆæ˜¾ç„¶å¯ä»¥è‡ªå·±è®¾ä»»ä½•åˆ†å¸ƒï¼‰<br>å³æ•°æ®ä»é«˜æ–¯åˆ†å¸ƒé‡‡æ ·å¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370663870205.jpg" width="55%" height="50%"></p><p>æ ¹æ®æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå¯ä»¥è·å¾—æ¯ä¸ªç±»åˆ«çš„Î¼å’ŒÎ£ï¼š<br><img src="/images/2018-09-16-15370664041246.jpg" width="70%" height="50%"></p><p>å¾—åˆ°äº†å‚æ•°åï¼Œå³å¯ä»£å…¥å¾—åˆ°P(C|x) ï¼š<br><img src="/images/2018-09-16-15370664355955.jpg" width="80%" height="50%"></p><p>åˆšåˆšå‡è®¾$Î£$å¯¹äºä¸åŒç±»åˆ«ä¸åŒï¼Œç°æˆ‘ä»¬<strong>ä»¤ä¸åŒç±»åˆ«å…±äº«ç›¸åŒ$Î£$</strong>ï¼š<br>ï¼ˆå› ä¸ºåæ–¹å·®ä»£è¡¨çš„æ˜¯ä¸åŒfeatureä¹‹é—´çš„è”ç³»ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯å’Œç±»åˆ«æ— å…³çš„ï¼‰</p><p>$Î£$çš„è®¡ç®—å…¬å¼æ˜¯åŠ æƒæ±‚å’Œï¼š<br><img src="/images/2018-09-16-15370665362081.jpg" width="24%" height="50%"></p><p>åœ¨ä½¿ç”¨äº†ç›¸åŒçš„åæ–¹å·®çŸ©é˜µåï¼Œè¾¹ç•Œå°±æ˜¯çº¿æ€§çš„ï¼ˆåé¢ä¼šæåˆ°ä¸ºä»€ä¹ˆæ˜¯è¿™æ ·ï¼‰ï¼š<br><img src="/images/2018-09-16-15370665553962.jpg" alt=""></p><p> æ€»ç»“ï¼š<br> ä¸‰æ­¥èµ°ï¼Œå®šä¹‰function setï¼Œè®¡ç®—Î¼å’Œåæ–¹å·®çŸ©é˜µï¼Œå¾—åˆ°best functionï¼š<br><img src="/images/2018-09-16-15370665888683.jpg" width="60%" height="50%"></p><p>æ³¨æ„åˆ°ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºï¼Œä¸åŒfeatureä¹‹é—´æ²¡æœ‰å…³ç³»ï¼Œæ¯ä¸ªfeatureç¬¦åˆç‰¹å®šçš„é«˜æ–¯åˆ†å¸ƒï¼Œåˆ™è¯¥åˆ†ç±»å™¨åˆ™æ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼š<br><img src="/images/2018-09-16-15370666092459.jpg" width="60%" height="50%"></p><h3 id="åˆ†ç±»ä¸logistics-regression"><a href="#åˆ†ç±»ä¸logistics-regression" class="headerlink" title="åˆ†ç±»ä¸logistics regression"></a>åˆ†ç±»ä¸logistics regression</h3><p>ç°æ¨å¯¼ï¼Œè¯¥åˆ†ç±»é—®é¢˜ä¸logistics regressionä¹‹é—´çš„è”ç³»ï¼š<br>å³ï¼š<br><img src="/images/2018-09-16-15370666567324.jpg" width="60%" height="50%"></p><h4 id="å‡è®¾"><a href="#å‡è®¾" class="headerlink" title="å‡è®¾"></a>å‡è®¾</h4><p>æ•°æ®æœä»é«˜æ–¯åˆ†å¸ƒï¼Œå…±äº«$Î£$</p><h4 id="æ¨å¯¼"><a href="#æ¨å¯¼" class="headerlink" title="æ¨å¯¼"></a>æ¨å¯¼</h4><p>â‘ æ€»æ¡†æ¶ï¼š<br><img src="/images/2018-09-16-15370667000974.jpg" width="50%" height="50%"></p><p>ä»¤<br><img src="/images/2018-09-16-15370667135868.jpg" width="24%" height="50%"></p><p>åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370667376312.jpg" width="50%" height="50%"></p><p>â‘¡zçš„è¿›ä¸€æ­¥æ¨å¯¼ä¸ç®€åŒ–ï¼š<br><img src="/images/2018-09-16-15370667582564.jpg" width="30%" height="50%"></p><p>å°†zå±•å¼€ï¼š<br><img src="/images/2018-09-16-15370667763267.jpg" width="50%" height="50%"></p><p>è€Œç¬¬ä¸€éƒ¨åˆ†æœ‰ï¼š<br><img src="/images/2018-09-16-15370667880942.jpg" width="50%" height="50%"></p><p>ç¬¬ä¸€éƒ¨åˆ†ç›¸é™¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668274551.jpg" width="50%" height="50%"></p><p>å†è¿›è¡Œå±•å¼€ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668394919.jpg" width="50%" height="50%"></p><p>æœ€ç»ˆzçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-16-15370668522531.jpg" width="50%" height="50%"></p><p>ç”±äºå…±äº«åæ–¹å·®çŸ©é˜µï¼Œåˆ™å¯ä»¥æ¶ˆå»éƒ¨åˆ†ï¼Œå¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370668957564.jpg" width="50%" height="50%"></p><p>æ›¿æ¢æˆwå’Œbï¼š<br><img src="/images/2018-09-16-15370669103562.jpg" width="50%" height="50%"></p><p>â‘¢æœ€ç»ˆï¼Œå°†zå¸¦å›åˆ°åŸå¼ï¼š<br><img src="/images/2018-09-16-15370669221472.jpg" width="25%" height="50%"></p><p>æ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦å†ä¼°è®¡N1,N2,Î¼å’ŒÎ£ï¼Œç›´æ¥è®¡ç®—wå’Œbå³å¯ã€‚ä¹Ÿå› æ­¤ï¼Œåˆ†ç•Œçº¿æ˜¯çº¿æ€§çš„ã€‚</p><p>å…¨è¿‡ç¨‹ï¼š<br><img src="/images/2018-09-16-15370669594744.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Classification </tag>
            
            <tag> Probabilistic Generative Model </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 3:Gradient Descent</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%203%20Gradient%20Descent/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%203%20Gradient%20Descent/</url>
      
        <content type="html"><![CDATA[<h2 id="Gradient-Descent-tips"><a href="#Gradient-Descent-tips" class="headerlink" title="Gradient Descent tips"></a>Gradient Descent tips</h2><h3 id="tip-1ï¼šAdaptive-Learning-Rates"><a href="#tip-1ï¼šAdaptive-Learning-Rates" class="headerlink" title="tip 1ï¼šAdaptive Learning Rates"></a>tip 1ï¼šAdaptive Learning Rates</h3><h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><h5 id="åŸºæœ¬æ€æƒ³"><a href="#åŸºæœ¬æ€æƒ³" class="headerlink" title="åŸºæœ¬æ€æƒ³"></a>åŸºæœ¬æ€æƒ³</h5><p><img src="/images/2018-09-16-15370654467771.jpg" width="30%" height="50%"></p><p><img src="/images/2018-09-16-15370654502774.jpg" width="20%" height="50%"></p><p>å…¶ä¸­Ïƒæ˜¯ä¹‹å‰æ‰€æœ‰çš„æ¢¯åº¦çš„å¹³æ–¹æ ¹<br><img src="/images/2018-09-16-15370654728457.jpg" width="30%" height="50%"></p><p>åŒ–ç®€å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370654853172.jpg" width="50%" height="50%"></p><h5 id="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"></a>ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ</h5><p>è€ƒè™‘ä¸€ä¸ªå¼€å£å‘ä¸Šçš„äºŒæ¬¡å‡½æ•°<br><img src="/images/2018-09-16-15370655091732.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³ï¼Œæœ€å¥½çš„æ­¥é•¿æ˜¯ä¸€æ¬¡å¯¼é™¤ä»¥äºŒæ¬¡å¯¼ï¼Œä½†äºŒæ¬¡å¯¼è®¡ç®—é‡å¤§ï¼Œå› æ­¤ä½¿ç”¨è¿‘ä¼¼çš„æ–¹å¼ï¼š<br><strong>å¯¹ä¸€æ¬¡å¯¼ä½œå¤šæ¬¡çš„sample</strong>ã€‚<br>ä¸‹å›¾æ˜¾ç¤ºï¼Œå¦‚æœäºŒæ¬¡å¯¼å°ï¼Œé‚£ä¹ˆå¤šæ¬¡sampleè·å¾—çš„ä¸€æ¬¡å¯¼ä¹Ÿå°ï¼Œåä¹‹åˆ™å¤§ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€æ¬¡å¯¼åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥åæ˜ äºŒæ¬¡å¯¼çš„å¤§å°ï¼Œæ‰€ä»¥ç›´æ¥ç”¨ä¸€æ¬¡å¯¼è¿‘ä¼¼ï¼Œå¯ä»¥å‡å°‘è®¡ç®—é‡ã€‚</p><p><img src="/images/2018-09-16-15370655850876.jpg" width="50%" height="50%"></p><h3 id="tip-2ï¼šfeature-scaling"><a href="#tip-2ï¼šfeature-scaling" class="headerlink" title="tip 2ï¼šfeature scaling"></a>tip 2ï¼šfeature scaling</h3><p><img src="/images/2018-09-16-15370656836724.jpg" width="50%" height="50%"></p><p>èƒ½å¤Ÿæ”¹å˜lossçš„åˆ†å¸ƒï¼Œä¸Šå›¾1ä¸­w2å¯¹lossçš„å½±å“è¾ƒå¤§ï¼Œåˆ™è¾ƒé™¡å³­ï¼Œå‚æ•°æ›´æ–°å°±è¾ƒå›°éš¾ï¼Œéœ€è¦adaptive learning rateï¼›å¦‚æœè¿›è¡Œfeature scalingï¼Œèƒ½å¤Ÿæ›´å¥½è¾¾åˆ°local optimal</p><h2 id="Gradient-Descent-Theory"><a href="#Gradient-Descent-Theory" class="headerlink" title="Gradient Descent Theory"></a>Gradient Descent Theory</h2><p>å¦ä¸€ç§è§’åº¦çœ‹gradient descentï¼š</p><p>åŸºæœ¬æ€æƒ³ï¼š<br>æˆ‘ä»¬å¸Œæœ›æ¯ä¸€æ¬¡éƒ½åœ¨å½“å‰ç‚¹é™„è¿‘æ‰¾åˆ°ä¸€ä¸ªæœ€å°çš„ç‚¹ï¼Œå³åœ¨ä¸€ä¸ªèŒƒå›´å†…ï¼š<br><img src="/images/2018-09-16-15370657785697.jpg" width="40%" height="50%"></p><p>åº”è¯¥å¦‚ä½•æ‰¾åˆ°è¯¥æœ€å°ç‚¹ï¼Ÿ</p><p>æˆ‘ä»¬çŸ¥é“ï¼Œæ³°å‹’çº§æ•°çš„å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370658066669.jpg" width="50%" height="50%"></p><p>å½“xæ¥è¿‘x0æ—¶ï¼Œä¼šæœ‰å¦‚ä¸‹è¿‘ä¼¼ï¼š<br><img src="/images/2018-09-16-15370658167935.jpg" width="30%" height="50%"></p><p>æ¨å¹¿åˆ°å¤šå…ƒæ³°å‹’çº§æ•°åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370658315314.jpg" width="60%" height="50%"></p><p>é‚£ä¹ˆï¼Œå¦‚å‰æ‰€è¿°ï¼Œxæ¥è¿‘x0ï¼Œå¯¹äºå›¾ä¸­ï¼Œå³åœ†åœˆè¶³å¤Ÿå°æ—¶ï¼š<br><img src="/images/2018-09-16-15370658494091.jpg" width="50%" height="50%"></p><p>ç®€åŒ–ç¬¦å·ï¼š<br><img src="/images/2018-09-16-15370658736683.jpg" width="12%" height="50%"></p><p><img src="/images/2018-09-16-15370658623258.jpg" width="30%" height="50%"></p><p>æ‰€ä»¥å¯ä»¥ç®€å†™æˆï¼š<br><img src="/images/2018-09-16-15370658855882.jpg" width="30%" height="50%"></p><p>ç”±äºs,u,véƒ½æ˜¯å¸¸æ•°ï¼Œåœ¨åœ†åœˆèŒƒå›´å†…å¯»æ‰¾æœ€å°å€¼å¯¹åº”çš„å‚æ•°å¯ä»¥ç®€åŒ–æˆï¼š<br><img src="/images/2018-09-16-15370658981519.jpg" width="40%" height="50%"></p><p><img src="/images/2018-09-16-15370659061025.jpg" width="30%" height="50%"></p><p>å†åº¦ç®€åŒ–ï¼Œå¯ä»¥è¡¨è¾¾æˆï¼š<br><img src="/images/2018-09-16-15370659680601.jpg" width="40%" height="50%"></p><p><img src="/images/2018-09-16-15370659747339.jpg" width="30%" height="50%"></p><p>åœ¨å›¾ä¸­å¯ä»¥ç”»ä¸ºä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯<br><img src="/images/2018-09-16-15370660126195.jpg" width="40%" height="50%"></p><p>æ˜¾ç„¶ï¼Œå½“åæ–¹å‘æ—¶ï¼Œæœ€å°ï¼š<br><img src="/images/2018-09-16-15370660243469.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/2018-09-16-15370660628961.jpg" width="50%" height="50%"></p><p>æœ€ç»ˆå®Œæ•´çš„å¼å­ï¼š<br><img src="/images/2018-09-16-15370660794436.jpg" width="55%" height="50%"></p><p>å› æ­¤ï¼Œå½“learning rateä¸å¤Ÿå°æ—¶ï¼Œæ˜¯ä¸æ»¡è¶³æ³°å‹’çº§æ•°è¿‘ä¼¼çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Gradient Descent </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 2:Bias and Variance</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%202%20Bias%20and%20Variance/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%202%20Bias%20and%20Variance/</url>
      
        <content type="html"><![CDATA[<h3 id="å¦‚ä½•ç†è§£bias-amp-variance"><a href="#å¦‚ä½•ç†è§£bias-amp-variance" class="headerlink" title="å¦‚ä½•ç†è§£bias&amp;variance"></a>å¦‚ä½•ç†è§£bias&amp;variance</h3><p><img src="/images/2018-09-16-15370650140053.jpg" width="40%" height="50%"><br>biasæ˜¯function spaceä¸­å¿ƒç¦»optimal modelçš„å·®è·ï¼Œvarianceæ˜¯æŸæ¬¡å®éªŒæ‰€å¾—æ¨¡å‹ç¦»function spaceä¸­å¿ƒçš„è·ç¦»ã€‚</p><p>æ¯”å¦‚è¯´ï¼Œç®€å•åœ°æ¨¡å‹çš„function spaceå°ï¼Œéšæœºæ€§å°ï¼Œå› æ­¤varianceå°ï¼Œä½†ä¹Ÿå› ä¸ºfunction spaceå°ï¼Œè¡¨ç¤ºèƒ½åŠ›æœ‰é™ï¼Œå› æ­¤biaså¤§ã€‚</p><p>å¦‚å›¾ï¼š<br><img src="/images/2018-09-16-15370651353167.jpg" width="70%" height="50%"><br>è¯¥å›¾ä¸­è“è‰²åœˆä»£è¡¨æ¨¡å‹æ‰€èƒ½è¡¨è¾¾çš„èŒƒå›´ã€‚</p><h3 id="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"><a href="#å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜" class="headerlink" title="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"></a>å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜</h3><p>â‘ æ›´å¤šçš„data<br>â‘¡regularizationï¼šå¼ºè¿«functionæ›´å¹³æ»‘ï¼Œå› æ­¤å‡å°varianceï¼Œä½†å› ä¸ºè°ƒæ•´äº†function spaceï¼Œå¯èƒ½ä¼šå¢åŠ biasã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> bias&amp;variance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯9</title>
      <link href="/2018/09/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D9/"/>
      <url>/2018/09/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D9/</url>
      
        <content type="html"><![CDATA[<h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€</strong>ã€‚<br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p><hr><h3 id="ç»å‘½è¯—"><a href="#ç»å‘½è¯—" class="headerlink" title="ç»å‘½è¯—"></a>ç»å‘½è¯—</h3><p>è°­å—£åŒ<br>æœ›é—¨æŠ•æ­¢æ€å¼ ä¿­ï¼Œ<br>å¿æ­»é¡»è‡¾å¾…æœæ ¹ã€‚<br><strong>æˆ‘è‡ªæ¨ªåˆ€å‘å¤©ç¬‘ï¼Œ<br>å»ç•™è‚èƒ†ä¸¤æ˜†ä»‘ï¼</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pytorch backward()æµ…æ</title>
      <link href="/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Pytorch%20backward()%E6%B5%85%E6%9E%90/"/>
      <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Pytorch%20backward()%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘åœ¨çœ‹pytorchæ–‡æ¡£çš„æ—¶å€™ï¼Œçœ‹åˆ°backwardå†…æœ‰ä¸€ä¸ªå‚æ•°gradientï¼Œåœ¨ç»è¿‡æŸ¥é˜…äº†ç›¸å…³èµ„æ–™å’Œè¿›è¡Œäº†å®éªŒåï¼Œå¯¹backwardæœ‰äº†æ›´æ·±çš„è®¤è¯†ã€‚</p><h2 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h2><p>1ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¦‚ï¼š<code>loss.backward()</code><br>åˆ™gradientä¸éœ€è¦æ‰‹åŠ¨ä¼ å…¥ï¼Œä¼šè‡ªåŠ¨æ±‚å¯¼ã€‚<br>ä¾‹å­:<br>$a=[x_1,x_2],b=\frac{x_1+x_2}{2}$<br>åˆ™bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b}{\partial x_{1}}=\frac{1}{2}ï¼Œ\dfrac {\partial b}{\partial x_{2}}=\frac{1}{2}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.Tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.mean(a)  <span class="comment">#tensor(2.5000, grad_fn=&lt;MeanBackward1&gt;)</span></span><br><span class="line">b.backward()</span><br><span class="line">a.grad   <span class="comment">#tensor([0.5000, 0.5000])</span></span><br></pre></td></tr></table></figure><p>gradientæ­¤æ—¶åªæ˜¯åœ¨ç¼©æ”¾åŸgradçš„å¤§å°ï¼Œä¹Ÿå³ä¸æŒ‡å®šgradientå’Œgradient=1æ˜¯ç­‰ä»·çš„</p><p>å½“ç„¶ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šgradientï¼Œå…¶ä¸­æŒ‡å®šgradientçš„shapeå¿…é¡»å’Œbçš„ç»´åº¦ç›¸åŒ<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gradient=torch.tensor(<span class="number">10.0</span>)</span><br><span class="line">b.backward(gradient)</span><br><span class="line">a.grad   <span class="comment">#tensor([5., 5.])</span></span><br></pre></td></tr></table></figure></p><p>2ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªå‘é‡<br>ä¾‹å­ï¼š<br>$a=[x_1,x_2],b=[b_1,b_2]$, å…¶ä¸­ $b_1=x_1+x_2,b_2=x_1*x_2$<br>bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b_1}{\partial x_{1}}=1,\dfrac {\partial b_1}{\partial x_{2}}=1$</p><p>$\dfrac {\partial b_2}{\partial x_{1}}=x_2,\dfrac {\partial b_2}{\partial x_{2}}=x_1$</p><p>åœ¨backwardçš„æ—¶å€™åˆ™å¿…é¡»æŒ‡å®šgradientã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.FloatTensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.zeros(<span class="number">2</span>)</span><br><span class="line">b[<span class="number">0</span>]=a[<span class="number">0</span>]+a[<span class="number">1</span>]</span><br><span class="line">b[<span class="number">1</span>]=a[<span class="number">0</span>]*a[<span class="number">1</span>]    <span class="comment"># b=tensor([5., 6.], grad_fn=&lt;CopySlices&gt;)</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">0.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment">#tensor([1., 1.])ï¼Œè¯´æ˜æ˜¯å¯¹b_1è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()  <span class="comment">#å°†æ¢¯åº¦æ¸…ç©ºï¼Œå¦åˆ™ä¼šå åŠ </span></span><br><span class="line"><span class="comment">#-------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">0.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad  <span class="comment"># tensor([3., 2.])ï¼Œè¯´æ˜å¯¹b_2è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()</span><br><span class="line"><span class="comment"># ------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment"># tensor([4., 3.])ï¼Œå³b_1,b_2çš„å¯¼æ•°çš„å åŠ </span></span><br><span class="line">a.grad.zero_()</span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°b.backward()æ—¶éœ€è¦retain_graphè®¾ä¸ºTrueï¼Œå¦åˆ™åœ¨è®¡ç®—å®Œåä¼šè‡ªåŠ¨é‡Šæ”¾è®¡ç®—å›¾çš„å†…å­˜ï¼Œè¿™æ ·å°±æ²¡æ³•è¿›è¡ŒäºŒæ¬¡åå‘ä¼ æ’­äº†ã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.pytorchtutorial.com/pytorch-backward/" target="_blank" rel="noopener">https://www.pytorchtutorial.com/pytorch-backward/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> backward </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯8</title>
      <link href="/2018/09/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D8/"/>
      <url>/2018/09/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D8/</url>
      
        <content type="html"><![CDATA[<h3 id="æœ›æœˆæ€€è¿œ"><a href="#æœ›æœˆæ€€è¿œ" class="headerlink" title="æœ›æœˆæ€€è¿œ"></a>æœ›æœˆæ€€è¿œ</h3><p>[å”] å¼ ä¹é¾„<br><strong>æµ·ä¸Šç”Ÿæ˜æœˆï¼Œå¤©æ¶¯å…±æ­¤æ—¶ã€‚</strong><br>æƒ…äººæ€¨é¥å¤œï¼Œç«Ÿå¤•èµ·ç›¸æ€ã€‚<br>ç­çƒ›æ€œå…‰æ»¡ï¼ŒæŠ«è¡£è§‰éœ²æ»‹ã€‚<br>ä¸å ªç›ˆæ‰‹èµ ï¼Œè¿˜å¯æ¢¦ä½³æœŸã€‚</p><p>é¥å¤œï¼Œé•¿å¤œã€‚</p><p><a href="http://m.xichuangzhu.com/work/57aca120a341310060e2a09f" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aca120a341310060e2a09f</a></p><hr><h3 id="æ— é¢˜"><a href="#æ— é¢˜" class="headerlink" title="æ— é¢˜"></a>æ— é¢˜</h3><p>è¨é•‡å†°<br>äº”åä¸ƒè½½çŠ¹å¦‚æ¢¦ï¼Œä¸¾å›½æ²¦äº¡ç¼˜æ±‰åŸã€‚<br><strong>é¾™æ¸¸æµ…æ°´å‹¿è‡ªå¼ƒï¼Œç»ˆæœ‰æ‰¬çœ‰åæ°”å¤©ã€‚</strong></p><p>1951å¹´ï¼Œä¸­å›½äººæ°‘å¿—æ„¿å†›åœ¨æŠ—ç¾æ´æœæˆ˜äº‰ç¬¬ä¸‰æ¬¡æˆ˜å½¹åæ‰“è¿›äº†æ±‰åŸï¼Œè¨é•‡å†°å¾—çŸ¥æ­¤äº‹ï¼Œå›æƒ³èµ·57å¹´å‰çš„ç”²åˆæ‚²æ­Œï¼Œå½“å³ä½œè¯—ä¸€é¦–ã€‚</p><hr><h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€ã€‚</strong><br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„</strong>ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯7</title>
      <link href="/2018/09/02/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D7/"/>
      <url>/2018/09/02/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D7/</url>
      
        <content type="html"><![CDATA[<h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„é£ã€‚çˆ½ç±å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éã€‚ç¢å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼›é‚ºæ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ã€‚å››ç¾å…·ï¼ŒäºŒéš¾å¹¶ã€‚ç©·ç‡çœ„äºä¸­å¤©ï¼Œæå¨±æ¸¸äºæš‡æ—¥ã€‚å¤©é«˜åœ°è¿¥ï¼Œè§‰å®‡å®™ä¹‹æ— ç©·ï¼›å…´å°½æ‚²æ¥ï¼Œè¯†ç›ˆè™šä¹‹æœ‰æ•°ã€‚æœ›é•¿å®‰äºæ—¥ä¸‹ï¼Œç›®å´ä¼šäºäº‘é—´ã€‚åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œã€‚å…³å±±éš¾è¶Šï¼Œè°æ‚²å¤±è·¯ä¹‹äººï¼›èæ°´ç›¸é€¢ï¼Œå°½æ˜¯ä»–ä¹¡ä¹‹å®¢ã€‚æ€€å¸é˜è€Œä¸è§ï¼Œå¥‰å®£å®¤ä»¥ä½•å¹´ï¼Ÿ</p><hr><p><strong>æ³¨é‡Šï¼š</strong><br>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„ï¼ˆchuÃ¡nï¼‰é£ï¼šç™»é«˜æœ›è¿œçš„èƒ¸æ€€é¡¿æ—¶èˆ’ç•…ï¼Œé£˜æ¬²è„±ä¿—çš„å…´è‡´æ²¹ç„¶è€Œç”Ÿã€‚</p><p>çˆ½ç±ï¼ˆlÃ iï¼‰å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éï¼šå®´ä¼šä¸Šï¼Œæ’ç®«å“èµ·ï¼Œå¥½åƒæ¸…é£æ‹‚æ¥ï¼›æŸ”ç¾çš„æ­Œå£°ç¼­ç»•ä¸æ•£ï¼Œéæ­¢äº†ç™½äº‘é£åŠ¨ã€‚çˆ½ï¼šå½¢å®¹ç±çš„å‘éŸ³æ¸…è„†ã€‚ç±ï¼šæ’ç®«ï¼Œä¸€ç§ç”±å¤šæ ¹ç«¹ç®¡ç¼–æ’è€Œæˆçš„ç®¡ä¹å™¨ã€‚</p><p>ç¢ï¼ˆsuÄ«ï¼‰å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼šä»Šæ—¥çš„å®´ä¼šï¼Œå¥½æ¯”å½“å¹´ç¢å›­ç«¹æ—çš„èšä¼šï¼Œåœ¨åº§çš„æ–‡äººé›…å£«ï¼Œè±ªçˆ½å–„é¥®çš„æ°”æ¦‚è¶…è¿‡äº†é™¶æ¸Šæ˜ã€‚ç¢å›­ï¼šè¥¿æ±‰æ¢å­ç‹åœ¨ç¢æ°´æ—ä¿®å»ºçš„ç«¹å›­ï¼Œä»–å¸¸å’Œä¸€äº›æ–‡äººåœ¨æ­¤é¥®é…’èµ‹è¯—ã€‚</p><p>é‚ºï¼ˆyÃ¨ï¼‰æ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ï¼šè¿™æ˜¯å€Ÿè¯—äººæ›¹æ¤ã€è°¢çµè¿æ¥æ¯”æ‹Ÿå‚åŠ å®´ä¼šçš„æ–‡äººã€‚é‚ºï¼šä»Šæ²³åŒ—ä¸´æ¼³ï¼Œæ˜¯æ›¹é­å…´èµ·çš„åœ°æ–¹ã€‚æ›¹æ¤æ›¾åœ¨è¿™é‡Œä½œè¿‡ã€Šå…¬å®´è¯—ã€‹ï¼Œè¯—ä¸­æœ‰â€œæœ±åå†’ç»¿æ± â€çš„å¥å­ã€‚ä¸´å·ä¹‹ç¬”ï¼šæŒ‡è°¢çµè¿ï¼Œä»–æ›¾ä»»ä¸´å·ï¼ˆä»Šå±æ±Ÿè¥¿ï¼‰å†…å²ã€‚</p><p>å››ç¾ï¼šæŒ‡è‰¯è¾°ã€ç¾æ™¯ã€èµå¿ƒã€ä¹äº‹ã€‚</p><p>äºŒéš¾ï¼šè´¤ä¸»ã€å˜‰å®¾ã€‚</p><p>åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œï¼šåœ°åŠ¿åè¿œï¼Œå—æµ·æ·±é‚ƒï¼›å¤©æŸ±é«˜è€¸ï¼ŒåŒ—ææ˜Ÿè¿œæ‚¬ã€‚</p><p>å¸é˜ï¼ˆhÅ«nï¼‰ï¼šåŸæŒ‡å¤©å¸çš„å®ˆé—¨è€…ã€‚è¿™é‡ŒæŒ‡çš‡å¸çš„å®«é—¨ã€‚</p><p>å¥‰å®£å®¤ä»¥ä½•å¹´ï¼šä»€ä¹ˆæ—¶å€™æ‰èƒ½åƒè´¾è°Šé‚£æ ·å»ä¾å¥‰å›ç‹å‘¢</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†6</title>
      <link href="/2018/09/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%866/"/>
      <url>/2018/09/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%866/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-dropout"><a href="#1ï¸âƒ£-dropout" class="headerlink" title="1ï¸âƒ£[dropout]"></a>1ï¸âƒ£[dropout]</h3><p>dropoutå½¢å¼:<br><img src="/images/2018-09-02-15358857481798.jpg" width="70%" height="50%"><br>RNNçš„å½¢å¼æœ‰å¤šç§ï¼š</p><ul><li><p>recurrent dropout<br>RNN: $h_t=f(W_h âŠ™ [x_t,h_{t-1}]+b_h)$<br>åŠ ä¸Šdropoutçš„RNNï¼š$h_t=f(W_h âŠ™ [x_t,d(h_{t-1})]+b_h)$ï¼Œå…¶ä¸­$d(\cdot)$ä¸ºdropoutå‡½æ•°<br>åŒç†ï¼š<br>LSTM:$c_t=f_t âŠ™c_{t-1} + i_t âŠ™ d(g_t)$<br>GRU:$h_t=(1-z_t)âŠ™c_{t-1}+z_tâŠ™d(g_t)$</p></li><li><p>å‚ç›´è¿æ¥çš„dropout<br>dropoutçš„ä½œç”¨å³æ˜¯å¦å…è®¸Lå±‚æŸä¸ªLSTMå•å…ƒçš„éšçŠ¶æ€ä¿¡æ¯æµå…¥L+1å±‚å¯¹åº”å•å…ƒã€‚<br><img src="/images/2018-09-02-15358866404870.jpg" width="50%" height="50%"></p></li></ul><p>Reference:<br><a href="https://blog.csdn.net/falianghuang/article/details/72910161" target="_blank" rel="noopener">https://blog.csdn.net/falianghuang/article/details/72910161</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>pack_padded_sequenceç”¨äºRNNä¸­ï¼Œå°†paddingçŸ©é˜µå‹ç¼©:<br><img src="/images/2018-09-02-15358868858836.jpg" width="60%" height="50%"><br>è¿™æ ·å°±å¯ä»¥å®ç°åœ¨RNNä¼ è¾“è¿‡ç¨‹ä¸­çŸ­å¥æå‰ç»“æŸã€‚</p><p>pad_packed_sequenceæ˜¯pack_padded_sequenceçš„é€†è¿ç®—ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> dropout </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æˆ‘æ²¡æœ‰è¯´è¯</title>
      <link href="/2018/08/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%88%91%E6%B2%A1%E6%9C%89%E8%AF%B4%E8%AF%9D/"/>
      <url>/2018/08/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%88%91%E6%B2%A1%E6%9C%89%E8%AF%B4%E8%AF%9D/</url>
      
        <content type="html"><![CDATA[<p>ã€Šæˆ‘æ²¡æœ‰è¯´è¯ã€‹</p><p>çº³ç²¹æ€å…±äº§å…šæ—¶ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å…±äº§å…šå‘˜ï¼›<br>æ¥ç€ä»–ä»¬è¿«å®³çŠ¹å¤ªäººï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯çŠ¹å¤ªäººï¼›<br>ç„¶åä»–ä»¬æ€å·¥ä¼šæˆå‘˜ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å·¥ä¼šæˆå‘˜ï¼›<br>åæ¥ä»–ä»¬è¿«å®³å¤©ä¸»æ•™å¾’ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘æ˜¯æ–°æ•™å¾’ï¼›<br>æœ€åå½“ä»–ä»¬å¼€å§‹å¯¹ä»˜æˆ‘çš„æ—¶å€™ï¼Œ<br>å·²ç»æ²¡æœ‰äººèƒ½ç«™å‡ºæ¥ä¸ºæˆ‘å‘å£°äº†</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep Learning NLP best practicesç¬”è®°</title>
      <link href="/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Deep%20Learning%20NLP%20best%20practices%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Deep%20Learning%20NLP%20best%20practices%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>åšå®¢åœ°å€ï¼š<a href="http://ruder.io/deep-learning-nlp-best-practices/index.html" target="_blank" rel="noopener">http://ruder.io/deep-learning-nlp-best-practices/index.html</a><br>ä¸ªäººè§‰å¾—è¿™ç¯‡æ–‡ç« å†™å¾—å¾ˆå¥½ï¼Œæœ‰è®¸å¤šå®è·µå¾—åˆ°çš„ç»éªŒï¼Œé€šè¿‡è¿™ç¯‡å¯ä»¥é¿å…èµ°ä¸€äº›å¼¯è·¯ã€‚</p><h2 id="Practices"><a href="#Practices" class="headerlink" title="Practices"></a>Practices</h2><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><blockquote><p>The optimal dimensionality of word embeddings is mostly task-dependent: a smaller dimensionality works better for more syntactic tasks such as named entity recognition or part-of-speech (POS) tagging, while a larger dimensionality is more useful for more semantic tasks such as sentiment analysis.</p></blockquote><p>å¯¹äºåå‘è¯­æ³•çš„ï¼Œä½¿ç”¨ç»´åº¦ä½ä¸€äº›çš„è¯å‘é‡ï¼›è€Œå¯¹äºåå‘è¯­ä¹‰å†…å®¹çš„ï¼Œä½¿ç”¨ç»´åº¦å¤§ä¸€äº›çš„è¯å‘é‡ï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€‚</p><h3 id="LSTM-Depth"><a href="#LSTM-Depth" class="headerlink" title="LSTM Depth"></a>LSTM Depth</h3><blockquote><p>performance improvements of making the model deeper than 2 layers are minimal </p></blockquote><p>LSTMæ·±åº¦æœ€å¥½ä¸è¦è¶…è¿‡ä¸¤å±‚ã€‚</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><blockquote><p>It is often thought that Adam clearly outperforms vanilla stochastic gradient descent (SGD). However, while it converges much faster than SGD, it has been observed that SGD with learning rate annealing slightly outperforms Adam. Recent work furthermore shows that SGD with properly tuned momentum outperforms Adam .</p></blockquote><p>Adamå¯ä»¥æ›´æ—©æ‹Ÿåˆï¼Œè€ŒSGDæ•ˆæœå¯èƒ½ä¼šæ›´å¥½ä¸€äº›ã€‚</p><p>å¯ä»¥é‡‡ç”¨ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨Adamè®­ç»ƒç›´åˆ°æ‹Ÿåˆï¼Œç„¶åå°†å­¦ä¹ ç‡å‡åŠï¼Œå¹¶é‡æ–°å¯¼å…¥ä¹‹å‰è®­ç»ƒå¥½çš„æœ€å¥½çš„æ¨¡å‹ã€‚è¿™æ ·Adamèƒ½å¤Ÿå¿˜è®°ä¹‹å‰çš„ä¿¡æ¯å¹¶é‡æ–°å¼€å§‹è®­ç»ƒã€‚</p><blockquote><p>Denkowski &amp; Neubig (2017) show that Adam with 2 restarts and learning rate annealing is faster and performs better than SGD with annealing</p></blockquote><h3 id="Ensembling"><a href="#Ensembling" class="headerlink" title="Ensembling"></a>Ensembling</h3><blockquote><p>Combining multiple models into an ensemble by averaging their predictions is a proven strategy to improve model performance.</p></blockquote><p>Ensemblingå¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯éœ€è¦ä¿è¯å¤šæ ·æ€§ï¼š</p><blockquote><p>Ensembling is an important way to ensure that results are still reliable if the diversity of the evaluated models increases (Denkowski &amp; Neubig, 2017). While ensembling different checkpoints of a model has been shown to be effective (Jean et al., 2015; Sennrich et al., 2016) [51, 52], it comes at the cost of model diversity. Cyclical learning rates can help to mitigate this effect</p></blockquote><h3 id="LSTM-tricks"><a href="#LSTM-tricks" class="headerlink" title="LSTM tricks"></a>LSTM tricks</h3><ul><li><p>åœ¨initial stateä¸­æˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨å…¨0å‘é‡ï¼Œå®é™…ä¸Šå¯ä»¥å°†å…¶ä½œä¸ºå‚æ•°å­¦ä¹ ã€‚</p><blockquote><p>Instead of fixing the initial state, we can learn it like any other parameter, which can improve performance</p></blockquote></li><li><p>å°†inputå’Œoutput embeddingçš„å‚æ•°å…±äº«ï¼Œå¦‚æœæ˜¯åšlanguage modelæˆ–è€…æœºå™¨ç¿»è¯‘ä¹‹ç±»çš„ï¼Œå¯ä»¥è®©ä»–ä»¬å…±äº«ã€‚</p></li><li><p>Gradient Norm Clipping</p><blockquote><p>Rather than clipping each gradient independently, clipping the global norm of the gradient yields more significant improvements</p></blockquote></li></ul><p>è¿™ç‚¹æˆ‘æ²¡çœ‹æ‡‚ã€‚</p><h3 id="Classification-practices"><a href="#Classification-practices" class="headerlink" title="Classification practices"></a>Classification practices</h3><p>å…³äºCNN</p><blockquote><p>CNN filters:Combining filter sizes near the optimal filter size, e.g. (3,4,5) performs best (Kim, 2014; Kim et al., 2016). The optimal number of feature maps is in the range of 50-600 (Zhang &amp; Wallace, 2015) [59].</p><p>Aggregation function:1-max-pooling outperforms average-pooling and k-max pooling (Zhang &amp; Wallace, 2015).</p></blockquote><p>è¿™åœ¨æˆ‘ä¹‹å‰çš„å…³äºCNNæ–‡æœ¬åˆ†ç±»æŒ‡å—ä¸­æœ‰æ›´è¯¦å°½çš„åˆ†æã€‚</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>è¿™æ˜¯ä¸€ç¯‡å¹²è´§æ»¡æ»¡çš„åšå®¢ï¼Œå®é™…ä¸Šæˆ‘è¿˜æ˜¯æœ‰è®¸å¤šåœ°æ–¹æ²¡æœ‰è¯»æ‡‚ï¼Œè¿™é€‚åˆå¤šçœ‹å‡ éï¼Œæ…¢æ…¢ç†è§£ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æŒ‡å— </tag>
            
            <tag> è°ƒå‚ </tag>
            
            <tag> NLPğŸ¤– </tag>
            
            <tag> ç¬”è®°ğŸ“’ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†5</title>
      <link href="/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%865/"/>
      <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%865/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Paper]<br>Joint Embeddings of Chinese Words, Characters, and Fine-grained Subcharacter Components</p><p>åŸºæœ¬æ¡†æ¶å’ŒCBOWä¸€è‡´ï¼Œä¸»è¦è´¡çŒ®åœ¨äºé’ˆå¯¹ä¸­æ–‡è¯å‘é‡æ·»åŠ äº†åæ—ã€å­—çš„ç»„ä»¶ä½œä¸ºè®­ç»ƒä¿¡æ¯ã€‚</p><p><img src="/images/2018-08-26-15352530482345.jpg" width="50%" height="50%"></p><hr><p>2ï¸âƒ£[Paper]<br>Highway Networks</p><p>ä¸ºäº†è§£å†³ç¥ç»ç½‘ç»œæ·±åº¦è¿‡æ·±æ—¶å¯¼è‡´çš„åå‘ä¼ æ’­å›°éš¾çš„é—®é¢˜ã€‚<br>å‰å‘ä¼ æ’­çš„å…¬å¼ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H)</script><p>è€Œè®ºæ–‡æ‰€åšçš„æ”¹è¿›ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot C(x,W_C)</script><p>å…¶ä¸­$T$æ˜¯transform gateï¼Œ$C$æ˜¯carry gateã€‚æ–¹ä¾¿èµ·è§ï¼Œå¯ä»¥å°† $C=1-T$ï¼Œæœ€ç»ˆæœ‰ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot (1-T(x,W_T))</script><p>å¯ä»¥çœ‹å‡ºæ€æƒ³å’ŒLSTMå¾ˆç±»ä¼¼ï¼Œéƒ½æ˜¯gateçš„æ€æƒ³ã€‚</p><hr><p>3ï¸âƒ£[è°ƒå‚æ–¹æ³•]<br>åšå®¢ï¼š<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41</a></p><ul><li><strong>å­¦ä¹ ç‡</strong>ï¼š</li></ul><p>ä¸€æ¡åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚</p><p>å¦‚ä½•å‡å°‘ï¼Ÿ</p><p><img src="/images/2018-08-26-15352871548330.jpg" width="50%" height="50%"></p><p>æˆ–è€…ï¼š</p><p><img src="/images/2018-08-26-15352873283890.jpg" width="50%" height="50%"><br>è®¾å®šä¸€å®šçš„epochä½œä¸ºä¸€ä¸ªstepsizeï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çº¿æ€§å¢åŠ å­¦ä¹ ç‡ï¼Œç„¶ååœ¨åˆ°è¾¾æœ€å¤§å€¼åå†çº¿æ€§å‡å°ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ–¹æ³•å¯ä»¥åœ¨ä¸€åŠçš„epochå†…è¾¾åˆ°ç›¸åŒçš„æ•ˆæœã€‚</p><ul><li><strong>batch size</strong>ï¼š</li></ul><p><img src="/images/2018-08-26-15352891425729.jpg" width="50%" height="50%"></p><p>ç”±äºbatch sizeå’Œå­¦ä¹ ç‡çš„å¼ºç›¸å…³æ€§ï¼Œ<a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">ç›¸å…³è®ºæ–‡</a>æå‡ºæé«˜batch sizeè€Œä¸æ˜¯é™ä½å­¦ä¹ ç‡çš„æ–¹æ³•æ¥æå‡æ¨¡å‹è¡¨ç°ã€‚</p><blockquote><p>increasing the batch size during training, instead of decaying learning rate.â€Šâ€”â€ŠL. Smith<br><a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.00489.pdf</a></p></blockquote><p>ä¸€ä¸ªtrickï¼šä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Paper </tag>
            
            <tag> è°ƒå‚æ–¹æ³• </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•6</title>
      <link href="/2018/08/26/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB6/"/>
      <url>/2018/08/26/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB6/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"><a href="#1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch" class="headerlink" title="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"></a>1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_iter_batch</span><span class="params">(paras,labels,batch_size,shuffle=True)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param paras:</span></span><br><span class="line"><span class="string">    :param labels:</span></span><br><span class="line"><span class="string">    :param batch_size:</span></span><br><span class="line"><span class="string">    :param shuffle:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> len(paras)==len(labels)</span><br><span class="line">    paras_size=len(paras)</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        indices=np.arange(paras_size)</span><br><span class="line">        np.random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> range(<span class="number">0</span>,paras_size-batch_size+<span class="number">1</span>,batch_size):</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            excerpt=indices[start_idx:start_idx+batch_size]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            excerpt=slice(start_idx,start_idx+batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> paras[excerpt],labels[excerpt]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯6</title>
      <link href="/2018/08/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D6/"/>
      <url>/2018/08/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D6/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£</p><h3 id="æˆä¸ºå…­ç»å¥"><a href="#æˆä¸ºå…­ç»å¥" class="headerlink" title="æˆä¸ºå…­ç»å¥"></a>æˆä¸ºå…­ç»å¥</h3><p>[å”] æœç”«<br>ã€å…¶äºŒã€‘<br>ç‹æ¨å¢éª†å½“æ—¶ä½“ï¼Œè½»è–„ä¸ºæ–‡å“‚æœªä¼‘ã€‚<br><strong>å°”æ›¹èº«ä¸åä¿±ç­ï¼Œä¸åºŸæ±Ÿæ²³ä¸‡å¤æµ</strong>ã€‚</p><p>å“‚ï¼ˆshÄ›nï¼‰ï¼šè®¥ç¬‘ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNNæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—</title>
      <link href="/2018/08/25/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/CNN%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8C%87%E5%8D%97/"/>
      <url>/2018/08/25/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/CNN%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘å› ä¸ºæ¯”èµ›çš„ç¼˜æ•…å¯¹æ–‡æœ¬åˆ†ç±»æœ‰ä¸€å®šçš„äº†è§£ã€‚å…¶ä¸­ä½¿ç”¨CNNæ–¹æ³•åšæƒ…æ„Ÿåˆ†æä»»åŠ¡å­˜åœ¨ç€è®¸å¤šä¼˜åŠ¿ã€‚è™½ç„¶æ¨¡å‹ç®€å•ï¼Œä½†å¦‚ä½•è®¾ç½®è¶…å‚æœ‰æ—¶å€™å¯¹ç»“æœæœ‰å¾ˆå¤§çš„å½±å“ã€‚æœ¬æ–‡è®°å½•äº†å…³äºCNNæ–‡æœ¬åˆ†ç±»çš„ä¸€äº›å­¦ä¹ å†ç¨‹å’ŒæŒ‡å—ï¼ŒåŸºæœ¬å‚è€ƒäº†è®ºæ–‡ã€‚</p><h2 id="åšæ³•"><a href="#åšæ³•" class="headerlink" title="åšæ³•"></a>åšæ³•</h2><p>åŸºæœ¬ä¸Šç›®å‰è¾ƒä¸ºæµ…å±‚çš„CNNæ–‡æœ¬åˆ†ç±»çš„åšæ³•éƒ½æ˜¯å¦‚ä¸‹å›¾ï¼š<br><img src="/images/2018-08-25-15351860103617.jpg" alt=""></p><p>å°†è¯å‘é‡å †ç§¯æˆä¸ºäºŒç»´çš„çŸ©é˜µï¼Œé€šè¿‡CNNçš„å·ç§¯å•å…ƒå¯¹çŸ©é˜µè¿›è¡Œå·ç§¯å¤„ç†ï¼ŒåŒæ—¶ä½¿ç”¨poolingï¼ˆé€šå¸¸æ˜¯1max-poolingï¼‰æ“ä½œï¼Œå°†ä¸ç­‰é•¿çš„å·ç§¯ç»“æœå˜ä¸ºç­‰é•¿ï¼Œå¯¹ä¸åŒçš„å·ç§¯å•å…ƒçš„ç»“æœè¿›è¡Œæ‹¼æ¥åç”Ÿæˆå•ä¸ªå‘é‡ï¼Œæœ€åå†é€šè¿‡çº¿æ€§å±‚è½¬åŒ–æˆç±»åˆ«æ¦‚ç‡åˆ†å¸ƒã€‚</p><p>å¦ä¸€å¼ å›¾ä¹Ÿè¯´æ˜äº†è¯¥æµç¨‹ã€‚</p><p><img src="/images/2018-08-25-15351863867337.jpg" alt=""></p><h2 id="å»ºè®®ä¸æŒ‡å¯¼"><a href="#å»ºè®®ä¸æŒ‡å¯¼" class="headerlink" title="å»ºè®®ä¸æŒ‡å¯¼"></a>å»ºè®®ä¸æŒ‡å¯¼</h2><h3 id="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"><a href="#è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“" class="headerlink" title="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"></a>è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“</h3><p>æ¥ä¸‹æ¥çš„å†…å®¹å‚è€ƒäº†è®ºæ–‡<a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p><p>CNNæ–‡æœ¬åˆ†ç±»çš„è¶…å‚ï¼š</p><ul><li>è¾“å…¥å‘é‡</li><li>å·ç§¯å¤§å°</li><li>è¾“å‡ºé€šé“ï¼ˆfeature mapsï¼‰</li><li>æ¿€æ´»å‡½æ•°</li><li>æ± åŒ–ç­–ç•¥</li><li>æ­£åˆ™åŒ–</li></ul><h4 id="è¾“å…¥å‘é‡çš„å½±å“"><a href="#è¾“å…¥å‘é‡çš„å½±å“" class="headerlink" title="è¾“å…¥å‘é‡çš„å½±å“"></a>è¾“å…¥å‘é‡çš„å½±å“</h4><p>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨word2vecå’ŒGloVeä¸åˆ†ä¼¯ä»²ï¼Œä½†å°†word2vecå’ŒGloVeç®€å•æ‹¼æ¥åœ¨ä¸€èµ·å¹¶ä¸èƒ½å¸¦æ¥æå‡ã€‚</p><blockquote><p>unfortunately, simply concatenating these representations does necessarily seem helpful</p></blockquote><p>å½“å¥å­é•¿åº¦å¾ˆé•¿ï¼ˆdocument classificationï¼‰æ—¶ï¼Œä½¿ç”¨one-hotå¯èƒ½ä¼šæœ‰æ•ˆæœï¼Œä½†åœ¨å¥å­é•¿åº¦ä¸æ˜¯å¾ˆé•¿æ—¶ï¼Œæ•ˆæœä¸å¥½ã€‚</p><h5 id="å»ºè®®"><a href="#å»ºè®®" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>å¯¹äºæ–°ä»»åŠ¡ï¼Œå¯ä»¥word2vecæˆ–GloVeæˆ–è€…å…¶ä»–è¯å‘é‡éƒ½è¯•ä¸€ä¸‹ï¼Œå¦‚æœå¥å­é•¿ï¼Œå¯ä»¥è¯•ç€ä½¿ç”¨one-hotã€‚</p><h4 id="å·ç§¯å¤§å°"><a href="#å·ç§¯å¤§å°" class="headerlink" title="å·ç§¯å¤§å°"></a>å·ç§¯å¤§å°</h4><p>ç”±äºå·ç§¯çš„é•¿åº¦æ˜¯å›ºå®šçš„ï¼Œä¹Ÿå°±æ˜¯è¯å‘é‡çš„é•¿åº¦ï¼Œå› æ­¤åªéœ€è®¨è®ºå®½åº¦ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä¸åŒçš„æ•°æ®é›†ä¼šæœ‰ä¸åŒçš„æœ€ä½³å¤§å°ï¼Œä½†ä¼¼ä¹å¯¹äºé•¿åº¦è¶Šé•¿çš„å¥å­ï¼Œæœ€ä½³å¤§å°æœ‰è¶Šå¤§çš„è¶‹åŠ¿ã€‚</p><blockquote><p>However, for datasets comprising longer sentences, such as CR (maximum sentence length is 105, whereas it ranges from 36-56 on the other sentiment datasets used here), the optimal region size may be larger.</p></blockquote><p>åŒæ—¶ï¼Œå½“å¢åŠ ä¸åŒå·ç§¯å¤§å°ä½œä¸ºç»„åˆæ—¶ï¼Œå¦‚æœç»„åˆçš„å·ç§¯æ ¸å¤§å°æ¥è¿‘äºæœ€ä½³å¤§å°ï¼ˆoptimal region sizeï¼‰ï¼Œæœ‰åŠ©äºç»“æœçš„æå‡ï¼›ç›¸åï¼Œå¦‚æœå·ç§¯æ ¸å¤§å°ç¦»æœ€ä½³å¤§å°å¾ˆè¿œæ—¶ï¼Œåè€Œä¼šäº§ç”Ÿè´Ÿé¢å½±å“ã€‚</p><h5 id="å»ºè®®-1"><a href="#å»ºè®®-1" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>é¦–å…ˆè¯•ç€æ‰¾åˆ°æœ€ä¼˜çš„å·ç§¯æ ¸å¤§å°ï¼Œç„¶ååœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ å’Œè¯¥å·ç§¯æ ¸å¤§å°ç±»ä¼¼çš„å·ç§¯æ ¸ã€‚</p><h4 id="feature-maps"><a href="#feature-maps" class="headerlink" title="feature maps"></a>feature maps</h4><p>ä¹Ÿå°±æ˜¯è¾“å‡ºé€šé“ï¼ˆout channelï¼‰ï¼Œè¡¨æ˜è¯¥å·ç§¯æ ¸å¤§å°çš„å·ç§¯æ ¸æœ‰å¤šå°‘ä¸ªã€‚</p><p>å®éªŒè¡¨æ˜ï¼Œæœ€ä½³çš„feature mapså’Œæ•°æ®é›†ç›¸å…³ï¼Œä½†ä¸€èˆ¬ä¸è¶…è¿‡600ã€‚</p><blockquote><p>it would seem that increasing the number of maps beyond 600 yields at best very marginal returns, and often hurts performance.</p></blockquote><h5 id="å»ºè®®-2"><a href="#å»ºè®®-2" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>åœ¨600å†…æœç´¢æœ€ä¼˜ï¼Œå¦‚æœåœ¨600çš„è¾¹ç¼˜è¿˜æ²¡æœ‰æ˜æ˜¾çš„æ•ˆæœä¸‹é™ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•å¤§äº600çš„feature mapsã€‚</p><h4 id="æ¿€æ´»å‡½æ•°"><a href="#æ¿€æ´»å‡½æ•°" class="headerlink" title="æ¿€æ´»å‡½æ•°"></a>æ¿€æ´»å‡½æ•°</h4><p>å®éªŒç»“æœï¼š<br><img src="/images/2018-08-25-15351889835594.jpg" alt=""></p><p>ç»“æœè¡¨æ˜ï¼Œtanhã€ReLUå’Œä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°æ•ˆæœè¾ƒå¥½ã€‚tanhçš„ä¼˜ç‚¹æ˜¯ä»¥0ä¸ºä¸­å¿ƒï¼ŒReLUèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œè‡³äºä¸ºä»€ä¹ˆä¸ä½¿ç”¨çš„æ•ˆæœä¼šå¥½ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹è¾ƒä¸ºç®€å•ï¼š</p><blockquote><p>This indicates that on some datasets, a linear transformation is enough to capture the<br>correlation between the word embedding and the output label.</p></blockquote><h5 id="å»ºè®®-3"><a href="#å»ºè®®-3" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>ä½¿ç”¨tanhã€ReLUæˆ–è€…å¹²è„†ä¸ä½¿ç”¨ã€‚ä½†å¦‚æœæ¨¡å‹æ›´ä¸ºå¤æ‚ï¼Œæœ‰å¤šå±‚çš„ç»“æ„ï¼Œè¿˜æ˜¯éœ€è¦ä½¿ç”¨æ¿€æ´»å‡½æ•°çš„ã€‚</p><h4 id="poolingç­–ç•¥"><a href="#poolingç­–ç•¥" class="headerlink" title="poolingç­–ç•¥"></a>poolingç­–ç•¥</h4><p>æ‰€æœ‰çš„å®éªŒéƒ½è¡¨æ˜äº†ï¼Œ1-max poolingçš„æ•ˆæœæ¯”å…¶ä»–å¥½ï¼Œå¦‚k-max poolingã€‚åœ¨poolingè¿™ä¸€æ­¥å¯ä»¥ç›´æ¥é€‰æ‹©1-max poolingã€‚</p><blockquote><p>This may be because the location of predictive contexts does not matter, and certain n-grams in the sentence can be more predictive on their own than the entire sentence considered jointly.</p></blockquote><h4 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h4><p>ä¸»è¦æ˜¯dropoutå’Œl2 norm constraintã€‚<br>dropoutå°±æ˜¯éšæœºå°†ä¸€äº›ç¥ç»å…ƒç½®ä¸º0ï¼Œl2 norm constraintæ˜¯å¯¹å‚æ•°çŸ©é˜µWè¿›è¡Œæ•´ä½“ç¼©æ”¾ï¼Œä½¿å…¶ä¸è¶…è¿‡ä¸€å®šé˜ˆå€¼ã€‚ï¼ˆä¸é€šå¸¸çš„l2 regularizationä¸åŒï¼Œæœ€æ—©å¯è¿½æº¯åˆ°Hintonçš„<a href="https://arxiv.org/pdf/1207.0580.pdf" target="_blank" rel="noopener">Improving neural networks by preventing<br>co-adaptation of feature detectors</a>ï¼‰</p><blockquote><p>the l2 norm of a weight vector is linearly scaled to a constraint c when it exceeds this threshold, so a smaller c implies stronger regularization</p></blockquote><p>å®éªŒè¡¨æ˜ï¼Œdropoutèµ·çš„ä½œç”¨å¾ˆå°ï¼Œl2 normæ²¡æœ‰æå‡ç”šè‡³è¿˜ä¼šå¯¼è‡´ä¸‹é™ã€‚å¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å‚æ•°ä¸å¤šï¼Œå› æ­¤è¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§è¾ƒä½ã€‚</p><h5 id="å»ºè®®-4"><a href="#å»ºè®®-4" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>è®¾ç½®è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„l2 normï¼Œå½“feature mapså¢å¤§æ—¶ï¼Œå¯ä»¥è¯•ç€è°ƒèŠ‚è¾ƒå¤§çš„dropoutä»¥é¿å…è¿‡æ‹Ÿåˆã€‚</p><h3 id="å»ºè®®åŠç»“è®º"><a href="#å»ºè®®åŠç»“è®º" class="headerlink" title="å»ºè®®åŠç»“è®º"></a>å»ºè®®åŠç»“è®º</h3><ul><li>åˆšå¼€å§‹çš„ä½¿ç”¨ä½¿ç”¨word2vecæˆ–è€…GloVeï¼Œå¦‚æœæ•°æ®é‡å¤Ÿå¤§ï¼Œå¯ä»¥å°è¯•one-hot</li><li>çº¿æ€§æœç´¢æœ€ä½³çš„å·ç§¯æ ¸å¤§å°ï¼Œå¦‚æœå¥å­å¤Ÿé•¿ï¼Œé‚£ä¹ˆå¯ä»¥æ‰©å¤§æœç´¢èŒƒå›´ã€‚ä¸€æ—¦ç¡®å®šäº†æœ€ä½³å·ç§¯æ ¸å¤§å°ï¼Œå°è¯•åœ¨è¯¥å·ç§¯æ ¸å¤§å°çš„é™„è¿‘è¿›è¡Œç»„åˆï¼Œå¦‚æœ€ä½³å·ç§¯æ ¸å®½åº¦æ˜¯5ï¼Œé‚£ä¹ˆå°è¯•[3,4,5]æˆ–è€…[2,3,4,5]ç­‰</li><li>ä½¿ç”¨è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„max norm constraintï¼Œç„¶ååœ¨[100,600]èŒƒå›´å†…æœç´¢feature mapsï¼Œå¦‚æœæœ€ä½³çš„feature mapsåœ¨600é™„è¿‘ï¼Œå¯ä»¥è¯•ç€é€‰æ‹©æ¯”600æ›´å¤§çš„èŒƒå›´</li><li>å°è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸tanhå’ŒReLUæ˜¯è¾ƒå¥½çš„ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•ä»€ä¹ˆéƒ½ä¸åŠ ã€‚</li><li>ä½¿ç”¨1-max poolingã€‚</li><li>å¦‚æœæ¨¡å‹å¤æ‚ï¼Œæ¯”å¦‚feature mapså¾ˆå¤§ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•æ›´ä¸ºä¸¥æ ¼çš„æ­£åˆ™åŒ–ï¼Œå¦‚æ›´å¤§çš„dropout rateå’Œè¾ƒå°çš„max norm constraintã€‚</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://www.aclweb.org/anthology/D14-1181" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></p><p><a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> æƒ…æ„Ÿåˆ†æ </tag>
            
            <tag> æŒ‡å— </tag>
            
            <tag> è°ƒå‚ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­çš„inplaceçš„æ“ä½œ</title>
      <link href="/2018/08/20/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADin-place%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/08/20/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADin-place%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘åœ¨å†™Hierarchical attention networkçš„æ—¶å€™é‡åˆ°äº†å¦‚ä¸‹çš„bugï¼š</p><blockquote><p>one of the variables needed for gradient computation has been modified by an inplace operation</p></blockquote><p>åœ¨æŸ¥é˜…äº†æ–‡æ¡£å’Œè¯·æ•™äº†å…¶ä»–äººä¹‹åï¼Œæœ€ç»ˆæ‰¾åˆ°äº†bugã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze_(<span class="number">1</span>)  <span class="comment"># take in-place opt may cause an error</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure><p>è¿™æ˜¯æˆ‘åŸæ¥çš„é€»è¾‘ï¼Œæˆ‘åœ¨æ— æ„ä¸­åšäº†inplaceæ“ä½œï¼Œå¯¼è‡´äº†bugçš„å‘ç”Ÿã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    <span class="comment"># a_i = attn_weights[i].unsqueeze_(1)  # take in-place opt may cause an error</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze(<span class="number">1</span>)  <span class="comment"># batch,1</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure><p>å®é™…ä¸Šï¼Œåœ¨å®è·µè¿‡ç¨‹ä¸­åº”å½“å°½é‡é¿å…inplaceæ“ä½œï¼Œåœ¨å®˜æ–¹æ–‡æ¡£ä¸­ä¹Ÿæåˆ°äº†ï¼ˆå­˜ç–‘ï¼‰è¿™ç‚¹ï¼Œè™½ç„¶æä¾›äº†inplaceæ“ä½œï¼Œä½†å¹¶ä¸æ¨èä½¿ç”¨ã€‚</p><p>å…·ä½“çš„åŸå› æ˜¯ï¼Œåœ¨Pytorchæ„å»ºè®¡ç®—å›¾çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®°å½•æ¯ä¸ªèŠ‚ç‚¹æ˜¯æ€ä¹ˆæ¥çš„ï¼Œä½†inplaceä¼šç ´åè¿™ç§å…³ç³»ï¼Œä½¿å¾—åœ¨å›ä¼ çš„æ—¶å€™æ²¡æ³•æ­£å¸¸æ±‚å¯¼ã€‚</p><p>ç‰¹åˆ«åœ°ï¼Œæœ‰ä¸¤ç§æƒ…å†µä¸åº”è¯¥ä½¿ç”¨inplaceæ“ä½œï¼ˆæ‘˜è‡ªçŸ¥ä¹ï¼‰ï¼š</p><ol><li>å¯¹äºrequires_grad=Trueçš„å¶å­å¼ é‡(leaf tensor)ä¸èƒ½ä½¿ç”¨inplace operation</li><li>å¯¹äºåœ¨æ±‚æ¢¯åº¦é˜¶æ®µéœ€è¦ç”¨åˆ°çš„å¼ é‡ä¸èƒ½ä½¿ç”¨inplace operation</li></ol><p>Reference:<br><a href="https://zhuanlan.zhihu.com/p/38475183" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38475183</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”</title>
      <link href="/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%84%BF%E4%B8%AD%E5%9B%BD%E9%9D%92%E5%B9%B4%E9%83%BD%E6%91%86%E8%84%B1%E5%86%B7%E6%B0%94/"/>
      <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%84%BF%E4%B8%AD%E5%9B%BD%E9%9D%92%E5%B9%B4%E9%83%BD%E6%91%86%E8%84%B1%E5%86%B7%E6%B0%94/</url>
      
        <content type="html"><![CDATA[<p>è¿‘æœŸçš„æ–°é—»å¸¸è®©äººæ„Ÿåˆ°æ„¤æ€’ä»¥è‡´ç»æœ›â€¦</p><hr><p>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”ï¼Œåªæ˜¯å‘ä¸Šèµ°ï¼Œä¸å¿…å¬è‡ªæš´è‡ªå¼ƒè€…æµçš„è¯ã€‚èƒ½åšäº‹çš„åšäº‹ï¼Œèƒ½å‘å£°çš„å‘å£°ã€‚æœ‰ä¸€åˆ†çƒ­ï¼Œå‘ä¸€åˆ†å…‰ã€‚å°±ä»¤è¤ç«ä¸€èˆ¬ï¼Œä¹Ÿå¯ä»¥åœ¨é»‘æš—é‡Œå‘ä¸€ç‚¹å…‰ï¼Œä¸å¿…ç­‰å€™ç‚¬ç«ã€‚</p><p>â€”é²è¿…ã€Šçƒ­é£ã€‹</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•5</title>
      <link href="/2018/08/19/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB5/"/>
      <url>/2018/08/19/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB5/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"><a href="#1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤" class="headerlink" title="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"></a>1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">clf = svm.SVC()</span><br><span class="line">clf.fit(X, y)  </span><br><span class="line">clf.fit(train_X,train_y)</span><br><span class="line">joblib.dump(clf, <span class="string">"train_model.m"</span>)</span><br><span class="line">clf = joblib.load(<span class="string">"train_model.m"</span>)</span><br><span class="line">clf.predit(test_X)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£Dictionaryç±»"><a href="#2ï¸âƒ£Dictionaryç±»" class="headerlink" title="2ï¸âƒ£Dictionaryç±»"></a>2ï¸âƒ£Dictionaryç±»</h3><p>åœ¨æ„é€ å­—å…¸æ—¶éœ€è¦ç”¨åˆ°<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)</span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_word</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            self.idx2word.append(word)</span><br><span class="line">            self.word2idx[word] = self.__vocab_size</span><br><span class="line">            self.__vocab_size += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_index</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[word]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[<span class="string">'&lt;UNK&gt;'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_word</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.idx2word[idx]</span><br></pre></td></tr></table></figure></p><hr><h3 id="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"><a href="#3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"></a>3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;<span class="string">'apple'</span>:<span class="number">10</span>,<span class="string">'orange'</span>:<span class="number">20</span>,<span class="string">'banana'</span>:<span class="number">5</span>,<span class="string">'watermelon'</span>:<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line">print(sorted(d.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"></span><br><span class="line">print(sorted(d.items(),key=itemgetter(<span class="number">1</span>))) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"></span><br><span class="line">print(sorted(d,key=d.get))  <span class="comment">#['watermelon', 'banana', 'apple', 'orange'] æ²¡æœ‰valueäº†</span></span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"><a href="#4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"></a>4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1=&#123;<span class="string">'a'</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d2=&#123;<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d=&#123;**d1,**d2&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd=dict(d1.items()|d2.items())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1.update(d2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"><a href="#5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index" class="headerlink" title="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"></a>5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lst = [<span class="number">40</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> min(range(len(lst)),key=lst.__getitem__)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> max(range(len(lst)),key=lst.__getitem__)</span><br><span class="line">    </span><br><span class="line">print(minIndex(lst))</span><br><span class="line">print(maxIndex(lst))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­çš„Embedding padding</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADEmbedding%E7%9A%84padding/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADEmbedding%E7%9A%84padding/</url>
      
        <content type="html"><![CDATA[<p>åœ¨Pytorchä¸­ï¼Œnn.Embedding()ä»£è¡¨embeddingçŸ©é˜µï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªå‚æ•°<code>padding_idx</code>æŒ‡å®šç”¨ä»¥paddingçš„ç´¢å¼•ä½ç½®ã€‚æ‰€è°“paddingï¼Œå°±æ˜¯åœ¨å°†ä¸ç­‰é•¿çš„å¥å­ç»„æˆä¸€ä¸ªbatchæ—¶ï¼Œå¯¹é‚£äº›ç©ºç¼ºçš„ä½ç½®è¡¥0ï¼Œä»¥å½¢æˆä¸€ä¸ªç»Ÿä¸€çš„çŸ©é˜µã€‚</p><p>ç”¨æ³•ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>) <span class="comment">#ä¹Ÿå¯ä»¥æ˜¯åˆ«çš„æ•°å€¼</span></span><br></pre></td></tr></table></figure></p><p>åœ¨æ˜¾å¼è®¾å®š<code>padding_idx=0</code>åï¼Œåœ¨è‡ªå®šä¹‰çš„è¯å…¸å†…ä¹Ÿåº”å½“åœ¨ç›¸åº”ä½ç½®æ·»åŠ <code>&lt;pad&gt;</code>ä½œä¸ºä¸€ä¸ªè¯ã€‚å¦‚ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)  <span class="comment"># should add &lt;pad&gt; first</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br></pre></td></tr></table></figure><p>é‚£ä¹ˆå¯¹äº<code>padding_idx</code>ï¼Œå†…éƒ¨æ˜¯å¦‚ä½•æ“ä½œçš„å‘¢ï¼Ÿ</p><p>åœ¨æŸ¥çœ‹äº†Embeddingçš„æºç åï¼Œå‘ç°è®¾ç½®äº†<code>padding_idx</code>ï¼Œç±»å†…éƒ¨ä¼šæœ‰å¦‚ä¸‹æ“ä½œï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-----Embedding __init__ å†…éƒ¨--------------</span></span><br><span class="line"><span class="keyword">if</span> _weight <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">    self.weight = Parameter(torch.Tensor(num_embeddings, embedding_dim))</span><br><span class="line">    self.reset_parameters()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#---------reset_parameters()--------</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_parameters</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.weight.data.normal_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> self.padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        self.weight.data[self.padding_idx].fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„çŸ©é˜µæ—¶ï¼Œä¼šå¯¹<code>padding_idx</code>æ‰€åœ¨çš„è¡Œè¿›è¡Œå¡«0ã€‚ä¿è¯äº†paddingè¡Œä¸ºçš„æ­£ç¡®æ€§ã€‚</p><p>é‚£ä¹ˆï¼Œè¿˜éœ€è¦ä¿è¯ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨åå‘å›ä¼ çš„æ—¶å€™ï¼Œ<code>padding_idx</code>æ˜¯ä¸ä¼šæ›´æ–°çš„.</p><p>åœ¨æŸ¥çœ‹äº†æºç åå‘ç°åœ¨Embeddingç±»å†…æœ‰å¦‚ä¸‹æ³¨é‡Šï¼š</p><blockquote><p>.. note::<br>        With :attr:<code>padding_idx</code> set, the embedding vector at<br>        :attr:<code>padding_idx</code> is initialized to all zeros. However, note that this<br>        vector can be modified afterwards, e.g., using a customized<br>        initialization method, and thus changing the vector used to pad the<br>        output. The gradient for this vector from :class:<code>~torch.nn.Embedding</code><br>        is always zero.</p></blockquote><p>å¹¶ä¸”åœ¨æŸ¥é˜…äº†å…¶ä»–èµ„æ–™åï¼Œå‘ç°è¯¥è¡Œç¡®å®ä¼šä¸æ›´æ–°ã€‚æœ‰æ„æ€çš„æ˜¯ï¼ŒæŸ¥é˜…æºç å¹¶æ²¡æœ‰æ‰¾åˆ°å¦‚ä½•ä½¿å…¶ä¸æ›´æ–°çš„æœºåˆ¶ï¼Œå› ä¸ºåœ¨F.embeddingå‡½æ•°ä¸­ï¼Œè¿”å›ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure><p>ä½†æˆ‘å¹¶ä¸èƒ½è·³è½¬åˆ°torch.embeddingä¸­ï¼Œå¤§æ¦‚æ˜¯å› ä¸ºè¿™éƒ¨åˆ†è¢«éšè—äº†å§ã€‚æˆ‘ä¹Ÿæ²¡æœ‰å†æ·±ç©¶ä¸‹å»ã€‚æˆ‘çŒœæµ‹æœ‰å¯èƒ½æ˜¯åœ¨autogradå†…éƒ¨æœ‰å¯¹è¯¥éƒ¨åˆ†è¿›è¡Œå•ç‹¬çš„å¤„ç†ï¼Œç”¨maskå±è”½è¿™éƒ¨åˆ†çš„æ›´æ–°ï¼›æˆ–è€…ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•ï¼Œå°±æ˜¯ä»»å…¶æ›´æ–°ï¼Œä½†æ¯ä¸€æ¬¡éƒ½resetï¼Œå°†ç¬¬ä¸€è¡Œæ‰‹åŠ¨è®¾ä¸ºå…¨0ã€‚</p><p><strong>é™„è®°</strong>ï¼š</p><p>å‡å¦‚è¯´æ²¡æœ‰æ˜¾å¼è®¾ç½®è¯¥è¡Œï¼Œæ˜¯å¦paddingå°±æ²¡æœ‰æ•ˆæœå‘¢ï¼Ÿ<br>æˆ‘è®¤ä¸ºæ˜¯çš„ã€‚</p><p>ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬éƒ½æ˜¯ä»¥0ä½œä¸ºpaddingçš„å¡«å……ï¼Œå¦‚ï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>12</td><td>44</td><td>22</td><td>67</td><td>85</td></tr><tr><td>12</td><td>13</td><td>534</td><td>31</td><td>0</td></tr><tr><td>87</td><td>23</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div><p>æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªå¥å­ï¼Œå…¶ä¸­0ä½œä¸ºå¡«å……ã€‚ç„¶åå°†è¯¥çŸ©é˜µé€å…¥åˆ°embedding_lookupä¸­ï¼Œè·å¾—ä¸‰ç»´çš„tensorï¼Œé‚£ä¹ˆ0å¡«å……çš„éƒ¨åˆ†ï¼Œæ‰€è·å¾—çš„embeddingè¡¨ç¤ºåº”å½“æ˜¯è¦å…¨0ã€‚</p><p>å‡å¦‚ä¸æ˜¾å¼è®¾ç½®<code>padding_idx=0</code>ï¼Œå°±å¯èƒ½ä¼šå‡ºç°ä¸¤ä¸ªç»“æœï¼ˆä¸ªäººæ¨æµ‹)ï¼š</p><p>â‘ æœ¬åº”è¯¥å…¨0çš„åœ°æ–¹ï¼Œè¢«è¯å…¸ä¸­ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡è¡¨ç¤ºç»™æ›¿ä»£äº†ï¼Œå› ä¸ºå°†0ä½œä¸ºç´¢å¼•å»embeddingçŸ©é˜µè·å–åˆ°çš„è¯å‘é‡ï¼Œå°±æ˜¯ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼Œè€Œè¯¥è¯å¹¶ä¸å…¨0ã€‚</p><p>â‘¡è¯å…¸çš„æœ€åä¸€ä¸ªè¯è¢«å…¨0è¦†ç›–ã€‚F.embeddingä¸­æœ‰å¦‚ä¸‹ç‰‡æ®µï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    <span class="keyword">if</span> padding_idx &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &lt; weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">    <span class="keyword">elif</span> padding_idx &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &gt;= -weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">        padding_idx = weight.size(<span class="number">0</span>) + padding_idx</span><br><span class="line"><span class="keyword">elif</span> padding_idx <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        padding_idx = <span class="number">-1</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢ç‰‡æ®µæ˜¾ç¤ºï¼Œ<code>padding_idx</code>è¢«è®¾ç½®ä¸º-1ï¼Œä¹Ÿå°±æ˜¯æœ€åä¸€ä¸ªå•è¯ã€‚åšå®Œè¿™æ­¥ç´§æ¥ç€å°±è¿”å›ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure><p>è¿˜æ˜¯ç”±äºtorch.embeddingæ— æ³•æŸ¥çœ‹çš„åŸå› ï¼Œæˆ‘ä¸çŸ¥é“å†…éƒ¨æ˜¯å¦‚ä½•å®ç°çš„ï¼Œä½†åº”è¯¥æ¥è¯´ï¼Œæœ€åä¸€ä¸ªè¯å°±æ˜¯è¢«è¦†ç›–äº†ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Embedding </tag>
            
            <tag> padding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python Tricks[è½¬]</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%20Tricks%5B%E8%BD%AC%5D/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%20Tricks%5B%E8%BD%AC%5D/</url>
      
        <content type="html"><![CDATA[<p>åŸæ–‡åœ°å€:<a href="https://hackernoon.com/python-tricks-101-2836251922e0" target="_blank" rel="noopener">https://hackernoon.com/python-tricks-101-2836251922e0</a></p><p>æˆ‘è§‰å¾—è¿™ä¸ªä»‹ç»Pythonä¸€äº›tricksçš„æ–‡ç« å¾ˆå¥½ï¼Œèƒ½å¤Ÿæ›´åŠ ç†Ÿæ‚‰Pythonçš„ä¸€äº›éå¸¸æ–¹ä¾¿çš„ç”¨æ³•ã€‚<br>ä»¥ä¸‹æ˜¯æˆ‘è§‰å¾—æœ‰ç”¨çš„å‡ ä¸ªç‚¹ã€‚</p><p>1ï¸âƒ£Reverse a String/List</p><p><img src="/images/2018-08-19-15346465152976.jpg" width="70%" height="50%"></p><p><img src="/images/2018-08-19-15346467215597.jpg" width="70%" height="50%"></p><p>[::-1]è§£é‡Šï¼š<br>[:]è¡¨ç¤ºå–æ‰€æœ‰çš„å…ƒç´ ï¼Œ-1è¡¨ç¤ºæ­¥è¿›ã€‚[1:5:2]è¡¨ç¤ºçš„å°±æ˜¯ä»å…ƒç´ 1åˆ°å…ƒç´ 5ï¼Œæ¯2ä¸ªè·ç¦»å–ä¸€ä¸ªã€‚</p><hr><p>2ï¸âƒ£transpose 2d array</p><p><img src="/images/2018-08-19-15346470165919.jpg" width="70%" height="50%"></p><p>zip()ç›¸å½“äºå‹ç¼©ï¼Œzip(*)ç›¸å½“äºè§£å‹ã€‚</p><hr><p>3ï¸âƒ£Chained function call</p><p><img src="/images/2018-08-19-15346471756442.jpg" width="70%" height="50%"></p><p>éå¸¸ç®€æ´çš„å†™æ³•ã€‚</p><hr><p>4ï¸âƒ£Copy List</p><p><img src="/images/2018-08-19-15346472744350.jpg" width="50%" height="50%"></p><p>ä¹‹å‰è°ˆè¿‡çš„Pythonçš„èµ‹å€¼ã€æµ…æ‹·è´ã€æ·±æ‹·è´ã€‚</p><hr><p>5ï¸âƒ£Dictionary get</p><p><img src="/images/2018-08-19-15346473929918.jpg" width="70%" height="50%"></p><p>é¿å…äº†dictä¸å­˜åœ¨è¯¥å…ƒç´ çš„é—®é¢˜ã€‚</p><hr><p>6ï¸âƒ£âœ¨Sort Dictionary by Value</p><p><img src="/images/2018-08-19-15346475170316.jpg" width="90%" height="50%"></p><p>å…¶ä¸­ç¬¬ä¸‰ç§è¿”å›çš„æ˜¯[â€˜watermelonâ€™, â€˜bananaâ€™, â€˜appleâ€™, â€˜orangeâ€™]ï¼Œæ²¡æœ‰valueäº†ã€‚</p><hr><p>7ï¸âƒ£Forâ€¦else</p><p><img src="/images/2018-08-19-15346481408714.jpg" width="90%" height="50%"></p><p>æ³¨æ„åˆ°å¦‚æœforåœ¨ä¸­é€”breakäº†ï¼Œå°±ä¸ä¼šè¿›å…¥åˆ°elseäº†ï¼›åªæœ‰é¡ºåˆ©å¾ªç¯å®Œæ‰ä¼šè¿›å…¥åˆ°elseã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> e==<span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span><span class="comment">#ä»€ä¹ˆéƒ½æ²¡æœ‰print</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    print(e)</span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure><hr><p>8ï¸âƒ£Merge dictâ€™s</p><p><img src="/images/2018-08-19-15346483785515.jpg" width="90%" height="50%"></p><p>åˆå¹¶dictçš„æ–¹æ³•ã€‚</p><hr><p>9ï¸âƒ£Min and Max index in List</p><p><img src="/images/2018-08-19-15346487918895.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Python tricks </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†4</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%864/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%864/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[æ¦‚ç‡æ ¡å‡†(Probability Calibration)]<br>ä¸€ç§å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¾“å‡ºç»“æœçš„æ ¡å‡†ï¼Œé€šè¿‡å‡ ä¸ªå®éªŒå¯ä»¥å‘ç°ï¼Œæ¦‚ç‡æ ¡å‡†èƒ½å¤Ÿä¸€å®šç¨‹åº¦æé«˜è¡¨ç°ã€‚<br>å‡ ä¸ªå‚è€ƒèµ„æ–™ï¼š<br>ç›´è§‚ç†è§£:  <a href="http://www.bubuko.com/infodetail-2133893.html" target="_blank" rel="noopener">http://www.bubuko.com/infodetail-2133893.html</a><br>SVCçš„æ¦‚ç‡æ ¡å‡†åœ¨sklearnä¸Šçš„åº”ç”¨: <a href="https://blog.csdn.net/ericcchen/article/details/79337716" target="_blank" rel="noopener">https://blog.csdn.net/ericcchen/article/details/79337716</a><br>âœ¨å®Œå…¨æ‰‹å†Œ: <a href="http://users.dsic.upv.es/~flip/papers/BFHRHandbook2010.pdf" target="_blank" rel="noopener">Calibration of Machine Learning Models</a></p><hr><p>2ï¸âƒ£[Paper]<br><a href="https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf" target="_blank" rel="noopener">Hierarchical Attention Networks for Document Classification</a></p><p>äº®ç‚¹åœ¨ä½¿ç”¨å±‚æ¬¡çš„RNNç»“æ„ï¼Œä»¥åŠä½¿ç”¨äº†attentionæ–¹æ³•ã€‚<br><img src="/images/2018-08-19-15346447273228.jpg" width="50%" height="50%"></p><p>å‚è€ƒäº†å…¶ä»–äººçš„ä»£ç è‡ªå·±ä¹Ÿè¯•ç€å®ç°äº†ä¸€ä¸ªï¼ŒGitHubåœ°å€ï¼š<a href="https://github.com/linzehui/pytorch-hierarchical-attention-network" target="_blank" rel="noopener">https://github.com/linzehui/pytorch-hierarchical-attention-network</a></p><hr><p>3ï¸âƒ£[XGBoost]<br>kaggleç¥å™¨XGBoostï¼Œä¸€ç¯‡åŸç†çš„è¯¦ç»†ä»‹ç»ï¼š<br><a href="http://www.cnblogs.com/willnote/p/6801496.html" target="_blank" rel="noopener">http://www.cnblogs.com/willnote/p/6801496.html</a><br>è™½ç„¶è¿˜æ˜¯æœ‰å¥½äº›åœ°æ–¹æ²¡ææ‡‚ï¼Œæœ‰å¿…è¦ä»å¤´å­¦èµ·ã€‚</p><hr><p>4ï¸âƒ£[Python]<br>å…³äºå‡½æ•°åˆ—è¡¨ä¸­å•æ˜Ÿå·(*)å’ŒåŒæ˜Ÿå·(**)<br>å•æ˜Ÿå·ï¼š</p><ul><li>ä»£è¡¨æ¥æ”¶ä»»æ„å¤šä¸ªéå…³é”®å­—å‚æ•°ï¼Œå°†å…¶è½¬æ¢æˆå…ƒç»„ï¼š</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one</span><span class="params">(a,*b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šä¼ å…¥å‚æ•°ï¼Œ*bæ˜¯ä¸€ä¸ªéå…³é”®å­—æ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">one(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="comment">#è¾“å‡ºï¼š(2, 3, 4, 5, 6)</span></span><br></pre></td></tr></table></figure><ul><li>å¯¹ä¸€ä¸ªæ™®é€šå˜é‡ä½¿ç”¨å•æ˜Ÿå·ï¼Œè¡¨ç¤ºå¯¹è¯¥å˜é‡æ‹†åˆ†æˆå•ä¸ªå…ƒç´ </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    print(a,b)</span><br><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">fun(*l)  <span class="comment">#è¾“å‡º 1,2</span></span><br></pre></td></tr></table></figure><p>åŒæ˜Ÿå·ï¼š</p><ul><li>è·å¾—å­—å…¸å€¼</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two</span><span class="params">(a=<span class="number">1</span>,**b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šå…³é”®å­—å‚æ•°ï¼Œ**bæ˜¯ä¸€ä¸ªå…³é”®å­—åŒæ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">two(a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>,d=<span class="number">4</span>,e=<span class="number">5</span>,f=<span class="number">6</span>)  <span class="comment">#è¾“å‡º&#123;'b': 2, 'c': 3, 'e': 5, 'f': 6, 'd': 4&#125;</span></span><br></pre></td></tr></table></figure><hr><p>5ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œåªè¦ä¸€ä¸ªtensorçš„requires_gradæ˜¯trueï¼Œé‚£ä¹ˆä¸¤ä¸ªtensorçš„åŠ å‡ä¹˜é™¤åçš„ç»“æœçš„requires_gradä¹Ÿä¼šæ˜¯trueã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¦‚ç‡æ ¡å‡† </tag>
            
            <tag> Probability Calibration </tag>
            
            <tag> HAN </tag>
            
            <tag> XGBoost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯5</title>
      <link href="/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D5/"/>
      <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D5/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨å¤ªå¿™äº†ï¼Œæ²¡èƒŒä»€ä¹ˆè¯—è¯ï¼ŒåªèƒŒï¼ˆå¤ä¹ ï¼‰äº†éƒ¨åˆ†çš„ã€Šæ»•ç‹é˜åºã€‹ã€‚</p><p>1ï¸âƒ£</p><h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>å—Ÿä¹ï¼æ—¶è¿ä¸é½ï¼Œå‘½é€”å¤šèˆ›ã€‚å†¯å”æ˜“è€ï¼Œæå¹¿éš¾å°ã€‚å±ˆè´¾è°Šäºé•¿æ²™ï¼Œéæ— åœ£ä¸»ï¼›çªœæ¢é¸¿äºæµ·æ›²ï¼Œå²‚ä¹æ˜æ—¶ï¼Ÿæ‰€èµ–<strong>å›å­è§æœºï¼Œè¾¾äººçŸ¥å‘½</strong>ã€‚è€å½“ç›Šå£®ï¼Œå®ç§»ç™½é¦–ä¹‹å¿ƒï¼Ÿ<strong>ç©·ä¸”ç›Šåšï¼Œä¸å é’äº‘ä¹‹å¿—</strong>ã€‚é…Œè´ªæ³‰è€Œè§‰çˆ½ï¼Œå¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ã€‚<strong>åŒ—æµ·è™½èµŠï¼Œæ‰¶æ‘‡å¯æ¥ï¼›ä¸œéš…å·²é€ï¼Œæ¡‘æ¦†éæ™šã€‚</strong>å­Ÿå°é«˜æ´ï¼Œç©ºé¦€æŠ¥å›½ä¹‹æƒ…ï¼›é˜®ç±çŒ–ç‹‚ï¼Œå²‚æ•ˆç©·é€”ä¹‹å“­ï¼</p><p>å‹ƒï¼Œä¸‰å°ºå¾®å‘½ï¼Œä¸€ä»‹ä¹¦ç”Ÿã€‚æ— è·¯è¯·ç¼¨ï¼Œç­‰ç»ˆå†›ä¹‹å¼±å† ï¼›æœ‰æ€€æŠ•ç¬”ï¼Œæ…•å®—æ…¤ä¹‹é•¿é£ã€‚èˆç°ªç¬äºç™¾é¾„ï¼Œå¥‰æ™¨æ˜äºä¸‡é‡Œã€‚éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ã€‚ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼›ä»Šå…¹æ§è¢‚ï¼Œå–œæ‰˜é¾™é—¨ã€‚æ¨æ„ä¸é€¢ï¼ŒæŠšå‡Œäº‘è€Œè‡ªæƒœï¼›é”ºæœŸæ—¢é‡ï¼Œå¥æµæ°´ä»¥ä½•æƒ­ï¼Ÿ</p><hr><p><strong>æ³¨é‡Šï¼š</strong><br>å†¯å”ï¼šè¥¿æ±‰äººï¼Œæœ‰æ‰èƒ½å´ä¸€ç›´ä¸å—é‡ç”¨ã€‚æ±‰æ­¦å¸æ—¶é€‰æ±‚è´¤è‰¯ï¼Œæœ‰äººä¸¾èå†¯å”ï¼Œå¯æ˜¯ä»–å·²ä¹åå¤šå²ï¼Œéš¾å†åšå®˜äº†ã€‚æå¹¿ï¼šæ±‰æ­¦å¸æ—¶çš„åå°†ï¼Œå¤šå¹´æŠ—å‡»åŒˆå¥´ï¼Œå†›åŠŸå¾ˆå¤§ï¼Œå´ç»ˆèº«æ²¡æœ‰å°ä¾¯ã€‚</p><p>è´¾è°Šï¼šæ±‰æ–‡å¸æœ¬æƒ³ä»»è´¾è°Šä¸ºå…¬å¿ï¼Œä½†å› æœä¸­æƒè´µåå¯¹ï¼Œå°±ç–è¿œäº†è´¾è°Šï¼Œä»»ä»–ä¸ºé•¿æ²™ç‹å¤ªå‚…ã€‚æ¢é¸¿ï¼šä¸œæ±‰äººï¼Œå› ä½œè¯—è®½åˆºå›ç‹ï¼Œå¾—ç½ªäº†æ±‰ç« å¸ï¼Œè¢«è¿«é€ƒåˆ°é½é²ä¸€å¸¦èº²é¿ã€‚</p><p>é…Œï¼ˆzhuÃ³ï¼‰è´ªæ³‰è€Œè§‰çˆ½ï¼šå–ä¸‹è´ªæ³‰çš„æ°´ï¼Œä»è§‰å¾—å¿ƒå¢ƒæ¸…çˆ½ã€‚å¤ä»£ä¼ è¯´å¹¿å·æœ‰æ°´åè´ªæ³‰ï¼Œäººå–äº†è¿™é‡Œçš„æ°´å°±ä¼šå˜å¾—è´ªå©ªã€‚è¿™å¥æ˜¯è¯´æœ‰å¾·è¡Œçš„äººåœ¨æ±¡æµŠçš„ç¯å¢ƒä¸­ä¹Ÿèƒ½ä¿æŒçº¯æ­£ï¼Œä¸è¢«æ±¡æŸ“ã€‚å¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ï¼šå¤„åœ¨å¥„å¥„å¾…æ¯™çš„æ—¶å€™ï¼Œä»ç„¶ä¹è§‚å¼€æœ—ã€‚å¤„æ²³è¾™ï¼šåŸæŒ‡é²‹é±¼å¤„åœ¨å¹²æ¶¸çš„è½¦è¾™æ—¦ã€‚æ¯”å–»äººé™·å…¥å±æ€¥ä¹‹ä¸­ã€‚</p><p>å­Ÿå°ï¼šä¸œæ±‰äººï¼Œä¸ºå®˜æ¸…æ­£è´¤èƒ½ï¼Œä½†ä¸è¢«é‡ç”¨ï¼Œåæ¥å½’ç”°ã€‚é˜®ç±ï¼šä¸‰å›½é­è¯—äººï¼Œä»–æœ‰æ—¶ç‹¬è‡ªé©¾è½¦å‡ºè¡Œï¼Œåˆ°æ— è·¯å¤„ä¾¿æ¸å“­è€Œè¿”ï¼Œå€Ÿæ­¤å®£æ³„ä¸æ»¡äºç°å®çš„è‹¦é—·å¿ƒæƒ…ã€‚</p><p>ç»ˆå†›ï¼šã€Šæ±‰ä¹¦Â·ç»ˆå†›ä¼ ã€‹è®°è½½ï¼Œæ±‰æ­¦å¸æƒ³è®©å—è¶Šï¼ˆä»Šå¹¿ä¸œã€å¹¿è¥¿ä¸€å¸¦ï¼‰ç‹å½’é¡ºï¼Œæ´¾ç»ˆå†›å‰å¾€åŠè¯´ï¼Œç»ˆå†›è¯·æ±‚ç»™ä»–é•¿ç¼¨ï¼Œå¿…ç¼šä½å—è¶Šç‹ï¼Œå¸¦å›åˆ°çš‡å®«é—¨å‰ï¼ˆæ„æ€æ˜¯ä¸€å®šå®Œæˆä½¿å‘½ï¼‰ã€‚åæ¥ç”¨â€œè¯·ç¼¨â€æŒ‡æŠ•å†›æŠ¥å›½ã€‚</p><p>å®—æ‚«ï¼ˆquÃ¨ï¼‰ï¼šå—æœå®‹äººï¼Œå°‘å¹´æ—¶å¾ˆæœ‰æŠ±è´Ÿï¼Œè¯´â€œæ„¿ä¹˜é•¿é£ç ´ä¸‡é‡Œæµªâ€ã€‚</p><p>ç°ªï¼ˆzÄnï¼‰ç¬ï¼ˆhÃ¹ï¼‰ï¼šè¿™é‡Œä»£æŒ‡å®˜èŒã€‚æ™¨æ˜ï¼šæ™¨æ˜å®šçœï¼Œå‡ºè‡ª ã€Šç¤¼è®°Â·æ›²ç¤¼ä¸Šã€‹ï¼Œé‡Šä¹‰ä¸ºæ—§æ—¶ä¾å¥‰çˆ¶æ¯çš„æ—¥å¸¸ç¤¼èŠ‚ã€‚</p><p>éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè‡ªå·±å¹¶ä¸æ˜¯åƒè°¢ç„é‚£æ ·å‡ºè‰²çš„äººæ‰ï¼Œå´èƒ½åœ¨ä»Šæ—¥çš„å®´ä¼šä¸Šç»“è¯†å„ä½åå£«ã€‚è°¢å®¶ä¹‹å®æ ‘ï¼šæŒ‡è°¢ç„ã€‚ã€Šæ™‹ä¹¦Â·è°¢ç„ä¼ ã€‹è®°è½½ï¼Œæ™‹æœè°¢å®‰æ›¾é—®å­ä¾„ä»¬ï¼šä¸ºä»€ä¹ˆäººä»¬æ€»å¸Œæœ›è‡ªå·±çš„å­å¼Ÿå¥½ï¼Ÿä¾„å­è°¢ç„å›ç­”ï¼šâ€œè­¬å¦‚èŠå…°ç‰æ ‘ï¼Œæ¬²ä½¿å…¶ç”Ÿäºåº­é˜¶è€³ã€‚â€åæ¥å°±ç§°è°¢ç„ä¸ºè°¢å®¶å®æ ‘ã€‚å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè¿™é‡Œå€Ÿå­Ÿå­çš„æ¯äº²ä¸ºå¯»æ‰¾é‚»å±…è€Œä¸‰æ¬¡æ¬å®¶çš„æ•…äº‹ï¼Œæ¥æŒ‡èµ´å®´çš„å˜‰å®¾ã€‚</p><p>ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼šè¿‡äº›æ—¶å€™è‡ªå·±å°†åˆ°çˆ¶äº²é‚£é‡Œé™ªä¾å’Œè†å¬æ•™è¯²ã€‚è¶‹åº­ï¼šå¿«æ­¥èµ°è¿‡åº­é™¢ï¼Œè¿™æ˜¯è¡¨ç¤ºå¯¹é•¿è¾ˆçš„æ­æ•¬ã€‚å¨ï¼šæƒ­æ„§åœ°æ‰¿å—ï¼Œè¡¨ç¤ºè‡ªè°¦ã€‚é²¤å¯¹ï¼šå­”é²¤æ˜¯å­”å­çš„å„¿å­ï¼Œé²¤å¯¹æŒ‡æ¥å—çˆ¶äº²æ•™è¯²ã€‚äº‹è§ã€Šè®ºè¯­Â·å­£æ°ã€‹ï¼šï¼ˆå­”å­ï¼‰å°ç‹¬ç«‹ï¼Œï¼ˆå­”ï¼‰é²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦è¯—ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€œæœªä¹Ÿã€‚â€â€œä¸å­¦è¯—ï¼Œæ— ä»¥è¨€ã€‚â€é²¤é€€è€Œå­¦è¯—ã€‚ä»–æ—¥ï¼Œåˆç‹¬ç«‹ï¼Œé²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦ç¤¼ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€˜æœªä¹Ÿã€‚â€â€œä¸å­¦ç¤¼ï¼Œæ— ä»¥ç«‹ã€‚â€é²¤é€€è€Œå­¦ç¤¼ã€‚</p><p>æ§è¢‚ï¼ˆmÃ¨iï¼‰ï¼šä¸¾èµ·åŒè¢–ä½œæ–ï¼ŒæŒ‡è°’è§é˜å…¬ã€‚å–œæ‰˜é¾™é—¨ï¼šï¼ˆå—åˆ°é˜å…¬çš„æ¥å¾…ï¼‰ååˆ†é«˜å…´ï¼Œå¥½åƒç™»ä¸Šé¾™é—¨ä¸€æ ·ã€‚</p><p>æ¨æ„ï¼šå³èœ€äººæ¨å¾—æ„ï¼Œä»»æŒç®¡å¤©å­çŒçŠ¬çš„å®˜ï¼Œè¥¿æ±‰è¾èµ‹å®¶å¸é©¬ç›¸å¦‚æ˜¯ç”±ä»–æ¨èç»™æ±‰æ­¦å¸çš„ã€‚å‡Œäº‘ï¼šè¿™é‡ŒæŒ‡å¸é©¬ç›¸å¦‚çš„èµ‹ï¼Œã€Šå²è®°Â·å¸é©¬ç›¸å¦‚ä¼ ã€‹è¯´ï¼Œç›¸å¦‚çŒ®ã€Šå¤§äººèµ‹ã€‹ï¼Œâ€œå¤©å­å¤§æ‚¦ï¼Œé£˜é£˜æœ‰å‡Œäº‘ä¹‹æ°”ï¼Œä¼¼æ¸¸å¤©åœ°ä¹‹é—´â€ã€‚é’ŸæœŸï¼šå³é’Ÿå­æœŸã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonä¸­çš„æ‹·è´</title>
      <link href="/2018/08/18/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84%E6%8B%B7%E8%B4%9D/"/>
      <url>/2018/08/18/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84%E6%8B%B7%E8%B4%9D/</url>
      
        <content type="html"><![CDATA[<p>Pythonçš„æ‹·è´å’ŒC/C++çš„å·®åˆ«å¾ˆå¤§ï¼Œå¾ˆç»å¸¸å°±å®¹æ˜“ææ··ï¼Œå› æ­¤è®°å½•ä¸€ä¸‹ã€‚</p><h3 id="èµ‹å€¼ã€æ‹·è´"><a href="#èµ‹å€¼ã€æ‹·è´" class="headerlink" title="èµ‹å€¼ã€æ‹·è´"></a>èµ‹å€¼ã€æ‹·è´</h3><ul><li>èµ‹å€¼ï¼šå®é™…ä¸Šå°±æ˜¯å¯¹è±¡çš„å¼•ç”¨ï¼Œæ²¡æœ‰å¼€è¾Ÿæ–°çš„å†…å­˜ç©ºé—´<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lst=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">l=lst</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>æµ…æ‹·è´:åˆ›å»ºäº†æ–°å¯¹è±¡ï¼Œä½†æ˜¯<strong>å†…å®¹æ˜¯å¯¹åŸå¯¹è±¡çš„å¼•ç”¨</strong>ï¼Œæœ‰ä¸‰ç§å½¢å¼</p><ol><li><p>åˆ‡ç‰‡  </p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l=lst[:]</span><br><span class="line">l=[i <span class="keyword">for</span> i <span class="keyword">in</span> lst]</span><br></pre></td></tr></table></figure></li><li><p>å·¥å‚</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l=list(lst)</span><br></pre></td></tr></table></figure></li><li><p>copy </p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.copy(lst)</span><br></pre></td></tr></table></figure></li></ol></li><li><p>æ·±æ‹·è´:copyä¸­çš„deepcopyï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„å¯¹è±¡ï¼Œä¸åŸæ¥çš„å¯¹è±¡æ— å…³</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.deepcopy(lst)</span><br></pre></td></tr></table></figure></li></ul><h3 id="ä¾‹å­"><a href="#ä¾‹å­" class="headerlink" title="ä¾‹å­"></a>ä¾‹å­</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### å¼•ç”¨https://www.cnblogs.com/huangbiquan/p/7795152.html çš„ä¾‹å­###</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> copy</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,[<span class="string">'a'</span>,<span class="string">'b'</span>]] <span class="comment">#å®šä¹‰ä¸€ä¸ªåˆ—è¡¨a</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a <span class="comment">#èµ‹å€¼</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = copy.copy(a) <span class="comment">#æµ…æ‹·è´</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = copy.deepcopy(a) <span class="comment">#æ·±æ‹·è´</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.append(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#aæ·»åŠ ä¸€ä¸ªå…ƒç´ 5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ 5 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#cä¿æŒä¸å˜</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">4</span>].append(<span class="string">'c'</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#aä¸­çš„list(å³a[4])æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]] <span class="comment">#cè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#è¯´æ˜å¦‚ä¸‹ï¼š</span></span><br><span class="line"><span class="comment">#1.å¤–å±‚æ·»åŠ å…ƒç´ æ—¶ï¼Œ æµ…æ‹·è´cä¸ä¼šéšåŸåˆ—è¡¨aå˜åŒ–è€Œå˜åŒ–ï¼›å†…å±‚listæ·»åŠ å…ƒç´ æ—¶ï¼Œæµ…æ‹·è´cæ‰ä¼šå˜åŒ–ã€‚</span></span><br><span class="line"><span class="comment">#2.æ— è®ºåŸåˆ—è¡¨aå¦‚ä½•å˜åŒ–ï¼Œæ·±æ‹·è´déƒ½ä¿æŒä¸å˜ã€‚</span></span><br><span class="line"><span class="comment">#3.èµ‹å€¼å¯¹è±¡éšç€åŸåˆ—è¡¨ä¸€èµ·å˜åŒ–</span></span><br></pre></td></tr></table></figure><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/huangbiquan/p/7795152.html" target="_blank" rel="noopener">https://www.cnblogs.com/huangbiquan/p/7795152.html</a><br><a href="https://www.cnblogs.com/xueli/p/4952063.html" target="_blank" rel="noopener">https://www.cnblogs.com/xueli/p/4952063.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> æ‹·è´ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¦‚ä½•å°†ELMoè¯å‘é‡ç”¨äºä¸­æ–‡</title>
      <link href="/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E5%B0%86ELMo%E8%AF%8D%E5%90%91%E9%87%8F%E7%94%A8%E4%BA%8E%E4%B8%AD%E6%96%87/"/>
      <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E5%B0%86ELMo%E8%AF%8D%E5%90%91%E9%87%8F%E7%94%A8%E4%BA%8E%E4%B8%AD%E6%96%87/</url>
      
        <content type="html"><![CDATA[<p>10.10æ›´æ–°ï¼šELMoå·²ç»ç”±å“ˆå·¥å¤§ç»„ç”¨PyTorché‡å†™äº†ï¼Œå¹¶ä¸”æä¾›äº†ä¸­æ–‡çš„é¢„è®­ç»ƒå¥½çš„language modelï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚</p><hr><p>ELMoäºä»Šå¹´äºŒæœˆç”±AllenNLPæå‡ºï¼Œä¸word2vecæˆ–GloVeä¸åŒçš„æ˜¯å…¶åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œå…¶æœ¬è´¨å³é€šè¿‡è®­ç»ƒlanguage modelï¼Œå¯¹äºä¸€å¥è¯è¿›å…¥åˆ°language modelè·å¾—ä¸åŒçš„è¯å‘é‡ã€‚æ ¹æ®å®éªŒå¯å¾—ï¼Œä½¿ç”¨äº†Elmoè¯å‘é‡ä¹‹åï¼Œè®¸å¤šNLPä»»åŠ¡éƒ½æœ‰äº†å¤§å¹…çš„æé«˜ã€‚</p><p>è®ºæ–‡:<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">Deep contextualized word representations</a></p><p>AllenNLPä¸€å…±releaseäº†ä¸¤ä»½ELMoçš„ä»£ç ï¼Œä¸€ä»½æ˜¯Pytorchç‰ˆæœ¬çš„ï¼Œå¦ä¸€ä»½æ˜¯Tensorflowç‰ˆæœ¬çš„ã€‚Pytorchç‰ˆæœ¬çš„åªå¼€æ”¾äº†ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡çš„æ¥å£ï¼Œä½†æ²¡æœ‰ç»™å‡ºè‡ªå·±è®­ç»ƒçš„æ¥å£ï¼Œå› æ­¤æ— æ³•ä½¿ç”¨åˆ°ä¸­æ–‡è¯­æ–™ä¸­ã€‚Tensorflowç‰ˆæœ¬æœ‰æä¾›è®­ç»ƒçš„ä»£ç ï¼Œå› æ­¤æœ¬æ–‡è®°å½•å¦‚ä½•å°†ELMoç”¨äºä¸­æ–‡è¯­æ–™ä¸­ï¼Œä½†æœ¬æ–‡åªè®°å½•ä½¿ç”¨åˆ°çš„éƒ¨åˆ†ï¼Œè€Œä¸ä¼šåˆ†æå…¨éƒ¨çš„ä»£ç ã€‚</p><p>éœ€æ±‚:<br>ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡ä½œä¸ºå¥å­è¡¨ç¤ºç›´æ¥ä¼ å…¥åˆ°RNNä¸­(ä¹Ÿå°±æ˜¯ä¸ä½¿ç”¨ä»£ç ä¸­é»˜è®¤çš„å…ˆè¿‡CNN)ï¼Œåœ¨è®­ç»ƒå®Œåï¼Œå°†æ¨¡å‹ä¿å­˜ï¼Œåœ¨éœ€è¦ç”¨çš„æ—¶å€™loadè¿›æ¥ï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„å¥å­ï¼Œé¦–å…ˆå°†å…¶è½¬æ¢æˆé¢„è®­ç»ƒçš„è¯å‘é‡ï¼Œä¼ å…¥language modelä¹‹åæœ€ç»ˆå¾—åˆ°ELMoè¯å‘é‡ã€‚</p><p>å‡†å¤‡å·¥ä½œ:</p><ol><li>å°†ä¸­æ–‡è¯­æ–™åˆ†è¯</li><li>è®­ç»ƒå¥½GloVeè¯å‘é‡æˆ–è€…word2vec</li><li>ä¸‹è½½<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">bilm-tfä»£ç </a></li><li>ç”Ÿæˆè¯è¡¨ vocab_file ï¼ˆè®­ç»ƒçš„æ—¶å€™è¦ç”¨åˆ°ï¼‰</li><li>optional:é˜…è¯»Readme</li><li>optional:é€šè¯»bilm-tfçš„ä»£ç ï¼Œå¯¹ä»£ç ç»“æ„æœ‰ä¸€å®šçš„è®¤è¯†</li></ol><p>æ€è·¯:</p><ol><li>å°†é¢„è®­ç»ƒçš„è¯å‘é‡è¯»å…¥</li><li>ä¿®æ”¹bilm-tfä»£ç <ol><li>optionéƒ¨åˆ†</li><li>æ·»åŠ ç»™embedding weightèµ‹åˆå€¼</li><li>æ·»åŠ ä¿å­˜embedding weightçš„ä»£ç </li></ol></li><li>å¼€å§‹è®­ç»ƒï¼Œè·å¾—checkpointå’Œoptionæ–‡ä»¶</li><li>è¿è¡Œè„šæœ¬ï¼Œè·å¾—language modelçš„weightæ–‡ä»¶</li><li>å°†embedding weightä¿å­˜ä¸ºhdf5æ–‡ä»¶å½¢å¼</li><li>è¿è¡Œè„šæœ¬ï¼Œå°†è¯­æ–™è½¬åŒ–æˆELMo embeddingã€‚</li></ol><h3 id="è®­ç»ƒGloVeæˆ–word2vec"><a href="#è®­ç»ƒGloVeæˆ–word2vec" class="headerlink" title="è®­ç»ƒGloVeæˆ–word2vec"></a>è®­ç»ƒGloVeæˆ–word2vec</h3><p>å¯å‚è§æˆ‘ä»¥å‰çš„åšå®¢æˆ–è€…ç½‘ä¸Šçš„æ•™ç¨‹ã€‚<br>æ³¨æ„åˆ°ï¼Œå¦‚æœè¦ç”¨gensimå¯¼å…¥GloVeè®­å¥½çš„è¯å‘é‡ï¼Œéœ€è¦åœ¨å¼€å¤´æ·»åŠ num_word embedding_dimã€‚ å¦‚ï¼š<br><img src="/images/2018-08-10-15338861462682.jpg" width="70%" height="50%"></p><h3 id="è·å¾—vocabè¯è¡¨æ–‡ä»¶"><a href="#è·å¾—vocabè¯è¡¨æ–‡ä»¶" class="headerlink" title="è·å¾—vocabè¯è¡¨æ–‡ä»¶"></a>è·å¾—vocabè¯è¡¨æ–‡ä»¶</h3><p>æ³¨æ„åˆ°ï¼Œè¯è¡¨æ–‡ä»¶çš„å¼€å¤´å¿…é¡»è¦æœ‰<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œä¸”å¤§å°å†™æ•æ„Ÿã€‚å¹¶ä¸”åº”å½“æŒ‰ç…§å•è¯çš„è¯é¢‘é™åºæ’åˆ—ã€‚å¯ä»¥é€šè¿‡æ‰‹åŠ¨æ·»åŠ è¿™ä¸‰ä¸ªç‰¹æ®Šç¬¦å·ã€‚<br>å¦‚ï¼š<br><img src="/images/2018-08-11-15339757184030.jpg" width="10%" height="50%"></p><p>ä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model=gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">    fname=<span class="string">'/home/zhlin/GloVe/vectors.txt'</span>,binary=<span class="keyword">False</span></span><br><span class="line">)</span><br><span class="line">words=model.vocab</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'vocab.txt'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'&lt;S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>ï¼‰</span><br><span class="line">    f.write(<span class="string">'&lt;/S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)</span><br><span class="line">    f.write(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)    <span class="comment"># bilm-tf è¦æ±‚vocabæœ‰è¿™ä¸‰ä¸ªç¬¦å·ï¼Œå¹¶ä¸”åœ¨æœ€å‰é¢</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        f.write(word)</span><br><span class="line">        f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="ä¿®æ”¹bilm-tfä»£ç "><a href="#ä¿®æ”¹bilm-tfä»£ç " class="headerlink" title="ä¿®æ”¹bilm-tfä»£ç "></a>ä¿®æ”¹bilm-tfä»£ç </h3><p>æ³¨æ„åˆ°ï¼Œåœ¨ä½¿ç”¨è¯¥ä»£ç ä¹‹å‰ï¼Œéœ€è¦å®‰è£…å¥½ç›¸åº”çš„ç¯å¢ƒã€‚</p><p><img src="/images/2018-08-10-15338879402377.jpg" width="50%" height="50%"></p><p>å¦‚æœä½¿ç”¨çš„æ˜¯condaä½œä¸ºé»˜è®¤çš„Pythonè§£é‡Šå™¨ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨condaå®‰è£…ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°ä¸€äº›è«åçš„é”™è¯¯ã€‚<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install tensorflow-gpu=1.4</span><br><span class="line">conda install h5py</span><br><span class="line">python setup.py install <span class="comment">#åº”åœ¨bilm-tfçš„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œè¯¥æŒ‡ä»¤</span></span><br></pre></td></tr></table></figure></p><p>ç„¶åå†è¿è¡Œæµ‹è¯•ä»£ç ï¼Œé€šè¿‡è¯´æ˜å®‰è£…æˆåŠŸã€‚</p><h4 id="ä¿®æ”¹train-elmo-py"><a href="#ä¿®æ”¹train-elmo-py" class="headerlink" title="ä¿®æ”¹train_elmo.py"></a>ä¿®æ”¹train_elmo.py</h4><p>binæ–‡ä»¶å¤¹ä¸‹çš„train_elmo.pyæ˜¯ç¨‹åºçš„å…¥å£ã€‚<br>ä¸»è¦ä¿®æ”¹çš„åœ°æ–¹ï¼š</p><ol><li>load_vocabçš„ç¬¬äºŒä¸ªå‚æ•°åº”è¯¥æ”¹ä¸ºNone</li><li>n_gpus CUDA_VISIBLE_DEVICES æ ¹æ®è‡ªå·±éœ€æ±‚æ”¹</li><li>n_train_tokens å¯æ”¹å¯ä¸æ”¹ï¼Œå½±å“çš„æ˜¯è¾“å‡ºä¿¡æ¯ã€‚è¦æŸ¥çœ‹è‡ªå·±è¯­æ–™çš„è¡Œæ•°ï¼Œå¯ä»¥é€šè¿‡<code>wc -l corpus.txt</code> æŸ¥çœ‹ã€‚</li><li><strong>optionçš„ä¿®æ”¹</strong>ï¼Œå°†char_cnnéƒ¨åˆ†éƒ½æ³¨é‡Šæ‰ï¼Œå…¶ä»–æ ¹æ®è‡ªå·±éœ€æ±‚ä¿®æ”¹</li></ol><p>å¦‚ï¼š<br><img src="/images/2018-08-10-15338888745894.jpg" width="70%" height="50%"></p><h4 id="ä¿®æ”¹LanguageModelç±»"><a href="#ä¿®æ”¹LanguageModelç±»" class="headerlink" title="ä¿®æ”¹LanguageModelç±»"></a>ä¿®æ”¹LanguageModelç±»</h4><p>ç”±äºæˆ‘éœ€è¦ä¼ å…¥é¢„è®­ç»ƒå¥½çš„GloVe embeddingï¼Œé‚£ä¹ˆè¿˜éœ€è¦ä¿®æ”¹embeddingéƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†åœ¨bilmæ–‡ä»¶å¤¹ä¸‹çš„training.pyï¼Œè¿›å…¥åˆ°LanguageModelç±»ä¸­_build_word_embeddingså‡½æ•°ä¸­ã€‚æ³¨æ„åˆ°ï¼Œç”±äºå‰ä¸‰ä¸ªæ˜¯<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œè€Œè¿™ä¸‰ä¸ªå­—ç¬¦åœ¨GloVeé‡Œé¢æ˜¯æ²¡æœ‰çš„ï¼Œå› æ­¤è¿™ä¸‰ä¸ªå­—ç¬¦çš„embeddingåº”å½“åœ¨è®­ç»ƒçš„æ—¶å€™é€æ¸å­¦ä¹ åˆ°ï¼Œè€Œæ­£å› æ­¤ <code>embedding_weights</code>çš„<code>trainable</code>åº”å½“è®¾ä¸º<code>True</code></p><p>å¦‚:</p><p><img src="/images/2018-08-12-15340585073779.jpg" alt=""></p><h4 id="ä¿®æ”¹trainå‡½æ•°"><a href="#ä¿®æ”¹trainå‡½æ•°" class="headerlink" title="ä¿®æ”¹trainå‡½æ•°"></a>ä¿®æ”¹trainå‡½æ•°</h4><p>æ·»åŠ ä»£ç ï¼Œä½¿å¾—åœ¨trainå‡½æ•°çš„æœ€åä¿å­˜embeddingæ–‡ä»¶ã€‚<br><img src="/images/2018-08-12-15340607132103.jpg" alt=""></p><h3 id="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"><a href="#è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶" class="headerlink" title="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"></a>è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶</h3><p>è®­ç»ƒéœ€è¦è¯­æ–™æ–‡ä»¶corpus.txtï¼Œè¯è¡¨æ–‡ä»¶vocab.txtã€‚</p><h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>cdåˆ°bilm-tfæ–‡ä»¶å¤¹ä¸‹ï¼Œè¿è¡Œ<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=4</span><br><span class="line">nohup python -u bin/train_elmo.py \</span><br><span class="line">--train_prefix=<span class="string">'/home/zhlin/bilm-tf/corpus.txt'</span> \</span><br><span class="line">--vocab_file /home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try &gt;bilm_out.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>æ ¹æ®å®é™…æƒ…å†µè®¾å®šä¸åŒçš„å€¼å’Œè·¯å¾„ã€‚</p><p>è¿è¡Œæƒ…å†µï¼š<br><img src="/images/2018-08-10-15339015862848.jpg" width="50%" height="50%"></p><p>PS:è¿è¡Œè¿‡ç¨‹ä¸­å¯èƒ½ä¼šæœ‰warning:</p><blockquote><p>â€˜listâ€™ object has no attribute â€˜nameâ€™<br>WARNING:tensorflow:Error encountered when serializing lstm_output_embeddings.<br>Type is unsupported, or the types of the items donâ€™t match field type in CollectionDef.</p></blockquote><p>åº”è¯¥ä¸ç”¨æ‹…å¿ƒï¼Œè¿˜æ˜¯èƒ½å¤Ÿç»§ç»­è¿è¡Œçš„ï¼Œåé¢ä¹Ÿä¸å—å½±å“ã€‚</p><p>åœ¨ç­‰å¾…äº†ç›¸å½“é•¿çš„æ—¶é—´åï¼Œåœ¨save_diræ–‡ä»¶å¤¹å†…ç”Ÿæˆäº†å‡ ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­checkpointå’Œoptionsæ˜¯å…³é”®ï¼Œcheckpointèƒ½å¤Ÿè¿›ä¸€æ­¥ç”Ÿæˆlanguage modelçš„weightsæ–‡ä»¶ï¼Œè€Œoptionsè®°å½•language modelçš„å‚æ•°ã€‚</p><p><img src="/images/2018-08-11-15339734319058.jpg" alt=""></p><h4 id="è·å¾—language-modelçš„weights"><a href="#è·å¾—language-modelçš„weights" class="headerlink" title="è·å¾—language modelçš„weights"></a>è·å¾—language modelçš„weights</h4><p>æ¥ä¸‹æ¥è¿è¡Œbin/dump_weights.pyå°†checkpointè½¬æ¢æˆhdf5æ–‡ä»¶ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup python -u  /home/zhlin/bilm-tf/bin/dump_weights.py  \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try  \</span><br><span class="line">--outfile /home/zhlin/bilm-tf/try/weights.hdf5 &gt;outfile.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­save_diræ˜¯checkpointå’Œoptionæ–‡ä»¶ä¿å­˜çš„åœ°å€ã€‚</p><p>æ¥ä¸‹æ¥ç­‰å¾…ç¨‹åºè¿è¡Œï¼š</p><p><img src="/images/2018-08-11-15339740970081.jpg" width="70%" height="50%"></p><p><img src="/images/2018-08-11-15339745511775.jpg" width="70%" height="50%"></p><p>æœ€ç»ˆè·å¾—äº†æƒ³è¦çš„weightså’Œoptionï¼š<br><img src="/images/2018-08-11-15339978499136.jpg" alt=""></p><h3 id="å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding"><a href="#å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding" class="headerlink" title="å°†è¯­æ–™è½¬åŒ–æˆELMo embedding"></a>å°†è¯­æ–™è½¬åŒ–æˆELMo embedding</h3><p>ç”±äºæˆ‘ä»¬æœ‰äº†vocab_fileã€ä¸vocab_fileä¸€ä¸€å¯¹åº”çš„embedding h5pyæ–‡ä»¶ã€ä»¥åŠlanguage modelçš„weights.hdf5å’Œoptions.jsonã€‚<br>æ¥ä¸‹æ¥å‚è€ƒusage_token.pyå°†ä¸€å¥è¯è½¬åŒ–æˆELMo embeddingã€‚</p><p>å‚è€ƒä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> bilm <span class="keyword">import</span> TokenBatcher, BidirectionalLanguageModel, weight_layers, \</span><br><span class="line">    dump_token_embeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># Our small dataset.</span></span><br><span class="line">raw_context = [</span><br><span class="line">    <span class="string">'è¿™ æ˜¯ æµ‹è¯• .'</span>,</span><br><span class="line">    <span class="string">'å¥½çš„ .'</span></span><br><span class="line">]</span><br><span class="line">tokenized_context = [sentence.split() <span class="keyword">for</span> sentence <span class="keyword">in</span> raw_context]</span><br><span class="line">tokenized_question = [</span><br><span class="line">    [<span class="string">'è¿™'</span>, <span class="string">'æ˜¯'</span>, <span class="string">'ä»€ä¹ˆ'</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">vocab_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt'</span></span><br><span class="line">options_file=<span class="string">'/home/zhlin/bilm-tf/try/options.json'</span></span><br><span class="line">weight_file=<span class="string">'/home/zhlin/bilm-tf/try/weights.hdf5'</span></span><br><span class="line">token_embedding_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab_embedding.hdf5'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Now we can do inference.</span></span><br><span class="line"><span class="comment"># Create a TokenBatcher to map text to token ids.</span></span><br><span class="line">batcher = TokenBatcher(vocab_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input placeholders to the biLM.</span></span><br><span class="line">context_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line">question_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the biLM graph.</span></span><br><span class="line">bilm = BidirectionalLanguageModel(</span><br><span class="line">    options_file,</span><br><span class="line">    weight_file,</span><br><span class="line">    use_character_inputs=<span class="keyword">False</span>,</span><br><span class="line">    embedding_weight_file=token_embedding_file</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get ops to compute the LM embeddings.</span></span><br><span class="line">context_embeddings_op = bilm(context_token_ids)</span><br><span class="line">question_embeddings_op = bilm(question_token_ids)</span><br><span class="line"></span><br><span class="line">elmo_context_input = weight_layers(<span class="string">'input'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_input = weight_layers(</span><br><span class="line">        <span class="string">'input'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">elmo_context_output = weight_layers(</span><br><span class="line">    <span class="string">'output'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_output = weight_layers(</span><br><span class="line">        <span class="string">'output'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># It is necessary to initialize variables once before running inference.</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create batches of data.</span></span><br><span class="line">    context_ids = batcher.batch_sentences(tokenized_context)</span><br><span class="line">    question_ids = batcher.batch_sentences(tokenized_question)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute ELMo representations (here for the input only, for simplicity).</span></span><br><span class="line">    elmo_context_input_, elmo_question_input_ = sess.run(</span><br><span class="line">        [elmo_context_input[<span class="string">'weighted_op'</span>], elmo_question_input[<span class="string">'weighted_op'</span>]],</span><br><span class="line">        feed_dict=&#123;context_token_ids: context_ids,</span><br><span class="line">                   question_token_ids: question_ids&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">print(elmo_context_input_,elmo_context_input_)</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥ä¿®æ”¹ä»£ç ä»¥é€‚åº”è‡ªå·±çš„éœ€æ±‚ã€‚</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">https://github.com/allenai/bilm-tf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
            <tag> ELMo </tag>
            
            <tag> è¯å‘é‡ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•4</title>
      <link href="/2018/08/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB4/"/>
      <url>/2018/08/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB4/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨æ²¡æœ‰ä»€ä¹ˆä»£ç è¦è®°å½•çš„ã€‚</p><h3 id="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"><a href="#1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­" class="headerlink" title="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"></a>1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­</h3><p>ç”¨æœºå™¨å­¦ä¹ è§£å†³é—®é¢˜çš„æµç¨‹ï¼š<br>(å»æ‰éƒ¨åˆ†æ•°æ®ï¼‰â€”&gt; è·å–featureï¼ˆTf-idfç­‰ï¼‰ â€”&gt; ï¼ˆfeature selectionï¼Œchi2ã€äº’ä¿¡æ¯ç­‰ï¼‰ â€”&gt; ï¼ˆç¼©æ”¾/æ­£åˆ™åŒ–ï¼‰ â€”&gt; åˆ†ç±»å™¨ â€”&gt; GridSearch/RandomizedSearchè°ƒå‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pipe=Pipeline([     <span class="comment">#å»ºç«‹pipeline</span></span><br><span class="line">    (<span class="string">'vect'</span>,TfidfVectorizer()),</span><br><span class="line">    (<span class="string">'select'</span>,SelectKBest(chi2),</span><br><span class="line">    (<span class="string">'norm'</span>,MaxAbsScaler()),   </span><br><span class="line">    (<span class="string">'svm'</span>,svm.LinearSVC())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">parameters=&#123;</span><br><span class="line">    <span class="string">'vect__ngram_range'</span>:[(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>)],</span><br><span class="line">    <span class="string">'vect__max_df'</span>:[<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>],</span><br><span class="line">    <span class="string">'vect__min_df'</span>:[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>],</span><br><span class="line">    <span class="string">'vect__norm'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__penalty'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__loss'</span>:[<span class="string">'squared_hinge'</span>],  </span><br><span class="line">    <span class="string">'svm__dual'</span>:[<span class="keyword">False</span>,<span class="keyword">True</span>],</span><br><span class="line">    <span class="string">'svm__tol'</span>:[<span class="number">1e-5</span>,<span class="number">1e-4</span>],</span><br><span class="line">    <span class="string">'svm__C'</span>:[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">1.0</span>,<span class="number">1.1</span>],</span><br><span class="line">    <span class="string">'svm__class_weight'</span>:[<span class="keyword">None</span>,<span class="string">'balanced'</span>],</span><br><span class="line">    <span class="string">'svm__max_iter'</span>:[<span class="number">1000</span>,<span class="number">5000</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search_model=GridSearchCV(pipe,parameters,error_score=<span class="number">0</span>,n_jobs=<span class="number">5</span>)</span><br><span class="line">grid_search_model.fit(train[column],train[<span class="string">'class'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> para_name <span class="keyword">in</span> sorted(parameters.keys()):</span><br><span class="line">    print(para_name,grid_search_model.best_params_[para_name])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"cv_result:"</span>)</span><br><span class="line">print(grid_search_model.cv_results_)</span><br></pre></td></tr></table></figure><hr>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†3</title>
      <link href="/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%863/"/>
      <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%863/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Python]<br>åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç æ—¶ï¼Œå¦‚ <code>python project/folder1/a.py</code>ï¼Œå¦‚æœa.pyå¼•ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„æ¨¡å—ä½†åˆä¸åœ¨folder1å†…ï¼Œæ­¤æ—¶interpreterå°±ä¼šæŠ¥é”™ï¼Œæç¤ºæ‰¾ä¸åˆ°è¯¥æ¨¡å—ã€‚è¿™æ˜¯å› ä¸ºè§£é‡Šå™¨é»˜è®¤åªä¼šåœ¨åŒä¸€ä¸ªfolderä¸‹æŸ¥æ‰¾ã€‚è§£å†³æ–¹æ¡ˆæ˜¯åœ¨è¿è¡Œå‰æ˜¾å¼æ·»åŠ æŸ¥æ‰¾èŒƒå›´ã€‚å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONPATH=/home/zhlin/bilm-tf:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure></p><p>é‚£ä¹ˆpythonè§£é‡Šå™¨å°±ä¼šåˆ°è¯¥ç›®å½•ä¸‹å»æ‰¾ã€‚</p><hr><p>2ï¸âƒ£[åº¦é‡æ ‡å‡†]<br><img src="/images/2018-08-12-15340420442670.jpg" alt=""></p><ul><li>å‡†ç¡®ç‡(accuracy):  $ACC=\frac{TP+TN}{TP+TN+FP+FN}$<br> è¡¡é‡çš„æ˜¯åˆ†ç±»å™¨é¢„æµ‹å‡†ç¡®çš„æ¯”ä¾‹</li><li>å¬å›ç‡(recall): $Recall=\frac{TP}{TP+FN}$<br>  æ­£ä¾‹ä¸­è¢«åˆ†å¯¹çš„æ¯”ä¾‹ï¼Œè¡¡é‡äº†åˆ†ç±»å™¨å¯¹æ­£ä¾‹çš„è¯†åˆ«èƒ½åŠ›ã€‚</li><li>ç²¾ç¡®ç‡(Precision): $P=\frac{TP}{TP+FP}$<br>åº¦é‡äº†è¢«åˆ†ä¸ºæ­£ä¾‹çš„ç¤ºä¾‹ä¸­å®é™…ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ã€‚</li><li>F-Measure: $F=\frac{(\alpha^2 +1)P*R}{\alpha^2 (P+R)}$<br>  å…¶ä¸­Pæ˜¯Precision,Ræ˜¯Recallã€‚ç»¼åˆè€ƒé‡äº†ä¸¤ç§åº¦é‡ã€‚<br>  å½“$\alpha=1$æ—¶ï¼Œç§°ä¸ºF1å€¼ $F1=\frac{2PR}{P+R}$</li></ul><hr><p>3ï¸âƒ£[è°ƒå‚æŠ€å·§]<br>åœ¨googleå‘å¸ƒçš„ä¸€ä»½å…³äºtext-classificationçš„<a href="https://developers.google.com/machine-learning/guides/text-classification/" target="_blank" rel="noopener">guide</a>ä¸­ï¼Œæåˆ°äº†å‡ ä¸ªè°ƒå‚çš„trickã€‚</p><ol><li>åœ¨feature selectionæ­¥éª¤ä¸­ï¼Œå¡æ–¹æ£€éªŒchi2å’Œæ–¹å·®åˆ†æçš„Få€¼ f_classifçš„è¡¨ç°ç›¸å½“ï¼Œåœ¨å¤§çº¦é€‰æ‹©20kçš„featureæ—¶ï¼Œå‡†ç¡®ç‡è¾¾åˆ°é¡¶å³°ï¼Œå½“featureè¶Šå¤šï¼Œæ•ˆæœå¹¶æ²¡æœ‰æå‡ç”šè‡³ä¼šä¸‹é™ã€‚<br><img src="/images/2018-08-12-15340434326365.jpg" width="90%" height="50%"></li><li>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œä¼¼ä¹ä½¿ç”¨normalizationå¹¶æ²¡æœ‰å¤šå°‘ç”¨å¤„ï¼Œå»ºè®®è·³è¿‡ã€‚<blockquote><p>Normalization converts all feature/sample values to small and similar values. This simplifies gradient descent convergence in learning algorithms. From what we have seen, normalization during data preprocessing does not seem to add much value in text classification problems; we recommend skipping this step.</p></blockquote></li></ol><p>å®é™…ä¸Šæˆ‘ä¹Ÿæµ‹è¯•è¿‡ï¼Œå‘ç°ç¡®å®normalizationå¯¹äºå‡†ç¡®ç‡çš„æé«˜æ²¡ä»€ä¹ˆå¸®åŠ©ï¼Œç”šè‡³è¿˜æœ‰ä¸€ç‚¹ä¸‹é™ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> åº¦é‡æ ‡å‡† </tag>
            
            <tag> è°ƒå‚æŠ€å·§ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯4</title>
      <link href="/2018/08/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D4/"/>
      <url>/2018/08/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D4/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£</p><h3 id="çä¸Šç§‹å±…"><a href="#çä¸Šç§‹å±…" class="headerlink" title="çä¸Šç§‹å±…"></a>çä¸Šç§‹å±…</h3><p>[å”] é©¬æˆ´<br>çåŸé£é›¨å®šï¼Œæ™šè§é›è¡Œé¢‘ã€‚<br>è½å¶ä»–ä¹¡æ ‘ï¼Œå¯’ç¯ç‹¬å¤œäººã€‚<br>ç©ºå›­ç™½éœ²æ»´ï¼Œå­¤å£é‡åƒ§é‚»ã€‚<br><strong>å¯„å§éƒŠæ‰‰ä¹…ï¼Œä½•å¹´è‡´æ­¤èº«ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9</a></p><hr><p>2ï¸âƒ£</p><h3 id="å”å¤šä»¤"><a href="#å”å¤šä»¤" class="headerlink" title="å”å¤šä»¤"></a>å”å¤šä»¤</h3><p>[å®‹] åˆ˜è¿‡<br>èŠ¦å¶æ»¡æ±€æ´²ï¼Œå¯’æ²™å¸¦æµ…æµã€‚äºŒåå¹´é‡è¿‡å—æ¥¼ã€‚æŸ³ä¸‹ç³»èˆ¹çŠ¹æœªç¨³ï¼Œèƒ½å‡ æ—¥ï¼Œåˆä¸­ç§‹ã€‚<br>é»„é¹¤æ–­çŸ¶å¤´ï¼Œæ•…äººä»Šåœ¨å¦ï¼Ÿæ—§æ±Ÿå±±æµ‘æ˜¯æ–°æ„ã€‚<strong>æ¬²ä¹°æ¡‚èŠ±åŒè½½é…’ï¼Œç»ˆä¸ä¼¼ã€å°‘å¹´æ¸¸ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b922e7c4c9710055904842" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b922e7c4c9710055904842</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vimå¸¸ç”¨å¿«æ·é”®</title>
      <link href="/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Vim%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
      <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Vim%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<p>åœ¨æœåŠ¡å™¨ç»å¸¸è¦ç”¨åˆ°Vimï¼Œå› æ­¤è®°å½•å¸¸ç”¨çš„å¿«æ·é”®å¹¶ç†Ÿæ‚‰ä¹‹ã€‚</p><h3 id="é€€å‡º"><a href="#é€€å‡º" class="headerlink" title="é€€å‡º"></a>é€€å‡º</h3><p>:q é€€å‡º<br>:wq å†™å…¥å¹¶é€€å‡º<br>:q! é€€å‡ºå¹¶å¿½ç•¥æ‰€æœ‰æ›´æ”¹<br>:e! æ”¾å¼ƒä¿®æ”¹å¹¶æ‰“å¼€åŸæ¥çš„æ–‡ä»¶</p><h3 id="æ’å…¥"><a href="#æ’å…¥" class="headerlink" title="æ’å…¥"></a>æ’å…¥</h3><p>i åœ¨å½“å‰ä½ç½®å‰æ’å…¥<br>a åœ¨å½“å‰ä½ç½®åæ’å…¥</p><h3 id="æ’¤é”€"><a href="#æ’¤é”€" class="headerlink" title="æ’¤é”€"></a>æ’¤é”€</h3><p>:u æ’¤é”€<br>:U æ’¤é”€æ•´è¡Œæ“ä½œ<br>Ctrl+r é‡åš</p><h3 id="åˆ é™¤"><a href="#åˆ é™¤" class="headerlink" title="åˆ é™¤"></a>åˆ é™¤</h3><p>:md åˆ é™¤ç¬¬mè¡Œ<br>nd åˆ é™¤å½“å‰è¡Œå¼€å§‹çš„nè¡Œ(ä¸€å…±n+1è¡Œ)<br>dd åˆ é™¤å½“å‰è¡Œ<br>D åˆ é™¤å½“å‰å­—ç¬¦è‡³è¡Œå°¾<br>:m,nd åˆ é™¤ä»måˆ°nè¡Œçš„å†…å®¹ï¼Œå¦‚: <code>:100,10000d</code><br>:m,$d åˆ é™¤mè¡ŒåŠä»¥åæ‰€æœ‰çš„è¡Œ<br>:10d</p><h3 id="ç§»åŠ¨"><a href="#ç§»åŠ¨" class="headerlink" title="ç§»åŠ¨"></a>ç§»åŠ¨</h3><p>:n è·³è½¬åˆ°è¡Œå·  å¦‚ï¼Œ :100<br>gg è·³åˆ°è¡Œé¦–<br>G(shift+g)ç§»åŠ¨åˆ°æ–‡ä»¶å°¾</p><h3 id="æœç´¢"><a href="#æœç´¢" class="headerlink" title="æœç´¢"></a>æœç´¢</h3><p>/text æœç´¢textï¼Œnæœç´¢ä¸‹ä¸€ä¸ªï¼ŒNæœç´¢ä¸Šä¸€ä¸ª<br>?text åå‘æŸ¥æ‰¾<br>:set ignorecase å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>:set noignorecase ä¸å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>*æˆ–# å¯¹å…‰æ ‡å¤„çš„å•è¯æœç´¢</p><h3 id="å¤åˆ¶ç²˜è´´"><a href="#å¤åˆ¶ç²˜è´´" class="headerlink" title="å¤åˆ¶ç²˜è´´"></a>å¤åˆ¶ç²˜è´´</h3><p>v ä»å½“å‰ä½ç½®å¼€å§‹ï¼Œå…‰æ ‡ç»è¿‡çš„åœ°æ–¹è¢«é€‰ä¸­ï¼Œå†æŒ‰ä¸€ä¸‹vç»“æŸ</p><h3 id="ç¯å¢ƒè®¾ç½®"><a href="#ç¯å¢ƒè®¾ç½®" class="headerlink" title="ç¯å¢ƒè®¾ç½®"></a>ç¯å¢ƒè®¾ç½®</h3><p>:set nu æ˜¾ç¤ºè¡Œå·<br>:set nonu éšè—è¡Œå·<br>:set hlsearch è®¾ç½®æœç´¢ç»“æœé«˜äº®</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/wangrx/p/5907013.html" target="_blank" rel="noopener">https://www.cnblogs.com/wangrx/p/5907013.html</a><br><a href="https://www.cnblogs.com/yangjig/p/6014198.html" target="_blank" rel="noopener">https://www.cnblogs.com/yangjig/p/6014198.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æŠ€å·§ </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> å¿«æ·é”® </tag>
            
            <tag> Vim </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pycharmå¸¸ç”¨æŠ€å·§</title>
      <link href="/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Pycharm%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
      <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Pycharm%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<p>è®°å½•Pycharmçš„ä¸€äº›æŠ€å·§ï¼Œè®©Pycharmæ›´é¡ºæ‰‹</p><h3 id="å¿«æ·é”®"><a href="#å¿«æ·é”®" class="headerlink" title="å¿«æ·é”®"></a>å¿«æ·é”®</h3><p>0ï¸âƒ£Double Shift ä¸‡èƒ½æœç´¢<br>å¯ä»¥æœç´¢<strong>æ–‡ä»¶åã€ç±»åã€æ–¹æ³•åã€ç›®å½•å</strong>ï¼ˆåœ¨å…³é”®å­—å‰é¢åŠ / ï¼‰ï¼Œå¹¶ä¸èƒ½ç”¨æ¥æœç´¢ä»»æ„å…³é”®å­—</p><p>1ï¸âƒ£ Command+F åœ¨é¡µé¢æœç´¢</p><p>2ï¸âƒ£ Ctrl+Shift+F Find in Path åœ¨è·¯å¾„ä¸‹æœç´¢</p><p>3ï¸âƒ£âœ¨Command+E å¿«é€ŸæŸ¥æ‰¾æ–‡ä»¶<br>æ˜¾ç¤ºæœ€è¿‘æ‰“å¼€çš„æ–‡ä»¶</p><p>4ï¸âƒ£ Shift+Enter ä»»æ„ä½ç½®æ¢è¡Œ<br>æ— è®ºå…‰æ ‡åœ¨ä½•å¤„éƒ½å¯ä»¥ç›´æ¥å¦èµ·ä¸€è¡Œ</p><p>5ï¸âƒ£ Option+Enter è‡ªåŠ¨å¯¼å…¥æ¨¡å—ï¼›ä¸‡èƒ½æç¤ºé”®<br>è‡ªåŠ¨å¯¼å…¥å¦‚ä½•è®¾ç½®è§å°æŠ€å·§#0ï¸âƒ£</p><p>6ï¸âƒ£ Ctrl+F10 è¿è¡Œ<br>æˆ‘å·²ç»æ·»åŠ äº†Ctrl+Rä½œä¸ºå¦ä¸€å¯¹è¿è¡Œå¿«æ·é”®</p><p>7ï¸âƒ£ Command+Shift+ +/-  å±•å¼€/æ”¶ç¼©ä»£ç  </p><p>8ï¸âƒ£ Option+F åœ¨Dashä¸­æœç´¢</p><p>9ï¸âƒ£ Ctrl+J ä¸è·³è½¬æŸ¥çœ‹ä»£ç </p><h3 id="å°æŠ€å·§"><a href="#å°æŠ€å·§" class="headerlink" title="å°æŠ€å·§"></a>å°æŠ€å·§</h3><p>0ï¸âƒ£ Pycharmè‡ªåŠ¨å¯¼å…¥æ¨¡å—<br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a></p><p>1ï¸âƒ£ âœ¨è¿œç¨‹éƒ¨ç½²å·¥ç¨‹ å¼ºçƒˆæ¨è<br>ä¸¤æ­¥èµ°ï¼šé…ç½®æœåŠ¡å™¨æ˜ å°„+é…ç½®æœåŠ¡å™¨è§£é‡Šå™¨</p><p>2ï¸âƒ£è·³è½¬åå¦‚ä½•å›é€€<br>å¼€å¯toolbarå³å¯<br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://foofish.net/pycharm-tips.html" target="_blank" rel="noopener">https://foofish.net/pycharm-tips.html</a><br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a><br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æŠ€å·§ </tag>
            
            <tag> Pycharm </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> å¿«æ·é”® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2018/08/06/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E9%A2%98/"/>
      <url>/2018/08/06/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>äººè¿™è¾ˆå­ä¸€å…±ä¼šæ­»ä¸‰æ¬¡ã€‚</p><p>ç¬¬ä¸€æ¬¡æ˜¯ä½ çš„å¿ƒè„åœæ­¢è·³åŠ¨ï¼Œé‚£ä¹ˆä»ç”Ÿç‰©çš„è§’åº¦æ¥è¯´ï¼Œä½ æ­»äº†ï¼›</p><p>ç¬¬äºŒæ¬¡æ˜¯åœ¨è‘¬ç¤¼ä¸Šï¼Œè®¤è¯†ä½ çš„äººéƒ½æ¥ç¥­å¥ ï¼Œé‚£ä¹ˆä½ åœ¨ç¤¾ä¼šå…³ç³»ä¸Šçš„äº‹å®å­˜åœ¨å°±æ­»äº†ï¼›</p><p>ç¬¬ä¸‰æ¬¡æ˜¯åœ¨æœ€åä¸€ä¸ªè®°å¾—ä½ çš„äººæ­»åï¼Œé‚£ä½ å°±çœŸçš„æ­»äº†ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>äººå¯ä»¥å‘å¾®å¦‚å°˜åœŸ,ä¸å¯æ‰­æ›²å¦‚è›†è™«</title>
      <link href="/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E5%8F%AF%E4%BB%A5%E5%8D%91%E5%BE%AE%E5%A6%82%E5%B0%98%E5%9C%9F,%E4%B8%8D%E5%8F%AF%E6%89%AD%E6%9B%B2%E5%A6%82%E8%9B%86%E8%99%AB/"/>
      <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E5%8F%AF%E4%BB%A5%E5%8D%91%E5%BE%AE%E5%A6%82%E5%B0%98%E5%9C%9F,%E4%B8%8D%E5%8F%AF%E6%89%AD%E6%9B%B2%E5%A6%82%E8%9B%86%E8%99%AB/</url>
      
        <content type="html"><![CDATA[<p>å¦‚æœå¤©æ€»ä¹Ÿä¸äº®ï¼Œé‚£å°±æ‘¸é»‘è¿‡ç”Ÿæ´»; </p><p>å¦‚æœå‘å‡ºå£°éŸ³æ˜¯å±é™©çš„ï¼Œé‚£å°±ä¿æŒæ²‰é»˜; </p><p>å¦‚æœè‡ªè§‰æ— åŠ›å‘å…‰ï¼Œé‚£å°±åˆ«å»ç…§äº®åˆ«äººã€‚ </p><p>ä½†æ˜¯â€”â€”ä¸è¦ä¹ æƒ¯äº†é»‘æš—å°±ä¸ºé»‘æš—è¾©æŠ¤; </p><p>ä¸è¦ä¸ºè‡ªå·±çš„è‹Ÿä¸”è€Œå¾—æ„æ´‹æ´‹; </p><p>ä¸è¦å˜²è®½é‚£äº›æ¯”è‡ªå·±æ›´å‹‡æ•¢ã€æ›´æœ‰çƒ­é‡çš„äººä»¬ã€‚ </p><p><strong>å¯ä»¥å‘å¾®å¦‚å°˜åœŸï¼Œä¸å¯æ‰­æ›²å¦‚è›†è™«</strong>ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonæƒ¯ä¾‹[è½¬]</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E6%83%AF%E4%BE%8B/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E6%83%AF%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>fork from <a href="https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md" target="_blank" rel="noopener">https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md</a></p><h2 id="Pythonæƒ¯ä¾‹"><a href="#Pythonæƒ¯ä¾‹" class="headerlink" title="Pythonæƒ¯ä¾‹"></a>Pythonæƒ¯ä¾‹</h2><p>â€œæƒ¯ä¾‹â€è¿™ä¸ªè¯æŒ‡çš„æ˜¯â€œä¹ æƒ¯çš„åšæ³•ï¼Œå¸¸è§„çš„åŠæ³•ï¼Œä¸€è´¯çš„åšæ³•â€ï¼Œä¸è¿™ä¸ªè¯å¯¹åº”çš„è‹±æ–‡å•è¯å«â€œidiomâ€ã€‚ç”±äºPythonè·Ÿå…¶ä»–å¾ˆå¤šç¼–ç¨‹è¯­è¨€åœ¨è¯­æ³•å’Œä½¿ç”¨ä¸Šè¿˜æ˜¯æœ‰æ¯”è¾ƒæ˜¾è‘—çš„å·®åˆ«ï¼Œå› æ­¤ä½œä¸ºä¸€ä¸ªPythonå¼€å‘è€…å¦‚æœä¸èƒ½æŒæ¡è¿™äº›æƒ¯ä¾‹ï¼Œå°±æ— æ³•å†™å‡ºâ€œPythonicâ€çš„ä»£ç ã€‚ä¸‹é¢æˆ‘ä»¬æ€»ç»“äº†ä¸€äº›åœ¨Pythonå¼€å‘ä¸­çš„æƒ¯ç”¨çš„ä»£ç ã€‚</p><ol><li><p>è®©ä»£ç æ—¢å¯ä»¥è¢«å¯¼å…¥åˆå¯ä»¥è¢«æ‰§è¡Œã€‚ </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br></pre></td></tr></table></figure></li><li><p>ç”¨ä¸‹é¢çš„æ–¹å¼åˆ¤æ–­é€»è¾‘â€œçœŸâ€æˆ–â€œå‡â€ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x:</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> x:</span><br></pre></td></tr></table></figure><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name <span class="keyword">and</span> fruits <span class="keyword">and</span> owners:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name != <span class="string">''</span> <span class="keyword">and</span> len(fruits) &gt; <span class="number">0</span> <span class="keyword">and</span> owners != &#123;&#125;:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure></li><li><p>å–„äºä½¿ç”¨inè¿ç®—ç¬¦ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x <span class="keyword">in</span> items: <span class="comment"># åŒ…å«</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> items: <span class="comment"># è¿­ä»£</span></span><br></pre></td></tr></table></figure><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'L'</span> <span class="keyword">in</span> name:</span><br><span class="line">    print(<span class="string">'The name has an L in it.'</span>)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> name.find(<span class="string">'L'</span>) != <span class="number">-1</span>:</span><br><span class="line">    print(<span class="string">'This name has an L in it!'</span>)</span><br></pre></td></tr></table></figure></li><li><p>ä¸ä½¿ç”¨ä¸´æ—¶å˜é‡äº¤æ¢ä¸¤ä¸ªå€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure></li><li><p><strong>ç”¨åºåˆ—æ„å»ºå­—ç¬¦ä¸²</strong>ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span>.join(chars)</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> char <span class="keyword">in</span> chars:</span><br><span class="line">    name += char</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure></li><li><p><strong>EAFPä¼˜äºLBYL</strong>ã€‚</p><p>EAFP - <strong>E</strong>asier to <strong>A</strong>sk <strong>F</strong>orgiveness than <strong>P</strong>ermission.</p><p>LBYL - <strong>L</strong>ook <strong>B</strong>efore <strong>Y</strong>ou <strong>L</strong>eap.</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">except</span> (KeyError, TypeError, ValueError):</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> <span class="string">'x'</span> <span class="keyword">in</span> d <span class="keyword">and</span> isinstance(d[<span class="string">'x'</span>], str) \</span><br><span class="line"><span class="keyword">and</span> d[<span class="string">'x'</span>].isdigit():</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure></li><li><p>ä½¿ç”¨enumerateè¿›è¡Œè¿­ä»£ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line"><span class="keyword">for</span> index, fruit <span class="keyword">in</span> enumerate(fruits):</span><br><span class="line">print(index, <span class="string">':'</span>, fruit)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fruit <span class="keyword">in</span> fruits:</span><br><span class="line">    print(index, <span class="string">':'</span>, fruit)</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>ç”¨ç”Ÿæˆå¼ç”Ÿæˆåˆ—è¡¨ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = [num * <span class="number">3</span> <span class="keyword">for</span> num <span class="keyword">in</span> data <span class="keyword">if</span> num &gt; <span class="number">10</span>]</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">        result.append(i * <span class="number">3</span>)</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure></li><li><p>ç”¨zipç»„åˆé”®å’Œå€¼æ¥åˆ›å»ºå­—å…¸ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = dict(zip(keys, values))</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i, key <span class="keyword">in</span> enumerate(keys):</span><br><span class="line">    d[key] = values[i]</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure></li></ol><blockquote><p><strong>è¯´æ˜</strong>ï¼šè¿™ç¯‡æ–‡ç« çš„å†…å®¹æ¥è‡ªäºç½‘ç»œï¼Œæœ‰å…´è¶£çš„è¯»è€…å¯ä»¥é˜…è¯»<a href="http://safehammad.com/downloads/python-idioms-2014-01-16.pdf" target="_blank" rel="noopener">åŸæ–‡</a>ã€‚</p></blockquote><p>æ³¨ï¼š<br>è®¸å¤šåŸåˆ™æˆ‘è®¤ä¸ºéå¸¸æœ‰æ„ä¹‰ï¼Œèƒ½å¤Ÿæ‘†è„±C/C++çš„é£æ ¼ï¼ŒçœŸæ­£å†™å‡ºPythonicçš„ä»£ç ã€‚è®©æˆ‘æœ‰å¾ˆå¤§æ„Ÿè§¦çš„æ˜¯1ã€3ã€8ï¼Œèƒ½å¤Ÿå†™å‡ºéå¸¸ç®€æ´ä¼˜é›…çš„ä»£ç ã€‚åŒæ—¶6æˆ‘ä¹‹å‰ä»æ²¡æ³¨æ„è¿‡ï¼Œä¹ æƒ¯äº†C/C++é£æ ¼ä¹‹åæ€»æ˜¯ä¼šåœ¨æ‰§è¡Œä¹‹å‰è€ƒè™‘æ‰€æœ‰æƒ…å†µï¼Œä½†ç¡®å®ä¸å¤Ÿä¼˜é›…ï¼Œä»Šåå¯ä»¥å°è¯•EAFPé£æ ¼ï¼ˆ<a href="https://stackoverflow.com/questions/11360858/what-is-the-eafp-principle-in-python" target="_blank" rel="noopener">ä»€ä¹ˆæ˜¯EAFP</a>ï¼‰ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¦‚ä½•è®­ç»ƒGloVeä¸­æ–‡è¯å‘é‡</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83GloVe%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83GloVe%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="å‡†å¤‡è¯­æ–™"><a href="#å‡†å¤‡è¯­æ–™" class="headerlink" title="å‡†å¤‡è¯­æ–™"></a>å‡†å¤‡è¯­æ–™</h3><p>å‡†å¤‡å¥½è‡ªå·±çš„è¯­æ–™ï¼Œä¿å­˜ä¸ºtxtï¼Œæ¯è¡Œä¸€ä¸ªå¥å­æˆ–ä¸€æ®µè¯ï¼Œæ³¨æ„è¦åˆ†å¥½è¯ã€‚</p><p><img src="/images/2018-08-05-15334388069130.jpg" width="60%" height="60%"></p><h3 id="å‡†å¤‡æºç "><a href="#å‡†å¤‡æºç " class="headerlink" title="å‡†å¤‡æºç "></a>å‡†å¤‡æºç </h3><p>ä»GitHubä¸‹è½½ä»£ç ï¼Œ<a href="https://github.com/stanfordnlp/GloVe" target="_blank" rel="noopener">https://github.com/stanfordnlp/GloVe</a><br>å°†è¯­æ–™corpus.txtæ”¾å…¥åˆ°Gloveçš„ä¸»æ–‡ä»¶å¤¹ä¸‹ã€‚</p><h3 id="ä¿®æ”¹bash"><a href="#ä¿®æ”¹bash" class="headerlink" title="ä¿®æ”¹bash"></a>ä¿®æ”¹bash</h3><p>æ‰“å¼€demo.shï¼Œä¿®æ”¹ç›¸åº”çš„å†…å®¹</p><ol><li>å› ä¸ºdemoé»˜è®¤æ˜¯ä¸‹è½½ç½‘ä¸Šçš„è¯­æ–™æ¥è®­ç»ƒçš„ï¼Œå› æ­¤å¦‚æœè¦è®­ç»ƒè‡ªå·±çš„è¯­æ–™ï¼Œéœ€è¦æ³¨é‡Šæ‰</li></ol><p><img src="/images/2018-08-05-15334390298383.jpg" width="70%" height="50%"></p><ol><li>ä¿®æ”¹å‚æ•°è®¾ç½®ï¼Œå°†CORPUSè®¾ç½®æˆè¯­æ–™çš„åå­—</li></ol><p><img src="/images/2018-08-05-15334391029224.jpg" width="50%" height="50%"></p><h3 id="æ‰§è¡Œbashæ–‡ä»¶"><a href="#æ‰§è¡Œbashæ–‡ä»¶" class="headerlink" title="æ‰§è¡Œbashæ–‡ä»¶"></a>æ‰§è¡Œbashæ–‡ä»¶</h3><p>è¿›å…¥åˆ°ä¸»æ–‡ä»¶å¤¹ä¸‹</p><ol><li>make</li></ol><p><img src="/images/2018-08-05-15334392348665.jpg" width="70%" height="50%"></p><ol><li>bash demo.sh</li></ol><p><img src="/images/2018-08-05-15334392595148.jpg" width="70%" height="70%"></p><p>æ³¨æ„ï¼Œå¦‚æœè®­ç»ƒæ•°æ®è¾ƒå¤§ï¼Œåˆ™è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œé‚£ä¹ˆå»ºè®®ä½¿ç”¨nohupæ¥è¿è¡Œç¨‹åº</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bash demo.sh &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>åç­‰è®­ç»ƒï¼Œæœ€åä¼šå¾—åˆ°vectors.txt ä»¥åŠå…¶ä»–çš„ç›¸åº”çš„æ–‡ä»¶ã€‚å¦‚æœè¦ç”¨gensimçš„word2ve loadè¿›æ¥ï¼Œé‚£ä¹ˆéœ€è¦åœ¨vectors.txtçš„ç¬¬ä¸€è¡ŒåŠ ä¸Švacob_size vector_sizeï¼Œç¬¬ä¸€ä¸ªæ•°æŒ‡æ˜ä¸€å…±æœ‰å¤šå°‘ä¸ªå‘é‡ï¼Œç¬¬äºŒä¸ªæ•°æŒ‡æ˜æ¯ä¸ªå‘é‡æœ‰å¤šå°‘ç»´ã€‚</p><h3 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h3><p><a href="https://www.cnblogs.com/echo-cheng/p/8561171.html" target="_blank" rel="noopener">https://www.cnblogs.com/echo-cheng/p/8561171.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GloVe </tag>
            
            <tag> æ•™ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†2</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%862/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%862/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Pytorch]<br>é¿å…å†™å‡ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.zeros(...), requires_grad=<span class="keyword">True</span>).cuda()</span><br></pre></td></tr></table></figure><p>è€Œæ˜¯åº”è¯¥è¦ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.zeros(...).cuda(), requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187" target="_blank" rel="noopener">https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187</a></p><hr><p>2ï¸âƒ£[Tf-idf]<br>æœ¬å‘¨å› ä¸ºæ¯”èµ›çš„åŸå› äº†è§£äº†ä¸€ä¸‹å„ç§æ–‡æœ¬å»ºæ¨¡çš„æ–¹æ³•ã€‚Tf-idfèƒ½å¤Ÿå–å¾—ä¸é”™çš„æˆç»©ï¼Œä½†æœ‰ä¸€å®šçš„ç¼ºé™·ã€‚</p><blockquote><p>TF-IDFç”¨äºå‘é‡ç©ºé—´æ¨¡å‹ï¼Œè¿›è¡Œæ–‡æ¡£ç›¸ä¼¼åº¦è®¡ç®—æ˜¯ç›¸å½“æœ‰æ•ˆçš„ã€‚ä½†åœ¨æ–‡æœ¬åˆ†ç±»ä¸­å•çº¯ä½¿ç”¨TF-IDFæ¥åˆ¤æ–­ä¸€ä¸ªç‰¹å¾æ˜¯å¦æœ‰åŒºåˆ†åº¦æ˜¯ä¸å¤Ÿçš„ã€‚</p><ol><li>å®ƒä»…ä»…ç»¼åˆè€ƒè™‘äº†è¯¥è¯åœ¨æ–‡æ¡£ä¸­çš„é‡è¦ç¨‹åº¦å’Œæ–‡æ¡£åŒºåˆ†åº¦ã€‚</li><li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»é—´çš„åˆ†å¸ƒã€‚ç‰¹å¾é€‰æ‹©æ‰€é€‰æ‹©çš„ç‰¹å¾åº”è¯¥åœ¨æŸç±»å‡ºç°å¤šï¼Œè€Œå…¶å®ƒç±»å‡ºç°å°‘ï¼Œå³è€ƒå¯Ÿå„ç±»çš„æ–‡æ¡£é¢‘ç‡çš„å·®å¼‚ã€‚å¦‚æœä¸€ä¸ªç‰¹å¾è¯ï¼Œåœ¨å„ä¸ªç±»é—´åˆ†å¸ƒæ¯”è¾ƒå‡åŒ€ï¼Œè¿™æ ·çš„è¯å¯¹åˆ†ç±»åŸºæœ¬æ²¡æœ‰è´¡çŒ®ï¼›ä½†æ˜¯å¦‚æœä¸€ä¸ªç‰¹å¾è¯æ¯”è¾ƒé›†ä¸­çš„åˆ†å¸ƒåœ¨æŸä¸ªç±»ä¸­ï¼Œè€Œåœ¨å…¶å®ƒç±»ä¸­å‡ ä¹ä¸å‡ºç°ï¼Œè¿™æ ·çš„è¯å´èƒ½å¤Ÿå¾ˆå¥½ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œè€ŒTF-IDFä¸èƒ½åŒºåˆ†è¿™ä¸¤ç§æƒ…å†µã€‚</li><li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»å†…éƒ¨æ–‡æ¡£ä¸­çš„åˆ†å¸ƒæƒ…å†µã€‚åœ¨ç±»å†…éƒ¨çš„æ–‡æ¡£ä¸­ï¼Œå¦‚æœç‰¹å¾è¯å‡åŒ€åˆ†å¸ƒåœ¨å…¶ä¸­ï¼Œåˆ™è¿™ä¸ªç‰¹å¾è¯èƒ½å¤Ÿå¾ˆå¥½çš„ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œå¦‚æœåªåœ¨å‡ ç¯‡æ–‡æ¡£ä¸­å‡ºç°ï¼Œè€Œåœ¨æ­¤ç±»çš„å…¶å®ƒæ–‡æ¡£ä¸­ä¸å‡ºç°ï¼Œæ˜¾ç„¶è¿™æ ·çš„ç‰¹å¾è¯ä¸èƒ½å¤Ÿä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ã€‚</li></ol></blockquote><p>Reference:<br><a href="https://blog.csdn.net/mmc2015/article/details/46771791" target="_blank" rel="noopener">https://blog.csdn.net/mmc2015/article/details/46771791</a></p><hr><p>3ï¸âƒ£[å¡æ–¹æ£€éªŒCHI]<br>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œç”¨äºé€‰æ‹©æœ€ç›¸å…³çš„ç‰¹å¾ã€‚</p><p>Reference:<br><a href="https://blog.csdn.net/blockheadls/article/details/49977361" target="_blank" rel="noopener">https://blog.csdn.net/blockheadls/article/details/49977361</a></p><hr><p>4ï¸âƒ£[æ–‡æœ¬åˆ†ç±»]<br>å„ç§æ–‡æœ¬åˆ†ç±»æ–¹æ³•çš„ç®€å•ä»‹ç»ã€‚</p><p>Reference:<br><a href="https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md" target="_blank" rel="noopener">https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md</a></p><hr><p>5ï¸âƒ£[Python]<br>collectionsçš„ä¸¤ä¸ªæœ‰ç”¨çš„ç±»</p><ol><li>named_tupleï¼šå¿«é€Ÿå»ºç«‹ä¸€ä¸ªç±»ï¼Œä½¿å¾—å¯ä»¥ä½¿ç”¨å±æ€§æ¥è®¿é—®è€Œéç´¢å¼•ï¼Œæé«˜äº†ä»£ç å¯è¯»æ€§</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line">Point = namedtuple(<span class="string">'Point'</span>,[<span class="string">'x'</span>,<span class="string">'y'</span>])</span><br><span class="line">p = Point(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">print(p.x)  <span class="comment"># 1</span></span><br><span class="line">print(p.y)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure><ol><li>Counterï¼šç»Ÿè®¡å­—ç¬¦å‡ºç°çš„æ¬¡æ•°</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">count = Counter([...]).most_commom()  <span class="comment">#ä¼šæŒ‰ç…§å‡ºç°çš„æ¬¡æ•°æ’åºï¼Œé€šå¸¸å¯ç”¨äºæ„å»ºè¯å…¸</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> count:     <span class="comment"># cæ˜¯ä¸€ä¸ªtupleï¼Œc[0]æ˜¯è¯ï¼Œc[1]æ˜¯é¢‘ç‡</span></span><br><span class="line">    <span class="keyword">if</span> c[<span class="number">1</span>]&gt;= threshold:</span><br><span class="line">        vocab.add_word(c[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>Counterç”¨æ³•ï¼š<br><a href="https://blog.csdn.net/u014755493/article/details/69812244" target="_blank" rel="noopener">https://blog.csdn.net/u014755493/article/details/69812244</a></p><hr><p>6ï¸âƒ£[nohup]<br>æœ¬å‘¨åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç çš„æ—¶å€™é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨nohupæ‰§è¡Œpythonç¨‹åºæ—¶ï¼Œå‘ç°è¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ˜¾ç¤ºã€‚ä»¥ä¸ºæ˜¯ä»£ç çš„é—®é¢˜ï¼Œä½†ç»è¿‡æ’æŸ¥å¹¶éæ˜¯ä»£ç çš„é—®é¢˜ã€‚é€šè¿‡æŸ¥é˜…èµ„æ–™ï¼Œå‘ç°é—®é¢˜æ‰€åœ¨ï¼š<br>å› ä¸ºpythonè¾“å‡ºæœ‰ç¼“å†²ï¼Œå¯¼è‡´outputä¸èƒ½<strong>é©¬ä¸Š</strong>çœ‹åˆ°è¾“å‡ºã€‚å®é™…ä¸Šï¼Œåœ¨ç­‰å¾…äº†ä¸€æ®µæ—¶é—´åï¼Œè¾“å‡ºæ–‡ä»¶ç»ˆäºæ˜¾ç¤ºå‡ºæ¥äº†ã€‚</p><p>è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨pythonçš„å‚æ•° -u ä½¿å¾—pythonä¸å¯ç”¨ç¼“å†²ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://blog.csdn.net/sunlylorn/article/details/19127107" target="_blank" rel="noopener">https://blog.csdn.net/sunlylorn/article/details/19127107</a></p><hr><p>7ï¸âƒ£[hexoé…ç½®]</p><ol><li>mathjaxé…ç½®: <a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">https://www.jianshu.com/p/7ab21c7f0674</a></li><li>é…ç½®åŸŸå:<a href="https://www.zhihu.com/question/31377141" target="_blank" rel="noopener">https://www.zhihu.com/question/31377141</a></li><li>é…ç½®sitemap:<a href="http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/" target="_blank" rel="noopener">http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/</a></li></ol><hr><p>8ï¸âƒ£[Paper]<br><a href="http://aclweb.org/anthology/D17-1025" target="_blank" rel="noopener">Learning Chinese Word Representations From Glyphs Of Characters</a></p><p>ä½¿ç”¨å›¾åƒçš„å·ç§¯æ¥ç”Ÿæˆè¯å‘é‡:<br><img src="/images/2018-08-05-15334453515509.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Paper </tag>
            
            <tag> Tf-idf </tag>
            
            <tag> æ–‡æœ¬åˆ†ç±» </tag>
            
            <tag> hexo </tag>
            
            <tag> nohup </tag>
            
            <tag> CHI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•3</title>
      <link href="/2018/08/05/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB3/"/>
      <url>/2018/08/05/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB3/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨åªæœ‰ç®€å•çš„ä»£ç ã€‚</p><h3 id="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"><a href="#1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec" class="headerlink" title="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"></a>1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line">sentences=word2vec.Text8Corpus(<span class="string">u'åˆ†è¯åçš„çˆ½è‚¤æ°´è¯„è®º.txt'</span>)   <span class="comment">#sentence:[ [ a b ],[c d]... ]</span></span><br><span class="line">model=word2vec.Word2Vec(sentences, size=<span class="number">50</span>)  <span class="comment">#size:dim </span></span><br><span class="line"></span><br><span class="line">y2=model.similarity(<span class="string">u"å¥½"</span>, <span class="string">u"è¿˜è¡Œ"</span>)  <span class="comment">#è®¡ç®—ç›¸ä¼¼åº¦</span></span><br><span class="line">print(y2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> model.most_similar(<span class="string">u"æ»‹æ¶¦"</span>):</span><br><span class="line">    <span class="keyword">print</span> i[<span class="number">0</span>],i[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment">#ä¿å­˜</span></span><br><span class="line">model.save(<span class="string">'/model/word2vec_model'</span>)</span><br><span class="line"></span><br><span class="line">new_model=gensim.models.Word2Vec.load(<span class="string">'/model/word2vec_model'</span>)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"><a href="#2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"></a>2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dict</span><span class="params">(dataset,min_freq=<span class="number">5</span>)</span>:</span></span><br><span class="line">    dictionary=Dictionary() </span><br><span class="line">    count=Counter(flat(dataset)).most_common()  </span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> count:</span><br><span class="line">        <span class="keyword">if</span> c[<span class="number">1</span>]&gt;=min_freq:</span><br><span class="line">            dictionary.add_word(c[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> dictionary</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯3</title>
      <link href="/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D3/"/>
      <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D3/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨èƒŒçš„éƒ½æ˜¯æ¯”è¾ƒç®€å•çš„ã€‚</p><p>1ï¸âƒ£</p><h3 id="æŠŠé…’é—®æœˆ"><a href="#æŠŠé…’é—®æœˆ" class="headerlink" title="æŠŠé…’é—®æœˆ"></a>æŠŠé…’é—®æœˆ</h3><p>[å”] æç™½<br>é’å¤©æœ‰æœˆæ¥å‡ æ—¶ï¼Ÿæˆ‘ä»Šåœæ¯ä¸€é—®ä¹‹ã€‚<br>äººæ”€æ˜æœˆä¸å¯å¾—ï¼Œæœˆè¡Œå´ä¸äººç›¸éšã€‚<br>çšå¦‚é£é•œä¸´ä¸¹é˜™ï¼Œç»¿çƒŸç­å°½æ¸…è¾‰å‘ã€‚<br>ä½†è§å®µä»æµ·ä¸Šæ¥ï¼Œå®çŸ¥æ™“å‘äº‘é—´æ²¡ã€‚<br>ç™½å…”æ£è¯ç§‹å¤æ˜¥ï¼Œå«¦å¨¥å­¤æ –ä¸è°é‚»ï¼Ÿ<br><strong>ä»Šäººä¸è§å¤æ—¶æœˆï¼Œä»Šæœˆæ›¾ç»ç…§å¤äººã€‚<br>å¤äººä»Šäººè‹¥æµæ°´ï¼Œå…±çœ‹æ˜æœˆçš†å¦‚æ­¤ã€‚</strong><br><strong>å”¯æ„¿å½“æ­Œå¯¹é…’æ—¶ï¼Œæœˆå…‰é•¿ç…§é‡‘æ¨½é‡Œã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13</a></p><hr><p>2ï¸âƒ£</p><h3 id="é‡‘ç¼•è¡£"><a href="#é‡‘ç¼•è¡£" class="headerlink" title="é‡‘ç¼•è¡£"></a>é‡‘ç¼•è¡£</h3><p>[å”] æœç§‹å¨˜<br>åŠå›è«æƒœé‡‘ç¼•è¡£ï¼ŒåŠå›æƒœå–å°‘å¹´æ—¶ã€‚<br><strong>èŠ±å¼€å ªæŠ˜ç›´é¡»æŠ˜ï¼Œè«å¾…æ— èŠ±ç©ºæŠ˜æã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e</a></p><hr><p>3ï¸âƒ£</p><h3 id="åŒ—é’è"><a href="#åŒ—é’è" class="headerlink" title="åŒ—é’è"></a>åŒ—é’è</h3><p>[å”] æå•†éš<br>æ®‹é˜³è¥¿å…¥å´¦ï¼ŒèŒ…å±‹è®¿å­¤åƒ§ã€‚<br>è½å¶äººä½•åœ¨ï¼Œå¯’äº‘è·¯å‡ å±‚ã€‚<br>ç‹¬æ•²åˆå¤œç£¬ï¼Œé—²å€šä¸€æè—¤ã€‚<br><strong>ä¸–ç•Œå¾®å°˜é‡Œï¼Œå¾å®çˆ±ä¸æ†ã€‚</strong></p><p>å´¦ï¼ˆyÄnï¼‰ï¼šå³â€œå´¦åµ«ï¼ˆzÄ«ï¼‰â€ï¼Œå±±åï¼Œåœ¨ç”˜è‚ƒã€‚å¤æ—¶å¸¸ç”¨æ¥æŒ‡å¤ªé˜³è½å±±çš„åœ°æ–¹ã€‚<br><strong>ç£¬ï¼ˆqÃ¬ngï¼‰</strong>ï¼šå¤ä»£æ‰“å‡»ä¹å™¨ï¼Œå½¢çŠ¶åƒæ›²å°ºï¼Œç”¨ç‰ã€çŸ³åˆ¶æˆï¼Œå¯æ‚¬æŒ‚ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e</a></p><hr><p>4ï¸âƒ£</p><h3 id="å¤æ—¥ç»å¥"><a href="#å¤æ—¥ç»å¥" class="headerlink" title="å¤æ—¥ç»å¥"></a>å¤æ—¥ç»å¥</h3><p>[å®‹] ææ¸…ç…§<br>ç”Ÿå½“ä½œäººæ°ï¼Œæ­»äº¦ä¸ºé¬¼é›„ã€‚<br><strong>è‡³ä»Šæ€é¡¹ç¾½ï¼Œä¸è‚¯è¿‡æ±Ÿä¸œã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e</a></p><hr><p>5ï¸âƒ£</p><h3 id="é›¨éœ–é“ƒ"><a href="#é›¨éœ–é“ƒ" class="headerlink" title="é›¨éœ–é“ƒ"></a>é›¨éœ–é“ƒ</h3><p>[å®‹] æŸ³æ°¸<br>å¯’è‰å‡„åˆ‡ï¼Œå¯¹é•¿äº­æ™šï¼Œéª¤é›¨åˆæ­‡ã€‚éƒ½é—¨å¸é¥®æ— ç»ªï¼Œç•™æ‹å¤„ï¼Œå…°èˆŸå‚¬å‘ã€‚æ‰§æ‰‹ç›¸çœ‹æ³ªçœ¼ï¼Œç«Ÿæ— è¯­å‡å™ã€‚å¿µå»å»ï¼Œåƒé‡ŒçƒŸæ³¢ï¼Œæš®éœ­æ²‰æ²‰æ¥šå¤©é˜”ã€‚<br><strong>å¤šæƒ…è‡ªå¤ä¼¤ç¦»åˆ«</strong>ï¼Œæ›´é‚£å ªã€å†·è½æ¸…ç§‹èŠ‚ã€‚ä»Šå®µé…’é†’ä½•å¤„ï¼Ÿæ¨æŸ³å²¸ï¼Œæ™“é£æ®‹æœˆã€‚æ­¤å»ç»å¹´ï¼Œåº”æ˜¯è‰¯è¾°å¥½æ™¯è™šè®¾ã€‚<strong>ä¾¿çºµæœ‰åƒç§é£æƒ…ï¼Œæ›´ä¸ä½•äººè¯´</strong>ï¼Ÿ</p><p><a href="http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­gradçš„ç†è§£</title>
      <link href="/2018/08/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADgrad%E7%9A%84%E7%90%86%E8%A7%A3/"/>
      <url>/2018/08/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADgrad%E7%9A%84%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>äº‹æƒ…èµ·æºäºæˆ‘å†™äº†ä¸€ä¸ªCNNç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œä½†lossä¸€ç›´æ²¡é™ï¼Œå› æ­¤æˆ‘å°è¯•<code>print(loss.grad)</code>çš„gradï¼Œå‘ç°ç¥å¥‡çš„æ˜¯loss gradæ˜¾ç¤ºä¸ºNoneï¼Œæ¥ç€å°è¯•<code>print(y_pred.grad)</code>ï¼ŒåŒæ ·æ˜¯Noneï¼Œä½†å†print losså’Œy_predçš„requires_gradå‘ç°æ˜¯æ­£å¸¸çš„Trueã€‚</p><p>åœ¨æŸ¥é˜…äº†èµ„æ–™ï¼Œä»¥åŠé—®äº†å­¦é•¿ä¹‹åå‘ç°åŸæ¥å¹¶ä¸æ˜¯bugï¼Œè€Œæ˜¯å› ä¸ºï¼ŒPytorché»˜è®¤ä¸ä¼šä¿å­˜ä¸­é—´èŠ‚ç‚¹(intermediate variable)çš„gradï¼Œæ­¤ä¸¾æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜ã€‚</p><blockquote><p>By default, gradients are only retained for leaf variables. non-leaf variablesâ€™ gradients are not retained to be inspected later. This was done by design, to save memory.</p></blockquote><p><a href="https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94" target="_blank" rel="noopener">https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94</a></p><p>å®é™…ä¸Šå¯ä»¥é€šè¿‡retain_grad()æˆ–è€…hookæ¥æŸ¥çœ‹ä¸­é—´èŠ‚ç‚¹çš„gradã€‚</p><p>æˆ‘åé¢å°è¯•printäº†å¶å­èŠ‚ç‚¹ï¼Œå¦‚ <code>print(CNN_model.fc.weight.grad)</code>ï¼Œæœ€ç»ˆè·å¾—äº†æ­£ç¡®çš„gradã€‚</p><p>psï¼šæ‰€è°“ä¸­é—´èŠ‚ç‚¹ï¼Œæ˜¯<strong>ç”±å…¶ä»–èŠ‚ç‚¹è®¡ç®—æ‰€å¾—</strong>çš„tensorï¼Œè€Œå¶å­èŠ‚ç‚¹åˆ™æ˜¯<strong>è‡ªå·±å®šä¹‰</strong>å‡ºæ¥çš„ã€‚</p><p>æœ€åæˆ‘å‘ç°ï¼ŒåŸæ¥lossä¸€ç›´æ²¡é™çš„åŸå› æ˜¯å› ä¸ºæˆ‘å®šä¹‰çš„CNNè¿‡äºå¤æ‚ï¼Œå¹¶ä¸”æ•°æ®é›†åå°ï¼Œæ— æ³•å¿«é€Ÿæ”¶æ•›å¯¼è‡´çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> grad </tag>
            
            <tag> bug </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linuxå¸¸ç”¨å‘½ä»¤</title>
      <link href="/2018/08/03/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/08/03/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="å‘½ä»¤"><a href="#å‘½ä»¤" class="headerlink" title="å‘½ä»¤"></a>å‘½ä»¤</h3><p>è®°å½•è‡ªå·±å¸¸ç”¨çš„å‘½ä»¤ã€‚</p><p>1ï¸âƒ£lsï¼šæ˜¾å¼å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å’Œç›®å½•<br>    -a åŒ…æ‹¬éšè—æ–‡ä»¶<br>    -h å°†æ–‡ä»¶çš„å®¹é‡ä»¥æ˜“è¯»æ–¹å¼åˆ—å‡ºï¼ˆé…åˆ-sä½¿ç”¨ï¼‰<br>    -s ä»¥å—æ•°å½¢å¼æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶åˆ†é…çš„å°ºå¯¸<br>    -l ä»¥è¾ƒé•¿æ ¼å¼åˆ—å‡ºä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥å†™æˆ <code>ll</code><br><img src="/images/2018-08-10-15339070264416.jpg" width="70%" height="50%"></p><hr><p>2ï¸âƒ£cd åˆ°è¾¾æŒ‡å®šåœ°å€</p><hr><p>3ï¸âƒ£kill æ€æ­»ç¨‹åº<br>    -l ä¿¡æ¯ç¼–å·ã€‚<strong>å½“l=9æ—¶ï¼Œæ— æ¡ä»¶ç»ˆæ­¢ï¼Œå…¶ä»–ä¿¡å·å¯èƒ½å¿½ç•¥</strong><br>    killall -u <user_name> æ€æ­»è¯¥ç”¨æˆ·å…¨éƒ¨è¿›ç¨‹</user_name></p><p><img src="/images/2018-08-03-15332830170623.jpg" width="50%" height="50%"></p><hr><p>4ï¸âƒ£ps æŠ¥å‘Šå½“å‰ç³»ç»Ÿçš„è¿›ç¨‹çŠ¶æ€<br>    -a æ‰€æœ‰<br>    -p æŒ‡å®šç¨‹åº<br>    -u æŒ‡å®šç”¨æˆ·<br>    -x åˆ—å‡ºè¯¥ç”¨æˆ·çš„è¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯(æˆ‘çš„ç†è§£åº”è¯¥æ˜¯)<br>    å¦‚ï¼š<br><img src="/images/2018-08-10-15339036207642.jpg" width="70%" height="50%"></p><hr><p>5ï¸âƒ£htop æ¯”topæ›´ä¼˜ï¼Œäº¤äº’æ›´å¥½ï¼ŒåŒæ—¶å¯ä»¥ç›´è§‚çœ‹åˆ°èµ„æºå ç”¨æƒ…å†µ<br>åŸºæœ¬å‘½ä»¤ä¸topä¸€è‡´<br><img src="/images/2018-08-04-15333484387393.jpg" width="70%" height="50%"></p><hr><p>6ï¸âƒ£topï¼šåŠ¨æ€æŸ¥çœ‹ç³»ç»Ÿè¿è¡ŒçŠ¶æ€<br>    -u æŒ‡å®šç”¨æˆ·å<br>    -p æŒ‡å®šè¿›ç¨‹</p><p>7ï¸âƒ£nvidia-smi æŸ¥çœ‹æ˜¾å¡çŠ¶æ€<br>watch nvidia-smi å®æ—¶æŸ¥çœ‹æ˜¾å¡çŠ¶æ€ï¼Œå®šæ—¶åˆ·æ–°</p><hr><p>8ï¸âƒ£tail æ˜¾ç¤ºæŒ‡å®šæ–‡ä»¶çš„æœ«å°¾è‹¥å¹²è¡Œ<br>    -f æ˜¾ç¤ºæ–‡ä»¶æœ€æ–°è¿½åŠ çš„å†…å®¹<br>    -n æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨nè¡Œå†…å®¹<br>    -c æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨æœ€åcä¸ªå­—ç¬¦</p><p>å¦‚ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tail file æ˜¾ç¤ºæœ€å10è¡Œ</span><br><span class="line">tail -n +20 file æ˜¾ç¤ºä»ç¬¬20è¡Œè‡³æœ«å°¾</span><br><span class="line">tail -c 10 file æ˜¾ç¤ºæ–‡ä»¶fileçš„æœ€å10ä¸ªå­—ç¬¦</span><br></pre></td></tr></table></figure><pre><code>-------</code></pre><p>9ï¸âƒ£echo ç”¨äºæ‰“å°æŒ‡å®šçš„å­—ç¬¦ä¸²<br><img src="/images/2018-08-04-15333497266470.jpg" width="50%" height="50%"></p><hr><p>ğŸ”Ÿwhich ç”¨äºæŸ¥æ‰¾å¹¶æ˜¾ç¤ºç»™å®šå‘½ä»¤çš„ç»å¯¹è·¯å¾„ï¼ŒwhichæŒ‡ä»¤ä¼šåœ¨ç¯å¢ƒå˜é‡$PATHè®¾ç½®çš„ç›®å½•é‡ŒæŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚ä½¿ç”¨whichå‘½ä»¤ï¼Œå¯ä»¥çœ‹åˆ°æŸä¸ªç³»ç»Ÿå‘½ä»¤æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ‰§è¡Œçš„æ˜¯å“ªä¸ªä½ç½®çš„å‘½ä»¤ã€‚å¦‚ï¼š</p><p><img src="/images/2018-08-04-15333500837235.jpg" width="50%" height="50%"></p><hr><p>1ï¸âƒ£1ï¸âƒ£nohup å°†ç¨‹åºä»¥å¿½ç•¥æŒ‚èµ·ä¿¡å·çš„æ–¹å¼è¿è¡Œï¼Œç»å¸¸ç”¨äºåœ¨æœåŠ¡å™¨è·‘ä»£ç <br>å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python xxx.py &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>å³ï¼Œå°†è¾“å‡ºé‡å®šå‘åˆ°output.txt ï¼›æœ€åä¸€ä¸ª<code>&amp;</code>è¡¨ç¤ºåå°æŒ‚èµ·</p><hr><p>1ï¸âƒ£2ï¸âƒ£cp å¤åˆ¶æ–‡ä»¶   cp [æ–‡ä»¶] [ç›®æ ‡æ–‡ä»¶å¤¹]<br>    -r é€’å½’å¤åˆ¶ï¼Œç”¨äºç›®å½•çš„å¤åˆ¶</p><hr><p>1ï¸âƒ£3ï¸âƒ£mv ç§»åŠ¨æ–‡ä»¶ã€ç›®å½•æˆ–æ›´å  mv [æ–‡ä»¶/æ–‡ä»¶å¤¹] [æ–‡ä»¶å¤¹]<br>    -f å¼ºåˆ¶ï¼Œå½“ç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†ç›–<br>    -i ä¼šè¯¢é—®</p><hr><p>1ï¸âƒ£4ï¸âƒ£rm åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•<br>    -f å¼ºåˆ¶åˆ é™¤<br>    -r é€’å½’åˆ é™¤ï¼Œç”¨äºç›®å½•åˆ é™¤</p><hr><p>1ï¸âƒ£5ï¸âƒ£file ç”¨äºåˆ¤æ–­æ–‡ä»¶çš„åŸºæœ¬æ•°æ®<br>å¦‚ï¼š</p><p><img src="/images/2018-08-05-15334547949248.jpg" width="80%" height="50%"></p><hr><p>1ï¸âƒ£6ï¸âƒ£tar å¯¹æ–‡ä»¶æ‰“åŒ…/å‹ç¼©<br>    -t æŸ¥çœ‹æ‰“åŒ…æ–‡ä»¶çš„å†…å®¹å«æœ‰å“ªäº›æ–‡ä»¶å<br>    -x è§£å‹ç¼©<br>    -c æ–°å»ºæ‰“åŒ…æ–‡ä»¶<br>    -C æŒ‡å®šå‹ç¼©/è§£å‹ç›®å½•<br>    -v è§£å‹/å‹ç¼©è¿‡ç¨‹ä¸­å°†å¤„ç†çš„æ–‡ä»¶åæ˜¾ç¤ºå‡ºæ¥<br>å¸¸ç”¨çš„ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">å‹ç¼©ï¼štar -jcv -f filename.tar.bz2 è¦è¢«å¤„ç†çš„æ–‡ä»¶æˆ–ç›®å½•åç§°</span><br><span class="line">æŸ¥è¯¢ï¼štar -jtv -f filename.tar.bz2</span><br><span class="line">è§£å‹ï¼štar -jxv -f filename.tar.bz2 -C æ¬²è§£å‹ç¼©çš„ç›®å½•</span><br></pre></td></tr></table></figure><hr><p>1ï¸âƒ£7ï¸âƒ£wc word count ç»Ÿè®¡æ–‡ä»¶å†…å®¹ä¿¡æ¯ï¼Œå¦‚è¡Œæ•°ã€å­—ç¬¦æ•°<br>    -l æ˜¾ç¤ºæ–‡ä»¶è¡Œæ•°<br>    -c æ˜¾ç¤ºå­—èŠ‚æ•°<br>    -m æ˜¾ç¤ºå­—ç¬¦æ•°<br>    -w æ˜¾ç¤ºå­—æ•°  å­—è¢«å®šä¹‰ä¸ºç”±ç©ºç™½ã€è·³æ ¼ã€æ¢è¡Œå­—ç¬¦åˆ†éš”çš„å­—ç¬¦ä¸²<br>    -L æ˜¾ç¤ºæœ€é•¿è¡Œçš„é•¿åº¦<br>    ä¸åŠ å‚æ•°ï¼Œæ‰€æœ‰çš„éƒ½æ˜¾ç¤ºï¼Œä¾æ¬¡æ˜¯è¡Œæ•°ã€å•è¯æ•°ã€å­—èŠ‚æ•°ã€æ–‡ä»¶å</p><hr><p>1ï¸âƒ£8ï¸âƒ£df æ˜¾ç¤ºç£ç›˜ç›¸å…³ä¿¡æ¯<br>    -h ä»¥å¯è¯»æ€§è¾ƒé«˜çš„æ–¹å¼æ˜¾ç¤ºä¿¡æ¯</p><hr><p>1ï¸âƒ£9ï¸âƒ£scp æœåŠ¡å™¨ä¹‹é—´çš„æ–‡ä»¶å¤åˆ¶<br>    å¦‚:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /test1 zhlin@123.12.1.12:/home/zhlin</span><br></pre></td></tr></table></figure><h3 id="âœ¨å¿«æ·é”®"><a href="#âœ¨å¿«æ·é”®" class="headerlink" title="âœ¨å¿«æ·é”®"></a>âœ¨å¿«æ·é”®</h3><p>Ctrl+a è·³åˆ°è¡Œé¦–<br>Ctrl+c é€€å‡ºå½“å‰è¿›ç¨‹<br>Ctrl+e è·³åˆ°é¡µå°¾<br>Ctrl+k åˆ é™¤å½“å‰å…‰æ ‡åé¢çš„æ–‡å­—<br>Ctrl+l æ¸…å±ï¼Œç­‰ä»·äºclear<br>Ctrl+r æœç´¢ä¹‹å‰æ‰“è¿‡çš„å‘½ä»¤<br>Ctrl+u åˆ é™¤å½“å‰å…‰æ ‡å‰é¢çš„æ–‡å­—<br>âœ¨Ctrl+å·¦å³é”® å•è¯ä¹‹é—´è·³è½¬ åœ¨Macä¸Šå¯ä»¥ä½¿ç”¨option+å·¦å³é”®<br>Ctrl+y è¿›è¡Œæ¢å¤åˆ é™¤<br>Ctrl+z å°†å½“å‰è¿›ç¨‹è½¬åˆ°åå°ï¼Œä½¿ç”¨fgæ¢å¤</p><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/leo_618/article/details/53003111" target="_blank" rel="noopener">https://blog.csdn.net/leo_618/article/details/53003111</a></p><p>â€”â€”â€”-æŒç»­æ›´æ–°â€”â€”â€”-</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æŠ€å·§ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä¸€ä¸ªå…³äºyieldçš„é‡æ–°è®¤è¯†</title>
      <link href="/2018/07/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Eyield%E7%9A%84%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86/"/>
      <url>/2018/07/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Eyield%E7%9A%84%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<p>ä»Šå¤©é‡åˆ°äº†ä¸€ä¸ªç¥å¥‡çš„â€bugâ€ï¼Œè®©æˆ‘å¯¹yieldçš„ç†è§£æ›´æ·±ä¸€æ­¥ã€‚</p><p>è¿™æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæˆ‘æœ¬æ¥æ‰“ç®—è¯•ç€printä¸€ä¸‹lineå†…éƒ¨çš„æ ¼å¼å’Œå†…å®¹ã€‚<br><img src="/images/2018-07-31-15330184801079.jpg" width="40%" height="40%"></p><p>è¿™æ˜¯è°ƒç”¨çš„ä¸»å‡½æ•°ï¼š<br><img src="/images/2018-07-31-15330185414299.jpg" width="50%" height="50%"></p><p>ç»“æœè·‘å‡ºçš„ç»“æœæ˜¯ï¼š<br><img src="/images/2018-07-31-15330185762441.jpg" width="90%" height="90%"></p><p>ï¼Ÿï¼Ÿï¼Ÿ<br><img src="/images/2018-07-31-15330186003254.jpg" alt=""></p><p>æˆ‘å°è¯•åœ¨å‡½æ•°çš„å¼€å¤´æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330186689312.jpg" width="40%" height="50%"></p><p>ç»“æœä»ç„¶æ²¡æœ‰ä»»ä½•çš„è¾“å‡ºã€‚</p><p>æˆ‘è¯•ç€åœ¨mainå‡½æ•°æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330187249603.jpg" width="50%" height="50%"></p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-31-15330187445810.jpg" width="50%" height="50%"></p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œæ ¹æœ¬æ²¡æœ‰è¿›å…¥åˆ°get_dataset_from_txtå‡½æ•°å•Šã€‚</p><p>æˆ‘ä»¥ä¸ºæ˜¯pycharmçš„é—®é¢˜è¿˜é‡å¯äº†ä¸€éï¼Œç„¶è€Œå¹¶æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚é—®äº†å…¶ä»–äººï¼Œä»–ä»¬ä¹Ÿè§‰å¾—å¾ˆç¥å¥‡ã€‚æœ€åä¸€ä¸ªåŒå­¦çœ‹äº†ä¸€ä¸‹å‡½æ•°ï¼Œå‘ç°äº†é—®é¢˜æ‰€åœ¨ï¼š<strong>yield</strong></p><p>æˆ‘çªç„¶æƒ³èµ·æ¥ï¼Œ<strong>yieldè¿”å›çš„æ˜¯ä¸€ä¸ªgeneratorï¼Œåªæœ‰åœ¨å¯¹generatorè¿›è¡Œéå†æ—¶ï¼Œæ‰ä¼šå¼€å§‹è¿è¡Œ</strong>â€¦</p><p>äºæ˜¯ï¼Œæˆ‘è¯•ç€è¿™ä¹ˆå†™ï¼Œè¯•ç€å¯¹generatoréå†ï¼š</p><p><img src="/images/2018-07-31-15330189280379.jpg" width="50%" height="50%"></p><p>è™½ç„¶æŠ¥é”™äº†ï¼Œä½†å‡½æ•°ç»ˆäºæ˜¯è¿›å»äº†â€¦</p><p><img src="/images/2018-07-31-15330189613535.jpg" width="70%" height="50%"></p><p><strong>ç»“è®ºï¼šæœ‰yieldçš„å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªgeneratorï¼Œå½“å¯¹å…¶è¿›è¡Œéå†æ—¶ï¼Œå‡½æ•°æ‰ä¼šå¼€å§‹è¿è¡Œã€‚</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Python </tag>
            
            <tag> yield </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•2</title>
      <link href="/2018/07/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB2/"/>
      <url>/2018/07/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB2/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨ä¸»è¦çœ‹äº†<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">AllenNLP/ELMO</a>çš„ä»£ç ï¼Œä½†å¹¶æ²¡æœ‰æ‰¾åˆ°å¾ˆå¤šå¯å¤ç”¨çš„ä»£ç ã€‚æœ¬å‘¨ä¹Ÿæ²¡æœ‰æ¯”è¾ƒæœ‰æ„ä¹‰çš„ä»£ç ã€‚</p><hr><h3 id="1ï¸âƒ£get-time-diff"><a href="#1ï¸âƒ£get-time-diff" class="headerlink" title="1ï¸âƒ£get_time_diff"></a>1ï¸âƒ£get_time_diff</h3><p>è·å–å·²ä½¿ç”¨çš„æ—¶é—´<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line">start_time=time.time()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time_dif</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    <span class="string">"""è·å–å·²ä½¿ç”¨æ—¶é—´"""</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    time_dif = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=int(round(time_dif)))</span><br></pre></td></tr></table></figure></p><hr><h3 id="2ï¸âƒ£parserä½¿ç”¨"><a href="#2ï¸âƒ£parserä½¿ç”¨" class="headerlink" title="2ï¸âƒ£parserä½¿ç”¨"></a>2ï¸âƒ£parserä½¿ç”¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--save_dir'</span>, help=<span class="string">'Location of checkpoint files'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--vocab_file'</span>, help=<span class="string">'Vocabulary file'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--train_prefix'</span>, help=<span class="string">'Prefix for train files'</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">    </span><br><span class="line">main(args)   <span class="comment">#ä½¿ç”¨</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†1</title>
      <link href="/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%861/"/>
      <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%861/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Python]<br>assertç”¨æ³•ï¼š</p><p><code>assert expression</code><br>ç­‰ä»·äº<br><code>if not expression: raise AssertionError</code></p><hr><p>2ï¸âƒ£[Pytorch]<br>Pytorch viewï¼š<br>åˆ›å»ºä¸€ä¸ªæ–°çš„tensorï¼Œä½†ä»–ä»¬çš„<strong>dataæ˜¯å…±äº«çš„</strong>ã€‚</p><p><img src="/images/2018-07-29-15328360404485.jpg" width="50%" height="50%"></p><hr><p>3ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œembeddingçš„indexæ˜¯ä¸èƒ½requires_grad=Trueçš„ï¼Œå¦åˆ™ä¼šå‡ºé”™ã€‚<br><a href="https://github.com/pytorch/pytorch/issues/7021" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/7021</a></p><p>ä¹‹å‰çœ‹è¿‡ä¸€ä»½ä»£ç ï¼Œè®¾ç½®volatile=falseä½†æ²¡æœ‰å‡ºé”™ï¼Œæ˜¯å› ä¸ºåœ¨Pytorch0.4ä¹‹åvolatileå·²ç»è¢«å¼ƒç”¨äº†ï¼Œå› æ­¤volatile=falseä¸èµ·ä½œç”¨ï¼Œè€Œé»˜è®¤requires_grad=false</p><hr><p>4ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œ<code>nn.Linear(self.hidden_dim,self.vocab_size)</code>çš„ç»´åº¦æ˜¯vocab_size<em>hidden_dimï¼Œä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚<br>å› ä¸ºnn.Linearçš„<em>*ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºè¾“å…¥ç»´åº¦ï¼Œç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºè¾“å‡ºç»´åº¦</em></em></p><hr><p>5ï¸âƒ£[Pytorch]<br>Pytorchä¸­ï¼Œä½¿ç”¨viewä¸€èˆ¬æ¥è¯´å¿…é¡»è¦ç”¨ .contiguous()ã€‚ä¹Ÿå³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch.view(batch_size, <span class="number">-1</span>).t().contiguous()</span><br></pre></td></tr></table></figure><p>contiguous()çš„å®˜æ–¹è§£é‡Šï¼š<br><a href="https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930" target="_blank" rel="noopener">https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930</a></p><blockquote><p>It means that your tensor is not a single block of memory, but a block with holes. view can be only used with contiguous tensors, so if you need to use it here, just call .contiguous() before.</p></blockquote><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œcontiguousä¼šå°†æ•°æ®å­˜åˆ°ä¸€ä¸ªè¿ç»­çš„ç©ºé—´å†…ï¼ˆblockï¼‰ã€‚</p><hr><p>6ï¸âƒ£[Pytorch]<br>è°ƒç”¨Cross_entropyæ—¶ï¼ŒPytorchä¼šå¸®åŠ©ä½ åŠ logå’Œsoftmaxã€‚</p><p><img src="/images/2018-07-29-15328370301774.jpg" alt=""></p><hr><p>7ï¸âƒ£[Paper]<br><a href="https://arxiv.org/abs/1807.02291" target="_blank" rel="noopener">Sliced_RNN</a></p><p>å°†RNNåˆ†å—ä»¥æé«˜å¹¶è¡Œæ€§ï¼Œç”šè‡³æ¯å±‚çš„RNNéƒ½å¯ä»¥ä¸ä¸€æ ·ï¼Œè¾¾åˆ°æŠ½å–ä¸åŒç¨‹åº¦çš„æŠ½è±¡è¯­ä¹‰ä¿¡æ¯çš„ç›®çš„ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ä¸åŒä»»åŠ¡ä¸Šéƒ½æœ‰ä¸€å®šçš„æå‡ï¼Œä½†é€Ÿåº¦çš„æå‡å¾ˆå¤§ã€‚</p><p><img src="/images/2018-07-29-15328372609264.jpg" width="50%" height="50%"></p><hr><p>8ï¸âƒ£[Tf-idf]<br>è®¡ç®—è¯è¯­å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦</p><p><a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Tf-idf</a></p><p>tfæ˜¯è¯é¢‘ï¼Œidfæ˜¯é€†å‘æ–‡ä»¶é¢‘ç‡ã€‚ä¹Ÿå³å¦‚æœè¯åœ¨è¯¥å¥å‡ºç°çš„æ¬¡æ•°è¶Šå¤šï¼Œåœ¨æ‰€æœ‰æ–‡æœ¬çš„å‡ºç°æ¬¡æ•°è¶Šå°‘ï¼Œåˆ™è¯å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦è¶Šé«˜ã€‚</p><hr><p>9ï¸âƒ£[Numpy]<br>åœ¨Numpyä¸­ï¼Œä¸€ä¸ªåˆ—è¡¨è™½ç„¶æ˜¯æ¨ªç€è¡¨ç¤ºçš„ï¼Œä½†å®ƒæ˜¯åˆ—å‘é‡ã€‚æˆ‘ä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚</p><p><img src="/images/2018-07-29-15328375536418.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Python </tag>
            
            <tag> Paper </tag>
            
            <tag> Tf-idf </tag>
            
            <tag> Numpy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Macé…ç½®å¤æ—¦æœ‰çº¿ç½‘</title>
      <link href="/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E9%85%8D%E7%BD%AE%E5%A4%8D%E6%97%A6%E6%9C%89%E7%BA%BF%E7%BD%91/"/>
      <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E9%85%8D%E7%BD%AE%E5%A4%8D%E6%97%A6%E6%9C%89%E7%BA%BF%E7%BD%91/</url>
      
        <content type="html"><![CDATA[<h3 id="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"><a href="#é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨" class="headerlink" title="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"></a>é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨</h3><p>æœ‰çº¿ä¼¼ä¹ä¸æ”¯æŒDHCPï¼Œå› æ­¤åªå¥½è‡ªå·±è®¾ç½®ã€‚<br>é¦–å…ˆè¿æ¥ä¸Šæœ‰çº¿ï¼Œå°†é…ç½®iPv4é€‰ä¸ºæ‰‹åŠ¨ã€‚é—®å®éªŒå®¤çš„å­¦é•¿å…·ä½“çš„ipåœ°å€ã€å­ç½‘æ©ç ã€è·¯ç”±å™¨ã€DNSæœåŠ¡å™¨ã€‚å…¶ä¸­ipåœ°å€æœ€åä¸‰ä½è¦è‡ªå·±è®¾å®šï¼Œåªè¦ä¸å’Œå…¶ä»–äººå†²çªå°±å¥½ã€‚</p><p><img src="/images/2018-07-29-15328333841584.jpg" width="50%" height="50%"></p><p><img src="/images/2018-07-29-15328335236981.jpg" width="50%" height="50%"></p><h3 id="æ‰‹åŠ¨è®¤è¯"><a href="#æ‰‹åŠ¨è®¤è¯" class="headerlink" title="æ‰‹åŠ¨è®¤è¯"></a>æ‰‹åŠ¨è®¤è¯</h3><p>åˆ°è®¤è¯å¹³å°ï¼Œä¸‹è½½Macå®¢æˆ·ç«¯ï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ª.shæ–‡ä»¶ï¼š<br><a href="http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1" target="_blank" rel="noopener">http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1</a></p><p><img src="/images/2018-07-29-15328336395029.jpg" width="30%" height="30%"></p><p>ç„¶åï¼Œæ‰“å¼€æ–‡ä»¶é…ç½®ç”¨æˆ·åå¯†ç ï¼Œæ³¨æ„åˆ°ç­‰å·åé¢è¦æœ‰åŒå¼•å·ï¼š</p><p><img src="/images/2018-07-29-15328337135244.jpg" width="50%" height="50%"></p><p>ä¿å­˜å¹¶æ”¾å…¥ç»ˆç«¯è¿è¡Œï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥ä½¿ç”¨æœ‰çº¿ç½‘äº†ã€‚</p><h3 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h3><p>ä¼¼ä¹ï¼Œæ¯æ¬¡é‡æ–°è¿æ¥éƒ½è¦è¿™æ ·é…ç½®ï¼Œæˆ‘æ²¡æœ‰è¯•è¿‡ä¸æ¸…æ¥šï¼›<br>æœ‰çº¿ç½‘å¥½åƒä¹Ÿæ²¡æœ‰æ¯”æ— çº¿ç½‘å¿«å¤šå°‘ï¼Œä½†åº”è¯¥ä¼šç¨³å®šä¸€äº›ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç½‘ç»œ </tag>
            
            <tag> é…ç½® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sshå¿«é€Ÿç™»å½•é…ç½®</title>
      <link href="/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/ssh%E5%BF%AB%E9%80%9F%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/ssh%E5%BF%AB%E9%80%9F%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>åˆ†é…äº†æœåŠ¡å™¨ä¹‹åï¼Œæ¯æ¬¡è¦sshè¿›å…¥éƒ½å¾ˆéº»çƒ¦ï¼š<code>ssh user_name@ip_address</code> ç„¶åè¿˜è¦è¾“å…¥å¯†ç ã€‚</p><p>ç‰¹åˆ«æ˜¯å¦‚æœåˆ†é…äº†å¤šä¸ªæœåŠ¡å™¨ï¼Œé‚£æœ‰æ—¶å€™è¿˜å®¹æ˜“å¿˜è®°ipåœ°å€ã€‚å› æ­¤å¦‚æœèƒ½å¤Ÿä¸€æ¡å‘½ä»¤å°±è¿›å…¥æœåŠ¡å™¨èƒ½å¤Ÿå‡å°‘éº»çƒ¦ã€‚<br>ä¸»è¦æœ‰ä¸‰ç‚¹ï¼š</p><ol><li>åˆ›å»ºrsa key</li><li>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</li><li>è®¾ç½®alias</li></ol><h1 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h1><h2 id="åˆ›å»ºrsa-key"><a href="#åˆ›å»ºrsa-key" class="headerlink" title="åˆ›å»ºrsa key"></a>åˆ›å»ºrsa key</h2><p>åœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>å½“ç„¶å¦‚æœä»¥å‰æœ‰åˆ›å»ºè¿‡çš„å¯ä»¥ä¸ç”¨ã€‚</p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-29-Xnip2018-07-29_10-43-15.jpg" width="50%" height="50%"></p><h2 id="ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨"><a href="#ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨" class="headerlink" title="ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨"></a>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</h2><p>ä½¿ç”¨å‘½ä»¤ï¼š<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub user@127.0.0.1</span><br></pre></td></tr></table></figure></p><p>è¾“å…¥å¯†ç å³å¯</p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-29-15328324683354.jpg" width="60%" height="60%"></p><h2 id="è®¾ç½®alias"><a href="#è®¾ç½®alias" class="headerlink" title="è®¾ç½®alias"></a>è®¾ç½®alias</h2><p>å®Œæˆä»¥ä¸Šæ­¥éª¤å°±å¯ä»¥ä¸è¾“å…¥å¯†ç ç™»å½•ï¼Œä½†è¿˜æ˜¯éœ€è¦è¾“å…¥ipåœ°å€å’Œç”¨æˆ·åï¼Œä¸ºäº†æ›´ç®€åŒ–æ“ä½œï¼Œç»™å‘½ä»¤èµ·ä¸ªåˆ«åã€‚éœ€è¦é…ç½® .bash_profileæ–‡ä»¶ã€‚<br>è¾“å…¥å‘½ä»¤:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶åé¢æ·»åŠ ä»¥ä¸‹æ–‡å­—ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># alias </span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ Ã—Ã—Ã—æ˜¯ä½ è‡ªå·±èµ·çš„åå­—ï¼Œå¯ä»¥æ˜¯æœåŠ¡å™¨çš„åå­—ï¼Œuser_nameå’Œip_addressæ˜¯è‡ªå·±æœåŠ¡å™¨çš„ç”¨æˆ·åå’Œåœ°å€ã€‚ä¿å­˜æ›´æ”¹é€€å‡ºã€‚</p><p>ç„¶åè¿˜è¦ä½¿å…¶ç”Ÿæ•ˆ:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><p>è¿™æ ·ï¼Œè¾“å…¥åˆ«åï¼Œå°±å¯ä»¥ç›´æ¥ç™»å½•äº†ï¼š</p><p><img src="/images/2018-07-29-15328329815456.jpg" width="50%" height="50%"></p><h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><p><a href="https://www.jianshu.com/p/66d658c7cb9e" target="_blank" rel="noopener">https://www.jianshu.com/p/66d658c7cb9e</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> é…ç½® </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºå›°æƒ‘åº¦</title>
      <link href="/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E%E5%9B%B0%E6%83%91%E5%BA%A6/"/>
      <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E%E5%9B%B0%E6%83%91%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ å¤©åœ¨å†™æ–°æ‰‹ä»»åŠ¡<a href="https://github.com/FudanNLP/nlp-beginner" target="_blank" rel="noopener">task3</a>çš„æ—¶å€™ï¼Œå‚è€ƒäº†Pytorchå®˜æ–¹exampleçš„word language modelï¼Œå®˜æ–¹exampleåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—å›°æƒ‘åº¦æ˜¯è¿™æ ·çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">math.exp(cur_loss)</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œcur_lossè¡¨ç¤ºäº¤å‰ç†µçš„lossï¼Œå³ $-P(\hat{x})logP(x)$ï¼Œ$\hat{x}$è¡¨ç¤ºground truthã€‚</p><p>ç„¶è€Œï¼Œåœ¨æŸ¥é˜…äº†å›°æƒ‘åº¦ç›¸å…³èµ„æ–™åï¼Œæˆ‘å‘ç°ï¼Œå›°æƒ‘åº¦çš„å®šä¹‰æ˜¯è¿™æ ·çš„ï¼š</p><script type="math/tex; mode=display">\begin{aligned}PP(S)= &{P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\= &\sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>è¿™æ˜¯å¦ä¸€ç§å½¢å¼:</p><script type="math/tex; mode=display">\begin{aligned}Perplexity (W)=& 2^{H(W)} \\= & {P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\= & \sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>å¯ä»¥çœ‹åˆ°ï¼ŒäºŒè€…æœ¬è´¨æ˜¯ä¸€æ ·çš„ã€‚</p><p><strong>é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆåœ¨ä»£ç ä¸­ä»¥eä¸ºåº•å»è®¡ç®—å›°æƒ‘åº¦ï¼Œè€Œä¸æ˜¯2å‘¢?</strong></p><p>å®é™…ä¸Šï¼Œæ˜¯å› ä¸ºåœ¨ä¸Šè¿°å…¬å¼ä¸­ï¼Œlogæ˜¯ä»¥2ä¸ºåº•çš„ï¼Œä½†åœ¨Pytorchä¸­ï¼Œlogé»˜è®¤æ˜¯ä»¥eä¸ºåº•çš„ã€‚å› æ­¤åœ¨ä»£ç ä¸­ï¼Œéœ€è¦ç”¨eä½œä¸ºæŒ‡æ•°çš„åº•æ¥è¿˜åŸæˆå›°æƒ‘åº¦çš„åŸæœ¬å½¢å¼ï¼š </p><script type="math/tex; mode=display">\begin{aligned}\sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>æœ€åè¿™æ˜¯perplexityçš„æ•°å­¦æ¨å¯¼ï¼š<br><a href="https://www.zhihu.com/question/58482430" target="_blank" rel="noopener">https://www.zhihu.com/question/58482430</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> å›°æƒ‘åº¦ </tag>
            
            <tag> perplexity </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯2</title>
      <link href="/2018/07/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D2/"/>
      <url>/2018/07/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D2/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨çš„è¯—è¯æœ‰ä¸¤ç¯‡æ˜¯å·²ç»èƒŒè¿‡çš„ï¼Œæƒå½“æ˜¯å¤ä¹ äº†ä¸€éã€‚</p><hr><p>1ï¸âƒ£</p><h3 id="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"><a href="#ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’" class="headerlink" title="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"></a>ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’</h3><p>[å”] æç™½<br>æš®ä»ç¢§å±±ä¸‹ï¼Œå±±æœˆéšäººå½’ã€‚<br>å´é¡¾æ‰€æ¥å¾„ï¼Œè‹è‹æ¨ªç¿ å¾®ã€‚<br>ç›¸æºåŠç”°å®¶ï¼Œç«¥ç¨šå¼€è†æ‰‰ã€‚<br>ç»¿ç«¹å…¥å¹½å¾„ï¼Œé’èæ‹‚è¡Œè¡£ã€‚<br>æ¬¢è¨€å¾—æ‰€æ†©ï¼Œç¾é…’èŠå…±æŒ¥ã€‚<br>é•¿æ­ŒåŸæ¾é£ï¼Œæ›²å°½æ²³æ˜Ÿç¨€ã€‚<br>æˆ‘é†‰å›å¤ä¹ï¼Œé™¶ç„¶å…±å¿˜æœºã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b900307db2a20054269a2a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b900307db2a20054269a2a</a></p><hr><p>2ï¸âƒ£</p><h3 id="é€¢å…¥äº¬ä½¿"><a href="#é€¢å…¥äº¬ä½¿" class="headerlink" title="é€¢å…¥äº¬ä½¿"></a>é€¢å…¥äº¬ä½¿</h3><p>[å”] å²‘å‚<br>æ•…å›­ä¸œæœ›è·¯æ¼«æ¼«ï¼ŒåŒè¢–é¾™é’Ÿæ³ªä¸ä¹¾ã€‚<br><strong>é©¬ä¸Šç›¸é€¢æ— çº¸ç¬”ï¼Œå‡­å›ä¼ è¯­æŠ¥å¹³å®‰ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b92218df0eea006335f923" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92218df0eea006335f923</a></p><hr><p>3ï¸âƒ£</p><h3 id="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"><a href="#å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤" class="headerlink" title="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"></a>å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤</h3><p>[å®‹] è‹è½¼<br>å¤§æ±Ÿä¸œå»ï¼Œæµªæ·˜å°½ã€åƒå¤é£æµäººç‰©ã€‚æ•…å’è¥¿è¾¹ï¼Œäººé“æ˜¯ã€ä¸‰å›½å‘¨éƒèµ¤å£ã€‚ä¹±çŸ³ç©¿ç©ºï¼ŒæƒŠæ¶›æ‹å²¸ï¼Œå·èµ·åƒå †é›ªã€‚æ±Ÿå±±å¦‚ç”»ï¼Œä¸€æ—¶å¤šå°‘è±ªæ°ã€‚<br>é¥æƒ³å…¬ç‘¾å½“å¹´ï¼Œå°ä¹”åˆå«äº†ï¼Œé›„å§¿è‹±å‘ã€‚ç¾½æ‰‡çº¶å·¾ï¼Œè°ˆç¬‘é—´ï¼Œæ¨¯æ©¹ç°é£çƒŸç­ã€‚æ•…å›½ç¥æ¸¸ï¼Œå¤šæƒ…åº”ç¬‘æˆ‘ï¼Œæ—©ç”Ÿåå‘ã€‚<strong>äººç”Ÿå¦‚æ¢¦ï¼Œä¸€å°Šè¿˜é…¹æ±Ÿæœˆã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•1</title>
      <link href="/2018/07/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB1/"/>
      <url>/2018/07/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB1/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-get-batch"><a href="#1ï¸âƒ£-get-batch" class="headerlink" title="1ï¸âƒ£ get_batch"></a>1ï¸âƒ£ get_batch</h3><p>æ³¨æ„åˆ°shuffleçš„æ ‡å‡†åšæ³•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self,data,batch_size=<span class="number">32</span>,is_shuffle)</span>:</span></span><br><span class="line">  N=len(data)  <span class="comment">#è·å¾—æ•°æ®çš„é•¿åº¦</span></span><br><span class="line">  <span class="keyword">if</span> is_shuffle <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">    r=random.Random()</span><br><span class="line">    r.seed()</span><br><span class="line">    r.shuffle(data) <span class="comment">#å¦‚æœis_shuffleä¸ºçœŸåˆ™æ‰“ä¹±</span></span><br><span class="line">  <span class="comment">#å¼€å§‹è·å¾—batchï¼Œä½¿ç”¨[ for in ]</span></span><br><span class="line">  batch=[data[k:k+batch_size] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,N,batch_size)]</span><br><span class="line">  <span class="keyword">if</span> N%batch_size!=<span class="number">0</span>:  <span class="comment">#å¤„ç†ä¸æ•´é™¤é—®é¢˜ï¼Œå¦‚æœæœ‰æ˜¾å¼è¦æ±‚ä¸¢æ‰åˆ™ä¸éœ€è¦å¤„ç†ï¼Œè¿™é‡Œé»˜è®¤å¤„ç†</span></span><br><span class="line">    remainder=N-N%batch_size  <span class="comment">#å‰©ä¸‹çš„éƒ¨åˆ†</span></span><br><span class="line">    batch.append(data[temp:N])</span><br><span class="line">  <span class="keyword">return</span> batch</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"><a href="#2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"></a>2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥</h3><p>å®é™…ä¸Šè¿™ä»½ä»£ç æœ‰ç‚¹é—®é¢˜ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå‘ç°gloveæ–‡ä»¶éœ€è¦æ”¾åœ¨gensimçš„æ–‡ä»¶å¤¹ä¸‹æ‰èƒ½è¢«è¯»åˆ°(7.20 updated,åº”è¯¥ä½¿ç”¨ç»å¯¹åœ°å€)ï¼Œå¹¶ä¸å¥½ã€‚</p><p>æ•™ç¨‹åœ°å€ï¼š<a href="https://radimrehurek.com/gensim/scripts/glove2word2vec.html" target="_blank" rel="noopener">gensim: scripts.glove2word2vec â€“ Convert glove format to word2vec</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. ä½¿ç”¨gensimè¯»å…¥word2vec</span></span><br><span class="line"></span><br><span class="line">model = gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">        fname=<span class="string">'GoogleNews-vectors-negative300-SLIM.bin'</span>, binary=<span class="keyword">True</span>)</span><br><span class="line">words = model.vocab  <span class="comment">#è·å¾—è¯è¡¨</span></span><br><span class="line">vector= model[word]  <span class="comment">#wordæ˜¯wordsé‡Œé¢çš„å…ƒç´ </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. ä½¿ç”¨gensimè¯»å…¥glove</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> datapath, get_tmpfile</span><br><span class="line"><span class="keyword">from</span> gensim.scripts.glove2word2vec <span class="keyword">import</span> glove2word2vec</span><br><span class="line">glove_file=datapath(<span class="string">'glove.txt'</span>)  <span class="comment">#æœ€å¥½ä½¿ç”¨ç»å¯¹åœ°å€</span></span><br><span class="line">tmp_file=get_tmpfile(<span class="string">'word2vec.txt'</span>)</span><br><span class="line">glove2word2vec(glove_file,tmp_file)</span><br><span class="line">model=KeyedVectors.load_word2vec_format(tmp_file)</span><br><span class="line"><span class="comment">#æ¥ä¸‹æ¥ä½¿ç”¨çš„æ–¹æ³•æ˜¯ä¸€æ ·çš„</span></span><br></pre></td></tr></table></figure></p><hr><h3 id="3ï¸âƒ£data-splitæ–¹æ³•"><a href="#3ï¸âƒ£data-splitæ–¹æ³•" class="headerlink" title="3ï¸âƒ£data_splitæ–¹æ³•"></a>3ï¸âƒ£data_splitæ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span><span class="params">(seed=<span class="number">1</span>, proportion=<span class="number">0.7</span>)</span>:</span> </span><br><span class="line">    data = list(iter_corpus())</span><br><span class="line">    ids = list(range(len(data)))</span><br><span class="line"></span><br><span class="line">    N = int(len(ids) * proportion)  <span class="comment"># number of training data</span></span><br><span class="line"></span><br><span class="line">    rng = random.Random(seed)</span><br><span class="line">    rng.shuffle(ids)</span><br><span class="line">    test_ids = set(ids[N:])</span><br><span class="line">    train_data = []</span><br><span class="line">    test_data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> x[<span class="number">1</span>] <span class="keyword">in</span> test_ids:  <span class="comment"># x[1]: sentence id</span></span><br><span class="line">            test_data.append(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_data.append(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_data, test_data</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"><a href="#4ï¸âƒ£å¯¹stringé¢„å¤„ç†" class="headerlink" title="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"></a>4ï¸âƒ£å¯¹stringé¢„å¤„ç†</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_str</span><span class="params">(string)</span>:</span></span><br><span class="line">    string = re.sub(<span class="string">r"[^A-Za-z0-9()!?\'\`]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'s"</span>, <span class="string">" \'s"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'m"</span>, <span class="string">" \'m"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ve"</span>, <span class="string">" \'ve"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"n\'t"</span>, <span class="string">" n\'t"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'re"</span>, <span class="string">" \'re"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'d"</span>, <span class="string">" \'d"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ll"</span>, <span class="string">" \'ll"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r","</span>, <span class="string">" , "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"!"</span>, <span class="string">" ! "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\("</span>, <span class="string">" \( "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\)"</span>, <span class="string">" \) "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\?"</span>, <span class="string">" \? "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\s&#123;2,&#125;"</span>, <span class="string">" "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\@.*?[\s\n]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"https*://.+[\s]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    <span class="keyword">return</span> string.strip().lower()</span><br></pre></td></tr></table></figure><hr><h3 id="5ï¸âƒ£collate-fn-batchï¼‰"><a href="#5ï¸âƒ£collate-fn-batchï¼‰" class="headerlink" title="5ï¸âƒ£collate_fn(batchï¼‰"></a>5ï¸âƒ£collate_fn(batchï¼‰</h3><p>é‡å†™collate_fnç»„å»ºmini-batchï¼Œåœ¨NLPä¸­å¸¸ç”¨ï¼Œå¥å­çš„ä¸ç­‰é•¿æ€§<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span>  <span class="comment"># rewrite collate_fn to form a mini-batch</span></span><br><span class="line">    lengths = np.array([len(data[<span class="string">'sentence'</span>]) <span class="keyword">for</span> data <span class="keyword">in</span> batch])</span><br><span class="line">    sorted_index = np.argsort(-lengths)</span><br><span class="line">    lengths = lengths[sorted_index]  <span class="comment"># descend order</span></span><br><span class="line"></span><br><span class="line">    max_length = lengths[<span class="number">0</span>]</span><br><span class="line">    batch_size = len(batch)</span><br><span class="line">    sentence_tensor = torch.LongTensor(batch_size, int(max_length)).zero_()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> enumerate(sorted_index):</span><br><span class="line">        sentence_tensor[i][:lengths[i]] = torch.LongTensor(batch[index][<span class="string">'sentence'</span>][:max_length])</span><br><span class="line"></span><br><span class="line">    sentiments = torch.autograd.Variable(torch.LongTensor([batch[i][<span class="string">'sentiment'</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_index]))</span><br><span class="line">    <span class="keyword">if</span> config.use_cuda:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()).cuda(), lengths)  <span class="comment">#remember to transpose</span></span><br><span class="line">        sentiments = sentiments.cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()),lengths)  <span class="comment"># remember to transpose</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'sentence'</span>: packed_sequences, <span class="string">'sentiment'</span>: sentiments&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## é‡å†™collate_fn(batch)ä»¥ç”¨äºdataloaderä½¿ç”¨ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š</span></span><br><span class="line"></span><br><span class="line">train_dataloader=DataLoader(train_data,batch_size=<span class="number">32</span>,shuffle=<span class="keyword">True</span>,collate_fn=collate_fn)</span><br><span class="line">â€‹</span><br><span class="line"><span class="comment">## å…¶ä¸­ï¼Œtrain_dataloaderå¯å¾ªç¯éå†â€‹â€‹ã€‚</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><hr><h3 id="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"><a href="#6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator" class="headerlink" title="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"></a>6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator</h3><p>yieldçš„ç”¨æ³•<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span><span class="params">(txt_file)</span>:</span>     <span class="comment"># return generator</span></span><br><span class="line">    <span class="keyword">with</span> open(txt_file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">if</span> len(line.strip())==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            sentence=list(line.strip())+[<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            <span class="keyword">yield</span> sentence</span><br><span class="line">            </span><br><span class="line"><span class="comment">#åœ¨ä½¿ç”¨çš„æ—¶å€™ï¼š</span></span><br><span class="line">dataset=get_dataset(txt_file)</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#å¦‚æœéœ€è¦è¿˜å¯ä»¥æ”¹æˆlistå½¢å¼</span></span><br><span class="line">dataset=list(get_dataset(txt_file))</span><br></pre></td></tr></table></figure></p><hr><h3 id="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"><a href="#7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹" class="headerlink" title="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"></a>7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹</h3><p>æ ¹æ®rnn_typeåŠ¨æ€åˆ›å»ºå¯¹è±¡å®ä¾‹ï¼Œä½¿ç”¨äº†getattr<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rnn in ['GRU','LSTM','RNN']</span></span><br><span class="line"></span><br><span class="line">self.rnn = getattr(nn, self.rnn_type)(self.embedding_dim, self.hidden_dim, self.num_layers, dropout=self.dropout)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯1</title>
      <link href="/2018/07/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D1/"/>
      <url>/2018/07/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D1/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨èƒŒäº†å››ç¯‡ã€‚</p><hr><p>1ï¸âƒ£</p><h3 id="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"><a href="#ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹" class="headerlink" title="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"></a>ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹</h3><p>[å®‹] è‹è½¼<br>å¤œé¥®ä¸œå¡é†’å¤é†‰ï¼Œå½’æ¥å½·å½¿ä¸‰æ›´ã€‚å®¶ç«¥é¼»æ¯å·²é›·é¸£ï¼Œæ•²é—¨éƒ½ä¸åº”ï¼Œå€šæ–å¬æ±Ÿå£°ã€‚<br><strong>é•¿æ¨æ­¤èº«éæˆ‘æœ‰ï¼Œä½•æ—¶å¿˜å´è¥è¥ï¼Ÿ</strong>å¤œé˜‘é£é™ç¸ çº¹å¹³ï¼Œå°èˆŸä»æ­¤é€ï¼Œæ±Ÿæµ·å¯„é¦€ç”Ÿã€‚</p><p>ç¸ ï¼ˆhÃºï¼‰çº¹<br>çš‹ï¼ˆgaoï¼‰<br><a href="http://m.xichuangzhu.com/work/57ae79400a2b580063150e39" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ae79400a2b580063150e39</a></p><hr><p>2ï¸âƒ£</p><h3 id="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"><a href="#è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦" class="headerlink" title="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"></a>è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦</h3><p>[æ¸…] ç‹å›½ç»´<br>é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦ã€‚ä¸é“å½’æ¥ï¼Œé›¶è½èŠ±å¦‚è®¸ã€‚èŠ±åº•ç›¸çœ‹æ— ä¸€è¯­ï¼Œç»¿çª—æ˜¥ä¸å¤©ä¿±è«ã€‚<br>å¾…æŠŠç›¸æ€ç¯ä¸‹è¯‰ã€‚ä¸€ç¼•æ–°æ¬¢ï¼Œæ—§æ¨åƒåƒç¼•ã€‚<strong>æœ€æ˜¯äººé—´ç•™ä¸ä½ï¼Œæœ±é¢œè¾é•œèŠ±è¾æ ‘ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17</a></p><hr><p>3ï¸âƒ£</p><h3 id="é€å‹äºº"><a href="#é€å‹äºº" class="headerlink" title="é€å‹äºº"></a>é€å‹äºº</h3><p>[å”] æç™½<br>é’å±±æ¨ªåŒ—éƒ­ï¼Œç™½æ°´ç»•ä¸œåŸã€‚<br>æ­¤åœ°ä¸€ä¸ºåˆ«ï¼Œå­¤è“¬ä¸‡é‡Œå¾ã€‚<br><strong>æµ®äº‘æ¸¸å­æ„ï¼Œè½æ—¥æ•…äººæƒ…ã€‚</strong><br>æŒ¥æ‰‹è‡ªå…¹å»ï¼Œè§è§ç­é©¬é¸£ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4</a></p><hr><p>4ï¸âƒ£</p><h3 id="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"><a href="#é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ" class="headerlink" title="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"></a>é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ</h3><p>[å”] æç™½<br>æ•…äººè¥¿è¾é»„é¹¤æ¥¼ï¼ŒçƒŸèŠ±ä¸‰æœˆä¸‹æ‰¬å·ã€‚<br>å­¤å¸†è¿œå½±ç¢§ç©ºå°½ï¼Œå”¯è§é•¿æ±Ÿå¤©é™…æµã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å®‰è£…condaé”™è¯¯</title>
      <link href="/2018/07/23/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%AE%89%E8%A3%85conda%E9%94%99%E8%AF%AF/"/>
      <url>/2018/07/23/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%AE%89%E8%A3%85conda%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<p>åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…condaçš„æ—¶å€™ï¼Œä¸€å¼€å§‹ä½¿ç”¨äº†pipå®‰è£…<br><code>pip install conda</code><br>åœ¨å®‰è£…å¥½condaä¹‹åæƒ³è¦ä½¿ç”¨condaå‘½ä»¤ï¼Œå‡ºç°ï¼š</p><p>ERROR: The install method you used for condaâ€”probably either <code>pip install conda</code> or <code>easy_install conda</code>â€”is not compatible with using conda as an application. If your intention is to install conda as a standalone application, currently supported install methods include the Anaconda installer and the miniconda installer. You can download the miniconda installer from <a href="https://conda.io/miniconda.html" target="_blank" rel="noopener">https://conda.io/miniconda.html</a>.</p><p><img src="/images/2018-07-23-15323331261104.jpg" alt=""></p><p>ç„¶ååˆ°å®˜ç½‘ä¸‹è½½.shæ–‡ä»¶å¹¶bashå®‰è£…ï¼Œä»ç„¶æ²¡æœ‰è§£å†³è¯¥é—®é¢˜ï¼›æ¥ç€å°è¯•pip uninstall condaï¼Œå‡ºç°<br><img src="/images/2018-07-23-15323337042406.jpg" alt=""></p><p>æœ€ååœ¨æŸ¥é˜…äº†ç½‘ä¸Šä¹‹åï¼Œä½¿ç”¨ <code>which conda</code>æ‰¾åˆ°condaçš„åœ°å€ï¼Œå¹¶åˆ é™¤<code>rm Ã—Ã—Ã—</code><br><img src="/images/2018-07-23-15323337894186.jpg" alt=""></p><p>æœ€åé‡æ–°bashå®‰è£…å³å¯ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> conda </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
