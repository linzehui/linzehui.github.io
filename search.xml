<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>ä½³å¥åˆ†äº«2</title>
      <link href="/2019/07/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB2/"/>
      <url>/2019/07/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB2/</url>
      
        <content type="html"><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>Learn to be ordinary before you wish to be extraordinary.</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡24</title>
      <link href="/2019/07/07/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8724/"/>
      <url>/2019/07/07/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8724/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Curriculum Learning for Multi-Task Classiï¬cation of Visual Attributes</li><li>Highway Networks</li><li>Deep Residual Learning for Image Recognition</li><li>Gated Feedback Recurrent Neural Networks</li><li>Densely Connected Convolutional Networks</li></ol><h2 id="Curriculum-Learning-for-Multi-Task-Classiï¬cation-of-Visual-Attributes"><a href="#Curriculum-Learning-for-Multi-Task-Classiï¬cation-of-Visual-Attributes" class="headerlink" title="[Curriculum Learning for Multi-Task Classiï¬cation of Visual Attributes]"></a>[Curriculum Learning for Multi-Task Classiï¬cation of Visual Attributes]</h2><p>å¤§è‡´æ€è·¯æ˜¯ï¼šå°†æ•°æ®åˆ†ä¸ºä¸¤ä¸ªtaskï¼Œå…ˆè®­ç»ƒå¼ºç›¸å…³çš„taskï¼Œç„¶åå†è®­ç»ƒå¼±ç›¸å…³çš„taskã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºvisual attributeï¼Œå…ˆè®­ç»ƒå¼ºç›¸å…³labelï¼Œç„¶åå†è®­ç»ƒå¼±ç›¸å…³çš„labelã€‚<br><img src="/images/15624682482609.jpg" width="60%" height="50%"></p><p>å…·ä½“å½¢å¼ï¼š</p><p><img src="/images/15624684432867.jpg" width="80%" height="50%"></p><p>å¦‚ä½•è®¡ç®—ç›¸å…³æ€§ï¼š</p><script type="math/tex; mode=display">p_{i}=\sum_{j=1, j \neq i}^{T} \frac{\operatorname{cov}\left(y_{t_{i}}, y_{t_{j}}\right)}{\sigma\left(y_{t_{i}}\right) \sigma\left(y_{t_{j}}\right)}, i=1, \ldots, T</script><p>top 50%æ˜¯å¼ºç›¸å…³çš„ï¼Œå‰©ä¸‹éƒ½æ˜¯å¼±ç›¸å…³çš„ã€‚</p><p>æˆ‘çš„ç†è§£æ˜¯ï¼Œä¼¼ä¹æ˜¯å°†labelç»™åˆ‡åˆ†äº†ï¼š</p><p><img src="/images/15624684979775.jpg" width="60%" height="50%"></p><hr><h2 id="Highway-Networks"><a href="#Highway-Networks" class="headerlink" title="[Highway Networks]"></a>[Highway Networks]</h2><p>åŸå…ˆçš„æ™®é€šlayerï¼š</p><script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right)</script><p>ä¸ºäº†èƒ½å¤Ÿè®­ç»ƒå¾ˆæ·±çš„ç½‘ç»œï¼Œæ”¹æˆï¼š</p><script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right) \cdot T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)+\mathbf{x} \cdot C\left(\mathbf{x}, \mathbf{W}_{\mathbf{C}}\right)</script><p>ä¹Ÿå³å¢åŠ ä¸¤ä¸ªä»¿å°„å˜æ¢ã€‚å…¶ä¸­Tæ˜¯transformer gateï¼Œè€ŒCæ˜¯carry gateã€‚è¿™æ ·èƒ½å¤Ÿæœ‰åŠ©äºæ¨¡å‹çš„ä¼˜åŒ–ã€‚</p><p>ç®€å•èµ·è§ï¼š</p><script type="math/tex; mode=display">\mathbf{y}=H\left(\mathbf{x}, \mathbf{W}_{\mathbf{H}}\right) \cdot T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)+\mathbf{x} \cdot\left(1-T\left(\mathbf{x}, \mathbf{W}_{\mathbf{T}}\right)\right)</script><p>åœ¨Tä¸­ï¼Œå¯ä»¥è®¾biasä¸ºè´Ÿï¼Œä¹Ÿå³ä¸€å¼€å§‹åå‘carryçš„è¡Œä¸ºã€‚</p><hr><h2 id="Deep-Residual-Learning-for-Image-Recognition"><a href="#Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="[Deep Residual Learning for Image Recognition]"></a>[Deep Residual Learning for Image Recognition]</h2><p><img src="/images/15624688998473.jpg" width="50%" height="50%"></p><p>æœ¬è´¨æ˜¯æ®‹å·®æ¯”ç›´æ¥å­¦ä¹ xçš„å˜æ¢æ›´å®¹æ˜“ã€‚å¯¹æ¨¡å‹çš„ä¼˜åŒ–æ›´å®¹æ˜“ã€‚</p><blockquote><p>if an identity mapping were optimal, it would be easier to push the residual to zero than to ï¬t an identity mapping by a stack of nonlinear layers</p></blockquote><p>å¯å¦ç†è§£highway networkæ˜¯ResNetçš„è¿›é˜¶ç‰ˆï¼Ÿ</p><hr><h2 id="Gated-Feedback-Recurrent-Neural-Networks"><a href="#Gated-Feedback-Recurrent-Neural-Networks" class="headerlink" title="[Gated Feedback Recurrent Neural Networks]"></a>[Gated Feedback Recurrent Neural Networks]</h2><p><img src="/images/15624692408778.jpg" width="80%" height="50%"></p><p>å¯¹äºå¤šå±‚çš„RNNï¼Œç¬¬lå±‚çš„time stepä¸ºtçš„hï¼Œå¯ä»¥æ¥æ”¶ä¸Šä¸€ä¸ªtime stepçš„å¤§äºlå±‚çš„ä¹Ÿæ¥æ”¶å°äºlå±‚çš„hidden stateã€‚</p><hr><h2 id="Densely-Connected-Convolutional-Networks"><a href="#Densely-Connected-Convolutional-Networks" class="headerlink" title="[Densely Connected Convolutional Networks]"></a>[Densely Connected Convolutional Networks]</h2><p>åœ¨ä¸€ä¸ªblockå†…ï¼Œæ¯å±‚éƒ½è¿æ¥åˆ°åé¢çš„å±‚ã€‚</p><p><img src="/images/15624693085589.jpg" width="70%" height="50%"></p><p>æ³¨æ„åˆ°ï¼Œåœ¨è¿æ¥å½¢å¼ä¸Šï¼Œresnetæ˜¯ç›¸åŠ ï¼š</p><script type="math/tex; mode=display">\mathbf{x}_{\ell}=H_{\ell}\left(\mathbf{x}_{\ell-1}\right)+\mathbf{x}_{\ell-1}</script><p>è€ŒDenseNetåˆ™æ˜¯concatï¼š</p><script type="math/tex; mode=display">\mathbf{x}_{\ell}=H_{\ell}\left(\left[\mathbf{x}_{0}, \mathbf{x}_{1}, \dots, \mathbf{x}_{\ell-1}\right]\right)</script><p>è¿™é‡Œçš„Hæ˜¯Bn-Relu-Convã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­infå¯¼æ•°çš„nané—®é¢˜</title>
      <link href="/2019/07/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPyTorch%E4%B8%ADinf%E5%AF%BC%E6%95%B0%E7%9A%84nan%E9%97%AE%E9%A2%98/"/>
      <url>/2019/07/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPyTorch%E4%B8%ADinf%E5%AF%BC%E6%95%B0%E7%9A%84nan%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>æƒ³è¦å®ç°ä¸€ä¸ªåŠŸèƒ½ã€‚å°†Transformerä¸­å¤šå±‚çš„attentionçŸ©é˜µåŠ æƒå¹³å‡ã€‚ä¹Ÿå³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pre_attn shape: batch_size*n_head,6,target_len,source_len</span></span><br><span class="line">self.attn_alpha = Parameter(torch.zeros(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">normalized_alpha = F.softmax(self.attn_alpha, dim=<span class="number">-1</span>)  <span class="comment"># 1,6</span></span><br><span class="line">normalized_alpha = normalized_alpha.reshape(<span class="number">1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 1,6,1,1</span></span><br><span class="line"></span><br><span class="line">weighted_attn = prev_attn * normalized_alpha</span><br><span class="line">weighted_attn = weighted_attn.sum(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>è·å¾—çš„<code>weighted_attn</code>å°±æ˜¯æ‰€æœ‰å±‚çš„attentionçŸ©é˜µçš„åŠ æƒå¹³å‡ã€‚å†å°†<code>weighted_attn</code>ç”¨äºåé¢çš„è®¡ç®—ã€‚å…¶ä¸­<code>attn_alpha</code>æ˜¯å¯å­¦ä¹ çš„å‚æ•°ã€‚</p><p>åŠŸèƒ½å¾ˆç®€å•ï¼Œä½†åœ¨backwardå®Œåï¼Œ<code>attn_alpha</code>å°±ä¼šä¸€ä¸‹å­è·³åˆ°nanã€‚æŒ‰ç†è¯´ï¼Œè™½ç„¶attnçŸ©é˜µé‡Œé¢å­˜åœ¨-infï¼Œä½†åªè¦æ˜¯åŒä¸€ä¸ªbatchï¼Œinfå­˜åœ¨çš„ç´¢å¼•ä½ç½®åº”è¯¥éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå³ä½¿åŠ æƒæ±‚å’Œä¹Ÿä¸ä¼šå¯¼è‡´æŸä¸€è¡Œå…¨ä¸º-infï¼Œä½¿å¾—åœ¨softmaxåå­˜åœ¨nançš„æƒ…å†µã€‚</p><p>åœ¨èˆªæ€»æ’æŸ¥äº†ä¸€æ™šä¸Šåï¼Œä¹Ÿå°è¯•äº†å„ç§å‡è®¾ï¼Œæœ€ç»ˆå‘ç°ï¼Œæ˜¯å› ä¸ºæ¢¯åº¦å›ä¼ æ—¶çš„é—®é¢˜ã€‚ä¹Ÿå³å½“<code>weighted_attn = prev_attn * normalized_alpha</code>è¿™å¥ä»£ç æ¢¯åº¦å›ä¼ çš„æ—¶å€™ï¼Œç”±äºå­˜åœ¨â€™-infâ€™çš„å€¼ï¼Œalphaçš„æ¢¯åº¦å°±ä¼šæœ‰nanï¼ˆå› ä¸ºä¸Šå¥ä»£ç ä¸­alphaçš„å¯¼æ•°æ˜¯<code>prev_attn</code>ï¼Œå½“<code>prev_attn</code>å­˜åœ¨infæ—¶ï¼Œåˆ™gradåˆ™ä¸ºnanã€‚</p><p>è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œé¦–å…ˆè·å¾—attentionçŸ©é˜µçš„maskï¼Œæ¥ç€ä½¿ç”¨masked_fillå°†infçš„éƒ¨åˆ†ç½®ä¸º0ï¼Œå†å’Œalphaç›¸ä¹˜ï¼Œæ­¤æ—¶å°±ä¸ä¼šæœ‰nançš„æƒ…å†µå‡ºç°äº†ã€‚ä¹Ÿå³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pre_attn shape: batch_size*n_head,6,target_len,source_len</span></span><br><span class="line">self.attn_alpha = Parameter(torch.zeros(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">normalized_alpha = F.softmax(self.attn_alpha, dim=<span class="number">-1</span>)  <span class="comment"># 1,6</span></span><br><span class="line">normalized_alpha = normalized_alpha.reshape(<span class="number">1</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 1,6,1,1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----å¤šåŠ è¿™å‡ è¡Œ --- #</span></span><br><span class="line">_attn_mask = prev_attn == float(<span class="string">'-inf'</span>)  <span class="comment"># -infçš„ä½ç½®ä¸º1</span></span><br><span class="line">new_pre_attn = pre_attn.data.masked_fill(_attn_mask,<span class="number">0</span>) <span class="comment"># å°†-infå¡«å……ä¸º0</span></span><br><span class="line"><span class="comment"># --------------- # </span></span><br><span class="line"></span><br><span class="line">weighted_attn = new_pre_attn * normalized_alpha</span><br><span class="line">weighted_attn = weighted_attn.sum(dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>æ€»ç»“èµ·æ¥ï¼Œåˆ™æ˜¯ï¼Œå½“tensorå­˜åœ¨infæ—¶ï¼Œä¸å®ƒç›¸ä¹˜çš„tensorå¦‚æœæ˜¯å¯æ›´æ–°çš„ï¼Œåˆ™è¯¥tensorçš„gradä¸ºnanã€‚æ‰€ä»¥åœ¨å¤„ç†æœ‰infçš„tensorè¦ç‰¹åˆ«æ³¨æ„ï¼Œå¯èƒ½å‡ºç°ç›¸ä¹˜åæ¢¯åº¦å›ä¼ gradä¸ºnançš„æƒ…å†µï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µåˆ™æ˜¯è‹¥æŸä¸€è¡Œå…¨ä¸ºinfï¼Œè¿‡softmaxååˆ™ä¹Ÿä¼šå‡ºç°nanã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> nan </tag>
            
            <tag> inf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†24</title>
      <link href="/2019/06/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8624/"/>
      <url>/2019/06/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8624/</url>
      
        <content type="html"><![CDATA[<h3 id="Homebrew"><a href="#Homebrew" class="headerlink" title="[Homebrew]"></a>[Homebrew]</h3><p>Homebrewå®‰è£…é‡åˆ° Permission denied @ dir_s_mkdir</p><p>No need to chown the whole /usr/local if brew only fails to create a single directory.<br>For example, I fixed this error:<br>Permission denied @ dir_s_mkdir - /usr/local/Frameworks<br>With this command:<br>sudo install -d -o $(whoami) -g admin /usr/local/Frameworks</p><p><a href="https://gist.github.com/irazasyed/7732946" target="_blank" rel="noopener">https://gist.github.com/irazasyed/7732946</a></p><hr><h3 id="Alfred"><a href="#Alfred" class="headerlink" title="[Alfred]"></a>[Alfred]</h3><p>mac ä¸Š QQ ä¼šé˜»æ­¢ Alfred é”å±åŠŸèƒ½ï¼Œè¿™æ˜¯å› ä¸ºå¿«æ·é”®å†²çªï¼Œå–æ¶ˆæŸ¥çœ‹è”ç³»äººçš„å¿«æ·é”®å³å¯ã€‚</p><p><img src="/images/15618638268867.jpg" width="60%" height="50%"></p><p><a href="https://www.v2ex.com/t/477934" target="_blank" rel="noopener">https://www.v2ex.com/t/477934</a></p><hr><h3 id="Autodiff"><a href="#Autodiff" class="headerlink" title="[Autodiff]"></a>[Autodiff]</h3><p>Autodiffæœ‰ä¸¤ç§æ¨¡å¼ï¼Œforwardå’Œreverseã€‚å½“å‰çš„æ·±åº¦å­¦ä¹ æ¡†æ¶éƒ½ç”¨çš„reverseã€‚</p><p><a href="https://blog.csdn.net/aws3217150/article/details/70214422" target="_blank" rel="noopener">https://blog.csdn.net/aws3217150/article/details/70214422</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 8:Imitation Learning</title>
      <link href="/2019/06/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%208:%20Imitation%20Learning/"/>
      <url>/2019/06/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%208:%20Imitation%20Learning/</url>
      
        <content type="html"><![CDATA[<p>è®¨è®ºäº†åœ¨æ²¡æœ‰rewardçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨expertæ¥è¿›è¡ŒRLã€‚</p><p>é—®é¢˜å®šä¹‰ï¼šåœ¨ä¸€äº›é—®é¢˜ä¸Šæ˜¯æ²¡æœ‰rewardçš„ï¼Œç»™å®šä¸€äº›expertçš„demonstration exampleï¼Œå¦‚ä½•åˆ©ç”¨è¿™äº›exampleä½¿å¾—æœºå™¨èƒ½å¤Ÿå­¦ä¹ ï¼Ÿ</p><h3 id="Behavior-Cloning"><a href="#Behavior-Cloning" class="headerlink" title="Behavior Cloning"></a>Behavior Cloning</h3><p>æœ¬è´¨å°±æ˜¯ç›‘ç£å­¦ä¹ ï¼Œç»™å®šè®­ç»ƒæ•°æ®ï¼Œè¦æ¨¡å‹è¾“å…¥sèƒ½å¤Ÿè·å¾—å°½é‡å’Œexpertç›¸ä¼¼çš„actionã€‚</p><p><img src="/images/15618627790626.jpg" width="60%" height="50%"></p><p>ç”±äºexpert exampleæ˜¯è¾ƒå°‘çš„ï¼Œæœºå™¨å¯èƒ½é‡åˆ°æ²¡é‡åˆ°çš„æƒ…å†µã€‚<br>åŒæ—¶ç”±äºæœºå™¨çš„capacityæ˜¯æœ‰é™çš„ï¼Œå¯èƒ½é€‰æ‹©æ— å…³çš„è¡Œä¸ºå»å­¦ä¹ ã€‚<br>è¿˜æœ‰å¯èƒ½å¸¦æ¥ç”±äºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„åˆ†å¸ƒä¸åŒå¯¼è‡´çš„é—®é¢˜ã€‚å› ä¸ºRLæœ‰åºåˆ—æ€§ï¼Œå¦‚æœä½¿ç”¨Behavior Cloningï¼Œåœ¨æŸä¸ªstateä¸‹é‡‡ç”¨äº†ä¸åŒçš„actionï¼Œåˆ™ä¹‹åçš„stateéƒ½ä¼šå®Œå…¨ä¸åŒï¼ˆå¤±ä¹‹æ¯«å˜è°¬ä»¥åƒé‡Œï¼‰</p><h3 id="Inverse-Reinforcement-Learning-IRL"><a href="#Inverse-Reinforcement-Learning-IRL" class="headerlink" title="Inverse Reinforcement Learning (IRL)"></a>Inverse Reinforcement Learning (IRL)</h3><p>é€šè¿‡expert exampleæ¥å­¦ä¹ reward functionï¼Œåœ¨å­¦ä¹ å®Œreward functionåè®©agentä¸ç¯å¢ƒäº¤äº’è·å¾—agent exampleã€‚æ¥ç€è°ƒæ•´reward functionä½¿å¾—expert exampleä¸€å®šå¤§äºagentçš„exampleã€‚ä¸æ–­å¾ªç¯ã€‚è¿™å’ŒGANçš„æ€æƒ³æœ‰ç‚¹åƒï¼š</p><p><img src="/images/15618628831028.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Imitation Learning </tag>
            
            <tag> IRL </tag>
            
            <tag> Inverse Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯30</title>
      <link href="/2019/06/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D30/"/>
      <url>/2019/06/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D30/</url>
      
        <content type="html"><![CDATA[<h3 id="æ°´é¾™åŸ-Â·-ç™»å»ºåº·èµå¿ƒäº­"><a href="#æ°´é¾™åŸ-Â·-ç™»å»ºåº·èµå¿ƒäº­" class="headerlink" title="æ°´é¾™åŸ Â· ç™»å»ºåº·èµå¿ƒäº­"></a>æ°´é¾™åŸ Â· ç™»å»ºåº·èµå¿ƒäº­</h3><p>[å®‹] è¾›å¼ƒç–¾<br>æ¥šå¤©åƒé‡Œæ¸…ç§‹ï¼Œæ°´éšå¤©å»ç§‹æ— é™…ã€‚é¥å²‘è¿œç›®ï¼ŒçŒ®æ„ä¾›æ¨ï¼Œç‰ç°ªèºé«»ã€‚è½æ—¥æ¥¼å¤´ï¼Œæ–­é¸¿å£°é‡Œï¼Œæ±Ÿå—æ¸¸å­ã€‚æŠŠå´é’©çœ‹äº†ï¼Œæ å¹²æ‹éï¼Œæ— äººä¼šã€ç™»ä¸´æ„ã€‚<br>ä¼‘è¯´é²ˆé±¼å ªè„ï¼Œå°½è¥¿é£ã€å­£é¹°å½’æœªï¼Ÿæ±‚ç”°é—®èˆï¼Œæ€•åº”ç¾è§ï¼Œåˆ˜éƒæ‰æ°”ã€‚å¯æƒœæµå¹´ï¼Œå¿§æ„é£é›¨ï¼Œæ ‘çŠ¹å¦‚æ­¤ã€‚<strong>å€©ä½•äººå”¤å–ï¼Œçº¢å·¾ç¿ è¢–ï¼Œæ¾è‹±é›„æ³ª</strong>ã€‚</p><p>å€©ï¼ˆqÃ¬ngï¼‰ï¼šè¯·æ‰˜ã€‚<br>æ¾ï¼ˆwÃ¨nï¼‰ï¼šæ“¦æ‹­ã€‚</p><hr><h3 id="æ»¡æ±Ÿçº¢"><a href="#æ»¡æ±Ÿçº¢" class="headerlink" title="æ»¡æ±Ÿçº¢"></a>æ»¡æ±Ÿçº¢</h3><p>[å®‹] å²³é£<br>æ€’å‘å†²å† ï¼Œå‡­æ å¤„ã€æ½‡æ½‡é›¨æ­‡ã€‚æŠ¬æœ›çœ¼ï¼Œä»°å¤©é•¿å•¸ï¼Œå£®æ€€æ¿€çƒˆã€‚<strong>ä¸‰ååŠŸåå°˜ä¸åœŸï¼Œå…«åƒé‡Œè·¯äº‘å’Œæœˆ</strong>ã€‚<strong>è«ç­‰é—²ï¼Œç™½äº†å°‘å¹´å¤´ï¼Œç©ºæ‚²åˆ‡</strong>ï¼<br>é–åº·è€»ï¼ŒçŠ¹æœªé›ªã€‚è‡£å­æ¨ï¼Œä½•æ—¶ç­ï¼Ÿé©¾é•¿è½¦ã€è¸ç ´è´ºå…°å±±ç¼ºï¼å£®å¿—é¥¥é¤èƒ¡è™è‚‰ï¼Œç¬‘è°ˆæ¸´é¥®åŒˆå¥´è¡€ã€‚<strong>å¾…ä»å¤´ã€æ”¶æ‹¾æ—§å±±æ²³ï¼Œæœå¤©é˜™ï¼</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡23</title>
      <link href="/2019/06/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8723/"/>
      <url>/2019/06/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8723/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Reinforcement Learning based Curriculum Optimization for Neural Machine Translation</li><li>Curriculum Dropout</li><li>Self-Paced Curriculum Learning</li><li>Learning the Easy Things First: Self-Paced Visual Category Discovery</li><li>Curriculum Learning and Minibatch Bucketing in Neural Machine Translation</li><li>Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks</li><li>LEARNING TO TEACH</li><li>Learning to learn by gradient descent by gradient descent</li><li>Curriculum Learning of Multiple Tasks</li></ol><h2 id="Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation"><a href="#Reinforcement-Learning-based-Curriculum-Optimization-for-Neural-Machine-Translation" class="headerlink" title="[Reinforcement Learning based Curriculum Optimization for Neural Machine Translation]"></a>[Reinforcement Learning based Curriculum Optimization for Neural Machine Translation]</h2><p>ä½¿ç”¨RLæ¥è¿›è¡Œå­¦ä¹ curriculum learningï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å„å¼å„æ ·çš„æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆä¹Ÿå³é«˜æ•ˆåˆ©ç”¨noiseå¾ˆå¤§çš„æ•°æ®é›†ï¼Œå¦‚Paracrawl)ã€‚</p><p><img src="/images/15618207015732.jpg" width="60%" height="50%"></p><p>ä½¿ç”¨ä¸€ä¸ªæŒ‡æ ‡CDSæ¥å°†æ•°æ®åˆ‡åˆ†ï¼š</p><script type="math/tex; mode=display">s(e, f)=\log p_{\theta_{c}}(f | e)-\log p_{\theta_{n}}(f | e)</script><p>$e$å’Œ$f$æ˜¯ç¿»è¯‘å¯¹ã€‚å…¶ä¸­$\theta_c$æ˜¯åœ¨å¯ä¿¡ä»»çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼›$\theta_n$åœ¨noisy corpusä¸Šè®­ç»ƒçš„ï¼ˆæ¯”å¦‚Paracrawl)ã€‚</p><p>RLçš„å‡ ä¸ªåŸºæœ¬å› ç´ ï¼š</p><p>Observation Engineeringï¼šthe observation is the vector containing sentence-level log-likelihoods produced by the NMT system for this prototype batch  å‚è€ƒï¼ˆReinforced co-training.ï¼‰</p><p>Reward Engineeringï¼šThe reward is a function of the log-likelihood of the development set of interest.</p><p>Actionï¼šå°†æ•°æ®é›†åˆ†ä¸ºå¤šä¸ªbinï¼Œactionå°±æ˜¯é€‰æ‹©åœ¨å“ªä¸ªbiné‡Œé¢é€‰æ‹©æ•°æ®é›†ã€‚</p><hr><h2 id="Curriculum-Dropout"><a href="#Curriculum-Dropout" class="headerlink" title="[Curriculum Dropout]"></a>[Curriculum Dropout]</h2><p>é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯é€æ¸å¢åŠ dropout rateã€‚</p><p><img src="/images/15618211418694.jpg" width="40%" height="50%"></p><hr><h2 id="Self-Paced-Curriculum-Learning"><a href="#Self-Paced-Curriculum-Learning" class="headerlink" title="[Self-Paced Curriculum Learning]"></a>[Self-Paced Curriculum Learning]</h2><p>å°†self-paced learningä¸curriculum learningç»“åˆã€‚</p><h3 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><p>é€šè¿‡å…ˆéªŒçŸ¥è¯†å¯¹exampleçš„éš¾åº¦è¿›è¡Œé¢„å®šä¹‰ï¼Œç„¶åæŒ‰ç…§å…ˆåé¡ºåºè®­ç»ƒæ¨¡å‹ï¼›</p><p>è¿™æ˜¯ä¸€ç§Instructor-drivençš„è®­ç»ƒæ–¹æ³•ï¼›å¹¶ä¸è€ƒè™‘learnerçš„feedback</p><h3 id="Self-paced-Learning"><a href="#Self-paced-Learning" class="headerlink" title="Self-paced Learning"></a>Self-paced Learning</h3><p>æ˜¯ç›´æ¥å°†ç›®æ ‡å‡½æ•°å’Œcurriculumä¸€èµ·ç»“åˆèµ·æ¥ï¼Œä¹Ÿå³åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­æ ¹æ®æ¨¡å‹çš„å­¦ä¹ æƒ…å†µï¼ˆlossï¼‰è°ƒæ•´curriculumã€‚çµæ´»ï¼Œä½†ä¸è€ƒè™‘å…ˆéªŒçŸ¥è¯†ã€‚</p><script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v} \in[0,1]^{n}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, f\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)-\lambda \sum_{i=1}^{n} v_{i}</script><p>å½“losså°äº$\lambda$æ—¶ï¼Œå°±è¢«è®¤ä¸ºæ˜¯easy sampleï¼Œ$v=1$ï¼›è‹¥å¤§äº$\lambda$åˆ™$v=0$ã€‚</p><p>Î» controls the pace at which the model learns new samples, and physically Î» corresponds to the â€œageâ€ of the model</p><p>ç”±äºå­¦ä¹ è¿‡ç¨‹å®Œå…¨è¢«lossä¸»å¯¼ï¼Œå› æ­¤å¯èƒ½ä¼šoverfittingã€‚</p><h3 id="Self-paced-Curriculum-Learning"><a href="#Self-paced-Curriculum-Learning" class="headerlink" title="Self-paced Curriculum Learning"></a>Self-paced Curriculum Learning</h3><p>åœ¨äºŒè€…åŸºç¡€ä¸Šç»“åˆï¼Œåœ¨SPLçš„æ¡†æ¶ä¸‹å¼•å…¥CLçš„å…ˆéªŒçŸ¥è¯†ã€‚ä¹Ÿå³æ—¢è€ƒè™‘äº†å…ˆéªŒçŸ¥è¯†ï¼Œåˆè€ƒè™‘äº†æ¨¡å‹å­¦ä¹ çš„åé¦ˆï¼ˆlossï¼‰ã€‚</p><script type="math/tex; mode=display">\min _{\mathbf{w}, \mathbf{v} \in[0,1]^{n}} \mathbb{E}(\mathbf{w}, \mathbf{v} ; \lambda, \Psi)=\sum_{i=1}^{n} v_{i} L\left(y_{i}, g\left(\mathbf{x}_{i}, \mathbf{w}\right)\right)+f(\mathbf{v} ; \lambda),\text { s.t. } \mathbf{v} \in \Psi</script><p>å…¶ä¸­$\Psi$ä»£è¡¨äº†é¢„å®šä¹‰çš„curriculumçš„é›†åˆã€‚</p><p>ç›¸å½“äºCLæä¾›äº†ä¸€ä¸ªå¼±sampleçš„é¡ºåºï¼Œå»ºè®®æ¨¡å‹è¦å…ˆå­¦å“ªäº›ï¼Œä½†ä»–æœ‰è‡ªç”±å»è°ƒæ•´å­¦ä¹ ç›®æ ‡ã€‚<br>æˆ‘çš„ç†è§£æ˜¯ï¼Œ$\Psi$æ˜¯å¯ä»¥åŠ¨æ€å¢å¤§çš„ã€‚ä½†æ˜¯æ¨¡å‹æ˜¯å¦è¦å°†é›†åˆé‡Œçš„exampleç”¨äºè®­ç»ƒè¿˜æ˜¯è¦çœ‹ä¸Šè¿°çš„ç›®æ ‡å‡½æ•°çš„ï¼Œlosså°çš„æ—¶å€™ä»£è¡¨çš„easy exampleï¼Œä¼šç”¨äºå­¦ä¹ ã€‚</p><p><img src="/images/15618570682762.jpg" width="60%" height="50%"></p><p>è¿™æ˜¯CL/SPL/SPCLçš„åŒºåˆ«ï¼š</p><p><img src="/images/15618570907601.jpg" width="100%" height="50%"></p><p>æ€è€ƒï¼š</p><p>$\lambda$ä»£è¡¨äº†æ¨¡å‹çš„æˆç†Ÿåº¦ï¼Œæ§åˆ¶çš„æ˜¯æ¨¡å‹è‡ªèº«çš„competenceï¼›è€Œ$\Psi$é›†åˆå¤§å°ä»£è¡¨äº†instructorè®¤ä¸ºæ¨¡å‹çš„æˆç†Ÿåº¦ã€‚è¿™äºŒè€…çš„ç»“åˆèƒ½å¤Ÿè®©æ¨¡å‹æ›´çµæ´»ã€‚ä½†æ˜¯competenceè¿˜æ˜¯éœ€è¦ä¸€ä¸ªæ‰‹åŠ¨çš„scheduleã€‚</p><hr><h2 id="Learning-the-Easy-Things-First-Self-Paced-Visual-Category-Discovery"><a href="#Learning-the-Easy-Things-First-Self-Paced-Visual-Category-Discovery" class="headerlink" title="[Learning the Easy Things First: Self-Paced Visual Category Discovery]"></a>[Learning the Easy Things First: Self-Paced Visual Category Discovery]</h2><p>å°†self-pacedçš„æ€è·¯åº”ç”¨äºvisual category discoveryã€‚ä¸ä¼ ç»Ÿself-paced learningä¸åŒçš„æ˜¯ï¼Œå¹¶æ²¡æœ‰å°†self-pacedç»‘å®šåœ¨loss functionä¸Šã€‚</p><p>æ¯ä¸€æ¬¡è®¡ç®—ä¸¤ä¸ªæŒ‡æ ‡ objectnesså’Œcontext-awarenessã€‚å°†æœ€ç®€å•çš„é€‰å‡ºæ¥è®­ç»ƒï¼Œç„¶åå†è®¡ç®—æŒ‡æ ‡ï¼Œå†é€‰å‡ºç®€å•çš„è®­ç»ƒã€‚ä¸æ–­å¾ªç¯ã€‚</p><p>self-pacedä¸curriculum learningä¸åŒï¼Œæ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„teacheræ¥åˆ¤æ–­éš¾æ˜“ç¨‹åº¦ï¼Œæ ¹æ®æ¯æ¬¡è‡ªå·±å­¦ä¹ çš„è¿›ç¨‹æ¥åˆ¤æ–­éš¾åº¦ã€‚æœ¬æ–‡ç›¸è¾ƒä¼ ç»Ÿself-pacedä¸åŒï¼Œå› ä¸ºå°†losså’Œå¯¹éš¾æ˜“ç¨‹åº¦çš„åˆ¤æ–­ä¸¤ä¸ªæ­¥éª¤åˆ†ç¦»å¼€æ¥ã€‚</p><hr><h2 id="Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation"><a href="#Curriculum-Learning-and-Minibatch-Bucketing-in-Neural-Machine-Translation" class="headerlink" title="[Curriculum Learning and Minibatch Bucketing in Neural Machine Translation]"></a>[Curriculum Learning and Minibatch Bucketing in Neural Machine Translation]</h2><p>åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šåšäº†ä¸€äº›è®­ç»ƒæ–¹æ³•ä¸Šçš„ç»„åˆå°è¯•ï¼Œç»™å‡ºäº†ä¸€äº›ç»“è®ºã€‚</p><h3 id="Minibatch-Bucketing"><a href="#Minibatch-Bucketing" class="headerlink" title="Minibatch Bucketing"></a>Minibatch Bucketing</h3><p>é¦–å…ˆæ˜¯å°è¯•äº†åœ¨åŒä¸€ä¸ªbatché‡Œä¸ä»…å¥å­é•¿åº¦ç›¸åŒï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰ï¼Œè¿˜å¸Œæœ›åŒä¸€ä¸ªbatchå†…éƒ¨æœ‰æŸç§linguisticçš„ä¿¡æ¯(sentence length, number of coordinating conjunctions, number of nouns, number of proper nouns and the number of verbs in the training data pairs)ã€‚å¯èƒ½ç”±äºä»–é€‰çš„è¿™äº›linguisticå¹¶ä¸å¥½ï¼Œæœ€ç»ˆå¹¶æ²¡æœ‰å‘ç°ç»“æœçš„æå‡ã€‚</p><p><img src="/images/15618573588977.jpg" width="55%" height="50%"></p><h3 id="Curriculum-Learning-1"><a href="#Curriculum-Learning-1" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><p>å¯¹curriculum learningè¿›è¡Œäº†æ”¹è¿›ï¼Œå®é™…ä¸Šæ™®é€šçš„CLé—´æ¥åœ°å¼ºè°ƒäº†easier exampleï¼Œå› ä¸ºä»–ä»¬è¢«sampleäº†å¤šæ¬¡ï¼Œæ‰€ä»¥è¿™é‡Œé‡‡ç”¨äº†ä¸€ç§æ–°çš„æ–¹æ³•èƒ½å¤Ÿè®©æ¯ä¸ªexampleåœ¨ä¸€ä¸ªepochéƒ½åªè¢«sampleä¸€æ¬¡ã€‚</p><p>æŒ‰ç…§éš¾åº¦å°†æ ·ä¾‹åˆ†ä¸ºå‡ ä¸ªbinï¼Œé¦–å…ˆä»æœ€ç®€å•çš„binå¼€å§‹å–æ ·ä¾‹ï¼Œç›´åˆ°è¯¥binçš„å‰©ä½™æ ·ä¾‹ä¸ªæ•°å’Œç¬¬äºŒä¸ªbinçš„æ ·ä¾‹ä¸€æ ·ï¼Œç„¶åä»è¿™ä¸¤ä¸ªbinå‰©ä¸‹çš„æ ·ä¾‹ä¸­å–æ ·ä¾‹ï¼Œç›´åˆ°å‰©ä¸‹å’Œç¬¬ä¸‰ä¸ªbinæ ·ä¾‹ä¸ªæ•°ä¸€æ ·ã€‚è¿™æ ·èƒ½ä¿è¯åœ¨ä¸€ä¸ªepochå†…æ¯ä¸ªexampleçš„æ¦‚ç‡æ˜¯ä¸€è‡´çš„ã€‚</p><p>å¦‚ä½•åˆ¤æ–­éš¾æ˜“ç¨‹åº¦ï¼Ÿé•¿åº¦ï¼Œè¯çš„é¢‘ç‡ç­‰</p><h4 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h4><p>â‘ <br>é¦–å…ˆï¼Œåœ¨è®­ç»ƒå®Œä¸€ä¸ªepochåï¼Œä½¿ç”¨CLç›¸æ¯”æ²¡ä½¿ç”¨CLæœ‰æå‡ï¼š</p><p><img src="/images/15618574547524.jpg" width="55%" height="50%"></p><p>â‘¡<br>åœ¨ä¸€ä¸ªepochå†…çš„è®­ç»ƒæ›²çº¿ï¼š</p><p><img src="/images/15618574884386.jpg" width="70%" height="50%"></p><p>å¯ä»¥çœ‹åˆ°ç”¨CLçš„åœ¨æ¯æ¬¡æ–°åŠ exampleåéƒ½ä¼šæœ‰ä¸€ä¸ªé™¡å³­çš„è·³è·ƒã€‚ç‰¹åˆ«è¦æ³¨æ„æŒ‰ç…§sourceé•¿åº¦å’ŒæŒ‰ç…§targeté•¿åº¦çš„CLæœ‰å¾ˆå¤§çš„ä¸åŒï¼Œå¯èƒ½æ˜¯æŒ‰ç…§targetçš„CLç»™äº†è®­ç»ƒè¿›ç¨‹ä¸€ä¸ªè¾ƒå¤§çš„penalizationã€‚</p><p>â‘¢<br>æ¨¡å‹å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆrecent exampleï¼Œå› æ­¤å¦‚æœåªæä¾›éš¾ä¸€ç‚¹çš„exampleï¼Œé‚£ä¹ˆåœ¨easyçš„exampleå°±å®¹æ˜“ä¸‹é™ã€‚æ‰€ä»¥éœ€è¦mixing strategyã€‚</p><p><img src="/images/15618575566938.jpg" width="70%" height="50%"></p><p>ä»CL by target lengthå¯ä»¥çœ‹å‡ºï¼Œé™¡å³­çš„è·³è·ƒè¯´æ˜æ¨¡å‹åœ¨æ–°åŠ å…¥æ•°æ®ä¹‹å‰å¾ˆå¿«åœ°adaptåœ¨çŸ­çš„å¥å­ï¼Œè€Œé•¿å¥ä¸€è¿›æ¥åˆå¾ˆå¿«adaptåˆ°é•¿å¥ã€‚è¿™ç§å¿«é€Ÿè½¬æ¢ä¼¼ä¹è¯´æ˜äº†æ¨¡å‹çš„å¿«é€Ÿé€‚åº”æ€§ã€‚<br>å¦‚æœä¸å›é¡¾ç®€å•çš„å¥å­ï¼Œè§sorted by lengthçš„æ›²çº¿ï¼Œå¯ä»¥çœ‹åˆ°performanceå¾ˆå·®ã€‚<br>åŒæ—¶å¦‚æœreverse CLï¼Œä¹Ÿå³ä¸€å¼€å§‹evenly coveræ‰€æœ‰å¥å­ï¼Œç„¶ååªä½¿ç”¨çŸ­çš„å¥å­ï¼Œé‚£ä¹ˆå¯ä»¥çœ‹åˆ°ä¸€å¼€å§‹æ•ˆæœä¸é”™ï¼Œåˆ°åé¢å°±é™ä½äº†ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹å¿«é€Ÿé€‚åº”äº†ç”ŸæˆçŸ­çš„å¥å­ï¼Œå°±æ²¡æ³•ç”Ÿæˆtesté›†çš„æ­£å¸¸é•¿åº¦çš„å¥å­ã€‚</p><p>â‘£<br>æ³¨æ„åˆ°ä»¥ä¸Šéƒ½æ˜¯åœ¨ä¸€ä¸ªepochå†…ï¼ˆä¹Ÿå³è¿‡å®Œäº†ä¸€éè®­ç»ƒæ•°æ®ï¼‰çš„ç»“è®ºã€‚åœ¨è¿™ä¸ªepochåç»§ç»­å‡ ç§è®­ç»ƒæ–¹å¼ï¼ˆåŸºäºâ€˜CL by target lengthâ€™ï¼‰ã€‚</p><p><img src="/images/15618576497211.jpg" width="70%" height="50%"></p><p>é‡æ–°ä»æœ€ç®€å•çš„å¼€å§‹ï¼ˆsecond epoch of CL by target length)ï¼Œä¼šä¼¤å®³performanceï¼Œä½†åˆ°åé¢è¿˜æ˜¯æœ‰æå‡çš„ã€‚å¦‚æœåœ¨ç¬¬äºŒä¸ªepochç”¨shuffleçš„æ•°æ®è®­ç»ƒï¼Œé‚£ä¹ˆå¯ä»¥çœ‹åˆ°æ˜¯å‡ ä¹æ²¡æœ‰æå‡çš„ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å·²ç»é™·å…¥äº†å½“å‰çš„optimumäº†ã€‚</p><h3 id="æ€è€ƒä¸ç»“è®º"><a href="#æ€è€ƒä¸ç»“è®º" class="headerlink" title="æ€è€ƒä¸ç»“è®º"></a>æ€è€ƒä¸ç»“è®º</h3><p>è¿™é‡Œçš„å›é¡¾å¼çš„CLï¼Œæ— æ³•å‡å°‘è®­ç»ƒæ—¶é—´ï¼Œå› ä¸ºè¦åˆ°æœ€åæ‰èƒ½è·å¾—è¶…è¶Šbaselineçš„performanceã€‚<br>åŒæ—¶å®éªŒè¯æ˜äº†ï¼Œæ¨¡å‹çš„å¿«é€Ÿé€‚åº”æ€§ï¼Œå¾ˆå®¹æ˜“overfittingåˆ°æœ€è¿‘çš„è®­ç»ƒæ ·ä¾‹ä¸Šï¼Œå› æ­¤è¦è®¾è®¡mixing strategyã€‚</p><hr><h2 id="Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks"><a href="#Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks" class="headerlink" title="[Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks]"></a>[Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks]</h2><p>å¯¹CLåœ¨LSTMçš„è®­ç»ƒçš„å½±å“è¿›è¡Œåˆ†æã€‚å¾—åˆ°ä¸€äº›ç»“è®ºã€‚</p><p>å¿«é€Ÿå›é¡¾äº†ä¸¤ç§CLï¼šOne-Pass Curriculumå’ŒBaby Steps Curriculumã€‚</p><p>One-Pass Curriculumï¼šå°†è®­ç»ƒæ•°æ®åˆ†ä¸ºå‡ ä¸ªbucketï¼Œç„¶åä»ç®€å•çš„bucketå¼€å§‹ï¼Œè®­ç»ƒå®Œç®€å•çš„bucketä¹‹åè·³åˆ°éš¾çš„bucketã€‚</p><p><img src="/images/15618578493722.jpg" width="60%" height="50%"></p><p>Baby Steps Curriculumï¼šä»ç®€å•çš„å¼€å§‹ï¼Œä½†åœ¨å¢åŠ éš¾çš„æ•°æ®åï¼Œä¸ä¼šdiscardç®€å•çš„æ•°æ®ã€‚</p><p><img src="/images/15618578792843.jpg" width="60%" height="50%"></p><h3 id="å®éªŒ-amp-ç»“è®º"><a href="#å®éªŒ-amp-ç»“è®º" class="headerlink" title="å®éªŒ&amp;ç»“è®º"></a>å®éªŒ&amp;ç»“è®º</h3><p>â‘ <br>Baby Stepåœ¨å¤šä¸ªä»»åŠ¡ä¸Šéƒ½æ˜æ˜¾æ›´å¥½ï¼Œå¦‚ï¼Œdigit sum</p><p><img src="/images/15618579415036.jpg" width="90%" height="50%"></p><p>ä¸ä»…ä»…æ˜¯ç»“æœå¥½ï¼ŒåŒæ—¶å…¶varianceä¹Ÿæ›´å°ï¼š</p><p><img src="/images/15618579749575.jpg" width="70%" height="50%"></p><p>â‘¡<br>åœ¨ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹ä¸Šï¼ŒCLæ•ˆæœéƒ½å¥½ï¼Œå½“æ¨¡å‹è¶Šå¤§ï¼Œæ•ˆæœçš„å·®è·ä¼šè¶Šå°ã€‚æ³¨æ„åˆ°ï¼ŒCLåœ¨å‚æ•°æ•°é‡æ›´å°‘çš„æƒ…å†µä¸‹æ•ˆæœæ›´å¥½ã€‚</p><p><img src="/images/15618584599852.jpg" width="60%" height="50%"></p><p>â‘¢<br>åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„ç»“æœ</p><p><img src="/images/15618585223767.jpg" width="60%" height="50%"></p><p>é¦–å…ˆæ˜¯ä½¿ç”¨CLæ•ˆæœå¥½ï¼Œå…¶æ¬¡æ˜¯ä½¿ç”¨conjunctionï¼ˆæ˜¯æŒ‡è¿æ¥ä¸¤ä¸ªæƒ…æ„Ÿææ€§ç›¸åå¥å­çš„è¯ï¼ˆbutç­‰ï¼‰ï¼ˆconjunctions where a span of text contradicts or supports overall sentiment polarityï¼‰ï¼‰æ•ˆæœå·®è·æ›´å¤§ã€‚è¯´æ˜ä½¿ç”¨CLä½¿å¾—æ¨¡å‹çš„é²æ£’æ€§æ›´å¼ºã€‚</p><p>åŒæ—¶CLåœ¨ä½¿ç”¨ä¸åŒè¯æ¥é¢„æµ‹ï¼Œå…¶è¡¨ç°è¾ƒä¸ºä¸€è‡´ï¼š</p><p><img src="/images/15618586132751.jpg" width="70%" height="50%"></p><p>åŒæ—¶ï¼Œåœ¨æ•°æ®é‡æ›´å°‘çš„æƒ…å†µä¸‹ï¼ŒCLçš„æ•ˆæœè¶Šæ˜æ˜¾ï¼š</p><p><img src="/images/15618586384812.jpg" width="60%" height="50%"></p><p>ç»“è®ºï¼š<br>CLåœ¨æ•°æ®å°‘ï¼Œæ¨¡å‹å°çš„æƒ…å†µä¸‹å¾ˆé‡è¦ã€‚</p><hr><h2 id="LEARNING-TO-TEACH"><a href="#LEARNING-TO-TEACH" class="headerlink" title="[LEARNING TO TEACH]"></a>[LEARNING TO TEACH]</h2><p>é‡‡ç”¨RLçš„æ–¹æ³•æ¥è¿›è¡Œschedule learningã€‚ ä¸»è¦ç»“æ„æ˜¯ï¼Œä¸€ä¸ªteacherå†³å®šç»™å­¦ç”Ÿçš„æ•°æ®ï¼Œä¸€ä¸ªå­¦ç”Ÿé€šè¿‡ç»™å®šçš„æ•°æ®è®­ç»ƒï¼Œå¹¶è·å¾—rewardå’Œstateä½œä¸ºfeedbackè¿”å›ç»™teacherã€‚ </p><p>teacherçš„ç›®æ ‡æ˜¯æä¾›æ•°æ®ï¼Œloss functionå’Œhypothesis spaceã€‚å®é™…ä¸Šè®ºæ–‡åªè®¨è®ºäº†æ•°æ®çš„æä¾›ã€‚ç›®æ ‡ï¼š</p><script type="math/tex; mode=display">\min _{D, L, \Omega} \mathcal{M}\left(\mu(D, L, \Omega), D_{t e s t}\right)</script><p><img src="/images/15618587842064.jpg" width="55%" height="50%"></p><p>RLçš„å‡ ä¸ªè¦ç´ ï¼š</p><p>actionï¼šéšæœºsampleæ•°æ®ï¼Œç„¶åä»è¿™äº›sampleçš„æ•°æ®é‡Œå†ç­›é€‰å‡ºæ•°æ®ã€‚ä¹Ÿå³å¯¹æ‰€æœ‰sampleçš„æ•°æ®æ‰“æ ‡ç­¾ï¼Œ1ä»£è¡¨ç»™å­¦ç”Ÿmodelè®­ç»ƒï¼Œ0åˆ™è¢«æŠ›å¼ƒæ‰ã€‚</p><p>stateï¼šå®é™…ä¸Šå°±æ˜¯ä¸€äº›äººå·¥å®šå¥½çš„featureã€‚æ•°æ®çš„featureï¼Œæ¯”å¦‚label categoryï¼Œå¥å­é•¿åº¦ï¼Œlinguistic featureç­‰ï¼›student modelçš„featureï¼Œä¹Ÿå³ä»£è¡¨äº†å½“å‰NNè¢«è®­ç»ƒå¾—å¤šå¥½çš„featureï¼Œå†å²training losså’Œå†å²çš„validation accuracyç­‰ï¼›è¿˜æœ‰å°±æ˜¯äºŒè€…çš„ç»“åˆï¼Œæ¯”å¦‚predicted probability ï¼›dataçš„lossç­‰</p><p>rewardï¼šå’Œstudent modelæ”¶æ•›é€Ÿåº¦ç›¸å…³ï¼Œä¹Ÿå³è®°å½•ç¬¬ä¸€ä¸ªåœ¨æµ‹è¯•é›†ä¸Šå‡†ç¡®ç‡è¶…è¿‡æŸä¸ªé˜ˆå€¼çš„mini-batchçš„ç´¢å¼•ï¼Œç„¶åè®¡ç®—ï¼š</p><script type="math/tex; mode=display">r_{T}=-\log \left(i_{\tau} / T^{\prime}\right)</script><p>è¿™æ˜¯ä¸ºäº†é¼“åŠ±æ—©ç‚¹æ”¶æ•›ã€‚</p><p>æœ¬ç¯‡æ–‡ç« æ¡†æ¶è®¾å®šå¾—å¾ˆå¥½ï¼Œä½†å¹¶æ²¡æœ‰è®¨è®ºå¦å¤–ä¸¤ä¸ªã€‚</p><hr><h2 id="Learning-to-learn-by-gradient-descent-by-gradient-descent"><a href="#Learning-to-learn-by-gradient-descent-by-gradient-descent" class="headerlink" title="[Learning to learn by gradient descent by gradient descent]"></a>[Learning to learn by gradient descent by gradient descent]</h2><p>meta-learningçš„ä¸€ç§æ–¹æ³•ã€‚è¢«é¢˜ç›®å¸å¼•ï¼Œå¤§æ¦‚çœ‹äº†çœ‹ã€‚</p><p>åˆ©ç”¨LSTMæ¥å­¦ä¹ optimizerçš„æ¢¯åº¦ï¼Œä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½çš„è®­ç»ƒã€‚</p><p><img src="/images/15618590469237.jpg" width="50%" height="50%"></p><p><img src="/images/15618590754597.jpg" width="60%" height="50%"></p><p>å…¶ä¸­è™šçº¿ä¸å›ä¼ ï¼Œå®çº¿å›ä¼ ã€‚</p><p>åŒæ—¶ï¼Œæ³¨æ„åˆ°ä¸ºäº†è®©å‚æ•°çš„é¡ºåºå¯¹è¾“å‡ºæ²¡æœ‰å½±å“ï¼Œå› ä¸ºå‡è®¾æ¯ä¸ªå‚æ•°åæ ‡éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤ä½¿ç”¨separate hidden stateï¼Œä½†LSTMçš„å‚æ•°æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³æ¯ä¸ªè¾“å…¥æ¢¯åº¦éƒ½å•ç‹¬å¤„ç†ã€‚</p><p><img src="/images/15618591345801.jpg" width="45%" height="50%"></p><hr><h2 id="Teacher-Student-Curriculum-Learning"><a href="#Teacher-Student-Curriculum-Learning" class="headerlink" title="[Teacher-Student Curriculum Learning]"></a>[Teacher-Student Curriculum Learning]</h2><p>æ²¡ä»”ç»†çœ‹ï¼Œå¤§æ¦‚æ€æƒ³æ˜¯ï¼Œä¸€ä¸ªteacherå¸®å¿™é€‰æ‹©sub-taskè®©studentå­¦ã€‚</p><p><img src="/images/15618591847957.jpg" width="50%" height="50%"></p><p>stateä»£è¡¨çš„æ˜¯studentçš„æ•´ä¸ªçŠ¶æ€ï¼Œneural network parameters and optimizer state) and is not observable to the Teacher.</p><p>actionæ˜¯teacheræ‰€é‡‡å–çš„åŠ¨ä½œï¼Œä¹Ÿå³é€‰æ‹©æŸä¸ªtaskï¼›</p><p>observation æ˜¯åœ¨é€‰æ‹©äº†taskåæ‰€è·å¾—çš„scoreï¼›</p><p>rewardä¹Ÿå³åœ¨è¯¥timestepçš„scoreçš„æ”¹å˜ $r_{t}=x_{t}^{(i)}-x_{t_{i}^{\prime}}^{(i)}$</p><p>CLçš„åœ°æ–¹åœ¨äºä»ç®€å•çš„å­¦èµ·ï¼ˆä¹Ÿå³å¸¦æ¥çš„æ”¹å˜æœ€å¤§çš„taskï¼‰ï¼Œç„¶åå½“å…¶æå‡çš„é€Ÿç‡é™ä½äº†ï¼Œåˆ™é™ä½å…¶sampleçš„æ¦‚ç‡ã€‚</p><p>æ€»ç»“èµ·æ¥ï¼ŒCLçš„å‡ ä¸ªåŸåˆ™ï¼š</p><p><img src="/images/15618592716048.jpg" width="80%" height="50%"></p><p>ç†æƒ³åŒ–çš„CLï¼š</p><p><img src="/images/15618593002197.jpg" width="76%" height="50%"></p><p>å½“æŸä¸ªtaskçš„scoreä¸‹é™äº†ï¼Œè¯´æ˜ä»–å¿˜äº†è¿™éƒ¨åˆ†çš„çŸ¥è¯†ï¼Œåˆè¦æå‡è¯¥sampleçš„æ¦‚ç‡ã€‚</p><hr><h2 id="Curriculum-Learning-of-Multiple-Tasks"><a href="#Curriculum-Learning-of-Multiple-Tasks" class="headerlink" title="[Curriculum Learning of Multiple Tasks]"></a>[Curriculum Learning of Multiple Tasks]</h2><p>å­¦ä¹ å¤šä¸ªtaskï¼ŒæŒ‰ç…§å…ˆåé¡ºåºæ¥ï¼Œè€Œä¸æ˜¯è”åˆè®­ç»ƒã€‚ä¸Šä¸€ä¸ªtaskå­¦åˆ°çš„weightç”¨äºä¸‹ä¸€ä¸ªtaskçš„åˆå§‹åŒ–ã€‚</p><p><img src="/images/15618593717627.jpg" width="55%" height="50%"></p><p>è‡ªåŠ¨é€‰æ‹©taské¡ºåºã€‚æˆ‘çš„ç†è§£æ˜¯ï¼Œæ¯å½“è®­ç»ƒå®Œä¸€ä¸ªsubtaskï¼Œæµ‹è¯•æ‰€æœ‰å…¶ä»–subtaskï¼Œé€‰æ‹©è¡¨ç°æœ€å¥½çš„é‚£ä¸ªï¼ˆæŸä¸ªæŒ‡æ ‡ï¼Œå¹³å‡æœŸæœ›è¯¯å·®ï¼‰ï¼Œç„¶åé€‰æ‹©è¯¥subtaskç»§ç»­è®­ç»ƒã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> LSTM </tag>
            
            <tag> NMT </tag>
            
            <tag> Curriculum Learning </tag>
            
            <tag> Dropout </tag>
            
            <tag> meta-learning </tag>
            
            <tag> multi-task </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯29</title>
      <link href="/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D29/"/>
      <url>/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D29/</url>
      
        <content type="html"><![CDATA[<h3 id="æ°¸é‡ä¹-Â·-äº¬å£åŒ—å›ºäº­æ€€å¤"><a href="#æ°¸é‡ä¹-Â·-äº¬å£åŒ—å›ºäº­æ€€å¤" class="headerlink" title="æ°¸é‡ä¹ Â· äº¬å£åŒ—å›ºäº­æ€€å¤"></a>æ°¸é‡ä¹ Â· äº¬å£åŒ—å›ºäº­æ€€å¤</h3><p>[å®‹] è¾›å¼ƒç–¾<br>åƒå¤æ±Ÿå±±ï¼Œè‹±é›„æ— è§…ï¼Œå­™ä»²è°‹å¤„ã€‚èˆæ¦­æ­Œå°ï¼Œé£æµæ€»è¢«ï¼Œé›¨æ‰“é£å¹å»ã€‚æ–œé˜³è‰æ ‘ï¼Œå¯»å¸¸å··é™Œï¼Œäººé“å¯„å¥´æ›¾ä½ã€‚æƒ³å½“å¹´ã€é‡‘æˆˆé“é©¬ï¼Œæ°”åä¸‡é‡Œå¦‚è™ã€‚<br>å…ƒå˜‰è‰è‰ï¼Œå°ç‹¼å±…èƒ¥ï¼Œèµ¢å¾—ä»“çš‡åŒ—é¡¾ã€‚å››åä¸‰å¹´ï¼Œæœ›ä¸­çŠ¹è®°ï¼Œçƒ½ç«æ‰¬å·è·¯ã€‚å¯å ªå›é¦–ï¼Œä½›è²ç¥ ä¸‹ï¼Œä¸€ç‰‡ç¥é¸¦ç¤¾é¼“ã€‚å‡­è°é—®ï¼Œ<strong>å»‰é¢‡è€çŸ£ï¼Œå°šèƒ½é¥­å¦</strong>ï¼Ÿ</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä½³å¥åˆ†äº«1</title>
      <link href="/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB1/"/>
      <url>/2019/06/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BD%B3%E5%8F%A5%E5%88%86%E4%BA%AB1/</url>
      
        <content type="html"><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>ä»“ä¿ƒæœ¬èº«å°±æ˜¯æœ€è¦ä¸å¾—çš„æ€åº¦ã€‚å½“ä½ åšæŸä»¶äº‹çš„æ—¶å€™ï¼Œä¸€æ—¦æƒ³è¦æ±‚å¿« ï¼Œå°±è¡¨ç¤ºä½ å†ä¹Ÿä¸å…³å¿ƒå®ƒï¼Œè€Œæƒ³å»åšåˆ«çš„äº‹ â€”ã€Šç¦…ä¸æ‘©æ‰˜è½¦ç»´ä¿®è‰ºæœ¯ã€‹</p><h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>è‡ªå¾‹ä½¿æˆ‘ä»¬ä¸ä¼—ä¸åŒï¼Œè‡ªå¾‹ä»¤æˆ‘ä»¬æ´»å¾—æ›´é«˜çº§ã€‚<br>ä¹Ÿæ­£æ˜¯è‡ªå¾‹ï¼Œä½¿æˆ‘ä»¬è·å¾—æ›´è‡ªç”±çš„äººç”Ÿã€‚<br>å‡å¦‚æˆ‘ä»¬åƒåŠ¨ç‰©ä¸€æ ·ï¼Œå¬ä»æ¬²æœ›ï¼Œé€ƒé¿ç—›è‹¦ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯çœŸçš„è‡ªç”±è¡ŒåŠ¨ã€‚æˆ‘ä»¬åªæ˜¯æˆäº†æ¬²æœ›å’Œå†²åŠ¨çš„å¥´éš¶ã€‚æˆ‘ä»¬ä¸æ˜¯åœ¨é€‰æ‹©ï¼Œè€Œæ˜¯åœ¨æœä»ã€‚ä½†äººä¹‹æ‰€ä»¥ä¸ºäººï¼Œ å°±åœ¨äºï¼Œäººä¸æ˜¯è¢«æ¬²æœ›ä¸»å®°ï¼Œè€Œæ˜¯è‡ªæˆ‘ä¸»å®°ã€‚ â€”åº·å¾·</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†23</title>
      <link href="/2019/06/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8623/"/>
      <url>/2019/06/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8623/</url>
      
        <content type="html"><![CDATA[<h3 id="NAS"><a href="#NAS" class="headerlink" title="[NAS]"></a>[NAS]</h3><p>å…³äºNAS(Neural Architecture Search)çš„ç§‘æ™®æ–‡ã€‚<br><a href="https://medium.com/@ashiqbuet14/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136" target="_blank" rel="noopener">https://medium.com/@ashiqbuet14/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136</a></p><p><img src="/images/15612604991653.jpg" width="60%" height="50%"></p><p><strong>Search space</strong>ï¼šå°±æ˜¯ä¸€ä¸ªæ¥ä¸€ä¸ªçš„layerï¼Œä¹Ÿå¯ä»¥åŒ…æ‹¬skip connectionï¼›</p><p><img src="/images/15612605302179.jpg" width="60%" height="50%"></p><p>å¦‚æœå¸Œæœ›å¤§çš„æ¡†æ¶å®šå¥½ï¼Œåªæ˜¯é‡Œé¢çš„layeræœç´¢ï¼Œè¿™ç§°ä¸ºmicro-searchã€‚</p><p><strong>RL</strong>ï¼šå¯ä»¥ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥åšNASï¼Œä»¥RNNä¸ºåŸºæœ¬æ¨¡å‹ã€‚</p><p><img src="/images/15612606028985.jpg" width="77%" height="50%"></p><p>å…¶å®å°±æ˜¯æ¯ä¸ªè¾“å‡ºæŒ‡ç¤ºä¸€ä¸ªlayeré€‰é¡¹ï¼Œç„¶åé€šè¿‡RLè·å¾—çš„rewardæ¥æ›´æ–°ã€‚</p><p><img src="/images/15612606279730.jpg" width="65%" height="50%"></p><p><strong>Progressive Neural Architecture Search(PNAS)</strong>ï¼šè¿™å°±æ˜¯å‰é¢æåˆ°çš„å›ºå®šæ•´ä¸ªå¤§çš„æ¡†æ¶ï¼ˆblockï¼‰ï¼Œç„¶åæœç´¢é‡Œé¢çš„layerã€‚</p><p><img src="/images/15612606813899.jpg" width="70%" height="50%"></p><p><img src="/images/15612606939857.jpg" width="40%" height="50%"></p><p><img src="/images/15612607076908.jpg" width="68%" height="50%"></p><p>å¯ä»¥é€šè¿‡æ¯å±‚é€‰å®Œå»æ‰ä¸€äº›é€‰é¡¹æ¥å‡å°‘æ’åˆ—ç»„åˆå·¨å¤§çš„æ€»æ•°ã€‚</p><p><strong>Differentiable Architecture Search(DARTS)</strong>ï¼šå°†é€‰æ‹©layerçš„discreteçš„åŠ¨ä½œå˜æˆè¿ç»­çš„ï¼Œä½¿å¾—èƒ½å¤Ÿé€šè¿‡æ±‚å¯¼çš„æ–¹å¼æ›´æ–°ã€‚</p><p>å…¶æœ¬è´¨å°±æ˜¯ä¸¤ä¸ªnodeä¹‹é—´è¿å¤šä¸ªoperationï¼Œç„¶åè®­ç»ƒè·å¾—æ¯ä¸ªoperationçš„æ¯”ä¾‹ï¼Œåªä¿ç•™æœ€å¤§çš„ã€‚</p><p><img src="/images/15612607664055.jpg" width="40%" height="50%"></p><p><img src="/images/15612607797249.jpg" width="80%" height="50%"></p><p>è¿™ä¸ªç”¨è¿ç»­æ¥è¾¾åˆ°ç¦»æ•£çš„åšæ³•è¿˜æŒºæœ‰åˆ›æ–°çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> NAS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 7:Sparse Reward</title>
      <link href="/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%207:%20Sparse%20Reward/"/>
      <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%207:%20Sparse%20Reward/</url>
      
        <content type="html"><![CDATA[<p>è®¨è®ºäº†å½“RLé‡åˆ°sparse rewardæ—¶çš„å‡ ä¸ªè§£å†³æ–¹æ¡ˆã€‚</p><h2 id="Reward-Shaping"><a href="#Reward-Shaping" class="headerlink" title="Reward Shaping"></a>Reward Shaping</h2><h3 id="hand-crafted"><a href="#hand-crafted" class="headerlink" title="hand-crafted"></a>hand-crafted</h3><p>ä¹Ÿå³è™šæ„å‡ºrewardå¼•å¯¼agentèµ°å‘è‡ªå·±æœŸæœ›çš„ç»“æœã€‚</p><p><img src="/images/15612581947292.jpg" width="80%" height="50%"></p><p>å¦‚ä¸Šå›¾ï¼Œä»”ç»†å®šä¹‰äº†æ¸¸æˆä¸­æ¯ä¸ªæ“ä½œçš„rewardã€‚</p><h3 id="Curiosity"><a href="#Curiosity" class="headerlink" title="Curiosity"></a>Curiosity</h3><p>å¾€agenté‡Œæ·»åŠ å¥½å¥‡å¿ƒã€‚</p><p><img src="/images/15612582253155.jpg" width="60%" height="50%"></p><p>è¾“å…¥æ˜¯$a_t$å’Œ$s_t$å°è¯•é¢„æµ‹å‡º$s_{t+1}$ï¼Œå¦‚æœé¢„æµ‹çš„å’ŒçœŸå®çš„å·®è·è¾ƒå¤§æ—¶ï¼Œåˆ™è¯¥actionçš„rewardå¤§ï¼Œè¿™æ ·èƒ½å¤Ÿé¼“åŠ±agentæ¢ç´¢æ›´å¤šçš„æ“ä½œã€‚</p><p><img src="/images/15612583393730.jpg" width="60%" height="50%"></p><p>ä½†æœ‰æ—¶å€™éš¾ä»¥é¢„æµ‹çš„stateå¹¶ä¸ä»£è¡¨å…¶é‡è¦ã€‚åº”å½“è¿‡æ»¤æ‰è¿™æ ·çš„stateï¼Œæ¯”å¦‚æ¸¸æˆä¸­æ ‘å¶é£˜åŠ¨ï¼Œä½†è¿™ä¸ªstateå®Œå…¨ä¸é‡è¦ã€‚å› æ­¤å¯¹ä¸Šè¿°æ¨¡å‹è¿›è¡Œæ”¹è¿›ï¼š</p><p><img src="/images/15612583648401.jpg" width="60%" height="50%"></p><p>æ·»åŠ feature extractorï¼ŒåŒæ—¶æ·»åŠ å¦ä¸€ä¸ªç½‘ç»œï¼Œæ¥é€šè¿‡$s_t$å’Œ$s_{t+1}$é¢„æµ‹actionï¼Œè¿™æ ·å°±èƒ½å¤Ÿè¿‡æ»¤æ‰stateä¸­æ²¡æ„ä¹‰çš„éƒ¨åˆ†ã€‚</p><h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h2><p>ä»ç®€å•çš„å¼€å§‹å­¦èµ·ï¼Œæ¯”å¦‚ç©æ¸¸æˆçš„ä¾‹å­ï¼š</p><p><img src="/images/15612584604093.jpg" width="74%" height="50%"></p><p>è¿™ä¸ªéœ€è¦äººå·¥è¾ƒä¸ºç²¾ç»†çš„è°ƒæ•´ã€‚</p><h3 id="Reverse-Curriculum-Generation"><a href="#Reverse-Curriculum-Generation" class="headerlink" title="Reverse Curriculum Generation"></a>Reverse Curriculum Generation</h3><p>é¦–å…ˆç»™å®šä¸€ä¸ªgold stateï¼Œä¹Ÿå³ç›®æ ‡ï¼Œç„¶åå¯»æ‰¾ä¸gold stateæœ€æ¥è¿‘çš„stateè·å¾—ç›¸åº”çš„rewardã€‚</p><p><img src="/images/15612585028635.jpg" width="40%" height="50%"></p><p>ç„¶åå»æ‰rewardå¤ªå¤§æˆ–å¤ªå°çš„ã€‚åœ¨ç•™ä¸‹æ¥çš„stateä¸­å†è·å–ä¸ä»–ä»¬æ¥è¿‘çš„stateï¼Œç»§ç»­ä»¥ä¸Šæµç¨‹ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Sparse Reward </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 6:Actor-Critic</title>
      <link href="/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%206:%20Actor-Critic/"/>
      <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%206:%20Actor-Critic/</url>
      
        <content type="html"><![CDATA[<p>ä»‹ç»äº†actor-criticçš„ç®—æ³•ï¼Œç»“åˆäº†policy gradientå’ŒQ-learningã€‚</p><h2 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h2><p>åŸå…ˆpolicy gradientçš„ç®—æ³•æ˜¯ç›´æ¥å­¦ä¹ ä¸€ä¸ªpolicyï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n}-b\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ä½†æ˜¾ç„¶rewardæ˜¯ä¸ç¨³å®šçš„ï¼Œå®ƒä»£è¡¨äº†é‡‡å–actionä¹‹åçš„rewardçš„æœŸæœ›å€¼ï¼Œå½“sampleæ¬¡æ•°ä¸å¤Ÿå¤šï¼Œå…¶é¢„ä¼°çš„ä¹Ÿä¸å‡†ã€‚</p><p>å› æ­¤åœ¨è¿™é‡Œå°†Q-learningå¼•å…¥åˆ°é¢„ä¼°rewardä¸­ï¼Œä¹Ÿå³policy gradientå’Œq-learningçš„ç»“åˆã€‚</p><p>ä¹Ÿå³æˆ‘ä»¬å°†rewardæ›¿æ¢æˆ$E\left[G_{t}^{n}\right]=Q^{\pi_{\theta}}\left(s_{t}^{n}, a_{t}^{n}\right)$ã€‚åŒæ—¶æ ¹æ®baselineçš„å®šä¹‰ï¼Œæˆ‘ä»¬å°†å…¶æ›¿æ¢æˆ$V^{\pi_{\theta}}\left(s_{t}^{n}\right)$ã€‚</p><p>æ‰€ä»¥æ‹¬å·å†…çš„$\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n}-b$å°±å˜æˆ$Q^{\pi \theta}\left(s_{t}^{n}, a_{t}^{n}\right)-V^{\pi_{\theta}}\left(s_{t}^{n}\right)$ã€‚</p><p>å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦åˆ†åˆ«è®­ç»ƒä¸¤ä¸ªç½‘ç»œï¼Œç›´æ¥æ•´åˆæˆä¸€ä¸ªç½‘ç»œå³å¯ã€‚ä¹Ÿå³å°†$Q^{\pi \theta}\left(s_{t}^{n}, a_{t}^{n}\right)-V^{\pi_{\theta}}\left(s_{t}^{n}\right)$æ”¹æˆ$r_{t}^{n}+V^{\pi}\left(s_{t+1}^{n}\right)-V^{\pi}\left(s_{t}^{n}\right)$ã€‚</p><p>å› æ­¤æ•´ä¸ªæµç¨‹ï¼š</p><p><img src="/images/15612575693660.jpg" width="40%" height="50%"></p><p>å½¢å¼åŒ–ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(r_{t}^{n}+V^{\pi}\left(s_{t+1}^{n}\right)-V^{\pi}\left(s_{t}^{n}\right)\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ç”±äº$\pi$å’Œ$V$çš„è¾“å…¥éƒ½æ˜¯$s$ï¼Œåœ¨å®é™…æ“ä½œä¸­å¯ä»¥å°†è¿™ä¸¤ä¸ªç½‘ç»œçš„å‰å‡ å±‚å‚æ•°å…±äº«ï¼š</p><p><img src="/images/15612576221669.jpg" width="50%" height="50%"></p><p>åŒæ—¶å¯¹$\pi$çš„è¾“å‡ºåŠ ä»¥é™åˆ¶ï¼Œå¸Œæœ›æœ‰æ›´å¤§çš„entropyï¼Œè¿™æ ·èƒ½å¤Ÿæ¢ç´¢æ›´å¤šæƒ…å†µã€‚</p><h2 id="Pathwise-Derivative-Policy-Gradient"><a href="#Pathwise-Derivative-Policy-Gradient" class="headerlink" title="Pathwise Derivative Policy Gradient"></a>Pathwise Derivative Policy Gradient</h2><p>æ¥ä¸‹æ¥ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç›´æ¥å­¦ä¹ ä¸€ä¸ª$\pi$ï¼Œè¾“å…¥$s$å¯ä»¥è·å¾—èƒ½å¤Ÿæœ€å¤§åŒ–Qçš„actionã€‚è¿™å’ŒGANçš„æ€æƒ³å¾ˆç›¸ä¼¼ã€‚</p><p><img src="/images/15612577121214.jpg" width="60%" height="50%"></p><p>è¿™æ ·$\pi$å¤©ç„¶åœ°èƒ½å¤Ÿå¤„ç†continuousçš„æƒ…å†µã€‚</p><p>æ‰€ä»¥æ•´ä¸ªæµç¨‹ï¼š</p><p><img src="/images/15612577508356.jpg" width="55%" height="50%"></p><p>å…ˆäº¤äº’ï¼Œå­¦ä¹ ä¸€ä¸ªå¥½çš„$Q$ï¼Œç„¶åå°†è¿™ä¸ª$Q$ä½œä¸ºæ ‡å‡†ï¼Œå­¦ä¹ $\pi$ä½¿å¾—è¾“å‡ºçš„$Q$æœ€å¤§ã€‚å’ŒGANå¾ˆåƒã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Actor-Critic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 5:Q-learning (Continuous Action)</title>
      <link href="/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%205:%20Q-learning%20(Continuous%20Action)/"/>
      <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%205:%20Q-learning%20(Continuous%20Action)/</url>
      
        <content type="html"><![CDATA[<p>è®¨è®ºäº†å¦‚ä½•å°†Q-learningç”¨äºè¿ç»­çš„actionä¸­ã€‚</p><p>å‰é¢æåˆ° Q-learningå°±æ˜¯ï¼š</p><script type="math/tex; mode=display">a=\arg \max _{a} Q(s, a)</script><p>è‹¥aæ˜¯è¿ç»­çš„ï¼Œå‡ ç§è§£å†³æ–¹æ¡ˆï¼š</p><p>â‘ sampleä¸€å †action$\left\{a_{1}, a_{2}, \cdots, a_{N}\right\}$ï¼Œç„¶åæŒ‰ç…§discreteçš„æƒ…å†µæ¥å¤„ç†ã€‚ä½†ç²¾åº¦ä¸é«˜ï¼Œå› ä¸ºæ²¡æ³•sampleå¤ªå¤šæƒ…å†µã€‚</p><p>â‘¡ä½¿ç”¨gradient ascentæ¥è®¡ç®—å¤„ç†ä¸Šå¼ã€‚è¯¥æ–¹æ³•æ˜¾ç„¶å¤ªè€—æ—¶ï¼Œå› ä¸ºæ¯ä¸ªsampleéƒ½ç­‰äºè¦è®­ç»ƒä¸€éæ¨¡å‹ã€‚</p><p>â‘¢è®¾è®¡ä¸“é—¨çš„ç½‘ç»œä½¿å¾—è¯¥ä¼˜åŒ–å¯è¡Œã€‚<br>é¦–å…ˆè¾“å…¥stateï¼š</p><p><img src="/images/15612569949700.jpg" width="60%" height="50%"></p><p>è·å¾—ä¸€ä¸ª$\mu$ï¼Œ$\Sigma$å’Œ$V$ã€‚æ¥ç€å’Œactionäº¤äº’ï¼š</p><script type="math/tex; mode=display">Q(s, a)=-(a-\mu(s))^{T} \Sigma(s)(a-\mu(s))+V(s)</script><p>æ˜¾ç„¶,ç¬¬ä¸€é¡¹è‹¥$\Sigma$åŠæ­£å®šï¼Œå¿…å®šå°äºç­‰äº0ï¼Œæ‰€ä»¥å½“$a=\mu(s)$æ—¶$Q$æœ€å¤§ã€‚å®é™…ä¸Š$\Sigma$æ˜¯é€šè¿‡å…ˆè·å¾—ä¸€ä¸ªçŸ©é˜µ$A$ï¼Œç„¶å$A\times A^{T}$ä¿è¯å…¶æ­£å®šæ€§ã€‚</p><p>å› æ­¤ï¼š</p><script type="math/tex; mode=display">\mu(s)=\arg \max _{a} Q(s, a)</script><p>â‘£åˆ«ç”¨Q-learningå¤„ç†è¿ç»­çš„æƒ…å†µï¼Œå› ä¸ºå¤„ç†è¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Q-learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 4:Q-learning (Advanced Tips)</title>
      <link href="/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%204:%20Q-learning%20(Advanced%20Tips)/"/>
      <url>/2019/06/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%204:%20Q-learning%20(Advanced%20Tips)/</url>
      
        <content type="html"><![CDATA[<p>ä»‹ç»ä¸€äº›è¿›é˜¶çš„Q-learning tipsï¼Œèƒ½å¤Ÿå¸®åŠ©Q-learningæå‡è¡¨ç°ã€‚</p><h3 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h3><p>å‘ç°Q-valueæ€»æ˜¯å®¹æ˜“è¢«é«˜ä¼°ï¼ŒåŸå› æ˜¯ç®—æ³•ä¸­æœ‰$Q\left(s_{t}, a_{t}\right)=r_{t}+\max _{a} Q\left(s_{t+1}, a\right)$ã€‚è¯¥å…¬å¼çš„maxä½¿å¾—$Q$æ€»æ˜¯é€‰æ‹©æœ€å¤§çš„actionï¼Œä½¿å¾—$Q$çš„æ‹Ÿåˆæ€»æ˜¯åå¤§ã€‚</p><p><img src="/images/15612561913726.jpg" width="40%" height="50%"></p><p>é‚£ä¹ˆåœ¨è¿™é‡Œå¤šåŠ ä¸€ä¸ª$Q^{\prime}$ä»¥è§„é¿ä¸Šè¿°æƒ…å†µï¼Œä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">Q\left(s_{t}, a_{t}\right)=r_{t}+Q^{\prime}\left(s_{t+1}, \arg \max _{a} Q\left(s_{t+1}, a\right)\right)</script><p>è‹¥$Q$é«˜ä¼°äº†aï¼Œ$Q^{\prime}$ä¸é«˜ä¼°é‚£ä¹ˆ$Q^{\prime}$çš„å€¼ä¹Ÿä¸ä¼šé‚£ä¹ˆå¤§åˆ™å·¦å¼çš„å€¼å°±ä¸ä¼šè¢«é«˜ä¼°ï¼›è‹¥$Q^{\prime}$å¯¹æŸä¸ªactioné«˜ä¼°äº†ï¼Œåªè¦$Q$ä¸é«˜ä¼°è¯¥actionï¼Œé‚£ä¹ˆä¹Ÿä¸ä¼šé€‰æ‹©è¯¥actionã€‚</p><h3 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h3><p>å°†æ¨¡å‹ç»“æ„åšäº†æ”¹å˜ï¼š</p><p><img src="/images/15612563207080.jpg" width="60%" height="50%"></p><p>ä¹Ÿå³å°†$Q$åˆ†ç¦»å¼€æ¥ã€‚ä¸€ç§è§£é‡Šæ˜¯è¿™æ ·çš„åˆ†ç¦»å¯ä»¥ä½¿å¾—æ•°æ®çš„ä½¿ç”¨æ›´æœ‰æ•ˆç‡ï¼Œä½¿å¾—æ¨¡å‹æ›´ä¸ºçµæ´»ã€‚è¯¾ä»¶ä¸Šè¿˜ä¸¾äº†ä¸€ä¸ªä¾‹å­ã€‚ åŒæ—¶è¿˜å¯ä»¥å¯¹$A$åŠ ä¸€äº›é™åˆ¶ï¼Œæ¯”å¦‚å‘é‡å’Œä¸º0ã€‚</p><h3 id="Prioritized-Reply"><a href="#Prioritized-Reply" class="headerlink" title="Prioritized Reply"></a>Prioritized Reply</h3><p>å¯¹replay bufferè¿›è¡Œæ”¹è¿›ã€‚å¯¹TD errorè¾ƒå¤§çš„ä¼˜å…ˆsampleï¼Œä¹Ÿå³å¯¹é‚£äº›å­¦å¾—ä¸å¥½çš„exampleä¼˜å…ˆå­¦ä¹ ã€‚</p><h3 id="Multi-step"><a href="#Multi-step" class="headerlink" title="Multi-step"></a>Multi-step</h3><p>å°†MCå’ŒTDç»¼åˆèµ·æ¥ã€‚ç»™å®š$\left(s_{t}, a_{t}, r_{t}, \cdots, s_{t+N}, a_{t+N}, r_{t+N}, s_{t+N+1}\right)$ï¼Œæœ‰ï¼š</p><p><img src="/images/15612565388930.jpg" width="65%" height="50%"></p><p>ä¹Ÿå³ä»‹äºMCçš„æ•´ä¸ªepisodeå®Œæˆåå†è®¡ç®—å’ŒTDçš„æ¯ä¸ªstepéƒ½è®¡ç®—ä¸€æ¬¡ã€‚</p><h3 id="Noisy-Net"><a href="#Noisy-Net" class="headerlink" title="Noisy Net"></a>Noisy Net</h3><p>epsilon greedyä¹Ÿå¯ä»¥çœ‹åšæ˜¯åŠ å™ªå£°ï¼Œä½†æ˜¯æ˜¯åŠ åœ¨actionä¸Šï¼š</p><script type="math/tex; mode=display">a=\left\{\begin{aligned} \arg \max _{a} Q(s, a), & \text {with probability } 1-\varepsilon \\ \text {random}, & \text { otherwise } \end{aligned}\right.</script><p>è¿™æ ·ä½¿å¾—æ¨¡å‹çš„è¡Œä¸ºä¸ä¸€è‡´ï¼Œå¯èƒ½ä¸å¤§å¥½ã€‚</p><p>è€ŒNoisy Netæ˜¯åœ¨parameterä¸ŠåŠ å™ªå£°ã€‚ä¹Ÿå³åœ¨episodeå¼€å§‹ä¹‹å‰å¯¹$Q$åŠ å™ªå£°ï¼Œå˜æˆ$\tilde{Q}$ï¼š</p><script type="math/tex; mode=display">a=\arg \max _{a} \tilde{Q}(s, a)</script><p>è€Œåœ¨episodeæœŸé—´ä¸ä¼šæ”¹å˜noiseã€‚è¿™æ ·æ›´æœ‰ç³»ç»Ÿæ€§çš„æ¢ç´¢å¯èƒ½ä¼šæ›´å¥½ï¼Œå› ä¸ºæ¨¡å‹è¡Œä¸ºä¸€è‡´ã€‚</p><h3 id="Distributional-Q-function"><a href="#Distributional-Q-function" class="headerlink" title="Distributional Q-function"></a>Distributional Q-function</h3><p>åŸºæœ¬æ€æƒ³æ˜¯ä»¤$Q$é¢„æµ‹æ¯ä¸ªè¡Œä¸ºçš„rewardçš„åˆ†å¸ƒè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªæœŸæœ›å€¼ã€‚å› ä¸ºæœŸæœ›å€¼æŸå¤±äº†å¤ªå¤šä¿¡æ¯äº†ï¼Œä¸åŒçš„distributionå¯èƒ½æœ‰åŒæ ·å¤§å°çš„æœŸæœ›ã€‚</p><p><img src="/images/15612567428631.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šæ“ä½œä¹Ÿå³ï¼š</p><p><img src="/images/15612567546608.jpg" width="60%" height="50%"></p><p>Distributional Q-functionå¾€å¾€ä¸ä¼šé«˜ä¼°expectationè€Œæ˜¯ä½ä¼°ã€‚å› ä¸ºåœ¨é¢„æµ‹distributionæ—¶å·²ç»é™å®šäº†æœ€é«˜å’Œæœ€ä½çš„èŒƒå›´äº†ï¼Œå¯¹äºé‚£äº›å¤§äºæˆ–å°äºçš„å€¼éƒ½å¿½ç•¥æ‰ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Q-learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 3:Q-learning (Basic Idea)</title>
      <link href="/2019/06/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%203:%20Q-learning%20(Basic%20Idea)/"/>
      <url>/2019/06/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%203:%20Q-learning%20(Basic%20Idea)/</url>
      
        <content type="html"><![CDATA[<p>ç®€å•ä»‹ç»Q-learningçš„æ€æƒ³ä»¥åŠç›¸å…³çš„è®­ç»ƒtipsã€‚</p><h3 id="æ˜¯ä»€ä¹ˆ"><a href="#æ˜¯ä»€ä¹ˆ" class="headerlink" title="æ˜¯ä»€ä¹ˆ"></a>æ˜¯ä»€ä¹ˆ</h3><p>ä¸Policy Gradientä¸åŒçš„æ˜¯ï¼ŒQ-Learningæ˜¯å±äºvalue basedï¼Œä¹Ÿå³å­¦ä¹ ä¸€ä¸ªcriticå»ä¼°è®¡ç‰¹å®šactor Ï€åœ¨æŸä¸ªstate sä¸‹çš„ç´¯ç§¯rewardã€‚</p><p>æ³¨æ„åˆ°Q-learningè™½ç„¶åªå­¦ä¹ äº†criticï¼Œä½†ä»ç„¶å¯ä»¥ç”¨äºåšå†³ç­–ã€‚</p><p>é¦–å…ˆæ˜¯å¦‚ä½•é¢„ä¼°criticï¼Ÿ<br>criticçš„æœ¬è´¨å°±æ˜¯å‡½æ•°æ˜ å°„$V^{\pi}(s)$ï¼Œè¾“å…¥$s$ï¼Œè¾“å‡ºä¸€ä¸ªscalarä½œä¸ºä½¿ç”¨äº†actor $\pi$çš„ç´¯ç§¯rewardã€‚æœ‰ä¸¤ç§æ–¹æ³•ï¼šMonte-Carlo (MC) based approachå’ŒTemporal-difference (TD) approachã€‚</p><h4 id="Monte-Carlo-MC-based-approach"><a href="#Monte-Carlo-MC-based-approach" class="headerlink" title="Monte-Carlo (MC) based approach"></a>Monte-Carlo (MC) based approach</h4><p>criticçœ‹å®Œæ•´ä¸ªepisodeï¼Œç„¶åå¯¹$s$åšå‡ºé¢„ä¼°ï¼š</p><p><img src="/images/15612136873633.jpg" width="35%" height="50%"></p><p>å…¶å®è´¨ä¸Šå°±æ˜¯åœ¨åšregressionã€‚</p><h4 id="Temporal-difference-TD-approach"><a href="#Temporal-difference-TD-approach" class="headerlink" title="Temporal-difference (TD) approach"></a>Temporal-difference (TD) approach</h4><p>ç”±äºæœ‰äº›episodeéå¸¸é•¿ï¼Œç­‰è·‘å®Œå†é¢„ä¼°æ•ˆç‡å¤ªä½ï¼Œå› æ­¤ç›´æ¥å¯¹æ¯ä¸ªstepè¿›è¡Œé¢„ä¼°ã€‚<br>å¯¹äºä¸€ä¸ªtime step $\cdots s_{t}, a_{t}, r_{t}, s_{t+1} \cdots$ï¼Œç›´æ¥é¢„ä¼°ï¼š</p><p><img src="/images/15612137939102.jpg" width="70%" height="50%"></p><p>ä»‹ç»å®Œ$V^{\pi}(s)$ï¼Œè¿˜æœ‰ä¸€ç§criticï¼Œè¾“å…¥$s$å’Œ$a$ä»¥è·å¾—ä¸€ä¸ªç´¯ç§¯rewardã€‚è¿™é‡Œå’Œ$V^{\pi}(s)$ä¸åŒçš„æ˜¯ï¼Œå¯¹äºåŒä¸€ä¸ªÏ€ï¼Œèƒ½å¤Ÿè¯„ä¼°å¼ºåˆ¶é‡‡ç”¨$a$æ‰€è·å¾—çš„rewardã€‚</p><p><img src="/images/15612139717700.jpg" width="70%" height="50%"></p><h3 id="å¦‚ä½•ä½¿ç”¨criticå†³ç­–"><a href="#å¦‚ä½•ä½¿ç”¨criticå†³ç­–" class="headerlink" title="å¦‚ä½•ä½¿ç”¨criticå†³ç­–"></a>å¦‚ä½•ä½¿ç”¨criticå†³ç­–</h3><p>åœ¨è®­ç»ƒå®Œäº†ä¸€ä¸ªcriticï¼Œå¦‚ä½•ç”¨äºè¿›è¡Œå†³ç­–ï¼Ÿ</p><p>å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šç»™å®š$Q$ï¼Œæ€»èƒ½æ‰¾åˆ°ä¸€ä¸ª$\pi^{\prime}$ æ¯”$\pi$å¥½ï¼Œä¹Ÿå³$V^{\pi^{\prime}}(s) \geq V^{\pi}(s)$ã€‚å½¢å¼åŒ–ï¼š</p><script type="math/tex; mode=display">\pi^{\prime}(s)=\arg \max _{a} Q^{\pi}(s, a)</script><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨å­¦ä¹ å®Œä¸€ä¸ªç‰¹å®š$\pi$å¯¹åº”çš„$Q$åï¼Œåªéœ€è¦éµç…§æ¯é‡åˆ°ä¸€ä¸ªstateï¼Œé€‰æ‹©èƒ½ä½¿$Q$æœ€å¤§åŒ–çš„actionï¼Œè¯¥æ–°çš„$\pi$å°±ä¼šæ¯”åŸæ¥çš„$\pi$æ›´ä¼˜ã€‚</p><p>ä¸ºä»€ä¹ˆä¸€å®šä¼šæ›´ä¼˜ã€‚æä¾›è¯æ˜ï¼š</p><p><img src="/images/15612142985976.jpg" width="60%" height="50%"></p><p>æ¯ä¸€æ­¥é€‰æ‹©æœ€ä¼˜éƒ½ä¼šæ¯”åŸæ¥å¥½ä¸€äº›ã€‚</p><h3 id="å¦‚ä½•è®­ç»ƒQ-function"><a href="#å¦‚ä½•è®­ç»ƒQ-function" class="headerlink" title="å¦‚ä½•è®­ç»ƒQ function"></a>å¦‚ä½•è®­ç»ƒQ function</h3><p>æˆ‘ä»¬é€šè¿‡ç±»ä¼¼TDçš„æ–¹æ³•æ¥è®­ç»ƒã€‚ç»™å®š$\cdots s_{t}, a_{t}, r_{t}, s_{t+1} \cdots$,æˆ‘ä»¬æœ‰ï¼š</p><script type="math/tex; mode=display">\mathrm{Q}^{\pi}\left(s_{t}, a_{t}\right)=r_{t}+\mathrm{Q}^{\pi}\left(s_{t+1}, \pi\left(s_{t+1}\right)\right)</script><p>å…¶ä¸­ç”±äºå…¬å¼æœ‰ä¸¤ä¸ªQï¼Œè‹¥è®©ä¸¤ä¸ªQåŒæ—¶å˜ï¼Œä¸å¥½åšå›å½’ã€‚å› æ­¤æˆ‘ä»¬è®©å³è¾¹çš„Qå›ºå®šä½ï¼Œè®­ç»ƒå·¦è¾¹çš„Qï¼Œåœ¨æ›´æ–°å®Œå‡ æ¬¡åï¼Œç›´æ¥å°†å·¦è¾¹çš„Qè¦†ç›–å³è¾¹ã€‚é‡å¤å¤šæ¬¡ï¼š</p><p><img src="/images/15612553664628.jpg" width="65%" height="50%"></p><p>å¦ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚ä½•æ”¶é›†æ•°æ®ï¼Ÿ</p><p>ç”±äºactionæ˜¯åŸºäºQå‡½æ•°çš„ï¼Œä¹Ÿå³æ¯æ¬¡éƒ½é‡‡ç”¨è´ªå¿ƒçš„ç­–ç•¥ï¼Œä¼šä½¿å¾—åœ¨åˆå§‹æƒ…å†µä¸‹å›ºå®šçš„actionä¼šä¸€ç›´å‡ºç°ï¼Œæ— æ³•æ¢ç´¢åˆ°å…¶ä»–æƒ…å†µã€‚å› æ­¤é‡‡ç”¨ä¸¤ç§ç­–ç•¥ï¼š</p><p>â‘ epsilon greedyï¼š</p><p><script type="math/tex">a=\left\{\begin{aligned} \arg \max _{a} Q(s, a), & \text { with probability } 1-\varepsilon \\ \text {random}, & \text { otherwise } \end{aligned}\right.</script></p><p>å…¶ä¸­$\varepsilon$éšç€æ—¶é—´è€Œé€æ¸å˜å°ã€‚</p><p>â‘¡boltzmann explorationï¼š<br>æŒ‰æ¦‚ç‡é‡‡æ ·</p><script type="math/tex; mode=display">P(a | s)=\frac{\exp (Q(s, a))}{\sum_{a} \exp (Q(s, a))}</script><p>è¿˜æœ‰ä¸€ä¸ªå°æŠ€å·§ç”¨äºæ›´å¥½åˆ©ç”¨sampleï¼Œä¹Ÿå³replay bufferï¼šå°†æ¯æ¬¡Ï€ä¸ç¯å¢ƒäº¤äº’çš„episodeéƒ½æ”¾åœ¨ä¸€ä¸ªbufferé‡Œé¢ï¼Œå¯ä»¥éƒ½ç”¨æ¥å­¦ä¹ Qå‡½æ•°ï¼Œå³ä½¿æ•°æ®æ¥è‡ªä¸åŒçš„policyä¹Ÿæ²¡å…³ç³»ã€‚è¿™å’Œoff-policyæœ‰ç‚¹åƒã€‚ä¸ºä»€ä¹ˆå¯ä»¥è¿™ä¹ˆç”¨ä¸€ç§è§£é‡Šæ˜¯è¿™æ ·å¯ä»¥ä½¿å¾—æ•°æ®æ›´diverseï¼ŒåŒæ—¶å‡å°‘sampleæ¬¡æ•°åŠ å¿«è®­ç»ƒã€‚</p><p><img src="/images/15612559617307.jpg" width="40%" height="50%"></p><p>å› æ­¤ä¸€ä¸ªå…¸å‹çš„q-learningåˆ™æ˜¯ï¼š</p><p><img src="/images/15612560018865.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Q-learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡22</title>
      <link href="/2019/06/22/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8722/"/>
      <url>/2019/06/22/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8722/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Boosting Neural Machine Translation</li><li>Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks</li><li>On The Power of Curriculum Learning in Training Deep Networks</li><li>XLNet: Generalized Autoregressive Pretraining for Language Understanding</li><li>An Empirical Exploration of Curriculum Learning for Neural Machine Translation</li></ol><h2 id="Boosting-Neural-Machine-Translation"><a href="#Boosting-Neural-Machine-Translation" class="headerlink" title="[Boosting Neural Machine Translation]"></a>[Boosting Neural Machine Translation]</h2><p>é€šè¿‡å°†æœºå™¨å­¦ä¹ ä¸­çš„boostingå¼•å…¥NMTï¼Œå¯¹ç¿»è¯‘æ•ˆæœæœ‰ä¸€å®šæå‡ã€‚åŒæ—¶è¿˜æå‡ºäº†å¦å¤–å‡ ç§æ–¹æ³•ï¼Œå¯¹è¾“å…¥æ•°æ®pipelineè¿›è¡Œäº†ä¿®æ”¹ï¼Œå‘ç°éƒ½æœ‰ä¸€å®šçš„æå‡ã€‚æœ¬æ–‡çš„ä¸­å¿ƒæ€æƒ³å°±æ˜¯focus on difficult examplesï¼Œä½œè€…è®¤ä¸ºæ›´å¤šå…³æ³¨äºdifficult exampleï¼Œèƒ½å¤Ÿå¯¹æ¨¡å‹æœ‰æå‡çš„ä½œç”¨ã€‚</p><h3 id="å‡ ç§policy"><a href="#å‡ ç§policy" class="headerlink" title="å‡ ç§policy"></a>å‡ ç§policy</h3><p><img src="/images/15611921654433.jpg" width="40%" height="50%"></p><p>originalï¼šå°±æ˜¯å°†æ‰€æœ‰çš„æ•°æ®éƒ½è¿‡ä¸€é<br>boostï¼šå°†æœ€éš¾çš„10%é‡å¤ä¸€é<br>reduceï¼šå°†æœ€ç®€å•çš„20%å»æ‰ã€‚å…·ä½“æ“ä½œæ˜¯ï¼Œæ¯ä¸ªepoché‡æ–°è¡¡é‡ä¸€æ¬¡ï¼Œæ¯ä¸‰ä¸ªepochä½œä¸ºä¸€ä¸ªè®­ç»ƒï¼Œä¹Ÿå³ä¸‰ä¸ªepochå†…éƒ¨åˆ†åˆ«ä½¿ç”¨100% 80% 64%çš„æ•°æ®<br>bootstrapï¼šæ¯ä¸ªepochéƒ½re-sampleä¸€éï¼Œä¹Ÿå³å…è®¸é‡å¤ä»¥åŠéƒ¨åˆ†å¥å­æ¶ˆå¤±ã€‚</p><p>éš¾åº¦æ˜¯é€šè¿‡perplexityæ¥è¡¡é‡çš„ï¼Œå› ä¸ºæ¯ä¸ªepochåœ¨è®­ç»ƒæ—¶å°±å·²ç»è®¡ç®—è¿‡perplexityäº†ï¼Œå› æ­¤æ²¡æœ‰å¼•å…¥é¢å¤–çš„è®¡ç®—å¤æ‚åº¦ã€‚</p><h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p>è®ºæ–‡çš„å®éªŒé‡‡ç”¨çš„æ˜¯åŒå‘LSTMä½œä¸ºç¿»è¯‘çš„æ¨¡å—ã€‚</p><p><img src="/images/15611922669857.jpg" width="40%" height="50%"></p><p><img src="/images/15611922830047.jpg" width="40%" height="50%"></p><p>å‡ ä¸ªå®éªŒç»“è®ºï¼š<br>boostingèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œå¹¶ä¸”ç»“æœæ›´å¥½ï¼›<br>reduceç”¨æ›´å°‘çš„æ•°æ®ï¼Œè¾¾åˆ°æœ€å¥½çš„æ•ˆæœã€‚è¿™ç‚¹ä»¤äººå°è±¡æ·±åˆ»<br>boostrapï¼Œç¨å¾®å¥½ä¸€äº›ï¼Œä¸”è®­ç»ƒæ›´ç¨³å®šã€‚</p><p>ä¸ºä»€ä¹ˆè¦focus on difficult example?</p><blockquote><p>We emulate a human spending additional energy on learning complex concepts<br>To force the system to pay much attention on them can adjust it towards â€œmasteringâ€ more information for these sentences.</p></blockquote><h3 id="å‡ ä¸ªæƒ³æ³•"><a href="#å‡ ä¸ªæƒ³æ³•" class="headerlink" title="å‡ ä¸ªæƒ³æ³•"></a>å‡ ä¸ªæƒ³æ³•</h3><p>è¿™ç¯‡æ–‡ç« æ˜¯ä¸€ç¯‡çŸ­æ–‡ï¼Œå¾ˆæ˜æ˜¾å¾ˆå¤šå®éªŒæ²¡åšï¼Œä¼°è®¡æ˜¯åˆ°deadlineäº†å°±æäº¤äº†ï¼Œæ¯”å¦‚åˆ†æä¸åŒæ¯”ä¾‹çš„ç»“æœï¼Œä»¥åŠä¸€äº›æ¶ˆèå®éªŒä¹Ÿæ²¡åšã€‚</p><p>ä¸ºä»€ä¹ˆboostrapèƒ½å¤Ÿæœ‰æå‡å¹¶ä¸”æœ‰æ›´ç¨³å®šçš„è®­ç»ƒï¼Ÿè¿™ç§resampleçš„æ–¹å¼èƒ½å¤Ÿå¸¦æ¥ä¸€å®šçš„uncertaintyï¼Œå¯èƒ½ä¼šæœ‰ä¸€å®šçš„å¸®åŠ©ï¼Œè™½ç„¶å¸®åŠ©ä¸å¤§ï¼Œè®ºæ–‡é‡Œé¢ä¹Ÿä»…ä»…æåˆ°äº†uncertaintyï¼Œæ˜¾ç„¶åº”è¯¥åšè¿›ä¸€æ­¥çš„åˆ†æã€‚</p><p>è¿™ç¯‡è®ºæ–‡æä¾›çš„insightæˆ‘è®¤ä¸ºè¿˜æ˜¯æœ‰ä¸€å®šå¯å‘çš„ï¼Œé¦–å…ˆè¿™å¹¶ä¸æ˜¯curriculum-learningï¼Œä¹Ÿå³æ²¡æœ‰ä»ç®€å•åˆ°éš¾ï¼Œè€Œæ˜¯æ­£å¸¸çš„è®­ç»ƒï¼Œåªä¸è¿‡é€šè¿‡å¢åŠ æ›´å¤šçš„difficult exampleï¼ŒåŒæ—¶å»æ‰äº†éƒ¨åˆ†å¤ªç®€å•çš„sampleï¼Œè¯´æ˜ä»…ä»…æ˜¯ä¿®æ”¹æ•°æ®åˆ†å¸ƒè€Œä¸æ˜¯ä¿®æ”¹æ•°æ®çš„è¾“å…¥é¡ºåºï¼ˆæœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¿®æ”¹æ•°æ®åˆ†å¸ƒï¼‰ï¼Œä¹Ÿèƒ½å¤Ÿå¸¦æ¥æå‡æ•ˆæœï¼›ç¬¬äºŒï¼Œé€šè¿‡å‡å°‘ç®€å•æ•°æ®ï¼Œæ˜¯å¦æ„å‘³ç€ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ‰ä¸€ä¸ªä¸‹é™ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¥ç»ç½‘ç»œè¿™ç§èƒ½åŠ›å¾ˆå¼ºçš„æ¨¡å‹ï¼‰ï¼Œä½è¿‡è¿™ä¸ªä¸‹é™çš„æ•°æ®å¯¹æ¨¡å‹çš„è®­ç»ƒæ˜¯æ²¡æœ‰å¸®åŠ©çš„ï¼Œåè€Œå¯èƒ½ä¼šä½¿æ¨¡å‹overfitåˆ°æŸä¸ªç®€å•çš„patternï¼ˆè¿™å’Œlearning to executeçš„ç»“è®ºä¼¼ä¹æœ‰äº›ç±»ä¼¼ï¼‰ï¼›åŒæ—¶ï¼Œå¢åŠ æ›´å¤šçš„difficult sampleï¼Œä½¿å¾—æ¨¡å‹çš„ä¸Šé™è¢«æé«˜äº†ï¼›ä»¥åŠï¼Œæ˜¯å¦å¯ä»¥å°†curriculum learningä¸è¯¥æ€è·¯ç»“åˆèµ·æ¥ï¼Œè¾¾åˆ°æ›´å¥½çš„ç»“æœï¼Œä¸€æ–¹é¢ç”±æ˜“åˆ°éš¾ï¼Œå¦ä¸€æ–¹é¢ä¿®æ”¹æ•°æ®åˆ†å¸ƒï¼Œä½¿å¾—æ¨¡å‹æ›´å¤šå…³æ³¨éš¾çš„æ•°æ®ã€‚</p><hr><h2 id="Curriculum-Learning-by-Transfer-Learning-Theory-and-Experiments-with-Deep-Networks"><a href="#Curriculum-Learning-by-Transfer-Learning-Theory-and-Experiments-with-Deep-Networks" class="headerlink" title="[Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks]"></a>[Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks]</h2><p>ICML18çš„æ–‡ç« ï¼Œæå…¶ç¡¬æ ¸ï¼Œæ ¹æœ¬çœ‹ä¸æ‡‚ç†è®ºçš„éƒ¨åˆ†ã€‚</p><p>å…ˆè´´å‡ºICML oralçš„ä¸‰å¼ PPTï¼š</p><p><img src="/images/15611926258594.jpg" width="60%" height="50%"></p><p><img src="/images/15611926643253.jpg" width="60%" height="50%"></p><p><img src="/images/15611926800604.jpg" width="60%" height="50%"></p><p>ä»ç†è®ºä¸Šè¯æ˜äº†ï¼š</p><p>â‘ the rate of convergence of an ideal curriculum learning method is monotonically increasing with the difï¬culty of the examples</p><p>â‘¡convergence is faster when using points which incur higher loss with respect to the current hypothesis.<br>å½“difficulty scoreæ˜¯å›ºå®šçš„ï¼Œå¯¹äºcurrent hypothesisè€Œè¨€ï¼Œé«˜çš„lossèƒ½å¤Ÿæ¯”ä½çš„lossæ‹Ÿåˆé€Ÿåº¦æ›´å¿«ã€‚è¯¥ç»“è®ºéå¸¸ç›´è§‚ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œéš¾çš„exampleæ›´æœ‰ç›Šæ˜¯é’ˆå¯¹å½“å‰è€Œè¨€ï¼ˆcurrent hypothesisï¼‰è€Œç®€å•çš„exampleæ›´æœ‰ç›Šæ˜¯é’ˆå¯¹final hypothesisè€Œè¨€çš„ã€‚</p><p>â‘¢ä½¿ç”¨pretrainå¥½çš„æ¨¡å‹æ¥ä½œä¸ºdifficultyçš„ä¼°è®¡ï¼Œa signiï¬cant boost in convergence speed at the beginning of training</p><p>â‘£ä½¿ç”¨curriculum learningèƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿæ‹Ÿåˆï¼›å½“ä»»åŠ¡éš¾åº¦ï¼ˆè¿™å’Œæ¨¡å‹æœ¬èº«çš„å®¹é‡ä¹Ÿæœ‰å…³ï¼Œæ¨¡å‹è¶Šå¼±ç›¸å¯¹çš„ä»»åŠ¡éš¾åº¦ä¹Ÿå°±è¶Šå¤§ï¼ŒåŒæ—¶ä¹Ÿå’Œregularizationç›¸å…³ï¼Œè¶Šå¼ºä»£è¡¨æ¨¡å‹çš„è‡ªç”±åº¦è¶Šå¼±ï¼‰è¶Šå¤§æ—¶ï¼Œä½¿ç”¨CLçš„æ•ˆæœå°±è¶Šæ˜æ˜¾ã€‚</p><p>å‡ ä¸ªç»“æœï¼š</p><p><img src="/images/15611928935044.jpg" width="90%" height="50%"></p><p><img src="/images/15611929075096.jpg" width="45%" height="50%"></p><p>æ€è€ƒï¼š<br>æ–‡ä¸­çš„ç»“è®ºè¿˜æ˜¯å¯ä»¥å‚è€ƒå‚è€ƒçš„ï¼Œä½†theoreticalçš„ç»“è®ºæ¯•ç«Ÿæ˜¯åœ¨å‡¸å‡½æ•°ä¸Šå¾—åˆ°çš„ï¼Œä¼¼ä¹è¯´æœåŠ›ä¸å¤§ã€‚æ–‡ä¸­çš„æ€è·¯æ˜¯ä»ç†è®ºä¸Šè¯æ˜å‡¸å‡½æ•°çš„ç»“è®ºï¼›ç„¶åé€šè¿‡å®éªŒåœ¨éå‡¸å‡½æ•°ä¸Šä»å®è·µè¯æ˜ç›¸ä¼¼ç»“è®ºã€‚å…¶ä¸»è¦çš„è´¡çŒ®åœ¨äºä¸€äº›CLç›¸å…³çš„ç»“è®ºå’Œå¼•å…¥transfer learningä½œä¸ºdifficulty scoreã€‚</p><hr><h2 id="On-The-Power-of-Curriculum-Learning-in-Training-Deep-Networks"><a href="#On-The-Power-of-Curriculum-Learning-in-Training-Deep-Networks" class="headerlink" title="[On The Power of Curriculum Learning in Training Deep Networks]"></a>[On The Power of Curriculum Learning in Training Deep Networks]</h2><p>ICML19ä¸€ç¯‡å¾ˆç¡¬æ ¸çš„æ–‡ç« ï¼Œè¯´å®è¯é‡Œé¢çš„è¯æ˜ä»¥åŠéƒ¨åˆ†å®éªŒè®¾è®¡æˆ‘è¿˜æ˜¯æ²¡æ€ä¹ˆææ‡‚ã€‚ä½†æ˜¯ä¸€äº›ç»“è®ºå€¼å¾—æ³¨æ„ã€‚è¿™å±äºæœ‰å¯å‘çš„ä¸€ç±»è®ºæ–‡ã€‚</p><p>é€šè¿‡transfer-learningå’Œself-taughtçš„æ–¹æ³•è·å¾—æ–°çš„curriculum-learningç®—æ³•ï¼ŒåŒæ—¶é€šè¿‡ç†è®ºè¯æ˜è·å¾—äº†ä¸€äº›æœ‰å¯å‘æ€§çš„ç»“è®ºã€‚</p><p>curriculum learningæœ‰ä¸¤ä¸ªæŒ‘æˆ˜ï¼š å¦‚ä½•å®šä¹‰æ•°æ®çš„éš¾åº¦ï¼›ä»¥åŠæ•°æ®å–‚ç»™æ¨¡å‹çš„é€Ÿåº¦ï¼Œå¤ªå¿«ä¼šè®©æ¨¡å‹æ›´confusedï¼Œå¤ªæ…¢å¯¼è‡´å­¦ä¹ å¤ªæ…¢</p><p>æœ¬æ–‡å¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜éƒ½æœ‰ä¸€å®šçš„è§£å†³æ–¹æ¡ˆï¼šåˆ†åˆ«å®šä¹‰äº†scoring function å’Œ pacing function</p><p>scoring functionæœ‰ä¸¤ç§ï¼štransfer learningå’Œself-tutoringï¼Œä¸€ä¸ªå°±æ˜¯pretrained modelï¼Œå¦ä¸€ä¸ªæ˜¯ä½¿ç”¨è®­ç»ƒå¥½çš„æœªé‡‡ç”¨curriculum learningçš„æ¨¡å‹ã€‚</p><p>pacing functionï¼šâ‘ Fixed exponential pacingæ²¡å›ºå®šæ¬¡æ•°çš„stepå°±æå‡ä¸€ä¸‹ â‘¡Varied exponential pacing æå‡çš„stepå¯ä»¥æ˜¯å˜åŒ–çš„ â‘¢Single-step pacing ç®€åŒ–ç‰ˆçš„â‘ </p><p><img src="/images/15611932107816.jpg" width="50%" height="50%"></p><p>å…³äºcurrent hypothesisä¸target hypothesisï¼š</p><p>æœ‰äº›æ–¹æ³•ä¸­ï¼ˆself-paced learning hard example mining æˆ– active learningï¼‰æ›´å€¾å‘äºhard exampleã€‚å®é™…ä¸Šå’ŒCLä¸åŒï¼Œæ˜¯å› ä¸ºfocus on hard exampleæ˜¯åŸºäºå½“å‰æ¨¡å‹çš„çŠ¶æ€å»å®šä¹‰éš¾åº¦çš„ï¼ˆcurrent hypothesisï¼‰ï¼ŒCLåˆ™æ˜¯åŸºäºæœ€ç»ˆçš„çŠ¶æ€ï¼ˆtarget hypothesisï¼‰ã€‚å®é™…ä¸Šè¿™ä¸¤ç§å¹¶ä¸çŸ›ç›¾ï¼Œæœ‰ç ”ç©¶è¡¨æ˜æ¨¡å‹å¯ä»¥åŒæ—¶å—ç›Šäºè¿™ä¸¤ç§ã€‚è¿™ç¯‡æ–‡ç« ä¹Ÿä»ç†è®ºè§’åº¦å»è¯æ˜äº†è¿™ä¸€ç»“è®ºã€‚</p><h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><p>å…³äºcurriculum by transferçš„ç»“è®ºï¼š<br>Curriculum learning is clearly and signiï¬cantly beneï¬cial - learning starts faster, and converges to a better solution.<br>the observed advantage of CL is more signiï¬cant when the task is more difï¬cultï¼ˆå¾ˆç›´è§‚ï¼Œå› ä¸ºè¶Šéš¾çš„ä»»åŠ¡è¶Šéœ€è¦CLï¼‰</p><p>å…¶ä¸­anti-curriculumæŒ‡çš„æ˜¯æŒ‰ç…§éš¾åº¦ä»é«˜åˆ°ä½æ’ï¼›randomåˆ™æ˜¯å¯¹éš¾åº¦éšæœºæ’ï¼š</p><p><img src="/images/15611933223227.jpg" width="70%" height="50%"></p><p>å…¶ä»–ç»“è®ºï¼š</p><p>ä½¿ç”¨ä¸åŒçš„transfer functionéƒ½æŒ‡å‘äº†ç›¸ä¼¼çš„gradientæ–¹å‘ï¼›ä¸ä½¿ç”¨æ‰€æœ‰æ•°æ®ç›¸æ¯”ï¼Œtransfer functionåˆ™æŒ‡å‘äº†ä¸åŒçš„æ–¹å‘ï¼›åŒæ—¶ä½¿ç”¨æ‰€æœ‰æ•°æ®çš„gradientå’Œä½¿ç”¨random scoring functionçš„gradientç›¸ä¼¼ï¼Œè¯´æ˜randomèƒ½å¤Ÿè¾ƒä¸ºåˆç†çš„å»estimateçœŸæ­£çš„empirical gradientã€‚å¦‚å›¾ï¼š</p><p><img src="/images/15611934853212.jpg" width="65%" height="50%"></p><h3 id="ç†è®º"><a href="#ç†è®º" class="headerlink" title="ç†è®º"></a>ç†è®º</h3><p>ç•¥è¿‡å¤§é‡å…¬å¼ã€‚ç›´æ¥è°ˆç»“è®ºï¼š</p><p>â‘ é€šè¿‡CLä¿®æ”¹åçš„optimization landscapeæ‹¥æœ‰å’ŒåŸæ¥ä¸€æ ·çš„optimization functionï¼›å¹¶ä¸”ä¿®æ”¹åçš„global maximum æ¯”åŸå…ˆçš„æ›´æ˜æ˜¾ï¼ˆpronouncedï¼‰</p><p>â‘¡å¦‚æœæ•°æ®åˆ†å¸ƒpå’Œæœ€ä¼˜çš„utility $U_{\tilde{\vartheta}}(X)$ æ˜¯æ­£ç›¸å…³çš„ï¼Œä¸”æ¯”å…¶ä»–çš„$U_{\vartheta}(X)$æ›´æ­£ç›¸å…³ï¼Œé‚£ä¹ˆå¾€optimal parameter $\tilde{\vartheta}$ æ€»ä½“ä¸Šä¼šæ›´åŠ steeperï¼ˆé™¡å³­ï¼‰ã€‚</p><p>â‘¢the optimization landscape is modiï¬ed to amplify the difference between the optimal parameters vector and all other parameter values whose covariance with the optimal solution (the covariance is measured between the induced prior vectors) is small, and speciï¬cally smaller than the variance of the optimum. </p><h3 id="ç»“è®ºä¸æ€è€ƒ"><a href="#ç»“è®ºä¸æ€è€ƒ" class="headerlink" title="ç»“è®ºä¸æ€è€ƒ"></a>ç»“è®ºä¸æ€è€ƒ</h3><p>å°±æˆ‘çš„ç†è§£è€Œè¨€ï¼Œæœ¬æ–‡çš„æœ€å¤§è´¡çŒ®å°±æ˜¯ï¼šç»Ÿä¸€äº†åŸå…ˆçš„ä»ç®€å•åˆ°éš¾ï¼ˆcurriculum learningæˆ–self-paced learningï¼‰å’Œfocus on difficulty examplesï¼ˆboostingæˆ–hard data miningï¼‰ï¼Œåªè¦ä¿®æ”¹åçš„æ•°æ®åˆ†å¸ƒä¸optimal utilityæ˜¯æ­£ç›¸å…³çš„ï¼Œé‚£ä¹ˆå°±å¯ä»¥æå‡è¡¨ç°ï¼Œå› æ­¤ä¸¤ç§strategyéƒ½æ˜¯æœ‰æ•ˆçš„ã€‚ It may even be possible to find a curriculum which is directly correlated with the optimal utility, and that outperforms both methods</p><p>ä¸è¿‡è¿™ç¯‡æ–‡ç« æœ‰äº›å¥‡æ€ªï¼Œempiricalå’Œtheoreticalçš„éƒ¨åˆ†å®Œå…¨å‰²è£‚çš„æ„Ÿè§‰ã€‚</p><hr><h2 id="XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet-Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="[XLNet: Generalized Autoregressive Pretraining for Language Understanding]"></a>[XLNet: Generalized Autoregressive Pretraining for Language Understanding]</h2><p>æœ€è¿‘æ¯”è¾ƒç«çš„æ–‡ç« ï¼Œå¯¹Bertçš„å…¨é¢è¶…è¶Šã€‚å°†bertçš„åŒå‘å’Œcontextä»¥åŠlanguage modelçš„long range dependencyå·§å¦™ç»“åˆï¼Œè·å¾—æ–°çš„pretrain modelã€‚</p><h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><p>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¯ä»¥åˆ†ä¸ºä¸¤ç§ autoregressive(AR)è¯­è¨€æ¨¡å‹å’Œ autoencodingï¼ˆAEï¼‰ã€‚ARå°±æ˜¯ä¼ ç»Ÿçš„è¯­è¨€æ¨¡å‹ï¼Œä»å‰åˆ°åæˆ–ä»ååˆ°å‰é¢„æµ‹ï¼Œå…¸å‹çš„å°±æ˜¯GPTï¼›AEåˆ™æ˜¯é€šè¿‡å—ç ´åçš„æ•°æ®è¿˜åŸå‡ºåŸå§‹æ•°æ®ï¼ŒBertå°±æ˜¯å…¶ä¸­ä¸€å‘˜ã€‚</p><p>ä½†è¿™ä¸¤ç§æ–¹æ³•å„æœ‰ç¼ºç‚¹ï¼š</p><p>bertçš„AEæ–¹æ³•å‡è®¾äº†æ‰€æœ‰è¢«é¢„æµ‹çš„tokenæ˜¯ç‹¬ç«‹çš„ï¼ˆä¹Ÿå³maskæ‰çš„è¯ç›¸äº’ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œä¹Ÿå³ä¸Šä¸€ä¸ªmaskçš„è¯å¹¶ä¸èƒ½å¯¹é¢„æµ‹ä¸‹ä¸€ä¸ªmaskçš„è¯æœ‰å¸®åŠ©ï¼‰ï¼Œä½†è‡ªç„¶è¯­è¨€ä¸­è¿™ç§ä¾èµ–å…³ç³»åº”è¯¥æ˜¯å­˜åœ¨çš„ï¼›åŒæ—¶[Mask]åœ¨çœŸå®æ•°æ®ä¸­å¹¶ä¸å­˜åœ¨ï¼Œä¹Ÿå³å­˜åœ¨input noiseï¼Œå¯¼è‡´pretrain-ï¬netune discrepancyã€‚</p><p>è€ŒARçš„é—®é¢˜ä¸»è¦åœ¨æ²¡æœ‰å……åˆ†åˆ©ç”¨å‰åçš„ä¸Šä¸‹æ–‡ï¼Œåªä½¿ç”¨äº†éƒ¨åˆ†ã€‚</p><p>æœ¬æ–‡é€šè¿‡permutationæ¥è¾¾åˆ°è§„é¿è¿™ä¸¤ä¸ªç¼ºç‚¹çš„ç›®çš„ï¼Œä¹Ÿå³ æ—¢åˆ©ç”¨äº†å‰åä¸Šä¸‹æ–‡ï¼Œåˆæ²¡æœ‰input noiseï¼ŒåŒæ—¶è¿˜æ²¡æœ‰independence assumptionã€‚</p><h3 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><p>å®šä¹‰ä¸€ä¸ªfactorization ordersï¼ˆæ³¨æ„æ˜¯è™šæ‹Ÿçš„é¡ºåºï¼ŒåŸå§‹é¡ºåºè¿˜æ˜¯ä¼šä¿ç•™çš„ï¼‰ï¼Œå°†åŸå§‹çš„é¡ºåºæ‰“ä¹±ã€‚ä½¿å¾—ä¸€ä¸ªè¯çš„é¢„æµ‹å¯ä»¥ç”±ä¸¤ä¾§çš„è¯æ¥å¸®åŠ©ã€‚</p><p>å¦‚å›¾ï¼Œè¾“å…¥çš„åŸå§‹é¡ºåºè¿˜æ˜¯ä¸å˜ï¼Œä½†é€šè¿‡ mask attentionæ¥è¾¾åˆ°ä¸åŒçš„factorization orderçš„ç›®çš„ï¼Œåœ¨ä¸åŒorderä¸‹é¢„æµ‹åŒä¸€ä¸ª$x_3$ï¼Œç”±äºfactorization orderçš„é¡ºåºä¸åŒï¼Œåœ¨3ä¹‹å‰çš„è¯å‘æŒ¥äº†ä½œç”¨ï¼Œè€Œåœ¨ä»–ä¹‹åçš„è¯å°±æ²¡æœ‰å‚ä¸é¢„æµ‹ã€‚</p><p><img src="/images/15611948252404.jpg" width="70%" height="50%"></p><p>å½¢å¼åŒ–åˆ™æœ‰ï¼š</p><script type="math/tex; mode=display">\max _{\theta} \mathbb{E}_{\mathbf{z} \sim \mathcal{Z}_{T}}\left[\sum_{t=1}^{T} \log p_{\theta}\left(x_{z_{t}} | \mathbf{x}_{\mathbf{z}_{<t}}\right)\right]</script><p>å…¶ä¸­$z$æ˜¯permutation/factorization orderã€‚</p><p>æ˜¾ç„¶è¿™ä¸ªæ¨¡å‹å¦‚æœåªä½¿ç”¨åŸæ¥çš„transformerç»“æ„æ˜¯æœ‰é—®é¢˜çš„ï¼Œä¹Ÿå³target position unawareã€‚å‡è®¾ä»Šå¤©æœ‰ä¸¤ç§factorization orderï¼Œåœ¨tä¹‹å‰çš„å†…å®¹éƒ½æ˜¯ä¸€è‡´çš„ï¼Œåœ¨tä¸Šåˆ™æœ‰ä¸åŒçš„è¯ï¼Œé‚£ä¹ˆä»–ä»¬é¢„æµ‹çš„åˆ†å¸ƒéƒ½ä¼šæ˜¯ä¸€æ ·çš„ï¼Œä½†æŒ‰ç†è¯´ä¸åº”è¯¥ä¸€æ ·ï¼Œå› ä¸ºtargetä¸ä¸€æ ·ã€‚æ‰€ä»¥éœ€è¦è®©targetå‘æŒ¥ä½œç”¨ã€‚</p><p>å› æ­¤åœ¨è¿™é‡Œä¿®æ”¹äº†ä¸€ä¸‹transformeræ¶æ„ï¼Œå¼•å…¥Two-Stream Self-Attention for Target-Aware Representationsã€‚</p><p><img src="/images/15611949233220.jpg" width="90%" height="50%"></p><p>å¯ä»¥çœ‹åˆ°ï¼Œç°åœ¨å…µåˆ†ä¸¤è·¯ï¼Œæ¯ä¸€å±‚éƒ½å¾—åˆ°ä¸¤ä¸ªè¡¨ç¤ºã€‚å…¶ä¸­$h$å’ŒåŸæ¥transformerä¸€æ ·ï¼Œè€Œ$g$åˆ™æ˜¯æ–°å¼•è¿›çš„ï¼Œä¹Ÿå³åœ¨Qä¸­åªä½¿ç”¨<strong>position</strong>è€Œæ²¡æœ‰contentã€‚</p><p>å½¢å¼åŒ–æœ‰ï¼š</p><script type="math/tex; mode=display">\begin{array}{l}{g_{z_{t}}^{(m)} \leftarrow \text { Attention }\left(\mathbf{Q}=g_{z_{t}}^{(m-1)}, \mathbf{K V}=\mathbf{h}_{\mathbf{z}<t}^{(m-1)} ; \theta\right)} \text{  (query stream: use } z_t \text{ but cannot see }  x_{z_t}) \\ {h_{z_{t}}^{(m)} \leftarrow \text { Attention }\left(\mathbf{Q}=h_{z_{t}}^{(m-1)}, \mathbf{K V}=\mathbf{h}_{\mathbf{z} \leq t}^{(m-1)} ; \theta\right)} \text{  (content stream: use both } z_t \text{ and }  x_{z_t})\end{array}</script><p>æ‰€ä»¥ï¼Œè¿›è¡Œé¢„æµ‹è¯æ“ä½œçš„æ—¶å€™åªä½¿ç”¨$g$å»é¢„æµ‹ç›¸åº”ä½ç½®ä¸Šçš„å†…å®¹å³å¯ã€‚</p><p>ä¸€äº›ç»†èŠ‚ï¼š<br>â‘  ä¸ºäº†è®©è®­ç»ƒæ›´å®¹æ˜“ï¼Œåªé¢„æµ‹æœ€åçš„å‡ ä¸ªtokensï¼ˆfactorization orderçš„æœ€åå‡ ä¸ªï¼‰ï¼›<br>â‘¡å°†transformer-xlå¼•å…¥ï¼Œä¹Ÿå³ç›¸å¯¹ä½ç½®å’Œå†å²ä¿¡æ¯çš„idea<br>â‘¢å¼•å…¥ç›¸å¯¹ä½ç½®çš„segment encodingï¼Œä½¿å¾—æ›´çµæ´»ï¼Œå› ä¸ºè¿™æ ·å°±å¯ä»¥encodeè¶…è¿‡ä¸¤ä¸ªè¾“å…¥çš„segmentäº†ï¼Œä½¿ç”¨absolute segmentåˆ™ä¸è¡Œ.</p><h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>ç›¸å¯¹bertè€Œè¨€ï¼Œæœ‰æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œå› ä¸ºbertä½¿ç”¨äº†maskï¼Œä½¿å¾—maskä¹‹é—´ä¸èƒ½ç›¸äº’å¸®åŠ©ã€‚åŒæ—¶ä¹Ÿæœ‰åŸå…ˆlanguage modelçš„ç‰¹ç‚¹ï¼Œä¹Ÿå³é¡ºåºé¢„æµ‹çš„ç‰¹ç‚¹ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥ç”¨äºä¸€äº›æœ‰è¯¥ç‰¹ç‚¹çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä½œè€…æ•´ä¸ªæ€è·¯è¡Œäº‘æµæ°´ï¼Œå¹¶ä¸”å¯¹æ¨¡å‹çš„æœ¬è´¨çœ‹å¾—å¾ˆé€ã€‚</p><p>ä½†è¿™ç§æ–¹æ³•å› ä¸ºè¦ä¿å­˜ä¸¤ä»½hidden stateï¼Œä¼šéœ€è¦æ›´å¤šçš„å†…å­˜å’Œè®¡ç®—èµ„æºã€‚</p><p>è¿™ç¯‡æ–‡ç« çš„ç»“æœå¾ˆå¼ºï¼Œä¸”æ¨¡å‹ä¹Ÿæœ‰è¯´æœåŠ›ã€‚ä½†è®­ç»ƒä½¿ç”¨äº†512å¼ TPUï¼Œä»¥åŠç”¨äº†è¶…è¿‡Bertçš„æ•°æ®é‡ï¼ˆæ•°æ®é‡æ˜¯å¦å¯¹è¶…è¿‡Bertæœ‰å¾ˆå¤§çš„å¸®åŠ©ï¼Ÿï¼‰ã€‚ä¸å¾—ä¸è¯´è¿™ç±»æ–‡ç« æ™®é€šäººåªèƒ½çœ‹çœ‹ï¼ŒNLPå·²ç»è¿›å…¥äº†å†›å¤‡ç«èµ›äº†ã€‚</p><hr><h2 id="An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#An-Empirical-Exploration-of-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="[An Empirical Exploration of Curriculum Learning for Neural Machine Translation]"></a>[An Empirical Exploration of Curriculum Learning for Neural Machine Translation]</h2><p>è®¨è®ºäº†ä¸€äº›å…³äºåœ¨NMTä¸Šä½¿ç”¨CLçš„ç­–ç•¥ï¼ˆç›¸æ¯”åŸæœ¬çš„CLæ›´åŠ çµæ´»ï¼‰ï¼Œå¹¶åšäº†ä¸€ç³»åˆ—å®éªŒå¾—åˆ°ä¸€äº›ç»“è®ºã€‚</p><h3 id="ç­–ç•¥åˆ›æ–°"><a href="#ç­–ç•¥åˆ›æ–°" class="headerlink" title="ç­–ç•¥åˆ›æ–°"></a>ç­–ç•¥åˆ›æ–°</h3><p>â‘ <br>é¦–å…ˆæ˜¯å°†sample distributionçš„æ¦‚å¿µæ‰©å±•åˆ°shardçš„å±‚é¢è€Œä¸æ˜¯å•ä¸€çš„exampleã€‚ä¹Ÿå³ï¼š</p><p><img src="/images/15612123996612.jpg" width="50%" height="50%"></p><p>å°†exampleç»“æˆgroupã€‚å°†ç›¸ä¼¼difficultyçš„æ”¾åœ¨åŒä¸€ä¸ªshardé‡Œé¢ã€‚</p><p>å…·ä½“åº”å¦‚ä½•åšï¼Ÿæœ‰ä¸‰ç§æ–¹æ¡ˆï¼š<br>â‘ è®¾å®šä¸€ä¸ªéš¾åº¦scoreçš„é˜ˆå€¼ï¼Œæ˜¾ç„¶è¿™ä¸ªæ–¹æ³•ä¸å¥½å¼„ï¼Œå› ä¸ºä¸å¥½æ‰‹åŠ¨è®¾é˜ˆå€¼ã€‚<br>â‘¡ç›´æ¥ç­‰å¤§å°åˆ†ï¼Œæ¯ä¸ªshardçš„ä¸ªæ•°ä¸€æ ·ï¼Œä½†è¿™æ ·å¯èƒ½ä¼šå¸¦æ¥shardå†…éƒ¨çš„éš¾åº¦scoreçš„æ³¢åŠ¨ã€‚  â‘¢æœ¬æ–‡é‡‡ç”¨çš„æ˜¯<strong>Jenks Natural Breaks classiï¬cation algorithm</strong>ï¼Œä¹Ÿå³shardå†…éƒ¨çš„varianceå°½é‡å°ï¼Œshardä¹‹é—´çš„varianceå°½é‡å¤§</p><p>â‘¡<br>ç¬¬äºŒæ˜¯sample difficulty criteriaï¼š<br>é‡‡ç”¨äº†ä¸¤ç§æ–¹æ³•ï¼šä¸€ä¸ªæ˜¯è®­ç»ƒè¾…åŠ©ï¼ˆå°çš„ï¼‰æ¨¡å‹æ¥åšåˆ¤æ–­ï¼›å¦ä¸€ä¸ªæ˜¯é‡‡ç”¨linguisticçš„feature</p><p>ç¬¬ä¸€ç§ä¹Ÿå³Model-based Difï¬culty Criteriaï¼Œç»™å®šsource sentenceï¼Œè·å¾—targetçš„æ¦‚ç‡ã€‚<br>ç¬¬äºŒç§æ˜¯Linguistic Difï¬culty Criteriaï¼Œä¹Ÿå³word frequencyï¼Œç„¶åå°†å¥å­æŒ‰ç…§least frequent wordæ¥æ’åºï¼ˆè¿™å®é™…ä¸Šå’Œé€æ­¥æ·»åŠ è¯è¡¨å¤§å°ï¼Œç„¶åè®­ç»ƒæ‰€æœ‰è¯éƒ½åœ¨è¯¥è¯è¡¨çš„å¥å­æ˜¯ç­‰ä»·çš„ï¼‰</p><p>â‘¢<br>ç¬¬ä¸‰æ˜¯scheduleï¼š</p><p><img src="/images/15612125916364.jpg" width="60%" height="50%"></p><p>æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªé˜¶æ®µï¼ˆphaseï¼‰ã€‚</p><p>æ³¨æ„åˆ°defaultæ˜¯æœ‰shuffleçš„ï¼ˆshardä¹‹é—´çš„shuffleï¼‰ï¼›è€Œnoshuffleæ˜¯shardå†…éƒ¨æœ‰shuffleï¼Œä½†ä¹‹é—´æ²¡æœ‰shuffleã€‚</p><h3 id="å®éªŒç»“è®º"><a href="#å®éªŒç»“è®º" class="headerlink" title="å®éªŒç»“è®º"></a>å®éªŒç»“è®º</h3><p>ä¼¼ä¹ä¸¥æ ¼æŒ‰ç…§é¡ºåºæ¥åšï¼ˆnoshuffle)å¹¶æ²¡æœ‰å¸®åŠ©ï¼ˆç›¸å¯¹defaultè€Œè¨€ï¼‰ï¼›<br>å¯¹learning rateæ•æ„Ÿï¼›<br>CLç¡®å®æœ‰å¸®åŠ©ï¼Œdifficulty criteriaæ˜¯å…³é”®ï¼Œè¯è¡¨é¢‘ç‡å’Œä½¿ç”¨å°æ¨¡å‹æ¥åšæ ‡å‡†éƒ½æœ‰ç”¨ï¼Œä½†åœ¨è¿™é‡Œå¥å­é•¿åº¦æ²¡ç”¨ã€‚</p><h3 id="å‡ ä¸ªæ€è€ƒ"><a href="#å‡ ä¸ªæ€è€ƒ" class="headerlink" title="å‡ ä¸ªæ€è€ƒ"></a>å‡ ä¸ªæ€è€ƒ</h3><p>å®éªŒåšå¾—æœ‰ç‚¹å¥‡æ€ªï¼›è®ºæ–‡ä¸­çš„phaseä¼¼ä¹æ˜¯æ¯æ¬¡æ•°æ®è¿‡ä¸€éå°±åˆ°ä¸‹ä¸€ä¸ªphaseäº†ï¼Œç„¶è€Œshardåˆ†å¾—ä¹Ÿå¤ªå°‘äº†ï¼Œé‚£å…¶å®å‰å‡ ä¸ªepochå°±æŠŠCLçš„phaseå…¨éƒ¨èµ°å®Œäº†ï¼›<br>ä¸ºä»€ä¹ˆnoshuffleæ²¡æœ‰å¸®åŠ©ï¼Œæ˜¯å¦æ„å‘³ç€åœ¨ä¸€ä¸ªphaseå†…éƒ¨ä¸¥æ ¼æŒ‰ç…§ä»æ˜“åˆ°éš¾æ˜¯æ²¡æœ‰å¸®åŠ©çš„ï¼Œè€Œæ¨¡å‹æ›´éœ€è¦çš„æ˜¯é‚£äº›å¯¹å®ƒå½“å‰æœ€éš¾çš„é‚£ä¸€æ‰¹ï¼Œè€Œåœ¨è¿™ä¸ªphaseå†…æ˜¯å…ˆå‡ºç°è¿˜æ˜¯åå‡ºç°éƒ½æ²¡æœ‰å…³ç³»ï¼Ÿè¿™æ ·æ˜¯å¦å¯ä»¥åœ¨phaseå†…éƒ¨ä½¿ç”¨boostingï¼Ÿæˆ–è€…å¹²è„†åˆ æ‰ä¸é‡è¦çš„ä¾‹å­ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> Language Modeling </tag>
            
            <tag> NMT </tag>
            
            <tag> Curriculum Learning </tag>
            
            <tag> boosting </tag>
            
            <tag> XLNet </tag>
            
            <tag> pretrain </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 2:Proximal Policy Optimization (PPO)</title>
      <link href="/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%202:%20Proximal%20Policy%20Optimization%20(PPO)/"/>
      <url>/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%202:%20Proximal%20Policy%20Optimization%20(PPO)/</url>
      
        <content type="html"><![CDATA[<p>Policy Gradientçš„é—®é¢˜ï¼šæ¯æ¬¡sampleçš„dataåªèƒ½ä½¿ç”¨ä¸€æ¬¡ï¼Œè¾ƒä¸ºè€—è´¹æ—¶é—´ã€‚å› æ­¤å¼•å…¥off-policyï¼Œæ¯æ¬¡sampleçš„æ•°æ®å¯ä»¥å¤šæ¬¡ä½¿ç”¨ã€‚</p><p>ç‰¹ç‚¹ï¼šon-policyä¸­å­¦ä¹ çš„agentä¸å’Œç¯å¢ƒäº¤äº’çš„agentæ˜¯ä¸€è‡´çš„ï¼›è€Œoff-policyåˆ™æ˜¯æœ‰ä¸¤ä¸ªagentï¼Œå…¶ä¸­ä¸€ä¸ªagentè´Ÿè´£ä¸ç¯å¢ƒäº¤äº’æ¥è·å¾—episodeï¼Œå¦ä¸€ä¸ªagentåˆ™é€šè¿‡è¿™äº›episodeæ›´æ–°å‚æ•°ã€‚</p><p>åœ¨è¿™é‡Œåˆ©ç”¨importance-samplingæ¥è¾¾åˆ°è¿™ä¸€ç›®çš„ã€‚</p><h3 id="importance-sampling"><a href="#importance-sampling" class="headerlink" title="importance-sampling"></a>importance-sampling</h3><p>ç»™å®šæ¦‚ç‡$p$è¦è®¡ç®—$f(x)$çš„æœŸæœ›ï¼šå¯ä»¥é‡‡ç”¨sampleçš„æ–¹å¼æ¥è¾¾åˆ°è¯¥ç›®çš„ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">E_{x \sim p}[f(x)] \approx \frac{1}{N} \sum_{i=1}^{N} f\left(x^{i}\right)</script><p>è€Œè‹¥$p$åˆ†å¸ƒæ— æ³•è·å¾—ï¼Œå¯ä»¥åˆ©ç”¨å¦ä¸€ä¸ªå¯è·å¾—çš„åˆ†å¸ƒ$q$æ¥è¿‘ä¼¼ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">E_{x \sim p}[f(x)]=\int f(x) p(x) d x=\int f(x) \frac{p(x)}{q(x)} q(x) d x=E_{x \sim q}[f(x) \frac{p(x)}{q(x)}]</script><p>ç„¶åå†ç”±$q$æ¥åšsamplingã€‚</p><p>æ³¨æ„è¿™é‡Œ$p$ä¸$q$çš„åˆ†å¸ƒä¸åº”è¯¥å·®è·å¤ªå¤§ï¼Œå¦åˆ™å…¶varianceåˆ™ä¼šç›¸å·®å¾ˆå¤§ï¼Œé€ æˆè¿‘ä¼¼ç»“æœå·®è·è¾ƒå¤§ã€‚</p><h3 id="off-policy"><a href="#off-policy" class="headerlink" title="off-policy"></a>off-policy</h3><p>å°†importance samplingç”¨äºoff-policyã€‚</p><p>åŸæ¥ï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta}=E_{\tau \sim p_{\theta}(\tau)}\left[R(\tau) \nabla \log p_{\theta}(\tau)\right]</script><p>å˜æˆï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta}=E_{\tau \sim p_{\theta^{\prime}}(\tau)}\left[\frac{p_{\theta}(\tau)}{p_{\theta^{\prime}}(\tau)} R(\tau) \log p_{\theta}(\tau)\right]</script><p>å…¶ä¸­$p_{\theta^{\prime}}$æ˜¯å¦ä¸€ä¸ªagentçš„åˆ†å¸ƒï¼Œä¹Ÿå³dataæ˜¯ä»è¯¥agentçš„åˆ†å¸ƒsampleå¾—åˆ°çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨è¯¥dataæ¥å¤šæ¬¡è®­ç»ƒÎ¸ã€‚</p><p>å› æ­¤æ¢¯åº¦å…¬å¼åˆ™ä¸ºï¼š</p><script type="math/tex; mode=display">\begin{array}{l}{=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta}}\left[A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]} \\ {=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{P_{\theta}\left(s_{t}, a_{t}\right)}{P_{\theta^{\prime}}\left(s_{t}, a_{t}\right)} A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]} \\ {=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{p_{\theta}\left(a_{t} | s_{t}\right)}{p_{\theta^{\prime}}\left(a_{t} | s_{t}\right)} \frac{p_{\theta}\left(s_{t}\right)}{p_{\theta^{\prime}}\left(s_{t}\right)} A^{\theta}\left(s_{t}, a_{t}\right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)\right]}\end{array}</script><p>å…¶ä¸­ï¼Œæˆ‘ä»¬å°†$A^{\theta}\left(s_{t}, a_{t}\right)$æ”¹æˆ$A^{\theta^{\prime}}\left(s_{t}, a_{t}\right)$ï¼Œå› ä¸ºæ•°æ®æ˜¯ä»$\theta^{\prime}$ æ¥çš„ï¼›åŒæ—¶æˆ‘ä»¬å‡è®¾$\frac{p_{\theta}\left(s_{t}\right)}{p_{\theta^{\prime}}\left(s_{t}\right)}=1$ï¼Œä¸€æ–¹é¢æ˜¯ä¸æ–¹ä¾¿è®¡ç®—ï¼Œä½œæ­¤å‡è®¾å¯ä»¥æ–¹ä¾¿è®¡ç®—ï¼›å¦ä¸€æ–¹é¢è¯¥å‡è®¾ä¹Ÿæœ‰ä¸€å®šåˆç†æ€§ï¼Œå› ä¸ºæŸä¸ªstateå‡ºç°çš„å‡ ç‡åº”è¯¥å’Œagentçš„å…³ç³»è¾ƒå°ã€‚</p><p>é€šè¿‡æ¢¯åº¦å…¬å¼æˆ‘ä»¬å¯ä»¥è¿˜åŸå‡ºåŸå¼ï¼š </p><script type="math/tex; mode=display">J^{\theta^{\prime}}(\theta)=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[\frac{p_{\theta}\left(a_{t} | s_{t}\right)}{p_{\theta^{\prime}}\left(a_{t} | s_{t}\right)} A^{\theta^{\prime}}\left(s_{t}, a_{t}\right)\right]</script><p>å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåœ¨ä»€ä¹ˆæ—¶å€™åœæ­¢ä½¿ç”¨åŒä¸€ç»„dataæ›´æ–°å‚æ•°ï¼Ÿä¹Ÿå³åŒä¸€ç»„dataèƒ½å¤Ÿæ›´æ–°å‚æ•°å‡ æ¬¡ï¼Ÿ</p><p>ä¸€ä¸ªåŸåˆ™æ˜¯ï¼šæˆ‘ä»¬å¸Œæœ›ä¸¤ä¸ªagentçš„åˆ†å¸ƒå·®å¼‚å°ä¸€äº›ï¼Œå› ä¸ºåˆ†å¸ƒå·®å¼‚ä¸€æ—¦å¤§äº†ï¼Œvarianceåˆ™ä¼šå˜å¤§ï¼Œå› æ­¤è¿™é‡Œæ·»åŠ ä¸€ä¸ªconstraintã€‚</p><script type="math/tex; mode=display">J_{P P O}^{\theta^{\prime}}(\theta)=J^{\theta^{\prime}}(\theta)-\beta K L\left(\theta, \theta^{\prime}\right)</script><p>æ³¨æ„è¿™é‡Œçš„KLæ•£åº¦æ˜¯å¯¹actionåˆ†å¸ƒçš„KLæ•£åº¦è€Œä¸æ˜¯å‚æ•°çš„ã€‚</p><p>æ‰€ä»¥æœ€ç»ˆçš„ç®—æ³•ä¸ºï¼š</p><p><img src="/images/15606497157322.jpg" width="60%" height="50%"></p><p>å…¶ä¸­$\theta_{k}$æ˜¯ä¸Šæ¬¡æ›´æ–°å®Œçš„agentçš„å‚æ•°ã€‚ä¹Ÿå³ä¸ç¯å¢ƒäº¤äº’çš„agentçš„å‚æ•°æ€»æ˜¯ä¸Šä¸ªiteration å¦ä¸€ä¸ªagentæ›´æ–°åçš„å‚æ•°ã€‚</p><p>è¿˜æœ‰å‡ ä¸ªç»†èŠ‚ï¼Œ$\beta$å¯ä»¥æ˜¯adaptiveçš„ï¼›ä»¥åŠPPO2å¯¹PPOä¸­constraintçš„æ”¹è¿›ï¼Œä¸è¿‡éƒ½æ˜¯ç»†ææœ«èŠ‚ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> PPO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DRL Lecture 1:Policy Gradient (Review)</title>
      <link href="/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%201:%20Policy%20Gradient%20(Review)/"/>
      <url>/2019/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/DRL%20Lecture%201:%20Policy%20Gradient%20(Review)/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_" target="_blank" rel="noopener">æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹</a>ç¬”è®°ã€‚</p><hr><p>æœ¬lectureä¸»è¦æ˜¯å¤ä¹ å¼ºåŒ–å­¦ä¹ çš„policy gradientã€‚åŸºæœ¬çš„ä»‹ç»éƒ½åœ¨ä¹‹å‰çš„<a href="http://www.linzehui.me/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/">å¼ºåŒ–å­¦ä¹ ç¬”è®°</a>é‡Œé¢ã€‚</p><p>åŸºæœ¬å¤§è‡´æ¡†æ¶ä¸ºï¼š</p><p><img src="/images/15606479563499.jpg" width="50%" height="50%"></p><p>æ¯æ¬¡sampleå‡ ä¸ªepisodeï¼Œç„¶åæ›´æ–°æ¨¡å‹ï¼š</p><p><img src="/images/15606479845586.jpg" width="50%" height="50%"></p><p>å€¼å¾—æçš„å‡ ä¸ªæ–°çš„ç‚¹ï¼š<br>â‘ æˆ‘ä»¬è¦å¯¹rewardåŠ baselineï¼Œå› ä¸ºé˜²æ­¢rewardä¸€ç›´ä¸ºæ­£ï¼Œé¼“åŠ±å…¶ä»–å‡ºç°å‡ ç‡å°ä½†rewardé«˜çš„episodeè¢«sampleåˆ°ã€‚å› æ­¤åŠ ä¸€ä¸ªbaselineï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(R\left(\tau^{n}\right) -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>å…¶ä¸­$b$å¯ä»¥è®¾ä¸º$b \approx E[R(\tau)]$</p><p>â‘¡å¯¹æ¯ä¸ªactionåº”è¯¥åˆ†é…ä¸åŒçš„weightï¼Œé¼“åŠ±rewardé«˜çš„actionå‡ºç°ï¼š<br>ä¸€ç§æ–¹æ³•ï¼Œæ˜¯å°†å…¨å±€çš„Ræ¢æˆç´¯ç§¯çš„Rï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} r_{t^{\prime}}^{n} -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>ä¹Ÿå³å½“å‰actionåˆ°episodeç»“æŸç´¯åŠ çš„rewardã€‚</p><p>æ›´è¿›ä¸€æ­¥ï¼Œæ·»åŠ è¡°å‡å› å­ï¼Œå…¶ä¸­$\gamma&lt;1$ï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_{\theta} \approx \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_{n}}\left(\sum_{t^{\prime}=t}^{T_{n}} \gamma^{t^{\prime}-t} r_{t^{\prime}}^{n} -b \right) \nabla \log p_{\theta}\left(a_{t}^{n} | s_{t}^{n}\right)</script><p>å½“ç„¶ï¼Œä¸ºäº†ç®€ä¾¿ï¼Œå°†reward $R(\tau^{n})$ ç»Ÿä¸€å†™æˆ $A^Î¸ (s_t,a_t )$ï¼Œä»£è¡¨çš„æ˜¯åœ¨å½“å‰stateä¸‹é‡‡ç”¨actionçš„rewardã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> å¼ºåŒ–å­¦ä¹  </tag>
            
            <tag> RL </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Policy Gradient </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡21</title>
      <link href="/2019/06/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8721/"/>
      <url>/2019/06/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8721/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Named Entity Recognition with Bidirectional LSTM-CNNs</li></ol><h2 id="Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs"><a href="#Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs" class="headerlink" title="[Named Entity Recognition with Bidirectional LSTM-CNNs]"></a>[Named Entity Recognition with Bidirectional LSTM-CNNs]</h2><p>å…³äºNERçš„ç»å…¸è®ºæ–‡ã€‚</p><p>æ€»çš„ç»“æ„å¾ˆç®€å•ï¼Œå…¶å®å°±æ˜¯åˆ©ç”¨word embedding + CNN-char features + additional word featuresä½œä¸ºæ€»çš„featuresï¼Œè¿‡ä¸€ä¸ªåŒå‘LSTMè·å¾—ä¸Šä¸‹æ–‡ç›¸å…³çš„å‘é‡è¡¨ç¤ºï¼Œæœ€ç»ˆè·å¾—åˆ†ç±»ç»“æœã€‚</p><p><img src="/images/15606462750491.jpg" width="55%" height="50%"></p><p>å…¶ä¸­CNNçš„featureæ˜¯characterçº§åˆ«çš„ï¼š</p><p><img src="/images/15606463343904.jpg" width="55%" height="50%"></p><p>åŒæ—¶è¿˜åŠ äº†ä¸€äº›äººå·¥çš„featureï¼šæ¯”å¦‚å¤§å†™çš„featureï¼›æ¯”å¦‚å¤–éƒ¨è¯å…¸ç­‰ã€‚</p><p>æœ€ç»ˆ</p><p><img src="/images/15606463626767.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> NER </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯28</title>
      <link href="/2019/06/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D28/"/>
      <url>/2019/06/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D28/</url>
      
        <content type="html"><![CDATA[<h3 id="è¶æ‹èŠ±"><a href="#è¶æ‹èŠ±" class="headerlink" title="è¶æ‹èŠ±"></a>è¶æ‹èŠ±</h3><p>[å®‹] æ¬§é˜³ä¿®<br>åº­é™¢æ·±æ·±æ·±å‡ è®¸ï¼Ÿæ¨æŸ³å †çƒŸï¼Œå¸˜å¹•æ— é‡æ•°ã€‚ç‰å‹’é›•éæ¸¸å†¶å¤„ï¼Œæ¥¼é«˜ä¸è§ç« å°è·¯ã€‚<br>é›¨æ¨ªé£ç‹‚ä¸‰æœˆæš®ï¼Œé—¨æ©é»„æ˜ï¼Œæ— è®¡ç•™æ˜¥ä½ã€‚<strong>æ³ªçœ¼é—®èŠ±èŠ±ä¸è¯­ï¼Œä¹±çº¢é£è¿‡ç§‹åƒå»</strong>ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†22</title>
      <link href="/2019/06/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8622/"/>
      <url>/2019/06/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8622/</url>
      
        <content type="html"><![CDATA[<h3 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="[Sequence Labeling]"></a>[Sequence Labeling]</h3><p>ä»‹ç»sequence labelingåšå®¢ï¼š<br><a href="https://www.cnblogs.com/jiangxinyang/p/9368482.html" target="_blank" rel="noopener">https://www.cnblogs.com/jiangxinyang/p/9368482.html</a></p><p>å…³äºå‡ ä¸ªä»»åŠ¡çš„å®šä¹‰ï¼š</p><p>å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NER)ï¼šä»æ–‡æœ¬ä¸­è¯†åˆ«å‡ºå‘½åå®ä½“ï¼Œå®ä½“ä¸€èˆ¬åŒ…æ‹¬äººå(PER)ã€åœ°å(LOC)ã€æœºæ„å(ORG)ã€æ—¶é—´ã€æ—¥æœŸã€è´§å¸ã€ç™¾åˆ†æ¯”ç­‰ã€‚<br>ç»„å—åˆ†æ (Chunking)ï¼šæ ‡å‡ºå¥å­ä¸­çš„çŸ­è¯­å—ï¼Œä¾‹å¦‚åè¯çŸ­è¯­ï¼ˆNPï¼‰ï¼ŒåŠ¨è¯çŸ­è¯­ï¼ˆVPï¼‰ç­‰<br>è¯æ€§æ ‡æ³¨ (Part-of-speech Tagging, POS)ï¼šç¡®å®šæ–‡æœ¬ä¸­æ¯ä¸ªè¯çš„è¯æ€§ã€‚è¯æ€§åŒ…æ‹¬åŠ¨è¯ï¼ˆVerbï¼‰ã€åè¯ï¼ˆNounï¼‰ã€ä»£è¯ï¼ˆpronounï¼‰ç­‰ã€‚</p><h3 id="Active-learning"><a href="#Active-learning" class="headerlink" title="[Active learning]"></a>[Active learning]</h3><p>å®šä¹‰ï¼š</p><p>æ ·æœ¬ä¿¡æ¯å°±æ˜¯è¯´åœ¨è®­ç»ƒæ•°æ®é›†å½“ä¸­æ¯ä¸ªæ ·æœ¬å¸¦ç»™æ¨¡å‹è®­ç»ƒçš„ä¿¡æ¯æ˜¯ä¸åŒçš„ï¼Œå³æ¯ä¸ªæ ·æœ¬ä¸ºæ¨¡å‹è®­ç»ƒçš„è´¡çŒ®æœ‰å¤§æœ‰å°ï¼Œå®ƒä»¬ä¹‹é—´æ˜¯æœ‰å·®å¼‚çš„ã€‚<br>å› æ­¤ï¼Œä¸ºäº†å°½å¯èƒ½åœ°å‡å°è®­ç»ƒé›†åŠæ ‡æ³¨æˆæœ¬ï¼Œåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸä¸­ï¼Œæå‡ºä¸»åŠ¨å­¦ä¹ ï¼ˆactive learningï¼‰æ–¹æ³•ï¼Œä¼˜åŒ–åˆ†ç±»æ¨¡å‹ã€‚<br>ä¸»åŠ¨å­¦ä¹ (active learning)ï¼ŒæŒ‡çš„æ˜¯è¿™æ ·ä¸€ç§å­¦ä¹ æ–¹æ³•ï¼š<br>æœ‰çš„æ—¶å€™ï¼Œæœ‰ç±»æ ‡çš„æ•°æ®æ¯”è¾ƒç¨€å°‘è€Œæ²¡æœ‰ç±»æ ‡çš„æ•°æ®æ˜¯ç›¸å½“ä¸°å¯Œçš„ï¼Œä½†æ˜¯å¯¹æ•°æ®è¿›è¡Œäººå·¥æ ‡æ³¨åˆéå¸¸æ˜‚è´µï¼Œè¿™æ—¶å€™ï¼Œå­¦ä¹ ç®—æ³•å¯ä»¥ä¸»åŠ¨åœ°æå‡ºä¸€äº›æ ‡æ³¨è¯·æ±‚ï¼Œå°†ä¸€äº›ç»è¿‡ç­›é€‰çš„æ•°æ®æäº¤ç»™ä¸“å®¶è¿›è¡Œæ ‡æ³¨ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Sequence Labeling </tag>
            
            <tag> Active learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡20</title>
      <link href="/2019/06/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8720/"/>
      <url>/2019/06/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8720/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Neural Machine Translation in Linear Time</li><li>Curriculum Learning</li><li>Bilingual Word Embeddings for Phrase-Based Machine Translation</li><li>LEARNING TO EXECUTE</li><li>Self-Paced Learning for Latent Variable Models</li></ol><h2 id="Neural-Machine-Translation-in-Linear-Time"><a href="#Neural-Machine-Translation-in-Linear-Time" class="headerlink" title="[Neural Machine Translation in Linear Time]"></a>[Neural Machine Translation in Linear Time]</h2><p>ä½¿ç”¨æ–°çš„ç»“æ„å°†ç¿»è¯‘æ§åˆ¶åœ¨çº¿æ€§å¤æ‚åº¦ã€‚æ„Ÿè§‰æ€è·¯è¿˜è›®æ¸…æ™°ï¼ŒæŒºæ–°é¢–çš„ã€‚</p><p><img src="/images/15600510169611.jpg" width="55%" height="50%"></p><p>ä¸»è¦æœ‰ä¸‰ä¸ªç‚¹ï¼š</p><p>ç¬¬ä¸€ï¼Œç»“æ„ä¸Šé‡‡ç”¨bytenetï¼Œä¹Ÿå³é‡‡ç”¨äº†ç©ºæ´å·ç§¯çš„ç½‘ç»œï¼Œä½¿å¾—è®¡ç®—ä»£ä»·å‡å°ã€‚</p><p>ç¬¬äºŒï¼Œç›´æ¥å°†decoderå †åœ¨encoderä¸Šï¼Œæ¯æ¬¡decoderåªå–å¯¹åº”å¯¹åº”ä½ç½®ä¸Šçš„encoderï¼Œè¿™å’Œä¸€èˆ¬çš„åŸºäºencoder-decoderçš„æ–¹æ³•ä¸åŒã€‚</p><p>ç¬¬ä¸‰ï¼Œé‡‡ç”¨dynamic unfoldingä»¥è§£å†³encoderä¸decoderé•¿åº¦ä¸åŒçš„é—®é¢˜ã€‚äººå·¥é¢„å…ˆå®šä¹‰å¥½decoderçš„ä¸Šç•Œï¼š</p><script type="math/tex; mode=display">|\hat{\mathbf{t}}|=a|\mathbf{s}|+b</script><p>ä¹Ÿå³encoderå°†ä¼šç”Ÿæˆè¿™ä¹ˆå¤šçš„representationã€‚</p><p>è€Œå®é™…ä¸Štargetæ˜¯å¯ä»¥è¶…å‡ºè¿™ä¸ªä¸Šç•Œçš„ï¼Œç›´åˆ°ç”ŸæˆEOSä¸ºæ­¢ï¼Œå¦‚æœè¶…å‡ºä¸Šç•Œåˆ™åœ¨è¯¥æ­¥ä¸åˆ©ç”¨encoderçš„representationï¼Œä¸Šç•Œåªæ˜¯ç”¨ä»¥æŒ‡å¯¼encoderåº”è¯¥ç”Ÿæˆå¤šå°‘representationã€‚</p><p><img src="/images/15600511595880.jpg" width="80%" height="50%"></p><p>è¯¥æ¨¡å‹éå¸¸è½»é‡çº§ï¼›ä½†æˆ‘è¿˜æ˜¯æ²¡æœ‰æ€ä¹ˆææ‡‚encoderå¦‚ä½•ç”Ÿæˆå‡ºæ¯”sourceé•¿åº¦è¿˜é•¿çš„ä¿¡æ¯çš„ã€‚</p><hr><h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="[Curriculum Learning]"></a>[Curriculum Learning]</h2><p>è¯¾ç¨‹å­¦ä¹ çš„å¼€å±±ä¹‹ä½œã€‚å¯¹curriculum learningè¿›è¡Œäº†å½¢å¼åŒ–çš„æ€»ç»“ï¼Œå¹¶ä¸”é€šè¿‡å‡ ä¸ªå®éªŒå¯¹curriculum learningçš„æ€§è´¨è¿›è¡Œäº†æ¢ç´¢ã€‚è¯¥æ–‡ç« å±äºå¯¹å…¶ä»–äººæœ‰å¯å‘çš„æ€§è´¨ã€‚</p><p>curriculum learningçš„æ€æƒ³ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå…ˆä½¿ç”¨ç®€å•çš„æ ·ä¾‹è¿›è¡Œè®­ç»ƒï¼Œç„¶åé€æ¸å°†éš¾çš„æ ·ä¾‹åŠ å…¥åˆ°è®­ç»ƒæ ·ä¾‹ä¸­ã€‚æœ¬è´¨å°±æ˜¯ä»æ˜“åˆ°éš¾çš„è¿‡ç¨‹ï¼Œç¬¦åˆäººçš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿè·å¾—æ›´å¥½çš„æ•ˆæœã€‚</p><p>å½¢å¼åŒ–ï¼š<br>æ„Ÿè§‰ä¸é‡è¦ï¼Œå…¶å®å°±æ˜¯å¯¹data distributionè¿›è¡Œäº†é‡æ’ã€‚</p><p>æ€§è´¨ï¼š</p><p>â‘ è·å¾—æ›´å¥½çš„ç»“æœ </p><p>â‘¡èƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œâ€˜Cleaner Examples May Yield Better Generalization Faster â€™ï¼Œå› ä¸ºç®€å•çš„exampleèƒ½å¤Ÿé¿å…confuse the learner </p><p>â‘¢curriculum learningå±•ç°å‡ºregularizerçš„æ€§è´¨ï¼Œä¹Ÿå³åœ¨åŒæ ·training errorçš„æƒ…å†µä¸‹èƒ½å¤Ÿè·å¾—æ›´ä½çš„generalization errorã€‚</p><p>å¯¹äºlearneræ¥è¯´ï¼Œåœ¨è®­ç»ƒçš„æ¯ä¸ªé˜¶æ®µéƒ½æœ‰å¯¹ä»–æ¥è¯´å¤ªç®€å•å’Œå¤ªéš¾çš„çŸ¥è¯†ï¼Œå¤ªç®€å•çš„å­¦ä¸åˆ°ä»€ä¹ˆï¼Œå¤ªéš¾çš„å­¦ä¸ä¼šã€‚å› æ­¤åœ¨æ¯ä¸ªé˜¶æ®µé€‰æ‹©å¯¹learnerè€Œè¨€interestingçš„ä¾‹å­ï¼Œä¸å¤ªéš¾ä¹Ÿä¸å¤ªç®€å•çš„ï¼Œæ˜¯æœ€å¥½çš„ã€‚</p><p>åŒæ—¶curriculum learningä¸boosting algorithmä¸åŒï¼Œå› ä¸ºboosting algorithm æ˜¯å¼ºè°ƒéš¾çš„exampleè€Œcurriculum learningåªæ˜¯æ¯ä¸ªé˜¶æ®µæŒ‰ç…§éš¾åº¦å¯¹exampleèµ‹äºˆä¸åŒçš„æƒå€¼ã€‚</p><p>curriculum learningå¯ä»¥çœ‹åšæ˜¯transfer learningçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ã€‚transfer learningæ˜¯åˆ©ç”¨åŸå§‹ä»»åŠ¡æ¥å¼•å¯¼learneråœ¨æœ€ç»ˆä»»åŠ¡è·å¾—æ›´å¥½çš„ç»“æœï¼›è€Œcurriculum learningå°±æ˜¯åˆ©ç”¨è®­ç»ƒä¸Šçš„æŠ€å·§æ¥å¼•å¯¼learnerè·å¾—æ›´å¥½çš„æœ€ç»ˆç»“æœã€‚</p><p>å…¶å®curriculum learningçš„éš¾ç‚¹å°±åœ¨äºå¦‚ä½•å®šä¹‰easy exampleï¼Œå› ä¸ºä¸åŒä»»åŠ¡å¯èƒ½æœ‰ä¸åŒçš„å®šä¹‰ã€‚</p><hr><h2 id="Bilingual-Word-Embeddings-for-Phrase-Based-Machine-Translation"><a href="#Bilingual-Word-Embeddings-for-Phrase-Based-Machine-Translation" class="headerlink" title="[Bilingual Word Embeddings for Phrase-Based Machine Translation]"></a>[Bilingual Word Embeddings for Phrase-Based Machine Translation]</h2><p>è®²å…³äºè®­ç»ƒåŒè¯­word embeddingçš„ã€‚æˆ‘åªå…³æ³¨curriculum learningéƒ¨åˆ†ï¼Œä½†å…¶å®è®²çš„ä¸å¤šã€‚</p><hr><h2 id="LEARNING-TO-EXECUTE"><a href="#LEARNING-TO-EXECUTE" class="headerlink" title="[LEARNING TO EXECUTE]"></a>[LEARNING TO EXECUTE]</h2><p>è¿™ç¯‡è®ºæ–‡æ˜¯ä½¿ç”¨LSTMæ¥è¯„ä¼°çŸ­çš„è®¡ç®—æœºç¨‹åºã€‚æˆ‘æ¯”è¾ƒå…³æ³¨curriculum learningçš„éƒ¨åˆ†ï¼Œå…¶ä¸­çš„ä¸€äº›è§£é‡Šæˆ–è®¸èƒ½å¤Ÿæœ‰ä¸€äº›å¯å‘ã€‚</p><p>æœ¬æ–‡åœ¨ä½¿ç”¨ä¼ ç»Ÿcurriculum learningè®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œå‘ç°æ•ˆæœå¹¶ä¸å¥½ï¼Œå› æ­¤è½¬è€Œä½¿ç”¨ä¸€ç§æ··åˆè®­ç»ƒæ–¹æ³•ã€‚ä¹Ÿå³éƒ¨åˆ†éšæœºé‡‡æ ·ï¼Œéƒ¨åˆ†é‡‡ç”¨ä¼ ç»Ÿcurriculum learningçš„é€æ¸æå‡éš¾åº¦ã€‚</p><p>ä¸ºä»€ä¹ˆä¼ ç»Ÿçš„ä¸å¤Ÿå¥½ï¼Ÿ<br>ä½œè€…çš„è§£é‡Šæ˜¯ï¼Œå¦‚æœä»ç®€å•çš„å¼€å§‹å­¦ï¼ŒLSTMä¼šå°†æ‰€æœ‰çš„memoryç”¨ä»¥è®°å¿†ç®€å•çš„æ ·æœ¬ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±æ„å»ºå¥½äº†è¿™å¥—patternï¼Œè€Œåœ¨é€æ¸å¢åŠ éš¾åº¦æ—¶ï¼Œè¦æ±‚å¯¹memoryçš„patterné‡ç»„ï¼Œè€Œè¿™ç‚¹ä¸å®¹æ˜“åšåˆ°ã€‚è€Œå¦‚æœé‡‡æ ·éƒ¨åˆ†éšæœºæ ·æœ¬ï¼Œåˆ™èƒ½å¤ŸåŒæ—¶å­¦ä¹ åˆ°éƒ¨åˆ†éš¾çš„exampleï¼Œä»è€Œ<strong>é˜²æ­¢overfitåˆ°æŸä¸ªç®€å•çš„patternä¸Š</strong>ã€‚</p><hr><h2 id="Self-Paced-Learning-for-Latent-Variable-Models"><a href="#Self-Paced-Learning-for-Latent-Variable-Models" class="headerlink" title="[Self-Paced Learning for Latent Variable Models]"></a>[Self-Paced Learning for Latent Variable Models]</h2><p>ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ä¼˜åŒ–ç®—æ³•ã€‚<del>è¯æ˜äº†curriculum learningä¹Ÿèƒ½åœ¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•ä¸­å–å¾—æ•ˆæœã€‚</del> 7.2æ›´æ–°ï¼šä¹‹å‰ç†è§£é”™äº†ï¼Œself-paced learningä¸Curriculum Learningè™½æœ‰å…±é€šä¹‹å¤„ä½†å¹¶ä¸æ˜¯ä¸€ä¸ªä¸œè¥¿ã€‚CLçš„difficulty scoreæ˜¯åœ¨è®­ç»ƒå‰å›ºå®šçš„ï¼Œè€ŒSPLæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ ¹æ®exampleçš„lossæ¥åŠ¨æ€å†³å®šçš„ã€‚</p><script type="math/tex; mode=display">\left(\mathbf{w}_{t+1}, \mathbf{v}_{t+1}\right)=\underset{\mathbf{w} \in \mathbb{R}^{d}, \mathbf{v} \in\{0,1\}^{n}}{\operatorname{argmin}}\left(r(\mathbf{w})+\sum_{i=1}^{n} v_{i} f\left(\mathbf{x}_{i}, \mathbf{y}_{i} ; \mathbf{w}\right)-\frac{1}{K} \sum_{i=1}^{n} v_{i}\right)</script><p>åªæœ‰é‚£äº›èƒ½å¤Ÿå¾ˆå¥½fitçš„sampleä½œæ•°ï¼Œä¹Ÿå³ä½¿ç”¨äºŒå…ƒå˜é‡væ¥æ§åˆ¶ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> NMT </tag>
            
            <tag> Curriculum Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯27</title>
      <link href="/2019/06/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D27/"/>
      <url>/2019/06/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D27/</url>
      
        <content type="html"><![CDATA[<h3 id="å¤œä¸Šå—é™åŸé—»ç¬›"><a href="#å¤œä¸Šå—é™åŸé—»ç¬›" class="headerlink" title="å¤œä¸Šå—é™åŸé—»ç¬›"></a>å¤œä¸Šå—é™åŸé—»ç¬›</h3><p>[å”] æç›Š<br>å›ä¹å³°å‰æ²™ä¼¼é›ªï¼Œå—é™åŸå¤–æœˆå¦‚éœœã€‚<br><strong>ä¸çŸ¥ä½•å¤„å¹èŠ¦ç®¡ï¼Œä¸€å¤œå¾äººå°½æœ›ä¹¡</strong>ã€‚</p><p><a href="http://lib.xcz.im/work/57b91effa633bd00665e4f15" target="_blank" rel="noopener">http://lib.xcz.im/work/57b91effa633bd00665e4f15</a></p><hr><h3 id="é¥®ä¸­å…«ä»™æ­Œ"><a href="#é¥®ä¸­å…«ä»™æ­Œ" class="headerlink" title="é¥®ä¸­å…«ä»™æ­Œ"></a>é¥®ä¸­å…«ä»™æ­Œ</h3><p>[å”] æœç”«<br>â€¦<br>æç™½æ–—é…’è¯—ç™¾ç¯‡ï¼Œé•¿å®‰å¸‚ä¸Šé…’å®¶çœ ï¼Œ<br>å¤©å­å‘¼æ¥ä¸ä¸Šèˆ¹ï¼Œè‡ªç§°è‡£æ˜¯é…’ä¸­ä»™ã€‚<br>â€¦</p><p><a href="http://lib.xcz.im/work/57b8e3a7c4c97100558e7dc6" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8e3a7c4c97100558e7dc6</a></p><p>æ–°å”ä¹¦Â·æç™½ä¼ ã€‹è½½ï¼šæç™½åº”è¯è‡³é•¿å®‰ï¼Œå”ç„å®—åœ¨é‡‘éŠ®æ®¿å¬è§ä»–ï¼Œå¹¶èµé£Ÿï¼Œäº²ä¸ºè°ƒç¾¹ï¼Œè¯ä¸ºä¾›å¥‰ç¿°æ—ã€‚æœ‰ä¸€æ¬¡ï¼Œç„å®—åœ¨æ²‰é¦™äº­å¬ä»–å†™é…ä¹çš„è¯—ï¼Œè€Œä»–å´åœ¨é•¿å®‰é…’è‚†å–å¾—å¤§é†‰ã€‚èŒƒä¼ æ­£ã€Šæç™½æ–°å¢“ç¢‘ã€‹è½½ï¼šç„å®—æ³›èˆŸç™½è²åœ°ï¼Œå¬æç™½æ¥å†™æ–‡ç« ï¼Œè€Œè¿™æ—¶æç™½å·²åœ¨ç¿°æ—é™¢å–é†‰äº†ï¼Œç„å®—å°±å‘½é«˜åŠ›å£«æ‰¶ä»–ä¸Šèˆ¹æ¥è§ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†21</title>
      <link href="/2019/06/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8621/"/>
      <url>/2019/06/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8621/</url>
      
        <content type="html"><![CDATA[<h3 id="Dying-Relu"><a href="#Dying-Relu" class="headerlink" title="[Dying Relu]"></a>[Dying Relu]</h3><p>Dying Reluç°è±¡æŒ‡çš„æ˜¯ï¼Œåœ¨ä½¿ç”¨Reluä½œä¸ºæ¿€æ´»å‡½æ•°æ—¶ï¼Œå› ä¸ºå­¦ä¹ ç‡è¾ƒå¤§æˆ–æŸäº›åŸå› ï¼Œå¯¼è‡´æŸä¸€å±‚çš„biaså­¦åˆ°è¾ƒå¤§çš„è´Ÿå€¼ï¼Œä½¿å¾—è¯¥å±‚åœ¨è¿‡å®ŒReluæ¿€æ´»å‡½æ•°åçš„è¾“å‡ºå§‹ç»ˆæ˜¯0ã€‚</p><p><img src="/images/15594400435056.jpg" width="30%" height="50%"></p><p>å½“è¿›å…¥åˆ°è¿™ä¸€çŠ¶æ€æ—¶ï¼ŒåŸºæœ¬ä¸Šæ²¡åŠæ³•å†å›åˆ°æ­£å¸¸çŠ¶æ€ã€‚å› ä¸ºåœ¨å›ä¼ æ—¶ï¼Œå€¼ä¸º0å¯¼è‡´æ¢¯åº¦ä¹Ÿä¸º0ã€‚</p><p><a href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" target="_blank" rel="noopener">https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Dying Relu </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯26</title>
      <link href="/2019/05/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D26/"/>
      <url>/2019/05/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D26/</url>
      
        <content type="html"><![CDATA[<h3 id="å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—"><a href="#å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—" class="headerlink" title="å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—"></a>å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—</h3><p>å‡ä½¿æˆ‘ä»¬ä¸å»æ‰“ä»—ï¼Œ<br>æ•Œäººç”¨åˆºåˆ€<br>æ€æ­»äº†æˆ‘ä»¬ï¼Œ<br>è¿˜è¦ç”¨æ‰‹æŒ‡ç€æˆ‘ä»¬éª¨å¤´è¯´ï¼š<br>â€œçœ‹ï¼Œ<br>è¿™æ˜¯å¥´éš¶ï¼â€</p><hr><h3 id="èœ€å…ˆä¸»åº™"><a href="#èœ€å…ˆä¸»åº™" class="headerlink" title="èœ€å…ˆä¸»åº™"></a>èœ€å…ˆä¸»åº™</h3><p>[å”] åˆ˜ç¦¹é”¡<br><strong>å¤©åœ°è‹±é›„æ°”ï¼Œåƒç§‹å°šå‡›ç„¶ã€‚</strong><br>åŠ¿åˆ†ä¸‰è¶³é¼ï¼Œä¸šå¤äº”é“¢é’±ã€‚<br>å¾—ç›¸èƒ½å¼€å›½ï¼Œç”Ÿå„¿ä¸è±¡è´¤ã€‚<br>å‡„å‡‰èœ€æ•…å¦“ï¼Œæ¥èˆé­å®«å‰ã€‚</p><p><a href="http://lib.xcz.im/work/57b90d29d342d3005ac78cb5" target="_blank" rel="noopener">http://lib.xcz.im/work/57b90d29d342d3005ac78cb5</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>AIS2019è®ºæ–‡æŠ¥å‘Šä¼šä¹‹æ­å·è¡Œæµæ°´è´¦</title>
      <link href="/2019/05/28/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/AIS2019%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E6%9D%AD%E5%B7%9E%E8%A1%8C/"/>
      <url>/2019/05/28/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/AIS2019%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E6%9D%AD%E5%B7%9E%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<p>è¶ç€AIS2019è®ºæ–‡æŠ¥å‘Šä¼šï¼Œç»ˆäºæœ‰æœºä¼šå…¬è´¹æ—…æ¸¸å•¦ğŸ˜„</p><p>æ­å·éƒŠåŒºè¿˜æ˜¯è›®ç¹åçš„å“‡ã€‚å¦¹æƒ³åˆ°ã€‚</p><p><img src="/images/15590541433996.jpg" width="70%" height="50%"></p><p>ä¸ºäº†ç­‰lzyä¸‹è½¦ï¼Œåˆ°åç‚¹é’Ÿæ‰åƒæ™šé¥­ï¼Œéš¾é¡¶ğŸ™„ï¼Œåƒåˆ°12ç‚¹åŠã€‚</p><p><img src="/images/lzy.jpg" width="70%" height="50%"></p><p>æ‰¾äº†åŠå°æ—¶æ‰¾ä¸åˆ°é…’åº—ï¼Œè¿˜æ˜¯æ±‚åŠ©äº†åŒè¡Œçš„å…¶ä»–å°ä¼™ä¼´æ‰æ‰¾åˆ°ğŸ¤¦â€â™‚ï¸</p><p><img src="/images/room.jpg" width="70%" height="50%"></p><p><strong>Day1</strong>ï¼š</p><p>ç¡åˆ°11ç‚¹æ‰åŒ†åŒ†èµ¶åˆ°ä¼šåœº</p><p><img src="/images/15590935394726.jpg" width="70%" height="50%"></p><p>å¬äº†å‡ åœºå°±æ˜æ˜æ¬²ç¡äº†ï¼Œè€Œä¸”ä¼šè®®å®¤å†…ç½‘ç»œä¹Ÿå¤ªå·®äº†8ï¸âƒ£</p><p><img src="/images/15590935878376.jpg" width="70%" height="50%"></p><p>å†³å®šä¸‹åˆå·è·‘</p><p>ä¸‹åˆé¸½äº†ä»–ä»¬ï¼Œå›åˆ°å®¿èˆä¸€è§‰åˆç¡åˆ°5ç‚¹ã€‚ç™¾æ— èŠèµ–ï¼Œè¿˜æ˜¯åˆ°è¥¿æ¹–èµ°èµ°8ï¸âƒ£ğŸ˜†</p><p><img src="/images/15590936999475.jpg" width="70%" height="50%"></p><p><img src="/images/15590937248588.jpg" width="70%" height="50%"></p><p><img src="/images/15590938011843.jpg" width="70%" height="50%"></p><p>å¤©ä¸‹ç€é›¨ï¼Œåˆæ˜¯å¤§æ™šä¸Šï¼Œå…¶å®å•¥ä¹Ÿçœ‹ä¸åˆ°ã€‚èµ°äº†ä¸¤ä¸ªå°æ—¶ï¼Œä»æ–­æ¡¥èµ°åˆ°é›·å³°å¡”ğŸ¤¦â€â™‚ï¸ã€‚</p><p>å›åˆ°å®¿èˆï¼Œæœ¬æ¥è¦ç¡äº†ï¼Œä½†åˆé¢‡æœ‰äº›é¥¿ã€‚æŠŠåŒè¡Œçš„å°ä¼™ä¼´éƒ½æ‹‰ä¸Šï¼Œå¼€å§‹æ‰¾å®µå¤œğŸ˜‹</p><p><img src="/images/751559093999_.pic_hd.jpg" width="70%" height="50%"></p><p>ç­‰ljzä¸‹æ¥ç­‰åˆ°ä¸‰ä¸ªäººéƒ½å¼€å§‹æ‰“æ¸¸æˆäº†ğŸ™„</p><p><img src="/images/771559094127_.pic_hd.jpg" width="40%" height="50%"></p><p>å¼€å†²ï¼<br><img src="/images/781559094310_.pic_hd.jpg" width="70%" height="50%"></p><p>å…­ä¸ªäººç‚¹äº†4ç“¶é…’æœ€åé€€äº†ä¸¤ç“¶ã€‚å¤§å®¶å¯çœŸæ˜¯å¤ªèœäº†8ï¸âƒ£ğŸ¤¦â€â™‚ï¸</p><hr><p>Day2:</p><p>åˆæ˜¯ç¡åˆ°11ç‚¹ï¼Œåƒäº†ç‚¹ä¸œè¥¿ä¼‘æ¯ä¸€ä¸‹å°±å»åƒåˆé¥­äº†ã€‚</p><p>è‚¯å¾·åŸºçš„é¥­çœŸæ˜¯éš¾åƒåˆ°çˆ†ï¼Œå·®ç‚¹åäº†ğŸ¤¢ã€‚</p><p><img src="/images/15590944817604.jpg" width="40%" height="50%"></p><p>åœ¨åº§ä½ä¸Šç™¾æ— èŠèµ–çœ‹äº†ä¸¤ä¸ªå°æ—¶è§†é¢‘ï¼Œå‡ºå‘åˆ°ä¼šåœºï¼Œç­‰å…¶ä»–äººä¸€èµ·åˆ°é™†æ€»ğŸ åƒé¥­ğŸ˜¬ï¼ˆæ­¤è¡Œæœ€å¤§çš„motivation</p><p>é™†æ€»ğŸ çš„é¥­èœä¹Ÿå¤ªä¸°ç››äº†8ï¸âƒ£ï¼Œåƒåˆ°æ’‘ã€‚è¿˜è®¤è¯†äº†å‡ ä¸ªæ–°çš„å°ä¼™ä¼´(wsä¸xlw)ã€‚äº†è§£åˆ°è¶…å¤šä»¥å‰è½¯ä»¶å­¦é™¢çš„å…«å¦ã€‚æ€»çš„æ¥è¯´éå¸¸å¼€å¿ƒ</p><p><img src="/images/791559094738_.pic_hd.jpg" width="60%" height="50%"></p><p><img src="/images/801559094815_.pic_hd.jpg" width="60%" height="50%"></p><p>æºœäº†æºœäº†ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æ´»åŠ¨ </tag>
            
            <tag> AIS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡19</title>
      <link href="/2019/05/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8719/"/>
      <url>/2019/05/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8719/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>Generating Long Sequences with Sparse Transformers</li><li>CBAM: Convolutional Block Attention Module</li><li>Pyramid Scene Parsing Network</li></ol><h2 id="Generating-Long-Sequences-with-Sparse-Transformers"><a href="#Generating-Long-Sequences-with-Sparse-Transformers" class="headerlink" title="[Generating Long Sequences with Sparse Transformers]"></a>[Generating Long Sequences with Sparse Transformers]</h2><p>Motivationï¼štransformerå¯¹é•¿åºåˆ—ä¸å‹å¥½ï¼Œå¤æ‚åº¦è¾ƒé«˜ï¼›æœ¬æ–‡æå‡ºsparse transformerå¯¹<strong>ç”Ÿæˆ</strong>é•¿åºåˆ—çš„è®¡ç®—è¿›è¡Œä¼˜åŒ–ï¼Œå¤æ‚åº¦èƒ½å¤Ÿé™åˆ°$O(n \sqrt{n})$ã€‚</p><p>å®é™…ä¸Šå°±æ˜¯å°†å…¨è¿æ¥çš„attentionåˆ†åŒ–æˆå‡ ä¸ªsparseçš„attentionã€‚</p><p><img src="/images/15590983353143.jpg" width="60%" height="50%"></p><p>å¦‚ä¸Šå›¾ï¼Œå®é™…ä¸Šå°±æ˜¯è®©éƒ¨åˆ†head attendå‰é¢å‡ ä¸ªlocalï¼›éƒ¨åˆ†head attendåˆ°æ›´æ—©çš„ä¿¡æ¯ï¼Œå¹¶ä¸”æ˜¯è·³ç€çœ‹çš„ï¼ˆä¸¤ç§patternï¼‰ã€‚æˆ–è€…è¿˜å¯ä»¥è®©æ‰€æœ‰headéƒ½attendåˆ°è¿™äº›sparseçš„ç‚¹ã€‚</p><p>å½“ç„¶ä¹Ÿå¯ä»¥æ‰©å±•åˆ°å¤šç»´ç©ºé—´ã€‚å°†headåˆ†ä¸ºnç»„ï¼Œæ¯ä¸ªç»„è·³ç€çœ‹çš„ä¸ä¸€æ ·ã€‚</p><p>å…¶ä»–ä¼¼ä¹éƒ½æ˜¯ç»†èŠ‚ï¼Œæ²¡å•¥å¸®åŠ©ã€‚</p><p>å¹¶ä¸”è¿˜æ”¹äº†ä¸€ä¸‹transformerçš„è®¡ç®—è¿‡ç¨‹ï¼Œä»¥åŠåšäº†GPU kernelåº•å±‚çš„åŠ é€Ÿã€‚å…¶ä»–ä¼¼ä¹æ²¡æœ‰ä»€ä¹ˆinsightçš„åœ°æ–¹ã€‚</p><p>æ€è€ƒï¼š<br>è¿™å®é™…ä¸Šå°±æ˜¯å‡è®¾äº†ä¸€ä¸ªè¾ƒå¼ºçš„å…ˆéªŒäº†ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆçš„æ—¶å€™ç¡®å®å¯èƒ½å­˜åœ¨è¿™ç§patternï¼Œå› ä¸ºç”Ÿæˆè¦è¾¾åˆ°å¥½çš„æ•ˆæœï¼Œæ¯ä¸ªç‚¹éƒ½å¿…é¡»æ€»ç»“å‰é¢æ‰€æœ‰ç‚¹çš„ä¿¡æ¯ã€‚ä½†å¦‚æœä¸æ˜¯ç”Ÿæˆï¼Œæ˜¯å¦ä¹Ÿæœ‰è¿™ç§patternï¼Ÿ<br>è®ºæ–‡å¼ºè¡Œå°†æ–‡æœ¬ä¹Ÿåˆ‡æˆäºŒç»´ï¼Œè€Œä¸”ç”¨äº†30å±‚ï¼›æ„Ÿè§‰ä¸æ˜¯é‚£ä¹ˆæœ‰é“ç†ã€‚å› ä¸ºè¿™ç§sparseæ˜¯ä»å›¾åƒä¸­è§‚å¯Ÿå¾—åˆ°çš„ï¼Œæ˜¯å¦ä¹Ÿèƒ½åº”ç”¨äºæ–‡æœ¬ï¼Ÿä¼šä¸ä¼šæœ‰å¯èƒ½æ˜¯30å±‚æ‰è¾¾åˆ°è¿™ä¹ˆå¥½çš„æ•ˆæœï¼Ÿ</p><hr><h2 id="CBAM-Convolutional-Block-Attention-Module"><a href="#CBAM-Convolutional-Block-Attention-Module" class="headerlink" title="[CBAM: Convolutional Block Attention Module]"></a>[CBAM: Convolutional Block Attention Module]</h2><p>æå‡ºåœ¨channelç»´åº¦ä¸ç©ºé—´ç»´åº¦çš„åŒé‡attentionã€‚å’ŒSE-Netç›¸æ¯”åŠ äº†ä¸€å±‚ç©ºé—´ç»´åº¦ä¸Šçš„äº¤äº’ï¼Œåšæ³•å‡ ä¹éƒ½å·®ä¸å¤šã€‚</p><p><img src="/images/15590990182833.jpg" width="60%" height="50%"></p><p>å…·ä½“åšæ³•ï¼š<br><img src="/images/15590991719663.jpg" width="60%" height="50%"></p><p>â‘ åœ¨channelç»´åº¦ä¸Šåšattention</p><script type="math/tex; mode=display">\begin{aligned} \mathbf{M}_{\mathbf{c}}(\mathbf{F}) &=\sigma(M L P(A v g P o o l(\mathbf{F}))+M L P(M a x P o o l(\mathbf{F}))) \\ &=\sigma\left(\mathbf{W}_{\mathbf{1}}\left(\mathbf{W}_{\mathbf{0}}\left(\mathbf{F}_{\mathbf{a v g}}^{\mathbf{c}}\right)\right)+\mathbf{W}_{\mathbf{1}}\left(\mathbf{W}_{\mathbf{0}}\left(\mathbf{F}_{\mathbf{m a x}}^{\mathbf{c}}\right)\right)\right) \end{aligned}</script><p>å¯¹è¾“å…¥æŒ‰ç©ºé—´ç»´åº¦æ‹æ‰è·å¾—Cç»´çš„poolingã€‚å®é™…ä¸Šå°±æ˜¯ç”¨average poolingå’Œmax pooling è¿‡çº¿æ€§å±‚+sigmoidã€‚å’ŒSE-Netç›¸æ¯”åªæ˜¯å¤šåˆ©ç”¨äº†max-poolingã€‚</p><p>â‘¡åœ¨ç©ºé—´ç»´åº¦ä¸Šåšattention</p><script type="math/tex; mode=display">\begin{aligned} \mathbf{M}_{\mathbf{s}}(\mathbf{F}) &=\sigma\left(f^{7 \times 7}([A v g P o o l(\mathbf{F}) ; M a x P \operatorname{ool}(\mathbf{F})])\right) \\ &=\sigma\left(f^{7 \times 7}\left(\left[\mathbf{F}_{\mathbf{a v g}}^{\mathbf{s}} ; \mathbf{F}_{\mathbf{m a x}}^{\mathbf{s}}\right]\right)\right) \end{aligned}</script><p>åŒæ ·æ˜¯æŒ‰channelç»´åº¦æ‹æ‰åšmax/mean poolingã€‚è·å¾—çš„æ˜¯H<em>W</em>1çš„ç»´åº¦ï¼Œç„¶åæ‹¼èµ·æ¥è¿‡CNN+sigmoidã€‚</p><p>æ€è€ƒï¼šä¼¼ä¹åˆ›æ–°æ€§ä¸è¶³ï¼Œå¹¶æ²¡æœ‰æä¾›ä¸€äº›æœ‰ç”¨çš„insightã€‚</p><hr><h2 id="Pyramid-Scene-Parsing-Network"><a href="#Pyramid-Scene-Parsing-Network" class="headerlink" title="[Pyramid Scene Parsing Network]"></a>[Pyramid Scene Parsing Network]</h2><p><img src="/images/15590993469941.jpg" width="70%" height="50%"></p><p>åˆ©ç”¨pyramid poolingï¼ˆä¹Ÿå³ä¸åŒkernel sizeçš„poolingçš„ç»“åˆï¼‰åšåˆ‡å‰²çš„ä»»åŠ¡ã€‚</p><p>è¿™æ˜¯pyramid poolingï¼Œä¹Ÿå³åˆ†å±‚æ¬¡çš„poolingï¼š</p><p><img src="/images/15590994146803.jpg" width="60%" height="50%"></p><p>å…¶ä»–æ²¡æ„Ÿè§‰ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> CBAM </tag>
            
            <tag> pyramid pooling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>åªæœ‰åœ¨ä½ å·¥ä½œå †ç§¯å¦‚å±±æ—¶ï¼Œä½ æ‰å¯èƒ½äº«å—é—²æš‡</title>
      <link href="/2019/05/27/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E5%8F%AA%E6%9C%89%E5%9C%A8%E4%BD%A0%E5%B7%A5%E4%BD%9C%E5%A0%86%E7%A7%AF%E5%A6%82%E5%B1%B1%E6%97%B6%EF%BC%8C%E4%BD%A0%E6%89%8D%E5%8F%AF%E8%83%BD%E4%BA%AB%E5%8F%97%E9%97%B2%E6%9A%87/"/>
      <url>/2019/05/27/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E5%8F%AA%E6%9C%89%E5%9C%A8%E4%BD%A0%E5%B7%A5%E4%BD%9C%E5%A0%86%E7%A7%AF%E5%A6%82%E5%B1%B1%E6%97%B6%EF%BC%8C%E4%BD%A0%E6%89%8D%E5%8F%AF%E8%83%BD%E4%BA%AB%E5%8F%97%E9%97%B2%E6%9A%87/</url>
      
        <content type="html"><![CDATA[<p>â€œåªæœ‰åœ¨ä½ å·¥ä½œå †ç§¯å¦‚å±±æ—¶ï¼Œä½ æ‰å¯èƒ½äº«å—é—²æš‡ã€‚å½“ä½ æ— äº‹å¯åšæ—¶ï¼Œç©ºé—²å°±å˜å¾—ä¸€ç‚¹ä¹Ÿä¸æœ‰è¶£ï¼Œå› ä¸ºç©ºé—²å°±æ˜¯ä½ çš„å·¥ä½œï¼Œè€Œä¸”æ˜¯æœ€è€—äººçš„å·¥ä½œã€‚é—²æ‡’å’Œå»ä¸€æ ·ï¼Œå½“å®ƒè¢«ç›—èµ°äº†ä¹‹åï¼Œå®ƒçš„å‘³é“æ‰æ˜¯ç”œçš„ã€‚â€â€”â€”â€” æ°ç½—å§†Â·KÂ·æ°ç½—å§†</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— åè‹±é›„çºªå¿µç¢‘é“­</title>
      <link href="/2019/05/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E5%90%8D%E8%8B%B1%E9%9B%84%E7%BA%AA%E5%BF%B5%E7%A2%91%E9%93%AD/"/>
      <url>/2019/05/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E5%90%8D%E8%8B%B1%E9%9B%84%E7%BA%AA%E5%BF%B5%E7%A2%91%E9%93%AD/</url>
      
        <content type="html"><![CDATA[<h3 id="æ— åè‹±é›„çºªå¿µç¢‘é“­"><a href="#æ— åè‹±é›„çºªå¿µç¢‘é“­" class="headerlink" title="æ— åè‹±é›„çºªå¿µç¢‘é“­"></a>æ— åè‹±é›„çºªå¿µç¢‘é“­</h3><p>å¤«å¤©ä¸‹æœ‰å¤§å‹‡è€…ï¼Œæ™ºä¸èƒ½æµ‹ï¼Œåˆšä¸èƒ½åˆ¶ï¼ŒçŒç„¶ä¸´ä¹‹è€Œä¸æƒŠï¼Œæ— æ•…åŠ ä¹‹è€Œä¸æ€’ï¼Œæ­¤å…¶æ™ºç”šè¿œï¼Œæ‰€æ€€ç”šå¤§ä¹Ÿã€‚æ‰€æ€€è€…ä½•ï¼Ÿå¤©ä¸‹æœ‰é¥¥è€…ï¼Œå¦‚å·±ä¹‹é¥¥ï¼Œå¤©ä¸‹æœ‰æººè€…ï¼Œå¦‚å·±ä¹‹æººè€³ã€‚æ°‘æ—å±æ€¥ï¼Œåˆ«äº²ç¦»å­è€Œèµ´æ°´ç«ï¼Œæ˜“é¢äº‹æ•Œè€Œæ±‚å¤§åŒã€‚é£è§æ°´å¯’ï¼Œæ—Œéœœå±¥è¡€ï¼Œæˆ–æˆæˆ–è´¥ï¼Œæˆ–å›šæˆ–æ®(mÃ²)ï¼Œäººä¸çŸ¥ä¹‹ï¼Œä¹ƒè‡³æ®’åæ— åã€‚  é“­æ›°ï¼šå‘œå‘¼ï¼å¤§éŸ³å¸Œå£°ï¼Œå¤§è±¡æ— å½¢ã€‚æ¥å…®ç²¾é­„ï¼Œå®‰å…®è‹±çµã€‚é•¿æ²³ä¸ºå’½ï¼Œé’å±±ä¸ºè¯ï¼›å²‚æ›°æ— å£°ï¼Ÿæ²³å±±å³åï¼  äººæœ‰æ‰€å¿˜ï¼Œå²æœ‰æ‰€è½»ã€‚ä¸€ç»Ÿå¯æœŸï¼Œæ°‘æ—å°†å…´ï¼Œè‚ƒä¹‹å˜‰çŸ³ï¼Œæ²æ‰‹å‹’é“­ã€‚å™«æˆ‘å­å­™ï¼Œä»£ä»£æ°¸æ—Œã€‚ å…¬å…ƒäºŒé›¶ä¸€ä¸‰å¹´åæœˆç«‹ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2019/05/14/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%F0%9F%87%A8%F0%9F%87%B3/"/>
      <url>/2019/05/14/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%F0%9F%87%A8%F0%9F%87%B3/</url>
      
        <content type="html"><![CDATA[<p>äº”åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå¤åŸƒåŠäººä¸€æ ·é¢å¯¹æ´ªæ°´ï¼›<br>å››åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå·´æ¯”ä¼¦äººä¸€æ ·ç©é’é“œå™¨ï¼›<br>ä¸‰åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œå¤å¸Œè…Šäººä¸€æ ·æ€è€ƒå“²å­¦ï¼›<br>ä¸¤åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œç½—é©¬äººä¸€æ ·å››å¤„å¾ä¼ï¼›<br>ä¸€åƒå¹´å‰ï¼Œ<br>æˆ‘ä»¬å’Œé˜¿æ‹‰ä¼¯äººä¸€æ ·æ— æ¯”å¯Œè¶³ï¼›<br>äº”åƒå¹´äº†ï¼Œ<br>æˆ‘ä»¬ä¸€ç›´åœ¨ä¸–ç•Œçš„ç‰Œæ¡Œä¸Šæ‰“ç€éº»å°†ï¼Œ<br>è€Œå¦å¤–å‡ å®¶å·²ç»æ¢è¿‡å¥½å¤šè½®ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•17</title>
      <link href="/2019/05/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9517/"/>
      <url>/2019/05/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9517/</url>
      
        <content type="html"><![CDATA[<h3 id="Pytorch-restartå†™æ³•"><a href="#Pytorch-restartå†™æ³•" class="headerlink" title="[Pytorch restartå†™æ³•]"></a>[Pytorch restartå†™æ³•]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.restart:</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(args.restart_dir, <span class="string">'model.pt'</span>), <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model = torch.load(f)</span><br></pre></td></tr></table></figure><hr><h3 id="Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡"><a href="#Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡" class="headerlink" title="[Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡]"></a>[Pytorchè·å¾—æ¨¡å‹å‚æ•°é‡]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">args.n_all_param = sum([p.nelement() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()])</span><br></pre></td></tr></table></figure><hr><h3 id="Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥"><a href="#Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥" class="headerlink" title="[Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥]"></a>[Pytorchå°†æ•°æ®ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–¹ä¾¿å¿«é€Ÿè¯»å…¥]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transformer-xlæ ·ä¾‹</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_lm_corpus</span><span class="params">(datadir, dataset)</span>:</span></span><br><span class="line">    fn = os.path.join(datadir, <span class="string">'cache.pt'</span>)</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(fn):</span><br><span class="line">        print(<span class="string">'Loading cached dataset...'</span>)</span><br><span class="line">        corpus = torch.load(fn)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'Producing dataset &#123;&#125;...'</span>.format(dataset))</span><br><span class="line">        kwargs = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> dataset <span class="keyword">in</span> [<span class="string">'wt103'</span>, <span class="string">'wt2'</span>]:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = [<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">elif</span> dataset == <span class="string">'ptb'</span>:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = [<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">elif</span> dataset == <span class="string">'lm1b'</span>:</span><br><span class="line">            kwargs[<span class="string">'special'</span>] = []</span><br><span class="line">            kwargs[<span class="string">'lower_case'</span>] = <span class="keyword">False</span></span><br><span class="line">            kwargs[<span class="string">'vocab_file'</span>] = os.path.join(datadir, <span class="string">'1b_word_vocab.txt'</span>)</span><br><span class="line">        <span class="keyword">elif</span> dataset <span class="keyword">in</span> [<span class="string">'enwik8'</span>, <span class="string">'text8'</span>]:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        corpus = Corpus(datadir, dataset, **kwargs)</span><br><span class="line">        torch.save(corpus, fn)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> corpus</span><br></pre></td></tr></table></figure><hr><h3 id="Pytorchè‡ªå¸¦APIå®ç°inverse-sqrtçš„lr-schedule"><a href="#Pytorchè‡ªå¸¦APIå®ç°inverse-sqrtçš„lr-schedule" class="headerlink" title="[Pytorchè‡ªå¸¦APIå®ç°inverse sqrtçš„lr schedule]"></a>[Pytorchè‡ªå¸¦APIå®ç°inverse sqrtçš„lr schedule]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from transformer-xl</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># originally used for Transformer (in Attention is all you need)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_lambda</span><span class="params">(step)</span>:</span></span><br><span class="line">    <span class="comment"># return a multiplier instead of a learning rate</span></span><br><span class="line">    <span class="keyword">if</span> step == <span class="number">0</span> <span class="keyword">and</span> args.warmup_step == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (step ** <span class="number">0.5</span>) <span class="keyword">if</span> step &gt; args.warmup_step \</span><br><span class="line">            <span class="keyword">else</span> step / (args.warmup_step ** <span class="number">1.5</span>)</span><br><span class="line">            </span><br><span class="line">scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯25</title>
      <link href="/2019/05/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D25/"/>
      <url>/2019/05/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D25/</url>
      
        <content type="html"><![CDATA[<h3 id="è¥¿æ±Ÿæœˆ"><a href="#è¥¿æ±Ÿæœˆ" class="headerlink" title="è¥¿æ±Ÿæœˆ"></a>è¥¿æ±Ÿæœˆ</h3><p><strong>ä¸–äº‹ä¸€åœºå¤§æ¢¦ï¼Œäººç”Ÿå‡ åº¦æ–°å‡‰</strong>ï¼Ÿå¤œæ¥é£å¶å·²é¸£å»Šï¼Œçœ‹å–çœ‰å¤´é¬“ä¸Šã€‚<br>é…’è´±å¸¸æ„å®¢å°‘ï¼Œæœˆæ˜å¤šè¢«äº‘å¦¨ã€‚ä¸­ç§‹è°ä¸å…±å­¤å…‰ï¼ŒæŠŠç›å‡„ç„¶åŒ—æœ›ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡18</title>
      <link href="/2019/05/12/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8718/"/>
      <url>/2019/05/12/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8718/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</li><li>Ordered Neurons- Integrating Tree Structures into Recurrent Neural Networks</li><li>Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification</li><li>Unified Language Model Pre-training for Natural Language Understanding and Generation</li><li>Language Models are Unsupervised Multitask Learners</li><li>MASS: Masked Sequence to Sequence Pre-training for Language Generation</li><li>Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks</li><li>PSANet: Point-wise Spatial Attention Network for Scene Parsing</li><li>CCNet: Criss-Cross Attention for Semantic Segmentation</li></ol><h2 id="GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond"><a href="#GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond" class="headerlink" title="[GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond]"></a>[GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond]</h2><p>æå‡ºä¸€ç§æ–°çš„å¯¹é•¿è·ç¦»ä¾èµ–å»ºæ¨¡çš„æ–¹æ³•ï¼Œå¹¶ç»“åˆäº†ä¹‹å‰å…¶ä»–ç ”ç©¶è€…çš„å·¥ä½œï¼ŒæŠ½è±¡å¾—åˆ°å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ï¼ˆglobal context modelingï¼‰çš„æ¡†æ¶ã€‚</p><p>ç›®å‰é•¿è·ç¦»ä¾èµ–å»ºæ¨¡æœ‰ä¸¤ç§ï¼šä¸€ç§æ˜¯å¼•å…¥self-attentionæœºåˆ¶ï¼Œè·å¾—query-dependentçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¦‚NL-Netï¼›å¦ä¸€ç§åˆ™æ˜¯query-independentçš„å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¦‚SE-Netã€‚</p><h3 id="Simplified-NL-Net"><a href="#Simplified-NL-Net" class="headerlink" title="Simplified NL-Net"></a>Simplified NL-Net</h3><p>Motivationï¼šé€šè¿‡å¯¹Non-local networkçš„åˆ†æï¼Œå‘ç°ç½‘ç»œå®é™…ä¸Šå­¦åˆ°çš„æ˜¯queryæ— å…³çš„ä¸Šä¸‹æ–‡ï¼Œå› æ­¤å¯ä»¥ç›´æ¥å¯¹NL-Netè¿›è¡Œç®€åŒ–ã€‚</p><p>é¦–å…ˆæ˜¯å¯¹NL-Netçš„è§‚å¯Ÿï¼Œé€šè¿‡å¯è§†åŒ–ï¼Œä»¥åŠç»Ÿè®¡å¾—åˆ°çš„æ•°æ®ï¼Œå¯ä»¥å‘ç°ï¼ŒNL-Netå¯¹äºæ¯ä¸ªqueryæ¥è¯´ï¼Œå…¶å­¦åˆ°çš„å…¨å±€ä¿¡æ¯å·®å¼‚å¾ˆå°ã€‚</p><p><img src="/images/15576253999087.jpg" width="80%" height="50%"></p><p><img src="/images/15576254102911.jpg" width="60%" height="50%"></p><p>åŒæ—¶ï¼ŒNL-Netç”±äºè¿™ç§query-dependentçš„é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ï¼Œæ‹¥æœ‰è¾ƒé«˜çš„å¤æ‚åº¦ï¼ˆå¹³æ–¹çº§åˆ«ï¼‰ã€‚å› æ­¤é¦–å…ˆæˆ‘ä»¬å¯ä»¥å¯¹NL-Netè¿›è¡Œç®€åŒ–ã€‚</p><p><img src="/images/15576254433886.jpg" width="60%" height="50%"></p><p>åŸæ¥çš„NL-Netæ˜¯ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{z} \sum_{j=1}^{N_{p}} \frac{f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)}{\mathcal{C}(\mathbf{x})}\left(W_{v} \cdot \mathbf{x}_{j}\right)</script><p>æ¯ä¸¤ä¸ªfeatureä¹‹é—´è®¡ç®—ä¸€ä¸ªattentionåˆ†æ•°ã€‚</p><p>å°†query-dependentå»æ‰åï¼Œåˆ™æœ‰ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+\sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)}\left(W_{v} \cdot \mathbf{x}_{j}\right)</script><p>è¿˜å¯ä»¥å°†$W_{v}$ç§»åˆ°å¤–é¢ï¼Œæ›´è¿›ä¸€æ­¥åœ°ç®€åŒ–ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{v} \sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)} \mathbf{x}_{j}</script><h3 id="Global-Context-Modeling-Framework"><a href="#Global-Context-Modeling-Framework" class="headerlink" title="Global Context Modeling Framework"></a>Global Context Modeling Framework</h3><p>é€šè¿‡å¯¹æ¯”è¿‘æœŸç›¸å…³çš„å·¥ä½œï¼Œä½œè€…å°†å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡çš„æ–¹æ³•æŠ½è±¡å‡ºæ¥ï¼Œåˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š<br>a)global attention pooling å°†å…¨å±€çš„ä¿¡æ¯æ”¶é›†èµ·æ¥ï¼Œä¼´éšç€ä¸€ä¸ªå…¨è¿æ¥å’Œsoftmax<br>b)feature transform via a 1x1 convolution Wv  å°†æ‰€è·å¾—çš„featureè¿›è¡Œçº¿æ€§è½¬æ¢ã€‚<br>c)feature aggregation å°†global featureä¸æ¯ä¸ªpositionèåˆã€‚</p><p>å½¢å¼åŒ–åˆ™æœ‰ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=F\left(\mathbf{x}_{i}, \delta\left(\sum_{j=1}^{N_{p}} \alpha_{j} \mathbf{x}_{j}\right)\right)</script><p>å¦‚æœä»è¿™ä¸ªè§’åº¦å»ç†è§£ï¼Œé‚£ä¹ˆSE-Netä¹Ÿæ˜¯å±äºè¯¥æ¡†æ¶çš„ä¸€ç§å®ä¾‹ã€‚</p><p><img src="/images/15576257652930.jpg" width="87%" height="50%"></p><p>ä½œè€…åœ¨è¯¥æ¡†æ¶çš„åŸºç¡€ä¸Šæå‡ºäº†æ–°çš„å®ä¾‹ï¼Œä¹Ÿå³GC-Netï¼ŒåŒæ—¶æœ‰NL-Netçš„é«˜æ•ˆå»ºæ¨¡çš„ä¼˜ç‚¹å’ŒSE-Netçš„è®¡ç®—æ•ˆç‡é«˜çš„ä¼˜ç‚¹ã€‚</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\mathbf{x}_{i}+W_{v 2} \operatorname{ReLU}\left(\operatorname{LN}\left(W_{v 1} \sum_{j=1}^{N_{p}} \frac{e^{W_{k} \mathbf{x}_{j}}}{\sum_{m=1}^{N_{p}} e^{W_{k} \mathbf{x}_{m}}} \mathbf{x}_{j}\right)\right)</script><p>ç¬¬ä¸€ï¼ŒåŸºæœ¬é‡‡ç”¨NL-Netçš„å½¢å¼ï¼Œç®€åŒ–æˆquery-independentçš„å½¢å¼ï¼Œå¹¶ä¸”ä½¿ç”¨çš„æ˜¯åŠ çš„å½¢å¼è€Œä¸æ˜¯SE-Netçš„rescaleçš„å½¢å¼ï¼Œå°†global featureä¸æ¯ä¸ªä½ç½®èåˆã€‚<br>ç¬¬äºŒï¼Œé‡‡ç”¨SE-Netçš„bottleneckçš„å½¢å¼å»å‡å°‘å‚æ•°å’Œè®¡ç®—é‡ï¼Œå¹¶ä¸”åœ¨æ­¤åŸºç¡€ä¸Šå¤šäº†ä¸€æ­¥layer normä½¿å¾—æ¨¡å‹æ›´æ˜“è®­ç»ƒï¼Œå®è·µè¯æ˜ï¼Œlayer normèƒ½å¤Ÿæå‡è¡¨ç°ã€‚</p><h3 id="å¯¹æ¯”"><a href="#å¯¹æ¯”" class="headerlink" title="å¯¹æ¯”"></a>å¯¹æ¯”</h3><p>å¯¹æ¯”NL-Netï¼šä¸åŒä¹‹å¤„åœ¨äºglobal attention poolingï¼Œç”¨çš„æ˜¯query-independent<br>å¯¹æ¯”SE-Netï¼šä¸åŒä¹‹å¤„åœ¨äºfusion moduleï¼ˆæ¡†æ¶çš„ç¬¬ä¸‰æ­¥ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯additionè€Œä¸æ˜¯rescaleï¼›ä»¥åŠåœ¨bottleneckä¸Šåšäº†ä¸€ç‚¹æ”¹è¿›ï¼ŒåŠ äº†layer normã€‚</p><p>æ€è€ƒï¼š<br>æ–‡ç« æœ‰æ„æ€çš„ç‚¹æ˜¯ç«‹è¶³äºå®éªŒè§‚å¯Ÿï¼Œè¿™ç‚¹å€¼å¾—å­¦ä¹ ï¼Œä»å®è·µä¸­å‘ç°é—®é¢˜ã€‚åŒæ—¶ï¼Œåº”å­¦ä¼šç”¨æŠ½è±¡çš„æ€æƒ³å»æ€»ç»“å‰äººçš„å·¥ä½œï¼ˆæ¯”å¦‚NL-Netå®é™…ä¸Šä¹Ÿæ˜¯å¯¹å‰é¢çš„å·¥ä½œçš„æŠ½è±¡æ€»ç»“ï¼Œå®é™…ä¸Šä¸ªäººè®¤ä¸ºå¹¶æ²¡æœ‰ä»€ä¹ˆå¤§çš„åˆ›æ–°ï¼‰ï¼Œä»ä¸€ä¸ªæ›´é«˜çš„è§’åº¦å»çœ‹é—®é¢˜èƒ½å°†é—®é¢˜çœ‹å¾—æ›´æ¸…æ™°ã€‚</p><p>æŠ½è±¡å‡ºæ¡†æ¶æ˜¯æœ‰å¿…è¦çš„å—ï¼Ÿæˆ‘çœ‹åœ¨è¿™ç¯‡è®ºæ–‡é‡Œé¢æœ‰äº›å‹‰å¼ºï¼Œå› ä¸ºå®Œå…¨å¯ä»¥è¯´inspired by SE-Net for the computation efficiencyâ€¦ ä½†éè¦æŠ½è±¡æˆæ¡†æ¶ï¼Œä¼šä¸ä¼šåªæ˜¯è¦è¡¨ç°å‡ºå¯¹æ¨¡å‹çš„ç†è§£å¤Ÿæ·±ï¼Ÿä»¥åŠå¢åŠ ç‚¹å†…å®¹ï¼Ÿ</p><p>ä»¥åŠquery-dependentæ˜¯å¦çœŸçš„æ²¡å¿…è¦ï¼Ÿä¼¼ä¹åœ¨å…¶ä»–è®ºæ–‡ä¸­çš„ç»“è®ºåè€Œæ˜¯ç›¸åçš„ã€‚</p><hr><h2 id="Ordered-Neurons-Integrating-Tree-Structures-into-Recurrent-Neural-Networks"><a href="#Ordered-Neurons-Integrating-Tree-Structures-into-Recurrent-Neural-Networks" class="headerlink" title="[Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks]"></a>[Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks]</h2><p>ICLR19 best paperã€‚</p><p>åœ¨LSTMä¸­å¼•å…¥äº†æ–°çš„inductive biasï¼Œéšå¼å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚</p><p>Motivationï¼š<br>è¯­è¨€éƒ½æœ‰ä¸€å®šçš„æ ‘çš„ç»“æ„è€Œä¸æ˜¯åºåˆ—ç»“æ„ã€‚å‰äººç ”ç©¶è¡¨æ˜ï¼Œåœ¨NLPä¸­å¼•å…¥æ ‘çš„ç»“æ„æœ‰åŠ©äºå¢å¼ºæ³›åŒ–ï¼Œå¸®åŠ©å‡å°‘é•¿ç¨‹ä¾èµ–é—®é¢˜ï¼Œèƒ½å¤Ÿè·å¾—æ›´å¥½çš„æŠ½è±¡è¡¨ç¤ºã€‚<br>ä¸€äº›æ–¹æ³•åŒ…æ‹¬å¢åŠ ç›‘ç£ä¿¡å·ï¼Œä¹Ÿå³è¯­æ³•æ ‘ç­‰ï¼Œä½†è¯¥æ–¹æ³•æœ‰é™åˆ¶ï¼Œå¦‚æ ‡æ³¨æ•°æ®ä¸è¶³ï¼Œåœ¨ä¸€äº›é¢†åŸŸè¯­æ³•è§„åˆ™å®¹æ˜“è¢«æ‰“ç ´ï¼ˆå¦‚æ¨ç‰¹ï¼‰ï¼›åŒæ—¶éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¯­æ³•ä¹Ÿåœ¨å˜åŒ–ã€‚<br>åŒæ—¶ï¼Œä¸€äº›ç ”ç©¶ä¹Ÿè¡¨æ˜ï¼Œæœ‰è¶³å¤Ÿå®¹é‡çš„LSTMåœ¨èƒ½å¤Ÿéšå¼åœ°å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚</p><p>å› æ­¤åœ¨æœ¬æ–‡å¼•å…¥æ–°çš„inductive biasï¼Œ<strong>å®Œå…¨æ•°æ®é©±åŠ¨</strong>ï¼ˆç›¸å¯¹äºæ˜¾å¼æ„å»ºæ ‘ï¼‰ï¼Œéšå¼åœ°å¯¹å¥å­è¿›è¡Œæ ‘çš„å»ºæ¨¡ã€‚è¿™ç§å½’çº³åç½®ä¿ƒè¿›äº†æ¯ä¸ªç¥ç»å…ƒå†…å­˜å‚¨çš„ä¿¡æ¯çš„ç”Ÿå‘½å‘¨æœŸçš„åˆ†åŒ–ã€‚high-rankingçš„ç¥ç»å…ƒä¿å­˜é•¿ç¨‹çš„ä¿¡æ¯ï¼Œåœ¨ä¸€ä¸ªè¾ƒé•¿æ—¶é—´æ­¥å†…ä¿å­˜ï¼Œè€Œlow-rankingåˆ™ä¿å­˜çŸ­ç¨‹ä¿¡æ¯ï¼Œèƒ½å¤Ÿå¿«é€Ÿè¢«é—å¿˜ã€‚å¼•å…¥cumulative softmaxï¼Œä¸€ç§æ–°çš„æ¿€æ´»å‡½æ•°æ¥ç”Ÿæˆmaster input gateå’Œforget gate ä¿è¯å½“ä¸€ä¸ªç¥ç»å…ƒè¢«æ›´æ–°/é—å¿˜ï¼Œå…¶åçš„ç¥ç»å…ƒéƒ½ä¼šè¢«æ›´æ–°/é—å¿˜ã€‚</p><h3 id="ORDERED-NEURONS"><a href="#ORDERED-NEURONS" class="headerlink" title="ORDERED NEURONS"></a>ORDERED NEURONS</h3><p>ç»™å®šè¯­è¨€åºåˆ—$S=\left(x_{1}, \dots, x_{T}\right)$ä»¥åŠå¯¹åº”çš„constituency treeï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è®¡ç®—æ—¶é—´æ­¥tçš„æ—¶å€™ï¼ŒéšçŠ¶æ€$h_t$èƒ½åŒ…å«è¯¥èŠ‚ç‚¹åˆ°æ ¹èŠ‚ç‚¹è·¯å¾„ä¸Šæ‰€æœ‰èŠ‚ç‚¹çš„ä¿¡æ¯ã€‚ç›´è§‚ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›è¯¥è·¯å¾„ä¸Šçš„èŠ‚ç‚¹éƒ½èƒ½å¤Ÿè¢«$h_t$çš„ä¸€éƒ¨åˆ†ç¥ç»å…ƒè¡¨ç¤ºã€‚ç”±äº$h_t$çš„ç»´åº¦æ˜¯å›ºå®šçš„ï¼Œè€Œè·¯å¾„ä¸Šçš„èŠ‚ç‚¹åˆ™æ˜¯åŠ¨æ€çš„ï¼Œå› æ­¤ä¸€ç§æœ€å¥½çš„æƒ…å†µå°±æ˜¯èƒ½å¤ŸåŠ¨æ€åˆ†é…æ¯ä¸ªèŠ‚ç‚¹åœ¨hidden stateçš„ç»´åº¦ã€‚</p><p>åœ¨ä¸Šè¿°æ€è·¯çš„åŸºç¡€ä¸Šï¼Œä½œè€…å¼•å…¥äº†ordered neuronsï¼Œå¼ºåˆ¶è®©ç¥ç»å…ƒè¡¨ç¤ºä¸åŒæ—¶é—´å°ºåº¦ä¸Šçš„ä¿¡æ¯ã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œhigh-rankingçš„ç¥ç»å…ƒä¿å­˜çš„æ—¶é—´é•¿ï¼Œä»£è¡¨çš„å°±æ˜¯æ¥è¿‘æ ‘æ ¹çš„èŠ‚ç‚¹ï¼Œè€Œlow-rankingçš„ç¥ç»å…ƒä¿å­˜æ—¶é—´çŸ­ï¼Œä»£è¡¨çš„å°±æ˜¯å°çš„æˆåˆ†ï¼ˆå¦‚phraseï¼‰ã€‚åŸåˆ™æ˜¯ï¼šè¦æ›´æ–°/é—å¿˜high-rankingçš„ç¥ç»å…ƒï¼Œåº”è¯¥å…ˆæŠŠlow-rankingçš„ç¥ç»å…ƒå…ˆæ›´æ–°/é—å¿˜æ‰ã€‚</p><p>å¦‚å›¾ï¼š</p><p><img src="/images/15576268851485.jpg" width="80%" height="50%"></p><h3 id="ON-LSTM-â€œOrdered-Neurons-LSTMâ€"><a href="#ON-LSTM-â€œOrdered-Neurons-LSTMâ€" class="headerlink" title="ON-LSTM (â€œOrdered Neurons LSTMâ€)"></a>ON-LSTM (â€œOrdered Neurons LSTMâ€)</h3><p>LSTMç»“æ„ï¼š</p><p>$\begin{array}{ll}{f_{t}=\sigma\left(W_{f} x_{t}+U_{f} h_{t-1}+b_{f}\right)} \\ {i_{t}=\sigma\left(W_{i} x_{t}+U_{i} h_{t-1}+b_{i}\right)} \\ {o_{t}=\sigma\left(W_{o} x_{t}+U_{o} h_{t-1}+b_{o}\right)} \\ {\hat{c}_{t}=\tanh \left(W_{c} x_{t}+U_{c} h_{t-1}+b_{c}\right)} \\ {h_{t}=o_{t} \circ \tanh \left(c_{t}\right)}\end{array}$</p><p>OH-LSTMä¸LSTMçš„ä¸åŒåœ¨äºä¿®æ”¹äº†cell stateçš„æ›´æ–°æ–¹å¼ã€‚</p><p>é¦–å…ˆå®šä¹‰æ–°çš„æ¿€æ´»å‡½æ•°ï¼š</p><script type="math/tex; mode=display">\hat{g}=\operatorname{cumax}(\ldots)=\operatorname{cumsum}(\operatorname{softmax}(\ldots))</script><p>$\hat{g}$å¯ä»¥çœ‹åšæ˜¯äºŒå…ƒgateçš„æœŸæœ›ï¼Œè€Œgå°†cell stateåˆ†æˆä¸¤ä¸ªsegment $g=(0, \dots, 0,1, \dots, 1)$ã€‚</p><p>å› ä¸ºç¦»æ•£çš„æ–¹æ³•ä¸å¥½ä¼˜åŒ–ï¼Œä»¥åŠå¤ªè¿‡ä¸¥æ ¼ã€‚å…·ä½“çš„è§£é‡Šå’Œè¯æ˜åœ¨è®ºæ–‡é‡Œã€‚</p><p>å¼•å…¥ä¸¤ä¸ªæ–°çš„gateï¼Œmaster forget gateå’Œmaster input gateã€‚forget gateçš„å€¼å•è°ƒé€’å¢ï¼›è€Œinput gateçš„å€¼å•è°ƒé€’å‡ã€‚</p><p>$\begin{aligned} \tilde{f}_{t} &amp;=\operatorname{cumax}\left(W_{\tilde{f}} x_{t}+U_{\tilde{f}} h_{t-1}+b_{\tilde{f}}\right) \\ \tilde{i}_{t} &amp;=1-\operatorname{cumax}\left(W_{\tilde{i}} x_{t}+U_{i} h_{t-1}+b_{\tilde{i}}\right) \end{aligned}$</p><p>æ–°çš„æ›´æ–°è§„åˆ™ï¼š<br>$\begin{aligned} \omega_{t} &amp;=\tilde{f}_{t} \circ \tilde{i}_{t} \\ \hat{f}_{t} &amp;=f_{t} \circ \omega_{t}+\left(\tilde{f}_{t}-\omega_{t}\right)=\tilde{f}_{t} \circ\left(f_{t} \circ \tilde{i}_{t}+1-\tilde{i}_{t}\right) \\ \hat{i}_{t} &amp;=i_{t} \circ \omega_{t}+\left(\tilde{i}_{t}-\omega_{t}\right)=\tilde{i}_{t} \circ\left(i_{t} \circ \tilde{f}_{t}+1-\tilde{f}_{t}\right) \\ c_{t} &amp;=\hat{f}_{t} \circ c_{t-1}+\hat{i}_{t} \circ \hat{c}_{t} \end{aligned}$</p><p>master forget gate æ§åˆ¶çš„æ˜¯erasingè¡Œä¸ºï¼›master input gateåˆ™æ˜¯æ§åˆ¶writingè¡Œä¸ºã€‚å…·ä½“çš„ä¾‹å­è§è®ºæ–‡ã€‚$\omega_{t}$åˆ™æ˜¯$\tilde{f}_{t}$ä¸$\tilde{i}_{t}$çš„é‡å éƒ¨åˆ†ï¼Œè¡¨ç¤ºçš„æ˜¯ ç›¸åº”çš„ç¥ç»å…ƒæ®µç¼–ç åŒ…å«ä¸€äº›å…ˆå‰å•è¯å’Œå½“å‰è¾“å…¥å•è¯$x_t$çš„ä¸å®Œæ•´æˆåˆ†ã€‚</p><p>åŒæ—¶ï¼Œmaster gatesä¸“æ³¨ä¸€äº›ç²—ç²’åº¦çš„æ§åˆ¶ï¼Œå› æ­¤æ²¡å¿…è¦å’Œhidden stateä¸€æ ·çš„ç»´åº¦ï¼Œåˆ†é…å°ä¸€äº›çš„ç»´åº¦$D_{m}=\frac{D}{C}$å³å¯ã€‚å› æ­¤æ¯C-sizedä¸ªchunkæœ‰åŒæ ·çš„master gatesã€‚</p><p>æ€è€ƒï¼š<br>è®¾è®¡å¾ˆç²¾å·§ï¼Œé€šè¿‡å°†ç¥ç»å…ƒåˆ†åŒ–ï¼Œéšå¼å»ºæ¨¡ã€‚æ›´æ–°è§„åˆ™éƒ¨åˆ†æˆ‘å…¶å®è¿˜æ²¡ä»”ç»†å»çœ‹ï¼Œä½†è¯¥æ€æƒ³ç¡®å®å¾ˆæœ‰æ„æ€ã€‚</p><hr><h2 id="Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification"><a href="#Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification" class="headerlink" title="[Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification]"></a>[Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification]</h2><p>é…åˆä¸Šä¸€ç¯‡ON-LSTMçœ‹ï¼Œå‘ç°ä»–ä»¬ä¹‹é—´å…·æœ‰ç›¸ä¼¼ä¹‹å¤„ã€‚</p><p>æœ¬æ–‡åœ¨LSTMä¸Šå¼•å…¥cacheæœºåˆ¶ï¼Œå°†memoryåˆ‡åˆ†ä¸ºå¤šä¸ªgroupå¹¶èµ‹äºˆä¸åŒçš„forget rateï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°ä¿ç•™å…¨å±€çš„ä¿¡æ¯ï¼Œå¯¹documentçº§åˆ«çš„æƒ…æ„Ÿåˆ†ç±»èƒ½å¤Ÿæœ‰æ›´å¥½çš„ç»“æœã€‚</p><p>LSTMï¼š</p><script type="math/tex; mode=display">\begin{aligned} \mathbf{i}^{(t)} &=\sigma\left(\mathbf{W}_{i} \mathbf{x}^{(t)}+\mathbf{U}_{i} \mathbf{h}^{(t-1)}\right) \\ \mathbf{f}^{(t)} &=\sigma\left(\mathbf{W}_{f} \mathbf{x}^{(t)}+\mathbf{U}_{f} \mathbf{h}^{(t-1)}\right) \\ \mathbf{o}^{(t)} &=\sigma\left(\mathbf{W}_{o} \mathbf{x}^{(t)}+\mathbf{U}_{o} \mathbf{h}^{(t-1)}\right) \\ \tilde{\mathbf{c}}^{(t)} &=\tanh \left(\mathbf{W}_{c} \mathbf{x}^{(t)}+\mathbf{U}_{c} \mathbf{h}^{(t-1)}\right) \\ \mathbf{c}^{(t)} &=\mathbf{f}^{(t)} \odot \mathbf{c}^{(t-1)}+\mathbf{i}^{(t)} \odot \tilde{\mathbf{c}}^{(t)} ) \\ \mathbf{h}^{(t)} &=\mathbf{o}^{(t)} \odot \tanh \left(\mathbf{c}^{(t)}\right) \end{aligned}</script><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå®é™…ä¸Šæ˜¯ä½¿ç”¨äº†LSTMçš„å˜ä½“ï¼Œå°†input gateä¸forget gateåˆå¹¶ä¸ºä¸€ä¸ªï¼Œä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\mathbf{c}^{(t)}=\mathbf{f}^{(t)} \odot \mathbf{c}^{(t-1)}+\left(\mathbf{1}-\mathbf{f}^{(t)}\right) \odot \tilde{\mathbf{c}}^{(t)}</script><h3 id="Cached-LSTM"><a href="#Cached-LSTM" class="headerlink" title="Cached LSTM"></a>Cached LSTM</h3><p>æ”¹è¿›LSTMï¼Œå°†memoryåˆ†ä¸ºå¤šä¸ªgroupï¼Œæ¯ä¸ªgroupä»£è¡¨ä¸åŒçš„é•¿ç¨‹ä¾èµ–ï¼Œåˆ†é…ä¸åŒçš„forget rateã€‚ç›´è§‚ä¸Šï¼Œé«˜çš„rateä»£è¡¨äº†çŸ­ç¨‹ä¾èµ–ï¼Œä½çš„rateä»£è¡¨é•¿ç¨‹ä¾èµ–ã€‚</p><p>å°†memory cellåˆ‡æˆKå—$\left\{G_{1}, \cdots, G_{K}\right\}$ã€‚å› æ­¤æœ‰å¦‚ä¸‹å…¬å¼ï¼š</p><script type="math/tex; mode=display">\begin{aligned} \mathbf{r}_{k}^{(t)} &=\psi_{k}\left(\sigma\left(\mathbf{W}_{r}^{k} \mathbf{x}^{(t)}+\sum_{j=1}^{K} \mathbf{U}_{f}^{j \rightarrow k} \mathbf{h}_{j}^{(t-1)}\right)\right) \\ \mathbf{o}_{k}^{(t)} &=\sigma\left(\mathbf{W}_{o}^{k} \mathbf{x}^{(t)}+\sum_{j=1}^{K} \mathbf{U}_{o}^{j \rightarrow k} \mathbf{h}_{j}^{(t-1)}\right) \\ \tilde{\mathbf{c}}_{k}^{(t)} &=\tanh \left(\mathbf{W}_{c}^{(t)} \mathbf{x}^{(t-1)}+\left(\mathbf{r}_{k}^{(t)}\right) \odot \tilde{\mathbf{c}}_{k}^{(t)}\right) \\ \mathbf{h}_{k}^{(t)} &=\mathbf{o}_{k}^{(t)} \odot \tanh \left(\mathbf{c}_{k}^{(t)}\right) \end{aligned}</script><p>$\psi_{k}(\mathbf{z})$æ˜¯å‹ç¼©å‡½æ•°ï¼š</p><script type="math/tex; mode=display">\mathbf{r}_{k}=\psi_{k}(\mathbf{z})=\frac{1}{K} \cdot \mathbf{z}+\frac{k-1}{K}</script><p>å°†forget rateå‹ç¼©åœ¨ä¸€å®šèŒƒå›´$\left(\frac{k-1}{K}, \frac{k}{K}\right)$ã€‚</p><p>ç±»ä¼¼bi-LSTMï¼ŒåŒæ ·CLSTMå¯ä»¥æœ‰åŒå‘ã€‚åœ¨åšåˆ†ç±»æ—¶ï¼Œåªå°†ä»£è¡¨é•¿ç¨‹ä¾èµ–çš„é‚£ç»„å–å‡ºæ¥è¿‡softmaxã€‚</p><p><img src="/images/15576279206849.jpg" width="55%" height="50%"></p><p>æ€è€ƒï¼š<br>ä¸Ordered Neuronç›¸æ¯”ï¼Œè¿™é‡Œæ˜¾å¼åœ°å°†å›ºå®šç»´åº¦åˆ‡åˆ†æˆå¤šä¸ªç»„ï¼Œç›¸æ¯”è€Œè¨€Ordered Neuronæ›´åŠ çµæ´»ï¼Œä½†äºŒè€…è¿˜æ˜¯æœ‰ç›¸å½“çš„ç›¸ä¼¼ç¨‹åº¦çš„ï¼Œè™½ç„¶ä»»åŠ¡å’Œmotivationä¸åŒã€‚</p><hr><h2 id="Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation"><a href="#Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation" class="headerlink" title="[Unified Language Model Pre-training for Natural Language Understanding and Generation]"></a>[Unified Language Model Pre-training for Natural Language Understanding and Generation]</h2><p>å°†pretrainæ‰©å±•åˆ°ç”Ÿæˆé¢†åŸŸï¼Œä½¿ç”¨ç”Ÿæˆä»»åŠ¡æ¥å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œpretrainã€‚</p><p><img src="/images/15576282560620.jpg" width="80%" height="50%"></p><p>åŒæ—¶ä½¿ç”¨ä¸‰ç§è¯­è¨€æ¨¡å‹æ¥è¿›è¡Œpretrainã€‚ä¸€ç§æ˜¯bidirectionalçš„ï¼Œå’Œbertä¸€æ ·ï¼›ä¸€ç§æ˜¯ä»å·¦åˆ°å³/ä»å³åˆ°å·¦å•å‘çš„ï¼Œå’ŒGPTä¸€æ ·ï¼›å¦ä¸€ç§æ˜¯åšç”Ÿæˆçš„ï¼Œä¹Ÿå³encoderç«¯ç›¸äº’éƒ½attendåˆ°ï¼Œè€Œdecoderç«¯åªèƒ½çœ‹åˆ°encoderéƒ¨åˆ†å’Œdecoderçš„å·¦è¾¹ã€‚</p><p>ç»Ÿä¸€ä½¿ç”¨[MASK]çš„æ–¹æ³•ï¼ˆbertï¼‰åŒæ—¶è®­ç»ƒè¿™ä¸‰ç§è¯­è¨€æ¨¡å‹ï¼Œè¿™æ ·å¯ä»¥ä½¿ç”¨åŒä¸€å¥—è®­ç»ƒæµç¨‹åŒæ—¶è®­ç»ƒä¸‰ç§æ¨¡å‹ã€‚</p><p>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®å°±æ˜¯å°†ç”ŸæˆåŠ è¿›æ¥äº†å§ï¼Œå¹¶ä¸”æ•ˆæœè¿˜å¯ä»¥ã€‚å…¶ä»–å¹¶æ²¡æœ‰å¾ˆå¤§çš„åˆ›æ–°ç‚¹ã€‚</p><hr><h2 id="Language-Models-are-Unsupervised-Multitask-Learners"><a href="#Language-Models-are-Unsupervised-Multitask-Learners" class="headerlink" title="[Language Models are Unsupervised Multitask Learners]"></a>[Language Models are Unsupervised Multitask Learners]</h2><p>å¤§åé¼é¼çš„GPT2.0 é€šè¿‡å¢åŠ æ›´å¤šå±‚ï¼Œå¢åŠ æ›´å¤šæ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªæ›´å¥½çš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä¸”å°è¯•åœ¨ä¸fine-tuneçš„æƒ…å†µä¸‹å®Œæˆä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶å–å¾—ä¸é”™çš„æ•ˆæœã€‚</p><p>å…¨æ–‡éƒ½åœ¨è®¨è®ºæ€ä¹ˆè·å¾—æ•°æ®ä»¥åŠæ€ä¹ˆè®­ç»ƒã€‚å®é™…ä¸Šå¸®åŠ©å¹¶ä¸å¤§ï¼Œä½†ä¸ªäººè®¤ä¸ºæœ¬æ–‡æœ€å¤§çš„è´¡çŒ®å°±æ˜¯å°è¯•å»åšç”Ÿæˆï¼Œå¹¶ä¸”åœ¨zero-shotçš„æƒ…æ™¯ä¸‹å»æ¢ç´¢language modelçš„ä¸Šé™ã€‚</p><p>å…¶ä»–æˆ‘æ²¡ä»”ç»†çœ‹ã€‚</p><hr><h2 id="MASS-Masked-Sequence-to-Sequence-Pre-training-for-Language-Generation"><a href="#MASS-Masked-Sequence-to-Sequence-Pre-training-for-Language-Generation" class="headerlink" title="[MASS: Masked Sequence to Sequence Pre-training for Language Generation]"></a>[MASS: Masked Sequence to Sequence Pre-training for Language Generation]</h2><p>å¼•å…¥encoder-decoderç»“æ„æ¥åšpretrainï¼Œå¯ä»¥åŒæ—¶è®­ç»ƒencoderå’Œdecoderï¼Œå¯ä»¥ç”¨äºç”Ÿæˆä»»åŠ¡ã€‚ ideaè¿˜æ˜¯æŒºæœ‰æ„æ€çš„ã€‚</p><p>Motivation:<br>é‡‡ç”¨encoder-decoderæ¡†æ¶èƒ½è¿›ä¸€æ­¥æ›´å¥½åœ°ç”¨äºç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè€Œä¸åƒbertå’ŒGPTé‚£æ ·åªæœ‰ä¸€ä¸ªencoderæˆ–decoderï¼Œæ²¡æ³•å¯¹attentioné¢„è®­ç»ƒï¼Œå¯¹ç”Ÿæˆä»»åŠ¡ä¸å‹å¥½ã€‚</p><p>åšæ³•ï¼šåœ¨encoderç«¯maskè¿ç»­çš„è¯ï¼Œç„¶åä½¿ç”¨transformerå¯¹å…¶è¿›è¡Œencodeï¼›ç„¶åå†decoderç«¯è¾“å…¥åŒæ ·çš„å¥å­ï¼Œä½†æ˜¯maskedæ‰çš„æ­£å¥½å’Œencoderç›¸åï¼Œå’Œç¿»è¯‘ä¸€æ ·ï¼Œä½¿ç”¨attentionæœºåˆ¶å»è®­ç»ƒï¼Œä½†åªé¢„æµ‹encoderç«¯è¢«maskæ‰çš„è¯ã€‚</p><p><img src="/images/15576285238806.jpg" width="80%" height="50%"></p><p>ä½œè€…è®¤ä¸ºè¿™æ ·åšçš„å¥½å¤„ï¼š<br>å¯¹encoderç«¯çš„maskèƒ½å¤Ÿå¼ºåˆ¶è®©encoderç«¯æ›´å¥½åœ°å­¦ä¹ æœªè¢«maskæ‰çš„è¯çš„æ„ä¹‰ï¼Œè¿™æ ·æ‰èƒ½é¢„æµ‹maskæ‰çš„è¯ï¼›å¯¹decoderç«¯çš„inputè¿›è¡Œmaskèƒ½å¤Ÿå¼ºåˆ¶æ¨¡å‹æ›´å¤šä¾èµ–äºsourceç«¯ï¼Œè€Œä¸æ˜¯å‰é¢çš„inputã€‚</p><p>ä½œè€…è¿˜å°†MASSä¸Bert/GPTåšäº†å¯¹æ¯”ï¼Œå‘ç°Bert/GPTæ˜¯MASSçš„ä¸€ä¸ªç‰¹ä¾‹ã€‚MASSæœ‰ä¸€ä¸ªè¶…å‚kï¼Œæ§åˆ¶maskæ‰çš„segmenté•¿åº¦ã€‚å½“k=1æ—¶ï¼Œåˆ™æ˜¯BERTï¼›å½“k=mï¼Œä¹Ÿå³æ•´ä¸ªå¥å­é•¿åº¦æ—¶åˆ™æ˜¯GPTã€‚</p><p><img src="/images/15576285809670.jpg" width="50%" height="50%"></p><p><img src="/images/15576285948426.jpg" width="100%" height="50%"></p><p>å½“k=1æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºdecoderç«¯æ²¡æœ‰inputä¿¡æ¯ï¼Œå…¨éƒ¨ä¿¡æ¯æ¥è‡ªencoderï¼Œå’ŒBertå¯¹æ¯”ä¸€ä¸‹ï¼Œè™½ç„¶åœ¨ç»“æ„ä¸Šä¸ä¸€æ ·ï¼Œä½†åšçš„äº‹æƒ…æ˜¯ä¸€æ ·çš„ï¼Œæ­¤æ—¶decoderçš„è§’è‰²å°±æ˜¯berté‡Œé¢çš„åˆ†ç±»å™¨ã€‚<br>å½“k=mæ—¶ï¼Œå®é™…ä¸Šå°±æ˜¯å°†encoderç«¯çš„æ‰€æœ‰ä¿¡æ¯éƒ½maskæ‰äº†ï¼Œæ­¤æ—¶decoderè¦é¢„æµ‹åªèƒ½é decoderç«¯çš„inputï¼Œè¿™å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªæ ‡å‡†çš„è¯­è¨€æ¨¡å‹ã€‚</p><p>åœ¨å‡ ä¸ªç”Ÿæˆä»»åŠ¡ä¸Šçš„ç»“æœç›¸å½“ä¸é”™ï¼Œæˆ‘æ²¡ä»”ç»†çœ‹ã€‚</p><p>æ€è€ƒï¼šå°†bertå’ŒGPTæŠ½è±¡å‡ºæ¥ï¼Œä½œä¸ºå…¶æ¡†æ¶çš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼Œè¿™åˆå’ŒNL-Netæœ‰ä¸€äº›ç›¸ä¼¼ã€‚</p><hr><h2 id="Gather-Excite-Exploiting-Feature-Context-in-Convolutional-Neural-Networks"><a href="#Gather-Excite-Exploiting-Feature-Context-in-Convolutional-Neural-Networks" class="headerlink" title="[Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks]"></a>[Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks]</h2><p>å¦ä¸€ç§Gather-Distributeæ€æƒ³çš„å®ä¾‹ã€‚è¯¥æ¨¡å‹åŒæ ·æ˜¯ä¸ºäº†æ•è·é•¿è·ç¦»ä¸Šä¸‹æ–‡ï¼Œä»¥æå‡è¡¨ç°ã€‚</p><p>åˆ†ä¸ºä¸¤æ­¥ï¼šgatherï¼Œå°†è¾ƒå¤§ç©ºé—´å†…çš„ä¿¡æ¯èšé›†èµ·æ¥ï¼Œexciteï¼Œå°†ä¿¡æ¯é‡æ–°åˆ†å‘ç»™local featuresã€‚</p><p><img src="/images/15576287381755.jpg" width="80%" height="50%"></p><p>Motivationï¼šCNNçš„ä¿¡æ¯æµåŠ¨æ–¹å¼ã€‚æ¯æ¬¡æŠ½å–å‘¨å›´çš„ä¿¡æ¯èšåˆåœ¨ä¸€èµ·ï¼Œéšç€å±‚æ•°çš„å¢å¤šé€æ¸æŠ½è±¡ï¼Œå…¶æ„Ÿå—é‡ä¹Ÿé€æ¸å¢å¤§ã€‚æœ¬æ–‡æå‡ºçš„æ¨¡å‹å®é™…ä¸Šå°±æ˜¯åœ¨åŒä¸€å±‚å†…è®©æ¯ä¸ªç‚¹éƒ½æ„Ÿå—åˆ°å…¶å‘¨å›´æ›´å¤§ç©ºé—´çš„ä¿¡æ¯ã€‚</p><h3 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><p>æ¨¡å‹å®šä¹‰ï¼š<br>è¾“å…¥ï¼š$x=\left\{x^{c} : c \in\{1, \ldots, C\}\right\}$<br>Cä»£è¡¨Cä¸ªfeature mapsï¼Œä¹Ÿå³channelç»´ã€‚</p><p>å®šä¹‰selection operatorï¼š<br>$\iota(u, e)=\left\{e u+\delta : \delta \in[-\lfloor(2 e-1) / 2\rfloor,\lfloor(2 e-1) / 2\rfloor]^{2}\right\}$</p><p>uæ˜¯è¾“å‡ºçš„å…ƒç´ ï¼Œeæ˜¯extent ratioï¼Œä»£è¡¨çš„å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªçª—å£å¤§å°ã€‚</p><p>å› æ­¤gather operatorå¯ä»¥å®šä¹‰ä¸ºæ˜ å°„å‡½æ•°ï¼š<br>$\xi_{G} : \mathbb{R}^{H \times W \times C} \rightarrow \mathbb{R}^{H^{\prime} \times W^{\prime} \times C}\left(H^{\prime}=\left\lceil\frac{H}{e}\right\rceil, W^{\prime}=\left\lceil\frac{W}{e}\right\rceil\right)$<br>$\xi_{G}(x)_{u}^{c}=\xi_{G}\left(x \odot \mathbf{1}_{\iota_{(u, e)}}^{c}\right)$</p><p>å…¶å®å°±æ˜¯å¯¹è¯¥çª—å£å†…çš„å…ƒç´ è¿›è¡Œäº†æ˜ å°„ï¼ˆå¦‚mean-poolingï¼‰ã€‚å…¶ä¸­$u \in\left\{1, \ldots, H^{\prime}\right\} \times\left\{1, \ldots, W^{\prime}\right\}, c \in\{1, \ldots, C\}$</p><p>ä»ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œgatheræ“ä½œå®é™…ä¸Šå°±æ˜¯å¯¹äºæ¯ä¸ªè¾“å‡ºuï¼Œå…¶æ„Ÿå—é‡ä¸ºå•ä¸ªchannelçš„ä¸€ä¸ªçª—å£ã€‚å¦‚æœè¯¥çª—å£æ°å¥½è¦†ç›–äº†æ•´ä¸ªç©ºé—´ï¼Œåˆ™ç§°è¯¥gatheræ“ä½œæœ‰global extentã€‚</p><p>è€Œexciteæ“ä½œåˆ™æ˜¯åˆ©ç”¨gatherè·å¾—çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ›´æ–°æ¯ä¸ªfeatureã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\begin{array}{l}{\xi_{E}(x, \hat{x})=x \odot f(\hat{x})} \\ {f : \mathbb{R}^{H^{\prime} \times W^{\prime} \times C} \rightarrow[0,1]^{\overline{H} \times W \times C}}\end{array}</script><p>é‚£ä¹ˆGæ˜¯å¦‚ä½•è·å¾—çš„ï¼Ÿå¯ä»¥æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯æ— å‚æ•°ï¼Œå¦ä¸€ç§æ˜¯æœ‰å‚æ•°ã€‚</p><h4 id="æ— å‚æ•°GE"><a href="#æ— å‚æ•°GE" class="headerlink" title="æ— å‚æ•°GE"></a>æ— å‚æ•°GE</h4><p>å®é™…ä¸Šå°±æ˜¯mean-poolingã€‚<br>åˆ™æ•´ä¸ªGE-Netä¸ºï¼š</p><script type="math/tex; mode=display">y^{c}=x \odot \sigma\left(\text {interp}\left(\xi_{G}(x)^{c}\right)\right)</script><p>å…¶ä¸­interp(Â·)ä»£è¡¨äº†æœ€é‚»è¿‘æ’å€¼ã€‚å®é™…ä¸Šå¯ä»¥ç†è§£æˆï¼Œå°†ä¸€ä¸ªè¾ƒå¤§çª—å£çš„ä¿¡æ¯éƒ½mean-poolingä¸€ä¸‹ï¼Œç„¶åè¯¥çª—å£çš„featureéƒ½ç”¨mean-poolingçš„å€¼ä¹˜ä¸€ä¸‹ï¼ˆå› ä¸ºæœ€é‚»è¿‘çš„ç‰¹ç‚¹ï¼Œè¯¥çª—å£çš„æ’å€¼éƒ½æ˜¯è‡ªèº«ï¼‰ã€‚</p><p>å½“è®¾è®¡ä¸åŒçš„eæ—¶ï¼Œä¹Ÿå³çª—å£å¤§å°ï¼Œå¯ä»¥çœ‹åˆ°çª—å£è¶Šå¤§ï¼Œå…¶è¡¨ç°è¶Šå¥½ã€‚</p><p><img src="/images/15576291070929.jpg" width="40%" height="50%"></p><h4 id="æœ‰å‚æ•°GE"><a href="#æœ‰å‚æ•°GE" class="headerlink" title="æœ‰å‚æ•°GE"></a>æœ‰å‚æ•°GE</h4><p>é‡‡ç”¨strided depth-wise convolutionã€‚</p><p>åŒæ ·è¶Šå¤§çš„eè¶Šå¥½ï¼š</p><p><img src="/images/15576291449392.jpg" width="40%" height="50%"></p><p>å¹¶ä¸”è¡¨ç°ä¼šæ¯”æ— å‚æ•°çš„æ›´å¥½ã€‚</p><p>å®éªŒè¡¨æ˜ï¼Œåœ¨æ•´ä¸ªæ¨¡å‹çš„ä¸­é—´å±‚æˆ–è€…åé¢å±‚ï¼ˆæœ‰æ›´å¤šçš„channelï¼‰åŠ GEä¼šæ›´å¥½ã€‚</p><h3 id="ä¸SE-Netçš„å…³ç³»"><a href="#ä¸SE-Netçš„å…³ç³»" class="headerlink" title="ä¸SE-Netçš„å…³ç³»"></a>ä¸SE-Netçš„å…³ç³»</h3><p>SE-Netå¯ä»¥çœ‹åšæ˜¯ç‰¹æ®Šçš„GE-Netã€‚SE-Netçš„gatheræ“ä½œå°±æ˜¯å…¨å±€çš„mean-poolingï¼›è€Œåœ¨exciteæ—¶å¤šäº†ä¸€å±‚å…¨è¿æ¥çš„ç½‘ç»œï¼ˆï¼Ÿè®ºæ–‡è¯´å°±æ˜¯ä¸€å±‚å…¨è¿æ¥ï¼Œä½†ä¼¼ä¹ä¸æ˜¯è¿™æ ·çš„ï¼‰ã€‚</p><p><img src="/images/15576291939204.jpg" width="70%" height="50%"></p><p>è®ºæ–‡ä¸­è¿˜å°†SE-Netå’ŒGE-Netç»“åˆèµ·æ¥ï¼Œå‘ç°æœ‰æ›´å¤§çš„æå‡ï¼Œè¯æ˜äºŒè€…ä¸æ˜¯æ’æ–¥çš„ã€‚</p><p>åº”ç”¨GE-Netçš„å‡ ä¸ªä¾‹å­ï¼š</p><p><img src="/images/15576292257307.jpg" width="80%" height="50%"></p><p>æˆ‘çš„æ€è€ƒï¼š<br>ä¸SE-Netçš„å…³ç³»å¯†åˆ‡ï¼ˆå®é™…ä¸Šå°±æ˜¯åŒä¸€æ‹¨äººåšçš„ï¼‰ã€‚ä½†è¿™é‡Œå¼ºè°ƒçš„æ˜¯channelä¹‹é—´æ²¡æœ‰è”ç³»ï¼Œä»…ä»…æ˜¯é€šè¿‡æ‰©å¤§æ„Ÿå—é‡ï¼Œå¢å¼ºglobalçš„ä¿¡æ¯ï¼›è€ŒSE-Netåˆ™æ˜¯å¼ºè°ƒçš„channelä¹‹é—´çš„è”ç³»ï¼Œå¹¶æ²¡æœ‰è€ƒè™‘channelå†…éƒ¨çš„å…³ç³»ï¼Œç›¸å½“äºGE-Netå…·æœ‰å…¨å±€æ„Ÿå—é‡ã€‚å¦‚æœGE-Netæœ‰å…¨å±€æ„Ÿå—é‡ï¼Œé‚£ä¹ˆä»–æ¯”SE-Netå°±å·®åœ¨channelä¹‹é—´çš„è”ç³»äº†ã€‚</p><hr><h2 id="PSANet-Point-wise-Spatial-Attention-Network-for-Scene-Parsing"><a href="#PSANet-Point-wise-Spatial-Attention-Network-for-Scene-Parsing" class="headerlink" title="[PSANet: Point-wise Spatial Attention Network for Scene Parsing]"></a>[PSANet: Point-wise Spatial Attention Network for Scene Parsing]</h2><p>æå‡ºå¦ä¸€ç§è§£å†³local constraintçš„æ–¹æ¡ˆï¼Œä¹Ÿå³ä½¿å¾—featureä¹‹é—´èƒ½å¤Ÿå»ºç«‹é•¿è·ç¦»ä¾èµ–ã€‚feature mapä¸Šçš„æ¯ä¸ªä½ç½®é€šè¿‡attention mapä¸å…¶ä»–ç‚¹è¿›è¡Œè¿æ¥ï¼ŒåŒæ—¶ä¿¡æ¯æµåŠ¨æ˜¯åŒå‘çš„ï¼Œæ¯ä¸ªç‚¹åŒæ—¶è¿›è¡Œæ”¶é›†ä¸åˆ†å‘çš„æ“ä½œã€‚</p><p>é€šå¸¸è€Œè¨€ï¼Œä¿¡æ¯çš„aggregationå¯ä»¥å½¢å¼åŒ–æˆï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F\left(\mathbf{x}_{i}, \mathbf{x}_{j}, \Delta_{i j}\right) \mathbf{x}_{j}</script><p>$\mathbf{z}_{i}$æ˜¯ç¬¬iä¸ªä½ç½®çš„è¾“å‡ºï¼›$\mathbf{x}_{j}$æ˜¯è¾“å…¥çš„feature map $X$ã€‚$\forall j \in \Omega(i)$ æ˜¯ä¸iç›¸å…³çš„æ‰€æœ‰ä½ç½®çš„featureé›†åˆã€‚$ F\left(\mathbf{x}_{i}, \mathbf{x}_{j}, \Delta_{i j}\right)$ ä»£è¡¨çš„æ˜¯jåˆ°içš„ä¿¡æ¯æµåŠ¨ã€‚$\Delta$ ä»£è¡¨çš„æ˜¯ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p><p>å¯ä»¥å°†ä¸Šè¿°å¼å­ç®€åŒ–ä¸ºï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \mathbf{x}_{j}</script><p>å…¶ä¸­$\left\{F_{\Delta_{i j}}\right\}$æ˜¯ä½ç½®ç›¸å…³çš„å‡½æ•°æ˜ å°„ã€‚</p><p>å½“ä¸€ä¸ªfeature mapçš„ä½ç½®å¾ˆå¤šæ—¶ï¼Œ$x_i$ä¸$x_j$çš„pairå°†ä¼šå¾ˆå¤§ã€‚</p><p>å› æ­¤å°†ä¸Šå¼å‡½æ•°æ˜ å°„ç®€åŒ–ä¸ºï¼š</p><script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)</script><p>ä¹Ÿå³$j$åˆ°$i$çš„ä¿¡æ¯æµåŠ¨åªä¸$i$ä½ç½®çš„featureä»¥åŠ$i$ä¸$j$ä¹‹é—´çš„ç›¸å¯¹ä½ç½®æœ‰å…³ã€‚</p><p>åŒç†ï¼Œè¿˜å¯ä»¥å°†å‡½æ•°æ˜ å°„ç®€åŒ–æˆï¼š</p><script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)</script><p>ä¹Ÿå³ä¿¡æ¯æµåŠ¨åªä¸$i$ä¸$j$çš„ç›¸å¯¹ä½ç½®ä»¥åŠ$j$ä½ç½®ä¸Šçš„featureæœ‰å…³ã€‚</p><p>å°†ä¸Šè¿°ä¸¤ä¸ªç®€åŒ–å‡½æ•°ç»“åˆèµ·æ¥ï¼Œå¯ä»¥è·å¾—åŒå‘ä¿¡æ¯ä¼ æ’­è·¯å¾„ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">F_{\Delta_{i j}}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) \approx F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)+F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)</script><p>æ­¤æ—¶æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right) \mathbf{x}_{j}+\frac{1}{N} \sum_{\forall j \in \Omega(i)} F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right) \mathbf{x}_{j}</script><p>ç¬¬ä¸€é¡¹$F_{\Delta_{i j}}\left(\mathbf{x}_{i}\right)$encodeäº†åœ¨å…¶ä»–ä½ç½®ä¸Šçš„ä¿¡æ¯åœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿå¸®åŠ©ä½ç½®iï¼ˆé€šè¿‡ä½ç½®içš„featureä»¥åŠç›¸å¯¹ä½ç½®ï¼‰ã€‚</p><p>ç¬¬äºŒé¡¹$F_{\Delta_{i j}}\left(\mathbf{x}_{j}\right)$æ‰€åšçš„ä¹Ÿå³é¢„æµ‹å…¶ä»–ä½ç½®ä¸Šçš„featureçš„é‡è¦æ€§ï¼ˆé€šè¿‡ç›¸å¯¹ä½ç½®ï¼Œä»¥åŠä½ç½®jçš„featureï¼‰ã€‚</p><p>å¦‚ä¸‹å›¾ï¼š</p><p><img src="/images/15576301327447.jpg" width="70%" height="50%"></p><p>ä¸Šè¿°ä¸¤ä¸ªFå®é™…ä¸Šå¯ä»¥çœ‹åšæ˜¯åœ¨é¢„æµ‹ä¸€ä¸ªattentionçš„å€¼ï¼Œå»åšaggregationã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\mathbf{z}_{i}=\frac{1}{N} \sum_{\forall j} \mathbf{a}_{i, j}^{c} \mathbf{x}_{j}+\frac{1}{N} \sum_{\forall j} \mathbf{a}_{i, j}^{d} \mathbf{x}_{j}</script><p>é—®é¢˜åœ¨äºå¦‚ä½•è·å¾—aï¼Ÿ<br>ä¸‹å›¾æ˜¯è¾ƒä¸ºæ¸…æ™°çš„ä¸€ä¸ªæ¡†æ¶å›¾ï¼š</p><p><img src="/images/15576302667770.jpg" width="70%" height="50%"></p><p>å¯ä»¥çœ‹å‡ºæ˜¯é€šè¿‡å¤šä¸ªCNNæ¥è·å¾—attentionçŸ©é˜µçš„ã€‚</p><p>ä¸Šä¸‹ä¸¤æ¡çº¿å¾ˆç±»ä¼¼ã€‚ç¬¬ä¸€æ­¥æ˜¯å…ˆå‹ç¼©channelä»¥å‡å°‘è®¡ç®—é‡ï¼ˆC2&lt;C1)ã€‚ç¬¬äºŒæ­¥æ‰©å±•channelä¸º$(2H-1)\times(2W-1)$ï¼Œä¸‹é¢è§£é‡Šä¸ºä»€ä¹ˆã€‚æ¥ä¸‹æ¥åœ¨é‡æ–°è·å¾—$H\times W$çš„channelç»´ï¼Œè¯¥channelç»´çš„æ¯ä¸€ç»´æ‰€ä»£è¡¨çš„å°±æ˜¯ä¸€ä¸ªfeatureï¼ˆå…±æœ‰$H\times W$ä¸ªfeatureï¼‰çš„attentionå€¼ã€‚æœ€åä¹˜èµ·æ¥å†concatä¸€ä¸‹ï¼Œè·å¾—æœ€åçš„outputã€‚</p><p>ä¸ºä»€ä¹ˆæ˜¯$(2H-1)\times(2W-1)$çš„channelç»´ï¼Œå› ä¸ºå¸Œæœ›å°†è¯¥featureå‰ªè£ä¸€ä¸‹å˜æˆ$H\times W$ï¼Œæ­£å¥½å¯ä»¥è¡¨ç¤ºç›¸å¯¹ä½ç½®ã€‚</p><p><img src="/images/15576304353141.jpg" width="80%" height="50%"></p><p>å¯¹äºä¸€ä¸ª$(2H-1)\times(2W-1)$çš„featureå¯ä»¥å±•å¼€æˆäºŒç»´çš„ï¼Œå…¶ä¸­ä½ç½®iä¸ºä¸­å¿ƒï¼Œä»…æœ‰$H\times W$ä¸ªæœ‰ç”¨ã€‚å…·ä½“è€Œè¨€,åœ¨ç¬¬kè¡Œç¬¬låˆ—çš„ä½ç½®iï¼Œåˆ™æœ‰ç”¨çš„çŸ©é˜µæ˜¯ä»$H-k$è¡Œå’Œ$W-l$åˆ—å¼€å§‹çš„ã€‚è¿™ä¸ªåšæ³•å€’æŒºæœ‰æ„æ€çš„ã€‚</p><p>ä¸NL-Netçš„å…³ç³»ï¼šNL-Netæ²¡æœ‰è€ƒè™‘ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p><p>æ€è€ƒï¼š<br>è¯¥æ–¹æ³•ä¼¼ä¹ç¡®å®ç›¸æ¯”NL-Netçš„è®¡ç®—é‡å°ï¼Œè™½ç„¶çœ‹èµ·æ¥ä¹Ÿå¾ˆå¤§ã€‚NL-Netçš„è®¡ç®—é‡æ˜¯(HW)^2ã€‚è€Œè¿™é‡Œçš„æ•°é‡çº§æ˜¯HWã€‚ç©¶å…¶åŸå› ï¼Œæ˜¯å› ä¸ºattentionæ˜¯é¢„æµ‹å‡ºæ¥çš„ã€‚</p><p>ä»è·å¾—attentionçŸ©é˜µçš„æ–¹å¼å¯ä»¥çœ‹å‡ºï¼Œchannelä¸channelä¹‹é—´æœ‰äº¤äº’ã€‚</p><p>attentionçŸ©é˜µæ˜¯é¢„æµ‹å‡ºæ¥çš„ï¼ˆ$1\times 1$çš„convolutionï¼‰ï¼Œè€Œä¸æ˜¯ä¸€å¯¹pairè®¡ç®—å‡ºæ¥çš„ã€‚ä¼¼ä¹å°±æ²¡é‚£ä¹ˆæœ‰é“ç†ã€‚</p><p><del>å¹¶ä¸”ï¼Œä¸Šä¸‹ä¸¤æ¡æ”¯çº¿çš„æ“ä½œéƒ½æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯å°†å…¶è§£é‡Šä¸ºåŒå‘ä¿¡æ¯æµåŠ¨ï¼›é‚£è¿˜å¯ä»¥è§£é‡ŠæˆåƒTransformeré‚£æ ·ï¼Œå¤šä¸ªheadï¼Œå°†åŒä¸€ä¸ªè¡¨ç¤ºæ˜ å°„åˆ°å¤šä¸ªéšç©ºé—´ä¸­å¢å¼ºè¡¨ç¤ºã€‚</del>ä¹‹å‰ç†è§£é”™äº†ã€</p><hr><h2 id="CCNet-Criss-Cross-Attention-for-Semantic-Segmentation"><a href="#CCNet-Criss-Cross-Attention-for-Semantic-Segmentation" class="headerlink" title="[CCNet: Criss-Cross Attention for Semantic Segmentation]"></a>[CCNet: Criss-Cross Attention for Semantic Segmentation]</h2><p>å¯¹NL-Netçš„æ”¹è¿›ï¼Œé€šè¿‡å¼•å…¥åå­—äº¤å‰çš„attentionå’Œrecurrentç»“æ„ï¼Œå‡å°‘äº†è®¡ç®—é‡ï¼ŒåŒæ—¶ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•è·é•¿è·ç¦»ä¾èµ–ï¼Œä»¥åŠæå‡äº†æ¨¡å‹è¡¨ç°ã€‚</p><p>Motivation:<br>NL-Netä¼šç”Ÿæˆä¸€ä¸ªå¾ˆå¤§çš„attention mapï¼Œå…¶å¤æ‚åº¦ä¸º${\mathcal{O}}((H \times W)\times(H \times W))$ã€‚</p><p>ä¸»è¦åšæ³•ï¼Œå°†è¯¥position-wiseçš„attentionåˆ†è§£æˆä¸¤æ­¥ï¼šç¬¬ä¸€æ­¥æ˜¯æ¯ä¸ªç‚¹åªå’Œå…¶åŒä¸€è¡Œå’ŒåŒä¸€åˆ—çš„è¿›è¡Œattentionï¼Œå°†attentionçš„æ“ä½œå¾ªç¯å¤šæ¬¡ï¼Œè¾¾åˆ°æ¯ä¸ªç‚¹é—´æ¥å’Œå…¶ä»–ç‚¹éƒ½åšäº†attentionã€‚å…¶å¤æ‚åº¦åˆ™ä¸º $\mathcal{O}((H \times W) \times(H+W-1))$</p><p>ä¸¤ç§æ–¹æ³•çš„å¯¹æ¯”ï¼š</p><p><img src="/images/15576307417016.jpg" width="50%" height="50%"></p><p>æ³¨æ„åˆ°recurrentçš„ç»“æ„ä¸­å‚æ•°æ˜¯å…±äº«çš„ã€‚</p><p>å…·ä½“çš„æ¡†æ¶ï¼š</p><p><img src="/images/15576307988403.jpg" width="80%" height="50%"></p><p>å…ˆè¿›è¡Œé™ç»´ï¼Œåšå®Œcriss-cross attentionåçš„outputä¸åŸå…ˆçš„xæ‹¼èµ·æ¥ï¼Œå†è¿‡CNNç­‰è¿›è¡Œèåˆã€‚</p><h3 id="Criss-Cross-Attention"><a href="#Criss-Cross-Attention" class="headerlink" title="Criss-Cross Attention"></a>Criss-Cross Attention</h3><p><img src="/images/15576308514373.jpg" width="50%" height="50%"></p><p>è¿‡ä¸‰ä¸ªçº¿æ€§å±‚å¾—åˆ°QKVï¼ˆå’Œtransformerç±»ä¼¼ï¼‰ï¼›æ¥ç€Qä¸Kåšçºµæ¨ªäº¤å‰çš„attentionï¼Œè·å¾—softmaxï¼Œæ¥ç€å†å’ŒVå¯¹åº”çš„ä½ç½®ç›¸ä¹˜ã€‚</p><p>å…·ä½“è€Œè¨€ï¼š<br>è¾“å…¥ï¼š$\mathbf{H} \in \mathbb{R}^{C \times W \times H}$<br>è¿‡çº¿æ€§å±‚ï¼š$\{\mathbf{Q}, \mathbf{K}\} \in \mathbb{R}^{C^{\prime} \times W \times H}$<br>attentionåˆ†æ•°ï¼š$\mathbf{A} \in \mathbb{R}^{(H+W-1) \times W \times H}$<br>ä¸uå…ƒç´ åšattentionçš„featureé›†åˆï¼Œä¹Ÿå³åŒä¸€è¡Œæˆ–åŒä¸€åˆ—çš„featureï¼š$\boldsymbol{\Omega}_{\mathbf{u}} \in \mathbb{R}^{(H+W-1) \times C^{\prime}} \cdot \mathbf{\Omega}_{\mathbf{i}, \mathbf{u}} \in \mathbb{R}^{C^{\prime}}$<br>åšattentionï¼š$d_{i, u}=\mathbf{Q}_{\mathbf{u}} \mathbf{\Omega}_{\mathbf{i}, \mathbf{u}^{\top}}$<br>å†åšsoftmaxï¼Œæœ€ç»ˆè·å¾—outputï¼š$\mathbf{H}_{\mathbf{u}}^{\prime}=\sum_{i \in\left|\mathbf{\Phi}_{\mathbf{u}}\right|} \mathbf{A}_{\mathbf{i}, \mathbf{u}} \mathbf{\Phi}_{\mathbf{i}, \mathbf{u}}+\mathbf{H}_{\mathbf{u}}$<br>$\boldsymbol{\Phi}_{\mathbf{i}, \mathbf{u}}$ä¸$\boldsymbol{\Omega}_{\mathbf{u}}$æ˜¯åŒä¸€é›†åˆã€‚</p><h3 id="Recurrent-Criss-Cross-Attention"><a href="#Recurrent-Criss-Cross-Attention" class="headerlink" title="Recurrent Criss-Cross Attention"></a>Recurrent Criss-Cross Attention</h3><p>å¤šåšå‡ æ¬¡ï¼Œæ¯æ¬¡éƒ½å…±äº«ï¼Œå°±æ˜¯recurrentäº†ã€‚<br>å½“å¾ªç¯æ¬¡æ•°æ˜¯2æ—¶ï¼Œæ¯ä¸ªç‚¹éƒ½èƒ½å¤Ÿattendåˆ°å…¶ä»–ä»»ä½•ç‚¹äº†ã€‚</p><p><img src="/images/15576311079687.jpg" width="66%" height="50%"></p><p>æ€è€ƒï¼š<br>é€šè¿‡çºµæ¨ªæ¥é—´æ¥attendåˆ°æ‰€æœ‰ç‚¹ï¼Œè¿™ä¸ªæƒ³æ³•è¿˜è›®æœ‰è¶£çš„ã€‚å¹¶ä¸”å‡å°‘äº†è®¡ç®—é‡ã€‚å°±æ˜¯è¿™ç§çºµæ¨ªçš„æ–¹æ³•ä»£ç è¦æ€ä¹ˆå®ç°ï¼Ÿæœ‰äº›å¥½å¥‡ã€‚<br>åŒæ—¶æœ¬æ–‡çš„å›¾ä¹Ÿå¾ˆæ¼‚äº®ï¼Œæ¯ä¸ªå›¾éƒ½æ°åˆ°å¥½å¤„ï¼Œå¯ä»¥é€šè¿‡å›¾å°±å¤§è‡´ç†è§£æœ¬æ–‡åœ¨è®²ä»€ä¹ˆã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Classification </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> LSTM </tag>
            
            <tag> Language Modeling </tag>
            
            <tag> pretrain </tag>
            
            <tag> long-term dependency </tag>
            
            <tag> GC-Net </tag>
            
            <tag> Ordered Neuron </tag>
            
            <tag> GPT </tag>
            
            <tag> GE-Net </tag>
            
            <tag> PSANet </tag>
            
            <tag> CCNet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Macä¸Šå¾ˆå¥½ç”¨çš„è½¯ä»¶æ¨è</title>
      <link href="/2019/05/07/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E4%B8%8A%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/"/>
      <url>/2019/05/07/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E4%B8%8A%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<p>è®°å½•ä¸ªäººè§‰å¾—å¾ˆå¥½ç”¨çš„Macè½¯ä»¶ï¼Œè®©Macä½œä¸ºï¼ˆç¨‹åºå‘˜ğŸ‘¨â€ğŸ’»â€/ç§‘ç ”äººå‘˜ğŸ‘¨â€ğŸ”¬ï¼‰ç”Ÿäº§åŠ›å·¥å…·æ›´é¡ºæ‰‹ï¼Œæå‡ç”Ÿäº§æ•ˆç‡ã€‚</p><h3 id="Alfred3"><a href="#Alfred3" class="headerlink" title="[Alfred3]"></a>[Alfred3]</h3><p>ç½‘ä¸Šæœ‰å¤ªå¤šæ¨èAlfredçš„äº†ï¼Œæˆ‘ä¸»è¦æ˜¯ç”¨Alfredåšä¸€äº›å¸¸è§„æ“ä½œï¼Œå¦‚æ‰“å¼€/æœç´¢æ–‡ä»¶ï¼Œæ–‡æœ¬æ‰©å±•ç­‰ï¼Œä»¥åŠä¸€äº›workflowï¼Œå¦‚æœ‰é“ç¿»è¯‘ã€‚</p><p><img src="/images/15572414068036.jpg" width="50%" height="50%"></p><h3 id="SwitchResX"><a href="#SwitchResX" class="headerlink" title="[SwitchResX]"></a>[SwitchResX]</h3><p>ç”¨äºæ˜¾ç¤ºå™¨çš„è°ƒæ•´ï¼Œå¯¹äºæˆ‘è€Œè¨€ä¸»è¦ç”¨äºå¤–æ¥å±å¹•å¼€å¯HiDPIã€‚éå¸¸å¥½ç”¨ï¼</p><p><img src="/images/15572767190389.jpg" width="100%" height="50%"></p><p>å¦‚ä½•å¼€å¯HiDPIï¼š<br><a href="https://www.zhihu.com/question/35300978/answer/126332986" target="_blank" rel="noopener">https://www.zhihu.com/question/35300978/answer/126332986</a></p><h3 id="gfxCardStatus"><a href="#gfxCardStatus" class="headerlink" title="[gfxCardStatus]"></a>[gfxCardStatus]</h3><p>ç”¨äºåˆ‡æ¢å¤–æ¥æ˜¾å¡å’Œç‹¬ç«‹æ˜¾å¡ã€‚èƒ½å¤Ÿåœ¨menu barä¸Šè°ƒæ•´ï¼Œæ¯”æ¯æ¬¡è¿›å…¥system preferenceè®¾ç½®æ–¹ä¾¿ä¸€äº›ã€‚</p><p><img src="/images/15572214150588.jpg" width="25%" height="50%"></p><h3 id="Mendeley"><a href="#Mendeley" class="headerlink" title="[Mendeley]"></a>[Mendeley]</h3><p>æ–‡çŒ®ç®¡ç†å·¥å…·ï¼Œæœ‰ä¸°å¯Œçš„åŠŸèƒ½å’ŒåŒæ­¥åŠŸèƒ½ã€‚å¤šå¹³å°ä¸”å…è´¹ï¼Œå¾ˆçœå¿ƒã€‚</p><p><img src="/images/15572214826817.jpg" width="100%" height="50%"></p><h3 id="Bartender3"><a href="#Bartender3" class="headerlink" title="[Bartender3]"></a>[Bartender3]</h3><p>å¦‚æœå¤ªå¤šå›¾æ ‡éƒ½æ˜¾ç¤ºåœ¨menu barä¸Šï¼Œä¼šå½±å“è§‚æ„Ÿï¼Œä¸èƒ½ä¸€ä¸‹å­æ‰¾åˆ°è‡ªå·±æƒ³è¦çš„ä¸œè¥¿ã€‚ä½¿ç”¨Bartender3èƒ½å¤Ÿéšè—éƒ¨åˆ†å›¾æ ‡ï¼Œå¹¶ä¸”å¾ˆä¼˜é›…ã€‚</p><p>éšè—çŠ¶æ€ï¼š<br><img src="/images/15572217046758.jpg" width="60%" height="50%"></p><p>å±•å¼€çŠ¶æ€ï¼š<br><img src="/images/15572217330397.jpg" width="25%" height="50%"></p><h3 id="Todoist"><a href="#Todoist" class="headerlink" title="[Todoist]"></a>[Todoist]</h3><p>å­˜æ”¾è¦å®Œæˆçš„äº‹åŠ¡ï¼Œè¿˜å¯ä»¥å­˜æ”¾ä¸€äº›å…¶ä»–çš„ä¸œè¥¿ã€‚ç•Œé¢éå¸¸å¥½çœ‹ï¼ŒåŠŸèƒ½ä¸°å¯Œï¼Œå¹¶ä¸”ä¹Ÿæ˜¯å…¨å¹³å°çš„ã€‚ä»˜è´¹ï¼Œä½†å®Œå…¨å€¼å¾—ã€‚å¯¹æˆ‘è€Œè¨€Todoistå¸®åŠ©æˆ‘å°†å·¥ä½œæ•´ç†å¾—äº•äº•æœ‰æ¡ã€‚é™¤äº†å·¥ä½œï¼Œæˆ‘è¿˜ä¼šä¿å­˜ä¸€äº›å…¶ä»–listï¼ˆå¦‚èœå•/æ„¿æœ›æ¸…å•ğŸ˜„ï¼‰ã€‚</p><p><img src="/images/15572221262487.jpg" width="90%" height="50%"></p><h3 id="MWeb"><a href="#MWeb" class="headerlink" title="[MWeb]"></a>[MWeb]</h3><p>Markdownå†™ä½œå·¥å…·ã€‚æˆ‘ç”¨è¿™ä¸ªè½¯ä»¶å†™æ‰€æœ‰çš„åšå®¢ï¼Œé¢œå€¼å¾ˆé«˜ï¼Œå¹¶ä¸”åŠŸèƒ½ä¹Ÿå¾ˆå¼ºå¤§ï¼Œèƒ½å¤Ÿå®æ—¶é¢„è§ˆæ•ˆæœã€‚æ’å…¥å›¾ç‰‡å’Œå…¬å¼éå¸¸éå¸¸æ–¹ä¾¿ã€‚</p><p><img src="/images/15572255396438.jpg" width="110%" height="60%"></p><h3 id="IINA"><a href="#IINA" class="headerlink" title="[IINA]"></a>[IINA]</h3><p>Macä¸Šæœ€å¥½ç”¨çš„æ’­æ”¾å™¨ã€‚</p><p><img src="/images/15572256826384.jpg" width="80%" height="50%"></p><h3 id="VMware-Fusion"><a href="#VMware-Fusion" class="headerlink" title="[VMware Fusion]"></a>[VMware Fusion]</h3><p>å¶å°”éœ€è¦ç”¨åˆ°è™šæ‹Ÿæœºï¼Œå¯ä»¥æ— ç¼åˆ‡æ¢å¤šç³»ç»Ÿã€‚</p><p><img src="/images/15572258471958.jpg" width="100%" height="50%"></p><h3 id="Dash"><a href="#Dash" class="headerlink" title="[Dash]"></a>[Dash]</h3><p>APIæµè§ˆå™¨ï¼Œä¸€ä¸ªçª—å£æŸ¥æ‰€æœ‰è¯­è¨€/åŒ…çš„APIã€‚</p><p><img src="/images/15572259911688.jpg" width="80%" height="50%"></p><h3 id="Cinch"><a href="#Cinch" class="headerlink" title="[Cinch]"></a>[Cinch]</h3><p>[Deprecated]</p><p><del>Macä¸Šçš„åˆ†å±ç¡®å®ä¸å¦‚Windowsä¸Šçš„å¥½ç”¨ï¼ŒCinchè‡´åŠ›äºåœ¨Macä¸Šä¹Ÿæœ‰Windowsçš„åˆ†å±ä½“éªŒã€‚å°†çª—å£å‘ä¸Šæ‹–æˆ–å‘ä¸¤è¾¹æ‹–ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å…¨å±æˆ–è€…åˆ†å±ã€‚</del> å¯¹å¤šå±å¹•ä¸æ˜¯å¾ˆå‹å¥½ï¼Œå¦‚æœæ˜¯å‘å³æ‹–åˆ†å±å¯èƒ½ä¼šæ‹–åˆ°å¤–æ¥å±å¹•ä¸Šã€‚</p><!--<img src="/images/15572261520468.jpg" width="100%" height="50%">--><h3 id="Moom"><a href="#Moom" class="headerlink" title="[Moom]"></a>[Moom]</h3><p>åŠŸèƒ½æå…¶å¼ºå¤§çš„åˆ†å±åº”ç”¨ã€‚æ—¢é€‚åˆæ™®é€šé¼ æ ‡å…šä½¿ç”¨ï¼Œä¹Ÿæ”¯æŒé«˜åº¦å®šåˆ¶åŒ–é€‚åˆé”®ç›˜å…šçš„ä½¿ç”¨ã€‚</p><p><img src="/images/15613895824781.jpg" width="55%" height="50%"></p><p><a href="https://zhuanlan.zhihu.com/p/20258341" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20258341</a></p><h3 id="Mathpix-Snipping-Tool"><a href="#Mathpix-Snipping-Tool" class="headerlink" title="[Mathpix Snipping Tool]"></a>[Mathpix Snipping Tool]</h3><p>å¼ºçƒˆæ¨èè¿™æ¬¾è½¯ä»¶ï¼å†™åšå®¢æ—¶ç»å¸¸è¦æ’å…¥è®ºæ–‡é‡Œé¢çš„å…¬å¼ï¼Œå¦‚æœè‡ªå·±æ‰“ä¸ä»…éº»çƒ¦ï¼Œæœ‰äº›è¿˜ä¸çŸ¥é“æ€ä¹ˆæ‰“ã€‚Mathpixèƒ½å¤Ÿå°†æˆªå›¾è‡ªåŠ¨è½¬æ¢æˆå…¬å¼ï¼Œå¹¶ä¸”è¯†åˆ«ç‡æŒºé«˜ï¼Œçœäº†å¾ˆå¤šåŠ›æ°”ã€‚</p><p><img src="/images/15572263265931.jpg" width="70%" height="50%"></p><h3 id="Xnip"><a href="#Xnip" class="headerlink" title="[Xnip]"></a>[Xnip]</h3><p>ä¸€æ¬¾å¾ˆæ–¹ä¾¿çš„æˆªå›¾è½¯ä»¶ã€‚æä¾›äº†è®¸å¤šå¦‚é©¬èµ›å…‹ç”»å›¾çš„åŠŸèƒ½ï¼Œè¿˜æ”¯æŒæˆªé•¿å›¾ã€‚</p><h3 id="Paste"><a href="#Paste" class="headerlink" title="[Paste]"></a>[Paste]</h3><p>ä¿å­˜æ‰€æœ‰ä¹‹å‰å¤åˆ¶å†…å®¹çš„å†å²ï¼ŒåŒ…æ‹¬æ–‡æœ¬ï¼Œå›¾ç‰‡ï¼Œæ–‡ä»¶ç­‰ï¼Œè¿˜å¯ä»¥ä¿å­˜ä¸€äº›å¸¸ç”¨çš„å†…å®¹ã€‚å¹¶ä¸”å…¶æœ€å¤§çš„äº®ç‚¹åœ¨äºèƒ½å¤Ÿä¸iOSåŒæ­¥ï¼Œä¹Ÿå³åœ¨ä¸€ä¸ªå¹³å°å¤åˆ¶çš„å†…å®¹å¯ä»¥ç›´æ¥åœ¨å¦ä¸€ä¸ªå¹³å°ç”¨åˆ°ã€‚</p><p><img src="/images/15572265842706.jpg" width="100%" height="50%"></p><p><img src="/images/15572267155023.png" width="35%" height="50%"></p><h3 id="Transmit"><a href="#Transmit" class="headerlink" title="[Transmit]"></a>[Transmit]</h3><p>Macä¸ŠFTPåšå¾—å¾ˆå¥½çš„ä¸€ä¸ªè½¯ä»¶ï¼Œé¢œå€¼ä¹ŸæŒºé«˜ã€‚</p><p><img src="/images/15572269805499.jpg" width="100%" height="50%"></p><h3 id="iStat-Menus"><a href="#iStat-Menus" class="headerlink" title="[iStat Menus]"></a>[iStat Menus]</h3><p>ç›‘æ§ç³»ç»ŸçŠ¶æ€ï¼ˆCPU/GPU/å†…å­˜/ç½‘ç»œï¼‰çš„è½¯ä»¶ã€‚ç¨³å®šä¸”ç¾è§‚ã€‚æŒ‚åœ¨menu barä¸Šå¯ä»¥å¾ˆæ–¹ä¾¿æŸ¥çœ‹ã€‚</p><p><img src="/images/15572272550552.jpg" width="20%" height="50%"></p><p><img src="/images/istat.png" width="100%" height="50%"></p><h3 id="Downie3"><a href="#Downie3" class="headerlink" title="[Downie3]"></a>[Downie3]</h3><p>è½»é‡çº§çš„ä¸€ä¸ªä¸‹è½½è§†é¢‘çš„å·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨/æ‰‹åŠ¨æå–æµè§ˆå™¨çš„è§†é¢‘é“¾æ¥ã€‚</p><p><img src="/images/15572277461936.jpg" width="90%" height="50%"></p><h3 id="The-Unarchiver"><a href="#The-Unarchiver" class="headerlink" title="[The Unarchiver]"></a>[The Unarchiver]</h3><p>è½»é‡çº§çš„è§£å‹è½¯ä»¶ï¼Œè½»åˆ°ç”šè‡³æ„Ÿè§‰ä¸åˆ°ä»–çš„å­˜åœ¨ã€‚</p><h3 id="OneNote"><a href="#OneNote" class="headerlink" title="[OneNote]"></a>[OneNote]</h3><p>è®°ç¬”è®°çš„åˆ©å™¨ï¼Œofficeå¥—ä»¶ä¸­æˆ‘ç”¨å¾—æœ€é¢‘ç¹çš„è½¯ä»¶ã€‚è®°å½•è®ºæ–‡é˜…è¯»ç¬”è®°/æƒ³æ³•/å®éªŒã€‚ç‹¬ä¸€æ— äºŒçš„çµæ´»æ€§ï¼Œå¯ä»¥åœ¨é¡µé¢çš„ä»»ä½•åœ°æ–¹åˆ›å»ºç¬”è®°ï¼ˆæˆ‘è¯•äº†å¸‚é¢ä¸Šæ‰€æœ‰æµè¡Œçš„ç¬”è®°è½¯ä»¶ï¼Œéƒ½æ²¡æœ‰è¿™æ ·çš„çµæ´»æ€§ï¼‰ã€‚åŒæ—¶è¿˜æ˜¯å…¨å¹³å°ï¼Œè¿˜æ”¯æŒç¬”ï¼Œåœ¨iPadä¸Šçš„ç¬”è¿¹å¯ä»¥å¾ˆå¿«é€ŸåŒæ­¥åˆ°Macä¸Šã€‚å½“ç„¶ç›®å‰è€Œè¨€åŠŸèƒ½è¿˜æ²¡æœ‰Windowsä¸Šçš„OneNoteé‚£ä¹ˆå¼ºå¤§ã€‚</p><p><img src="/images/15572281358175.jpg" width="90%" height="50%"></p><h3 id="Maipo"><a href="#Maipo" class="headerlink" title="[Maipo]"></a>[Maipo]</h3><p>Macç«¯å¾ˆä¸é”™çš„å¾®åšå®¢æˆ·ç«¯ã€‚å¯ä»¥å¾ˆæ–¹ä¾¿åœ°åœ¨ç”µè„‘ç«¯åˆ·å¾®åšå­¦ä¹ ï¼ˆå¤§é›¾ ã€‚</p><p><img src="/images/15572363838509.jpg" width="70%" height="50%"></p><h3 id="linux-command"><a href="#linux-command" class="headerlink" title="[linux-command]"></a>[linux-command]</h3><p>æ–¹ä¾¿æœç´¢Linuxå‘½ä»¤ã€‚</p><p><img src="/images/15572363564485.jpg" width="90%" height="50%"></p><h3 id="iTerm"><a href="#iTerm" class="headerlink" title="[iTerm]"></a>[iTerm]</h3><p>å‘½ä»¤è¡Œæ˜¯ğŸ‘¨â€ğŸ’»â€å¿…å¤‡ã€‚è€ŒiTermç›¸å¯¹åŸç”Ÿterminalæœ‰æ›´ä¸°å¯Œçš„è®¾ç½®ä»¥åŠæ›´å¼ºå¤§çš„åŠŸèƒ½ã€‚</p><p><img src="/images/15572775111514.jpg" width="90%" height="50%"></p><h3 id="AppCleaner"><a href="#AppCleaner" class="headerlink" title="[AppCleaner]"></a>[AppCleaner]</h3><p>è½»æ¾åœ°åˆ é™¤Macè½¯ä»¶ï¼Œå¯ä»¥æ£€æµ‹è¯¥è½¯ä»¶æ‰€å¸¦çš„å…¶ä»–æ–‡ä»¶ï¼Œä¸€å¹¶åˆ é™¤ã€‚é…åˆAlfredçš„workflowå¾ˆæ–¹ä¾¿ã€‚</p><p><img src="/images/15572414475923.jpg" width="70%" height="50%"></p><h3 id="Mos"><a href="#Mos" class="headerlink" title="[Mos]"></a>[Mos]</h3><p>Macçš„è§¦æ§æ¿å’Œé¼ æ ‡çš„é€»è¾‘æ˜¯åçš„ã€‚å¦‚æœå¸Œæœ›è§¦æ§æ¿å’Œé¼ æ ‡ä¸€èµ·ç”¨ï¼Œå¹¶ä¸”é€»è¾‘å„ä¸ç›¸åŒï¼Œåˆ™å¯ä»¥ä½¿ç”¨Mosï¼ŒMosèƒ½å¤Ÿå°†é¼ æ ‡ç¿»è½¬ã€‚</p><p><img src="/images/15572415681851.jpg" width="70%" height="50%"></p><h3 id="PDF-Expert"><a href="#PDF-Expert" class="headerlink" title="[PDF Expert]"></a>[PDF Expert]</h3><p>å¼ºçƒˆæ¨èçš„PDFé˜…è¯»ç¼–è¾‘è½¯ä»¶ã€‚ç®€å•æ˜“ç”¨ï¼Œå¹¶ä¸”åŠŸèƒ½ä¹Ÿè¶³å¤Ÿå¼ºå¤§ã€‚å¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯å¯ä»¥å¤šå¹³å°åŒæ­¥ï¼ˆMac/iOSï¼‰ï¼Œè¿˜å¯ä»¥ä½¿ç”¨â€æ¥åŠ›â€œåŠŸèƒ½ï¼Œå‡å°‘åˆ‡æ¢è®¾å¤‡çš„éº»çƒ¦ã€‚</p><p><img src="/images/15572417246059.jpg" width="80%" height="50%"></p><h3 id="Contexts"><a href="#Contexts" class="headerlink" title="[Contexts]"></a>[Contexts]</h3><p>å¿«é€Ÿåˆ‡æ¢çª—å£çš„æ•ˆç‡å·¥å…·ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤šæ˜¾ç¤ºå™¨çš„æƒ…å†µä¸‹ï¼Œå¾€å¾€ä¼šæ‰¾ä¸åˆ°æƒ³è¦çš„çª—å£ã€‚å¯¹æˆ‘è€Œè¨€ï¼ŒContextsæå¤§å¢åŠ äº†æ•ˆç‡ã€‚è°ƒå‡ºçª—å£åˆ—è¡¨ï¼Œæ¥ç€æœç´¢å³å¯ï¼Œè¿˜å¯ä»¥é€šè¿‡é¼ æ ‡ç‚¹å‡»å±å¹•è¾¹ä¸Šçš„æµ®åŠ¨çª—å£åˆ‡æ¢ã€‚</p><p><img src="/images/context.png" width="90%" height="50%"></p><h3 id="SnippetsLab"><a href="#SnippetsLab" class="headerlink" title="[SnippetsLab]"></a>[SnippetsLab]</h3><p>æ”¶è—ä¸€äº›æœ‰ç”¨çš„ä»£ç ç‰‡æ®µã€‚ä¿æŒè®°å½•çš„ä¹ æƒ¯èƒ½å¤Ÿæé«˜ä»£ç æ•ˆç‡ã€‚</p><p><img src="/images/15572422193062.jpg" width="100%" height="50%"></p><h3 id="Sublime-Text"><a href="#Sublime-Text" class="headerlink" title="[Sublime Text]"></a>[Sublime Text]</h3><p>ä¸éœ€è¦æ¨èï¼Œå¤§åé¼é¼çš„æ–‡æœ¬ç¼–è¾‘è½¯ä»¶ã€‚ğŸ‘¨â€ğŸ’»â€å¿…å¤‡ã€‚</p><h3 id="AdGuard-for-Safari"><a href="#AdGuard-for-Safari" class="headerlink" title="[AdGuard for Safari]"></a>[AdGuard for Safari]</h3><p>å› ä¸ºSafariçš„è½»é‡ä»¥åŠé¢œå€¼æ”¾å¼ƒäº†ä½¿ç”¨å¾ˆä¹…çš„Chromeï¼Œä½†ä¹Ÿæ„å‘³ç€æ”¾å¼ƒäº†ä¸°å¯Œçš„æµè§ˆå™¨æ’ä»¶ã€‚åœ¨Chromeå¯ä»¥ä½¿ç”¨AdBlockï¼Œåœ¨Safariåˆ™å¯ä»¥ä½¿ç”¨AdGuardï¼Œéå¸¸è½»é‡ï¼Œç”šè‡³æ„Ÿè§‰ä¸åˆ°å®ƒçš„å­˜åœ¨ã€‚</p><h3 id="CatchMouse"><a href="#CatchMouse" class="headerlink" title="[CatchMouse]"></a>[CatchMouse]</h3><p>é’ˆå¯¹å¤šå±å¹•è€Œè®¾è®¡ã€‚æœ‰æ—¶å€™ä¼šæ‰¾ä¸åˆ°é¼ æ ‡åœ¨å“ªä¸ªå±å¹•ã€‚é€šè¿‡è®¾ç½®å¿«æ·é”®ï¼Œèƒ½å¤Ÿå¿«é€Ÿå°†é¼ æ ‡ç§»åŠ¨åˆ°æŒ‡å®šå±å¹•ï¼Œåœ¨åˆ‡æ¢çš„æ—¶å€™è¿˜ä¼šç¼©æ”¾é¼ æ ‡çš„å›¾æ ‡ä½œä¸ºæé†’ã€‚ï¼ˆæ‰¾äº†å¥½ä¹…æ‰æ‰¾åˆ°è¿™ä¸ªç¬¦åˆæˆ‘éœ€æ±‚çš„è½¯ä»¶ï¼‰</p><p><img src="/images/15572424938492.jpg" width="60%" height="50%"></p><p><img src="/images/15572425907175.jpg" width="60%" height="50%"></p><h3 id="Zoom"><a href="#Zoom" class="headerlink" title="[Zoom]"></a>[Zoom]</h3><p>ä¼šè®®ç”µè¯çš„è½¯ä»¶ã€‚å¼€è¿œç¨‹PaperReadingå¯ä»¥ç”¨ğŸŒšã€‚</p><h3 id="Mate-Translate"><a href="#Mate-Translate" class="headerlink" title="[Mate Translate]"></a>[Mate Translate]</h3><p>é›†æˆåœ¨å³é”®çš„ç¿»è¯‘å·¥å…·ã€‚åœ¨çœ‹è®ºæ–‡æˆ–è€…æµè§ˆç½‘é¡µæ—¶å¯ä»¥éšæ—¶ç¿»è¯‘å¥å­ã€‚</p><p><img src="/images/15592926038793.jpg" width="40%" height="50%"></p><p><img src="/images/15592926623566.jpg" width="55%" height="50%"></p><h3 id="ToothFairy"><a href="#ToothFairy" class="headerlink" title="[ToothFairy]"></a>[ToothFairy]</h3><p>ä¸€é”®è¿æ¥è“ç‰™è®¾å¤‡çš„åº”ç”¨ã€‚é©»æ‰åœ¨MenuBarä¸Šå¯ä»¥ä¸€é”®è¿æ¥è‡ªå·±çš„è“ç‰™è®¾å¤‡ã€‚æˆ‘ä¸€èˆ¬ç”¨äºè¿æ¥æ— çº¿è“ç‰™è€³æœºï¼ˆXM3ï¼‰å’ŒAirpodsã€‚</p><p><img src="/images/15613850296455.jpg" width="10%" height="50%"></p><h3 id="Quicklookæ’ä»¶"><a href="#Quicklookæ’ä»¶" class="headerlink" title="[Quicklookæ’ä»¶]"></a>[Quicklookæ’ä»¶]</h3><p>Macä¸Šä¸€ä¸ªå¾ˆäººæ€§åŒ–çš„æ“ä½œå°±æ˜¯å¯ä»¥ç©ºæ ¼é¢„è§ˆã€‚ä½†å¯¹äºä¸€äº›æ ¼å¼æ”¯æŒè¿˜ä¸å¤Ÿå¥½ï¼Œæ¯”å¦‚æ— æ‰©å±•åçš„æ— æ³•æ”¯æŒé¢„è§ˆï¼ŒMarkdownåªèƒ½é¢„è§ˆæºä»£ç ï¼Œé¢„è§ˆæºä»£ç åªæ”¯æŒé¢„è§ˆçº¯æ–‡æœ¬ï¼Œå¹¶æ²¡æœ‰é«˜äº®æ˜¾ç¤ºã€‚å› æ­¤Quicklookæ’ä»¶å¯ä»¥è§£å†³è¿™äº›ç»†èŠ‚é—®é¢˜ã€‚</p><p><a href="https://github.com/sindresorhus/quick-look-plugins" target="_blank" rel="noopener">https://github.com/sindresorhus/quick-look-plugins</a></p><p>é¢„è§ˆMarkdownï¼š</p><p><img src="/images/15613853773728.jpg" width="50%" height="50%"></p><p>é¢„è§ˆæ— æ‰©å±•åçš„çº¯æ–‡æœ¬ï¼š</p><p><img src="/images/15613855291056.jpg" width="60%" height="50%"></p><hr><p>æœ€åæ™’æ™’è‡ªå·±çš„å·¥ä½œå°â˜ºï¸ï¼ˆæœ¬ç§‘ä¸€ç›´å¿ƒå¿ƒå¿µå¿µçš„å·¥ä½œå°ï¼Œä¼¼ä¹ç»ˆäºè¾¾æˆäº†ï¼Œè™½ç„¶æ¡Œé¢å¤§å°è¿˜æ˜¯å°äº†ä¸€äº›ï¼‰ã€‚æœ‰å¥½çš„ç”Ÿäº§å·¥å…·çœŸæ˜¯å¯ä»¥è®©å·¥ä½œå˜æˆä¸€ç§äº«å—ğŸ˜„ï¼Œå¼€å¿ƒã€‚</p><p><img src="/images/15572429074807.jpg" width="90%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> Mac </tag>
            
            <tag> app </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºtransformer-xlä¸­rel-shiftå®ç°çš„è§£è¯»</title>
      <link href="/2019/05/07/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E5%85%B3%E4%BA%8Etransformer-xl%E4%B8%ADrel-shift%E5%AE%9E%E7%8E%B0%E7%9A%84%E8%A7%A3%E8%AF%BB/"/>
      <url>/2019/05/07/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E5%85%B3%E4%BA%8Etransformer-xl%E4%B8%ADrel-shift%E5%AE%9E%E7%8E%B0%E7%9A%84%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h4 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h4><p>transformer-xlä¸­æœ‰ä¸€æ­¥ä½¿ç”¨ç›¸å¯¹ä½ç½®è®¡ç®—attention weightï¼š</p><p>$\mathbf{A}_{i, j}^{\mathrm{rel}}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(b)}+\underbrace{u^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{v^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(d)}$</p><p>ç”±äºç›¸å¯¹ä½ç½®è¦è®¡ç®—æ‰€æœ‰çš„queryä¸keyå¯¹ï¼Œå› æ­¤æ˜¯å¹³æ–¹çš„å¤æ‚åº¦ã€‚è€Œåœ¨è®ºæ–‡çš„é™„å½•ä¸­æåˆ°å¯ä»¥é€šè¿‡ç®€å•çš„æ¨å¯¼å°†å¤æ‚åº¦é™ä¸ºçº¿æ€§ã€‚<br>ç®€å•åœ°è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›è·å¾—ï¼š<br>$\mathbf{B} = \left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}} &amp; {0} &amp; {\cdots} &amp; {0} \\ {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+1}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{1}} &amp; {q_{1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}} &amp; {\cdots} &amp; {0} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+L-1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{M+L-1}} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{L-1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{W}_{k, R} \mathbf{R}_{0}}\end{array}\right] \\  = \left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{Q}_{L-1}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M+L-1}} &amp; {0} &amp; {\cdots} &amp; {0} \\ {q_{1}^{\top} \mathbf{Q}_{L-2}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-2}} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-1}} &amp; {\cdots} &amp; {0} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M}} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+L-1}}\end{array}\right]$</p><p>å…¶ä¸­ï¼š<br>$\mathbf{Q} :=\left[ \begin{array}{c}{\mathbf{R}_{M+L-1}^{\top}} \\ {\mathbf{R}_{M+L-2}^{\top}} \\ {\vdots} \\ {\mathbf{R}_{1}^{\top}} \\ {\mathbf{R}_{0}^{\top}}\end{array}\right] \mathbf{W}_{k, R}^{\top}=\left[ \begin{array}{c}{\left[\mathbf{W}_{k, R} \mathbf{R}_{M+L-1}\right]^{\top}} \\ {\vdots} \\ {\vdots} \\ {\left[\mathbf{W}_{k, R} \mathbf{R}_{1}\right]^{\top}} \\ {\left[\mathbf{W}_{k, R} \mathbf{R}_{0}\right]^{\top}}\end{array}\right] \in \mathbb{R}^{(M+L) \times d}$</p><p>è€Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è·å¾—çš„æ˜¯ï¼š<br>$\tilde{\mathbf{B}}=\mathbf{q} \mathbf{Q}^{\top}=\left[ \begin{array}{cccccc}{q_{0}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M}} &amp; {q_{0}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{0}^{\top} \mathbf{Q}_{M+L-1}} \\ {q_{1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M}} &amp; {q_{1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{1}^{\top} \mathbf{Q}_{M+L-1}} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {q_{L-1}^{\top} \mathbf{Q}_{0}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M}} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+1}} &amp; {\cdots} &amp; {q_{L-1}^{\top} \mathbf{Q}_{M+L-1}}\end{array}\right]<br>$</p><p>$\tilde{\mathbf{B}}$ä¸$\mathbf{B}$çš„åŒºåˆ«åœ¨äº$\tilde{\mathbf{B}}$æ˜¯$\mathbf{B}$çš„left-shiftedç‰ˆæœ¬ï¼Œå…¶ä¸­ç¬¬ä¸€è¡Œå·¦ç§»äº†L-1ï¼Œåé¢æ¯è¡Œä¾æ¬¡é€’å‡å·¦ç§»ä¸ªæ•°ï¼Œæœ€åä¸€è¡Œåˆ™ä¸å·¦ç§»ã€‚</p><h4 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h4><p>æŠ½è±¡åœ°çœ‹ï¼Œæˆ‘ä»¬è¦åšçš„äº‹æƒ…å°±æ˜¯ï¼Œç»™å®šä¸€ä¸ªçŸ©é˜µï¼Œæ¯è¡Œéƒ½è¿›è¡Œå·¦ç§»ï¼Œè€Œç§»åŠ¨çš„ä¸ªæ•°éšè¡Œæ•°é€’å¢è€Œé€’å‡ã€‚</p><p>æˆ‘ç›®å‰æƒ³åˆ°çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨gatherï¼Œå°†æƒ³è¦çš„indexæå‰å®šå¥½ï¼Œç„¶åä½¿ç”¨Pytorchçš„gatherå°±èƒ½å¤Ÿå®ç°ã€‚</p><p>è€Œtransformer-xlå®ç°äº†å¦ä¸€ç§æ›´å¥½çš„æ–¹æ³•ï¼š<code>_rel_shift</code>ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_rel_shift</span><span class="params">(self, x, zero_triu=False)</span>:</span></span><br><span class="line">    <span class="comment"># x: q,k,bs,n_head</span></span><br><span class="line">    zero_pad = torch.zeros((x.size(<span class="number">0</span>), <span class="number">1</span>, *x.size()[<span class="number">2</span>:]),</span><br><span class="line">                           device=x.device, dtype=x.dtype)</span><br><span class="line">    x_padded = torch.cat([zero_pad, x], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x_padded = x_padded.view(x.size(<span class="number">1</span>) + <span class="number">1</span>, x.size(<span class="number">0</span>), *x.size()[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line">    x = x_padded[<span class="number">1</span>:].view_as(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>ç¬¬ä¸€æ­¥æ˜¯ï¼Œå°†xçš„ç¬¬ä¸€åˆ—å¡«ä¸Špaddingï¼Œæ­¤æ—¶<code>x.size()=q,k+1,bs,n_head</code>ï¼Œæ¥ä¸‹æ¥å°†å…¶é‡æ–°reshapeï¼Œåˆ™å˜æˆäº†<code>x.size()=k+1,q,bs,n_head</code>ï¼Œæœ€åå°†ç¬¬ä¸€è¡Œå»æ‰ï¼Œå˜æˆ<code>x.size()=k,q,bs,n_head</code>ï¼Œå†å°†å…¶reshapeå›xåŸæ¥çš„æ ·å­ã€‚</p><p>ä¸ºä»€ä¹ˆè¿™ä¹ˆåšå®ç°äº†æˆ‘ä»¬æƒ³è¦çš„å·¦ç§»çš„åŠŸèƒ½ï¼Ÿæˆ‘ä»¬åº”è¯¥ä»ä¸€ç»´çš„è§’åº¦å»ç†è§£ã€‚å› ä¸ºå®é™…ä¸Šåœ¨å†…å­˜ä¸­æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æŒ‰ç…§ä¸€ç»´å»æ’åˆ—çš„ã€‚</p><p>åŸæ¥çš„çŸ©é˜µï¼š<br><img src="/images/15572009149790.jpg" width="60%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯æœ‰qä¸ªkeyæŒ‰ç…§ä¸€è¡Œå»æ’åˆ—ã€‚</p><p>åœ¨åšå®Œpaddingä¹‹åï¼Œåˆ™ï¼š<br><img src="/images/15572009689231.jpg" width="60%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯åœ¨æ¯ä¸ªkeyå‰é¢æ’å…¥äº†0ã€‚</p><p>æ¥ä¸‹æ¥viewï¼Œå®é™…ä¸Šæ•°æ®çš„å…ˆåé¡ºåºè¿˜æ˜¯æ²¡æœ‰å˜ï¼ˆå› ä¸ºä¸æ˜¯transposeï¼‰ï¼š<br><img src="/images/15572010355613.jpg" width="60%" height="50%"></p><p>å®é™…ä¸Šåªæ˜¯å¼ºè¡Œå°†è¯¥è¡Œåˆ‡æˆä¸€ä¸ªä¸€ä¸ªqè€Œå·²ã€‚</p><p>é‚£ä¹ˆæœ€åä¸€ä¸ªæ“ä½œï¼Œå°†ç¬¬ä¸€è¡Œä¸¢æ‰ï¼Œå®é™…ä¸Šå°±æ˜¯è¦æŠŠåŸæ¥çš„xçš„ç¬¬ä¸€è¡Œå¼ºè¡Œå·¦ç§»q-1ä¸ªï¼ˆå› ä¸ºæœ‰paddingï¼‰ã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆåé¢çš„è¡Œèƒ½å¤Ÿå·¦ç§»çš„ä¸ªæ•°ä¾æ¬¡å‡å°‘ï¼Ÿåˆ«å¿˜äº†paddingï¼Œç¬¬ä¸€è¡Œå·¦ç§»äº†q-1ä¸ªï¼Œä½†ç¬¬äºŒä¸ªkeyå‰é¢ä¹Ÿæœ‰ä¸€ä¸ªpaddingï¼Œæ‰€ä»¥ç›¸å½“äºå°†å…¶å‘å³æ¨äº†ä¸€æ ¼ï¼›ç¬¬ä¸‰ä¸ªåˆæœ‰ä¸€ä¸ªpaddingï¼Œå°±åœ¨åŸæ¥çš„åŸºç¡€ä¸Šåˆæ¨äº†ä¸€æ ¼ï¼Œä¹Ÿå³æ¨äº†ä¸¤æ ¼ã€‚å› æ­¤æœ€åè¾¾åˆ°äº†æˆ‘ä»¬æƒ³è¦çš„ç›®çš„ã€‚</p><p>å®é™…ä¸Šè¦ç†è§£è¯¥æ–¹æ³•ï¼Œéœ€è¦ç‰¢ç‰¢æŠŠæ¡æ•°æ®å­˜å‚¨çš„æœ¬è´¨æ˜¯ä¸€æ•´è¡Œã€‚</p><p>è¯¥æ–¹æ³•æ²¡æœ‰æ•°æ®çš„æ‹·è´ï¼Œå…¨éƒ¨éƒ½æ˜¯viewæ“ä½œï¼Œå› æ­¤æ›´é«˜æ•ˆã€‚</p><p>ä¸å¾—ä¸ä½©æœæƒ³åˆ°è¯¥æ–¹æ³•çš„äººçš„å·¥ç¨‹èƒ½åŠ›ï¼ŒåŒæ—¶ä¹Ÿæ„Ÿè°¢æˆ´å®å¸¦æˆ‘ç†è§£è¯¥æ–¹æ³•çš„æœ¬è´¨ï¼Œä¸€å¼€å§‹æˆ‘æ˜¯æ­»æ´»ä¸ç†è§£çš„ã€‚ä»¥åæˆ–è®¸å¯ä»¥å°†è¯¥æ€æƒ³çµæ´»åº”ç”¨åˆ°å…¶ä»–æ–¹é¢ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
            <tag> transformer-xl </tag>
            
            <tag> rel-shift </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­Parameterçš„nan</title>
      <link href="/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADParameter%E7%9A%84nan/"/>
      <url>/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADParameter%E7%9A%84nan/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ å¤©é‡åˆ°ä¸€ä¸ªå¾ˆç¥å¥‡çš„bugï¼Œåœ¨Modelé‡Œé¢å®šä¹‰ä¸€ä¸ªParameterï¼ŒParameterå‡ºç°äº†nanã€‚<br>å¦‚ï¼š<br><img src="/images/15571956719188.jpg" width="80%" height="50%"></p><p><del>æ‰¾äº†ä¸€åœˆç½‘ä¸Šæ²¡æœ‰æ‰¾åˆ°å…¶åŸå› ï¼Œå·²ç»åœ¨è®ºå›æé—®äº†ã€‚</del><br>æˆ‘çš„è§£å†³æ–¹æ¡ˆæ˜¯æ˜¾å¼å¯¹å…¶è¿›è¡Œåˆå§‹åŒ–ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.init == <span class="string">'uniform'</span>:</span><br><span class="line">    nn.init.uniform_(self.u, -args.init_range, args.init_range)</span><br><span class="line">    nn.init.uniform_(self.v, -args.init_range, args.init_range)</span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> args.init == <span class="string">'normal'</span>:</span><br><span class="line">    nn.init.normal_(self.u, <span class="number">0.0</span>, args.init_std)</span><br><span class="line">    nn.init.normal_(self.v, <span class="number">0.0</span>, args.init_std)</span><br></pre></td></tr></table></figure><hr><p>åŸæ¥æ˜¯torch.Tensorçš„é”…ï¼Œtorch.Tensorä¼šåˆ†é…å†…å­˜ç©ºé—´ï¼Œä½†ä¸ä¼šæ¸…ç©ºè¯¥ç©ºé—´çš„å€¼ï¼Œå› æ­¤é‡Œé¢å¯èƒ½ä¼šæœ‰å¥‡æ€ªçš„å€¼ã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Parameter(torch.rand(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># æˆ–è€…</span></span><br><span class="line">torch.nn.Parameter(torch.zeros(<span class="number">10</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure><p>å‚è€ƒèµ„æ–™ï¼š<br><a href="https://discuss.pytorch.org/t/nan-in-torch-tensor/8987" target="_blank" rel="noopener">https://discuss.pytorch.org/t/nan-in-torch-tensor/8987</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Parameter </tag>
            
            <tag> nan </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pytorchä¸­é‡åˆ°çš„é—®é¢˜ï¼ˆåˆé›†ï¼‰</title>
      <link href="/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/PyTorch%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E5%90%88%E9%9B%86%EF%BC%89/"/>
      <url>/2019/05/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/PyTorch%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E5%90%88%E9%9B%86%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>æ–­æ–­ç»­ç»­è®°å½•ä¸€ä¸‹åœ¨å†™ä»£ç è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ä»¥åŠè§£å†³æ–¹æ¡ˆã€‚</p><h3 id="Parameter-nan"><a href="#Parameter-nan" class="headerlink" title="[Parameter nan]"></a>[Parameter nan]</h3><p><a href="http://www.linzehui.me/2019/05/07/ç¢ç‰‡çŸ¥è¯†/å…³äºPytorchä¸­Parameterçš„nan/">http://www.linzehui.me/2019/05/07/ç¢ç‰‡çŸ¥è¯†/å…³äºPytorchä¸­Parameterçš„nan/</a></p><h4 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>åœ¨å®šä¹‰Parameteræ—¶é‡åˆ°å…¶å…ƒç´ å­˜åœ¨nançš„é—®é¢˜ã€‚</p><p><img src="/images/15571956719188.jpg" width="80%" height="50%"></p><h4 id="åŸå› "><a href="#åŸå› " class="headerlink" title="åŸå› "></a>åŸå› </h4><p><code>torch.Tensor(m,n)</code>åªåˆ†é…ç©ºé—´è€Œæ²¡æœ‰å°†å…¶ä¸­çš„å€¼æ›´æ–°ã€‚</p><h4 id="è§£å†³æ–¹æ¡ˆ"><a href="#è§£å†³æ–¹æ¡ˆ" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p><code>torch.Tensor(m,n)</code>æ˜¯ä¸å»ºè®®ä½¿ç”¨çš„åˆå§‹åŒ–æ–¹æ³•ã€‚æ”¹æˆ<code>torch.nn.Parameter(torch.rand(10,10))</code>æˆ–<code>torch.nn.Parameter(torch.zeros(10,10))</code>ã€‚</p><hr><h3 id="inplace-operation"><a href="#inplace-operation" class="headerlink" title="[+= inplace operation]"></a>[+= inplace operation]</h3><p><a href="http://www.linzehui.me/2018/12/09/ç¢ç‰‡çŸ¥è¯†/Pythonä¸­çš„+=æ“ä½œ/">http://www.linzehui.me/2018/12/09/ç¢ç‰‡çŸ¥è¯†/Pythonä¸­çš„+=æ“ä½œ/</a></p><h4 id="é—®é¢˜æè¿°-1"><a href="#é—®é¢˜æè¿°-1" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output+=pos  <span class="comment"># posæ˜¯ä¸å¯æ›´æ–°çš„tensorï¼Œoutputæ˜¯å¯æ›´æ–°çš„tensor</span></span><br></pre></td></tr></table></figure><p>ç¨‹åºæŠ¥é”™ï¼šâ€œone of the variables needed for gradient computation has been modified by an inplace operationâ€ã€‚</p><h4 id="åŸå› -1"><a href="#åŸå› -1" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>åœ¨Pythonä¸­ï¼Œ<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ä¸åŒçš„ï¼Œå¦‚æœè¢«æ“ä½œæ•°æ²¡æœ‰éƒ¨ç½² â€™<strong>iadd</strong>â€˜æ–¹æ³•ï¼Œåˆ™<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ç­‰ä»·çš„ï¼Œâ€™+=â€˜å¹¶ä¸ä¼šäº§ç”Ÿin-placeæ“ä½œï¼›å½“è¢«æ“ä½œæ•°æœ‰éƒ¨ç½²è¯¥æ–¹æ³•ä¸”æ­£ç¡®éƒ¨ç½²ï¼Œåˆ™æ˜¯ä¼šäº§ç”Ÿin-placeæ“ä½œçš„ã€‚å½“æ²¡æœ‰in-placeæ“ä½œæ—¶ï¼Œ<code>i=i+1</code>è¡¨ç¤ºå¯¹ié‡åˆ†é…ï¼Œä¹Ÿå³iæŒ‡å‘äº†å¦ä¸€ä¸ªç©ºé—´è€Œä¸æ˜¯åŸæ¥çš„ç©ºé—´ã€‚<br>åœ¨Pytorchä¸­ï¼Œä¹Ÿæœ‰éƒ¨ç½²â€™<strong>iadd</strong>()â€˜æ“ä½œï¼Œæ‰€ä»¥å¯¹äº<code>output+=pos</code>ï¼Œoutputå†…éƒ¨çš„å€¼è¢«æ”¹å˜äº†ï¼Œä¹Ÿå³åœ¨è®¡ç®—å›¾ä¸­å¼•å…¥äº†ç¯ï¼Œåœ¨åå‘æ±‚å¯¼æ—¶åˆ™ä¼šå‡ºé”™ã€‚</p><h4 id="è§£å†³æ–¹æ¡ˆ-1"><a href="#è§£å†³æ–¹æ¡ˆ-1" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>å°½é‡ä¸ä½¿ç”¨inplaceæ“ä½œï¼Œå³ä½¿æ˜¯å®˜æ–¹çš„APIï¼Œå¦‚<code>unsqueeze_()</code>ã€‚å·²ç»å¥½å‡ æ¬¡è¢«inplaceæ“ä½œå‘äº†ã€‚</p><hr><h3 id="squeeze-dim"><a href="#squeeze-dim" class="headerlink" title="[squeeze dim]"></a>[squeeze dim]</h3><p><a href="http://www.linzehui.me/2019/05/06/ç¢ç‰‡çŸ¥è¯†/æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20/">http://www.linzehui.me/2019/05/06/ç¢ç‰‡çŸ¥è¯†/æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20/</a></p><h4 id="é—®é¢˜æè¿°-2"><a href="#é—®é¢˜æè¿°-2" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>å½“éœ€è¦squeezeæ—¶ï¼ŒæœªæŒ‡å®šsqueezeçš„ç»´åº¦ï¼Œå¯¼è‡´åé¢çš„ç»´æ•°ä¸ä¸€è‡´ï¼ŒæŠ¥é”™ã€‚</p><h4 id="åŸå› -2"><a href="#åŸå› -2" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>ç”±äºåœ¨æŸäº›æç«¯æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šå‡ºç°batch sizeä¸º1çš„æƒ…å†µï¼Œå½“é‡åˆ°è¿™ä¸ªæƒ…å†µæ—¶ï¼Œsqueezeä¼šå°†å…¶ä¸€å¹¶å‹ç¼©æ‰ï¼Œä½¿å¾—åé¢ä¼šå‡ºé”™ã€‚</p><h4 id="è§£å†³æ–¹æ¡ˆ-2"><a href="#è§£å†³æ–¹æ¡ˆ-2" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>å°½å¯èƒ½æ˜¾å¼æŒ‡å®šè¦å‹ç¼©çš„ç»´åº¦ï¼Œé™¤éå¾ˆæ˜ç¡®å°±è¦å°†æ‰€æœ‰çš„å‹ç¼©æ‰ã€‚</p><hr><h3 id="infâ€”-gt-nan"><a href="#infâ€”-gt-nan" class="headerlink" title="[infâ€”&gt;nan]"></a>[infâ€”&gt;nan]</h3><p><a href="http://www.linzehui.me/2019/07/03/ç¢ç‰‡çŸ¥è¯†/å…³äºPyTorchä¸­infå¯¼æ•°çš„nané—®é¢˜/">http://www.linzehui.me/2019/07/03/ç¢ç‰‡çŸ¥è¯†/å…³äºPyTorchä¸­infå¯¼æ•°çš„nané—®é¢˜/</a></p><h4 id="é—®é¢˜æè¿°-3"><a href="#é—®é¢˜æè¿°-3" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h4><p>ä¸¤ä¸ªtensorç›¸ä¹˜ï¼Œè‹¥å…¶ä¸­ä¸€ä¸ªtensorå¸¦æœ‰infï¼Œåˆ™å¦ä¸€ä¸ªtensorï¼ˆè¯¥tensorå¯æ›´æ–°ï¼‰çš„gradåˆ™ä¸ºnanã€‚</p><h4 id="åŸå› -3"><a href="#åŸå› -3" class="headerlink" title="åŸå› "></a>åŸå› </h4><p>ä¹˜æ³•çš„å¯¼æ•°çš„å®šä¹‰ã€‚ä¸¤ä¸ªtensorç›¸ä¹˜ï¼Œå¯¼æ•°ä¸ºå¯¹æ–¹ã€‚åœ¨PyTorchä¸­ï¼Œinfçš„gradåˆ™ä¸ºnanã€‚</p><h4 id="è§£å†³æ–¹æ¡ˆ-3"><a href="#è§£å†³æ–¹æ¡ˆ-3" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h4><p>åœ¨ç›¸ä¹˜å‰ï¼Œå°†å¸¦æœ‰infçš„tensoråšmasked_fillï¼Œinfè¢«ç½®ä¸º0åå†ç›¸ä¹˜ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Parameter </tag>
            
            <tag> nan </tag>
            
            <tag> inf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•16</title>
      <link href="/2019/05/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9516/"/>
      <url>/2019/05/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9516/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorchæ£€æŸ¥tensor-nan"><a href="#1ï¸âƒ£-Pytorchæ£€æŸ¥tensor-nan" class="headerlink" title="1ï¸âƒ£[Pytorchæ£€æŸ¥tensor nan]"></a>1ï¸âƒ£[Pytorchæ£€æŸ¥tensor nan]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ³•ä¸€ï¼ŒåŸºäºnan!=nan </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, np.nan])</span><br><span class="line">tensor([  <span class="number">1.</span>,   <span class="number">2.</span>, nan.])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x != x</span><br><span class="line">tensor([ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>], dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ³•äºŒï¼Œtorch.isnan(x)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.isnan(x)</span><br><span class="line">tensor([ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>], dtype=torch.uint8)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†20</title>
      <link href="/2019/05/06/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8620/"/>
      <url>/2019/05/06/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8620/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>â‘ <br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.gather(input, dim, index, out=<span class="keyword">None</span>) â†’ Tensor</span><br></pre></td></tr></table></figure></p><p>èƒ½å¤Ÿæ ¹æ®indexçš„å€¼åœ¨æŒ‡å®šç»´åº¦æ”¶é›†æ•°å€¼ã€‚å¯ä»¥ç”¨äºåˆ‡sliceã€‚</p><p>â‘¡<br>expandå’Œrepeatä¸åŒï¼Œä¸ä¼šåˆ†é…æ–°çš„å†…å­˜ã€‚å¦‚æœä¸€ä¸ªtensorä½¿ç”¨expandå†catåˆ°å…¶ä»–tensorä¸Šï¼Œè¿™ä¸ªexpandè¿˜ä¼šçœå†…å­˜å—ï¼Ÿ<br>ä¸ä¼šã€‚<br>åœ¨catçš„æ—¶å€™ä¼šé‡æ–°åˆ†é…æ•´ä¸ªtensorçš„å†…å­˜ï¼Œå¹¶ä¸”å°†å…ƒç´ ä¸€ä¸ªä¸€ä¸ªcopyè¿‡å»ã€‚</p><p><a href="https://discuss.pytorch.org/t/efficiency-of-torch-cat/8830" target="_blank" rel="noopener">https://discuss.pytorch.org/t/efficiency-of-torch-cat/8830</a></p><blockquote><p>it pre-allocates the full tensor and then copy into it each element</p></blockquote><p>â‘¢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.einsum(equation, *operands) â†’ Tensor</span><br></pre></td></tr></table></figure><blockquote><p>This function provides a way of computing multilinear expressions (i.e. sums of products) using the Einstein summation convention.</p></blockquote><p>å‘ç°ä¸€ä¸ªç¥å¥‡çš„apiï¼ŒPytorchæ”¯æŒçˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š(Einstein summation convention)ã€‚ä¹Ÿå³åœ¨ç»™å®šä¸¤ä¸ªtensoræ—¶ï¼Œå¯ä»¥æŒ‡å®šç»´åº¦è¿›è¡Œæ±‚å’Œï¼Œç›¸å½“çµæ´»ï¼Œå¯ä»¥ç†è§£æˆbmmæˆ–è€…mmçš„æ‰©å±•ç‰ˆï¼Œè¿™æ ·åœ¨åšä¸€äº›tensorä¹‹é—´çš„æ“ä½œå°±ä¸éœ€è¦view/permuteè°ƒæ•´æˆbmmæ”¯æŒçš„æ ¼å¼äº†ã€‚</p><p>å®˜æ–¹ä¾‹å­ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.randn(<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'i,j-&gt;ij'</span>, x, y)  <span class="comment"># outer product</span></span><br><span class="line">tensor([[<span class="number">-0.0570</span>, <span class="number">-0.0286</span>, <span class="number">-0.0231</span>,  <span class="number">0.0197</span>],</span><br><span class="line">        [ <span class="number">1.2616</span>,  <span class="number">0.6335</span>,  <span class="number">0.5113</span>, <span class="number">-0.4351</span>],</span><br><span class="line">        [ <span class="number">1.4452</span>,  <span class="number">0.7257</span>,  <span class="number">0.5857</span>, <span class="number">-0.4984</span>],</span><br><span class="line">        [<span class="number">-0.4647</span>, <span class="number">-0.2333</span>, <span class="number">-0.1883</span>,  <span class="number">0.1603</span>],</span><br><span class="line">        [<span class="number">-1.1130</span>, <span class="number">-0.5588</span>, <span class="number">-0.4510</span>,  <span class="number">0.3838</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l = torch.randn(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = torch.randn(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'bn,anm,bm-&gt;ba'</span>, l, A, r) <span class="comment"># compare torch.nn.functional.bilinear</span></span><br><span class="line">tensor([[<span class="number">-0.3430</span>, <span class="number">-5.2405</span>,  <span class="number">0.4494</span>],</span><br><span class="line">        [ <span class="number">0.3311</span>,  <span class="number">5.5201</span>, <span class="number">-3.0356</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>As = torch.randn(<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Bs = torch.randn(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'bij,bjk-&gt;bik'</span>, As, Bs) <span class="comment"># batch matrix multiplication</span></span><br><span class="line">tensor([[[<span class="number">-1.0564</span>, <span class="number">-1.5904</span>,  <span class="number">3.2023</span>,  <span class="number">3.1271</span>],</span><br><span class="line">         [<span class="number">-1.6706</span>, <span class="number">-0.8097</span>, <span class="number">-0.8025</span>, <span class="number">-2.1183</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">4.2239</span>,  <span class="number">0.3107</span>, <span class="number">-0.5756</span>, <span class="number">-0.2354</span>],</span><br><span class="line">         [<span class="number">-1.4558</span>, <span class="number">-0.3460</span>,  <span class="number">1.5087</span>, <span class="number">-0.8530</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">2.8153</span>,  <span class="number">1.8787</span>, <span class="number">-4.3839</span>, <span class="number">-1.2112</span>],</span><br><span class="line">         [ <span class="number">0.3728</span>, <span class="number">-2.1131</span>,  <span class="number">0.0921</span>,  <span class="number">0.8305</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'ii-&gt;i'</span>, A) <span class="comment"># diagonal</span></span><br><span class="line">tensor([<span class="number">-0.7825</span>,  <span class="number">0.8291</span>, <span class="number">-0.1936</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'...ii-&gt;...i'</span>, A) <span class="comment"># batch diagonal</span></span><br><span class="line">tensor([[<span class="number">-1.0864</span>,  <span class="number">0.7292</span>,  <span class="number">0.0569</span>],</span><br><span class="line">        [<span class="number">-0.9725</span>, <span class="number">-1.0270</span>,  <span class="number">0.6493</span>],</span><br><span class="line">        [ <span class="number">0.5832</span>, <span class="number">-1.1716</span>, <span class="number">-1.5084</span>],</span><br><span class="line">        [ <span class="number">0.4041</span>, <span class="number">-1.1690</span>,  <span class="number">0.8570</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.einsum(<span class="string">'...ij-&gt;...ji'</span>, A).shape <span class="comment"># batch permute</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure><p>æˆ‘å¯¹è¿™ä¸ªapiä¸€èˆ¬çš„ç”¨æ³•å°±æ˜¯ï¼Œå°†ä¸¤ä¸ªtensorçš„æ¯ä¸€ç»´ç”¨ä¸åŒçš„è®°å·æ ‡å·ï¼Œç„¶åæƒ³ä¸€ä¸‹æˆ‘æƒ³è¦çš„tensorçš„æ ¼å¼ï¼ŒæŒ‰ç…§è®°å·å†™ä¸‹å°±å¯ä»¥ç›´æ¥å¾—åˆ°äº†ã€‚</p><p>â‘£<br>squeezeåœ¨ä½¿ç”¨çš„æ—¶å€™å°½é‡æŒ‡å®šç»´åº¦ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°åœ¨è®­ç»ƒæœ€åä¸€ä¸ªbatchæ—¶ï¼Œbatch_sizeæ­£å¥½æ˜¯1ï¼Œå°±æŠŠbatch_sizeç»™squeezeæ‰äº†ã€‚ï¼ˆå·²ç»ä¸¤æ¬¡é‡åˆ°è¿™æ ·çš„bugäº†ï¼‰</p><p>â‘¤</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apply(fn)</span><br></pre></td></tr></table></figure><blockquote><p>Applies fn recursively to every submodule (as returned by .children()) as well as self. Typical use includes initializing the parameters of a model (see also torch-nn-init).</p></blockquote><p>å¯ä»¥ç”¨äºæ‰€æœ‰çš„å­æ¨¡å—çš„åˆå§‹åŒ–ï¼Œå¥½åƒå¾ˆæ–¹ä¾¿çš„æ ·å­ã€‚ä½†æˆ‘çªç„¶æƒ³åˆ°è¿™ç§æ–¹æ³•å¯èƒ½ä¼šä¸å°å¿ƒæŠŠembeddingåˆå§‹åŒ–ç»™è¦†ç›–äº†ï¼Œå¦‚æœembeddingæœ‰ç”¨pretrainåˆå§‹åŒ–çš„è¯ã€‚</p><p>å®˜æ–¹ä¾‹å­ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">(m)</span>:</span></span><br><span class="line">        print(m)</span><br><span class="line">        <span class="keyword">if</span> type(m) == nn.Linear:</span><br><span class="line">            m.weight.data.fill_(<span class="number">1.0</span>)</span><br><span class="line">            print(m.weight)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = nn.Sequential(nn.Linear(<span class="number">2</span>, <span class="number">2</span>), nn.Linear(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.apply(init_weights)</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line">Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">        [ <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (<span class="number">1</span>): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">2</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><h3 id="2ï¸âƒ£-bpc"><a href="#2ï¸âƒ£-bpc" class="headerlink" title="2ï¸âƒ£[bpc]"></a>2ï¸âƒ£[bpc]</h3><p>bits per character(bpc)æ˜¯language modelä¸€ä¸ªè¯„ä»·æŒ‡æ ‡ï¼Œå¦ä¸€ä¸ªå¸¸ç”¨æŒ‡æ ‡æ˜¯pplï¼ˆå›°æƒ‘åº¦ï¼‰ã€‚å®é™…ä¸Šbpcå’Œppléƒ½æ˜¯å’Œäº¤å‰ç†µæŒ‚é’©çš„ï¼Œå…¶è®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">\begin{aligned} b p c(s t r i n g)=\frac{1}{T} \sum_{t=1}^{T} H\left(P_{t}, \hat{P}_{t}\right) &=-\frac{1}{T} \sum_{t=1}^{T} \sum_{c=1}^{n} P_{t}(c) \log _{2} \hat{P}_{t}(c) \\ &=-\frac{1}{T} \sum_{t=1}^{T} \log _{2} \hat{P}_{t}\left(x_{t}\right) \end{aligned}</script><p>åœ¨ä»£ç ä¸­è®¡ç®—äº¤å‰ç†µçš„lossæ˜¯ä»¥eä¸ºåº•çš„ï¼Œå› æ­¤éœ€è¦å°†lossé™¤ä»¥$\log _{e}2$å³å¯ï¼ˆlogçš„æ¢åº•å…¬å¼ï¼‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cur_loss / math.log(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><a href="https://stats.stackexchange.com/questions/211858/how-to-compute-bits-per-character-bpc" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/211858/how-to-compute-bits-per-character-bpc</a><br><a href="https://arxiv.org/pdf/1308.0850.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1308.0850.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> bpc </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯24</title>
      <link href="/2019/05/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D24/"/>
      <url>/2019/05/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D24/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-è§‚ä¹¦"><a href="#1ï¸âƒ£-è§‚ä¹¦" class="headerlink" title="1ï¸âƒ£ è§‚ä¹¦"></a>1ï¸âƒ£ è§‚ä¹¦</h3><p>[æ˜] äºè°¦<br>ä¹¦å·å¤šæƒ…ä¼¼æ•…äººï¼Œæ™¨æ˜å¿§ä¹æ¯ç›¸äº²ã€‚<br>çœ¼å‰ç›´ä¸‹ä¸‰åƒå­—ï¼Œèƒ¸æ¬¡å…¨æ— ä¸€ç‚¹å°˜ã€‚<br>æ´»æ°´æºæµéšå¤„æ»¡ï¼Œä¸œé£èŠ±æŸ³é€æ—¶æ–°ã€‚<br><strong>é‡‘éç‰å‹’å¯»èŠ³å®¢ï¼Œæœªä¿¡å¾åºåˆ«æœ‰æ˜¥ã€‚</strong></p><p><a href="http://lib.xcz.im/work/582ee1a2da2f600063ec45ea" target="_blank" rel="noopener">http://lib.xcz.im/work/582ee1a2da2f600063ec45ea</a></p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡17</title>
      <link href="/2019/04/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8717/"/>
      <url>/2019/04/28/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8717/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>PHRASE-BASED ATTENTIONS</li><li>Regularizing and Optimizing LSTM Language Models</li></ol><h2 id="1ï¸âƒ£-PHRASE-BASED-ATTENTIONS"><a href="#1ï¸âƒ£-PHRASE-BASED-ATTENTIONS" class="headerlink" title="1ï¸âƒ£[PHRASE-BASED ATTENTIONS]"></a>1ï¸âƒ£[PHRASE-BASED ATTENTIONS]</h2><p>è¿™ç¯‡æŠ•äº†ICLRä½†æ²¡ä¸­ã€‚<br>æå‡ºå¯¹Transformerçš„attentionæœºåˆ¶è¿›è¡Œæ”¹è¿›ï¼Œä»¥è¯ç»„ä¸ºå•ä½è¿›è¡Œattentionï¼Œå¼•å…¥è¯ç»„çš„å¯¹é½æ¥æå‡ç¿»è¯‘è¡¨ç°ã€‚æå‡ºçš„æƒ³æ³•ä¹Ÿæ˜¯æ¯”è¾ƒç®€å•ç›´è§‚çš„ã€‚</p><p>å›é¡¾ï¼š<br>transformerçš„åšæ³•ï¼š<br>$\begin{aligned} \text { Attention }\left(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}_{q}, \boldsymbol{W}_{k}, \boldsymbol{W}_{v}\right) &amp;=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right)\left(\boldsymbol{K} \boldsymbol{W}_{k}\right)^{T}}{\sqrt{d_{k}}}\right)\left(\boldsymbol{V} \boldsymbol{W}_{v}\right) \\ \text { Head }^{i} &amp;=\text { Attention }\left(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}_{q}^{i}, \boldsymbol{W}_{k}^{i}, \boldsymbol{W}_{v}^{i}\right) \text { for } i=1 \ldots h \\ \text { AttentionOutput }(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}, \boldsymbol{W}) &amp;=\text { concat (Head}^{1}, \text { Head}^{2}, \ldots, \text { Head}^{h} ) \boldsymbol{W} \end{aligned}<br>$</p><h3 id="æ¨¡å‹ä»‹ç»"><a href="#æ¨¡å‹ä»‹ç»" class="headerlink" title="æ¨¡å‹ä»‹ç»"></a>æ¨¡å‹ä»‹ç»</h3><h4 id="PHRASE-BASED-ATTENTION-METHODS"><a href="#PHRASE-BASED-ATTENTION-METHODS" class="headerlink" title="PHRASE-BASED ATTENTION METHODS"></a>PHRASE-BASED ATTENTION METHODS</h4><p>å…¶æœ¬è´¨æ˜¯ä½¿ç”¨CNNæ“ä½œä½¿å¾—è¯æœ‰phraseçš„ä¿¡æ¯ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">O_{t}=\mathbf{w} \oplus_{k=0}^{n} \mathbf{x}_{t \pm k}</script><p>ä¸‹é¢ä½¿ç”¨$\operatorname{Conv}_{n}(\boldsymbol{X}, \boldsymbol{W})$ä»£è¡¨$\boldsymbol{W}$å¯¹$\boldsymbol{X}$è¿›è¡Œå·ç§¯æ“ä½œã€‚å…¶ä¸­$\boldsymbol{W} \in \mathbb{R}^{n \times d_{1} \times d_{2}}$</p><p>æ¥ä¸‹æ¥æå‡ºä¸¤ç§æ–¹æ³•ã€‚</p><h5 id="KEY-VALUE-CONVOLUTION"><a href="#KEY-VALUE-CONVOLUTION" class="headerlink" title="KEY-VALUE CONVOLUTION"></a>KEY-VALUE CONVOLUTION</h5><script type="math/tex; mode=display">\operatorname{Conv} \mathrm{KV}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right) \operatorname{Conv}_{n}\left(\boldsymbol{K}, \boldsymbol{W}_{k}\right)^{T}}{\sqrt{d_{k}}}\right) \operatorname{Conv}_{n}\left(\boldsymbol{V}, \boldsymbol{W}_{v}\right)</script><p>Qä¸å˜ï¼Œåªå¯¹Kå’ŒVè¿›è¡Œå·ç§¯ã€‚</p><h5 id="QUERY-AS-KERNEL-CONVOLUTION"><a href="#QUERY-AS-KERNEL-CONVOLUTION" class="headerlink" title="QUERY AS-KERNEL CONVOLUTION"></a>QUERY AS-KERNEL CONVOLUTION</h5><script type="math/tex; mode=display">\operatorname{QUERYK}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\mathcal{S}\left(\frac{\operatorname{Conv}_{n}\left(\boldsymbol{K} \boldsymbol{W}_{k}, \boldsymbol{Q} \boldsymbol{W}_{q}\right)}{\sqrt{d_{k} * n}}\right) \operatorname{Conv}_{n}\left(\boldsymbol{V}, \boldsymbol{W}_{v}\right)</script><p>å°†Qä½œä¸ºconvolutionçš„kernelå‚æ•°è¿›è¡Œå·ç§¯ã€‚$\boldsymbol{W}_{q} \in \mathbb{R}^{n \times d_{q} \times d_{k}}, \boldsymbol{W}_{k} \in \mathbb{R}^{d_{k} \times d_{k}}, \boldsymbol{W}_{v} \in \mathbb{R}^{n \times d_{v} \times d_{v}}$</p><p>ä»¥ä¸Šæ˜¯åŸºæœ¬å½¢å¼ï¼Œæ‰©å±•åˆ°å¤šä¸ªheadå¯ä»¥æœ‰å¤šç§æ–¹æ³•ã€‚</p><h4 id="MULTI-HEADED-PHRASAL-ATTENTION"><a href="#MULTI-HEADED-PHRASAL-ATTENTION" class="headerlink" title="MULTI-HEADED PHRASAL ATTENTION"></a>MULTI-HEADED PHRASAL ATTENTION</h4><h5 id="HOMOGENEOUS-N-GRAM-ATTENTION"><a href="#HOMOGENEOUS-N-GRAM-ATTENTION" class="headerlink" title="HOMOGENEOUS N-GRAM ATTENTION"></a>HOMOGENEOUS N-GRAM ATTENTION</h5><p><img src="/images/15564587340044.jpg" width="90%" height="50%"></p><p>æ¯ä¸ªheadä¸“æ³¨æŸç§gramã€‚ä½†è¿™æ ·ä¼¼ä¹ä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºå¼ºè¡Œå¯¹æŸäº›headå¼•å…¥è¿™ç§ç‰¹æ€§ï¼Œæœ‰æ—¶å€™è¯ä¸è¯ä¹‹é—´æ²¡æœ‰è¿™ç§å…³ç³»ï¼Œè¿™æ ·ä¼šå¸¦æ¥å™ªå£°ã€‚</p><h5 id="HETEROGENEOUS-N-GRAM-ATTENTION"><a href="#HETEROGENEOUS-N-GRAM-ATTENTION" class="headerlink" title="HETEROGENEOUS N-GRAM ATTENTION"></a>HETEROGENEOUS N-GRAM ATTENTION</h5><p><img src="/images/15564587795887.jpg" width="90%" height="50%"></p><p>å°†æ‰€æœ‰çš„graméƒ½åŒæ—¶attendã€‚</p><p>ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{k, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{k, 2}\right)^{T} ; \ldots\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right) ; \ldots\right]</script><p>æˆ–ï¼š</p><script type="math/tex; mode=display">\mathcal{S}\left(\left[\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{k, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{k, 2}, \boldsymbol{Q} \boldsymbol{W}_{q, 2}\right)}{\sqrt{d * n_{2}}} ; \ldots\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right) ; \ldots\right]</script><h4 id="INTERLEAVED-PHRASES-TO-PHRASE-HETEROGENEOUS-ATTENTION"><a href="#INTERLEAVED-PHRASES-TO-PHRASE-HETEROGENEOUS-ATTENTION" class="headerlink" title="INTERLEAVED PHRASES TO PHRASE HETEROGENEOUS ATTENTION"></a>INTERLEAVED PHRASES TO PHRASE HETEROGENEOUS ATTENTION</h4><p>ä¸Šé¢ä»‹ç»çš„éƒ½æ˜¯sourceç«¯çš„phraseåˆ°targetçš„tokenï¼Œæœ‰æ—¶å€™éœ€è¦åè¿‡æ¥ï¼Œå› æ­¤å¯ä»¥äº¤å‰åœ°äº¤äº’ã€‚<br><img src="/images/15564588967513.jpg" width="90%" height="50%"></p><p>æˆ‘ä»¬å…ˆå¯¹Qè¿›è¡Œä¸¤ç§å·ç§¯ï¼Œè·å¾—unigramå’Œbigramã€‚ç„¶åä¸KVçš„unigramä¸æ¯”bigramè¿›è¡Œäº¤å‰ã€‚<br>$\boldsymbol{A}_{1, \mathrm{ConvKV}}=\mathcal{S}\left(\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q_{1}}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{k, 2}\right)^{T}\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p><p>$\boldsymbol{A}_{2, \text {ConvKV }}=\mathcal{S}\left(\frac{\operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}}\right)\left[\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T} ; \operatorname{Conv}_{2}\left(\boldsymbol{K}, \boldsymbol{W}_{\boldsymbol{k}, 2}\right)^{T}\right]}{\sqrt{d_{k}}}\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p><p>$\boldsymbol{A}_{1, \text {QueryK }}=\mathcal{S}\left(\left[\frac{\left(\boldsymbol{Q} \boldsymbol{W}_{q_{1}, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 2}, \boldsymbol{Q} \boldsymbol{W}_{q_{1}, 2}\right)}{\sqrt{d * n_{2}}}\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p><p>$\boldsymbol{A}_{2, \text { QueryK }}=\mathcal{S}\left(\left[\frac{\operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}, 1}\right)\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 1}\right)^{T}}{\sqrt{d}} ; \frac{\operatorname{Conv}_{2}\left(\boldsymbol{K} \boldsymbol{W}_{\boldsymbol{k}, 2}, \operatorname{Conv}_{2}\left(\boldsymbol{Q}, \boldsymbol{W}_{q_{2}, 2}\right)\right)}{\sqrt{d * n_{2}}}\right]\right)\left[\left(\boldsymbol{V} \boldsymbol{W}_{v, 1}\right) ; \operatorname{Conv}_{2}\left(\boldsymbol{V}, \boldsymbol{W}_{v, 2}\right)\right]$</p><p>æ€è€ƒï¼š<br>è¿™æ ·ä¼¼ä¹å‚æ•°é‡ä¼šæš´å¢ï¼Œå…¶å®åº”è¯¥å¯¹æ¯”çš„å°±ä¸æ˜¯transformer baseäº†ï¼Œåº”è¯¥æ˜¯å‚æ•°é‡å¤§è‡´ç›¸ç­‰çš„transformerï¼Œè¿™ä¹Ÿåœ¨reviewé‡Œé¢æåˆ°è¿‡ã€‚åŒæ—¶æˆ‘è§‰å¾—è¿™ä¸ªæ–¹æ³•æ˜¯å¦æœ‰äº›å¤ªå¤æ‚ï¼Œä¸å¤Ÿç®€å•æ˜äº†ã€‚ä»¥åŠç»“æœä¼¼ä¹ä¸å¤§ä»¤äººä¿¡æœï¼Œå› ä¸ºä»–çš„baselineæ²¡æœ‰å¤ç°å‡ºtransformer baseçš„ç»“æœï¼ˆdue to the limited GPU)ã€‚</p><hr><h2 id="2ï¸âƒ£-Regularizing-and-Optimizing-LSTM-Language-Models"><a href="#2ï¸âƒ£-Regularizing-and-Optimizing-LSTM-Language-Models" class="headerlink" title="2ï¸âƒ£[Regularizing and Optimizing LSTM Language Models]"></a>2ï¸âƒ£[Regularizing and Optimizing LSTM Language Models]</h2><p>æå‡ºä¸€äº›ä¼˜åŒ–æå‡LSTM-basedè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ã€‚æ­¤å³å¤§åé¼é¼çš„AWD-LSTMã€‚</p><h3 id="Weight-dropped-LSTM"><a href="#Weight-dropped-LSTM" class="headerlink" title="Weight-dropped LSTM"></a>Weight-dropped LSTM</h3><p>LSTMå…¬å¼å›é¡¾ï¼š</p><script type="math/tex; mode=display">\begin{aligned} i_{t} &=\sigma\left(W^{i} x_{t}+U^{i} h_{t-1}\right) \\ f_{t} &=\sigma\left(W^{f} x_{t}+U^{f} h_{t-1}\right) \\ o_{t} &=\sigma\left(W^{o} x_{t}+U^{o} h_{t-1}\right) \\ \tilde{c}_{t} &=\tanh \left(W^{c} x_{t}+U^{c} h_{t-1}\right) \\ c_{t} &=i_{t} \odot \tilde{c}_{t}+f_{t} \odot+\tilde{c}_{t-1} \\ h_{t} &=o_{t} \odot \tanh \left(c_{t}\right) \end{aligned}</script><p>å¯¹hidden-to-hiddençš„weightåº”ç”¨DropConnectã€‚ä¹Ÿå³å¯¹å…¶ä¸­çš„$\left[U^{i}, U^{f}, U^{o}, U^{c}\right]$è¿›è¡Œdropconnectã€‚æ³¨æ„åˆ°maskçŸ©é˜µåœ¨åŒä¸€ä¸ªbatchçš„æ¯ä¸ªæ—¶é—´æ­¥téƒ½æ˜¯ä¸€æ ·çš„ã€‚</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>ä¹‹å‰çš„å·¥ä½œè¡¨æ˜ï¼Œåœ¨è¯­è¨€æ¨¡å‹ä¸­ï¼Œä½¿ç”¨æ™®é€šçš„SGDï¼Œä¸å¸¦momentumï¼Œèƒ½è¶…è¿‡å…¶ä»–çš„ä¼˜åŒ–æ–¹æ³•ã€‚æ™®é€šSGDï¼š<br>$w_{k+1}=w_{k}-\gamma_{k} \hat{\nabla} f\left(w_{k}\right)$</p><p>æœ¬æ–‡æå‡ºåœ¨averaged SGD(ASGDï¼‰çš„åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ã€‚</p><p>ASGDå’Œä¸Šå¼ä¸€è‡´ï¼Œåªä¸è¿‡æœ€åæ›´æ–°å®Œæ˜¯å°†æœ€åå‡ æ¬¡æ›´æ–°çš„weightåšäº†å¹³å‡å¹¶è¿”å›ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\frac{1}{(K-T+1)} \sum_{i=T}^{K} w_{i}</script><p>å…¶ä¸­Kæ˜¯totalçš„å¾ªç¯æ¬¡æ•°ï¼›Tæ˜¯äººå·¥å®šä¹‰çš„é˜ˆå€¼ã€‚ä½†Tçš„é˜ˆå€¼éœ€è¦äººå·¥è°ƒï¼Œå› æ­¤è¯¥æ–¹æ³•ä¸æ˜¯å¾ˆå¥½ã€‚æœ€ç†æƒ³çš„å°±æ˜¯åœ¨SGDæ‹Ÿåˆåˆ°ä¸€ä¸ªç¨³å®šçŠ¶æ€æ—¶å†å¹³å‡ã€‚</p><p>å› æ­¤æå‡ºä¸€ç§æ–°çš„æ–¹æ³•ä»¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œé€šè¿‡validation lossè§¦å‘æœºåˆ¶ã€‚</p><p><img src="/images/15564599688438.jpg" width="50%" height="50%"></p><h3 id="Extended-regularization-techniques"><a href="#Extended-regularization-techniques" class="headerlink" title="Extended regularization techniques"></a>Extended regularization techniques</h3><h4 id="Variable-length-backpropagation-sequences"><a href="#Variable-length-backpropagation-sequences" class="headerlink" title="Variable length backpropagation sequences"></a>Variable length backpropagation sequences</h4><p>è‹¥æ¯æ¬¡éƒ½å›ºå®šçª—å£åˆ‡åˆ†å¥å­ï¼Œåˆ™æ€»ä¼šæœ‰ä¸€äº›è¯æ²¡æ³•æ›´æ–°è‡ªå·±ï¼Œå¦‚æœ€åä¸€ä¸ªè¯ï¼ŒåŒæ—¶é™¤äº†ç¬¬ä¸€ä¸ªè¯ï¼Œå…¶ä»–çš„è¯éƒ½åªèƒ½æ¥æ”¶åˆ°éƒ¨åˆ†bpã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ç§data inefficientã€‚</p><p>å¯ä»¥ä»åˆ‡åˆ†å¥å­çš„æ–¹æ³•ä¸Šè¿›è¡Œæ”¹è¿›ã€‚ä½¿ç”¨éšæœºé‡‡æ ·å¥å­é•¿åº¦çš„æ–¹å¼å»ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚ä»¥è¾ƒé«˜çš„pé€‰æ‹©seqé•¿åº¦ï¼Œ1-pé€‰æ‹©seq/2ã€‚æ¥ç€ä»¥æ­¤ä¸ºé«˜æ–¯å‡å€¼ï¼Œä»¥æ­£æ€åˆ†å¸ƒ$\mathcal{N}(\operatorname{seq}, s)$é‡‡æ ·å¥å­é•¿åº¦ã€‚</p><h4 id="Variational-dropout"><a href="#Variational-dropout" class="headerlink" title="Variational dropout"></a>Variational dropout</h4><p>åœ¨LSTMä¸­ï¼Œé™¤äº†hidden-to-hiddençš„ï¼Œå…¶ä»–åœ°æ–¹éƒ½é‡‡ç”¨variational dropoutã€‚</p><h4 id="Embedding-dropout"><a href="#Embedding-dropout" class="headerlink" title="Embedding dropout"></a>Embedding dropout</h4><p>å­—çº§åˆ«ï¼Œä¹Ÿå³å°†æ•´ä¸ªå­—çš„embeddingå»æ‰ã€‚åŒæ—¶ç”±äºæ˜¯åœ¨embedding matrixä¸Šåšçš„ï¼Œåœ¨ä¸€ä¸ªå®Œæ•´çš„forward passä¸backward passéƒ½ç”¨äº†ï¼Œå› æ­¤å°±ç›¸å½“äºä½¿ç”¨variational dropoutç”¨åœ¨one-hot embeddingä¸embedding lookupä¹‹é—´ã€‚</p><h4 id="Weight-tying"><a href="#Weight-tying" class="headerlink" title="Weight tying"></a>Weight tying</h4><p> embeddingä¸softmaxçš„æƒé‡ç»‘å®šã€‚</p><h4 id="Independent-embedding-size-and-hidden-size"><a href="#Independent-embedding-size-and-hidden-size" class="headerlink" title="Independent embedding size and hidden size"></a>Independent embedding size and hidden size</h4><p>LSTMçš„ç¬¬ä¸€å±‚ä¸æœ€åä¸€å±‚ä¸embedding sizeä¸€è‡´ï¼Œå…¶å®ƒå±‚çš„å°±æœ‰è‡ªå·±çš„hidden sizeã€‚</p><h4 id="Activation-Regularization-AR-and-Temporal-Activation-Regularization-TAR"><a href="#Activation-Regularization-AR-and-Temporal-Activation-Regularization-TAR" class="headerlink" title="Activation Regularization (AR) and Temporal Activation Regularization (TAR)"></a>Activation Regularization (AR) and Temporal Activation Regularization (TAR)</h4><p>ARï¼š<br>L2æ­£åˆ™åŒ–ï¼š$\alpha L_{2}\left(m \odot h_{t}\right)$<br>å…¶ä¸­mæ˜¯maskï¼Œhæ˜¯hidden state</p><p>TARï¼š<br>$\beta L_{2}\left(h_{t}-h_{t+1}\right)$<br>å‡å°‘ä¸¤ä¸ªhä¹‹é—´çš„å·®è·ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯23</title>
      <link href="/2019/04/28/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D23/"/>
      <url>/2019/04/28/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D23/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è¡Œé¦™å­-Â·-è¿°æ€€"><a href="#1ï¸âƒ£è¡Œé¦™å­-Â·-è¿°æ€€" class="headerlink" title="1ï¸âƒ£è¡Œé¦™å­ Â· è¿°æ€€"></a>1ï¸âƒ£è¡Œé¦™å­ Â· è¿°æ€€</h3><p>[å®‹] è‹è½¼<br><strong>æ¸…å¤œæ— å°˜ï¼Œæœˆè‰²å¦‚é“¶</strong>ã€‚é…’æ–Ÿæ—¶ã€é¡»æ»¡ååˆ†ã€‚æµ®åæµ®åˆ©ï¼Œè™šè‹¦åŠ³ç¥ã€‚<strong>å¹éš™ä¸­é©¹ï¼ŒçŸ³ä¸­ç«ï¼Œæ¢¦ä¸­èº«</strong>ã€‚<br>è™½æŠ±æ–‡ç« ï¼Œå¼€å£è°äº²ã€‚ä¸”é™¶é™¶ã€ä¹å°½å¤©çœŸã€‚å‡ æ—¶å½’å»ï¼Œä½œä¸ªé—²äººã€‚å¯¹ä¸€å¼ ç´ï¼Œä¸€å£¶é…’ï¼Œä¸€æºªäº‘ã€‚</p><p>éš™ä¸­é©¹ï¼šè¯­å‡ºã€Šåº„å­Â·çŸ¥åŒ—æ¸¸ã€‹ï¼šâ€œäººç”Ÿå¤©åœ°ä¹‹é—´ï¼Œè‹¥ç™½é©¹ä¹‹è¿‡éš™ï¼Œå¿½ç„¶è€Œå·²ã€‚â€œ<br>çŸ³ä¸­ç«ï¼Œæ¢¦ä¸­èº«ï¼šæ¯”å–»ç”Ÿå‘½çŸ­ä¿ƒï¼Œåƒå‡»çŸ³è¿¸å‡ºä¸€é—ªå³ç­çš„ç«èŠ±ï¼Œåƒåœ¨æ¢¦å¢ƒä¸­çŸ­æš‚çš„ç»å†ã€‚çŸ³ä¸­ç«ï¼Œè¯­å‡ºåŒ—é½åˆ˜æ˜¼ã€Šæ–°è®ºÂ·æƒœæ—¶ã€‹ï¼šâ€œäººä¹‹çŸ­ç”Ÿï¼ŒçŠ¹å¦‚çŸ³ç«ï¼Œç‚¯ç„¶è€Œè¿‡ã€‚â€æ¢¦ä¸­èº«ï¼Œè¯­å‡ºã€Šå…³å°¹å­Â·å››ç¬¦ã€‹ï¼šâ€œçŸ¥æ­¤èº«å¦‚æ¢¦ä¸­èº«ã€‚â€</p><p><a href="http://lib.xcz.im/work/57b2c8fa7db2a20054377ecd" target="_blank" rel="noopener">http://lib.xcz.im/work/57b2c8fa7db2a20054377ecd</a></p><hr><h3 id="2ï¸âƒ£æ—·æ€¡äº­å£å "><a href="#2ï¸âƒ£æ—·æ€¡äº­å£å " class="headerlink" title="2ï¸âƒ£æ—·æ€¡äº­å£å "></a>2ï¸âƒ£æ—·æ€¡äº­å£å </h3><p>[ç°ä»£] é©¬ä¸€æµ®<br>æµè½¬çŸ¥ä½•ä¸–ï¼Œæ±Ÿå±±å°šæ­¤äº­ã€‚<br>ç™»ä¸´çš†æ—·å£«ï¼Œä¸§ä¹±æœ‰é—ç»ã€‚<br><strong>å·²è¯†ä¹¾å¤å¤§ï¼ŒçŠ¹æ€œè‰æœ¨é’</strong>ã€‚<br>é•¿ç©ºé€é¸Ÿå°ï¼Œç•™å¹»ä¸äººçµã€‚</p><p><a href="http://lib.xcz.im/work/5992e274570c35006b8394b3" target="_blank" rel="noopener">http://lib.xcz.im/work/5992e274570c35006b8394b3</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†19</title>
      <link href="/2019/04/22/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8619/"/>
      <url>/2019/04/22/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8619/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>expand&amp;repeat</p><p>expandåªèƒ½å¯¹ç»´æ•°ä¸º1çš„ç»´åº¦è¿›è¡Œæ‰©å±•ï¼Œä¸”æ‰©å±•è¿‡ç¨‹ä¸­ä¸åˆ†é…æ–°å†…å­˜ï¼›repeatèƒ½å¯¹ä»»æ„ç»´åº¦è¿›è¡Œæ‰©å±•ï¼Œä½†éœ€è¦åˆ†é…æ–°å†…å­˜ã€‚</p><p>å¦‚æœæ»¡è¶³expandçš„éœ€è¦ï¼Œåº”å°½é‡ä½¿ç”¨expandã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯22</title>
      <link href="/2019/04/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D22/"/>
      <url>/2019/04/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D22/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜"><a href="#1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜" class="headerlink" title="1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜"></a>1ï¸âƒ£ä¹æ—¥é½å®‰ç™»é«˜</h3><p>[å”] æœç‰§<br>æ±Ÿæ¶µç§‹å½±é›åˆé£ï¼Œä¸å®¢æºå£¶ä¸Šç¿ å¾®ã€‚<br>å°˜ä¸–éš¾é€¢å¼€å£ç¬‘ï¼ŒèŠèŠ±é¡»æ’æ»¡å¤´å½’ã€‚<br>ä½†å°†é…©é…Šé…¬ä½³èŠ‚ï¼Œä¸ç”¨ç™»ä¸´æ¨è½æ™–ã€‚<br><strong>å¤å¾€ä»Šæ¥åªå¦‚æ­¤ï¼Œç‰›å±±ä½•å¿…ç‹¬æ²¾è¡£ï¼Ÿ</strong></p><p><a href="http://lib.xcz.im/work/57ba4972efa631005a799815" target="_blank" rel="noopener">http://lib.xcz.im/work/57ba4972efa631005a799815</a></p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡16</title>
      <link href="/2019/04/21/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8716/"/>
      <url>/2019/04/21/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8716/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡ï¼š</p><ol><li>MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES</li><li>Fine-Grained Attention Mechanism for Neural Machine Translation</li><li>Competence-based Curriculum Learning for Neural Machine Translation</li></ol><h2 id="1ï¸âƒ£-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES"><a href="#1ï¸âƒ£-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES" class="headerlink" title="1ï¸âƒ£[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]"></a>1ï¸âƒ£[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]</h2><p>æœ¬æ–‡æ¢ç©¶æ·±åº¦å­¦ä¹ ä¸­çš„è¿‡é‡å‚æ•°é—®é¢˜ï¼Œé€šè¿‡å®šä¹‰intrinsic dimensionï¼Œå»è¡¡é‡ç‰¹å®šæ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šæ‰€éœ€ç»´åº¦ã€‚</p><p>åœ¨ç»™å®šæ¨¡å‹ç»“æ„å’Œloss functionæ—¶ï¼Œæ•´ä¸ªä¼˜åŒ–ç©ºé—´ä¹Ÿéšä¹‹ç¡®å®šï¼Œè®­ç»ƒè¿‡ç¨‹ç±»ä¼¼äºåœ¨ä¸€ä¸ªç©ºé—´å†…ç§»åŠ¨ä½¿å¾—losså°½é‡å°ã€‚</p><p>ç»™å®šä¸€ä¸ªæœ‰Dä¸ªå‚æ•°çš„æ¨¡å‹ï¼Œé€šè¿‡é™åˆ¶è®­ç»ƒéšæœºsliceçš„å‚æ•°ï¼Œä¹Ÿå³é€‰å–ä¸€ä¸ªéšæœºæœ‰dä¸ªå‚æ•°çš„å­ç©ºé—´è®­ç»ƒï¼Œä¸æ–­å¢åŠ dï¼Œä½¿å¾—é¢„å®šä¹‰çš„solutionç¬¬ä¸€æ¬¡å‡ºç°ï¼Œåˆ™ç§°dä¸ºintrinsic dimensionï¼Œå¯ä»¥ç†è§£ä¸ºè¯¥dæ˜¯è§£å†³æŸç‰¹å®šé—®é¢˜æ‰€éœ€çš„å‚æ•°é‡ã€‚</p><p>å¦‚ä½•åšï¼Ÿ<br>$\theta^{(D)}=\theta_{0}^{(D)}+P \theta^{(d)}$<br>å…¶ä¸­Pæ˜¯éšæœºç”Ÿæˆçš„$D\times d$çš„æŠ•å½±çŸ©é˜µï¼Œè€Œ$\theta (d)$ æ˜¯å­ç©ºé—´çš„å‚æ•°ï¼›$P$æ˜¯å›ºå®šçš„è€Œä¸æ˜¯å¯è®­ç»ƒçš„ï¼Œä¸”$P$å¯ä»¥æ˜¯å½’ä¸€åŒ–ä¸ºå•ä½é•¿åº¦ä¸”æ­£äº¤çš„ã€‚</p><p><img src="/images/15559193313833.jpg" width="40%" height="50%"></p><p>ï¼ˆè¿™é‡Œçš„æŠ•å½±ç°åœ¨è¿˜æ˜¯ä¸èƒ½ç†è§£ï¼Ÿç­‰ä¹‹åçœ‹è¿™æ–¹é¢çš„è®ºæ–‡å†è¯´å§ï¼‰</p><p>å› ä¸ºä¸€äº›éšæœºæ€§ä»¥åŠå®é™…æ•ˆæœé—®é¢˜ï¼Œæ¯”å¦‚æ­£åˆ™åŒ–æ•ˆæœåœ¨å­ç©ºé—´æ— æ³•è¾¾åˆ°åœ¨å…¨ç©ºé—´çš„æ•ˆæœï¼Œå› æ­¤åœ¨è¿™é‡Œå®šä¹‰$d_{\mathrm{int} 90}$ï¼Œä¹Ÿå³è¾¾åˆ°baselineçš„90%æ‰€éœ€è¦çš„å‚æ•°é‡ã€‚</p><p>ä¸€äº›ç»“æœï¼š<br><img src="/images/15559195161338.jpg" width="70%" height="50%"></p><p>MNISTçš„æ¨¡å‹å¯ä»¥çœ‹åˆ°æ‰€éœ€å‚æ•°éå¸¸å°‘ï¼›æ¨ªå‘å¯¹æ¯”ï¼ŒCNNä¼šæ¯”å…¨è¿æ¥æ‰€éœ€çš„å°‘å¤šäº†ï¼Œè¿™ä¹Ÿç¬¦åˆæˆ‘ä»¬çš„ç›´è§‰ï¼Œä¹Ÿå³CNNæ¯”å…¨è¿æ¥æ›´é«˜æ•ˆã€‚</p><p><img src="/images/15559195378407.jpg" width="70%" height="50%"></p><p>åœ¨å…¨è¿æ¥ä¸­ï¼Œå¯¹äºæ¨¡å‹ä¸åŒçš„å®½åº¦ä»¥åŠlayeræ•°ï¼Œå‘ç°ä»–ä»¬çš„dint90ç›¸å·®ä¸å¤§ï¼Œè¯´æ˜å¯¹äºç‰¹å®šä»»åŠ¡ï¼ŒåŒä¸€ä¸ªæ¨¡å‹å®¶æ—æ‰€éœ€è¦çš„å‚æ•°é‡æ˜¯ç±»ä¼¼çš„ã€‚</p><hr><h2 id="2ï¸âƒ£-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation"><a href="#2ï¸âƒ£-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation" class="headerlink" title="2ï¸âƒ£[Fine-Grained Attention Mechanism for Neural Machine Translation]"></a>2ï¸âƒ£[Fine-Grained Attention Mechanism for Neural Machine Translation]</h2><p>æœ¬æ–‡æå‡ºå¯¹attentionè¿›è¡Œç»†åŒ–ï¼Œå°†åŸæ¥çš„æ¯ä¸ªè¯åˆ†é…ä¸€ä¸ªscoreæ‰©å±•ä¸ºæ¯ä¸ªè¯åˆ†é…dç»´ä¸ªscoreï¼Œå¹¶åœ¨æœºå™¨ç¿»è¯‘ä¸Šæœ‰ä¸€å®šæå‡ã€‚</p><p><img src="/images/15559197269175.jpg" width="80%" height="50%"></p><p>ç®€å•åœ°è¯´ï¼ŒåŸæ¥çš„attentionæœºåˆ¶æ˜¯ï¼š<br>$e_{t^{\prime}, t}=f_{\mathrm{Att}}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}\right)$</p><p>å…¶ä¸­$t^{\prime}$æ˜¯decoderç«¯çš„æ—¶é—´æ­¥ï¼Œ$t$åˆ™æ˜¯encoderç«¯çš„ç¬¬$t$ä¸ªè¯ã€‚</p><p>è€Œæœ¬æ–‡çš„ç»†ç²’åº¦attentionæœºåˆ¶ï¼š<br>$e_{t^{\prime}, t}^{d}=f_{\mathrm{Att} \mathrm{Y} 2 \mathrm{D}}^{d}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}, \boldsymbol{y}_{t^{\prime}-1}\right)$</p><p>ä¹Ÿå³åœ¨åŸæ¥çš„åŸºç¡€ä¸Šåšäº†dæ¬¡æ“ä½œï¼Œä¹Ÿå³å®é™…ä¸Šåœ¨è·å¾—æ¯ä¸€ç»´çš„åˆ†æ•°æ—¶ï¼Œæ˜¯èƒ½çœ‹åˆ°å…¶ä»–ç»´çš„ä¿¡æ¯çš„ã€‚ï¼ˆå¦‚æœæ˜¯æˆ‘è‡ªå·±åšï¼Œæˆ‘å¯èƒ½ä¼šå°†ä»–ä»¬éš”ç»å¼€æ¥ã€‚ï¼‰</p><p>æ€è€ƒï¼š<br>å°†RNNä½œä¸ºbaselineï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨transformerï¼Ÿå½“æ—¶transformerå·²ç»å‡ºäº†ï¼Œå¯èƒ½æ˜¯transformerä¸Šæ²¡æ•ˆæœï¼Ÿå› ä¸ºtransformerè‡ªå¸¦å¤šheadï¼Œå¯èƒ½è¡¨ç¤ºèƒ½åŠ›å°±å·²ç»è¶³å¤Ÿäº†ã€‚</p><hr><h2 id="3ï¸âƒ£-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#3ï¸âƒ£-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="3ï¸âƒ£[Competence-based Curriculum Learning for Neural Machine Translation]"></a>3ï¸âƒ£[Competence-based Curriculum Learning for Neural Machine Translation]</h2><h3 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h3><p>æå‡ºä¸€ç§æ–°çš„<strong>è®­ç»ƒ</strong>ç¿»è¯‘æ¨¡å‹çš„ç®—æ³•ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯è®©æ¨¡å‹ä»ç®€å•çš„æ ·ä¾‹å¼€å§‹å­¦èµ·ï¼Œéšç€è®­ç»ƒè¿‡ç¨‹çš„è¿›è¡Œé€æ¸å¢åŠ éš¾åº¦è¾ƒå¤§çš„æ ·ä¾‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¢å¼ºæ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œä¸”åœ¨æ•ˆæœä¸Šä¹Ÿæœ‰æå‡ï¼ŒåŒæ—¶è¿˜èƒ½å‡å°‘æ”¶æ•›æ‰€éœ€çš„è®­ç»ƒæ—¶é—´ã€‚</p><p><img src="/images/15559206435828.jpg" width="50%" height="50%"></p><p>è®ºæ–‡çš„Motivationï¼šå¦‚æœè®­ç»ƒæ•°æ®ä»¥ç‰¹å®šçš„é¡ºåºè¾“å…¥ï¼Œä¹Ÿå³ä»ç®€å•çš„æ•°æ®å¼€å§‹å­¦ï¼Œç­‰åˆ°æ¨¡å‹æœ‰ä¸€å®šçš„èƒ½åŠ›åå†å»å­¦éš¾çš„æ•°æ®ï¼Œè¿™æ ·ä¹Ÿæ›´ç¬¦åˆäººç±»çš„ç›´è§‰ï¼›åŒæ—¶ï¼Œä»æœºå™¨å­¦ä¹ çš„è§’åº¦å»çœ‹ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥é¿å…è¿‡æ—©é™·å…¥ä¸å¥½çš„å±€éƒ¨æœ€ä¼˜è§£ã€‚</p><p>è®ºæ–‡è¿˜æåˆ°äº†å¯¹äºç¿»è¯‘è€Œè¨€ï¼Œæ¨¡å‹å¾ˆéš¾è®­ç»ƒï¼Œéœ€è¦å¤æ‚çš„è°ƒå‚ï¼Œè´¹æ—¶è´¹åŠ›ã€‚ç‰¹åˆ«æ˜¯å¯¹äºTransformerè€Œè¨€ï¼Œéœ€è¦ç²¾ç»†çš„learning rate scheduleã€‚</p><p>æœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼Œåªæœ‰ä¸€ä¸ªå‚æ•°ï¼Œå› æ­¤ä¸éœ€è¦ç²¾ç»†çš„è°ƒå‚ï¼ŒåŒæ—¶å› ä¸ºåªæ”¹å˜è¾“å…¥çš„pipelineï¼Œå› æ­¤å¾ˆæ–¹ä¾¿åœ°ä½¿ç”¨åˆ°å·²æœ‰çš„æ¨¡å‹ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å¼•å…¥ä¸¤ä¸ªæ¦‚å¿µï¼š<br><strong>Difficulty</strong>ï¼šä»£è¡¨ä¸€ä¸ªè®­ç»ƒæ ·ä¾‹çš„éš¾åº¦ï¼Œå¯èƒ½å’Œæ¨¡å‹å½“å‰çš„çŠ¶æ€ç›¸å…³ã€‚æ¯”å¦‚å¥å­é•¿åº¦å°±æ˜¯è¡¡é‡æ ·ä¾‹éš¾åº¦çš„ä¸€ä¸ªæŒ‡æ ‡ã€‚</p><p><strong>Competence</strong>ï¼šèŒƒå›´0-1çš„æ•°å€¼ï¼Œä»£è¡¨æ¨¡å‹è®­ç»ƒçš„è¿›åº¦ï¼Œå®šä¹‰ä¸ºæ¨¡å‹çŠ¶æ€çš„ä¸€ä¸ªå‡½æ•°ã€‚æ›´è¿›ä¸€æ­¥ï¼Œå®šä¹‰$c(t)$ä¸ºæ¨¡å‹åœ¨æ—¶é—´æ­¥tæ‰€å…è®¸ä½¿ç”¨çš„è®­ç»ƒæ ·ä¾‹çš„æ¯”ä¾‹ã€‚ä¹Ÿå³è®­ç»ƒæ ·ä¾‹æ ¹æ®difficultyæ’åˆ—ï¼Œåœ¨æ—¶é—´æ­¥$t$åªå…è®¸top $c(t)$çš„æ•°æ®ä½¿ç”¨ã€‚</p><p>æ ¹æ®ä¸Šè¿°ä¸¤ä¸ªå®šä¹‰ï¼Œå¼•å…¥ç®—æ³•ï¼š<br><img src="/images/15559212081520.jpg" width="50%" height="50%"></p><p><img src="/images/15559212315953.jpg" width="100%" height="50%"></p><p><img src="/images/15559212598339.jpg" width="50%" height="50%"></p><p>é‚£ä¹ˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œå¦‚ä½•è¡¡é‡difficultyä»¥åŠcompetenceï¼Ÿ</p><h4 id="Difficulty-Metrics"><a href="#Difficulty-Metrics" class="headerlink" title="Difficulty Metrics"></a>Difficulty Metrics</h4><p>â‘ å¥å­é•¿åº¦<br>é•¿å¥å­æ›´éš¾ç¿»è¯‘ï¼Œå› ä¸ºé•¿å¥å­å¾€å¾€åŒ…å«äº†çŸ­å¥å­ï¼ŒåŒæ—¶åœ¨ç”Ÿæˆç›®æ ‡è¯­è¨€æ—¶ï¼Œå®¹æ˜“å‡ºç°é”™è¯¯ä¼ æ’­ã€‚</p><script type="math/tex; mode=display">d_{\text { length }}\left(s_{i}\right) \triangleq N_{i}</script><p>â‘¡Word Rarity<br>è‹¥ä¸€ä¸ªå¥å­å­˜åœ¨ç½•è§è¯ï¼Œæ›´éš¾ç¿»è¯‘è¯¥å¥å­ï¼Œå› ä¸ºæ¨¡å‹éœ€è¦å¤šæ¬¡çœ‹è§è¯¥è¯æ‰èƒ½å­¦åˆ°é²æ£’çš„è¡¨ç¤ºï¼›åŒæ—¶ç½•è§è¯çš„æ¢¯åº¦å®¹æ˜“æœ‰è¾ƒå¤§çš„æ–¹å·®ã€‚</p><p>å› æ­¤æˆ‘ä»¬å®šä¹‰ç›¸å¯¹è¯é¢‘ï¼š</p><script type="math/tex; mode=display">\hat{p}\left(w_{j}\right) \triangleq \frac{1}{N_{\text {total }}} \sum_{i=1}^{M} \sum_{k=1}^{N_{i}} \mathbb{1}_{w_{k}^{i}=w_{j}}</script><p>å…¶ä¸­ï¼Œ$j=1, \ldots, \{\text {unique words in corpus}\}$ï¼Œ$\mathbb{1}$ ä¸ºæŒ‡ç¤ºå‡½æ•°ã€‚</p><p>å› æ­¤æœ€ç»ˆåº¦é‡æ–¹æ³•ä¸ºï¼š<br>$d_{\text {rarity}}\left(s_{i}\right) \triangleq-\sum_{k=1}^{N_{i}} \log \hat{p}\left(w_{k}^{i}\right)$</p><p>è¿™æ ·å³è€ƒè™‘åˆ°äº†é•¿åº¦ä¹Ÿè€ƒè™‘åˆ°äº†è¯é¢‘ï¼ŒåŒæ—¶è¯¥æ–¹æ³•æœ‰ç‚¹ç±»ä¼¼language modelï¼Œå¯ä»¥ç†è§£ä¸ºlanguage modelçš„è¿‘ä¼¼ã€‚</p><h4 id="Competence-Functions"><a href="#Competence-Functions" class="headerlink" title="Competence Functions"></a>Competence Functions</h4><p>æˆ‘ä»¬å®šä¹‰competence functionåªä¸æ—¶é—´æ­¥$t$æœ‰å…³ï¼Œå› æ­¤åªéœ€è¦è€ƒè™‘å…·ä½“çš„å½¢å¼ã€‚<br>â‘ linearï¼š</p><script type="math/tex; mode=display">c(t) \triangleq \min \left(1, t r+c_{0}\right)</script><p>$c_{0}$æ˜¯åˆå§‹å€¼ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰Tä¸ºæ—¶é—´æ­¥é˜ˆå€¼ï¼Œå½“è¶…è¿‡è¯¥é˜ˆå€¼ï¼Œæˆ‘ä»¬è®¤ä¸ºæ¨¡å‹å·²ç»å®Œå…¨æœ‰èƒ½åŠ›äº†ï¼Œåˆ™ä¸Šå¼è¿˜å¯ä»¥å†™æˆï¼š</p><script type="math/tex; mode=display">c_{\text { linear }}(t) \triangleq \min \left(1, t \frac{1-c_{0}}{T}+c_{0}\right)</script><p>â‘¡Rootï¼š<br>çº¿æ€§çš„ä¸€ä¸ªä¸å¥½çš„åœ°æ–¹ï¼Œå½“æ ·ä¾‹å¢åŠ æ—¶ï¼Œæ¯ä¸ªæ ·ä¾‹è¢«sampleçš„å‡ ç‡å‡å°ï¼Œå› æ­¤æ–°åŠ è¿›å»çš„æ ·ä¾‹è¢«sampleåˆ°çš„å‡ ç‡ä¹Ÿå‡å°ï¼Œå› æ­¤åº”æ¯æ¬¡å‡å°‘æ–°åŠ å…¥çš„æ ·ä¾‹ï¼Œä½¿å¾—æ¨¡å‹æœ‰è¶³å¤Ÿçš„æ—¶é—´å»å­¦ä¹ çŸ¥è¯†ã€‚<br>ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\frac{d c(t)}{d t}=\frac{P}{c(t)}</script><p>ç§¯åˆ†åå¯å¾—ï¼š</p><script type="math/tex; mode=display">c_{\mathrm{sqrt}}(t) \triangleq \min \left(1, \sqrt{t \frac{1-c_{0}^{2}}{T}+c_{0}^{2}}\right)</script><p>å½“ç„¶è¿˜å¯ä»¥å°†å¼€næ¬¡æ–¹æ ¹</p><script type="math/tex; mode=display">c_{\mathrm{root}-p}(t) \triangleq \min \left(1, \sqrt[p]{t \frac{1-c_{0}^{p}}{T}+c_{0}^{p}}\right)</script><p>ä½¿å¾—æ›²çº¿æ›´ä¸ºé™¡å³­ï¼Œä¹Ÿå³ç»™æ¯ä¸ªæ ·ä¾‹çš„æ—¶é—´æ›´å¤šã€‚</p><p>æ›²çº¿å¯¹æ¯”ï¼š<br><img src="/images/15559218944874.jpg" width="50%" height="50%"></p><p>å®éªŒè¯æ˜æ˜¯p=2æ—¶æœ€å¥½ã€‚</p><h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p><img src="/images/15559219317633.jpg" width="70%" height="50%"></p><p>å®éªŒæœ‰ç›¸å½“ä¸é”™çš„ç»“æœï¼Œåœ¨RNNä»¥åŠåœ¨Transformerä¸Šéƒ½æœ‰æå‡ï¼Œå¹¶ä¸”æ˜¯åœ¨ä¸ç”¨learning rate scheduleçš„æƒ…å†µä¸‹ï¼Œå¹¶ä¸”æ—¶é—´æ›´çŸ­ã€‚</p><p>å‡ ä¸ªå®éªŒç°è±¡ï¼š<br>â‘ RNNçš„æå‡è¾ƒå°‘ï¼Œè€ŒTransformerå¾ˆå¤šï¼Œè¯´æ˜RNNæ¯”Transformeræ›´é²æ£’ã€‚RNNæ¯”Transformerè®­ç»ƒæ›´ä¸ºç¨³å®šã€‚<br>â‘¡å¯¹äºTransformerè€Œè¨€ï¼Œè‹¥åŒæ ·ä½¿ç”¨learning rate scheduleï¼Œä»ç„¶æœ‰å¸®åŠ©ï¼Œè¯´æ˜è¯¥æ–¹æ³•æ˜¯è¾ƒä¸ºé€šç”¨çš„ã€‚<br>â‘¢ä¸ä½¿ç”¨lr scheduleè€Œåªä½¿ç”¨æœ¬æ–‡æ–¹æ³•ï¼Œä¹Ÿèƒ½è¾¾åˆ°ä¸ä½¿ç”¨æœ¬æ–‡æ–¹æ³•è€Œä½¿ç”¨lr scheduleçš„ç»“æœï¼Œä½†éœ€è¦æ›´å¤šçš„stepã€‚</p><h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>ä¸ºä»€ä¹ˆè¯¥æ–¹æ³•èƒ½workï¼Ÿ<br>ç¬¦åˆç›´è§‰ï¼Œæ¨¡å‹ä»ç®€å•åˆ°éš¾ï¼Œæ›´å¥½è®­ã€‚åŒæ—¶ä»æœºå™¨å­¦ä¹ è§’åº¦ï¼Œå¦‚æœå®Œå…¨æ­£å¸¸çš„sampleï¼Œåˆ™å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°æˆ–è€…saddle pointï¼Œå› æ­¤éœ€è¦æ›´é•¿æ—¶é—´æˆ–è€…ä¸å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</p><p>åŒæ—¶è®ºæ–‡è¿˜æåˆ°äº†ï¼Œä¸ºä»€ä¹ˆTransformeråœ¨å¢åŠ batchèƒ½å¤Ÿæœ‰æ›´å¥½çš„æ”¶æ•›ï¼Œè¿™æ˜¯å› ä¸ºä¸€å¼€å§‹è®­ç»ƒçš„noisy gradientå¤ªå¤§ï¼Œè‹¥å¢åŠ batchèƒ½å¤Ÿä¿¡å™ªæ¯”ï¼Œè€Œæœ¬æ–‡æ–¹æ³•åœ¨æŸç§ç¨‹åº¦ä¸Šä¹Ÿè§£å†³äº†è¯¥é—®é¢˜ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> NMT </tag>
            
            <tag> Curriculum Learning </tag>
            
            <tag> intrinsic dimension </tag>
            
            <tag> attention mechanism </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Transformerç›¸å…³è¿‘æœŸç›˜ç‚¹</title>
      <link href="/2019/04/12/%E8%AE%BA%E6%96%87/Transformer%E7%9B%B8%E5%85%B3%E8%BF%91%E6%9C%9F%E7%9B%98%E7%82%B9/"/>
      <url>/2019/04/12/%E8%AE%BA%E6%96%87/Transformer%E7%9B%B8%E5%85%B3%E8%BF%91%E6%9C%9F%E7%9B%98%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>è¿‘å¹´æ¥è‡ªç„¶è¯­è¨€å¤„ç†æœ‰ç›¸å½“å¤§çš„è¿›å±•ï¼Œå›¿äºä¸ªäººæµ…è–„çš„èƒ½åŠ›ï¼Œå› æ­¤ä»…è°ˆè°ˆè‡ªå·±è¾ƒä¸ºäº†è§£çš„ä¸Transformerç›¸å…³ä¸€è·¯ä¸‹æ¥çš„ä¸€äº›å·¥ä½œã€‚è¿™ç¯‡çš„ä¸»è¦ç›®çš„æ˜¯å®Œæˆé‚±åšç»™æˆ‘çš„ä»»åŠ¡ï¼Œä¹Ÿé¡ºä¾¿æ¢³ç†ä¸€ä¸‹æ€ç»ªã€‚</p><hr><p>è‡ª2017å¹´çš„é—®ä¸–ï¼ŒTransformerå°±å¸å¼•äº†å¤§æ‰¹å­¦è€…çš„æ³¨æ„ï¼Œ2018å¹´Bertçš„å‡ºç°ï¼Œæ›´æ˜¯å°†Transformeræ¨ä¸Šäº†NLPèˆå°çš„ä¸­å¤®ã€‚Transformerä»¥å…¶é«˜æ•ˆç‡ï¼ˆé«˜å¹¶è¡Œæ€§ï¼‰ä»¥åŠæå¼ºçš„æ¨¡å‹èƒ½åŠ›ï¼Œä¿¨ç„¶æœ‰æ›¿ä»£ä¼ ç»ŸRNN/CNNçš„æ€åŠ¿ã€‚å› æ­¤æœ¬æ¬¡å°±è®¨è®ºè®¨è®ºTransformeråŠå…¶ç³»åˆ—ï¼ŒåŒæ—¶æœ€ååŠ ä¸Šæˆ‘ä¸ªäººå…³äºRNN/CNN/Transformerçš„ä¸€ç‚¹æ€è€ƒã€‚</p><p>è¦ç‚¹ï¼š</p><ol><li>TransformeråŠå…¶å˜ä½“</li><li>Transformeråœ¨å…¶ä»–ä»»åŠ¡</li><li>é¢„è®­ç»ƒæ¨¡å‹</li><li>Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ</li></ol><h2 id="TransformeråŠå…¶å˜ä½“"><a href="#TransformeråŠå…¶å˜ä½“" class="headerlink" title="TransformeråŠå…¶å˜ä½“"></a>TransformeråŠå…¶å˜ä½“</h2><h3 id="Transformerç®€å•å›é¡¾"><a href="#Transformerç®€å•å›é¡¾" class="headerlink" title="Transformerç®€å•å›é¡¾"></a>Transformerç®€å•å›é¡¾</h3><p>Transformer[1]é‡‡ç”¨å®Œå…¨çš„attentionæœºåˆ¶ç”¨ä»¥åºåˆ—å»ºæ¨¡ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œè¿™æ˜¯é€šè¿‡attentionæœºåˆ¶æ¥å®ç°çš„ã€‚</p><h4 id="Transformeræ¨¡å‹æ¶æ„"><a href="#Transformeræ¨¡å‹æ¶æ„" class="headerlink" title="Transformeræ¨¡å‹æ¶æ„"></a>Transformeræ¨¡å‹æ¶æ„</h4><p>Transformeræ¶æ„ï¼š<br><img src="/images/15550349717464.jpg" width="50%" height="50%"></p><p>ç”±äºTransformeræœ€æ—©ç”±äºç¿»è¯‘æ¨¡å‹ä¸­ï¼Œå› æ­¤æ¶æ„æ˜¯ç”±ä¸€ä¸ªencoderå’Œä¸€ä¸ªdecoderç»„æˆï¼Œè€Œencoderå’Œdecoderéƒ½æ˜¯ç”±å¤šä¸ªåŸºæœ¬çš„blockå †å è€Œæˆã€‚ä¸€ä¸ªblockç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¹Ÿå³multi-head attentionå±‚å’ŒPosition-wise Feed-Forward Networkså±‚ã€‚</p><h5 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h5><p>å¯¹äºåºåˆ—ä¸­ä¸€ä¸ªç‰¹å®šèŠ‚ç‚¹$x_i$ï¼Œ$x_i$ä½œä¸ºqueryï¼Œå…¶ä»–èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰ä½œä¸ºkeyå’Œvalueï¼Œé€šè¿‡å‘é‡ç‚¹ç§¯è®¡ç®—å‡ºattentionåˆ†æ•°ï¼Œè¿›è¡Œå½’ä¸€åŒ–åï¼ˆsoftmaxï¼‰å°†valueåŠ æƒå¹³å‡è·å¾—è¯¥èŠ‚ç‚¹$x_i$æ–°çš„è¡¨ç¤ºã€‚<br>åŒæ—¶ï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œä¸ºäº†å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œå¯ä»¥å°†å…¶æ˜ å°„åˆ°å¤šä¸ªä¸åŒéšç©ºé—´ä¸­ï¼Œåˆ†åˆ«å®Œæˆä¸Šè¿°åŸºæœ¬æ“ä½œã€‚</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br><img src="/images/15550350386364.jpg" width="70%" height="50%"></p><p>å·¦å›¾ä¸ºåŸºæœ¬æ“ä½œä¹Ÿå³scale-dot productï¼Œå³å›¾ä¸ºå¤šä¸ªscale-dot productåœ¨ä¸åŒéšç©ºé—´åŒæ—¶è¿›è¡Œï¼Œå¹¶ä¸”å°†å¤šä¸ªheadçš„ç»“æœæ‹¼æ¥èµ·æ¥ä½œä¸ºæœ€ç»ˆç»“æœã€‚</p><h5 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h5><p>ä¸ºäº†å¢å¼ºæ¨¡å‹è¡¨ç¤ºèƒ½åŠ›ï¼Œåœ¨Multi-head attentionä¹‹åï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½è¿‡ä¸¤å±‚MLPä»¥è·å¾—æ–°çš„å‘é‡è¡¨ç¤ºã€‚<br>ä¹Ÿå³:</p><script type="math/tex; mode=display">\mathrm{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}</script><p>ç›¸æ¯”ä¼ ç»Ÿçš„RNN/CNNè€Œè¨€ï¼Œå…¶æœ€å¤§çš„ä¼˜åŠ¿æ˜¯å…¨å±€çš„æ„Ÿå—é‡ï¼ˆGlobal Receptive Fieldï¼‰ä»¥åŠé«˜åº¦å¹¶è¡Œæ€§ï¼ˆparallelizationï¼‰ã€‚</p><h3 id="å˜ä½“"><a href="#å˜ä½“" class="headerlink" title="å˜ä½“"></a>å˜ä½“</h3><h4 id="Universal-Transformers"><a href="#Universal-Transformers" class="headerlink" title="Universal Transformers"></a>Universal Transformers</h4><p>æå‡ºä¸€ç§æ–°å‹é€šç”¨çš„Transformerï¼Œåœ¨Transformerçš„åŸºç¡€ä¸Šå¼•å…¥RNNçš„å½’çº³åç½®(inductive bias)ï¼Œä¹Ÿå³è¿­ä»£å­¦ä¹ (learning iterative)çš„ç‰¹å¾ã€‚Universal Transformer[2]çš„ä¸»è¦ç‰¹ç‚¹æœ‰ï¼š</p><ol><li>åœ¨Transformerä¸­æ¯å±‚çš„æƒé‡æ˜¯ç‹¬ç«‹çš„ï¼Œè€Œåœ¨Universal Transformerä¸­ï¼Œæ¯å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³multi-head Attentionä¸Feed-Forwardåœ¨æ¯å±‚çš„æƒé‡æ˜¯ä¸€è‡´çš„ã€‚</li><li>åœ¨Transformerä¸­å¼•å…¥è‡ªé€‚åº”è®¡ç®—æ—¶é—´(Adaptive Computation Time, ACT[3])ï¼Œä¹Ÿå³å¯¹äºä¸åŒçš„è¯å…è®¸è¿­ä»£ä¸åŒæ¬¡æ•°ã€‚è¿™æ˜¯åŸºäºæœ‰äº›è¯ç›¸æ¯”å…¶ä»–è¯è¯æ„æ›´ä¸°å¯Œï¼Œæ›´éš¾è¢«æ¨¡å‹å­¦ä¼šï¼Œå› æ­¤éœ€è¦æ›´å¤šçš„è¿­ä»£æ¬¡æ•°ã€‚ä¸å›ºå®šå±‚æ•°çš„Transformerç›¸æ¯”æœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li></ol><p>å› æ­¤å…¶æ€»ä½“ç»“æ„ä¸ºï¼š<br><img src="/images/15556585300051.jpg" width="70%" height="50%"></p><p>åœ¨è¿™é‡Œæœ‰ä¸¤ä¸ªç»†èŠ‚ï¼š</p><ol><li>åŠ äº†Timestep embeddingå»æŒ‡ç¤ºå½“å‰è¿­ä»£çš„æ¬¡æ•°</li><li>å°†Feedforward Functionç”¨æ›´ä¸ºé€šç”¨çš„Transition Functionï¼Œå¯ä»¥æ˜¯æ™®é€šçš„å…¨è¿æ¥ï¼Œä¹Ÿå¯ä»¥æ˜¯å‚æ•°æ›´å°‘çš„Depth-wise Convolutionã€‚</li></ol><h4 id="Star-Transformer"><a href="#Star-Transformer" class="headerlink" title="Star Transformer"></a>Star Transformer</h4><p>Star Transformer[20]æ˜¯ä¸€ç§è½»é‡çº§çš„Transformerï¼Œé€šè¿‡å°†å…¨è¿æ¥çš„ç»“æ„æ›¿æ¢ä¸ºæ˜Ÿå‹æ‹“æ‰‘ç»“æ„ï¼Œæ˜¾è‘—å‡å°Transformerçš„å¤æ‚åº¦ï¼Œä»$O(n^2)$å‡ä¸º$O(n)$ã€‚</p><p><img src="/images/15556834830687.jpg" width="50%" height="50%"></p><p>å…¶ä¸»è¦æ€æƒ³æ˜¯â€™Gather-Distributeâ€™ï¼Œä¹Ÿå³æ¯ä¸ªèŠ‚ç‚¹ä¸ç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œæ˜¯ä¸å…¨å±€èŠ‚ç‚¹è¿›è¡Œäº¤äº’ã€‚<br><img src="/images/15556836008776.jpg" width="50%" height="50%"></p><p>å®éªŒè¡¨æ˜ï¼ŒStar Transformerä¸ä»…åœ¨å¤šä¸ªæ•°æ®é›†è¡¨ç°æ›´ä¼˜ï¼Œä¸”é€Ÿåº¦æ›´å¿«ã€‚</p><p><img src="/images/15557700601922.jpg" width="90%" height="50%"></p><p><img src="/images/15557701172639.jpg" width="90%" height="50%"></p><h4 id="å…¶ä»–å°æ”¹è¿›"><a href="#å…¶ä»–å°æ”¹è¿›" class="headerlink" title="å…¶ä»–å°æ”¹è¿›"></a>å…¶ä»–å°æ”¹è¿›</h4><p>æ¥ä¸‹æ¥ä»‹ç»åŸºäºTransformerçš„å‡ ä¸ªå°æ”¹è¿›å·¥ä½œã€‚</p><p>åœ¨Convolutional Self-Attention Network[5]ä¸­ï¼Œé€šè¿‡åœ¨self-attentionå±‚å¼•å…¥CNNçš„å½’çº³åç½®ï¼Œåœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šæœ‰ä¸€å®šçš„æå‡ã€‚å…·ä½“åšæ³•ï¼š<br><img src="/images/15556604248879.jpg" width="80%" height="50%"><br>æ™®é€šself-attentionå±‚ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹äº¤äº’ï¼Œè€Œåœ¨1D-Convolutionalçš„self-attentionå±‚ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹åªèƒ½ä¸ä»¥è¯¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„çª—å£å†…çš„èŠ‚ç‚¹äº¤äº’ã€‚è€Œåœ¨2D-Convolutionä¸­ï¼Œå¯¹headè¿™ä¸€ç»´è¿›è¡Œæ‰©å±•ï¼Œä¹Ÿå³å¯¹äºä»»æ„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸ä»…èƒ½å’Œå‘¨å›´çš„èŠ‚ç‚¹äº¤äº’ï¼Œè¿˜å¯ä»¥ä¸å…¶ä»–headçš„èŠ‚ç‚¹äº¤äº’ã€‚<br>å®éªŒç»“æœï¼š<br><img src="/images/15556607769307.jpg" width="80%" height="50%"></p><p>åœ¨Multi-Head Attention with Disagreement Regularization[6]ä¸­ï¼Œæ˜¾å¼å¯¹multi-head attentionæ·»åŠ æ­£åˆ™åŒ–ï¼Œä½¿å¾—ä¸åŒheadå°½é‡åŒºåˆ†å¼€æ¥ï¼Œä»¥ä½¿å¾—ä¸åŒheadæ•è·åˆ°ä¸åŒçš„ç‰¹å¾ã€‚è®ºæ–‡æå‡ºäº†ä¸‰ç§ä¸åŒä½ç½®çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼š<br>â‘ å¯¹Valueï¼š</p><script type="math/tex; mode=display">D_{\text {subpace}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H} \frac{V^{i} \cdot V^{j}}{\left\|V^{i}\right\|\left\|V^{j}\right\|}</script><p>ä¹Ÿå³å¯¹ä¸åŒheadä¹‹é—´çš„valueï¼Œè®¡ç®—ä»–ä»¬ä¹‹é—´çš„coså€¼ï¼Œä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¹‹ä¸€ã€‚</p><p>â‘¡å¯¹Attentionæƒé‡ï¼š</p><script type="math/tex; mode=display">D_{\text {position}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H}\left|A^{i} \odot A^{j}\right|</script><p>ä¹Ÿå³å°†æ¯ä¸ªheadæ‰€è®¡ç®—å¾—åˆ°çš„attentionçŸ©é˜µï¼Œè®¡ç®—ä»–ä»¬ä¹‹é—´çš„element-wiseä¹˜æ³•ï¼Œä½œä¸ºä¼˜åŒ–ç›®æ ‡ä¹‹ä¸€ã€‚</p><p>â‘¢å¯¹è¾“å‡ºï¼š</p><script type="math/tex; mode=display">D_{\text {output}}=-\frac{1}{H^{2}} \sum_{i=1}^{H} \sum_{j=1}^{H} \frac{O^{i} \cdot O^{j}}{\left\|O^{i}\right\|\left\|O^{j}\right\|}</script><p>ä¹Ÿå³å¯¹æ¯ä¸ªheadçš„è¾“å‡ºé€šè¿‡coså€¼è¿›è¡Œæ­£åˆ™åŒ–ã€‚</p><p>Modeling Localness for Self-Attention Networks[7]åˆ™æ˜¯é€šè¿‡åŠ å¼ºå¯¹å±€éƒ¨ä¿¡æ¯çš„å…³æ³¨ï¼Œåœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šæå‡è¡¨ç°ã€‚å…¶ä¸»è¦çš„åŠ¨æœºæ˜¯ï¼šâ‘ åœ¨Transformerä¸­æ¯ä¸ªè¯éƒ½ç›´æ¥ä¸æ‰€æœ‰è¯äº¤äº’ï¼Œå¯¹æ‰€æœ‰è¯è¿›è¡Œçº¿æ€§åŠ æƒå¯¼è‡´å¯¹é‚»è¿‘è¯çš„å…³æ³¨ä¸å¤Ÿï¼ˆå› ä¸ºæƒé‡çš„åˆ†æ•£ï¼‰ï¼›â‘¡ä»ç›´æ¥ä¸Šçœ‹ï¼Œå½“è¯$i$ä¸è¯$j$æœ‰å¯¹é½å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸è¯$j$å‘¨å›´çš„è¯ä¹Ÿå¯¹é½ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•è·æ•´ä¸ªè¯­ä¹‰å•å…ƒçš„ä¿¡æ¯ã€‚å…¶å…·ä½“åšæ³•æ˜¯åœ¨softmaxå‡½æ•°å†…å¢åŠ ä¸€ä¸ªé«˜æ–¯åç½®ï¼ˆGaussian biasï¼‰å»ä¿®æ­£attentionæƒé‡åˆ†å¸ƒï¼š</p><script type="math/tex; mode=display">\operatorname{ATT}(Q, K)=\operatorname{softmax}(\text {energy}+G)</script><p>$G_{ij}$æ˜¯è¡¡é‡è¯jä¸è¯iæ‰€é¢„æµ‹çš„ä¸­å¿ƒè¯ä¹‹é—´çš„è”ç³»ç´§å¯†ç¨‹åº¦ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">G_{i, j}=-\frac{\left(j-P_{i}\right)^{2}}{2 \sigma_{i}^{2}}</script><p>å…¶ä¸­$\sigma_{i}=\frac{D_{i}}{2}$ï¼Œ$D_{i}$æ˜¯çª—å£å¤§å°ã€‚è€Œ$P_{i}$æ˜¯é€šè¿‡è®¡ç®—å¾—å‡ºçš„ï¼Œ$P_{i}$ä¸å¯¹åº”çš„queryæœ‰å…³ï¼Œå› æ­¤å¯ä»¥é€šè¿‡$p_{i}=U_{p}^{T} \tanh \left(W_{p} Q_{i}\right)$è®¡ç®—å¾—åˆ°ï¼›è€Œçª—å£å¤§å°$D_{i}$å¯ä»¥æœ‰å¤šç§é€‰æ‹©ï¼Œâ‘ å›ºå®šçª—å£å¤§å°ï¼›â‘¡æ¯å±‚ç‰¹å®šçš„å¤§å°ï¼Œä¹Ÿå³å°†è¯¥å±‚çš„keyå¹³å‡èµ·æ¥ï¼Œé€šè¿‡$z=U_{d}^{T} \tanh \left(W_{d} \overline{\mathbf{K}}\right)$è®¡ç®—ï¼›â‘¢æ¯ä¸ªqueryéƒ½æœ‰è‡ªå·±çš„çª—å£å¤§å°ï¼š$z_{i}=U_{d}^{T} \tanh \left(W_{p} Q_{i}\right)$ã€‚</p><p>Self-attention with relative position representations[8]åˆ™æ˜¯å°†Transformerä¸­çš„ç»å¯¹ä½ç½®embeddingæ”¹ä¸ºç›¸å¯¹ä½ç½®embeddingä»¥æå‡ç¿»è¯‘æ•ˆæœã€‚</p><h2 id="Transformeråœ¨å…¶ä»–ä»»åŠ¡"><a href="#Transformeråœ¨å…¶ä»–ä»»åŠ¡" class="headerlink" title="Transformeråœ¨å…¶ä»–ä»»åŠ¡"></a>Transformeråœ¨å…¶ä»–ä»»åŠ¡</h2><h3 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer XL"></a>Transformer XL</h3><p>æœ¬æ–‡æ¢ç´¢å°†Transformerç”¨äºè¯­è¨€æ¨¡å‹(language model)ï¼Œå¹¶åœ¨Transformerå¼•å…¥RNNçš„å½’çº³åç½®ï¼Œä¹Ÿå³RNNçš„å†å²ä¿¡æ¯ï¼Œä½¿å¾—Transformerèƒ½å¤Ÿå¤„ç†é•¿å¥å­ã€‚</p><p>ç”±äºTransformerçš„å¤æ‚åº¦æ˜¯$O(n^2)$ï¼Œè™½ç„¶åœ¨GPUä¸Šèƒ½å¤Ÿå¹¶è¡Œæ“ä½œï¼Œä½†å ç”¨æ˜¾å­˜è¾ƒå¤§ï¼Œå› æ­¤åœ¨å®ç°æ—¶ï¼Œé€šå¸¸æ˜¯å°†å¥å­åˆ‡åˆ†ä¸ºä¸€ä¸ªä¸€ä¸ªsegmentï¼Œsegmentä¹‹é—´æ²¡æœ‰è”ç³»ï¼š</p><p><img src="/images/15556764280028.jpg" width="30%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œåˆ™æ¯ç”Ÿæˆä¸€ä¸ªè¯æ—¶æ»‘åŠ¨ä¸€ä¸ªçª—å£ï¼š</p><p><img src="/images/15556765079362.jpg" width="60%" height="50%"></p><p>è¿™æ ·çš„æ–¹æ³•æ˜¾ç„¶æ•ˆç‡å¾ˆä½ã€‚</p><p>è€Œåœ¨Transformer-XL[9]ä¸­ï¼Œæ¯ä¸ªsegmenté˜¶æ®µéƒ½æ¥å—å‰ä¸€ä¸ª(ç”šè‡³å‰Lä¸ª)çš„å†å²ä¿¡æ¯ï¼š<br>å› æ­¤è¿‡ç¨‹å¦‚ä¸‹ï¼š<br><img src="/images/15556768100801.jpg" width="60%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œç”±äºæœ‰å†å²ä¿¡æ¯ï¼Œåˆ™ä¸éœ€è¦æ»‘åŠ¨çª—å£ï¼Œå› æ­¤æ•ˆç‡æ›´é«˜ã€‚</p><p>å…·ä½“è€Œè¨€ï¼š<br>$\begin{aligned} \widetilde{\mathbf{h}}_{\tau+1}^{n-1} &amp;=\left[\mathrm{SG}\left(\mathbf{h}_{\tau}^{n-1}\right) \circ \mathbf{h}_{\tau+1}^{n-1}\right] \\ \mathbf{q}_{\tau+1}^{n}, \mathbf{k}_{\tau+1}^{n}, \mathbf{v}_{\tau+1}^{n} &amp;=\mathbf{h}_{\tau+1}^{n-1} \mathbf{W}_{q}^{\top}, \widetilde{\mathbf{h}}_{\tau+1}^{n-1} \mathbf{W}_{k}^{\top}, \widetilde{\mathbf{h}}_{\tau+1}^{n-1} \mathbf{W}_{v}^{\top} \\ \mathbf{h}_{\tau+1}^{n} &amp;=\text { Transformer-Layer }\left(\mathbf{q}_{\tau+1}^{n}, \mathbf{k}_{\tau+1}^{n}, \mathbf{v}_{\tau+1}^{n}\right) \end{aligned}$<br>SGä»£è¡¨stop gradientï¼Œè€Œå†å²ä¿¡æ¯ä¸å½“å‰é˜¶æ®µçš„éšçŠ¶æ€æ‹¼æ¥åœ¨ä¸€èµ·ã€‚</p><p>åŒæ—¶æœ¬æ–‡å¦ä¸€å¤§ä¸¤ç‚¹æ˜¯å¼•å…¥ç›¸å¯¹ä½ç½®çš„encodingã€‚å¦‚æœä½¿ç”¨ç»å¯¹ä½ç½®encodingï¼Œé‚£ä¹ˆåˆ™ä¼šå‡ºç°ä¸‹è¿°æƒ…å†µï¼š<br>$\mathbf{h}_{\tau+1}=f\left(\mathbf{h}_{\tau}, \mathbf{E}_{\mathbf{s}_{\tau+1}}+\mathbf{U}_{1 : L}\right) \quad \text { and } \quad \mathbf{h}_{\tau}=f\left(\mathbf{h}_{\tau-1}, \mathbf{E}_{\mathbf{s}_{\tau}}+\mathbf{U}_{1 : L}\right)$<br>ä¹Ÿå³æ¯ä¸ªsegmentéƒ½ä¼šæœ‰ç›¸åŒçš„ä½ç½®ä¿¡æ¯ã€‚å› æ­¤åœ¨è¿™é‡Œå¼•å…¥$\mathbf{R} \in \mathbb{R}^{L_{\max } \times d}$ï¼Œç¬¬$i$è¡Œä»£è¡¨ç›¸å¯¹è·ç¦»$i$çš„encodingã€‚</p><p>å…·ä½“è€Œè¨€ï¼š<br>åœ¨æ ‡å‡†Transformerä¸­ï¼Œquery $q_i$ä¸key $k_j$æ‰€è·å¾—çš„attentionåˆ†æ•°å¯ä»¥æ‹†è§£ä¸ºï¼š<br>$\mathbf{A}_{i, j}^{\mathrm{abs}}=q_{i}^{\top} k_{j}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{U}_{j}}_{(b)}+\underbrace{\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k} \mathbf{U}_{j}}_{(d)}$</p><p>å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œè½¬åŒ–ä¸ºç›¸å¯¹ä½ç½®encodingï¼Œæœ‰ï¼š<br>$\mathbf{A}_{i, j}^{\mathrm{rel}}=\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{E}_{x_{j}}}_{(a)}+\underbrace{\mathbf{E}_{x_{i}}^{\top} \mathbf{W}_{q}^{\top} \mathbf{W}_{k, E} \mathbf{R}_{i-j}}_{(b)}+\underbrace{u^{\top} \mathbf{W}_{k, R} \mathbf{E}_{x_{j}}}_{(c)}+\underbrace{v^{\top} \mathbf{W}_{k, R} \mathbf{R}_{i-j}}_{(d)}$</p><p>é¦–å…ˆæ˜¯å°†æ‰€æœ‰å‡ºç°ç»å¯¹ä½ç½®çš„åœ°æ–¹éƒ½æ”¹ä¸ºç›¸å¯¹ä½ç½®ï¼Œç¬¬äºŒæ˜¯å°†å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„$u \in \mathbb{R}^{d}$å’Œ$v \in \mathbb{R}^{d}$å»æ›¿ä»£$\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top}$å’Œ$\mathbf{U}_{i}^{\top} \mathbf{W}_{q}^{\top}$ã€‚ç¬¬ä¸‰ï¼Œæ˜¯å°†åŒæ ·çš„$\mathbf{W}_{k}$ç»†åŒ–æˆä¸¤ä¸ªä¸åŒçš„$\mathbf{W}_{k, E}$ä¸$\mathbf{W}_{k, R}$ã€‚</p><p>Transformer-XLåœ¨ä¸åŒæ•°æ®é›†ä¸Šæœ‰ç›¸å½“å¥½çš„æ•ˆæœï¼š<br><img src="/images/15556790567795.jpg" width="80%" height="50%"></p><p><img src="/images/15556790839030.jpg" width="80%" height="50%"></p><h3 id="Character-Level-Language-Modeling-with-Deeper-Self-Attention"><a href="#Character-Level-Language-Modeling-with-Deeper-Self-Attention" class="headerlink" title="Character-Level Language Modeling with Deeper Self-Attention"></a>Character-Level Language Modeling with Deeper Self-Attention</h3><p>åŒæ ·æ˜¯åœ¨è¯­è¨€æ¨¡å‹ä¸Šä½¿ç”¨Transformerï¼Œä½†æ˜¯characterçº§åˆ«çš„è¯­è¨€æ¨¡å‹ã€‚å…¶ä¸»è¦æ€è·¯æ˜¯æ·»åŠ å¤šä¸ªlossæ¥æå‡å…¶è¡¨ç°ä»¥åŠåŠ å¿«æ‹Ÿåˆé€Ÿåº¦ã€‚</p><p>å¯¹äºä¼ ç»Ÿçš„RNN character-levelè¯­è¨€æ¨¡å‹ï¼Œä¸€èˆ¬åšæ³•æ˜¯â€œtruncated backpropagation through timeâ€ (TBTT)ï¼šä¹Ÿå³æ¯ä¸ªbatché¢„æµ‹æœ€åä¸€ä¸ªå­—ç¬¦ï¼Œç„¶åå°†è¯¥batchçš„éšçŠ¶æ€ä¼ å…¥ä¸‹ä¸€ä¸ªbatchã€‚</p><p>è€Œåœ¨Transformerä¸­ä¹Ÿå¯ä»¥é‡‡ç”¨è¯¥æ–¹æ³•ã€‚ä½†åœ¨è¯¥åŸºç¡€ä¸Šï¼Œå¼•å…¥ä¸‰ç§lossã€‚<br>â‘ Multiple Positions<br>åœ¨ä¸€ä¸ªbatchå†…ï¼Œæ¯ä¸ªæ—¶é—´æ­¥téƒ½é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•ï¼Œåªé¢„æµ‹batchæœ€åä¸€ä¸ªå­—ç¬¦ï¼š</p><p><img src="/images/15556794194598.jpg" width="60%" height="50%"></p><p>â‘¡Intermediate Layer Losses<br>ä¸ä»…ä»…æœ€åä¸€å±‚è¦è¿›è¡Œé¢„æµ‹ï¼Œä¸­é—´å±‚ä¹Ÿéœ€è¦é¢„æµ‹ã€‚</p><p><img src="/images/15556795039170.jpg" width="60%" height="50%"><br>è¶Šåº•å±‚çš„lossæ‰€åˆ†é…çš„æƒé‡è¶Šå°ã€‚</p><p>â‘¢Multiple Targets<br>æ¯ä¸ªä½ç½®ä¸ä»…ä»…è¦é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œè¿˜éœ€è¦é¢„æµ‹åå‡ ä¸ªçš„å­—ç¬¦ï¼š</p><p><img src="/images/15556796677182.jpg" width="60%" height="50%"></p><p>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨å¤šä¸ªlossèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œä¸”èƒ½å¤Ÿè·å¾—æ›´å¥½çš„ç»“æœã€‚</p><h2 id="é¢„è®­ç»ƒæ¨¡å‹"><a href="#é¢„è®­ç»ƒæ¨¡å‹" class="headerlink" title="é¢„è®­ç»ƒæ¨¡å‹"></a>é¢„è®­ç»ƒæ¨¡å‹</h2><p>è‡ªELMoå¼€å§‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹å°±å¼€å§‹å—åˆ°å¹¿æ³›çš„å…³æ³¨ï¼Œè€ŒBertéšåçš„é—®ä¸–åˆ™æ›´æ˜¯å°†é¢„è®­ç»ƒæ¨¡å‹æ¨ä¸Šäº†æ–°çš„é˜¶æ®µã€‚å› æ­¤åœ¨è¿™é‡Œç®€è¦ä»‹ç»é¢„è®­ç»ƒæ¨¡å‹çš„å†å²ã€‚</p><h3 id="Non-Transformer-based"><a href="#Non-Transformer-based" class="headerlink" title="Non-Transformer-based"></a>Non-Transformer-based</h3><h4 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h4><p>è¯å‘é‡æ˜¯æœ€æ—©çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ŒBengio, et al.[10] æœ€æ—©æå‡ºç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹ï¼Œè¯å‘é‡ä½œä¸ºè®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‰¯äº§å“ï¼Œå¯ä»¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚è€Œéšååˆ™å‡ºç°äº†word2vec[11],GloVe[12]ï¼Œæ˜¯ç›®å‰æœ€ä¸ºå¹¿æ³›ä½¿ç”¨çš„è¯å‘é‡ã€‚</p><h4 id="CoVe-ELMo"><a href="#CoVe-ELMo" class="headerlink" title="CoVe/ELMo"></a>CoVe/ELMo</h4><p>word2vecä¸GloVeä½œä¸ºé™æ€è¯å‘é‡ï¼Œä¸€å¤§é—®é¢˜å°±æ˜¯éš¾ä»¥è§£å†³å¤šä¹‰è¯ï¼Œè€Œå¤šä¹‰è¯çš„è¡¨ç¤ºå¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡æ¥æ¨æµ‹ã€‚CoVe[13]å°†è¯å‘é‡ä»é™æ€æ‰©å±•ä¸ºåŠ¨æ€ã€‚é€šè¿‡ä¸Šä¸‹æ–‡æ¥è·å¾—ç‰¹å®šè¯çš„åŠ¨æ€è¡¨ç¤ºï¼Œå…·ä½“æ˜¯é€šè¿‡ç¿»è¯‘æ¨¡å‹æ¥è¾¾åˆ°è¯¥ç›®çš„çš„ã€‚<br>è€ŒELMo[14]ç»§æ‰¿äº†åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œä¸è¿‡æ˜¯é€šè¿‡åŒå‘è¯­è¨€æ¨¡å‹æ¥è¾¾åˆ°è¿™ä¸€ç›®çš„çš„ã€‚é€šè¿‡åŒå‘LSTMçš„è¯­è¨€æ¨¡å‹ï¼Œå°†å‰å‘ä¸åå‘éšçŠ¶æ€æ‹¼æ¥èµ·æ¥ä½œä¸ºè¯¥è¯çš„è¡¨ç¤ºã€‚<br>ä»…ä»…æ˜¯å°†ä¼ ç»Ÿé™æ€è¯å‘é‡æ›¿æ¢æˆELMoï¼Œå°±èƒ½æœ‰å¾ˆå¤§çš„æå‡ã€‚è‡ªæ­¤å¼€å§‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹å¼€å§‹å—åˆ°å¹¿æ³›çš„å…³æ³¨ã€‚</p><h4 id="ULMFit"><a href="#ULMFit" class="headerlink" title="ULMFit"></a>ULMFit</h4><p>åœ¨ä¸Šè¿°é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œç ”ç©¶è€…çš„æ€è·¯ä¸»è¦é›†ä¸­åœ¨é¢„è®­ç»ƒè¯å‘é‡ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚ULMFit[16]åˆ™å°è¯•ç›´æ¥å¯¹åˆ†ç±»æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œæ¥ç€å†é€šè¿‡å¾®è°ƒ(fine-tuning)ä»¥æé«˜åˆ†ç±»çš„æ•ˆæœã€‚</p><p><img src="/images/15556816887199.jpg" width="80%" height="50%"></p><p>ULMFitçš„æˆåŠŸè¯´æ˜ç›´æ¥å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒè€Œä¸æ˜¯åªé¢„è®­ç»ƒè¯å‘é‡ç”¨äºä¸‹æ¸¸ä»»åŠ¡æ˜¯å¯è¡Œçš„ã€‚</p><h3 id="Transformer-based"><a href="#Transformer-based" class="headerlink" title="Transformer-based"></a>Transformer-based</h3><p>GPT[15]å°è¯•é€šè¿‡æ¢ç´¢æ„å»ºä¸€ç§é€šç”¨æ¨¡å‹å¹¶åœ¨å…¶ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥åœ¨å¤šç§ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚å…¶ä¸»è¦äº®ç‚¹åœ¨äºâ‘ æ„å»ºä¸€ç§é€šç”¨æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒä»»åŠ¡ï¼Œç¬¬äºŒä½¿ç”¨Transformerè€Œä¸æ˜¯LSTMä½œä¸ºå…¶åŸºæœ¬æ¨¡å‹ã€‚<br>å…¶åŸºæœ¬æ¨¡å‹ï¼š</p><p><img src="/images/15556818289287.jpg" width="85%" height="50%"></p><p>å…·ä½“è€Œè¨€ï¼Œä¸»è¦æ˜¯æ— ç›‘ç£çš„è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŠ ä¸Šæœ‰ç›‘ç£çš„å¾®è°ƒã€‚</p><p>è€ŒBert[17]åœ¨GPTçš„åŸºç¡€ä¸Šï¼Œå¼•å…¥maskedè¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡éšæœºmaskæ‰éƒ¨åˆ†è¯ï¼Œå¼ºè¿«æ¨¡å‹é€šè¿‡ä¸Šä¸‹æ–‡å»é¢„æµ‹maskæ‰çš„è¯ï¼ŒåŠ å¼ºäº†æ¨¡å‹çš„èƒ½åŠ›ã€‚</p><p><img src="/images/15556821324062.jpg" width="85%" height="50%"></p><p>åŒæ—¶å¼•å…¥æœ‰ç›‘ç£å­¦ä¹ ï¼Œä¹Ÿå³é¢„æµ‹ä¸‹ä¸€å¥ï¼ˆNext Sentence Predictionï¼‰ï¼Œéšæœºåœ¨å¥å¯¹ä¸­å–ä¸¤ä¸ªå¥å­ï¼Œä½¿å¾—æœ‰50%å¯èƒ½å¥å­å¯¹æœ‰ä¸Šä¸‹æ–‡å…³ç³»ï¼Œ50%å¥å¯¹æ²¡æœ‰å…³ç³»ï¼Œä½¿æ¨¡å‹å»é¢„æµ‹å¥å¯¹ä¹‹é—´çš„å…³ç³»ã€‚å…·ä½“è€Œè¨€åˆ™æ˜¯é€šè¿‡åœ¨å¥å­å¼€å¤´åŠ [CLS]ç¬¦å·ï¼Œåœ¨æœ€é«˜å±‚å°†è¯¥ç¬¦å·çš„è¡¨ç¤ºé€šè¿‡å…¨è¿æ¥å±‚ã€‚</p><p>Bertåœ¨11é¡¹æ•°æ®é›†ä¸Šåˆ·æ–°æœ€é«˜è®°å½•ã€‚</p><p>åœ¨æ­¤ä¹‹åï¼ŒMT-DNN[19]ã€GPT2.0[18]ç›¸ç»§é—®ä¸–ï¼Œé€šè¿‡æ·»åŠ æ›´å¤šçš„ä»»åŠ¡æˆ–è€…æ›´å¤šçš„æ•°æ®ä½¿å¾—æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚ç›¸ä¿¡åœ¨æ¥ä¸‹æ¥ä¸€æ®µæ—¶é—´å†…ï¼Œç›¸å…³ä¸»é¢˜çš„è®ºæ–‡ä¹Ÿä¼šæœ‰å¾ˆå¤šã€‚</p><h2 id="Transformer-CNN-RNNå¯¹æ¯”åŠæ€è€ƒ"><a href="#Transformer-CNN-RNNå¯¹æ¯”åŠæ€è€ƒ" class="headerlink" title="Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ"></a>Transformer/CNN/RNNå¯¹æ¯”åŠæ€è€ƒ</h2><p>ä¸Šè¿°çš„ä»‹ç»ï¼Œå¤§æ¦‚å¯¹Transformerä¸€æ”¯æœ‰ä¸€ä¸ªç®€å•çš„æ¢³ç†ã€‚Transformerä½œä¸ºä¸RNN/CNNå¹¶ç«‹çš„æ¨¡å‹ï¼Œç¡®å®å€¼å¾—é‡è§†ã€‚</p><p>ä¸ºä»€ä¹ˆTransformerè¿™ä¹ˆå¥½ï¼Œæ˜¯å¦èƒ½å¤Ÿæ›¿ä»£RNN/CNNï¼Ÿè¿™ä¹Ÿæ˜¯å€¼å¾—æ‰€æœ‰äººæ€è€ƒçš„ã€‚</p><p>æ­£å¦‚å‰é¢ä»‹ç»çš„é‚£æ ·ï¼ŒTransformerçš„ä¸€å¤§ä¼˜åŠ¿æ˜¯å…¨å±€æ„Ÿå—é‡ï¼Œä¹Ÿå³RNN/CNNæ¯æ¬¡åªèƒ½â€˜çœ‹â€™åˆ°éƒ¨åˆ†ä¸Šä¸‹æ–‡ï¼Œè€ŒTransformeråˆ™æ²¡æœ‰è¿™ä¸ªé™åˆ¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½å¤Ÿç›´æ¥ä¸å…¶ä»–èŠ‚ç‚¹è¿›è¡Œäº¤äº’ã€‚ä¹Ÿå¯ä»¥è¿™ä¹ˆè¯´ï¼ŒRNN/CNNå…·æœ‰æ›´å¼ºçš„å…ˆéªŒ(prior)ã€‚<br>ä½†è¿™ç§ä¼˜åŠ¿æœ‰æ—¶ä¹Ÿä¼šæˆä¸ºåŠ£åŠ¿ï¼šå®è·µè¯æ˜ï¼ŒTransformeråœ¨å°æ•°æ®é›†ä¸Šçš„æ•ˆæœæ˜¯ä¸å¦‚RNN/CNNçš„ã€‚æˆ–è®¸å¯ä»¥è¿™ä¹ˆç†è§£è¿™ç§ç°è±¡ï¼šTransformerç”±äºä¸å¼•å…¥å¼ºçš„å…ˆéªŒï¼Œå› æ­¤éœ€è¦å¤§é‡çš„æ•°æ®å»ä»å¤´å­¦ä¹ æ•°æ®æ‰€å­˜åœ¨çš„æŸç§patternï¼ˆå¦‚å±€éƒ¨æ€§ï¼‰ï¼Œè€Œå¼•å…¥å¼ºçš„å…ˆéªŒçš„RNN/CNNåˆ™å¯¹å°æ•°æ®é›†æ›´åŠ å‹å¥½ä¸€äº›ã€‚ä½†å½“æœ‰å¤§é‡è®­ç»ƒæ•°æ®æ—¶ï¼ˆå¦‚ç¿»è¯‘ã€è¯­è¨€æ¨¡å‹ï¼‰ï¼ŒTransformeråˆ™ä¼šæœ‰æ›´é«˜çš„ä¸Šé™ï¼ŒBert/GPTä¹Ÿå°è¯äº†è¿™ç‚¹ã€‚è€Œè¿™ç§Transformerçš„åŠ£åŠ¿æˆ–è®¸ä¹Ÿæ˜¯ä¸Šè¿°å‡ ä¸ªå·¥ä½œï¼ˆå¦‚universal transformerï¼‰çš„å…¶ä¸­ä¸€ä¸ªå‡ºå‘ç‚¹ï¼Œä¹Ÿå³åœ¨Transformerå†…å¼•å…¥RNN/CNNçš„å½’çº³åç½®ï¼ŒåŠ å¼ºå¯¹Transformerçš„å…ˆéªŒçŸ¥è¯†çš„çº¦æŸã€‚</p><h2 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h2><p>[1] Vaswani, Ashish, et al. â€œAttention is all you need.â€ Advances in neural information processing systems. 2017.<br>[2]Dehghani, Mostafa, et al. â€œUniversal transformers.â€ arXiv preprint arXiv:1807.03819 (2018).<br>[3]Graves, Alex. â€œAdaptive computation time for recurrent neural networks.â€ arXiv preprint arXiv:1603.08983 (2016).<br>[4]Ahmed, Karim, Nitish Shirish Keskar, and Richard Socher. â€œWeighted transformer network for machine translation.â€ arXiv preprint arXiv:1711.02132 (2017).<br>[5]Yang, Baosong, et al. â€œConvolutional Self-Attention Networks.â€ arXiv preprint arXiv:1904.03107 (2019).<br>[6]Li, Jian, et al. â€œMulti-head attention with disagreement regularization.â€ arXiv preprint arXiv:1810.10183 (2018).<br>[7]Yang, Baosong, et al. â€œModeling localness for self-attention networks.â€ arXiv preprint arXiv:1810.10182 (2018).<br>[8]Shaw, Peter, Jakob Uszkoreit, and Ashish Vaswani. â€œSelf-attention with relative position representations.â€ arXiv preprint arXiv:1803.02155 (2018).<br>[9]Dai, Zihang, et al. â€œTransformer-xl: Attentive language models beyond a fixed-length context.â€ arXiv preprint arXiv:1901.02860 (2019).<br>[10]Bengio, Yoshua, et al. â€œA neural probabilistic language model.â€ Journal of machine learning research 3.Feb (2003): 1137-1155.<br>[11]Mikolov, Tomas, et al. â€œEfficient estimation of word representations in vector space.â€ arXiv preprint arXiv:1301.3781 (2013).<br>[12]Pennington, Jeffrey, Richard Socher, and Christopher Manning. â€œGlove: Global vectors for word representation.â€ Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014.<br>[13]McCann, Bryan, et al. â€œLearned in translation: Contextualized word vectors.â€ Advances in Neural Information Processing Systems. 2017.<br>[14]Peters, Matthew E., et al. â€œDeep contextualized word representations.â€ arXiv preprint arXiv:1802.05365 (2018).<br>[15]Radford, Alec, et al. â€œImproving language understanding by generative pre-training.â€ URL <a href="https://s3-us-west-2" target="_blank" rel="noopener">https://s3-us-west-2</a>. amazonaws. com/openai-assets/research-covers/languageunsupervised/language understanding paper. pdf (2018).<br>[16]Universal Language Model Fine-tuning for Text Classification<br>[17]Devlin, Jacob, et al. â€œBert: Pre-training of deep bidirectional transformers for language understanding.â€ arXiv preprint arXiv:1810.04805 (2018).<br>[18]Radford, Alec, et al. â€œLanguage models are unsupervised multitask learners.â€ OpenAI Blog 1 (2019): 8.<br>[19]Multi-Task Deep Neural Networks for Natural Language Understanding<br>[20]Guo, Qipeng, et al. â€œStar-Transformer.â€ arXiv preprint arXiv:1902.09113 (2019).</p>]]></content>
      
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2019/04/11/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E7%B1%BB%E6%B0%B8%E6%81%92%E7%9A%84%E6%84%9A%E8%A0%A2/"/>
      <url>/2019/04/11/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E7%B1%BB%E6%B0%B8%E6%81%92%E7%9A%84%E6%84%9A%E8%A0%A2/</url>
      
        <content type="html"><![CDATA[<p>äººç±»æ°¸æ’çš„æ„šè ¢ï¼Œæ˜¯æŠŠè«åå…¶å¦™çš„æ‹…å¿§ï¼Œç­‰åŒäºæ™ºåŠ›è¶…ç¾¤ã€‚  â€”â€”ç¾å›½åŠ å°”å¸ƒé›·æ–¯</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡15</title>
      <link href="/2019/03/31/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8715/"/>
      <url>/2019/03/31/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8715/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡:</p><ol><li>Selective Kernel Networks</li><li>Attentional pooling for action recognition</li></ol><h2 id="1ï¸âƒ£-Selective-Kernel-Networks"><a href="#1ï¸âƒ£-Selective-Kernel-Networks" class="headerlink" title="1ï¸âƒ£[Selective Kernel Networks]"></a>1ï¸âƒ£[Selective Kernel Networks]</h2><p>é€šè¿‡å¯¹ä¸åŒkernel sizeçš„feature mapä¹‹é—´è¿›è¡Œä¿¡æ¯ç­›é€‰è·å¾—æ›´ä¸ºé²æ£’çš„è¡¨ç¤ºï¼Œèƒ½å¤Ÿå¯¹ä¸åŒçš„æ„Ÿå—é‡è¿›è¡Œæ•´åˆï¼Œå®ç°åŠ¨æ€è°ƒæ•´æ„Ÿå—é‡ã€‚å…¶æ€è·¯è¿˜æŒºæœ‰æ„æ€çš„ã€‚</p><p>Introductionå°†è¯¥æ¨¡å‹ä¸è§†è§‰ç¥ç»çš„ç†è®ºç»“åˆåœ¨ä¸€èµ·ï¼Œä¹Ÿå³ï¼Œå¯¹äºäººç±»è€Œè¨€ï¼Œåœ¨çœ‹ä¸åŒå°ºå¯¸ä¸åŒè¿œè¿‘çš„ç‰©ä½“æ—¶ï¼Œè§†è§‰çš®å±‚ç¥ç»å…ƒ<strong>æ„Ÿå—é‡å¤§å°</strong>æ˜¯ä¼šæ ¹æ®åˆºæ¿€æ¥è¿›è¡Œè°ƒèŠ‚çš„ï¼Œä½†ä¸€èˆ¬è€Œè¨€åœ¨CNNä¸­å·ç§¯æ ¸çš„å¤§å°æ˜¯å›ºå®šçš„ã€‚è¯¥æ¨¡å‹æ­£æ˜¯ä»è¿™ä¸€ç°è±¡ä¸­è·å¾—çµæ„Ÿã€‚</p><p>æ•´ä¸ªæ¨¡å‹ä¸€å…±åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼šsplitï¼Œfuseï¼Œselect</p><p>splitç”Ÿæˆå¤šä¸ªä¸åŒkernel sizeçš„feature mapï¼Œä¹Ÿå³å¯¹åº”ä¸åŒçš„æ„Ÿå—é‡å¤§å°ï¼›fuseå°†ä¸åŒfeature mapç»“åˆèµ·æ¥ï¼Œè·å¾—ä¸€ä¸ªå…¨å±€çš„ç»¼åˆçš„å‘é‡è¡¨ç¤ºï¼›selectæ ¹æ®ä¸åŒçš„weighté€‰æ‹©ä¸åŒæ„Ÿå—é‡çš„feature mapã€‚</p><p><img src="/images/15540416698404.jpg" width="80%" height="50%"></p><p>ä»¥ä¸Šå›¾ä¸ºä¾‹ã€‚</p><h3 id="SK-Net"><a href="#SK-Net" class="headerlink" title="SK-Net"></a>SK-Net</h3><h4 id="ç¬¬ä¸€æ­¥split"><a href="#ç¬¬ä¸€æ­¥split" class="headerlink" title="ç¬¬ä¸€æ­¥split"></a>ç¬¬ä¸€æ­¥split</h4><p>ç»™å®šè¾“å…¥$\mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}}$ï¼Œé€šè¿‡ä¸åŒçš„kernel sizeçš„CNNçš„å·ç§¯è·å¾—ä¸åŒçš„feature mapï¼Œä¸Šå›¾æ˜¯$3\times 3$ä¸$5\times 5$çš„å·ç§¯æ ¸ã€‚å·ç§¯å¯ä»¥æ˜¯ä¼ ç»Ÿçš„convolutionå·ç§¯ï¼Œä¹Ÿå¯ä»¥æ˜¯ç©ºæ´å·ç§¯ï¼ˆdilated convolutionï¼‰ï¼Œæˆ–è€…æ·±åº¦å·ç§¯ï¼ˆdepthwise convolutionï¼‰ã€‚åˆ™æœ‰ï¼š<br>$\widetilde{\mathcal{F}} : \mathbf{X} \rightarrow \widetilde{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$ ä¸ $\widehat{\mathcal{F}} : \mathbf{X} \rightarrow \widehat{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$ï¼Œå…¶ä¸­$\widetilde{\mathcal{F}},\widehat{\mathcal{F}}$æ˜¯å·ç§¯å˜æ¢ã€‚</p><h4 id="ç¬¬äºŒæ­¥fuse"><a href="#ç¬¬äºŒæ­¥fuse" class="headerlink" title="ç¬¬äºŒæ­¥fuse"></a>ç¬¬äºŒæ­¥fuse</h4><p>ç›´æ¥å°†ä¸åŒçš„feature mapç»“åˆèµ·æ¥ä»¥è·å¾—å…¨å±€ä¿¡æ¯ï¼Œç”¨ä»¥ä¹‹åçš„åŠ¨æ€è°ƒæ•´ã€‚è¿™é‡Œé‡‡ç”¨ç®€å•çš„æ±‚å’Œä»¥åŠglobal average poolingä»¥è·å¾—channel-wiseçš„ä¿¡æ¯$\mathbf{s} \in \mathbb{R}^{C}$ï¼š</p><script type="math/tex; mode=display">\mathbf{U}=\widetilde{\mathbf{U}}+\widehat{\mathbf{U}} \\ s_{c}=\mathcal{F}_{g p}\left(\mathbf{U}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} \mathbf{U}_{c}(i, j)</script><p>åœ¨è·å¾—$\mathbf{s}$åå†é€šè¿‡MLPè·å¾—$\mathbf{z}$ï¼š</p><script type="math/tex; mode=display">\mathbf{z}=\mathcal{F}_{f c}(\mathbf{s})=\delta(\mathcal{B}(\mathbf{W} \mathbf{s}))</script><p>å…¶ä¸­$\mathcal{B}$æ˜¯batch normalizationï¼›$\delta$æ˜¯Reluã€‚</p><h4 id="ç¬¬ä¸‰æ­¥select"><a href="#ç¬¬ä¸‰æ­¥select" class="headerlink" title="ç¬¬ä¸‰æ­¥select"></a>ç¬¬ä¸‰æ­¥select</h4><p>ä½¿ç”¨soft attentionå»é€‰æ‹©ä¸åŒkernel sizeçš„feature mapå¹¶ç»“åˆåœ¨ä¸€èµ·ã€‚ä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">a_{c}=\frac{e^{\mathbf{A}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}, b_{c}=\frac{e^{\mathbf{B}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}</script><p>å…¶ä¸­$\mathbf{A}_{c}$æ˜¯å¯¹åº”$\widetilde{\mathbf{U}}$ç¬¬$c$ä¸ªchannelçš„å‚æ•°ï¼Œ$\mathbf{B}_{c}$æ˜¯å¯¹åº”$\widehat{\mathbf{U}}$ç¬¬$c$ä¸ªchannelçš„å‚æ•°ã€‚$\mathbf{A}, \mathbf{B} \in \mathbb{R}^{C \times d}$ï¼Œé‚£ä¹ˆ$a_{c},b_{c}$å°±å¯¹åº”ä¸åŒfeature mapçš„weightã€‚</p><p>å› æ­¤ï¼Œæœ€ç»ˆçš„feature map $\mathbf{V}$ï¼š</p><script type="math/tex; mode=display">\mathbf{V}_{c}=a_{c} \cdot \tilde{\mathbf{U}}_{c}+b_{c} \cdot \widehat{\mathbf{U}}_{c}, \quad a_{c}+b_{c}=1 \\ \mathbf{V}=\left[\mathbf{V}_{1}, \mathbf{V}_{2}, \dots, \mathbf{V}_{C}\right], \mathbf{V}_{c} \in \mathbb{R}^{H \times W}</script><h3 id="å¯¹æ¯”-amp-æ€è€ƒ"><a href="#å¯¹æ¯”-amp-æ€è€ƒ" class="headerlink" title="å¯¹æ¯”&amp;æ€è€ƒ"></a>å¯¹æ¯”&amp;æ€è€ƒ</h3><h4 id="ä¸SE-Net"><a href="#ä¸SE-Net" class="headerlink" title="ä¸SE-Net"></a>ä¸SE-Net</h4><p>SE-Netæ˜¯é€šè¿‡ä¸åŒchannelä¹‹é—´çš„äº¤äº’ï¼Œä½¿å¾—channelè·å¾—å…¨å±€çš„æ„Ÿå—é‡ï¼Œä½¿ç”¨çš„æ˜¯å¯¹channelçš„æ”¾ç¼©ï¼ˆè¯¦è§ä¸Šä¸€ç¯‡è®ºæ–‡ç¬”è®°ï¼‰ï¼›è€ŒSK-Netæ˜¯ä¸åŒçš„æ„Ÿå—é‡ä¹‹é—´çš„åŒä¸€channelåœ¨é€šè¿‡å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹ä»¥soft-attentionçš„å½¢å¼åŠ æƒå¹³å‡ï¼Œè¿™å°±å’Œè®ºæ–‡ä¸­æåˆ°çš„äººç±»è§†è§‰å¯¹ä¸åŒç‰©ä½“è¿›è¡ŒåŠ¨æ€è°ƒæ•´æ„Ÿå—é‡çš„æ€è·¯ä¸€è‡´ã€‚</p><h4 id="ä¸dynamic-convolution"><a href="#ä¸dynamic-convolution" class="headerlink" title="ä¸dynamic convolution"></a>ä¸dynamic convolution</h4><p>åœ¨è®ºæ–‡[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]ä¸­ï¼Œç ”ç©¶äººå‘˜æå‡ºåŠ¨æ€æ„Ÿå—é‡çš„convolutionï¼Œé€šè¿‡åˆ©ç”¨å½“å‰è¯é¢„æµ‹ä¸€ä¸ªå·ç§¯çª—å£ï¼Œå¢åŠ äº†æ¨¡å‹çš„çµæ´»æ€§ï¼Œå¹¶åœ¨æœºå™¨ç¿»è¯‘ä¸Šå–å¾—äº†å¾ˆå¥½çš„ç»“æœã€‚</p><p>è™½ç„¶ç›®çš„ä¸æœ¬ç¯‡è®ºæ–‡ä¸€è‡´ï¼Œä½†æ€è·¯æ˜¯å®Œå…¨ä¸åŒçš„ã€‚ä¸€ä¸ªæ˜¯é€šè¿‡é¢„æµ‹ï¼›å¦ä¸€ä¸ªæ˜¯åœ¨å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹è¿›è¡ŒåŠ æƒã€‚åœ¨æˆ‘çš„ç†è§£çœ‹æ¥ï¼Œæˆ–è®¸æœ¬ç¯‡è®ºæ–‡çš„æ€è·¯æ›´åŠ åˆç†ä¸€äº›ï¼Œç¬¬ä¸€ï¼Œåœ¨æœ‰äº†å…¨å±€ä¿¡æ¯çš„æŒ‡å¯¼ä¸‹èƒ½å¤Ÿæ›´å¥½çš„è¿›è¡ŒåŠ æƒï¼Œè€Œé€šè¿‡é¢„æµ‹ï¼Œä¼¼ä¹æœ‰äº›ç›²ç›®ï¼Œå¯èƒ½éœ€è¦æ›´å¤šçš„æ•°æ®æ‰èƒ½å­¦å¾—æ›´å¥½ï¼›ç¬¬äºŒï¼Œdynamic convolutionè®ºæ–‡ä¸­ä¹Ÿæåˆ°äº†ï¼Œå¦‚æœä¸ä½¿ç”¨å¦‚æ·±åº¦å¯åˆ†ç¦»å·ç§¯ç­‰è½»é‡çº§å·ç§¯æ–¹æ³•ï¼Œdynamic convolutionä¸å¤§ç°å®ï¼ˆA dynamic version of standard convolutions would be impractical for current GPUs due to their large memory requirementsï¼‰ï¼Œè€ŒSK-Netåˆ™ä¸ä¼šæœ‰è¿™ä¸ªé—®é¢˜ã€‚</p><h4 id="å…¶ä»–æ€è€ƒ"><a href="#å…¶ä»–æ€è€ƒ" class="headerlink" title="å…¶ä»–æ€è€ƒ"></a>å…¶ä»–æ€è€ƒ</h4><p>ä»å¦ä¸€ä¸ªè§’åº¦å»æ€è€ƒï¼ŒSK-Neté€šè¿‡äººå·¥å®šä¹‰å¥½çš„å‡ ç§ä¸åŒå¤§å°çš„å·ç§¯ï¼Œç›¸å½“äºåœ¨æ¨¡å‹ä¸­å¼•å…¥æ›´å¼ºçš„å…ˆéªŒï¼ˆinductive biasï¼‰ï¼Œä¹Ÿå³å‡è®¾äº†æ•°æ®ä¸ä¼šè¶…è¿‡è¿™å‡ ç§å¤§å°çš„å·ç§¯çš„å¤„ç†èŒƒå›´ï¼Œè¿™æˆ–è®¸æ¯”ä¸å¼•å…¥å…ˆéªŒï¼Œå®Œå…¨é æ•°æ®å»å­¦æŸç§ç‰¹å®špatternçš„dynamic convolutionå¯¹å°æ•°æ®é›†æ›´å‹å¥½ï¼Œå› æ­¤å¯ä»¥ä¸éœ€è¦æ›´å¤šçš„æ•°æ®æ¥ä½¿å¾—æ¨¡å‹è¡¨ç°è‰¯å¥½ã€‚ç±»ä¼¼çš„ç†è§£å¯ä»¥åœ¨CNN/RNNä¸Transformerçš„å¯¹æ¯”ä¸­çœ‹è§ï¼Œå› ä¸ºCNN/RNNå¼•å…¥äº†è¾ƒå¼ºçš„local biasï¼Œå› æ­¤å¯¹äºå°æ•°æ®é›†æ›´å‹å¥½ï¼Œä½†åŒæ—¶å…¶ä¸Šé™æˆ–è®¸ä¸å¦‚Transformeré«˜ï¼›è€ŒTransformerä¸€å¼€å§‹å°±æ˜¯å…¨å±€æ„Ÿå—é‡ï¼Œä½¿å¾—éœ€è¦æ›´å¤šæ•°æ®æ¥å¸®åŠ©æ¨¡å‹å­¦åˆ°æŸç§ç‰¹å®špatternï¼ˆå¦‚æŸç§local biasï¼‰ï¼Œä½†å½“æ•°æ®å……è¶³æ—¶ï¼ŒTransformerçš„ä¸Šé™æ›´é«˜ï¼Œè¿‘æœŸéå¸¸ç«çš„pretrained model GPT/GPT-2.0/Bertä¼¼ä¹ä¹Ÿå°è¯äº†è¿™ç‚¹ã€‚</p><hr><h2 id="2ï¸âƒ£-Attentional-pooling-for-action-recognition"><a href="#2ï¸âƒ£-Attentional-pooling-for-action-recognition" class="headerlink" title="2ï¸âƒ£[Attentional pooling for action recognition]"></a>2ï¸âƒ£[Attentional pooling for action recognition]</h2><p>æå‡ºä¸€ç§åŸºäºattentionçš„poolingç­–ç•¥ï¼Œé‡‡ç”¨ä½ç§©è¿‘ä¼¼çš„æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨è®¡ç®—é‡ä¸å¢åŠ å¾ˆå¤šçš„æƒ…å†µä¸‹è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚å¯ä»¥å°†è¯¥æ–¹æ³•ç†è§£æˆå¯¹äºŒé˜¶poolingçš„ä½ç§©è¿‘ä¼¼ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><h4 id="ä¸€é˜¶pooling"><a href="#ä¸€é˜¶pooling" class="headerlink" title="ä¸€é˜¶pooling"></a>ä¸€é˜¶pooling</h4><p>è®°$X \in R^{n \times f}$ä¸ºè¢«poolingçš„å±‚ï¼Œå…¶ä¸­nä¸ºç©ºé—´ä½ç½®çš„ä¸ªæ•°ï¼Œå¦‚$16\times 16$ï¼Œ$f$ä¸ºchannelä¸ªæ•°ã€‚æ ‡å‡†çš„sum/max poolingå°†è¯¥çŸ©é˜µç¼©å‡ä¸º$R^{f \times 1}$ï¼Œç„¶åä½¿ç”¨å…¨è¿æ¥çš„æƒé‡$\mathbf{w} \in R^{f \times 1}$è·å¾—ä¸€ä¸ªåˆ†ç±»çš„åˆ†æ•°ã€‚è¿™é‡Œå‡è®¾çš„æ˜¯äºŒåˆ†ç±»ï¼Œä½†å¯ä»¥å¾ˆå®¹æ˜“æ¨å¹¿ä¸ºå¤šåˆ†ç±»ã€‚</p><p>ä¸Šè¿°æ“ä½œå½¢å¼åŒ–å¯ä»¥å†™æˆï¼š</p><script type="math/tex; mode=display">\operatorname{score}_{p o o l}(X)=\mathbf{1}^{T} X \mathbf{w}, \quad \text { where } \quad X \in R^{n \times f}, \mathbf{1} \in R^{n \times 1}, \mathbf{w} \in R^{f \times 1}</script><p>å…¶ä¸­$\mathbf{1}$ä¸ºå…¨1å‘é‡ï¼Œ$\mathbf{x}=\mathbf{1}^{T} X \in R^{1 \times f}$å°±æ˜¯é€šè¿‡sum poolingåçš„featureã€‚</p><h4 id="äºŒé˜¶pooling"><a href="#äºŒé˜¶pooling" class="headerlink" title="äºŒé˜¶pooling"></a>äºŒé˜¶pooling</h4><p>æ„å»ºäºŒé˜¶feature $X^{T} X \in R^{f \times f}$ï¼Œåœ¨è·å¾—äºŒé˜¶featureåï¼Œé€šå¸¸æˆ–å‘é‡åŒ–è¯¥çŸ©é˜µï¼Œå†é€å…¥å…¨è¿æ¥ä»¥åšåˆ†ç±»ã€‚ä¹Ÿå³æˆ‘ä»¬ä¼šå­¦ä¹ ä¸€ä¸ª$f\times f$çš„å…¨è¿æ¥æƒé‡å‘é‡ã€‚è‹¥ä¿æŒäºŒé˜¶featureä¸å¯¹åº”çš„å…¨è¿æ¥æƒé‡å‘é‡çš„å½¢å¼ä¸ºçŸ©é˜µï¼ŒçŸ©é˜µç›¸ä¹˜ï¼Œå…¶ä¸­çš„è¿¹å®é™…ä¸Šå°±æ˜¯è¿™ä¸¤ä¸ªå‘é‡åŒ–åçš„çŸ©é˜µæ‰€åšå†…ç§¯è·å¾—çš„åˆ†æ•°ã€‚å½¢å¼åŒ–å¯ä»¥å†™æˆï¼š</p><script type="math/tex; mode=display">\text {score}_{order2}(X)=\operatorname{Tr}\left(X^{T} X W^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W \in R^{f \times f}</script><p>è¿™å¯ä»¥ç”¨è¿¹çš„å®šä¹‰å»è¯æ˜ï¼šç¤ºæ„å›¾<br><img src="/images/15540862875594.jpg" width="100%" height="50%"></p><h4 id="ä½ç§©äºŒé˜¶pooling"><a href="#ä½ç§©äºŒé˜¶pooling" class="headerlink" title="ä½ç§©äºŒé˜¶pooling"></a>ä½ç§©äºŒé˜¶pooling</h4><p>ç°å°è¯•ä½¿ç”¨ä½ç§©å»è¿‘ä¼¼è¯¥äºŒé˜¶poolingï¼Œä¹Ÿå³å¯¹$W$è¿‘ä¼¼ï¼Œå°†$W$å†™æˆä¸¤ä¸ªå‘é‡çš„ä¹˜ç§¯ï¼Œä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">W=\mathbf{a b}^{T} \text { where } \mathbf{a}, \mathbf{b} \in R^{f \times 1}</script><p>å°†ä¸Šå¼ä»£å…¥äºŒé˜¶poolingï¼Œå¯è·å¾—ï¼š</p><script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\operatorname{Tr}\left(X^{T} X \mathbf{b a}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, \mathbf{a}, \mathbf{b} \in R^{f \times 1} \\ &=\operatorname{Tr}\left(\mathbf{a}^{T} X^{T} X \mathbf{b}\right) \\ &=\mathbf{a}^{T} X^{T} X \mathbf{b} \\ &=\mathbf{a}^{T}\left(X^{T}(X \mathbf{b})\right) \end{aligned}</script><p>ç¬¬äºŒè¡Œä½¿ç”¨çš„æ˜¯è¿¹çš„å®šç†ï¼š$\operatorname{Tr}(A B C)=\operatorname{Tr}(C A B)$<br>ç¬¬ä¸‰è¡Œä½¿ç”¨çš„æ˜¯æ ‡é‡çš„è¿¹ç­‰äºæ ‡é‡æœ¬èº«ã€‚<br>æœ€åä¸€è¡Œè¡¨æ˜æ•´ä¸ªæµç¨‹ï¼šç»™å®šä¸€ä¸ªfeature map $X$ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªå¯¹æ‰€æœ‰ç©ºé—´ä½ç½®çš„attentional mapï¼š$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$ï¼›ç„¶åæ ¹æ®è¯¥attentional mapè®¡ç®—åŠ æƒå¹³å‡çš„featureï¼š$\mathbf{x}=X^{T} \mathbf{h} \in R^{f \times 1}$ã€‚è¯¥featureå†é€šè¿‡çº¿æ€§å±‚è·å¾—æœ€ç»ˆçš„åˆ†æ•°ã€‚</p><p>å®é™…ä¸Šä¸Šå¼è¿˜æœ‰å…¶ä»–ç†è§£çš„è§’åº¦ï¼š</p><script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\left((X \mathbf{a})^{T} X\right) \mathbf{b} \\ &=(X \mathbf{a})^{T}(X \mathbf{b}) \end{aligned}</script><p>ç¬¬ä¸€è¡Œè¡¨æ˜attentional mapä¹Ÿå¯ä»¥é€šè¿‡$X \mathbf{a} \in R^{n \times 1}$æ¥è®¡ç®—ï¼Œ$\mathbf{b}$æ¥åšclassifierã€‚<br>ç¬¬äºŒè¡Œè¡¨æ˜ï¼Œè¯¥å¼å­æœ¬è´¨ä¸Šæ˜¯å¯¹ç§°çš„ï¼Œå¯ä»¥çœ‹æˆ<strong>ä¸¤ä¸ªattentional heapmapçš„å†…ç§¯</strong>ã€‚</p><p>ä¸‹å›¾æ˜¯æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15540869385196.jpg" width="80%" height="50%"></p><h4 id="Top-down-attention"><a href="#Top-down-attention" class="headerlink" title="Top-down attention"></a>Top-down attention</h4><p>ç°å°†äºŒåˆ†ç±»æ¨å¹¿ä¸ºå¤šåˆ†ç±»ï¼š</p><script type="math/tex; mode=display">\text {score}_{order2}(X, k)=\operatorname{Tr}\left(X^{T} X W_{k}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W_{k} \in R^{f \times f}</script><p>ä¹Ÿå³å°†$W$æ›¿æ¢æˆç±»ç›¸å…³çš„å‚æ•°ï¼Œä»¿ç…§ä¸Šé¢çš„æ¨å¯¼ï¼Œå¯ä»¥æ¨å‡ºæ¯ä¸ªç±»éƒ½æœ‰ç‰¹å®šçš„$\boldsymbol{a}_{k}$ä¸$\boldsymbol{b}_{k}$ã€‚</p><p>ä½†åœ¨è¿™é‡Œé€šè¿‡å›ºå®šå…¶ä¸­ä¸€ä¸ªå‚æ•°ä¸ºä¸ç±»æ— å…³çš„å‚æ•°ï¼Œä¹Ÿå³$\boldsymbol{b}_{k}=\boldsymbol{b}$ã€‚å®é™…ä¸Šå°±ç­‰ä»·äºä¸€ä¸ªæ˜¯ç±»ç›¸å…³çš„top-down attentionï¼›å¦ä¸€ä¸ªæ˜¯ç±»æ— å…³çš„bottom-up attentionã€‚ä¸€ä¸ªè·å¾—ç±»ç‰¹å®šçš„ç‰¹å¾ï¼›å¦ä¸€ä¸ªè·å¾—å…¨å±€é€šç”¨çš„ç‰¹å¾ã€‚</p><p>å› æ­¤æœ€ç»ˆä½ç§©attention modelä¸ºï¼š</p><script type="math/tex; mode=display">\text {score}_{attention}(X, k)=\mathbf{t}_{k}^{T} \mathbf{h}, \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{a}_{k}, \mathbf{h}=X \mathbf{b}</script><h4 id="Average-pooling-Revisited"><a href="#Average-pooling-Revisited" class="headerlink" title="Average-pooling Revisited"></a>Average-pooling Revisited</h4><p>å½“ç„¶åœ¨ç»™å®šäº†ä¸Šè¿°ä¸€ç³»åˆ—çš„æ¨å¯¼ï¼Œæˆ‘ä»¬å¯¹average-poolingé‡æ–°è¿›è¡Œå½¢å¼åŒ–ï¼š</p><script type="math/tex; mode=display">\text {score}_{top-down}(X, k)=\mathbf{1}^{T} X \mathbf{w}_{k}=\mathbf{1}^{T} \mathbf{t}_{k} \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{w}_{k}</script><p>å°†$\mathbf{w}$æ›¿æ¢æˆç±»ç›¸å…³çš„$\mathbf{w}_{k}$ï¼Œå®é™…ä¸Šå°±æ˜¯å°†äºŒåˆ†ç±»æ¨å¹¿ä¸ºå¤šåˆ†ç±»ã€‚ä½†è¯¥å½¢å¼èµ‹äºˆäº†average-poolingæ–°çš„ç†è§£ã€‚</p><p>å½“ç„¶ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†rank-1æ¨å¹¿ä¸ºrank-kï¼Œå®éªŒè¯æ˜å¯¹äºå¤§æ•°æ®é›†ä½¿ç”¨å¤§çš„ç§©ä¼šæ›´å¥½ã€‚</p><h3 id="å¯¹æ¯”"><a href="#å¯¹æ¯”" class="headerlink" title="å¯¹æ¯”"></a>å¯¹æ¯”</h3><h4 id="ä¸Self-attentiveçš„è”ç³»"><a href="#ä¸Self-attentiveçš„è”ç³»" class="headerlink" title="ä¸Self-attentiveçš„è”ç³»"></a>ä¸Self-attentiveçš„è”ç³»</h4><p>è®ºæ–‡[A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING]å°±æå‡ºäº†åˆ©ç”¨å¯å­¦ä¹ çš„headå¯¹featureè¿›è¡ŒattentionåŠ æƒå¹³å‡çš„æ–¹æ³•ï¼Œå¹¶ä¸”å°†ä¸€ä¸ªheadæ¨å¹¿åˆ°å¤šä¸ªheadã€‚<br>å®é™…ä¸Šåœ¨$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$æˆ‘ä»¬å°±å¯ä»¥çœ‹å‡ºï¼Œ$\mathbf{b}$åœ¨è¿™é‡Œæ‰®æ¼”çš„è§’è‰²å°±æ˜¯self-attentiveçš„headçš„è§’è‰²ã€‚å¯¹äºç§©ä¸º1çš„è¿‘ä¼¼ï¼Œå°±æ˜¯headä¸º1çš„æƒ…å†µï¼Œè‹¥å°†ç§©ä¸º1æ¨å¹¿ä¸ºç§©ä¸ºkï¼Œä¹Ÿå³ç­‰ä»·äºåœ¨Self-attentiveä¸­å¤šä¸ªheadçš„æƒ…å†µã€‚</p><p>æœ¬æ–‡å·§å¦™çš„åœ°æ–¹åœ¨äºheadæœ‰ä¸¤ä¸ªä½œç”¨ï¼Œä¸€ç§æ˜¯top-downçš„headï¼Œè·å¾—çš„æ˜¯ç±»ç›¸å…³çš„featureï¼›å¦ä¸€ä¸ªæ˜¯bottom-upçš„featureï¼Œè·å¾—çš„æ˜¯é€šç”¨çš„featureã€‚å¹¶ä¸”æœ¬æ–‡é€šè¿‡å·§å¦™çš„æ•°å­¦æ¨å¯¼æ¥è·å¾—æ–°çš„è§£é‡Šï¼Œæœ¬æ¥ä»…ä»…æ˜¯äºŒé˜¶featureè¿‡ä¸€ä¸ªå…¨è¿æ¥ï¼Œä½†é€šè¿‡å…¬å¼æ¨å¯¼èµ‹äºˆäº†attentionçš„è§£é‡Šï¼Œè¿™ç‚¹è®©äººçœ¼å‰ä¸€äº®ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> second-order </tag>
            
            <tag> pooling </tag>
            
            <tag> SK-Net </tag>
            
            <tag> attentional pooling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯21</title>
      <link href="/2019/03/31/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D21/"/>
      <url>/2019/03/31/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D21/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£é†‰è½é­„-Â·-å¸­ä¸Šå‘ˆå…ƒç´ "><a href="#1ï¸âƒ£é†‰è½é­„-Â·-å¸­ä¸Šå‘ˆå…ƒç´ " class="headerlink" title="1ï¸âƒ£é†‰è½é­„ Â· å¸­ä¸Šå‘ˆå…ƒç´ "></a>1ï¸âƒ£é†‰è½é­„ Â· å¸­ä¸Šå‘ˆå…ƒç´ </h3><p>[å®‹] è‹è½¼<br>åˆ†æºå¦‚æ˜¨ï¼Œäººç”Ÿåˆ°å¤„èé£˜æ³Šã€‚å¶ç„¶ç›¸èšè¿˜ç¦»ç´¢ã€‚å¤šç—…å¤šæ„ï¼Œé¡»ä¿¡ä»æ¥é”™ã€‚<br><strong>å°Šå‰ä¸€ç¬‘ä¼‘è¾å´ï¼Œå¤©æ¶¯åŒæ˜¯ä¼¤æ²¦è½</strong>ã€‚æ•…å±±çŠ¹è´Ÿå¹³ç”Ÿçº¦ã€‚è¥¿æœ›å³¨åµ‹ï¼Œé•¿ç¾¡å½’é£é¹¤ã€‚</p><p><a href="http://lib.xcz.im/work/57c467a86be3ff0058452840" target="_blank" rel="noopener">http://lib.xcz.im/work/57c467a86be3ff0058452840</a></p><hr><h3 id="2ï¸âƒ£æˆä¸ºå…­ç»å¥"><a href="#2ï¸âƒ£æˆä¸ºå…­ç»å¥" class="headerlink" title="2ï¸âƒ£æˆä¸ºå…­ç»å¥"></a>2ï¸âƒ£æˆä¸ºå…­ç»å¥</h3><p>[å”] æœç”«<br>ã€å…¶ä¸€ã€‘<br>åº¾ä¿¡æ–‡ç« è€æ›´æˆï¼Œå‡Œäº‘å¥ç¬”æ„çºµæ¨ªã€‚<br>ä»Šäººå—¤ç‚¹æµä¼ èµ‹ï¼Œä¸è§‰å‰è´¤ç•åç”Ÿã€‚</p><p>ã€å…¶ä¸‰ã€‘<br>çºµä½¿å¢ç‹æ“ç¿°å¢¨ï¼ŒåŠ£äºæ±‰é­è¿‘é£éªšã€‚<br>é¾™æ–‡è™è„Šçš†å›é©­ï¼Œå†å—è¿‡éƒ½è§å°”æ›¹ã€‚</p><p>è¿‡éƒ½å†å— (guÃ² dÅu lÃ¬ kuÃ i)<br>è§£é‡Šï¼šè¶Šè¿‡éƒ½å¸‚ï¼Œç»è¿‡å±±é˜œã€‚æ„æŒ‡çºµæ¨ªé©°éª‹ï¼Œæ–½å±•æ‰èƒ½ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡14</title>
      <link href="/2019/03/24/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8714/"/>
      <url>/2019/03/24/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8714/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨è®ºæ–‡:</p><ol><li>Is Second-order Information Helpful for Large-scale Visual Recognition?</li><li>The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification</li></ol><h2 id="1ï¸âƒ£-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition"><a href="#1ï¸âƒ£-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition" class="headerlink" title="1ï¸âƒ£[Is Second-order Information Helpful for Large-scale Visual Recognition?]"></a>1ï¸âƒ£[Is Second-order Information Helpful for Large-scale Visual Recognition?]</h2><p>é€šè¿‡åæ–¹å·®çš„æ–¹æ³•è·å¾—å›¾åƒçš„äºŒé˜¶ä¿¡æ¯ã€‚<br>å‚è€ƒäº†<a href="https://zhuanlan.zhihu.com/p/46864160" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46864160</a></p><p>æ·±åº¦åˆ†ç±»ç½‘ç»œä¸»è¦åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šç‰¹å¾æå–å’Œåˆ†ç±»å™¨ã€‚æ— è®ºæ˜¯VGGè¿˜æ˜¯GoogleNetï¼Œåæ¥çš„Resnetã€Densenetï¼Œåœ¨è¿æ¥åˆ†ç±»å™¨ä¹‹å‰ï¼Œä¸€èˆ¬éƒ½è¿æ¥äº†ä¸€ä¸ªPoolingå±‚ã€‚<br>ä½†poolingåªè·å¾—äº†featureçš„ä¸€é˜¶ä¿¡æ¯ï¼Œå¯¹äºç»†åˆ†ç±»é—®é¢˜ä¸­ç±»é—´å·®å¼‚ä¸æ˜¾è‘—ï¼Œä¸€é˜¶ä¿¡æ¯å¯èƒ½æœ‰ä¸€äº›ä¸é€‚ç”¨ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€é˜¶ä¿¡æ¯è·å¾—äºŒé˜¶ä¿¡æ¯ï¼Œä»è€Œè·å–æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</p><p>æœ¬æ–‡é€šè¿‡è·å–<strong>ç‰¹å¾åæ–¹å·®</strong>çš„æ–¹æ³•ï¼Œä»¥è¾¾åˆ°è¯¥ç›®çš„ã€‚</p><p>è¾“å…¥:$\mathbf{X} \in \mathbb{R}^{d \times N}$</p><p>åˆ™åæ–¹å·®çŸ©é˜µä¸º$\mathbf{X} \mapsto \mathbf{P}, \quad \mathbf{P}=\mathbf{X} \overline{\mathbf{I}} \mathbf{X}^{T}$ï¼Œå…¶ä¸­$\overline{\mathbf{I}}=\frac{1}{N}\left(\mathbf{I}-\frac{1}{N} \mathbf{1} \mathbf{1}^{T}\right)$, $\mathbf{I}$æ˜¯å•ä½é˜µï¼Œ$\mathbf{1}$æ˜¯å…¨1çš„å‘é‡ã€‚</p><p>åæ–¹å·®çŸ©é˜µæ˜¯åŠæ­£å®šçŸ©é˜µï¼Œå› æ­¤å¯å†™æˆ$\mathbf{P} \mapsto(\mathbf{U}, \mathbf{\Lambda}), \quad \mathbf{P}=\mathbf{U} \mathbf{\Lambda} \mathbf{U}^{T}$ï¼Œå…¶ä¸­$\boldsymbol{\Lambda}=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{d}\right)$ï¼Œ$\mathbf{U}=\left[\mathbf{u}_{1}, \dots, \mathbf{u}_{d}\right]$ï¼Œ$\mathbf{U}$æ˜¯å¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚</p><p>æœ€ç»ˆå¯è·å¾—$\mathbf{Q}$çŸ©é˜µï¼š$(\mathbf{U}, \boldsymbol{\Lambda}) \mapsto \mathbf{Q}, \mathbf{Q} \triangleq \mathbf{P}^{\alpha}=\mathbf{U F}(\mathbf{\Lambda}) \mathbf{U}^{T}$ï¼Œå…¶ä¸­$\alpha$æ˜¯ä¸€ä¸ªæ­£å®æ•°ï¼Œ$\mathbf{F}(\boldsymbol{\Lambda})=\operatorname{diag}\left(f\left(\lambda_{1}\right), \ldots, f\left(\lambda_{d}\right)\right)$ï¼Œå…¶ä¸­$f\left(\lambda_{i}\right)=\lambda_{i}^{\alpha}$ï¼Œæ˜¯ç‰¹å¾å€¼çš„å¹‚ï¼Œå¦‚æœè¦åšå½’ä¸€åŒ–ï¼Œé‚£ä¹ˆå¯ä»¥æœ‰ï¼š</p><script type="math/tex; mode=display">f\left(\lambda_{i}\right)=\left\{\begin{array}{cc}{\lambda_{i}^{\alpha} / \lambda_{1}^{\alpha}} & {\text { for MPN+M }-\ell_{2}} \\ {\lambda_{i}^{\alpha} /\left(\sum_{k} \lambda_{k}^{2 \alpha}\right)^{\frac{1}{2}}} & {\text { for MPN+M-Fro }}\end{array}\right.</script><p>ä¹‹æ‰€ä»¥å–å¹‚ï¼Œæ˜¯ä¸ºäº†è§£å†³åœ¨åæ–¹å·®ä¼°è®¡ä¸­å°æ ·æœ¬é«˜ç»´åº¦çš„é—®é¢˜ï¼Œä»¥resnetä¸ºä¾‹ï¼Œæœ€åå¾—åˆ°çš„featureä¸º7X7X512ï¼Œä¹Ÿå°±æ˜¯49ä¸ª512ç»´çš„featureï¼Œè¿™æ ·ä¼°è®¡å‡ºæ¥çš„åæ–¹å·®çŸ©é˜µæ˜¯ä¸é è°±çš„ï¼Œè€Œé€šè¿‡å¹‚è¿™ä¸ªæ“ä½œï¼Œå¯ä»¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚é€šè¿‡å®éªŒå¯ä»¥å‘ç°ï¼Œå½“å¹‚æ¬¡ä¸º0.5ä¹Ÿå°±æ˜¯å¹³æ–¹æ ¹æ“ä½œæ—¶ï¼Œæ•ˆæœæœ€ä¼˜ã€‚ï¼ˆä¼¼ä¹ç±»ä¼¼çš„æœ‰word2vecçš„å¹³æ»‘ï¼‰</p><p>ï¼ˆè™½ç„¶è¿™ç¯‡æœ‰äº›çœ‹ä¸å¤§æ‡‚ï¼Œä½†ä¸€ä¸ªå¯å‘å°±æ˜¯ï¼Œå¯ä»¥é€šè¿‡åæ–¹å·®çš„æ–¹å¼è¿›è¡Œç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼‰</p><hr><h2 id="2ï¸âƒ£-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification"><a href="#2ï¸âƒ£-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification" class="headerlink" title="2ï¸âƒ£[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]"></a>2ï¸âƒ£[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]</h2><p>æå‡ºä½¿ç”¨å·ç§¯å‡ºæ¥åçš„featureç»è¿‡poolingä½œä¸ºæœ€åçš„å›¾åƒç‰¹å¾è¡¨ç¤ºè€Œä¸æ˜¯å…¨è¿æ¥åçš„ç‰¹å¾è¡¨ç¤ºã€‚</p><p>Motivationï¼šåªä½¿ç”¨æœ€åä¸€å±‚fcçš„ç‰¹å¾æœ‰ä¸€ä¸ªç¼ºç‚¹ï¼Œå°±æ˜¯ä¸¢å¤±ä½ç½®ä¿¡æ¯ï¼Œè€Œconvolution layeråŒ…å«äº†ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯ã€‚åœ¨poolingå®Œåæ¯ä¸ªlocalåŒºåŸŸéƒ½èƒ½è·å¾—ä¸€ä¸ªç‰¹å¾ï¼Œå¹¶æ‹¼æ¥èµ·æ¥ä½œä¸ºæœ€åçš„è¡¨ç¤ºã€‚</p><p><img src="/images/15533936911589.jpg" width="60%" height="50%"></p><p>prerequisite:<br>â‘ é¦–å…ˆæœ‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹<br>â‘¡æœ‰ä¸¤å±‚ä¸€æ ·$H\times W$çš„convolutionã€‚è®ºæ–‡ä»¥AlexNetä½œä¸ºä¾‹å­</p><p>å‡è®¾å·ç§¯åçš„feature mapæ˜¯$H Ã— W Ã— D$ï¼Œé‚£ä¹ˆå¯ä»¥ç†è§£æˆï¼Œæˆ‘ä»¬å°†å›¾ç‰‡åˆ†ä¸º$H Ã— W$çš„åŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸçš„ç‰¹å¾ç”¨$D$ç»´è¡¨ç¤ºã€‚æˆ‘ä»¬ç§°æ¯ä¸ª$D$ç»´ç‰¹å¾ä¸€ä¸ªspatial unitã€‚å½“ä½¿ç”¨å…¨è¿æ¥æ—¶ï¼Œè¿™éƒ¨åˆ†çš„ç©ºé—´ä¿¡æ¯å°±ä¸¢å¤±äº†ï¼Œå¹¶ä¸”æ— æ³•è¿˜åŸã€‚</p><p>æœ¬æ–‡æå‡ºï¼Œå°†æ¯ä¸ªåŒºåŸŸæå–å‡ºä¸€ä¸ªç‰¹å¾ï¼Œç„¶åæ‹¼èµ·æ¥ç»„æˆä¸€æ•´å¼ å›¾çš„ç‰¹å¾ï¼Œå¦‚ä¸‹å›¾ï¼Œæ¯ä¸ªé•¿æ¡ï¼ˆä¹Ÿå³$1\times 1\times channel$ï¼‰ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼š</p><p><img src="/images/15533939765641.jpg" width="50%" height="50%"></p><p>å¦‚ä½•åˆ¤æ–­åŒºåŸŸï¼Ÿä¸€ç§æ–¹æ³•æ˜¯é¦–å…ˆæ£€æµ‹å‡ºå¤šä¸ªåŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸå¯¹åº”ä¸€ç§object partï¼Œç„¶åå¯¹äºè½å…¥è¯¥åŒºåŸŸçš„ç‰¹å¾è¿›è¡Œpoolingï¼Œç»™å®šDç§human-specified object partsï¼Œé‚£ä¹ˆå¯ä»¥è·å¾—Dä¸ªfeatureä¸”æ‹¼åœ¨ä¸€èµ·ã€‚</p><script type="math/tex; mode=display">\mathbf{P}_{k}^{t}=\sum_{i=1} \mathbf{x}_{i} I_{i, k}</script><p>å…·ä½“è€Œè¨€ï¼Œ$\mathbf{x}_{i}$æ˜¯ç‰¹å¾ï¼Œ$I_{i, k}$æ˜¯äºŒå…ƒçš„indicatorï¼Œè¡¨æ˜$\mathbf{x}_{i}$æ˜¯å¦è½å…¥è¯¥åŒºåŸŸï¼Œæ¯ä¸ª$I$å®é™…ä¸Šå®šä¹‰äº†ä¸€ä¸ªæ± åŒ–é€šé“ã€‚å½“ç„¶ï¼Œè¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å°†indicatorä»äºŒå…ƒæ‰©å±•ä¸ºæƒé‡ã€‚</p><p>ä½†åœ¨å®ç°çš„è¿‡ç¨‹ä¸­ï¼Œå¹¶æ²¡æœ‰human-specifiedçš„åŒºåŸŸã€‚è¿™é‡Œæˆ‘ä»¬å°±å€ŸåŠ©ä¸‹ä¸€å±‚çš„å·ç§¯ä½œä¸ºindicatorã€‚</p><blockquote><p>By doing so, D t+1 pooling channels are created for the local features extracted from the tth convolutional layer</p></blockquote><p>è¿™ä¹Ÿå°±è¢«ç§°ä¸ºcross-convolutional-layer poolingã€‚</p><p>å¦‚ä½•åšï¼Ÿ</p><blockquote><p>the filter of a convolutional layer works as a part detector and its feature map serves a similar role as the part region indicator map.</p></blockquote><p>å…·ä½“è€Œè¨€ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">\begin{array}{l}{\mathbf{P}^{t}=\left[\mathbf{P}_{1}^{t}, \mathbf{P}_{2}^{t}, \cdots, \mathbf{P}_{k}^{t}, \cdots, \mathbf{P}_{D_{t+1}}^{t}\right]} \\ {\text { where, } \mathbf{P}_{k}^{t}=\sum_{i=1}^{N_{t}} \mathbf{x}_{i}^{t} a_{i, k}^{t+1}}\end{array}</script><p>$\mathbf{P}^{t}$è¡¨ç¤ºç¬¬tå±‚convolutionåœ¨å·ç§¯è¿‡ååšcross-poolingåçš„ç‰¹å¾é›†åˆï¼Œä¹Ÿå³æˆ‘ä»¬è¦è·å¾—çš„è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºé€šè¿‡$D_{t+1}$æ¬¡poolingåçš„ç»“æœæ‹¼æ¥è€Œæˆã€‚$D_{t+1}$å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯ç¬¬t+1å±‚çš„å·ç§¯çš„channelç»´æ•°ã€‚å‡è®¾$\mathbf{a}_{i}^{t+1} \in \mathbb{R}^{D_{t+1}}$æ˜¯ç¬¬t+1å±‚convolutionçš„ç¬¬iä¸ªç©ºé—´å•ä½ï¼ˆspatial unitï¼‰çš„feature vectorï¼Œå…¶ä¸­$a_{i, k}^{t+1}$æ˜¯è¯¥å‘é‡çš„ä¸€ä¸ªå€¼ï¼Œè¯¥å€¼å°±ä½œä¸ºpoolingçš„æƒé‡ã€‚</p><p>ä¸Šè¿°æœ‰äº›ç»•å£ä¸”éš¾æ‡‚ï¼Œç›´æ¥çœ‹ä¾‹å­ï¼š<br><img src="/images/15533957004853.jpg" width="80%" height="50%"><br><img src="/images/15533957336100.jpg" width="80%" height="50%"></p><p>å³ï¼Œç¬¬t+1å±‚convolutionçš„channelç»´åº¦ä¸ºå¤šå°‘ï¼Œåˆ™poolingåçš„ç‰¹å¾ä¸ªæ•°å³ä¸ºå¤šå°‘ã€‚å› ä¸ºç¬¬tå±‚ä¸ç¬¬t+1å±‚çš„$H\times W$æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆå¯ä»¥ç”¨t+1å±‚çš„æ¯ä¸ªsliceå»å¯¹ç¬¬tå±‚çš„convolutionè¿›è¡ŒåŠ æƒã€‚</p><p>ä¸ºä»€ä¹ˆè¿™æ ·æ˜¯åˆç†çš„ï¼Ÿ<br>å› ä¸ºç¬¬t+1å±‚çš„convolutionæå–äº†$D_{t+1}$ä¸ªç‰¹å¾ï¼Œä½¿ç”¨çš„æ˜¯$m\times n$çš„kernel sizeï¼Œå¦‚æœ$x$æ˜¯è¢«$m\times n$çš„æŸä¸ªkernelæå–äº†ï¼Œé‚£ä¹ˆå¾ˆè‡ªç„¶çš„ï¼Œ$x$å°±æ˜¯å¯¹åº”è¯¥kernelæå–å‡ºæ¥çš„featureçš„ä¸€ä¸ªspatial unitã€‚è¯´ç™½äº†å°±æ˜¯ç¬¬tå±‚ä¸ç¬¬t+1å±‚çš„ç©ºé—´å¯¹åº”ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> second-order </tag>
            
            <tag> pooling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯20</title>
      <link href="/2019/03/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D20/"/>
      <url>/2019/03/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D20/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰"><a href="#1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰" class="headerlink" title="1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰"></a>1ï¸âƒ£æ‚è¯—ä¸ƒé¦–ï¼ˆå…¶å››ï¼‰</h3><p>[ä¸‰å›½] æ›¹æ¤<br>å—å›½æœ‰ä½³äººï¼Œå®¹åè‹¥æ¡ƒæã€‚<br>æœæ¸¸æ±ŸåŒ—å²¸ï¼Œå¤•å®¿æ½‡æ¹˜æ²šã€‚<br>æ—¶ä¿—è–„æœ±é¢œï¼Œè°ä¸ºå‘çš“é½¿ï¼Ÿ<br>ä¿¯ä»°å²å°†æš®ï¼Œè£è€€éš¾ä¹…æƒã€‚</p><p><a href="http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f" target="_blank" rel="noopener">http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f</a></p><hr><h3 id="2ï¸âƒ£æ¢¦æ±Ÿå—"><a href="#2ï¸âƒ£æ¢¦æ±Ÿå—" class="headerlink" title="2ï¸âƒ£æ¢¦æ±Ÿå—"></a>2ï¸âƒ£æ¢¦æ±Ÿå—</h3><p>[å”] æ¸©åº­ç­ <br>åƒä¸‡æ¨ï¼Œæ¨æåœ¨å¤©æ¶¯ã€‚å±±æœˆä¸çŸ¥å¿ƒé‡Œäº‹ï¼Œæ°´é£ç©ºè½çœ¼å‰èŠ±ï¼Œæ‘‡æ›³ç¢§äº‘æ–œã€‚</p><p><a href="http://lib.xcz.im/work/57b8d0c77db2a2005425c856" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8d0c77db2a2005425c856</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡13</title>
      <link href="/2019/03/17/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8713/"/>
      <url>/2019/03/17/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8713/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation"><a href="#1ï¸âƒ£-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation" class="headerlink" title="1ï¸âƒ£[Depthwise Separable Convolutions for Neural Machine Translation]"></a>1ï¸âƒ£[Depthwise Separable Convolutions for Neural Machine Translation]</h2><p>å°†depthwise separable convolution æ·±åº¦å¯åˆ†ç¦»å·ç§¯ ç”¨äºç¿»è¯‘ä»»åŠ¡ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹depthwise separableè¿›è¡Œæ›´è¿›ä¸€æ­¥çš„å‚æ•°é‡ä¼˜åŒ–ï¼Œä¹Ÿå³super-separableã€‚ï¼ˆå…¶å®æˆ‘è§‰å¾—å¹¶æ²¡æœ‰å•¥åˆ›æ–°æ€§çš„æ„Ÿè§‰ï¼‰</p><p><img src="/images/15528281403428.jpg" width="90%" height="50%"></p><p>é¦–å…ˆä»‹ç»ä»€ä¹ˆæ˜¯depthwise separable convolutionï¼Œå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªdepthwise+pointwiseã€‚</p><script type="math/tex; mode=display">\operatorname{Conv}(W, y)_{(i, j)}=\sum_{k, l, m}^{K, L, M} W_{(k, l, m)} \cdot y_{(i+k, j+l, m)}</script><script type="math/tex; mode=display">\operatorname{PointwiseConv}(W, y)_{(i, j)}=\sum_{m}^{M} W_{m} \cdot y_{(i, j, m)}</script><script type="math/tex; mode=display">\text {DepthwiseConv}(W, y)_{(i, j)}=\sum_{k, l}^{K, L} W_{(k, l)} \odot y_{(i+k, j+l)}</script><script type="math/tex; mode=display">\operatorname{SepConv}\left(W_{p}, W_{d}, y\right)_{(i, j)}=\text {PointwiseConv}_{(i, j)}\left(W_{p}, \text { DepthwiseConv }_{(i, j)}\left(W_{d}, y\right)\right)</script><p>å‡ ç§convolutionçš„å‚æ•°é‡å¯¹æ¯”ï¼š<br><img src="/images/15528283555357.jpg" width="80%" height="50%"><br>å…¶ä¸­kæ˜¯kernel sizeï¼Œcæ˜¯channelï¼Œgæ˜¯groupã€‚</p><p>g-Sub-separableæ˜¯æŒ‡å°†channelåˆ†ä¸ºå‡ ä¸ªgroupï¼Œæ¯ä¸ªgroupè¿›è¡Œå¸¸è§„çš„convolutionæ“ä½œï¼›g-Super-separableï¼Œä¹Ÿå³æœ¬æ–‡ä¸­æå‡ºçš„convolutionï¼ŒåŒæ ·æ˜¯å°†channelåˆ†ä¸ºå‡ ä¸ªgroupï¼Œç„¶åå¯¹æ¯ä¸ªgroupè¿›è¡Œdepthwise-separableçš„å·ç§¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Squeeze-and-Excitation-Networks"><a href="#2ï¸âƒ£-Squeeze-and-Excitation-Networks" class="headerlink" title="2ï¸âƒ£[Squeeze-and-Excitation Networks]"></a>2ï¸âƒ£[Squeeze-and-Excitation Networks]</h2><p>æå‡ºä¸€ç§æ–°å‹çš„ç½‘ç»œï¼Œèƒ½å¤Ÿé€šè¿‡å»ºæ¨¡channelä¹‹é—´çš„å…³ç³»ï¼Œä½¿å¾—æ¯ä¸ªchannelèƒ½å¤Ÿè·å¾—å…¨å±€çš„ä¿¡æ¯ï¼Œè¿›è€Œæé«˜æ¨¡å‹çš„èƒ½åŠ›ã€‚<br><img src="/images/15528285519609.jpg" width="90%" height="50%"></p><p>åˆ†ä¸ºä¸¤æ­¥ï¼šç¬¬ä¸€æ­¥æ˜¯è·å¾—ä¸€ä¸ªå…¨å±€çš„è¡¨ç¤ºï¼Œç¬¬äºŒæ­¥æ˜¯æ ¹æ®å…¨å±€ä¿¡æ¯æ›´æ–°æ¯ä¸ªchannelçš„ä¿¡æ¯ã€‚</p><h3 id="ç¬¦å·"><a href="#ç¬¦å·" class="headerlink" title="ç¬¦å·"></a>ç¬¦å·</h3><p>è¾“å…¥ï¼š$ \mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}} $<br>ç»è¿‡ç‰¹å¾æå–åï¼ˆå¦‚Convolution)ï¼š$\mathbf{U} \in \mathbb{R}^{H \times W \times C}$ï¼Œä¹Ÿå³ï¼š$\mathbf{U}=\mathbf{F}_{t r}(\mathbf{X})$<br>å°†$\mathbf{U}$å†™æˆï¼š$\mathbf{U}=\left[\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{C}\right]$<br>$\mathbf{V}$ æ˜¯å¯å­¦ä¹ çš„å·ç§¯æ ¸å‚æ•°ï¼š $\mathbf{V}=\left[\mathbf{v}_{1}, \mathbf{v}_{2}, \ldots, \mathbf{v}_{C}\right]$</p><p>åˆ™ä¸Šè¿°å·ç§¯å˜æ¢å¯å†™æˆï¼š$\mathbf{u}_{c}=\mathbf{v}_{c} \ast \mathbf{X}=\sum_{s=1}^{C^{\prime}} \mathbf{v}_{c}^{s} \ast \mathbf{x}^{s}$</p><h3 id="Squeeze-Global-Information-Embedding"><a href="#Squeeze-Global-Information-Embedding" class="headerlink" title="Squeeze: Global Information Embedding"></a>Squeeze: Global Information Embedding</h3><p>ç¬¬ä¸€æ­¥ï¼Œå°†æ‰€æœ‰çš„ç‰¹å¾è¿›è¡Œæ•´åˆå¾—åˆ°å…¨å±€çš„ç‰¹å¾ï¼š</p><script type="math/tex; mode=display">z_{c}=\mathbf{F}_{s q}\left(\mathbf{u}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} u_{c}(i, j)</script><p>è®ºæ–‡æå–å…¨å±€ç‰¹å¾çš„æ–¹æ³•ç›´æ¥ç”¨ç®€å•çš„global average poolingã€‚é‚£ä¹ˆ$\mathbf{z} \in \mathbb{R}^{C}$çš„æ¯ä¸€ç»´å°±ä»£è¡¨æ¯ä¸€ç»´çš„channelã€‚</p><h3 id="Excitation-Adaptive-Recalibration"><a href="#Excitation-Adaptive-Recalibration" class="headerlink" title="Excitation: Adaptive Recalibration"></a>Excitation: Adaptive Recalibration</h3><p>ä¸attentionä¸åŒçš„æ˜¯ï¼Œè®ºæ–‡å¸Œæœ›èƒ½å¤ŸåŒæ—¶å¼ºè°ƒä¸åŒå¤šä¸ªchannelçš„é‡è¦ï¼ˆè€Œä¸æ˜¯one-hotçš„å½¢å¼ï¼‰ï¼Œå› æ­¤ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é—¨æ§åˆ¶æœºåˆ¶ï¼Œé‡‡ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼šï¼ˆè¿™é‡Œçš„æƒ³æ³•æŒºæœ‰æ„æ€ï¼Œç›¸å¯¹attentionçš„softmaxä¼¼ä¹ç¡®å®ä¼šæ›´å¥½çš„æ ·å­ï¼‰</p><script type="math/tex; mode=display">\mathbf{s}=\mathbf{F}_{ex}(\mathbf{z}, \mathbf{W})=\sigma(g(\mathbf{z}, \mathbf{W}))=\sigma\left(\mathbf{W}_{2} \delta\left(\mathbf{W}_{1} \mathbf{z}\right)\right)</script><p>ä¸ºäº†å‡å°‘å‚æ•°è¿™é‡Œçš„MLPé‡‡ç”¨äº†bottleneckçš„å½¢å¼ã€‚äº¦å³ï¼š<br>${\mathbf{W}_{1} \in \mathbb{R}^{\frac{C}{r} \times C}}$ $ {\mathbf{W}_{2} \in \mathbb{R}^{C \times \frac{C}{r}}}$<br>$r$æ˜¯reduction ratioã€‚</p><p>è´´ä¸Šä½œè€…çš„æ€è·¯ï¼š</p><blockquote><p>To make use of the information aggregated in the squeeze operation, we follow it with a second operation which aims to fully capture channel-wise dependencies. To fulfill this objective, the function must meet two criteria: first, it must be ï¬‚exible (in particular, it must be capable of learning a nonlinear interaction between channels) and second, it must learn a non-mutually-exclusive relationship since we would like to ensure that multiple channels are allowed to be emphasised (rather than enforcing a one-hot activation). To meet these criteria, we opt to employ a simple gating mechanism with a sigmoid activation.</p></blockquote><p>æœ€åå¯¹æ¯ä¸ªchannelè¿›è¡Œ<strong>æ”¾ç¼©</strong>ï¼Œè·å¾—æ–°çš„è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">\widetilde{\mathbf{x}}_{c}=\mathbf{F}_{\text {scale}}\left(\mathbf{u}_{c}, s_{c}\right)=s_{c} \cdot \mathbf{u}_{c}</script><hr><h2 id="3ï¸âƒ£-Non-local-Neural-Networks"><a href="#3ï¸âƒ£-Non-local-Neural-Networks" class="headerlink" title="3ï¸âƒ£[Non-local Neural Networks]"></a>3ï¸âƒ£[Non-local Neural Networks]</h2><p>æå‡ºä¸€ç§æ–°çš„ç»“æ„ï¼Œä¸ä¸Šä¸€ç¯‡ç±»ä¼¼ï¼Œå¸Œæœ›æ¨¡å‹çš„æ¯ä¸ªä½ç½®éƒ½èƒ½æ„ŸçŸ¥åˆ°å…¶ä»–ä½ç½®ï¼Œä»è€Œæ•è·é•¿ç¨‹ä¾èµ–ï¼Œæ‹¥æœ‰å…¨å±€ä¿¡æ¯ã€‚</p><p><img src="/images/15528297540165.jpg" width="60%" height="50%"></p><h3 id="Non-local-Network"><a href="#Non-local-Network" class="headerlink" title="Non-local Network"></a>Non-local Network</h3><p>å®šä¹‰non-localç½‘ç»œï¼š</p><script type="math/tex; mode=display">\mathbf{y}_{i}=\frac{1}{\mathcal{C}(\mathbf{x})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) g\left(\mathbf{x}_{j}\right)</script><p>å…¶ä¸­$\mathcal{C}$æ˜¯å½’ä¸€åŒ–å‡½æ•°ï¼›$f$æ˜¯ç¬¬$i$ä¸ªä½ç½®ä¸ç¬¬$j$ä¸ªä½ç½®çš„äº¤äº’å‡½æ•°ï¼›$g$è®¡ç®—ç¬¬$j$ä¸ªä½ç½®çš„è¡¨ç¤ºã€‚</p><h4 id="g-çš„å…·ä½“å½¢å¼"><a href="#g-çš„å…·ä½“å½¢å¼" class="headerlink" title="$g$çš„å…·ä½“å½¢å¼"></a>$g$çš„å…·ä½“å½¢å¼</h4><p>ä¸€ä¸ªçº¿æ€§å‡½æ•°ï¼š$g\left(\mathbf{x}_{j}\right)=W_{g} \mathbf{x}_{j}$<br>åœ¨å®ç°çš„æ—¶å€™æ˜¯ä¸€ä¸ª$1\times1$æˆ– $1\times1\times1$çš„convolutionã€‚</p><h4 id="f-çš„å…·ä½“å½¢å¼"><a href="#f-çš„å…·ä½“å½¢å¼" class="headerlink" title="$f$çš„å…·ä½“å½¢å¼"></a>$f$çš„å…·ä½“å½¢å¼</h4><p>â‘ Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\mathbf{x}_{i}^{T} \mathbf{x}_{j}}$<br>åˆ™å½’ä¸€åŒ–å®šä¹‰ä¸º$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$ ã€‚</p><p>â‘¡Embedded Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)}$<br>å…¶ä¸­ï¼š$\theta\left(\mathbf{x}_{i}\right)=W_{\theta} \mathbf{x}_{i} $, $ \phi\left(\mathbf{x}_{j}\right)=W_{\phi} \mathbf{x}_{j}$<br>å½’ä¸€åŒ–ï¼š$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$</p><p>å¯ä»¥çœ‹åˆ°self-attentionæ˜¯Embedded Gaussiançš„ä¸€ç§å½¢å¼ã€‚è™½ç„¶æœ‰è¿™æ ·çš„å…³ç³»ï¼Œä½†ä½œè€…åœ¨å®éªŒä¸­å‘ç°softmaxå¹¶ä¸æ˜¯å¿…è¦çš„ã€‚</p><p>â‘¢Dot product<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)$<br>å½’ä¸€åŒ–ï¼š$\mathcal{C}(\mathbf{x})=N$</p><p>â‘£Concatenation<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\operatorname{ReLU}\left(\mathbf{w}_{f}^{T}\left[\theta\left(\mathbf{x}_{i}\right), \phi\left(\mathbf{x}_{j}\right)\right]\right)$<br>$\mathcal{C}(\mathbf{x})=N$</p><p>æœ‰äº†ä¸Šé¢çš„non-localçš„ä»‹ç»ï¼Œå¯ä»¥ç›´æ¥å°†å…¶ç”¨äºresidual networkã€‚<br>$\mathbf{z}_{i}=W_{z} \mathbf{y}_{i}+\mathbf{x}_{i}$<br>$y$åˆ™æ˜¯non-local networkçš„è¾“å‡ºã€‚</p><h3 id="Non-local-blockçš„ç­–ç•¥-tricks"><a href="#Non-local-blockçš„ç­–ç•¥-tricks" class="headerlink" title="Non-local blockçš„ç­–ç•¥/tricks"></a>Non-local blockçš„ç­–ç•¥/tricks</h3><p>â‘ è®¾ç½®$W_g$,$W_Î¸$,$W_Ï•$çš„channelçš„æ•°ç›®ä¸ºxçš„channelæ•°ç›®çš„ä¸€åŠï¼Œè¿™æ ·å°±å½¢æˆäº†ä¸€ä¸ªbottleneckï¼Œèƒ½å¤Ÿå‡å°‘ä¸€åŠçš„è®¡ç®—é‡ã€‚Wzå†é‡æ–°æ”¾å¤§åˆ°xçš„channelæ•°ç›®ï¼Œä¿è¯è¾“å…¥è¾“å‡ºç»´åº¦ä¸€è‡´ã€‚</p><p>â‘¡åœ¨$\frac{1}{\mathcal{C}(\hat{\mathbf{x}})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \hat{\mathbf{x}}_{j}\right) g\left(\hat{\mathbf{x}}_{j}\right)$ä½¿ç”¨ä¸‹é‡‡æ ·ï¼Œå¦‚max-poolingï¼Œå‡å°‘è®¡ç®—é‡ã€‚</p><hr><h2 id="4ï¸âƒ£-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition"><a href="#4ï¸âƒ£-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition" class="headerlink" title="4ï¸âƒ£[Bilinear CNN Models for Fine-grained Visual Recognition]"></a>4ï¸âƒ£[Bilinear CNN Models for Fine-grained Visual Recognition]</h2><p>æå‡ºä¸€ç§åŒçº¿æ€§æ¨¡å‹ï¼Œç”±ä¸¤ä¸ªç‰¹å¾æå–å™¨ç»„æˆï¼Œä»–ä»¬çš„è¾“å‡ºåš<strong>å¤–ç§¯</strong>ï¼Œæœ€ç»ˆè·å¾—å›¾åƒæè¿°ç‰¹å¾ã€‚</p><p>Motivation(?ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™æ ·)ï¼šå¯¹äºç»†ç²’åº¦ç‰©ä½“çš„åˆ†ç±»ï¼Œå…ˆå¯¹å±€éƒ¨å®šä½ï¼Œå†æå–ç‰¹å¾ã€‚ä¸¤ä¸ªç‰¹å¾æå–å™¨ä¸€ä¸ªæ˜¯æå–locationï¼Œå¦ä¸€ä¸ªæå–ç‰¹å¾ã€‚</p><p><img src="/images/15528310057673.jpg" width="60%" height="50%"></p><p>ä¸ºä»€ä¹ˆç”¨<strong>å¤–ç§¯</strong>ï¼Ÿ</p><blockquote><p>outer product captures pairwise correlations between the feature channels</p></blockquote><p>æœ‰æ„æ€çš„æ˜¯ä½œè€…å°†è¯¥æ¨¡å‹å’Œäººè„‘è§†è§‰å¤„ç†çš„ä¸¤ä¸ªå‡è®¾è”ç³»åœ¨ä¸€èµ·(stream hypothesis)ï¼š<br>here are two main pathways, or â€œstreamsâ€. The ventral stream (or, â€œwhat pathwayâ€) is involved with object identiï¬cation and recognition. The dorsal stream (or, â€œwhere pathwayâ€) is involved with processing the objectâ€™s spatial location relative to the viewer.<br>ä¸è¿‡çœ‹çœ‹å°±å¥½ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆé“ç†ã€‚</p><p>å¯¹äºä¸€ä¸ªåˆ†ç±»çš„åŒçº¿æ€§æ¨¡å‹è€Œè¨€ï¼Œå…¶ä¸€èˆ¬å½¢å¼æ˜¯ä¸€ä¸ªå››å…ƒç»„ï¼š$\mathcal{B}=\left(f_{A}, f_{B}, \mathcal{P}, \mathcal{C}\right)$ã€‚å…¶ä¸­$f$æ˜¯ç‰¹å¾å‡½æ•°ï¼Œ$\mathcal{P}$æ˜¯poolingå‡½æ•°ï¼Œ$\mathcal{C}$æ˜¯åˆ†ç±»å‡½æ•°ã€‚å…·ä½“è€Œè¨€ï¼Œ$f$æ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œ${f : \mathcal{L} \times \mathcal{I} \rightarrow} {R^ {c\times D}} $ã€‚ä¹Ÿå³å°†ä¸€ä¸ªimageå’Œä¸€ä¸ªlocation L æ˜ å°„æˆfeatureã€‚ï¼ˆWe refer to locations generally which can include position and scale å…¶å®è¿™é‡Œä¸æ˜¯å¾ˆæ‡‚locationçš„æ„æ€ï¼‰</p><p>å°†feature aå’Œfeature bç»“åˆåœ¨ä¸€èµ·ï¼š<br>$\text { bilinear }\left(l, \mathcal{I}, f_{A}, f_{B}\right)=f_{A}(l, \mathcal{I})^{T} f_{B}(l, \mathcal{I})$</p><p>poolingæœ‰å¥½å‡ ç§ï¼Œå¯ä»¥ç›´æ¥åŠ èµ·æ¥ï¼Œæˆ–è€…ä½¿ç”¨max-poolingã€‚è¿™é‡Œä½¿ç”¨ç›´æ¥åŠ èµ·æ¥çš„æ–¹å¼ï¼Œå¯ä»¥ç†è§£ä¸ºï¼Œè¿™äº›ç‰¹å¾æ˜¯æ— åº(orderless)çš„å åŠ ã€‚</p><p>åœ¨è·å¾—è¾“å‡ºåå†åšä¸€äº›æ“ä½œ/trickèƒ½å¤Ÿæå‡è¡¨ç°ï¼š<br>$\begin{array}{l}{\mathbf{y} \leftarrow \operatorname{sign}(\mathbf{x}) \sqrt{|\mathbf{x}|}} \\ {\mathbf{z} \leftarrow \mathbf{y} /|\mathbf{y}|_{2}}\end{array}$</p><p>è®¨è®ºï¼š<br>â‘ But do the networks specialize into roles of localization (â€œwhereâ€) and appearance modeling (â€œwhatâ€) when initialized asymmetrically and ï¬ne-tuned?<br>é€šè¿‡å¯è§†åŒ–å‘ç°ï¼Œå¹¶æ²¡æœ‰æ˜ç¡®çš„åŠŸèƒ½åˆ†å¼€ã€‚<br>Both these networks tend to activate strongly on highly speciï¬c semantic parts</p><p>â‘¡bilinearçš„å¥½å¤„è¿˜å¯ä»¥æ‰©å±•æˆtrilinearï¼Œæ·»åŠ æ›´å¤šçš„ä¿¡æ¯ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> NMT </tag>
            
            <tag> SE-Net </tag>
            
            <tag> Non-local </tag>
            
            <tag> Bilinear </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯19</title>
      <link href="/2019/03/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D19/"/>
      <url>/2019/03/17/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D19/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£é€çµæ¾ˆä¸Šäºº"><a href="#1ï¸âƒ£é€çµæ¾ˆä¸Šäºº" class="headerlink" title="1ï¸âƒ£é€çµæ¾ˆä¸Šäºº"></a>1ï¸âƒ£é€çµæ¾ˆä¸Šäºº</h3><p>[å”] åˆ˜é•¿å¿<br>è‹è‹ç«¹æ—å¯ºï¼Œæ³æ³é’Ÿå£°æ™šã€‚<br>è·ç¬ å¸¦æ–œé˜³ï¼Œé’å±±ç‹¬å½’è¿œã€‚</p><p>è·ï¼ˆhÃ¨ï¼‰ç¬ ï¼šèƒŒç€æ–—ç¬ ã€‚</p><p><a href="http://lib.xcz.im/work/57b90887128fe10054c9c750" target="_blank" rel="noopener">http://lib.xcz.im/work/57b90887128fe10054c9c750</a></p><hr><h3 id="2ï¸âƒ£è‹å¹•é®-Â·-æ€€æ—§"><a href="#2ï¸âƒ£è‹å¹•é®-Â·-æ€€æ—§" class="headerlink" title="2ï¸âƒ£è‹å¹•é® Â· æ€€æ—§"></a>2ï¸âƒ£è‹å¹•é® Â· æ€€æ—§</h3><p>[å®‹] èŒƒä»²æ·¹<br>ç¢§äº‘å¤©ï¼Œé»„å¶åœ°ï¼Œç§‹è‰²è¿æ³¢ï¼Œæ³¢ä¸Šå¯’çƒŸç¿ ã€‚å±±æ˜ æ–œé˜³å¤©æ¥æ°´ï¼ŒèŠ³è‰æ— æƒ…ï¼Œæ›´åœ¨æ–œé˜³å¤–ã€‚<br>é»¯ä¹¡é­‚ï¼Œè¿½æ—…æ€ã€‚å¤œå¤œé™¤éï¼Œå¥½æ¢¦ç•™äººç¡ã€‚æ˜æœˆæ¥¼é«˜ä¼‘ç‹¬å€šï¼Œé…’å…¥æ„è‚ ï¼ŒåŒ–ä½œç›¸æ€æ³ªã€‚</p><p><a href="http://lib.xcz.im/work/57b8ee4a128fe10054c91757" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8ee4a128fe10054c91757</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡12</title>
      <link href="/2019/03/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8712/"/>
      <url>/2019/03/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8712/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS"><a href="#1ï¸âƒ£-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS" class="headerlink" title="1ï¸âƒ£[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]"></a>1ï¸âƒ£[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]</h2><p>Facebookç ”ç©¶äººå‘˜æå‡ºçš„ä¸¤ç§åŸºäºå·ç§¯çš„æ–¹æ³•å°è¯•æ›¿ä»£self-attentionåœ¨transformerä¸­çš„ä½œç”¨ï¼Œæ‹¥æœ‰æ›´å°‘çš„å‚æ•°ä»¥åŠæ›´å¿«çš„é€Ÿåº¦ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚</p><p><img src="/images/15521843619624.jpg" width="80%" height="80%"></p><h3 id="Lightweight-convolution"><a href="#Lightweight-convolution" class="headerlink" title="Lightweight convolution"></a>Lightweight convolution</h3><p>èƒŒæ™¯ï¼šdepthwise convolution<br>æ¯ä¸ªchannelç‹¬ç«‹è¿›è¡Œå·ç§¯ï¼Œæ³¨æ„åˆ°æ”¾åˆ°NLPä»»åŠ¡ä¸Šchannelæ˜¯æŒ‡embeddingçš„æ¯ä¸€ç»´ã€‚</p><script type="math/tex; mode=display">O_{i, c}=\text{DepthwiseConv}\left(X, W_{c, :}, i, c\right)=\sum_{j=1}^{k} W_{c, j} \cdot X_{\left(i+j-\left\lceil\frac{k+1}{2}\right]\right), c}</script><p>å› æ­¤Lightweight convolutionçš„è®¡ç®—æ–¹æ³•ä¸ºï¼š</p><script type="math/tex; mode=display">\operatorname{LightConv}\left(X, W_{\left\lceil\frac{c H}{d}\right\rceil,:}, i, c\right)=\text { DepthwiseConv}\left(X, \text{softmax}(W_{\left\lceil\frac{c H}{d}\right\rceil,:}), i, c\right)</script><p>æ¯ä¸€å±‚éƒ½æœ‰å›ºå®šçš„window sizeï¼Œè¿™å’Œself-attentionä¸åŒï¼Œself-attentionæ˜¯æ‰€æœ‰çš„contextéƒ½è¿›è¡Œäº¤äº’ã€‚</p><ul><li>Weight sharing æ³¨æ„åˆ°è¿™é‡Œè®²æ¯d/Hä¸ªchannelçš„å‚æ•°è¿›è¡Œç»‘å®šï¼Œè¿›ä¸€æ­¥å‡å°‘å‚æ•°ã€‚</li><li>Softmax-normalization å¯¹channelä¸€ç»´è¿›è¡Œsoftmaxï¼Œç›¸å½“äºå½’ä¸€åŒ–æ¯ä¸ªè¯çš„æ¯ä¸€ç»´çš„çš„é‡è¦æ€§ï¼ˆæ¯”self-attentionæ›´ç²¾ç»†ï¼‰ã€‚å®éªŒè¯æ˜ï¼Œå¦‚æœæ²¡æœ‰softmaxæ²¡åŠæ³•æ”¶æ•›ã€‚</li></ul><p>å› æ­¤æ€»ä½“çš„æ¶æ„ä¸ºï¼š<br>inputâ€”&gt;linear â€”&gt; GLU(gated linear unit) â€”&gt; lightconv/dynamicConv â€”&gt; linear</p><h3 id="Dynamic-convolution"><a href="#Dynamic-convolution" class="headerlink" title="Dynamic convolution"></a>Dynamic convolution</h3><p>ä¸lightweight convolutionç›¸ä¼¼ï¼Œä½†åŠ äº†ä¸€ä¸ªåŠ¨æ€çš„kernel sizeã€‚</p><script type="math/tex; mode=display">\text { DynamicConv}( X , i , c ) = \operatorname{LightConv}\left(X, f\left(X_{i}\right)_{h,:}, i, c\right)</script><p>è¿™é‡Œçš„kernel sizeç®€å•ä½¿ç”¨çº¿æ€§æ˜ å°„ï¼š$f : \mathbb { R } ^ { d } \rightarrow \mathbb { R } ^ { H \times k }$<br>å¦‚ï¼š$f\left(X_{i}\right)=\sum_{c=1}^{d} W_{h, j, c}^{Q} X_{i, c}$</p><hr><h2 id="2ï¸âƒ£-Joint-Embedding-of-Words-and-Labels-for-Text-Classiï¬cation"><a href="#2ï¸âƒ£-Joint-Embedding-of-Words-and-Labels-for-Text-Classiï¬cation" class="headerlink" title="2ï¸âƒ£[Joint Embedding of Words and Labels for Text Classiï¬cation]"></a>2ï¸âƒ£[Joint Embedding of Words and Labels for Text Classiï¬cation]</h2><p>æå‡ºä¸€ç§æœºåˆ¶å°†labelä½œä¸ºembeddingä¸è¯ä¸€åŒè®­ç»ƒï¼ŒåŒæ—¶å¼•å…¥labelå’Œwordçš„attentionæœºåˆ¶ï¼Œåœ¨åˆ†ç±»ä¸Šè·å¾—æ•ˆæœã€‚</p><p><img src="/images/15521854844061.jpg" width="40%" height="50%"></p><p>ä¸Šå›¾ä¸­ï¼ŒCæ˜¯label embeddingï¼Œç»´åº¦ä¸º$P\times K$ ; Væ˜¯å¥å­æ‰€æœ‰è¯çš„embeddingçŸ©é˜µï¼Œç»´åº¦ä¸º$P\times L$ã€‚<br>$\mathbf{G}$çš„è®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">\mathbf{G}=\left(\mathbf{C}^{\top} \mathbf{V}\right) \oslash \hat{\mathbf{G}}</script><p>$\oslash$è¡¨ç¤ºelement-wiseç›¸é™¤ã€‚$\hat{\mathbf{G}}$è¡¨ç¤ºl2 normï¼Œä¹Ÿå³ï¼š</p><script type="math/tex; mode=display">\hat{g}_{k l}=\left\|\boldsymbol{c}_{k}\right\|\left\|\boldsymbol{v}_{l}\right\|</script><p>å› æ­¤å…¬å¼çš„æœ¬è´¨å³åœ¨è®¡ç®—labelä¸æ¯ä¸ªè¯çš„cosè·ç¦»ã€‚</p><p>åœ¨è·å¾—äº†$\mathbf{G}$åï¼Œä¸ºäº†è·å¾—æ›´é«˜çš„çš„è¡¨ç¤ºï¼Œå¦‚phraseï¼Œå°†ä¸€ä¸ªä¸€ä¸ªblockå–å‡ºï¼Œå¹¶è¿‡çº¿æ€§å±‚ï¼š</p><script type="math/tex; mode=display">\boldsymbol{u}_{l}=\operatorname{ReLU}\left(\mathbf{G}_{l-r : l+r} \mathbf{W}_{1}+\boldsymbol{b}_{1}\right)</script><p>æ¥ç€å¯¹æ¯ä¸ª$\boldsymbol{u}_{l}$å–æœ€å¤§å€¼ï¼š</p><script type="math/tex; mode=display">m_{l}=\textbf{max-pooling}\left(\boldsymbol{u}_{l}\right)</script><p>æ­¤æ—¶çš„$\mathbf{m}$æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºLçš„å‘é‡ã€‚æœ€ç»ˆå¯¹måšsoftmaxè·å¾—ä¸€ä¸ªåˆ†æ•°çš„åˆ†å¸ƒï¼š</p><script type="math/tex; mode=display">\boldsymbol{\beta}=\operatorname{SoftMax}(\boldsymbol{m})</script><p>å°†è¯¥åˆ†æ•°å’Œæ¯ä¸ªè¯åšåŠ æƒæ±‚å’Œï¼Œè·å¾—æœ€ç»ˆçš„å‘é‡è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">\boldsymbol{z}=\sum_{l} \beta_{l} \boldsymbol{v}_{l}</script><p>æ€è€ƒï¼šå°†labelä¸embeddingæ”¾åœ¨ä¸€èµ·è®­ç»ƒè¿™ä¸ªæ€è·¯ä¸é”™ã€‚ä½†æ•´åˆçš„æ–¹å¼æ˜¯å¦è¿‡äºç®€å•ç²—æš´äº†<br>ï¼Ÿç‰¹åˆ«æ˜¯phraseçš„æå–å’Œéšåçš„max-poolingçš„å¯è§£é‡Šæ€§å¹¶ä¸å¼ºçš„æ ·å­ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> Convolution </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> embedding </tag>
            
            <tag> text classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†18</title>
      <link href="/2019/03/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8618/"/>
      <url>/2019/03/10/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8618/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Depthwise-seperable-convolution"><a href="#1ï¸âƒ£-Depthwise-seperable-convolution" class="headerlink" title="1ï¸âƒ£[Depthwise seperable convolution]"></a>1ï¸âƒ£[Depthwise seperable convolution]</h3><p>Depthwise seperable convolution = depthwise + pointwise<br>å…ˆæ¯ä¸ªå·ç§¯æ ¸ç‹¬ç«‹å¯¹ä¸€ä¸ªfeature mapè¿›è¡Œå·ç§¯ï¼Œå†é€šè¿‡ä¸€ä¸ª$1\times 1 \times n$çš„å·ç§¯æ ¸å¯¹feature mapè¿›è¡Œæ•´åˆã€‚</p><p><a href="https://blog.csdn.net/tintinetmilou/article/details/81607721" target="_blank" rel="noopener">https://blog.csdn.net/tintinetmilou/article/details/81607721</a></p><hr><h3 id="2ï¸âƒ£-å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr"><a href="#2ï¸âƒ£-å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr" class="headerlink" title="2ï¸âƒ£[å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr]"></a>2ï¸âƒ£[å¦‚ä½•å¯»æ‰¾è¾ƒå¥½çš„lr]</h3><p>ä¸€ç§å¯å‘å¼çš„æ–¹æ³•ï¼š</p><blockquote><p>Over an epoch begin your SGD with a very low learning rate (like 10âˆ’8) but change it (by multiplying it by a certain factor for instance) at each mini-batch until it reaches a very high value (like 1 or 10). Record the loss each time at each iteration and once youâ€™re finished, plot those losses against the learning rate.</p></blockquote><p><a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html" target="_blank" rel="noopener">https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Convolution </tag>
            
            <tag> learning rate </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯18</title>
      <link href="/2019/03/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D18/"/>
      <url>/2019/03/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D18/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è¥¿æ±Ÿæœˆ-Â·-é£å…´"><a href="#1ï¸âƒ£è¥¿æ±Ÿæœˆ-Â·-é£å…´" class="headerlink" title="1ï¸âƒ£è¥¿æ±Ÿæœˆ Â· é£å…´"></a>1ï¸âƒ£è¥¿æ±Ÿæœˆ Â· é£å…´</h3><p>[å®‹] è¾›å¼ƒç–¾<br>é†‰é‡Œä¸”è´ªæ¬¢ç¬‘ï¼Œè¦æ„é‚£å¾—å·¥å¤«ã€‚è¿‘æ¥å§‹è§‰å¤äººä¹¦ï¼Œä¿¡è‘—å…¨æ— æ˜¯å¤„ã€‚<br>æ˜¨å¤œæ¾è¾¹é†‰å€’ï¼Œé—®æ¾ã€Œæˆ‘é†‰ä½•å¦‚ã€ã€‚åªç–‘æ¾åŠ¨è¦æ¥æ‰¶ï¼Œä»¥æ‰‹æ¨æ¾æ›°ã€Œå»ã€ï¼</p><p><a href="http://lib.xcz.im/work/57b935bcd342d3005ac8e63f" target="_blank" rel="noopener">http://lib.xcz.im/work/57b935bcd342d3005ac8e63f</a></p><hr><h3 id="2ï¸âƒ£è¶æ‹èŠ±"><a href="#2ï¸âƒ£è¶æ‹èŠ±" class="headerlink" title="2ï¸âƒ£è¶æ‹èŠ±"></a>2ï¸âƒ£è¶æ‹èŠ±</h3><p>[å®‹] æ™æ®Š<br>æ§›èŠæ„çƒŸå…°æ³£éœ²ï¼Œç½—å¹•è½»å¯’ï¼Œç‡•å­åŒé£å»ã€‚æ˜æœˆä¸è°™ç¦»æ¨è‹¦ï¼Œæ–œå…‰åˆ°æ™“ç©¿æœ±æˆ·ã€‚<br>æ˜¨å¤œè¥¿é£å‡‹ç¢§æ ‘ï¼Œç‹¬ä¸Šé«˜æ¥¼ï¼Œæœ›å°½å¤©æ¶¯è·¯ã€‚æ¬²å¯„å½©ç¬ºå…¼å°ºç´ ï¼Œå±±é•¿æ°´é˜”çŸ¥ä½•å¤„ï¼Ÿ</p><p><a href="http://lib.xcz.im/work/57b318dd1532bc00618ffaff" target="_blank" rel="noopener">http://lib.xcz.im/work/57b318dd1532bc00618ffaff</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¦‚ä½•ä½¿ç”¨fairseqå¤ç°Transformer NMT</title>
      <link href="/2019/01/28/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8fairseq%E5%A4%8D%E7%8E%B0Transformer%20NMT/"/>
      <url>/2019/01/28/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8fairseq%E5%A4%8D%E7%8E%B0Transformer%20NMT/</url>
      
        <content type="html"><![CDATA[<p>åŸºäºTransformerçš„NMTè™½ç„¶ç»“æœå¥½ï¼Œä½†è¶…å‚éå¸¸éš¾è°ƒï¼Œåªè¦æœ‰ä¸€ä¸¤ä¸ªå‚æ•°å’Œè®ºæ–‡ä¸ä¸€æ ·ï¼Œå°±æœ‰å¯èƒ½å¾—åˆ°å’Œè®ºæ–‡ç›¸å»ç”šè¿œçš„ç»“æœã€‚fairseqæ˜¯ç°æœ‰æ¯”è¾ƒå®Œå–„çš„seq2seqåº“ï¼Œç”±äºæ˜¯å¤§å…¬å¸å‡ºå“ï¼Œå› æ­¤ä¹Ÿå†™å¾—è¾ƒä¸ºå®Œå–„ï¼Œä¸è®ºæ˜¯ä»£ç è¿˜æ˜¯æ–‡æ¡£ã€‚</p><p>æœ¬æ–‡è®¨è®ºå¦‚ä½•ä½¿ç”¨fairseqå¤ç°åŸºäºTransformerçš„ç¿»è¯‘ä»»åŠ¡ï¼Œä¹Ÿå³å¤ç°Vaswani, et al. çš„è®ºæ–‡ç»“æœã€‚æœ¬æ–‡å°½é‡ä¸è®¨è®ºå®ç°ç»†èŠ‚ï¼Œåªè®¨è®ºå¦‚ä½•å¤ç°å‡ºç»“æœã€‚</p><p>fairseqé¡¹ç›®åœ°å€ï¼š<a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">https://github.com/pytorch/fairseq</a></p><h2 id="ä½¿ç”¨æ•™ç¨‹"><a href="#ä½¿ç”¨æ•™ç¨‹" class="headerlink" title="ä½¿ç”¨æ•™ç¨‹"></a>ä½¿ç”¨æ•™ç¨‹</h2><p>åœ¨è¿™é‡Œæˆ‘ä»¬å‚è€ƒçš„æ˜¯18å¹´çš„æ–‡ç« <a href="https://arxiv.org/abs/1806.00187" target="_blank" rel="noopener">Scaling Neural Machine Translation</a>ï¼ŒåŒæ ·æ˜¯åŸºäºTransformerçš„NMTã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨WMT16 EN-DEè€Œä¸æ˜¯Vaswani, et al.è®ºæ–‡ä¸­çš„WMT14 EN-DEã€‚äºŒè€…åªåœ¨ä¸€ä¸ªæ–‡ä»¶ï¼ˆcommoncrawlï¼‰ä¸Šæœ‰åŒºåˆ«ï¼Œå…¶ä»–æ˜¯ä¸€æ ·çš„ï¼Œç”±äºWMT16 EN-DEæœ‰é¢„å¤„ç†å¥½çš„æ•°æ®ï¼Œä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å°±ä½¿ç”¨è¯¥ä»½æ•°æ®ï¼ˆä¸‹æ–‡ä¹Ÿæœ‰é¢„å¤„ç†WMT14æ•°æ®çš„æ–¹æ³•ï¼‰</p><h3 id="å‡†å¤‡å·¥ä½œ"><a href="#å‡†å¤‡å·¥ä½œ" class="headerlink" title="å‡†å¤‡å·¥ä½œ"></a>å‡†å¤‡å·¥ä½œ</h3><ol><li>å®‰è£…fairseqï¼Œåœ¨Readmeå†…æœ‰</li><li>é˜…è¯»Readmeï¼ˆoptionalï¼‰</li><li>é˜…è¯»docï¼ˆoptionalï¼‰</li></ol><h3 id="æ•°æ®é¢„å¤„ç†"><a href="#æ•°æ®é¢„å¤„ç†" class="headerlink" title="æ•°æ®é¢„å¤„ç†"></a>æ•°æ®é¢„å¤„ç†</h3><h4 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h4><p>æ•°æ®é¢„å¤„ç†ä¸»è¦æ˜¯ä¸‹è½½å¤šä¸ªæ–‡ä»¶å¹¶åˆå¹¶â€”&gt;æ¸…ç†/tokenizeæ•°æ®â€”&gt;å°†æ•°æ®åˆ†ä¸ºtrainã€validâ€”&gt;bpe(bype pair encoding)ã€‚fairseqæä¾›äº†ä¸€æ•´å¥—å¤„ç†æµç¨‹çš„è„šæœ¬ï¼Œåœ¨examples/translation/prepare-wmt14en2de.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Adapted from https://github.com/facebookresearch/MIXER/blob/master/prepareData.sh</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Moses github repository (for tokenization scripts)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/moses-smt/mosesdecoder.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'Cloning Subword NMT repository (for BPE pre-processing)...'</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/rsennrich/subword-nmt.git</span><br><span class="line"></span><br><span class="line">SCRIPTS=mosesdecoder/scripts</span><br><span class="line">TOKENIZER=<span class="variable">$SCRIPTS</span>/tokenizer/tokenizer.perl</span><br><span class="line">CLEAN=<span class="variable">$SCRIPTS</span>/training/clean-corpus-n.perl</span><br><span class="line">NORM_PUNC=<span class="variable">$SCRIPTS</span>/tokenizer/normalize-punctuation.perl</span><br><span class="line">REM_NON_PRINT_CHAR=<span class="variable">$SCRIPTS</span>/tokenizer/remove-non-printing-char.perl</span><br><span class="line">BPEROOT=subword-nmt</span><br><span class="line">BPE_TOKENS=40000</span><br><span class="line"></span><br><span class="line">URLS=(</span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt13/training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"http://data.statmt.org/wmt17/translation-task/dev.tgz"</span></span><br><span class="line">    <span class="string">"http://statmt.org/wmt14/test-full.tgz"</span></span><br><span class="line">)</span><br><span class="line">FILES=(</span><br><span class="line">    <span class="string">"training-parallel-europarl-v7.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-commoncrawl.tgz"</span></span><br><span class="line">    <span class="string">"training-parallel-nc-v12.tgz"</span></span><br><span class="line">    <span class="string">"dev.tgz"</span></span><br><span class="line">    <span class="string">"test-full.tgz"</span></span><br><span class="line">)</span><br><span class="line">CORPORA=(</span><br><span class="line">    <span class="string">"training/europarl-v7.de-en"</span></span><br><span class="line">    <span class="string">"commoncrawl.de-en"</span></span><br><span class="line">    <span class="string">"training/news-commentary-v12.de-en"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will make the dataset compatible to the one used in "Convolutional Sequence to Sequence Learning"</span></span><br><span class="line"><span class="comment"># https://arxiv.org/abs/1705.03122</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> == <span class="string">"--icml17"</span> ]; <span class="keyword">then</span></span><br><span class="line">    URLS[2]=<span class="string">"http://statmt.org/wmt14/training-parallel-nc-v9.tgz"</span></span><br><span class="line">    FILES[2]=<span class="string">"training-parallel-nc-v9.tgz"</span></span><br><span class="line">    CORPORA[2]=<span class="string">"training/news-commentary-v9.de-en"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">"<span class="variable">$SCRIPTS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Please set SCRIPTS variable correctly to point to Moses scripts."</span></span><br><span class="line">    <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">src=en</span><br><span class="line">tgt=de</span><br><span class="line">lang=en-de</span><br><span class="line">prep=wmt14_en_de</span><br><span class="line">tmp=<span class="variable">$prep</span>/tmp</span><br><span class="line">orig=orig</span><br><span class="line">dev=dev/newstest2013</span><br><span class="line"></span><br><span class="line">mkdir -p <span class="variable">$orig</span> <span class="variable">$tmp</span> <span class="variable">$prep</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$orig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;<span class="variable">$&#123;#URLS[@]&#125;</span>;++i)); <span class="keyword">do</span></span><br><span class="line">    file=<span class="variable">$&#123;FILES[i]&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$file</span> already exists, skipping download"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        url=<span class="variable">$&#123;URLS[i]&#125;</span></span><br><span class="line">        wget <span class="string">"<span class="variable">$url</span>"</span></span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="variable">$file</span> ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> successfully downloaded."</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">"<span class="variable">$url</span> not successfully downloaded."</span></span><br><span class="line">            <span class="built_in">exit</span> -1</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">if</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tgz"</span> ]; <span class="keyword">then</span></span><br><span class="line">            tar zxvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">elif</span> [ <span class="variable">$&#123;file: -4&#125;</span> == <span class="string">".tar"</span> ]; <span class="keyword">then</span></span><br><span class="line">            tar xvf <span class="variable">$file</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing train data..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    rm <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;CORPORA[@]&#125;</span>"</span>; <span class="keyword">do</span></span><br><span class="line">        cat <span class="variable">$orig</span>/<span class="variable">$f</span>.<span class="variable">$l</span> | \</span><br><span class="line">            perl <span class="variable">$NORM_PUNC</span> <span class="variable">$l</span> | \</span><br><span class="line">            perl <span class="variable">$REM_NON_PRINT_CHAR</span> | \</span><br><span class="line">            perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt;&gt; <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pre-processing test data..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$l</span>"</span> == <span class="string">"<span class="variable">$src</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        t=<span class="string">"src"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        t=<span class="string">"ref"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    grep <span class="string">'&lt;seg id'</span> <span class="variable">$orig</span>/<span class="built_in">test</span>-full/newstest2014-deen-<span class="variable">$t</span>.<span class="variable">$l</span>.sgm | \</span><br><span class="line">        sed -e <span class="string">'s/&lt;seg id="[0-9]*"&gt;\s*//g'</span> | \</span><br><span class="line">        sed -e <span class="string">'s/\s*&lt;\/seg&gt;\s*//g'</span> | \</span><br><span class="line">        sed -e <span class="string">"s/\â€™/\'/g"</span> | \</span><br><span class="line">    perl <span class="variable">$TOKENIZER</span> -threads 8 -a -l <span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/<span class="built_in">test</span>.<span class="variable">$l</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">""</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"splitting train and valid..."</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 == 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/valid.<span class="variable">$l</span></span><br><span class="line">    awk <span class="string">'&#123;if (NR%100 != 0)  print $0; &#125;'</span> <span class="variable">$tmp</span>/train.tags.<span class="variable">$lang</span>.tok.<span class="variable">$l</span> &gt; <span class="variable">$tmp</span>/train.<span class="variable">$l</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">TRAIN=<span class="variable">$tmp</span>/train.de-en</span><br><span class="line">BPE_CODE=<span class="variable">$prep</span>/code</span><br><span class="line">rm -f <span class="variable">$TRAIN</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    cat <span class="variable">$tmp</span>/train.<span class="variable">$l</span> &gt;&gt; <span class="variable">$TRAIN</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"learn_bpe.py on <span class="variable">$&#123;TRAIN&#125;</span>..."</span></span><br><span class="line">python <span class="variable">$BPEROOT</span>/learn_bpe.py -s <span class="variable">$BPE_TOKENS</span> &lt; <span class="variable">$TRAIN</span> &gt; <span class="variable">$BPE_CODE</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> train.<span class="variable">$L</span> valid.<span class="variable">$L</span> <span class="built_in">test</span>.<span class="variable">$L</span>; <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"apply_bpe.py to <span class="variable">$&#123;f&#125;</span>..."</span></span><br><span class="line">        python <span class="variable">$BPEROOT</span>/apply_bpe.py -c <span class="variable">$BPE_CODE</span> &lt; <span class="variable">$tmp</span>/<span class="variable">$f</span> &gt; <span class="variable">$tmp</span>/bpe.<span class="variable">$f</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.train <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/train 1 250</span><br><span class="line">perl <span class="variable">$CLEAN</span> -ratio 1.5 <span class="variable">$tmp</span>/bpe.valid <span class="variable">$src</span> <span class="variable">$tgt</span> <span class="variable">$prep</span>/valid 1 250</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> L <span class="keyword">in</span> <span class="variable">$src</span> <span class="variable">$tgt</span>; <span class="keyword">do</span></span><br><span class="line">    cp <span class="variable">$tmp</span>/bpe.test.<span class="variable">$L</span> <span class="variable">$prep</span>/<span class="built_in">test</span>.<span class="variable">$L</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>å¦‚æœå¸Œæœ›ä½¿ç”¨é¢„å¤„ç†å¥½çš„æ•°æ®ï¼Œåˆ™å¯ä»¥ä½¿ç”¨WMT16 EN-DEï¼Œåœ°å€ä¸ºï¼š<a href="https://drive.google.com/uc?export=download&amp;id=0B_bZck-ksdkpM25jRUN2X2UxMm8" target="_blank" rel="noopener">https://drive.google.com/uc?export=download&amp;id=0B_bZck-ksdkpM25jRUN2X2UxMm8</a><br>å¹¶è§£å‹ã€‚</p><h4 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h4><p>æ¥ä¸‹æ¥å¯¹æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–(binarize):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">TEXT=wmt16_en_de_bpe32k</span><br><span class="line">mkdir <span class="variable">$TEXT</span></span><br><span class="line">tar -xzvf wmt16_en_de.tar.gz -C <span class="variable">$TEXT</span>  <span class="comment"># è§£å‹æ–‡ä»¶</span></span><br><span class="line">python preprocess.py --<span class="built_in">source</span>-lang en --target-lang de \</span><br><span class="line">  --trainpref <span class="variable">$TEXT</span>/train.tok.clean.bpe.32000 \</span><br><span class="line">  --validpref <span class="variable">$TEXT</span>/newstest2013.tok.bpe.32000 \</span><br><span class="line">  --testpref <span class="variable">$TEXT</span>/newstest2014.tok.bpe.32000 \</span><br><span class="line">  --destdir data-bin/wmt16_en_de_bpe32k \</span><br><span class="line">  --nwordssrc 32768 --nwordstgt 32768 \</span><br><span class="line">  --joined-dictionary</span><br></pre></td></tr></table></figure><p>åˆ°è¿™é‡Œï¼Œéº»çƒ¦çš„é¢„å¤„ç†å°±ç»“æŸäº†ã€‚</p><h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><p>cdåˆ°fairseqç›®å½•ä¸‹ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  python -m torch.distributed.launch --nproc_per_node 8 train.py data-bin/wmt16_en_de_bpe32k \        --arch transformer_wmt_en_de --share-all-embeddings \          --optimizer adam --adam-betas <span class="string">'(0.9, 0.98)'</span> --clip-norm 0.0 \            --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000 \              --lr 0.0007 --min-lr 1e-09 \             --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --weight-decay 0.0\              --max-tokens  4096   --save-dir checkpoints/en-de-base\               --no-progress-bar --<span class="built_in">log</span>-format json --<span class="built_in">log</span>-interval 50\             --save-interval-updates  1000 --keep-interval-updates 20</span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°è¯¥è®¾ç½®ä¸åŸè®ºæ–‡ä¸å¤§ä¸€è‡´ã€‚ä½†å·²è¯å®è¯¥è®¾ç½®å¯ä»¥å¤ç°è®ºæ–‡ç»“æœã€‚</p><p>å¦‚æœæ²¡æœ‰è¿™ä¹ˆå¤šå¡ï¼Œé‚£ä¹ˆå¯ä»¥è®¾ç½®<code>update freq</code>ä»¥æ¨¡æ‹Ÿ8å¡è¡Œä¸ºã€‚å¦‚ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3  python -m torch.distributed.launch --nproc_per_node 4 \</span><br><span class="line">train.py data-bin/wmt16_en_de_bpe32k    \</span><br><span class="line"> --arch transformer_wmt_en_de --share-all-embeddings \</span><br><span class="line">--optimizer adam --adam-betas <span class="string">'(0.9, 0.98)'</span> \</span><br><span class="line">--clip-norm 0.0   --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000  \</span><br><span class="line">--lr 0.0007 --min-lr 1e-09 --criterion label_smoothed_cross_entropy \</span><br><span class="line">--label-smoothing 0.1 --weight-decay 0.0 --max-tokens  4096   \</span><br><span class="line">--save-dir checkpoints/en-de-16-base   \ </span><br><span class="line">--no-progress-bar --<span class="built_in">log</span>-format json --<span class="built_in">log</span>-interval 50 --save-interval-updates  1000 \</span><br><span class="line">--keep-interval-updates 20  --update-freq 2 |tee exp2.log</span><br></pre></td></tr></table></figure><p>4å¼ å¡åˆ™è®¾<code>update freq=2</code>ï¼Œ2å¼ å¡åˆ™è®¾<code>update freq=4</code>ï¼Œä»¥æ­¤ç±»æ¨ã€‚</p><p>å¤§æ¦‚åœ¨100ä¸ªepochå†…èƒ½å¤Ÿæ”¶æ•›(å®é™…ä¸Šåº”è¯¥åœ¨150-200ä¸ªepochæ”¶æ•›ï¼Œ100epochçš„BLEUæ˜¯27.3ï¼Œ150-200epochçš„ç»“æœæ˜¯27.67)ï¼Œä¹Ÿå³åœ¨475000ä¸ªstepã€‚8å¼ 1080Tiåœ¨å¤§æ¦‚ä¸¤å¤©èƒ½å¤Ÿè®­ç»ƒå®Œæˆï¼Œ4å¼ 1080Tiå¤§æ¦‚4å¤©è®­ç»ƒå®Œæˆã€‚</p><p>å¼€å§‹è®­ç»ƒâ€¦<br><img src="/images/15491934129135.jpg" width="80%" height="50%"></p><p>æœ€ååˆ™ä¼šè·å¾—checkpointï¼š<br><img src="/images/15491934935157.jpg" width="80%" height="50%"></p><h3 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h3><p>æµ‹è¯•åˆ†ä¸ºå‡ ä¸ªé˜¶æ®µï¼šé¦–å…ˆå°†å‡ ä¸ªcheckpointè¿›è¡Œå¹³å‡ï¼Œå®éªŒè¡¨æ˜ï¼Œè¿›è¡Œå¹³å‡èƒ½å¤Ÿæœ‰ä¸€å®šçš„æå‡ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨å¹³å‡åçš„æ¨¡å‹å¯¹testé›†çš„å¥å­è¿›è¡Œç¿»è¯‘ï¼›æœ€ç»ˆå°†ç”Ÿæˆçš„å¥å­å’Œæ­£ç¡®çš„å¥å­è®¡ç®—bleuå€¼ã€‚</p><h4 id="average-checkpoint"><a href="#average-checkpoint" class="headerlink" title="average checkpoint"></a>average checkpoint</h4><p>åœ¨æµ‹è¯•é˜¶æ®µï¼Œè®ºæ–‡åœ¨Transformer-baseä¸­å¯¹æœ€åäº”ä¸ªcheckpointè¿›è¡Œå¹³å‡ï¼Œä¹Ÿå³å¯¹æƒå€¼è¿›è¡Œå¹³å‡ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python scripts/average_checkpoints.py \</span><br><span class="line">--inputs checkpoints/en-de-base/ \</span><br><span class="line">--num-epoch-checkpoints  5 --output averaged_model.pt</span><br></pre></td></tr></table></figure><p>æœ€ç»ˆè·å¾—averaged_model.ptï¼Œæˆ‘ä»¬å°†ç”¨è¯¥æ–‡ä»¶è¿›è¡Œæµ‹è¯•ã€‚</p><h4 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h4><p>æˆ‘ä»¬é‡‡ç”¨å’Œè®ºæ–‡ä¸€è‡´çš„è¶…å‚ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 python generate.py \</span><br><span class="line">data-bin/wmt16_en_de_bpe32k/ --path /some_checkpoint \</span><br><span class="line">--remove-bpe --beam 4 --batch-size 64 --lenpen 0.6 \</span><br><span class="line">--max-len<span class="_">-a</span> 1 --max-len-b 50|tee generate.out</span><br></pre></td></tr></table></figure><p>å…¶ä¸­lenpenæ˜¯ç”Ÿæˆå¥å­çš„é•¿åº¦æƒ©ç½šç³»æ•°ï¼›<code>max-len-a</code>å’Œ<code>max-len-b</code>æŒ‡çš„æ˜¯æ¯ä¸ªå¥å­çš„æœ€é•¿é•¿åº¦é™åˆ¶ï¼Œä¹Ÿå³ï¼šå‡è®¾æºå¥å­é•¿åº¦ä¸ºxï¼Œåˆ™ç›®æ ‡å¥å­çš„é•¿åº¦åº”å°äºax+b ã€‚</p><p>æœ€ç»ˆæˆ‘ä»¬ç¿»è¯‘å¥½çš„å¥å­ä»¥åŠç›¸å¯¹åº”çš„è¯¦ç»†ä¿¡æ¯éƒ½åœ¨generate.outé‡Œé¢ã€‚æˆ‘ä»¬éœ€è¦æå–æºè¯­è¨€å¥å­å’Œç›®æ ‡è¯­è¨€å¥å­ï¼Œä»¥æ–¹ä¾¿åé¢çš„è®¡ç®—ã€‚å› æ­¤ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep ^T generate.out | cut -f2- | perl -ple <span class="string">'s&#123;(\S)-(\S)&#125;&#123;$1 ##AT##-##AT## $2&#125;g'</span> &gt; generate.ref</span><br><span class="line"></span><br><span class="line">grep ^H generate.out |cut -f3- | perl -ple <span class="string">'s&#123;(\S)-(\S)&#125;&#123;$1 ##AT##-##AT## $2&#125;g'</span> &gt; generate.sys</span><br></pre></td></tr></table></figure><p>åˆ†åˆ«è¿è¡Œè¿™ä¸¤ä¸ªbashå‘½ä»¤ï¼Œæˆ‘ä»¬åˆ™è·å¾—äº†generate.refå’Œgenerate.sysï¼Œåˆ†åˆ«æ˜¯ç›®æ ‡å’Œæºè¯­è¨€çš„å¥å­ã€‚</p><p>æ³¨æ„åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„å°trickï¼Œä¹Ÿå³<strong>split compound</strong>ã€‚å› ä¸ºä¸€äº›å†å²åŸå› ï¼ˆæˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºå•¥ï¼Œtensor2tensoré‡Œé¢çš„è„šæœ¬æœ‰æåˆ°ï¼‰ï¼Œè¯¥trickå·²ç»åœ¨ä¸Šé¢çš„è„šæœ¬å‘½ä»¤ä½“ç°å‡ºæ¥äº†ã€‚å®è·µè¯æ˜ï¼Œä½¿ç”¨è¯¥trickèƒ½å¤Ÿæé«˜bleuå€¼ 0.5ä¸ªç‚¹ä»¥ä¸Šã€‚</p><h4 id="score"><a href="#score" class="headerlink" title="score"></a>score</h4><p>æˆ‘ä»¬æ­¤æ—¶å°±å¯ä»¥è®¡ç®—bleuå€¼äº†ï¼Œfairseqæä¾›äº†è¯¥è„šæœ¬ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python score.py --sys generate.sys --ref generate.ref</span><br></pre></td></tr></table></figure><p>å¤§åŠŸå‘Šæˆï¼æˆ‘ä»¬ç»ˆäºå¤ç°å‡ºç»“æœäº†ã€‚<br>ä½œä¸ºå‚è€ƒï¼šæ ¹æ®æˆ‘çš„å®éªŒï¼Œåªä½¿ç”¨checkpointä¸­æœ€å¥½çš„ä¸€ä¸ªcheckpointï¼Œåœ¨ç»è¿‡äº†ä¸Šè¿°çš„æµç¨‹åï¼Œå¯ä»¥å¾—åˆ°27.30çš„ç»“æœã€‚</p><h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><p>æ ¹æ®æˆ‘çš„éœ€æ±‚ï¼Œæˆ‘è¿˜éœ€è¦è¯¦ç»†è®°å½•ä¸­é—´ç»“æœï¼Œå¹¶æ‰“å°åœ¨tensorboardä¸Šæ–¹ä¾¿å¯è§†åŒ–ï¼Œå¦‚ï¼š<br><img src="/images/15491946401169.jpg" width="90%" height="50%"></p><p>fairseqå¹¶æ²¡æœ‰æä¾›è¿™ç§åŠŸèƒ½ï¼Œå› æ­¤éœ€è¦è‡ªå·±ä¿®æ”¹éƒ¨åˆ†æºä»£ç ã€‚<br>åªéœ€è¦ä¿®æ”¹train.pyæºæ–‡ä»¶å³å¯ã€‚</p><p>â‘ åœ¨å¼€å¤´åŠ summary writer<br><img src="/images/15492019614168.jpg" width="70%" height="50%"></p><p>æ³¨æ„åˆ°æ¯æ¬¡å®éªŒéƒ½éœ€è¦ä¿®æ”¹å®éªŒçš„åå­—ã€‚</p><p>â‘¡ä¿®æ”¹trainå‡½æ•°<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492020396304.jpg" width="70%" height="50%"></p><p>åœ¨epochç»“æŸï¼Œæ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492021296611.jpg" width="70%" height="50%"></p><p>å¯¹validateçš„ä½¿ç”¨è¿›è¡Œä¿®æ”¹ï¼ˆæ·»åŠ äº†is_epochï¼‰ï¼š<br><img src="/images/15492022604000.jpg" width="70%" height="50%"></p><p>trainå‡½æ•°å…¨éƒ¨ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(args, trainer, task, epoch_itr)</span>:</span></span><br><span class="line">    <span class="string">"""Train the model for one epoch."""</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update parameters every N batches</span></span><br><span class="line">    <span class="keyword">if</span> epoch_itr.epoch &lt;= len(args.update_freq):</span><br><span class="line">        update_freq = args.update_freq[epoch_itr.epoch - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        update_freq = args.update_freq[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize data iterator</span></span><br><span class="line">    itr = epoch_itr.next_epoch_itr(fix_batches_to_gpus=args.fix_batches_to_gpus)</span><br><span class="line">    itr = iterators.GroupedIterator(itr, update_freq)</span><br><span class="line">    progress = progress_bar.build_progress_bar(</span><br><span class="line">        args, itr, epoch_itr.epoch, no_progress_bar=<span class="string">'simple'</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    extra_meters = collections.defaultdict(<span class="keyword">lambda</span>: AverageMeter())</span><br><span class="line">    first_valid = args.valid_subset.split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">    max_update = args.max_update <span class="keyword">or</span> math.inf</span><br><span class="line">    <span class="keyword">for</span> i, samples <span class="keyword">in</span> enumerate(progress, start=epoch_itr.iterations_in_epoch):</span><br><span class="line">        log_output = trainer.train_step(samples)</span><br><span class="line">        <span class="keyword">if</span> log_output <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># log mid-epoch stats</span></span><br><span class="line">        stats = get_training_stats(trainer)</span><br><span class="line">        num_updates = stats[<span class="string">'num_updates'</span>]</span><br><span class="line">        <span class="comment"># print(type(num_updates))</span></span><br><span class="line">        <span class="comment"># print(type(stats['loss']))</span></span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_loss_update'</span>, float(stats[<span class="string">'loss'</span>]), num_updates)</span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_nll_loss_update'</span>, float(stats[<span class="string">'nll_loss'</span>]), num_updates)</span><br><span class="line">        summary_writer.add_scalar(<span class="string">'Training/training_ppl_update'</span>, float(stats[<span class="string">'ppl'</span>]), num_updates)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ------record training metrics --- #</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> log_output.items():</span><br><span class="line">            <span class="keyword">if</span> k <span class="keyword">in</span> [<span class="string">'loss'</span>, <span class="string">'nll_loss'</span>, <span class="string">'ntokens'</span>, <span class="string">'nsentences'</span>, <span class="string">'sample_size'</span>]:</span><br><span class="line">                <span class="keyword">continue</span>  <span class="comment"># these are already logged above</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'loss'</span> <span class="keyword">in</span> k:</span><br><span class="line">                extra_meters[k].update(v, log_output[<span class="string">'sample_size'</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                extra_meters[k].update(v)</span><br><span class="line">            stats[k] = extra_meters[k].avg</span><br><span class="line">        progress.log(stats)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ignore the first mini-batch in words-per-second calculation</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            trainer.get_meter(<span class="string">'wps'</span>).reset()</span><br><span class="line"></span><br><span class="line">        num_updates = trainer.get_num_updates()</span><br><span class="line">        <span class="keyword">if</span> args.save_interval_updates &gt; <span class="number">0</span> <span class="keyword">and</span> num_updates % args.save_interval_updates == <span class="number">0</span> <span class="keyword">and</span> num_updates &gt; <span class="number">0</span>:</span><br><span class="line">            valid_losses = validate(args, trainer, task, epoch_itr, [first_valid], is_epoch=<span class="keyword">False</span>)</span><br><span class="line">            save_checkpoint(args, trainer, epoch_itr, valid_losses[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_updates &gt;= max_update:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># log end-of-epoch stats</span></span><br><span class="line">    stats = get_training_stats(trainer)</span><br><span class="line">    <span class="comment"># ------record training metrics --- #</span></span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_loss_epoch'</span>, float(stats[<span class="string">'loss'</span>]), epoch_itr.epoch)</span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_nll_loss_epoch'</span>, float(stats[<span class="string">'nll_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">    summary_writer.add_scalar(<span class="string">'Training/training_ppl_epoch'</span>, float(stats[<span class="string">'ppl'</span>]), epoch_itr.epoch)</span><br><span class="line">    <span class="keyword">for</span> k, meter <span class="keyword">in</span> extra_meters.items():</span><br><span class="line">        stats[k] = meter.avg</span><br><span class="line">    progress.print(stats)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reset training meters</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [</span><br><span class="line">        <span class="string">'train_loss'</span>, <span class="string">'train_nll_loss'</span>, <span class="string">'wps'</span>, <span class="string">'ups'</span>, <span class="string">'wpb'</span>, <span class="string">'bsz'</span>, <span class="string">'gnorm'</span>, <span class="string">'clip'</span>,</span><br><span class="line">    ]:</span><br><span class="line">        meter = trainer.get_meter(k)</span><br><span class="line">        <span class="keyword">if</span> meter <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            meter.reset()</span><br></pre></td></tr></table></figure><p>â‘¢ä¿®æ”¹validateå‡½æ•°<br>æ·»åŠ äº†ä¸€ä¸ªå‚æ•°<code>is_epoch</code>ï¼š<br><img src="/images/15492023879130.jpg" width="50%" height="50%"></p><p>æ·»åŠ è®°å½•çš„ä»£ç ï¼š<br><img src="/images/15492024686078.jpg" width="90%" height="50%"></p><p>validateå…¨éƒ¨ä»£ç ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">def validate(args, trainer, task, epoch_itr, subsets, is_epoch=True):</span><br><span class="line">    <span class="string">""</span><span class="string">"Evaluate the model on the validation set(s) and return the losses."</span><span class="string">""</span></span><br><span class="line">    valid_losses = []</span><br><span class="line">    <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">        <span class="comment"># Initialize data iterator</span></span><br><span class="line">        itr = task.get_batch_iterator(</span><br><span class="line">            dataset=task.dataset(subset),</span><br><span class="line">            max_tokens=args.max_tokens,</span><br><span class="line">            max_sentences=args.max_sentences_valid,</span><br><span class="line">            max_positions=utils.resolve_max_positions(</span><br><span class="line">                task.max_positions(),</span><br><span class="line">                trainer.get_model().max_positions(),</span><br><span class="line">            ),</span><br><span class="line">            ignore_invalid_inputs=args.skip_invalid_size_inputs_valid_test,</span><br><span class="line">            required_batch_size_multiple=8,</span><br><span class="line">            seed=args.seed,</span><br><span class="line">            num_shards=args.distributed_world_size,</span><br><span class="line">            shard_id=args.distributed_rank,</span><br><span class="line">            num_workers=args.num_workers,</span><br><span class="line">        ).next_epoch_itr(shuffle=False)</span><br><span class="line">        progress = progress_bar.build_progress_bar(</span><br><span class="line">            args, itr, epoch_itr.epoch,</span><br><span class="line">            prefix=<span class="string">'valid on \'</span>&#123;&#125;\<span class="string">' subset'</span>.format(subset),</span><br><span class="line">            no_progress_bar=<span class="string">'simple'</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reset validation loss meters</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">'valid_loss'</span>, <span class="string">'valid_nll_loss'</span>]:</span><br><span class="line">            meter = trainer.get_meter(k)</span><br><span class="line">            <span class="keyword">if</span> meter is not None:</span><br><span class="line">                meter.reset()</span><br><span class="line">        extra_meters = collections.defaultdict(lambda: AverageMeter())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> sample <span class="keyword">in</span> progress:</span><br><span class="line">            log_output = trainer.valid_step(sample)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> log_output.items():</span><br><span class="line">                <span class="keyword">if</span> k <span class="keyword">in</span> [<span class="string">'loss'</span>, <span class="string">'nll_loss'</span>, <span class="string">'ntokens'</span>, <span class="string">'nsentences'</span>, <span class="string">'sample_size'</span>]:</span><br><span class="line">                    <span class="built_in">continue</span></span><br><span class="line">                extra_meters[k].update(v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log validation stats</span></span><br><span class="line">        stats = get_valid_stats(trainer)</span><br><span class="line">        <span class="comment"># ------record validate metrics --- #</span></span><br><span class="line">        <span class="keyword">if</span> is_epoch:  <span class="comment"># every epoch</span></span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_loss_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_nll_loss_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_nll_loss'</span>]), epoch_itr.epoch)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_ppl_epoch'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_ppl'</span>]), epoch_itr.epoch)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># every n update</span></span><br><span class="line">            num_updates = stats[<span class="string">'num_updates'</span>]</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_loss_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_loss'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_nll_loss_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_nll_loss'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line">            summary_writer.add_scalar(<span class="string">'Validation/valid_ppl_update'</span>, <span class="built_in">float</span>(stats[<span class="string">'valid_ppl'</span>]),</span><br><span class="line">                                      num_updates / args.save_interval_updates)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k, meter <span class="keyword">in</span> extra_meters.items():</span><br><span class="line">            stats[k] = meter.avg</span><br><span class="line">        progress.print(stats)</span><br><span class="line"></span><br><span class="line">        valid_losses.append(stats[<span class="string">'valid_loss'</span>])</span><br><span class="line">    <span class="built_in">return</span> valid_losses</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://github.com/pytorch/fairseq/tree/master/examples/translation#replicating-results-from-scaling-neural-machine-translation" target="_blank" rel="noopener">Replicating results from â€œScaling Neural Machine Translationâ€</a></p><p><a href="https://github.com/pytorch/fairseq/issues/346" target="_blank" rel="noopener">How to reproduce the result of WMT14 en-de on transformer BASE model?</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
            <tag> Transformer </tag>
            
            <tag> NMT </tag>
            
            <tag> fairseq </tag>
            
            <tag> æœºå™¨ç¿»è¯‘ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•15</title>
      <link href="/2019/01/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9515/"/>
      <url>/2019/01/06/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9515/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-flatten-multi-dimentional-list"><a href="#1ï¸âƒ£-flatten-multi-dimentional-list" class="headerlink" title="1ï¸âƒ£[flatten multi-dimentional list]"></a>1ï¸âƒ£[flatten multi-dimentional list]</h3><p>å¯¹å¤šå±‚åµŒå¥—çš„listè¿›è¡Œå±•å¹³ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€’å½’</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten</span><span class="params">(nestedList)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aux</span><span class="params">(listOrItem)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(listOrItem, list):</span><br><span class="line">            <span class="keyword">for</span> elem <span class="keyword">in</span> listOrItem:</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> aux(elem):</span><br><span class="line">                    <span class="keyword">yield</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> listOrItem</span><br><span class="line">    <span class="keyword">return</span> list(aux(nestedList))</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£-sorted-index"><a href="#2ï¸âƒ£-sorted-index" class="headerlink" title="2ï¸âƒ£[sorted index]"></a>2ï¸âƒ£[sorted index]</h3><p>ä½¿ç”¨å†…ç½®æ–¹æ³•è·å¾—æ’å¥½åºçš„index</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sorted_index=[i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(enumerate(sent_length),</span><br><span class="line">                                    key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],</span><br><span class="line">                                    reverse=self.reverse)]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡11</title>
      <link href="/2019/01/06/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8711/"/>
      <url>/2019/01/06/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8711/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Multi-Head-Attention-with-Disagreement-Regularization"><a href="#1ï¸âƒ£-Multi-Head-Attention-with-Disagreement-Regularization" class="headerlink" title="1ï¸âƒ£[Multi-Head Attention with Disagreement Regularization]"></a>1ï¸âƒ£[Multi-Head Attention with Disagreement Regularization]</h2><p>EMNLPçš„çŸ­æ–‡ã€‚</p><p>é¼“åŠ±transformerä¸­headä¸headä¹‹é—´çš„å·®å¼‚ã€‚</p><p>åŠ äº†ä¸‰ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼š<br>â‘ on subspace<br><img src="/images/15467399912055.jpg" width="40%" height="50%"></p><p>â‘¡on attention position<br><img src="/images/15467400218650.jpg" width="40%" height="50%"></p><p>â‘¢on output<br><img src="/images/15467400417247.jpg" width="40%" height="50%"></p><p>æ²¡ä»€ä¹ˆäº®ç‚¹ã€‚</p><hr><h2 id="2ï¸âƒ£-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overï¬tting"><a href="#2ï¸âƒ£-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overï¬tting" class="headerlink" title="2ï¸âƒ£[Dropout: A Simple Way to Prevent Neural Networks from Overï¬tting]"></a>2ï¸âƒ£[Dropout: A Simple Way to Prevent Neural Networks from Overï¬tting]</h2><p>ç»å…¸è®ºæ–‡ã€‚<br>dropoutæ–¹æ³•å¾ˆç®€å•ï¼Œä½†å¦‚ä½•æƒ³åˆ°ï¼Œå…¶èƒŒåçš„intuitionï¼Œä»¥åŠä¸€äº›ç°è±¡å¾ˆæœ‰å¯å‘æ„ä¹‰ã€‚<br>ä»…ç½—åˆ—ä¸€äº›intuition/motivationä»¥åŠç°è±¡ï¼š</p><ol><li>ç½‘ç»œå¤æ‚å…³ç³»å­¦åˆ°å¾ˆå¤šå™ªå£°ï¼Œå¯¼è‡´overfitting</li><li>æœ€å¥½çš„regularizationæ–¹æ³•æ˜¯å¯¹æ‰€æœ‰çš„parameter settingçš„ç»“æœè¿›è¡Œaverageã€‚è¿™å°±æ˜¯è´å¶æ–¯æ–¹æ³•ï¼Œ dropoutæ˜¯å¯¹è¯¥æ–¹æ³•è¿›è¡Œè¿‘ä¼¼ï¼Œè®ºæ–‡ä¹Ÿæåˆ°äº†model combination</li><li>dropoutèƒ½å¤Ÿå‡å°‘unitä¹‹é—´å¤æ‚çš„co-adaptationï¼Œèƒ½å¤Ÿæ›´é²æ£’ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸éœ€è¦ä¾èµ–å…¶ä»–unitå»çº æ­£è‡ªå·±çš„é”™è¯¯ã€‚each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes</li><li>dropoutçš„ç‰¹æ€§ï¼šsparsityã€‚æ ‡å‡†çš„ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå›ºåŒ–å…¶ä»–unitçš„é”™è¯¯ï¼Œå¯¼è‡´å¤æ‚çš„co-adaptationï¼Œä½†è¿™ç§å¤æ‚çš„adaptationä¼šå¯¼è‡´æ³›åŒ–æ€§çš„é™ä½ï¼Œå› ä¸ºå¯¹äºæœªè§åˆ°çš„æ•°æ®è¿™ç§å¤æ‚çš„adaptationæ˜¯æ²¡ç”¨çš„ã€‚å› æ­¤dropoutçš„ç½‘ç»œä¸­æ¯ä¸ªunitéƒ½è¦å­¦ä¼šè‡ªå·±çº æ­£è‡ªå·±çš„é”™è¯¯ï¼Œå› æ­¤æ¯ä¸ªunitèƒ½å¤Ÿç‹¬ç«‹å­¦åˆ°æ•°æ®çš„ä¸€éƒ¨åˆ†ç‰¹æ€§ã€‚dropoutä¼šå¯¼è‡´ç¨€ç–åŒ–ï¼Œæ¯æ¬¡éƒ½åªä¼šæœ‰ä¸€å°éƒ¨åˆ†çš„activationé«˜ã€‚ä½¿ç”¨dropouté…åˆé«˜çš„å­¦ä¹ ç‡æ¯”è¾ƒå¥½ï¼Œå› ä¸ºdropoutå¯èƒ½ä¼šå¯¼è‡´gradientä¹‹é—´äº’ç›¸cancelï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨é«˜çš„momentumã€‚</li></ol><p><img src="/images/15467404963033.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> dropout </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> regularization </tag>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­index_copy_åŠå…¶æ€è€ƒ</title>
      <link href="/2018/12/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADindex_copy_%E5%8F%8A%E5%85%B6%E6%80%9D%E8%80%83/"/>
      <url>/2018/12/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADindex_copy_%E5%8F%8A%E5%85%B6%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥å› ä¸ºin-placeæ“ä½œçš„é—®é¢˜ï¼Œdebugäº†å¥½å‡ å¤©ï¼Œæœ€ç»ˆæ‰å‘ç°é—®é¢˜ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure><p>å› ä¸ºPytorchä¸­pack_sequenceéœ€è¦å°†batchæŒ‰é•¿åº¦æ’åˆ—ï¼Œæˆ‘åœ¨è¿‡å®ŒGRUåéœ€è¦å°†å…¶é¡ºåºè¿˜åŸï¼Œåœ¨è¿™è¾¹sorted_indexå³æ˜¯è®°å½•åŸæ¥indexæ˜ å°„ã€‚</p><p>ç„¶è€Œæˆ‘åœ¨å†™çš„æ—¶å€™ï¼Œå‚è€ƒçš„æ˜¯å®˜æ–¹çš„exampleï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]], dtype=torch.float)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([<span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.index_copy_(<span class="number">0</span>, index, t)</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">7.</span>,  <span class="number">8.</span>,  <span class="number">9.</span>],</span><br><span class="line">        [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>]])</span><br></pre></td></tr></table></figure><p>å› æ­¤æˆ‘ä¹Ÿä¸å‡æ€ç´¢åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output,_=pad_packed_sequence(output,batch_first=<span class="keyword">True</span>)</span><br><span class="line">output=output.index_copy_(<span class="number">0</span>,torch.tensor(sorted_index),output)</span><br></pre></td></tr></table></figure></p><p>å°±å› ä¸ºå¤šäº†ä¸€ä¸ª_ï¼Œå¯¼è‡´é€»è¾‘å’Œæˆ‘æƒ³è±¡ä¸­çš„ä¸ä¸€æ ·ã€‚</p><p>ä¸€ä¸ªç®€å•çš„ä¾‹å­å±•ç¤ºä¸ºä»€ä¹ˆè¿™ä¹ˆæ˜¯é”™çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.Tensor([<span class="number">21</span>,<span class="number">42</span>,<span class="number">45</span>,<span class="number">59</span>])</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 42., 45., 59.])</span></span><br><span class="line"></span><br><span class="line">index=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">x=x.index_copy_(<span class="number">0</span>,index,x)</span><br><span class="line"></span><br><span class="line">print(x)  <span class="comment"># tensor([21., 21., 21., 59.])</span></span><br></pre></td></tr></table></figure><p>ç”±äºæ˜¯in-placeæ“ä½œï¼Œç¬¬ä¸€æ­¥ï¼Œå°†index=0çš„æ•°å€¼ï¼ˆä¹Ÿå³21ï¼‰å¤åˆ¶åˆ°index=1çš„åœ°æ–¹ï¼Œæ­¤æ—¶å˜æˆ[21,21,45,59]ï¼›æ¥ç€å°†index=1çš„æ•°å€¼å¤åˆ¶åˆ°index=2çš„ä½ç½®ä¸Šï¼Œæ³¨æ„åˆ°ä¹‹å‰å·²ç»æ˜¯in-placeæ“ä½œï¼Œå› æ­¤æ­¤æ—¶å–çš„ä¸æ˜¯æƒ³è±¡ä¸­çš„42ï¼Œè€Œæ˜¯å·²ç»è¢«æ›¿æ¢çš„21ã€‚åé¢çš„ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p><p>æ­£ç¡®çš„åšæ³•åªéœ€è¦å»æ‰in-placeå³å¯ã€‚</p><hr><p>å·²ç»å¥½å‡ æ¬¡é‡åˆ°in-placeçš„é—®é¢˜äº†ï¼Œåœ¨æ¯æ¬¡åšin-placeæ“ä½œæ—¶ï¼Œéƒ½è¦è­¦æƒ•ã€‚åº”å°½å¯èƒ½é¿å…in-placeæ“ä½œã€‚å®é™…ä¸ŠPytorchå®˜æ–¹ä¹Ÿä¸å»ºè®®ä½¿ç”¨in-placeæ“ä½œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> index_coopy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•14</title>
      <link href="/2018/12/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9514/"/>
      <url>/2018/12/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9514/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-shuffle-list"><a href="#1ï¸âƒ£-shuffle-list" class="headerlink" title="1ï¸âƒ£[shuffle list]"></a>1ï¸âƒ£[shuffle list]</h3><p>shuffle listå¯ä»¥ä½¿ç”¨randomçš„shuffleå‡½æ•°ï¼Œäº¦å³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">shuffle(l)  <span class="comment"># in place operation</span></span><br></pre></td></tr></table></figure><p>è€Œæƒ³è¦shuffleä¸¤ä¸ªå¯¹åº”listï¼Œä¹Ÿå³ç­‰é•¿ä¸”ä¸€ä¸€å¯¹åº”çš„listï¼Œåˆ™å¯ä»¥ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># borrow from stackoverflow</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> len(a) == len(b)</span><br><span class="line">    start_state = random.getstate()</span><br><span class="line">    random.shuffle(a)</span><br><span class="line">    random.setstate(start_state)</span><br><span class="line">    random.shuffle(b)</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br><span class="line">b = [<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">19</span>]</span><br><span class="line">shuffle(a,b)</span><br><span class="line">print(a) <span class="comment"># [9, 7, 3, 1, 2, 5, 4, 8, 6]</span></span><br><span class="line">print(b) <span class="comment"># [19, 17, 13, 11, 12, 15, 14, 18, 16]</span></span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£-inverse-tensor"><a href="#2ï¸âƒ£-inverse-tensor" class="headerlink" title="2ï¸âƒ£[inverse tensor]"></a>2ï¸âƒ£[inverse tensor]</h3><p>Pytorchç›®å‰è¿˜ä¸æ”¯æŒæ­¥è¿›ä¸ºè´Ÿçš„æƒ…å†µï¼Œå› æ­¤ä¸èƒ½ä½¿ç”¨ç±»ä¼¼Pythonçš„<code>l[::-1]</code>çš„æ–¹æ³•reverse tensorã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">inv_idx = torch.arange(tensor.size(<span class="number">0</span>)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>).long()</span><br><span class="line"><span class="comment"># or equivalently torch.range(tensor.size(0)-1, 0, -1).long()</span></span><br><span class="line">inv_tensor = tensor.index_select(<span class="number">0</span>, inv_idx)</span><br><span class="line"><span class="comment"># or equivalently</span></span><br><span class="line">inv_tensor = tensor[inv_idx]</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£-GRU-initialization"><a href="#3ï¸âƒ£-GRU-initialization" class="headerlink" title="3ï¸âƒ£[GRU initialization]"></a>3ï¸âƒ£[GRU initialization]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gru_init</span><span class="params">(self)</span>:</span>   <span class="comment"># use orthogonal seems better</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_ih_l0.data)  <span class="comment">#æ²¡æœ‰dataä¸è¡Œï¼Œä¼šæŠ¥leaf variable in-placeé”™è¯¯ï¼Œå¯èƒ½weight_ih_l0ä¸æ˜¯parameter</span></span><br><span class="line">    nn.init.orthogonal_(self.word_RNN.weight_hh_l0.data)</span><br><span class="line">    self.word_RNN.bias_ih_l0.data.zero_()</span><br><span class="line">    self.word_RNN.bias_hh_l0.data.zero_()</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£-sort-counter"><a href="#4ï¸âƒ£-sort-counter" class="headerlink" title="4ï¸âƒ£[sort counter]"></a>4ï¸âƒ£[sort counter]</h3><p>éœ€æ±‚ï¼šç»Ÿè®¡documentçš„å¥å­ä¸ªæ•°çš„åˆ†å¸ƒï¼Œå¹¶æŒ‰ç…§é•¿åº¦é¡ºåºæ’åˆ—ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_sents=[len(sentences) <span class="keyword">for</span> sentences <span class="keyword">in</span> documents]</span><br><span class="line">n_lengths=Counter(n_sents)</span><br><span class="line">n_lengths=sorted(n_lengths.items())</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†17</title>
      <link href="/2018/12/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8617/"/>
      <url>/2018/12/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8617/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨æœ‰RNNçš„ä»£ç ä¸­ï¼Œå¦‚æœå‡ºç°</p><blockquote><p>Cuda Error : RuntimeError: CUDNN_STATUS_EXECUTION_FAILED</p></blockquote><p>é‚£ä¹ˆå¯èƒ½çš„å‡ºé”™åŸå› æ˜¯æ²¡æœ‰å°†init stateæ”¾å…¥cudaä¸­ã€‚</p><p>Reference: <a href="https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625" target="_blank" rel="noopener">https://discuss.pytorch.org/t/cuda-error-runtimeerror-cudnn-status-execution-failed/17625</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>clone() â†’ Tensor<br>Returns a copy of the self tensor. The copy has the same size and data type as self.<br><strong>Unlike copy_(), this function is recorded in the computation graph. Gradients propagating to the cloned tensor will propagate to the original tensor.</strong></p><p>å¦‚æœéœ€è¦å¦ä¸€ä¸ªç›¸åŒçš„tensoråšå…¶ä»–è®¡ç®—ï¼Œåˆ™ä½¿ç”¨clone()è€Œä¸æ˜¯copy_()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">forward_vec=sent_vec</span><br><span class="line"><span class="comment"># backward_vec=sent_vec   wrong</span></span><br><span class="line">backward_vec=sent_vec.clone()</span><br></pre></td></tr></table></figure><p>å½“ç„¶ä¹Ÿä¸èƒ½ç›´æ¥èµ‹å€¼ï¼Œå› ä¸ºèµ‹çš„åªæ˜¯æŒ‡é’ˆï¼Œæ”¹å˜backward_vecä¹Ÿä¼šæ”¹å˜åŸæ¥çš„å€¼ã€‚</p><hr><h3 id="3ï¸âƒ£-Python"><a href="#3ï¸âƒ£-Python" class="headerlink" title="3ï¸âƒ£[Python]"></a>3ï¸âƒ£[Python]</h3><p>Pythonä¸­<code>==</code>å’Œ<code>is</code>çš„åŒºåˆ«ï¼š<br>isè¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªobjectï¼›è€Œ==è¡¨ç¤ºæ˜¯å¦æ˜¯åŒä¸€ä¸ªå€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str=<span class="string">'GRU'</span></span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br><span class="line">str=str.upper()</span><br><span class="line">str == <span class="string">'GRU'</span>  <span class="comment"># False</span></span><br><span class="line">str <span class="keyword">is</span> <span class="string">'GRU'</span>  <span class="comment"># True</span></span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£-RNN"><a href="#4ï¸âƒ£-RNN" class="headerlink" title="4ï¸âƒ£[RNN]"></a>4ï¸âƒ£[RNN]</h3><p>åœ¨RNNçš„åˆå§‹åŒ–ä¸­ï¼Œä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ä¼šæ¯”å…¶ä»–æ–¹æ³•å¥½ä¸€äº›ï¼ˆå¾…å¯¹æ¯”å®éªŒæµ‹éªŒï¼‰ã€‚<br>Reference: <a href="https://smerity.com/articles/2016/orthogonal_init.html" target="_blank" rel="noopener">https://smerity.com/articles/2016/orthogonal_init.html</a></p><hr><h3 id="5ï¸âƒ£-Pytorch"><a href="#5ï¸âƒ£-Pytorch" class="headerlink" title="5ï¸âƒ£[Pytorch]"></a>5ï¸âƒ£[Pytorch]</h3><p>åœ¨æä¾›é¢„è®­ç»ƒembeddingä½œä¸ºåˆå§‹åŒ–æ—¶ï¼Œæ­£ç¡®åšæ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> pretrained_matrix <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    pretrained_matrix=torch.from_numpy(pretrained_matrix).type(torch.FloatTensor)</span><br><span class="line">    self.embedding.weight= nn.Parameter(pretrained_matrix,</span><br><span class="line">                                                requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>å¿…é¡»è¦æœ‰<code>.type(torch.FloatTensor)</code>ï¼Œå¦åˆ™ä¼šå‡ºé”™ï¼šCuDNN error: CUDNN_STATUS_EXECUTION_FAILED</p><hr><h3 id="6ï¸âƒ£-Pytorch"><a href="#6ï¸âƒ£-Pytorch" class="headerlink" title="6ï¸âƒ£[Pytorch]"></a>6ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ï¼Œå°†åˆå§‹hidden stateä½œä¸ºå¯å­¦ä¹ å‚æ•°å®è·µï¼š<br><a href="https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9" target="_blank" rel="noopener">https://discuss.pytorch.org/t/solved-train-initial-hidden-state-of-rnns/2589/9</a><br><a href="https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7" target="_blank" rel="noopener">https://discuss.pytorch.org/t/learn-initial-hidden-state-h0-for-rnn/10013/7</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Pytorch </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>A Day with Google</title>
      <link href="/2018/12/23/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/A%20Day%20with%20Google/"/>
      <url>/2018/12/23/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/A%20Day%20with%20Google/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨ä¸€ä¹¡ä¸‹äººç»ˆäºå†æ¬¡è¿›åŸäº†ğŸ™ˆ<br><img src="/images/IMG_2243.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_8631.jpg" width="70%" height="50%"></p><p>æœ¬æ¬¡çš„ç›®çš„æ˜¯æ¥å‚è§‚Googleã€‚</p><p>é«˜æ¥¼æ—ç«‹ï¼š<br><img src="/images/IMG_2273.jpg" width="70%" height="50%"></p><p>Here We are:<br><img src="/images/IMG_9209-1.jpg" width="70%" height="50%"></p><p>å’•æœæ˜¯ä»€ä¹ˆé¬¼ï¼Ÿ<br><img src="/images/IMG_3389.jpg" width="70%" height="50%"></p><p>å®£è®²ï¼š<br><img src="/images/IMG_1782.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_1075.jpg" width="70%" height="50%"></p><p>ä¸å¾—ä¸æ„Ÿæ…¨é£Ÿå ‚çœŸå¥½ğŸ¦†ï¼Œè¿˜æœ‰ä¸“é—¨åƒé¢çš„é£Ÿå ‚ã€‚è€Œä¸”è¿˜éƒ½ä¸ç”¨é’±ğŸ™‰ï¼Œå¯¹æ¯”å¼ æ±Ÿçš„é£Ÿå ‚ğŸ™‰ï¼š</p><p><img src="/images/IMG_0546.jpg" width="70%" height="50%"></p><p>æºœäº†æºœäº†ï¼š<br><img src="/images/IMG_1255.jpg" width="70%" height="50%"></p><p><img src="/images/IMG_1256.jpg" width="70%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Google </tag>
            
            <tag> æ´»åŠ¨ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡10</title>
      <link href="/2018/12/23/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8710/"/>
      <url>/2018/12/23/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8710/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect"><a href="#1ï¸âƒ£-Regularization-of-Neural-Networks-using-DropConnect" class="headerlink" title="1ï¸âƒ£[Regularization of Neural Networks using DropConnect]"></a>1ï¸âƒ£[Regularization of Neural Networks using DropConnect]</h2><p>åœ¨dropoutçš„åŸºç¡€ä¸Šæå‡ºdropconnectã€‚ä¸dropoutä¸åŒçš„æ˜¯ï¼Œdropconnectå¯¹weightè¿›è¡Œdropè€Œä¸æ˜¯å¯¹layerè¿›è¡Œdropã€‚</p><p>åˆ›æ–°ä¹‹å¤„åœ¨äºinferenceçš„æ—¶å€™å’Œdropoutä¸åŒã€‚</p><h3 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h3><p><img src="/images/15455297378934.jpg" width="50%" height="50%"></p><h3 id="inference"><a href="#inference" class="headerlink" title="inference"></a>inference</h3><p><img src="/images/15455297645976.jpg" width="50%" height="50%"></p><p>åœ¨inferenceçš„æ—¶å€™é€šè¿‡é«˜æ–¯é‡‡æ ·çš„æ–¹æ³•å»æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚<br><strong>intuition</strong>ï¼š<br>æœ¬æ–‡å¯¹dropoutåœ¨inferenceç®€å•å¯¹unitè¿›è¡Œç¼©æ”¾è¿›è¡Œåæ€ï¼Œè®¤ä¸ºè¿™åœ¨æ•°å­¦ä¸Šå¹¶ä¸åˆç†ï¼Œå› æ­¤æå‡ºç”¨é«˜æ–¯åˆ†å¸ƒå»é‡‡æ ·ã€‚<br><img src="/images/15455299241433.jpg" width="50%" height="50%"></p><p><img src="/images/15455299403032.jpg" width="50%" height="50%"></p><p><img src="/images/15455299548705.jpg" width="50%" height="50%"></p><hr><h2 id="2ï¸âƒ£-Attentive-Pooling-Networks"><a href="#2ï¸âƒ£-Attentive-Pooling-Networks" class="headerlink" title="2ï¸âƒ£[Attentive Pooling Networks]"></a>2ï¸âƒ£[Attentive Pooling Networks]</h2><p>æå‡ºattentive poolingæœºåˆ¶ï¼Œç”¨ä»¥answer selectionã€‚<br>ï¼ˆä»€ä¹ˆæ˜¯answer selectionï¼šç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œç»™å®šå¤šä¸ªç­”æ¡ˆå€™é€‰ï¼Œè¦ä»ç­”æ¡ˆé€‰é¡¹ä¸­é€‰æ‹©æ­£ç¡®çš„ç­”æ¡ˆã€‚ï¼‰</p><p>ä¼ ç»Ÿanswer selectionï¼š<br><img src="/images/15455301265939.jpg" width="35%" height="50%"><br>é¦–å…ˆå°†è¯è½¬åŒ–æˆè¯å‘é‡ï¼Œæ¥ç€é€šè¿‡bi-LSTMæˆ–CNNè·å¾—ä¸€ä¸ªçŸ©é˜µè¡¨ç¤ºï¼Œæ¥ä¸‹æ¥å¯¹Qå’ŒAåˆ†åˆ«è¿›è¡Œmax-poolingè·å¾—å›ºå®šè¡¨ç¤ºï¼Œæœ€åé€šè¿‡cosè·ç¦»åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ˜¯æ­£ç¡®ç­”æ¡ˆï¼Œä»ç­”æ¡ˆå€™é€‰ä¸­é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ã€‚</p><p>ä½†è¿™æ ·çš„é—®é¢˜åœ¨äºQå’ŒAä¹‹é—´æ²¡æœ‰äº¤äº’ã€‚</p><p>æœ¬æ–‡åˆ©ç”¨attentionä½œä¸ºQå’ŒAçš„äº¤äº’ã€‚<br><img src="/images/15455301891043.jpg" width="39%" height="50%"></p><p>è·å¾—Qå’ŒAçŸ©é˜µçš„æ–¹å¼æ˜¯ä¸€è‡´çš„ã€‚<br>æ¥ä¸‹æ¥ï¼Œé¦–å…ˆè®¡ç®—ä¸€ä¸ªGçŸ©é˜µï¼Œé€šè¿‡åŒçº¿æ€§attentionå…¬å¼è·å¾—ï¼š<br><img src="/images/15455302279543.jpg" width="20%" height="50%"></p><p>Gæ‰€ä»£è¡¨çš„æ„ä¹‰æ˜¯Qå’ŒAçš„æ¯ä¸ªè¯ä¹‹é—´çš„å¯¹é½ï¼šå¯¹äºç¬¬iè¡Œæ¥è¯´ï¼Œä»£è¡¨Qçš„ç¬¬iä¸ªè¯å’ŒAä¸­æ‰€æœ‰è¯çš„ä¸€ä¸ªåˆ†æ•°ï¼›å¯¹äºç¬¬jåˆ—æ¥è¯´ï¼Œä»£è¡¨ç¬¬jä¸ªè¯å’ŒQä¸­æ‰€æœ‰è¯çš„åˆ†æ•°ã€‚</p><p>æ¥ä¸‹æ¥å¯¹Gçš„è¡Œå’Œåˆ—åˆ†åˆ«è¿›è¡Œmax-poolingæ“ä½œï¼š<br><img src="/images/15455303089243.jpg" width="25%" height="50%"></p><p>æ­¤æ­¥ä»£è¡¨é€‰æ‹©ä¸æŸè¯å…³ç³»æœ€é‡è¦çš„è¯ã€‚</p><p>æ¥ä¸‹æ¥å¯¹gåˆ†åˆ«è¿›è¡Œsoftmaxï¼Œå†åˆ†åˆ«è¿›è¡Œç‚¹ç§¯ä»¥è·å¾—æœ€ç»ˆå‘é‡è¡¨ç¤ºï¼š<br><img src="/images/15455303516483.jpg" width="13%" height="50%"></p><p>åŒæ ·ï¼Œæœ€ç»ˆä½¿ç”¨cosè·ç¦»è®¡ç®—ç›¸ä¼¼åº¦ã€‚</p><hr><h2 id="3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout"><a href="#3ï¸âƒ£-Improved-Regularization-of-Convolutional-Neural-Networks-with-Cutout" class="headerlink" title="3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]"></a>3ï¸âƒ£[Improved Regularization of Convolutional Neural Networks with Cutout]</h2><p>æ˜¯ä»æ•°æ®å¢å¼ºå’Œdropoutçš„è§’åº¦ï¼š</p><blockquote><p>dropout in convolutional layers simply acts to increase robustness to noisy inputs, rather than having the same model averaging effect that is observed in fully-connected layers</p></blockquote><p>æŸä¸ªè¾“å…¥è¢«ç§»å»ï¼Œæ‰€æœ‰åé¢ç›¸å…³çš„çš„feature mapéƒ½è¢«ç§»å»ï¼š</p><blockquote><p>In this sense, cutout is much closer to data augmentation than dropout, as it is not creating noise, but instead generating images that appear novel to the network</p></blockquote><p>å…¶å®åªæ˜¯å°†è¾“å…¥éšæœºdropæ‰ä¸€å—ã€‚<br><img src="/images/15455304317998.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> DropConnect </tag>
            
            <tag> Cutout </tag>
            
            <tag> Attentive Pooling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•13</title>
      <link href="/2018/12/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9513/"/>
      <url>/2018/12/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9513/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-flatten-list"><a href="#1ï¸âƒ£-flatten-list" class="headerlink" title="1ï¸âƒ£[flatten list]"></a>1ï¸âƒ£[flatten list]</h3><p>å¯¹äºŒç»´listè¿›è¡Œå±•å¼€ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list2d = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>], [<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"><span class="comment"># â‘ </span></span><br><span class="line">flatten = [l <span class="keyword">for</span> list <span class="keyword">in</span> list2d <span class="keyword">for</span> l <span class="keyword">in</span> list]</span><br><span class="line"><span class="comment"># â‘¡</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">merged = list(itertools.chain(*list2d))</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">merged = list(itertools.chain.from_iterable(list2d))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†16</title>
      <link href="/2018/12/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8616/"/>
      <url>/2018/12/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8616/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Softmax"><a href="#1ï¸âƒ£-Softmax" class="headerlink" title="1ï¸âƒ£[Softmax]"></a>1ï¸âƒ£[Softmax]</h3><p>åœ¨ä½¿ç”¨softmaxçš„æ—¶å€™ï¼Œè¦éå¸¸æ³¨æ„softmaxçš„è¡Œä¸ºã€‚åº”å°½é‡æ§åˆ¶softmaxå‰å…ƒç´ çš„è§„æ¨¡ï¼Œå¦åˆ™å®¹æ˜“å‡ºç°one-hotçš„æƒ…å†µï¼Œå¯¼è‡´è®­ç»ƒå›°éš¾ã€‚<br><img src="/images/15455275366030.jpg" width="70%" height="50%"></p><p>åŒæ—¶ï¼Œå¯¹å…¨-infåšsoftmaxæ˜¯æœªå®šä¹‰çš„ï¼Œå› æ­¤ä¹Ÿä¼šå‡ºç°é—®é¢˜ï¼š<br><img src="/images/15455278529550.jpg" width="40%" height="50%"></p><hr><h3 id="2ï¸âƒ£-slice"><a href="#2ï¸âƒ£-slice" class="headerlink" title="2ï¸âƒ£[slice]"></a>2ï¸âƒ£[slice]</h3><p>åœ¨å¯¹tensoræˆ–arrayæ“ä½œæ—¶ï¼Œå¦‚æœéœ€è¦å–æŸç»´çš„sliceï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">a[:,<span class="number">1</span>:<span class="number">3</span>]  <span class="comment"># å–ç¬¬1åˆ—åˆ°ç¬¬2åˆ—çš„slice</span></span><br><span class="line">a[:][<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># wrongï¼Œè·å¾—çš„æ˜¯ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„slice</span></span><br></pre></td></tr></table></figure><p>åŸå› æ˜¯ï¼Œ<code>a[:][1:3]</code>æ˜¯å…ˆåš<code>a[:]</code>æ“ä½œï¼Œè·å¾—äº†å…¨éƒ¨å…ƒç´ ï¼Œç„¶åå†åš<code>[1:3]</code>æ“ä½œï¼Œä¹Ÿå³è·å¾—ç¬¬1è¡Œåˆ°ç¬¬2è¡Œçš„å…ƒç´ ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Softmax </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•12</title>
      <link href="/2018/12/16/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9512/"/>
      <url>/2018/12/16/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9512/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-CUDA-time"><a href="#1ï¸âƒ£-CUDA-time" class="headerlink" title="1ï¸âƒ£[CUDA time]"></a>1ï¸âƒ£[CUDA time]</h3><p>æ­£ç¡®æµ‹è¯•ä»£ç åœ¨cudaè¿è¡Œæ—¶é—´ã€‚éœ€è¦åŠ ä¸Š<code>torch.cuda.synchronize()</code>ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line">b = torch.randint(high=<span class="number">1000</span>, size=(<span class="number">20</span>, <span class="number">200</span>, <span class="number">256</span>)).double().cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">M = torch.bmm(a, b.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"bmm"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">local_a = a.unsqueeze(<span class="number">2</span>)</span><br><span class="line">local_b = b.unsqueeze(<span class="number">1</span>)</span><br><span class="line">N = (local_a*local_b).sum(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"element-wise"</span>, end - start)</span><br><span class="line">print(<span class="string">"max_mem"</span>, torch.cuda.max_memory_allocated())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"output difference (should be 0)"</span>, (N - M).abs().max())</span><br><span class="line">print(<span class="string">"In single precision this can fail because of the size of the tensors."</span>)</span><br><span class="line">print(<span class="string">"Using double should always work"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†15</title>
      <link href="/2018/12/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8615/"/>
      <url>/2018/12/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8615/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åœ¨0.41çš„pytorchä¸­ï¼Œbernoulliçš„é€Ÿåº¦ä¼šæ¯”éšæœºsampleçš„é€Ÿåº¦æ…¢å¾ˆå¤šï¼›<br>åœ¨1.0ä¸­ä¿®å¤äº†è¯¥bugï¼Œä½†é€Ÿåº¦ä¸Šè¿˜æ˜¯éšæœºsampleå¿«ä¸€ç‚¹ç‚¹ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Pytorch0.41</span><br><span class="line">Bernoulli  0.430371046066</span><br><span class="line">sample  0.24411702156</span><br><span class="line"></span><br><span class="line"># Pytorch1.0</span><br><span class="line">Bernoulli  0.256921529</span><br><span class="line">sample  0.25317035184</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»¥ä¸‹äºŒè€…ç­‰ä»·</span></span><br><span class="line">mask = Bernoulli(gamma).sample(x.size()) <span class="comment"># slow</span></span><br><span class="line">mask = (torch.rand_like(x)&lt;gamma).float() <span class="comment"># faster</span></span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://github.com/pytorch/pytorch/issues/6940" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/6940</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡9</title>
      <link href="/2018/12/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%879/"/>
      <url>/2018/12/16/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%879/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation"><a href="#1ï¸âƒ£-Sentence-State-LSTM-for-Text-Representation" class="headerlink" title="1ï¸âƒ£[Sentence-State LSTM for Text Representation]"></a>1ï¸âƒ£[Sentence-State LSTM for Text Representation]</h2><p>æå‡ºä¸€ç§æ–°å‹çš„encodeå¥å­çš„æ–¹æ³•ã€‚æœ‰ç‚¹ç±»ä¼¼gather-distributeçš„æƒ³æ³•ã€‚</p><p><img src="/images/15449283844319.jpg" width="45%" height="50%"></p><p>æ¯ä¸ªæ—¶é—´æ­¥tæ‰€æœ‰çš„hä¸€èµ·æ›´æ–°ã€‚æ›´æ–°æ–¹å¼æ˜¯ä¸å…¶å·¦å³çš„ç‚¹è¿›è¡Œäº¤äº’ï¼ŒåŒæ—¶ä¸ä¸€ä¸ªglobal representationè¿›è¡Œäº¤äº’ã€‚è¿™æ ·å³è€ƒè™‘äº†localçš„ä¿¡æ¯ä¹Ÿè€ƒè™‘äº†globalçš„ä¿¡æ¯ã€‚æ¯æ¬¡æ›´æ–°éƒ½å¢åŠ äº†ä¿¡æ¯äº¤äº’ï¼Œä»3gramåˆ°5gramå†åˆ°7gramâ€¦</p><p>å…·ä½“æ¥è¯´ï¼š<br>â‘ å¦‚ä½•æ±‚$h_i$<br><img src="/images/15449285619763.jpg" width="45%" height="50%"></p><p>ä»å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„$h_i$ï¼ŒåŒæ—¶è€ƒè™‘å·¦å³ä¸¤ç‚¹ï¼Œä»¥åŠglobalä¿¡æ¯$g$ï¼Œä»¥åŠè¾“å…¥$x$ã€‚</p><p>â‘¡å¦‚ä½•æ±‚g<br><img src="/images/15449286595709.jpg" width="50%" height="50%"></p><p>é€šè¿‡averageåŒæ—¶è€ƒè™‘æ‰€æœ‰çš„è¯ï¼ŒåŒæ—¶è€ƒè™‘è‡ªå·±ä¸Šä¸€ä¸ªçŠ¶æ€ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> LSTM </tag>
            
            <tag> Encode </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonä¸­çš„+=æ“ä½œ</title>
      <link href="/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84+=%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84+=%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥åœ¨å†™ä¸€æ®µPytorchä»£ç æ—¶ï¼Œåˆä¸€æ¬¡é‡åˆ°äº†in-placeæ“ä½œçš„é—®é¢˜ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output+=pos  <span class="comment"># posæ˜¯ä¸å¯æ›´æ–°çš„tensorï¼Œoutputæ˜¯å¯æ›´æ–°çš„tensor</span></span><br></pre></td></tr></table></figure><p>ç¨‹åºæŠ¥é”™ï¼šâ€œone of the variables needed for gradient computation has been modified by an inplace operationâ€ã€‚</p><p>æ— æ„ä¸­å°†ä»£ç æ”¹æˆ<code>output=output+pos</code>ï¼Œç¨‹åºå°±ä¸ä¼šæŠ¥é”™äº†ã€‚</p><p>åœ¨æŸ¥é˜…äº†ç›¸å…³èµ„æ–™åï¼Œå°†æˆ‘çš„æ€è€ƒæ•´ç†ä¸‹æ¥ã€‚</p><p>åœ¨Pythonä¸­ï¼Œ<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ä¸åŒçš„ï¼Œå¦‚æœè¢«æ“ä½œæ•°æ²¡æœ‰éƒ¨ç½² â€™<strong>iadd</strong>â€˜æ–¹æ³•ï¼Œåˆ™<code>i=i+1</code>å’Œ<code>i+=1</code>æ˜¯ç­‰ä»·çš„ï¼Œâ€™+=â€˜å¹¶ä¸ä¼šäº§ç”Ÿin-placeæ“ä½œï¼›å½“è¢«æ“ä½œæ•°æœ‰éƒ¨ç½²è¯¥æ–¹æ³•ä¸”æ­£ç¡®éƒ¨ç½²ï¼Œåˆ™æ˜¯ä¼šäº§ç”Ÿin-placeæ“ä½œçš„ã€‚å½“æ²¡æœ‰in-placeæ“ä½œæ—¶ï¼Œ<code>i=i+1</code>è¡¨ç¤ºå¯¹ié‡åˆ†é…ï¼Œä¹Ÿå³iæŒ‡å‘äº†å¦ä¸€ä¸ªç©ºé—´è€Œä¸æ˜¯åŸæ¥çš„ç©ºé—´ã€‚</p><p>æ‰€ä»¥ï¼Œè¿™æ ·çš„ä¾‹å­å°±èƒ½è§£é‡Šæ¸…æ¥šäº†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">A = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    a = a + <span class="number">1</span></span><br><span class="line"><span class="comment"># Aå¹¶æ²¡æœ‰è¢«æ”¹å˜</span></span><br><span class="line">B = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">    b += <span class="number">1</span></span><br><span class="line"><span class="comment"># Bè¢«æ”¹å˜äº†</span></span><br></pre></td></tr></table></figure><p>åœ¨Pytorchä¸­ï¼Œä¹Ÿæœ‰éƒ¨ç½²â€™<strong>iadd</strong>()â€˜æ“ä½œï¼Œæ‰€ä»¥å¯¹äº<code>output+=pos</code>ï¼Œoutputå†…éƒ¨çš„å€¼è¢«æ”¹å˜äº†ï¼Œä¹Ÿå³åœ¨è®¡ç®—å›¾ä¸­å¼•å…¥äº†ç¯ï¼Œåœ¨åå‘æ±‚å¯¼æ—¶åˆ™ä¼šå‡ºé”™ã€‚</p><p>å› æ­¤ï¼Œåœ¨Pytorchä¸­ï¼Œåº”å½“é¿å…in-placeçš„æ“ä½œã€‚</p><p>Reference:<br><a href="https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop" target="_blank" rel="noopener">https://stackoverflow.com/questions/41446833/what-is-the-difference-between-i-i-1-and-i-1-in-a-for-loop</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Python </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡8</title>
      <link href="/2018/12/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%878/"/>
      <url>/2018/12/09/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%878/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding"><a href="#1ï¸âƒ£-DiSAN-Directional-Self-Attention-Network-for-RNN-CNN-Free-Language-Understanding" class="headerlink" title="1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]"></a>1ï¸âƒ£[DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding]</h2><p>æå‡ºäº†ä¸¤ç§attentionæœºåˆ¶ï¼Œå³ multi-dimentional attentionå’Œdirectional self-attentionï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæå‡ºæœ‰å‘è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼ˆdirectional self-attention network)</p><h3 id="Multi-dimensional-Attention"><a href="#Multi-dimensional-Attention" class="headerlink" title="Multi-dimensional Attention"></a>Multi-dimensional Attention</h3><p>ä¸ä¼ ç»Ÿçš„æ–¹æ³•ä¸åŒçš„æ˜¯ï¼Œå¯¹äºæ¯ä¸ªè¯å¯¹ï¼Œattentionå‡ºæ¥çš„ä¸æ˜¯æ ‡é‡è€Œæ˜¯å‘é‡ã€‚<br><img src="/images/15443239891184.jpg" width="60%" height="50%"></p><p>è®¡ç®—å…¬å¼ï¼š<br><img src="/images/15443240335179.jpg" width="40%" height="50%"></p><p>$f$çš„ç»´åº¦ä¸$q$ç›¸åŒï¼Œæ¯ä¸€ç»´ä»£è¡¨çš„æ˜¯$x_i$åœ¨è¯¥ç»´å¯¹$q$çš„é‡è¦æ€§ã€‚ä¹Ÿå³feature-wiseçš„attentionã€‚å› æ­¤å¯¹äº$q$è€Œè¨€ï¼Œå…¶è·å¾—çš„åŠ æƒæ±‚å’Œå‘é‡ä¸ºï¼š<br><img src="/images/15443241367138.jpg" width="55%" height="50%"></p><p>ä½¿ç”¨feature-wiseçš„attentionèƒ½å¤Ÿè§£å†³ä¸€æ¬¡å¤šä¹‰çš„é—®é¢˜ï¼Œå› ä¸ºèƒ½å¤Ÿè®¡ç®—æ¯ä¸€ç»´çš„é‡è¦æ€§ï¼Œåœ¨ä¸åŒçš„contextä¸‹æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</p><p>å°†å…¶åº”ç”¨äºself-attentionä¸­ï¼Œæœ‰ä¸¤ç§å˜ä½“ï¼š<br>â‘ token2token<br><img src="/images/15443242128118.jpg" width="58%" height="50%"></p><p><img src="/images/15443242249947.jpg" width="20%" height="50%"></p><p>å› æ­¤xåœ¨äº¤äº’å®Œæœ‰ï¼š<br><img src="/images/15443242733208.jpg" width="35%" height="50%"></p><p>â‘¡source2token<br><img src="/images/15443243090328.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³$x_i$æ²¡æœ‰å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ã€‚<br>å¯ç”¨ä½œè·å¾—sentence encodingï¼š<br><img src="/images/15443243968731.jpg" width="20%" height="50%"></p><h3 id="Directional-Self-Attention"><a href="#Directional-Self-Attention" class="headerlink" title="Directional Self-Attention"></a>Directional Self-Attention</h3><p>ä½¿ç”¨maskè¾¾åˆ°æœ‰å‘æ€§è¿™ä¸€ç›®çš„ï¼š<strong>é€šè¿‡maskçŸ©é˜µå°†ä½ç½®/æ–¹å‘ç¼–ç è¿›attentionï¼Œè§£å†³æ—¶åºä¸¢å¤±é—®é¢˜</strong>ã€‚<br>é¦–å…ˆå°†xè¿‡ä¸€å±‚è·å¾—æ–°çš„hè¡¨ç¤ºï¼š<br><img src="/images/15443244421489.jpg" width="27%" height="50%"></p><p>æ¥ç€ä½¿ç”¨token2tokenæ±‚attentionï¼Œè¿™é‡Œä¸ºäº†å‡å°‘å‚æ•°ä½œäº†ä¸€å®šæ”¹åŠ¨ï¼Œå°†Wæ¢æˆcï¼Œtanhæ›¿æ¢Ïƒã€‚<br><img src="/images/15443245099821.jpg" width="53%" height="50%"></p><p>$\textbf{1}$æ˜¯å…¨1çš„å‘é‡ã€‚Må°±æ˜¯maskçŸ©é˜µï¼Œä»£è¡¨iä¸jæ˜¯å¦è¿é€šï¼ŒMaskçŸ©é˜µæœ‰ï¼š<br><img src="/images/15443248745747.jpg" width="28%" height="50%"></p><p><img src="/images/15443248908199.jpg" width="31%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/15443249388350.jpg" width="50%" height="50%"></p><p>é¦–å…ˆmaskæ‰è‡ªå·±ï¼Œç¬¬äºŒï¼šåˆ†åˆ«maskæ‰forwardå’Œbackwardï¼Œç±»ä¼¼biLSTMï¼Œåªå’Œå‰é¢æˆ–åé¢çš„äº¤äº’ã€‚</p><h3 id="Directional-Self-Attention-Network"><a href="#Directional-Self-Attention-Network" class="headerlink" title="Directional Self-Attention Network"></a>Directional Self-Attention Network</h3><p>åœ¨ä¸Šè¿°ä¸¤ä¸ªæ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæ­¤æ—¶å·²è·å¾—äº†ä¸Šä¸‹æ–‡ç›¸å…³çš„$s_i$ï¼Œå†å¼•å…¥fusion gateï¼š<br><img src="/images/15443250617220.jpg" width="45%" height="50%"></p><p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443250338890.jpg" width="50%" height="50%"></p><p>å°†å‰å‘å’Œåå‘çš„è¡¨ç¤ºæ‹¼æ¥èµ·æ¥ï¼Œè·å¾—æœ€ç»ˆçš„è¡¨ç¤º$[u^{fw};u^{bw}]$ï¼š<br><img src="/images/15443251919096.jpg" width="50%" height="50%"></p><p>å¯¹äºæ‰€è·å¾—çš„æ¯ä¸€ä¸ªè¡¨ç¤ºï¼Œé€šè¿‡source2tokenï¼Œè·å¾—æœ€ç»ˆçš„å¥å­è¡¨ç¤ºã€‚</p><p>è¿™ä¸€ç‚¹è®ºæ–‡ä¹Ÿæåˆ°äº†ï¼Œéå¸¸ç±»ä¼¼bi-LSTMã€‚</p><hr><h2 id="2ï¸âƒ£-Targeted-Dropout"><a href="#2ï¸âƒ£-Targeted-Dropout" class="headerlink" title="2ï¸âƒ£[Targeted Dropout]"></a>2ï¸âƒ£[Targeted Dropout]</h2><p>ä¸€ç§ç½‘ç»œå‰ªææ–¹æ³•ï¼Œæƒ³æ³•ç®€å•æ˜“å®ç°ã€‚<br>ç®€å•è¯´ï¼Œåœ¨æ¯æ¬¡æ›´æ–°æ—¶å¯¹æœ€ä¸é‡è¦çš„weightæˆ–è€…unitè¿›è¡Œéšæœºdropoutã€‚</p><h3 id="Targeted-Dropout"><a href="#Targeted-Dropout" class="headerlink" title="Targeted Dropout"></a>Targeted Dropout</h3><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>ç»™å®šè¾“å…¥Xï¼Œæƒé‡Wï¼Œè¾“å‡ºY Mä¸ºdropoutçš„maskçŸ©é˜µã€‚<br>unit dropoutï¼š<br><img src="/images/15443218016315.jpg" width="22%" height="50%"></p><p>weight dropoutï¼š<br><img src="/images/15443218315803.jpg" width="22%" height="50%"></p><p>ä¹Ÿå³dropæ‰çš„æ˜¯layerä¹‹é—´çš„connectionã€‚</p><h4 id="Magnitude-based-pruning"><a href="#Magnitude-based-pruning" class="headerlink" title="Magnitude-based pruning"></a>Magnitude-based pruning</h4><p>å‰ªæé€šå¸¸å¯¹æƒé‡æœ€å°çš„è¿›è¡Œå‰ªæï¼Œä¹Ÿå³ä¿ç•™topkä¸ªæœ€å¤§çš„æƒé‡ã€‚</p><p>Unit pruningï¼šç›´æ¥å‰ªæ‰çš„æ˜¯ä¸€æ•´åˆ—ï¼Œä¹Ÿå³ä¸€ä¸ªunit<br><img src="/images/15443218793541.jpg" width="43%" height="50%"></p><p>Weight pruningï¼šå¯¹Wçš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå‰ªæã€‚æ³¨æ„æ˜¯å¯¹æ¯è¡Œçš„topkè¿›è¡Œä¿ç•™<br><img src="/images/15443219325533.jpg" width="58%" height="50%"></p><p>å¯ä»¥ç†è§£æˆå¯¹ä¸€ä¸ªunitæ¥è¯´ï¼Œä¿ç•™æœ€é«˜çš„kä¸ªconnectionã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>ç»“åˆdropoutå’Œå‰ªæã€‚<br>ä¸»è¦æ€æƒ³ï¼šé¦–å…ˆé€‰æ‹©N-kæœ€ä¸é‡è¦çš„elementï¼Œç”±äºæˆ‘ä»¬å¸Œæœ›è¿™äº›low-valueçš„å…ƒç´ æœ‰æœºä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜å¾—é‡è¦ï¼Œå› æ­¤æˆ‘ä»¬å¯¹è¿™äº›elementè¿›è¡Œéšæœºdropoutã€‚</p><p>å¼•å…¥targeting proportion Î³å’Œdrop probability Î±ï¼Œäº¦å³ï¼šé€‰æ‹©æœ€ä½çš„Î³|Î¸|ä¸ªweightï¼Œå†æ ¹æ®Î±è¿›è¡Œdropoutã€‚<br>è¿™æ ·åšçš„ç»“æœæ˜¯ï¼šå‡å°‘é‡è¦çš„å­ç½‘ç»œå¯¹ä¸é‡è¦çš„å­ç½‘ç»œçš„ä¾èµ–ã€‚</p><h3 id="é™„å½•"><a href="#é™„å½•" class="headerlink" title="é™„å½•"></a>é™„å½•</h3><p>â‘ dropoutçš„intuitionï¼šå‡å°‘unitä¹‹é—´çš„ç›¸äº’é€‚åº”ã€‚when dropout is applied to a unit, the remaining network can no longer depend on that unitâ€™s contribution to the function and must learn to propagate that unitâ€™s information through a more reliable channelã€‚<br>ä¹Ÿå¯ä»¥ç†è§£æˆï¼šä½¿å¾—unitä¹‹é—´çš„äº¤äº’ä¿¡æ¯è¾¾åˆ°æœ€å¤§ï¼Œåœ¨å¤±å»æŸä¸ªunitçš„æ—¶å€™å½±å“ä¸ä¼šé‚£ä¹ˆå¤§ã€‚</p><p>â‘¡targeted dropout intuitionï¼šthe important subnetwork is completely separated from the unimportant oneã€‚å‡è®¾ä¸€ä¸ªç½‘ç»œç”±ä¸¤ä¸ªä¸ç›¸äº¤çš„å­ç½‘ç»œç»„æˆï¼Œæ¯ä¸ªéƒ½èƒ½è¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œæ€»çš„ç½‘ç»œæ˜¯è¿™ä¸¤ä¸ªç½‘ç»œçš„å¹³å‡ã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸é‡è¦çš„å­ç½‘ç»œè¿›è¡Œdropoutï¼ˆä¹Ÿå³å¾€å­ç½‘ç»œé‡ŒåŠ noiseï¼Œä¼šç ´åè¯¥å­ç½‘ç»œçš„è¾“å‡ºï¼Œç”±äºé‡è¦çš„å­ç½‘ç»œå·²ç»èƒ½å¤Ÿè¾“å‡ºæ­£ç¡®çš„ç»“æœï¼Œå› æ­¤ä¸ºäº†å‡å°‘æŸå¤±ï¼Œæˆ‘ä»¬éœ€è¦å‡å°‘ä¸é‡è¦ç½‘ç»œçš„è¾“å‡ºåˆ°0ï¼Œä¹Ÿå³killæ‰è¯¥å­ç½‘ç»œï¼Œå¹¶ä¸”åŠ å¼ºè¿™ä¸¤ä¸ªç½‘ç»œçš„åˆ†ç¦»ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥èˆå¼ƒå‘¢ï¼Ÿå› ä¸ºæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ‰å¯èƒ½ä¼šæœ‰å˜åŒ–ï¼‰<br>è¿™ä¸ªè§£é‡Šè¿˜æ˜¯æ²¡å®Œå…¨æ‡‚ã€‚</p><hr><h2 id="3ï¸âƒ£-A2-Nets-Double-Attention-Networks"><a href="#3ï¸âƒ£-A2-Nets-Double-Attention-Networks" class="headerlink" title="3ï¸âƒ£[A2-Nets: Double Attention Networks]"></a>3ï¸âƒ£[A2-Nets: Double Attention Networks]</h2><p>å‘è¡¨äºNIPS2018ï¼Œä¸ªäººè®¤ä¸ºå¾ˆæœ‰å¯å‘ã€‚æå‡ºä¸€ç§æ–°çš„attentionæœºåˆ¶ï¼ŒåŸºäºâ€œæ”¶é›†-åˆ†å‘â€çš„æ€æƒ³ï¼Œèƒ½å¤Ÿè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>CNNæœ¬èº«ä¸»è¦æ˜¯æ•è·å±€éƒ¨ç‰¹å¾ä¸å…³ç³»ï¼Œä½†å¯¹äºé•¿è·ç¦»ä¹‹é—´çš„å…³ç³»åªèƒ½é€šè¿‡å †å å¤šå‡ å±‚æ‰èƒ½å®ç°ã€‚ä½†è¿™æ ·éœ€è¦æ›´é«˜çš„è®¡ç®—é‡ï¼Œä¸”å®¹æ˜“è¿‡æ‹Ÿåˆï¼›åŒæ—¶ï¼Œè¿œå¤„çš„ç‰¹å¾å®é™…ä¸Šæ˜¯æ¥è‡ªå¥½å‡ å±‚çš„å»¶è¿Ÿï¼Œå¯¼è‡´æ¨ç†çš„å›°éš¾ã€‚</p><p>é€šè¿‡å°†featureæ”¶é›†èµ·æ¥ï¼Œç„¶ååˆ†å‘ä¸‹å»ï¼Œä½¿å¾—featureä¹‹é—´æœ‰äº¤äº’ï¼Œè®©CNNè·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œèƒ½å¤Ÿæ•è·é•¿è·ç¦»çš„ç‰¹å¾ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15443223814542.jpg" width="80%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/15443224194279.jpg" width="34%" height="50%"></p><p>Xæ˜¯æ‰€æœ‰è¾“å…¥ï¼Œ$v_iæ˜¯$local featureã€‚</p><h4 id="The-First-Attention-Step-Feature-Gathering"><a href="#The-First-Attention-Step-Feature-Gathering" class="headerlink" title="The First Attention Step: Feature Gathering"></a>The First Attention Step: Feature Gathering</h4><p>å¯¹äºä¸¤ä¸ªfeature map A,Bï¼Œæœ‰ï¼š<br><img src="/images/15443225280678.jpg" width="40%" height="50%"></p><p>å…¶ä¸­ï¼š<br><img src="/images/15443226145868.jpg" width="35%" height="50%"></p><p><img src="/images/15443226262919.jpg" width="35%" height="50%"></p><p>å¦‚æœAã€Béƒ½æ¥è‡ªåŒä¸€ä¸ªXï¼Œå°†Bå½’ä¸€åŒ–softmaxï¼Œå°±ç±»ä¼¼transformerçš„attentionã€‚å…¶ä¸­ä¸Šå¼çš„æœ€å³è¾¹æ˜¯å¤–ç§¯çš„å½¢å¼ã€‚</p><p>æˆ‘ä»¬å°†Gæ‹†åˆ†æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/15443226708983.jpg" width="33%" height="50%"><br>åŒæ—¶å°†Bé‡å†™æˆè¡Œå‘é‡å½¢å¼ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15443227241595.jpg" width="22%" height="50%"></p><p>åˆ™ä¼šæœ‰ï¼š<br><img src="/images/15443227868015.jpg" width="28%" height="50%"></p><p>ä¸Šå¼è®©æˆ‘ä»¬æœ‰ä¸€ä¸ªæ–°çš„ç†è§£è§’åº¦ï¼šGå®é™…ä¸Šå°±æ˜¯ a bag of visual primitivesã€‚æ¯ä¸ª$g_i$æ˜¯æ‰€æœ‰local featureåŠ æƒæ±‚å’Œï¼Œå…¶ä¸­$b_i$æ˜¯æ±‚å’Œçš„weightã€‚</p><p>å› æ­¤æˆ‘ä»¬å¯¹Båšsoftmaxï¼Œä¿è¯æƒé‡ä¸º1ï¼š<br><img src="/images/15443228682403.jpg" width="28%" height="50%"></p><h4 id="The-Second-Attention-Step-Feature-Distribution"><a href="#The-Second-Attention-Step-Feature-Distribution" class="headerlink" title="The Second Attention Step: Feature Distribution"></a>The Second Attention Step: Feature Distribution</h4><p>åœ¨è·å¾—äº†å…¨å±€çš„feature Gåï¼Œç°åœ¨æ ¹æ®local featureå»è·å–å…¨å±€featureçš„éƒ¨åˆ†ï¼Œè¿™é€šè¿‡ä¸€ä¸ªæƒé‡æ§åˆ¶ï¼Œä¹Ÿå³$v_i$ï¼ˆlocal feature)çš„æ¯ä¸€ç»´ä½œä¸ºæƒé‡ã€‚å¯ä»¥ä¸å°†local feature $v_i$å½’ä¸€åŒ–ï¼Œä½†å½’ä¸€åŒ–èƒ½æ›´å¥½åœ°convergeã€‚</p><h4 id="The-Double-Attention-Block"><a href="#The-Double-Attention-Block" class="headerlink" title="The Double Attention Block"></a>The Double Attention Block</h4><p>æœ€ç»ˆå¾—åˆ°double attention blockï¼š<br><img src="/images/15443230115907.jpg" width="68%" height="50%"></p><p>æ•´ä¸ªæµç¨‹ï¼š<br><img src="/images/15443230641691.jpg" width="80%" height="50%"></p><p>æ‰€ä»¥å…¶å®æ˜¯æœ‰ä¸‰ä¸ªconvolution layerã€‚</p><p>ä¸Šå¼è¿˜å¯ä»¥å†™æˆï¼š<br><img src="/images/15443232642402.jpg" width="70%" height="50%"><br>æ•°å­¦ä¸Šç­‰ä»·ï¼Œä½†è®¡ç®—ä¸Šå·®å¾ˆå¤šã€‚ç¬¬ä¸€ä¸ªå¼å­ä¼šæœ‰æ›´ä½çš„å¤æ‚åº¦ã€‚</p><h3 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h3><p>è™½ç„¶ç”¨äº†attentionï¼Œä½†è¿™é‡Œå’ŒTransformerè¿˜æ˜¯æœ‰éå¸¸å¤§çš„åŒºåˆ«çš„ã€‚Transformeræ¯ä¸ªå…ƒç´ éƒ½å’Œå…¶ä»–å…ƒç´ æœ‰äº¤äº’ï¼Œé€šè¿‡ç›´æ¥çš„è®¡ç®—å¾—åˆ°æƒé‡ã€‚è€Œè¿™è¾¹çš„æƒé‡ç”±featureæœ¬èº«æ¥å†³å®šã€‚å¹¶æ²¡æœ‰ç›´æ¥çš„äº¤äº’ã€‚</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> Dropout </tag>
            
            <tag> DiSAN </tag>
            
            <tag> Targeted Dropout </tag>
            
            <tag> double attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†14</title>
      <link href="/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8614/"/>
      <url>/2018/12/09/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8614/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchçš„tensorå’ŒTensoræ˜¯æœ‰åŒºåˆ«çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a = torch.tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯æ ‡é‡ï¼Œsizeä¸º[]</span></span><br><span class="line">b = torch.Tensor(<span class="number">2</span>)  <span class="comment"># æ˜¯å‘é‡ï¼Œsizeä¸º[2]</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯17</title>
      <link href="/2018/12/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D17/"/>
      <url>/2018/12/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D17/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è™ç¾äºº"><a href="#1ï¸âƒ£è™ç¾äºº" class="headerlink" title="1ï¸âƒ£è™ç¾äºº"></a>1ï¸âƒ£è™ç¾äºº</h3><p>[å®‹] å¶æ¢¦å¾—<br>è½èŠ±å·²ä½œé£å‰èˆï¼Œåˆé€é»„æ˜é›¨ã€‚æ™“æ¥åº­é™¢åŠæ®‹çº¢ï¼ŒæƒŸæœ‰æ¸¸ä¸ï¼Œåƒä¸ˆè¢…æ™´ç©ºã€‚<br>æ®·å‹¤èŠ±ä¸‹åŒæºæ‰‹ï¼Œæ›´å°½æ¯ä¸­é…’ã€‚ç¾äººä¸ç”¨æ•›è›¾çœ‰ï¼Œ<strong>æˆ‘äº¦å¤šæƒ…ï¼Œæ— å¥ˆé…’é˜‘æ—¶</strong>ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†13</title>
      <link href="/2018/12/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8613/"/>
      <url>/2018/12/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8613/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-attention"><a href="#1ï¸âƒ£-attention" class="headerlink" title="1ï¸âƒ£[attention]"></a>1ï¸âƒ£[attention]</h3><p>æ‰€æœ‰attentionçš„æ€»ç»“ï¼š<br><img src="/images/15437180657954.jpg" width="70%" height="50%"><br><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention!</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>â‘ torch.no_gradèƒ½å¤Ÿæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œmodel.evalä¸èƒ½ã€‚å› ä¸ºevalä¸ä¼šå…³é—­å†å²è¿½è¸ªã€‚</p><blockquote><p>model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval model instead of training mode.<br>torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).</p></blockquote><p>Reference:<br><a href="https://discuss.pytorch.org/t/does-model-eval-with-torch-set-grad-enabled-is-train-have-the-same-effect-for-grad-history/17183/3" target="_blank" rel="noopener">Does model.eval() &amp; with torch.set_grad_enabled(is_train) have the same effect for grad history?</a></p><p><a href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615" target="_blank" rel="noopener">â€˜model.eval()â€™ vs â€˜with torch.no_grad()â€™</a></p><p>â‘¡torch.full(â€¦) returns a tensor filled with value.</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•11</title>
      <link href="/2018/12/02/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9511/"/>
      <url>/2018/12/02/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9511/</url>
      
        <content type="html"><![CDATA[<h2 id="â‘ "><a href="#â‘ " class="headerlink" title="â‘ "></a>â‘ </h2><p>éœ€æ±‚ï¼šå¯¹äºä¸¤ä¸ªå‘é‡$a$ã€$b$ï¼Œ$a,b \in R^d$ï¼Œå®šä¹‰ä¸€ç§å‡æ³•ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">a-b=M</script><p>å…¶ä¸­$M \in R^{d\times d}$ï¼Œ$M_{ij}=a_i-b_j$</p><p>åœ¨ä»£ç ä¸­å®é™…çš„ç»´åº¦ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.rand(batch_size,sequence_len,dim)</span><br><span class="line">b=torch.rand(batch_size,sequence_len,dim)</span><br></pre></td></tr></table></figure><p>æ–¹æ³•â‘ ï¼šforå¾ªç¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">M=torch.zeros(bz,seq_len,seq_len)</span><br><span class="line"><span class="keyword">for</span> b_i <span class="keyword">in</span> range(bz):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(seq_len):</span><br><span class="line">            M_ij=torch.norm(a[b_i][i]-b[b_i][j])</span><br><span class="line">            M[b][i][j]=M_ij</span><br></pre></td></tr></table></figure><p>æ–¹æ³•â‘¡ï¼šçŸ©é˜µè¿ç®—</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=a.unsqueeze(<span class="number">2</span>)  <span class="comment"># bz,seq_len,1,dim</span></span><br><span class="line">b=b.unsqueeze(<span class="number">1</span>)  <span class="comment"># bz,1,seq_lens,dim</span></span><br><span class="line">M=torch.norm(a-b,dim=<span class="number">-1</span>)   <span class="comment"># will broadcast</span></span><br></pre></td></tr></table></figure><hr><h2 id="â‘¡"><a href="#â‘¡" class="headerlink" title="â‘¡"></a>â‘¡</h2><p>éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªmaskçŸ©é˜µï¼Œæ¯ä¸€è¡Œæœ‰ä¸€æ®µè¿ç»­çš„ä½ç½®å¡«å……1ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¡«å……1çš„å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®éƒ½ä¸åŒã€‚å…·ä½“æ¥è¯´ï¼Œå…ˆç”Ÿæˆä¸€ä¸ªä¸­å¿ƒä½ç½®centerï¼Œåˆ™å¼€å§‹ä½ç½®ä¸ºcenter-windowï¼›ç»“æŸä½ç½®ä¸ºcenter+windowã€‚å…¶ä¸­å¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®ä¸èƒ½è¶Šç•Œï¼Œä¹Ÿå³ä¸å°äº0å’Œå¤§äºè¡Œçš„æ€»é•¿åº¦ã€‚<br>å¦‚ï¼š<br><img src="/images/15437208061953.jpg" width="25%" height="50%"></p><p>æ€è·¯ï¼š<br>â‘ å…ˆç”Ÿæˆnè¡Œæ¯è¡Œå¯¹åº”çš„éšæœºä¸­å¿ƒä½ç½®ï¼Œç„¶åå†è·å¾—å·¦å’Œå³è¾¹ç•Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">centers=torch.randint(low=<span class="number">0</span>,high=query_len,size=(query_len,),dtype=torch.long)</span><br><span class="line"></span><br><span class="line">left=centers-self.window</span><br><span class="line">left=torch.max(left,torch.LongTensor([<span class="number">0</span>])).unsqueeze(<span class="number">1</span>)   <span class="comment"># query_len,1</span></span><br><span class="line"></span><br><span class="line">right=centers+self.window</span><br><span class="line">right=torch.min(right,torch.LongTensor([query_len<span class="number">-1</span>])).unsqueeze(<span class="number">1</span>)  <span class="comment"># query_len,1</span></span><br></pre></td></tr></table></figure><p>â‘¡ç”Ÿæˆä¸€ä¸ªæ¯è¡Œéƒ½ç”¨[0,n-1]å¡«å……çš„çŸ©é˜µï¼Œ[0,n-1]è¡¨ç¤ºçš„æ˜¯è¯¥å…ƒç´ çš„indexï¼Œäº¦å³ï¼š<br><img src="/images/15437212363142.jpg" width="25%" height="50%"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br></pre></td></tr></table></figure><p>â‘¢åˆ©ç”¨&lt;=å’Œ&gt;=è·å¾—ä¸€ä¸ªå·¦è¾¹ç•Œå’Œå³è¾¹ç•ŒçŸ©é˜µï¼Œå·¦è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å·¦è¾¹ç•Œçš„å·¦è¾¹éƒ½æ˜¯å¡«å……çš„1ï¼›å³è¾¹ç•ŒçŸ©é˜µè¡¨ç¤ºåœ¨è¯¥å³è¾¹ç•Œå³è¾¹éƒ½æ˜¯å¡«å……çš„1ã€‚å†è¿›è¡Œå¼‚æˆ–æ“ä½œã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">range_matrix=torch.range(<span class="number">0</span>,query_len<span class="number">-1</span>,dtype=torch.long).unsqueeze(<span class="number">0</span>).expand(query_len,<span class="number">-1</span>)  <span class="comment"># query_len,query_len</span></span><br><span class="line">left_matrix=range_matrix&lt;=left</span><br><span class="line">right_matrix=range_matrix&lt;=right</span><br><span class="line">final_matrix=left_matrix^right_matrix</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡7</title>
      <link href="/2018/12/02/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%877/"/>
      <url>/2018/12/02/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%877/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Convolutional-Self-Attention-Network"><a href="#1ï¸âƒ£-Convolutional-Self-Attention-Network" class="headerlink" title="1ï¸âƒ£[Convolutional Self-Attention Network]"></a>1ï¸âƒ£[Convolutional Self-Attention Network]</h2><p>å¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œå¼•å…¥CNNçš„local-biasï¼Œä¹Ÿå³å¯¹queryçš„é‚»è¿‘è¯è¿›è¡Œattentionè€Œä¸æ˜¯æ‰€æœ‰è¯ï¼›å°†self-attentionæ‰©å±•åˆ°2Dï¼Œä¹Ÿå³è®©ä¸åŒçš„headä¹‹é—´ä¹Ÿæœ‰attentionäº¤äº’ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£the normalization in Softmax may inhibits the attention to neighboring information ä¹Ÿå³é‚»å±…çš„ä¿¡æ¯æ›´é‡è¦ï¼Œè¦åŠ å¼ºé‚»å±…çš„é‡è¦æ€§</p><p>2ï¸âƒ£features can be better captured by modeling dependencies across different channels å¯¹äºä¸åŒçš„channel/headä¹Ÿå¢åŠ ä»–ä»¬ä¹‹é—´çš„äº¤äº’ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p><img src="/images/15437126353758.jpg" width="80%" height="50%"></p><p>å¯¹äº1Dçš„convolutionï¼šé€‰å–ä¸­å¿ƒè¯å‘¨å›´ä¸€ä¸ªwindowï¼š<br><img src="/images/15437128149700.jpg" width="28%" height="50%"></p><p>å¯¹äº2Dçš„convolutionï¼Œåˆ™æœ‰ï¼š<br><img src="/images/15437128476725.jpg" width="45%" height="50%"></p><p>åœ¨å…·ä½“å®è·µä¸­ï¼Œåªå¯¹å‰ä¸‰å±‚æ·»åŠ local biasï¼Œè¿™æ˜¯å› ä¸ºmodeling localityåœ¨åº•å±‚æ›´æœ‰æ•ˆï¼Œå¯¹äºé«˜å±‚åº”è¯¥æ•è·æ›´è¿œçš„ä¿¡æ¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks"><a href="#2ï¸âƒ£-Modeling-Localness-for-Self-Attention-Networks" class="headerlink" title="2ï¸âƒ£[Modeling Localness for Self-Attention Networks]"></a>2ï¸âƒ£[Modeling Localness for Self-Attention Networks]</h2><p>å’Œä¸Šæ–‡ä¸€æ ·ï¼Œå¼•å…¥local biaså¯¹self-attentionè¿›è¡Œæ”¹è¿›ï¼Œä»è€Œæå‡äº†ç¿»è¯‘è¡¨ç°ã€‚å’Œä¸Šæ–‡æ˜¯åŒä¸€ä½œè€…ï¼Œå‘åœ¨EMNLPä¸Šã€‚</p><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>1ï¸âƒ£self-attentionå­˜åœ¨çš„é—®é¢˜ï¼šè™½ç„¶èƒ½å¤Ÿå¢åŠ é•¿ç¨‹å…³æ³¨ï¼Œä½†å› æ­¤ä¼šå¯¼è‡´æ³¨æ„åŠ›çš„åˆ†æ•£ï¼Œå¯¹é‚»å±…çš„ä¿¡å·ä¼šå¿½ç•¥ã€‚å®è·µè¯æ˜ï¼Œå¯¹local biaså»ºæ¨¡åœ¨self-attentionæœ‰æå‡ã€‚</p><p>2ï¸âƒ£ä»ç›´è§‰ä¸Šæ¥è¯´ï¼Œåœ¨ç¿»è¯‘æ¨¡å‹ä¸­ï¼Œå½“ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jæœ‰å¯¹é½å…³ç³»æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›è¯ièƒ½åŒæ—¶å¯¹è¯jå‘¨å›´çš„è¯è¿›è¡Œå¯¹é½ï¼Œä½¿å¾—èƒ½å¤Ÿæ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚phraseçš„ä¿¡æ¯ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åœ¨åŸæ¥çš„å…¬å¼ä¸Šæ·»åŠ Gï¼š<br><img src="/images/15437133932791.jpg" width="45%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/15437134105761.jpg" width="70%" height="50%"></p><p>Gæ˜¯ä¸€ä¸ªalignment position matrixï¼ˆå¯¹é½ä½ç½®çŸ©é˜µï¼‰ï¼Œå…ƒç´ ijä»£è¡¨ç›®æ ‡è¯iä¸æºè¯­è¨€è¯jä¹‹é—´çš„ç´§å¯†ç¨‹åº¦ã€‚<br>æˆ‘ä»¬æ¯æ¬¡æ ¹æ®ç›®æ ‡è¯ié¢„æµ‹ä¸€ä¸ªæºè¯­è¨€çš„ä¸­å¿ƒè¯ï¼Œåˆ™$G_{ij}$åˆ™ä¸ºï¼š</p><p><img src="/images/15437135769000.jpg" width="23%" height="50%"></p><p>$P_i$å°±æ˜¯å¯¹äºç›®æ ‡è¯jè€Œè¨€æºè¯­è¨€çš„ä¸­å¿ƒè¯ã€‚ $\sigma$ æ‰‹åŠ¨è®¾å®šï¼Œé€šå¸¸æ˜¯$\frac{D}{2}$ï¼ŒDä»£è¡¨çª—å£å¤§å°ã€‚</p><p>ä¹Ÿå³æœ€ç»ˆæˆ‘ä»¬éœ€è¦è®¡ç®—çš„æ˜¯ï¼Œä¸­å¿ƒè¯$P_i$å’Œçª—å£$D$ã€‚</p><h4 id="è®¡ç®—-P-i"><a href="#è®¡ç®—-P-i" class="headerlink" title="è®¡ç®—$P_i$"></a>è®¡ç®—$P_i$</h4><p>åˆ©ç”¨å¯¹åº”çš„ç›®æ ‡è¯içš„queryå³å¯ï¼š<br><img src="/images/15437138514005.jpg" width="28%" height="50%"><br>$p_i$æ˜¯ä¸€ä¸ªå®æ•°ã€‚</p><h4 id="è®¡ç®—window-size"><a href="#è®¡ç®—window-size" class="headerlink" title="è®¡ç®—window size"></a>è®¡ç®—window size</h4><p>â‘ å›ºå®šçª—å£ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªè¶…å‚ã€‚</p><p>â‘¡Layer-Speciï¬c Window<br>å°†è¯¥å±‚æ‰€æœ‰çš„keyå¹³å‡ï¼Œè®¡ç®—å‡ºä¸€ä¸ªå…±äº«çš„window sizeï¼š<br><img src="/images/15437139914993.jpg" width="28%" height="50%"></p><p>â‘¢Query-Speciï¬c Window<br>æ¯ä¸ªqueryéƒ½æœ‰è‡ªå·±çš„window size<br><img src="/images/15437140367683.jpg" width="30%" height="50%"></p><h3 id="å®éªŒåˆ†æä¸ç»“è®º"><a href="#å®éªŒåˆ†æä¸ç»“è®º" class="headerlink" title="å®éªŒåˆ†æä¸ç»“è®º"></a>å®éªŒåˆ†æä¸ç»“è®º</h3><p>â‘ å°†model localityç”¨äºä½å±‚æ•ˆæœä¼šæ›´å¥½ï¼Œè¿™æ˜¯å› ä¸ºä½å±‚å¯¹ç›¸é‚»å»ºæ¨¡ï¼Œè€Œè¶Šé«˜å±‚è¶Šå…³æ³¨æ›´è¿œçš„è¯ã€‚</p><p><img src="/images/15437141387365.jpg" width="50%" height="50%"></p><p>â‘¡å°†model localityæ”¾åœ¨encoderå’Œencoder-decoderéƒ¨åˆ†ä¼šæ›´å¥½ï¼ˆtransformeræœ‰ä¸‰ä¸ªåœ°æ–¹å¯ä»¥æ”¾ï¼‰</p><p><img src="/images/15437141719564.jpg" width="50%" height="50%"><br>å› ä¸ºdecoderæœ¬èº«å°±å€¾å‘å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œå¦‚æœç»§ç»­è®©å…¶å…³æ³¨ä¸´è¿‘çš„è¯ï¼Œé‚£ä¹ˆå°±éš¾ä»¥è¿›è¡Œé•¿ç¨‹å»ºæ¨¡ã€‚</p><p>â‘¢è¶Šé«˜å±‚ï¼Œwindow sizeï¼ˆscopeï¼‰è¶Šå¤§ã€‚</p><p><img src="/images/15437142078121.jpg" width="70%" height="50%"></p><p>ä¹Ÿå³ï¼Œåœ¨åº•å±‚æ›´å€¾å‘äºæ•è·é‚»è¿‘è¯çš„è¯­ä¹‰ï¼›è€Œé«˜å±‚å€¾å‘æ•è·é•¿ç¨‹ä¾èµ–ã€‚ä½†è¿™ä¸åŒ…æ‹¬ç¬¬ä¸€å±‚ï¼Œç¬¬ä¸€å±‚æ˜¯embeddingï¼Œè¿˜æ²¡æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤å€¾å‘äºæ•è·å…¨å±€ä¿¡æ¯ã€‚</p><hr><h2 id="3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation"><a href="#3ï¸âƒ£-Effective-Approaches-to-Attention-based-Neural-Machine-Translation" class="headerlink" title="3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]"></a>3ï¸âƒ£[Effective Approaches to Attention-based Neural Machine Translation]</h2><p>æå‡ºä¸¤ç§attentionæœºåˆ¶çš„ç¿»è¯‘æ¨¡å‹ï¼Œglobalå’Œlocalã€‚</p><p>æœ¬æ–‡ä¸åŸç‰ˆçš„ç¿»è¯‘æ¨¡å‹ç•¥æœ‰ä¸åŒï¼š<br><img src="/images/15437143753188.jpg" width="40%" height="50%"><br><img src="/images/15437143893418.jpg" width="30%" height="50%"></p><p>cæ˜¯contextï¼Œhæ˜¯decodeçš„éšå±‚ã€‚</p><h3 id="global-attention"><a href="#global-attention" class="headerlink" title="global attention"></a>global attention</h3><p><img src="/images/15437144396133.jpg" width="45%" height="50%"></p><p>è®¡ç®—attentionåˆ†æ•°ï¼š<br><img src="/images/15437145076271.jpg" width="40%" height="50%"></p><p>scoreæœ‰å¤šç§é€‰æ‹©ï¼š<br><img src="/images/15437145588496.jpg" width="52%" height="50%"></p><p>æ³¨æ„åˆ°è¯¥æ¨¡å‹ä¸ç¬¬ä¸€ä¸ªæå‡ºattention basedçš„æ¨¡å‹ä¸åŒä¹‹å¤„ï¼š<br>$h_t -&gt; a_t -&gt; c_t -&gt; \tilde{h_t}$<br>åŸç‰ˆæ˜¯ï¼š<br>$h_{t-1} -&gt; a_t -&gt; c_t -&gt; h_t$</p><h3 id="local-attention"><a href="#local-attention" class="headerlink" title="local attention"></a>local attention</h3><p><img src="/images/15437147612512.jpg" width="45%" height="50%"></p><p>ç”±äºglobal attentionè®¡ç®—ä»£ä»·é«˜ï¼Œä¸”å¯¹äºé•¿å¥æ•ˆæœä¸å¥½ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€éƒ¨åˆ†æ¥åšattentionã€‚<br>é¦–å…ˆç”Ÿæˆä¸€ä¸ªå¯¹é½ä½ç½®$p_t$ï¼Œå†é€‰æ‹©ä¸€ä¸ªçª—å£$[p_t - D,p_t + D]$ï¼Œå…¶ä¸­Dæ˜¯è¶…å‚ã€‚</p><p>å¦‚ä½•è·å¾—$p_t$?<br>â‘ ç›´æ¥å‡è®¾$p_t=t$ï¼Œä¹Ÿå³sourceå’Œtargetçš„ä½ç½®å¤§è‡´ä¸€ä¸€å¯¹åº”ã€‚</p><p>â‘¡åšé¢„æµ‹ï¼š<br><img src="/images/15437150115321.jpg" width="43%" height="50%"><br>å…¶ä¸­Sæ˜¯sourceçš„å¥å­é•¿åº¦ã€‚</p><p>æ¥ç€ï¼Œä»¥$p_t$ä¸ºä¸­å¿ƒï¼Œæ·»åŠ ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚æœ€ç»ˆattentionè®¡ç®—å…¬å¼ï¼š<br><img src="/images/15437150721538.jpg" width="50%" height="50%"></p><p>å…¶ä¸­alignå’Œä¸Šé¢ä¸€è‡´ï¼š<br><img src="/images/15437151043916.jpg" width="45%" height="50%"></p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå°†ä½ç½®ä¿¡æ¯ä¹Ÿè€ƒè™‘è¿›æ¥ã€‚</p><h3 id="Input-feeding-Approach"><a href="#Input-feeding-Approach" class="headerlink" title="Input-feeding Approach"></a>Input-feeding Approach</h3><p>motivationï¼šåœ¨ä¸‹ä¸€æ¬¡çš„alignmentï¼ˆä¹Ÿå°±æ˜¯è®¡ç®—attentionï¼‰ä¹‹å‰ï¼Œåº”å½“çŸ¥é“ä¹‹å‰çš„alignmentæƒ…å†µï¼Œæ‰€ä»¥åº”å½“ä½œä¸ºè¾“å…¥ä¿¡æ¯ä¼ è¿›ä¸‹ä¸€å±‚ï¼š<br><img src="/images/15437152269151.jpg" width="50%" height="50%"></p><p>æ³¨æ„è¿™é‡Œå’ŒBahdanauçš„ä¸åŒã€‚Bahdanauæ˜¯ç›´æ¥ç”¨ä¸Šä¸‹æ–‡å»æ„é€ éšå±‚ã€‚è¿™é‡Œæå‡ºçš„æ¨¡å‹ç›¸å¯¹æ›´ä¸ºé€šç”¨ï¼Œä¹Ÿå¯ä»¥è¢«åº”ç”¨äºéattentionçš„æ¨¡å‹ä¸­ï¼ˆä¹Ÿå°±æ˜¯æ¯æ¬¡å°†encoderçš„æœ€åä¸€å±‚ä½œä¸ºè¾“å…¥åœ¨æ¯ä¸ªtime stepéƒ½è¾“å…¥ï¼‰</p><hr><h2 id="4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks"><a href="#4ï¸âƒ£-Towards-Linear-Time-Neural-Machine-Translation-with-Capsule-Networks" class="headerlink" title="4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]"></a>4ï¸âƒ£[Towards Linear Time Neural Machine Translation with Capsule Networks]</h2><p>æ€æƒ³ï¼šåˆ©ç”¨capsuleæå‰ç”Ÿæˆsource sentenceçš„å›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œåœ¨decodeçš„æ—¶å€™ç›´æ¥ä½¿ç”¨ï¼Œè€Œä¸éœ€è¦attentionï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´NMTçš„ç›®çš„ã€‚</p><p>Motivationï¼šattention-basedçš„NMTæ—¶é—´å¤æ‚åº¦ä¸º$|S|\times |T|$ï¼Œè€Œæœ¬æ–‡å¸Œæœ›èƒ½å¤Ÿå°†NMTå‡å°‘åˆ°çº¿æ€§æ—¶é—´ã€‚è€Œä¼ ç»Ÿä¸åŠ attentionçš„NMTé€šå¸¸ä½¿ç”¨LSTMæœ€åä¸€å±‚éšå±‚ä½œä¸ºæºè¯­è¨€çš„encodeä¿¡æ¯ä¼ å…¥decodeï¼Œä½†è¿™æ ·çš„ä¿¡æ¯å¹¶ä¸èƒ½å¾ˆå¥½åœ°ä»£è¡¨æ•´ä¸ªå¥å­ï¼Œå› æ­¤æœ¬æ–‡ä½¿ç”¨capsuleä½œä¸ºæå–source sentenceä¿¡æ¯çš„æ–¹æ³•ï¼Œåˆ©ç”¨capsuleç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºï¼Œç›´æ¥ä¼ å…¥decodeç«¯ï¼Œä»¥è¾¾åˆ°çº¿æ€§æ—¶é—´çš„ç›®çš„ã€‚</p><p><img src="/images/15437164176973.jpg" width="50%" height="50%"></p><h3 id="é—®é¢˜å®šä¹‰"><a href="#é—®é¢˜å®šä¹‰" class="headerlink" title="é—®é¢˜å®šä¹‰"></a>é—®é¢˜å®šä¹‰</h3><p>å¯¹äºembeddingï¼š<br><img src="/images/15437164440500.jpg" width="37%" height="50%"><br>å¸Œæœ›èƒ½å¤Ÿè½¬æ¢æˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºCï¼š<br><img src="/images/15437164654931.jpg" width="37%" height="50%"></p><p>æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¸€ä¸ªåŒå‘çš„LSTMï¼š<br><img src="/images/15437165067165.jpg" width="28%" height="50%"></p><p>ä¸€ç§ç®€å•çš„è·å–Cçš„æ–¹æ³•ï¼š<br><img src="/images/15437165382025.jpg" width="30%" height="50%"><br>å…¶ä¸­$h_1$å’Œ$h_L$æœ‰äº’è¡¥å…³ç³»ã€‚</p><p>æœ¬æ–‡ä½¿ç”¨capsuleæå–æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚</p><p>åœ¨decodeé˜¶æ®µï¼Œç”±äºæ‹¥æœ‰å›ºå®šè¡¨ç¤ºï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦attentionï¼š</p><p><img src="/images/15437166827481.jpg" width="35%" height="50%"><br><img src="/images/15437167374470.jpg" width="37%" height="50%"></p><p>æ€»ä½“æ¶æ„ï¼š<br><img src="/images/15437167607085.jpg" width="60%" height="50%"></p><h3 id="Aggregation-layers-with-Capsule-Networks"><a href="#Aggregation-layers-with-Capsule-Networks" class="headerlink" title="Aggregation layers with Capsule Networks"></a>Aggregation layers with Capsule Networks</h3><p><img src="/images/15437168111687.jpg" width="65%" height="50%"><br>å®é™…ä¸Šå°±æ˜¯dynamic routingé‚£ä¸€å¥—ï¼Œå¯¹ä¿¡æ¯è¿›è¡Œæå–ï¼ˆè®ºæ–‡å…¬å¼æœ‰è¯¯å°±ä¸è´´å›¾äº†ï¼‰</p><p>ç®—æ³•ï¼š<br><img src="/images/15437168668191.jpg" width="55%" height="50%"></p><p>æœ€ç»ˆè·å¾—äº†ï¼š<br><img src="/images/15437168888967.jpg" width="27%" height="50%"></p><hr><h2 id="5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#5ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>5ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>é‡è¯»äº†ä¸€éã€‚<br>ä»‹ç»ä¸€ç§æ–°å‹çš„dropoutï¼Œå¯ç”¨äºå·ç§¯å±‚æé«˜è¡¨ç°ã€‚é€šè¿‡å¤§é‡çš„å®éªŒå¾—å‡ºè®¸å¤šæœ‰æ„ä¹‰çš„ç»“è®ºã€‚æœ¬æ–‡å‘è¡¨äºNIPS2018ã€‚</p><h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><p>ç”±äºå·ç§¯å±‚çš„featureç›¸äº’ä¹‹é—´æœ‰è”ç³»ï¼Œå³ä½¿ä½¿ç”¨äº†dropoutï¼Œä¿¡æ¯ä¹Ÿèƒ½å¤Ÿæ ¹æ®å‘¨å›´çš„featureä¼ åˆ°ä¸‹ä¸€å±‚ã€‚å› æ­¤ä½¿ç”¨dropblockï¼Œä¸€æ¬¡å°†ä¸€ä¸ªæ–¹å—å†…çš„éƒ½dropæ‰ã€‚</p><p><img src="/images/15437170173072.jpg" width="50%" height="50%"></p><h3 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h3><p><img src="/images/15437170840909.jpg" width="80%" height="50%"></p><p>å…¶ä¸­æœ‰ä¸¤ä¸ªè¶…å‚ï¼šâ‘ block_sizeè¡¨ç¤ºå—çš„å¤§å°ï¼›Î³è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªunitè¦dropæ‰ï¼Œç­‰ä»·ä¼ ç»Ÿçš„dropoutçš„pã€‚å½“block_size=1æ—¶ç­‰ä»·dropoutï¼›å½“block size=æ•´ä¸ªfeature mapï¼Œç­‰ä»·äºspatial dropoutã€‚</p><p>åœ¨å®è·µä¸­ï¼Œé€šè¿‡ä»¥ä¸‹å…¬å¼è®¡ç®—Î³ï¼š<br><img src="/images/15437172746112.jpg" width="55%" height="50%"></p><p>(why? é€šè¿‡è®¡ç®—æœŸæœ›çš„æ–¹å¼å°†ä¼ ç»Ÿdropoutçš„keep_probä¸å½“å‰çš„Î³è”ç³»èµ·æ¥ï¼Œå¾—åˆ°ä¸€ä¸ªç­‰å¼ï¼Œæ•´ç†å³å¯è·å¾—ä¸Šå¼ï¼‰</p><p>åœ¨å®éªŒä¸­ï¼Œè¿˜å¯ä»¥é€æ¸å‡å°keep_probä½¿å¾—æ›´åŠ é²æ£’æ€§ã€‚</p><h3 id="å®éªŒ-amp-ç»“è®º"><a href="#å®éªŒ-amp-ç»“è®º" class="headerlink" title="å®éªŒ&amp;ç»“è®º"></a>å®éªŒ&amp;ç»“è®º</h3><p>â‘ æ•ˆæœ:dropout&lt; spatial dropout &lt; dropblock</p><p>â‘¡dropblockèƒ½æœ‰æ•ˆå»æ‰semantic information</p><p>â‘¢dropblockæ˜¯ä¸€ä¸ªæ›´åŠ å¼ºçš„regularization</p><p>â‘£ä½¿ç”¨dropblockçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿå­¦ä¹ æ›´å¤šçš„åŒºåŸŸï¼Œè€Œä¸æ˜¯åªä¸“æ³¨äºä¸€ä¸ªåŒºåŸŸ<br><img src="/images/15437174940381.jpg" width="70%" height="50%"></p><p>å¯¹äºresnetï¼Œç›´æ¥å°†dropblockåº”ç”¨äºæ·»åŠ å®Œskip connectionåçš„featureèƒ½å¤Ÿæœ‰æ›´é«˜çš„è¡¨ç°ã€‚</p><hr><h2 id="6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling"><a href="#6ï¸âƒ£-Contextual-String-Embeddings-for-Sequence-Labeling" class="headerlink" title="6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]"></a>6ï¸âƒ£[Contextual String Embeddings for Sequence Labeling]</h2><p>æå‡ºä¸€ç§å»ºç«‹åœ¨characteråŸºç¡€ä¸Šçš„æ–°å‹çš„ä¸Šä¸‹æ–‡embedding(contextualized embeddingï¼‰ã€‚ç”¨äºsequence labelingã€‚æœ¬æ–‡å‘è¡¨äºcoling2018ã€‚</p><h3 id="æ–¹æ³•-2"><a href="#æ–¹æ³•-2" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æ•´ä½“æ¶æ„ï¼š<br><img src="/images/15437175991019.jpg" width="100%" height="50%"></p><p>é¦–å…ˆå°†characterä½œä¸ºåŸºæœ¬å•ä½ï¼Œè¿‡ä¸€ä¸ªåŒå‘LSTMï¼Œè¿›è¡Œlanguage modelçš„å»ºæ¨¡ã€‚</p><p>å¦‚ä½•æå–ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼š<br><img src="/images/15437176650871.jpg" width="100%" height="50%"><br>æå–å‰å‘LSTMä¸­è¯¥è¯çš„æœ€åä¸€ä¸ªcharacterçš„åä¸€ä¸ªhidden stateï¼Œä»¥åŠåå‘LSTMä¸­ç¬¬ä¸€ä¸ªè¯çš„å‰ä¸€ä¸ªhidden stateï¼Œ å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚æœ€ç»ˆæ‹¼èµ·æ¥å³å¯ï¼š<br><img src="/images/15437177090697.jpg" width="28%" height="50%"><br>å› æ­¤è¯¥è¯ä¸ä»…ä¸è¯å†…éƒ¨çš„characterç›¸å…³ï¼Œè¿˜è·Ÿå…¶å‘¨å›´çš„contextæœ‰å…³ã€‚</p><p>sequence labelingæˆ‘ä¸æ„Ÿå…´è¶£ï¼Œè¯¥éƒ¨åˆ†æ²¡çœ‹ã€‚</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>ç›¸æ¯”word levelçš„language modelï¼Œcharacter-levelç‹¬ç«‹äºtokenizationå’Œfixed vocabularyï¼Œæ¨¡å‹æ›´å®¹æ˜“è¢«è®­ç»ƒï¼Œå› ä¸ºè¯è¡¨å°ä¸”è®­ç»ƒæ—¶é—´çŸ­ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> capsule </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> self-attention </tag>
            
            <tag> NMT </tag>
            
            <tag> locality modeling </tag>
            
            <tag> dropblock </tag>
            
            <tag> contextualized embedding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯16</title>
      <link href="/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D16/"/>
      <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D16/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è©è¨è›®"><a href="#1ï¸âƒ£è©è¨è›®" class="headerlink" title="1ï¸âƒ£è©è¨è›®"></a>1ï¸âƒ£è©è¨è›®</h3><p>[äº”ä»£åå›½] æç…œ<br>äººç”Ÿæ„æ¨ä½•èƒ½å…ï¼Œé”€é­‚ç‹¬æˆ‘æƒ…ä½•é™ï¼æ•…å›½æ¢¦é‡å½’ï¼Œè§‰æ¥åŒæ³ªå‚ã€‚<br>é«™æ¥¼è°ä¸ä¸Šï¼Ÿé•¿è®°ç§‹æ™´æœ›ã€‚<strong>å¾€äº‹å·²æˆç©ºï¼Œè¿˜å¦‚ä¸€æ¢¦ä¸­</strong>ã€‚</p><p>è§‰(jue)æ¥ï¼šé†’æ¥ã€‚</p><hr><h3 id="2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"><a href="#2ï¸âƒ£å—ä¹¡å­-Â·-å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·" class="headerlink" title="2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·"></a>2ï¸âƒ£å—ä¹¡å­ Â· å’Œæ¨å…ƒç´ ï¼Œæ—¶ç§»å®ˆå¯†å·</h3><p>[å®‹] è‹è½¼<br>ä¸œæ­¦æœ›é¦€æ­ï¼Œäº‘æµ·å¤©æ¶¯ä¸¤æ³èŒ«ã€‚<strong>ä½•æ—¥åŠŸæˆåé‚äº†ï¼Œè¿˜ä¹¡ï¼Œé†‰ç¬‘é™ªå…¬ä¸‰ä¸‡åœº</strong>ã€‚<br><strong>ä¸ç”¨è¯‰ç¦»è§ï¼Œç—›é¥®ä»æ¥åˆ«æœ‰è‚ </strong>ã€‚ä»Šå¤œé€å½’ç¯ç«å†·ï¼Œæ²³å¡˜ï¼Œå •æ³ªç¾Šå…¬å´å§“æ¨ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%BB%8F%E5%8E%86%E4%B8%96%E7%95%8C%E4%B8%8A%E6%89%80%E6%9C%89%E7%83%AD%E9%97%B9/"/>
      <url>/2018/12/01/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%BB%8F%E5%8E%86%E4%B8%96%E7%95%8C%E4%B8%8A%E6%89%80%E6%9C%89%E7%83%AD%E9%97%B9/</url>
      
        <content type="html"><![CDATA[<p>äººä¸å¯èƒ½ç»å†ä¸–ç•Œä¸Šæ‰€æœ‰çƒ­é—¹ï¼Œä½†å¯ä»¥ç”¨çœ¼ç›çœ‹ï¼Œç”¨å¿ƒæ„Ÿå—ï¼Œç”¨èƒ¸æ€€æ‰©å¼ ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†12</title>
      <link href="/2018/11/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8612/"/>
      <url>/2018/11/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8612/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Transformer"><a href="#1ï¸âƒ£-Transformer" class="headerlink" title="1ï¸âƒ£[Transformer]"></a>1ï¸âƒ£[Transformer]</h3><p>å¯¹Transformeræ–°ç†è§£ï¼š</p><ul><li>å¯ä»¥å°†Transformerç†è§£æˆä¸€å¼ å…¨è¿æ¥å›¾ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä¸å…¶ä»–èŠ‚ç‚¹çš„å…³ç³»é€šè¿‡attentionæƒé‡è¡¨ç°ã€‚å›¾å…³ç³»æ˜¯åºåˆ—å…³ç³»æˆ–è€…æ ‘å…³ç³»çš„ä¸€èˆ¬åŒ–ã€‚</li><li>ä¸ºä»€ä¹ˆè¦æœ‰multi-headï¼Ÿä¸ä»…ä»…æ˜¯è®ºæ–‡çš„è§£é‡Šï¼Œæˆ–è®¸è¿˜å¯ä»¥ç†è§£æˆï¼Œå¯¹ä¸€ä¸ªå‘é‡çš„ä¸åŒéƒ¨åˆ†ï¼ˆå¦‚ç¬¬1ç»´åˆ°20ç»´ï¼Œç¬¬21ç»´åˆ°40ç»´ç­‰ï¼‰æ–½ä»¥ä¸åŒçš„attentionæƒé‡ï¼Œå¦‚æœä¸ä½¿ç”¨multi-headï¼Œé‚£ä¹ˆå¯¹äºä¸€ä¸ªqueryï¼Œå°±åªä¼šæœ‰ä¸€ä¸ªæƒé‡ï¼Œè€Œä¸åŒçš„ç»´åº¦æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚</li></ul><hr><h3 id="2ï¸âƒ£-attention-amp-capsule"><a href="#2ï¸âƒ£-attention-amp-capsule" class="headerlink" title="2ï¸âƒ£[attention&amp;capsule]"></a>2ï¸âƒ£[attention&amp;capsule]</h3><p>attentionæ˜¯æ”¶ä¿¡æ¯ï¼Œqueryä»valueæŒ‰æƒé‡è·å–ä¿¡æ¯ï¼Œå…¶ä¸­æ‰€æœ‰valueçš„æƒé‡å’Œæ˜¯1ã€‚<br>capsuleæ˜¯å‘ä¿¡æ¯ï¼Œå¯¹äº$l-1$å±‚çš„ä¸€ä¸ªcapsuleæ¥è¯´ï¼Œåœ¨ä¼ å…¥åˆ°$l$å±‚çš„kä¸ªcapsuleçš„ä¿¡æ¯ï¼Œå…¶æƒé‡å’Œä¸º1ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Transformer </tag>
            
            <tag> attention </tag>
            
            <tag> capsule </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡6</title>
      <link href="/2018/11/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%876/"/>
      <url>/2018/11/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%876/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING"><a href="#1ï¸âƒ£-A-STRUCTURED-SELF-ATTENTIVE-SENTENCE-EMBEDDING" class="headerlink" title="1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]"></a>1ï¸âƒ£[A STRUCTURED SELF ATTENTIVE SENTENCE EMBEDDING]</h2><p>ä»‹ç»äº†ä¸€ç§ç”Ÿæˆsentence embeddingçš„æ–¹æ³•ã€‚ä¸å…¶ä»–sentence embeddingä¸åŒçš„åœ°æ–¹åœ¨äºï¼Œç”Ÿæˆçš„æ˜¯ä¸€ä¸ªçŸ©é˜µè€Œä¸æ˜¯ä¸€ä¸ªå‘é‡ã€‚é€šè¿‡çŸ©é˜µçš„å½¢å¼ï¼Œèƒ½å¤Ÿå…³æ³¨ä¸åŒéƒ¨åˆ†çš„è¯­ä¹‰è¡¨ç¤ºï¼Œç±»ä¼¼äºTransformerçš„multi-headã€‚</p><p>Contribution:</p><ul><li>å°†sentence embeddingæ‰©å±•ä¸ºçŸ©é˜µå½¢å¼ï¼Œèƒ½å¤Ÿè·å¾—æ›´å¤šçš„ä¿¡æ¯ã€‚</li><li>å¼•å…¥æ­£åˆ™åŒ–ï¼Œä½¿å¾—sentence matrixå…·æœ‰æ›´ä¸°å¯Œçš„å¤šæ ·æ€§ã€‚</li></ul><p><img src="/images/15425908639518.jpg" width="70%" height="50%"></p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>åŒå‘LSTM+self-attentionã€‚</p><p>åŒå‘çš„LSTMè·å¾—ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºï¼š</p><p><img src="/images/15425911302081.jpg" width="27%" height="50%"></p><p><img src="/images/15425911849931.jpg" width="27%" height="50%"></p><p>å› æ­¤å¯ä»¥è·å¾—attentionæƒé‡å‘é‡ï¼š<br><img src="/images/15425912555350.jpg" width="50%" height="50%"></p><p>å…¶ä¸­$H:n\times2u,W_{s1}:d_a\times2u ,w_{s2}:d_a$ ï¼Œ$d_a$æ˜¯è¶…å‚ã€‚</p><p>ç°å°†å‘é‡$w_{s2}$æ‰©å±•ä¸ºçŸ©é˜µï¼Œäº¦å³æœ‰Multi-hop attentionï¼š<br><img src="/images/15425914364548.jpg" width="50%" height="50%"></p><p>$W_{s2}$ç»´åº¦ä¸º$r\times d_a$ï¼Œ$r$ä»£è¡¨äº†headçš„ä¸ªæ•°ã€‚</p><p>å› æ­¤æœ€ç»ˆçš„sentence embeddingçŸ©é˜µä¸ºï¼š<br><img src="/images/15425915371381.jpg" width="15%" height="50%"></p><h3 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h3><p>ä¸ºäº†è®©Aå°½å¯èƒ½æœ‰å¤šæ ·æ€§ï¼ˆå› ä¸ºå¦‚æœéƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œé‚£ä¹ˆåˆ™ä¼šæœ‰å†—ä½™æ€§ï¼‰ï¼Œå¼•å…¥å¦‚ä¸‹çš„æ­£åˆ™åŒ–ï¼š<br><img src="/images/15425915930785.jpg" width="28%" height="50%"></p><p>åŸå› ï¼š<br>å¯¹äºä¸åŒçš„head $a^i$ä¸$a^j$ï¼Œ$A A^T$æœ‰ï¼š<br><img src="/images/15425918790543.jpg" width="31%" height="50%"></p><p>å¦‚æœ$a^i$ä¸$a^j$å¾ˆç›¸ä¼¼é‚£ä¹ˆå°±ä¼šæ¥è¿‘äº1ï¼Œå¦‚æœéå¸¸ä¸ç›¸ä¼¼(no overlay)åˆ™ä¼šæ¥è¿‘äº0ã€‚<br>å› æ­¤æ•´ä¸ªå¼å­å°±æ˜¯:å¸Œæœ›å¯¹è§’çº¿éƒ¨åˆ†æ¥è¿‘äº0ï¼ˆå› ä¸ºå‡äº†å•ä½é˜µï¼‰ï¼Œè¿™å°±ç›¸å½“äºå°½å¯èƒ½focuså°éƒ¨åˆ†çš„è¯ï¼›åŒæ—¶å…¶ä»–éƒ¨åˆ†å°½å¯èƒ½æ¥è¿‘äº0ï¼Œä¹Ÿå³ä¸åŒçš„headä¹‹é—´æ²¡æœ‰overlapã€‚</p><h3 id="å¦‚ä½•ä½¿ç”¨"><a href="#å¦‚ä½•ä½¿ç”¨" class="headerlink" title="å¦‚ä½•ä½¿ç”¨"></a>å¦‚ä½•ä½¿ç”¨</h3><p>æ–‡ç« æåˆ°ï¼Œåœ¨åšåˆ†ç±»çš„æ—¶å€™å¯ä»¥ç›´æ¥å°†çŸ©é˜µMå±•å¼€ï¼Œè¿‡å…¨è¿æ¥å±‚å³å¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#2ï¸âƒ£-Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]"></a>2ï¸âƒ£[Attention-over-Attention Neural Networks for Reading Comprehension]</h2><p>åœ¨å®Œå½¢å¡«ç©ºä»»åŠ¡(Cloze-style Reading Comprehension)ä¸Šæå‡ºä¸€ç§æ–°çš„attentionï¼Œå³nested-attentionã€‚</p><h3 id="ä»»åŠ¡æè¿°"><a href="#ä»»åŠ¡æè¿°" class="headerlink" title="ä»»åŠ¡æè¿°"></a>ä»»åŠ¡æè¿°</h3><p>ä¸‰å…ƒç»„ $ D,Q,A $ï¼Œdocumentï¼Œquestionï¼Œanswerã€‚å…¶ä¸­answerä¸€èˆ¬æ˜¯documentçš„ä¸€ä¸ªè¯ã€‚</p><h3 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>æœ¬æ–‡æå‡ºçš„attentionæœºåˆ¶ï¼Œæ˜¯é€šè¿‡ä¸€ä¸ªæ–°çš„attentionå»æŒ‡ç¤ºå¦ä¸€ä¸ªattentionçš„é‡è¦ç¨‹åº¦ã€‚</p><p>é¦–å…ˆé€šè¿‡ä¸€å±‚å…±äº«çš„embeddingå±‚ï¼Œå°†documentå’Œqueryéƒ½encodeæˆword embeddingï¼Œç„¶åé€šè¿‡åŒå‘çš„GRUï¼Œå°†éšå±‚æ‹¼æ¥èµ·æ¥æˆä¸ºæ–°çš„è¡¨ç¤ºã€‚</p><p>æ¥ç€è·å¾—pair-wise matching matrixï¼š<br><img src="/images/15425993645945.jpg" width="40%" height="50%"></p><p>å…¶ä¸­$h$ä»£è¡¨ä¸Šè¿°æåˆ°çš„æ‹¼æ¥èµ·æ¥çš„è¡¨ç¤ºï¼Œ$M(i,j)$ä»£è¡¨äº†documentçš„è¯$i$å’Œquestionçš„è¯$j$ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚</p><p>æ¥ç€å¯¹<strong>column</strong>åšsoftmaxï¼š<br><img src="/images/15425994692189.jpg" width="50%" height="50%"><br>å…¶ä»£è¡¨çš„æ„ä¹‰å³query-to-document attentionï¼Œäº¦å³<strong>å¯¹äºä¸€ä¸ªqueryå†…çš„è¯ï¼Œdocumentçš„æ¯ä¸ªè¯ä¸å…¶åŒ¹é…çš„æƒé‡</strong>ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œå¯¹rowè¿›è¡Œsoftmaxæ“ä½œï¼š<br><img src="/images/15425995482827.jpg" width="50%" height="50%"><br>ä»£è¡¨çš„æ˜¯<strong>ç»™å®šä¸€ä¸ªdocumentçš„è¯ï¼Œqueryçš„å“ªä¸ªè¯æ›´ä¸ºé‡è¦</strong>ã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†Î²å¹³å‡èµ·æ¥ï¼Œè·å¾—ä¸€ä¸ªå‘é‡ï¼š<br><img src="/images/15425996847558.jpg" width="20%" height="50%"><br>è¿™ä¸ªå‘é‡ä»æœ‰attentionçš„æ€§è´¨ï¼Œå³æ‰€æœ‰å…ƒç´ åŠ å’Œä¸º1ã€‚ä»£è¡¨çš„æ˜¯<strong>ä»å¹³å‡æ¥çœ‹ï¼Œqueryè¯çš„é‡è¦æ€§</strong>ã€‚</p><p>æœ€åï¼Œæˆ‘ä»¬å¯¹Î±å’ŒÎ²åšç‚¹ç§¯ä»¥è·å¾—attended document-level attentionï¼š<br><img src="/images/15425997529193.jpg" width="13%" height="50%"></p><p>å…¶ä¸­$s$çš„ç»´åº¦æ˜¯$D\times 1$ã€‚sä»£è¡¨çš„æ„ä¹‰å³â€œa weighted sum of each individual document-level attention Î±(t) when looking at query word at time tâ€ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹Î±è¿›è¡ŒåŠ æƒï¼Œä»£è¡¨query wordçš„å¹³å‡é‡è¦ç¨‹åº¦ã€‚</p><p>æœ€ç»ˆåœ¨åšå®Œå‹å¡«ç©ºçš„é¢„æµ‹æ—¶ï¼š<br><img src="/images/15425999965777.jpg" width="38%" height="50%"></p><p>ä¸ªäººè§‰å¾—è¿™ç§attention-over-attentionçš„æƒ³æ³•è¿˜æ˜¯æŒºæœ‰åˆ›æ–°çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> attention </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> sentence embedding </tag>
            
            <tag> nested attention </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç½‘ç»œä¼˜åŒ–ä¸æ­£åˆ™åŒ–æ€»ç»“</title>
      <link href="/2018/11/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%BB%E7%BB%93/"/>
      <url>/2018/11/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>å¤§é‡å‚è€ƒè‡ª<a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a></p><h1 id="ä¼˜åŒ–ç®—æ³•"><a href="#ä¼˜åŒ–ç®—æ³•" class="headerlink" title="ä¼˜åŒ–ç®—æ³•"></a>ä¼˜åŒ–ç®—æ³•</h1><p>å¯¹äºæ ‡å‡†çš„SGDï¼Œå¸¸è§çš„æ”¹è¿›ç®—æ³•ä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œï¼šå­¦ä¹ ç‡è¡°å‡&amp;æ¢¯åº¦æ–¹å‘ä¼˜åŒ–ã€‚<br>è®°$g_t$ä¸ºtæ—¶åˆ»çš„å¯¼æ•°ï¼š<br><img src="/images/2018-11-13-15421196736629.jpg" width="20%" height="50%"></p><h2 id="å­¦ä¹ ç‡è¡°å‡"><a href="#å­¦ä¹ ç‡è¡°å‡" class="headerlink" title="å­¦ä¹ ç‡è¡°å‡"></a>å­¦ä¹ ç‡è¡°å‡</h2><h3 id="AdaGradç®—æ³•"><a href="#AdaGradç®—æ³•" class="headerlink" title="AdaGradç®—æ³•"></a>AdaGradç®—æ³•</h3><p>é€šè¿‡è®¡ç®—å†æ¬¡çš„æ¢¯åº¦å¹³æ–¹ç´¯è®¡å€¼è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ã€‚<br>$G_t$æ˜¯ç´¯è®¡å€¼ï¼š<br><img src="/images/2018-11-13-15421189802198.jpg" width="20%" height="50%"></p><p>æ›´æ–°å€¼åˆ™ä¸ºï¼š<br><img src="/images/2018-11-13-15421190100615.jpg" width="30%" height="50%"></p><p>ç¼ºç‚¹ï¼šéšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ å­¦ä¹ ç‡é€’å‡ã€‚åœ¨ç»è¿‡ä¸€å®šæ¬¡æ•°çš„è¿­ä»£ä¾ç„¶æ²¡æœ‰æ‰¾åˆ°æœ€ä¼˜ç‚¹æ—¶ï¼Œç”±äºè¿™æ—¶çš„å­¦ä¹ ç‡å·²ç»éå¸¸å°ï¼Œå¾ˆéš¾å†ç»§ç»­æ‰¾åˆ°æœ€ä¼˜ç‚¹ã€‚</p><h3 id="RMSpropç®—æ³•"><a href="#RMSpropç®—æ³•" class="headerlink" title="RMSpropç®—æ³•"></a>RMSpropç®—æ³•</h3><p>å¯¹AdaGradçš„æ”¹è¿›ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äº$G_t$çš„è®¡ç®—ï¼Œå°†å†å²ä¿¡æ¯å’Œå½“å‰ä¿¡æ¯è¿›è¡Œçº¿æ€§åŠ æƒï¼Œä½¿å¾—å­¦ä¹ ç‡å¯ä»¥åŠ¨æ€æ”¹å˜è€Œä¸æ˜¯å•è°ƒé€’å‡ï¼š<br><img src="/images/2018-11-13-15421192344025.jpg" width="40%" height="50%"></p><p>Î²ä¸ºè¡°å‡ç‡ï¼Œé€šå¸¸å–0.9ã€‚ä¹Ÿå³å†å²ä¿¡æ¯å ä¸»å¯¼ã€‚</p><h3 id="AdaDeltaç®—æ³•"><a href="#AdaDeltaç®—æ³•" class="headerlink" title="AdaDeltaç®—æ³•"></a>AdaDeltaç®—æ³•</h3><p>åŒæ ·æ˜¯å¯¹AdaGradçš„æ”¹è¿›ã€‚<br>æ¯æ¬¡è®¡ç®—ï¼š<br><img src="/images/2018-11-13-15421195264173.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³å†å²æ›´æ–°å·®å’Œä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®çš„åŠ æƒï¼ˆRMSpropæ˜¯å†å²æ¢¯åº¦å’Œå½“å‰æ¢¯åº¦ï¼‰ã€‚</p><p>æœ€ç»ˆæ›´æ–°å·®å€¼ä¸ºï¼š<br><img src="/images/2018-11-13-15421197355615.jpg" width="30%" height="50%"></p><p>å…¶ä¸­$G_t$è®¡ç®—æ–¹æ³•å’ŒRMSpropä¸€è‡´ã€‚</p><h2 id="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"><a href="#æ¢¯åº¦æ–¹å‘ä¼˜åŒ–" class="headerlink" title="æ¢¯åº¦æ–¹å‘ä¼˜åŒ–"></a>æ¢¯åº¦æ–¹å‘ä¼˜åŒ–</h2><p>åˆ©ç”¨å†å²çš„æ¢¯åº¦ï¼ˆæ–¹å‘ï¼‰è°ƒæ•´å½“å‰æ—¶åˆ»çš„æ¢¯åº¦ã€‚</p><h3 id="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"><a href="#åŠ¨é‡ï¼ˆMomentumï¼‰æ³•" class="headerlink" title="åŠ¨é‡ï¼ˆMomentumï¼‰æ³•"></a>åŠ¨é‡ï¼ˆMomentumï¼‰æ³•</h3><p>åŠ¨é‡æ³•ï¼ˆMomentum Methodï¼‰æ˜¯ç”¨ä¹‹å‰ç§¯ç´¯åŠ¨é‡æ¥æ›¿ä»£çœŸæ­£çš„æ¢¯åº¦ã€‚æ¯æ¬¡è¿­ä»£çš„æ¢¯åº¦å¯ä»¥çœ‹ä½œæ˜¯åŠ é€Ÿåº¦ã€‚</p><p><img src="/images/2018-11-13-15421199473226.jpg" width="28%" height="50%"></p><p>ä¹Ÿå³ä¸Šä¸€æ—¶åˆ»çš„æ›´æ–°å·®å€¼å’Œå½“å‰æ¢¯åº¦å…±åŒå†³å®šå½“å‰çš„æ›´æ–°å·®å€¼ã€‚$Ï$ä¸ºåŠ¨é‡å› å­ï¼Œé€šå¸¸ä¸º0.9ã€‚ä¹Ÿå³åŠ¨é‡å äº†ä¸»å¯¼ã€‚</p><p>å½“æŸä¸ªå‚æ•°åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘ä¸ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å°ï¼›ç›¸åï¼Œå½“åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„æ¢¯åº¦æ–¹å‘éƒ½ä¸€è‡´æ—¶ï¼Œå…¶çœŸå®çš„å‚æ•°æ›´æ–°å¹…åº¦å˜å¤§ï¼Œèµ·åˆ°åŠ é€Ÿä½œç”¨ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨è¿­ä»£åˆæœŸï¼Œæ¢¯åº¦æ–¹æ³•éƒ½æ¯”è¾ƒä¸€è‡´ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°åŠ é€Ÿä½œç”¨ï¼Œå¯ä»¥æ›´å¿«åœ°åˆ°è¾¾æœ€ä¼˜ç‚¹ã€‚åœ¨è¿­ä»£åæœŸï¼Œæ¢¯åº¦æ–¹æ³•ä¼šå–å†³ä¸ä¸€è‡´ï¼Œåœ¨æ”¶æ•›å€¼é™„è¿‘éœ‡è¡ï¼ŒåŠ¨é‡æ³•ä¼šèµ·åˆ°å‡é€Ÿä½œç”¨ï¼Œå¢åŠ ç¨³å®šæ€§ã€‚</p><h3 id="NesterovåŠ é€Ÿæ¢¯åº¦"><a href="#NesterovåŠ é€Ÿæ¢¯åº¦" class="headerlink" title="NesterovåŠ é€Ÿæ¢¯åº¦"></a>NesterovåŠ é€Ÿæ¢¯åº¦</h3><p>åŠ¨é‡æ³•çš„æ”¹è¿›ç‰ˆæœ¬ã€‚</p><p>å‰é¢æåˆ°çš„åŠ¨é‡æ³•ï¼Œæ˜¯ä¸Šä¸€æ­¥çš„æ›´æ–°æ–¹å‘$\Delta \theta_{t-1}$ä¸å½“å‰æ¢¯åº¦$-g_t$çš„åŠ å’Œã€‚å› æ­¤å¯ä»¥ç†è§£æˆï¼Œå…ˆæ ¹æ®$âˆ†Î¸_{tâˆ’1}$æ›´æ–°ä¸€æ¬¡å¾—åˆ°å‚æ•°Î¸ï¼Œå†ç”¨$g_t$è¿›è¡Œæ›´æ–°ã€‚äº¦å³ï¼š<br><img src="/images/2018-11-13-15421202426163.jpg" width="27%" height="50%"><br>ä¸Šå¼çš„ç¬¬äºŒæ­¥ä¸­ï¼Œ$g_t$æ˜¯åœ¨$ \theta_{t-1}$ä¸Šçš„æ¢¯åº¦ã€‚æˆ‘ä»¬å°†è¯¥æ­¥æ”¹ä¸ºåœ¨$\theta_{t}$çš„æ¢¯åº¦ã€‚<br>å› æ­¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-13-15421203421465.jpg" width="50%" height="50%"></p><p>å’ŒåŠ¨é‡æ³•ç›¸æ¯”ï¼Œç›¸å½“äºæå‰èµ°äº†ä¸€æ­¥ã€‚<br><img src="/images/2018-11-13-15421203910771.jpg" width="70%" height="50%"></p><h3 id="Adam-amp-Nadam"><a href="#Adam-amp-Nadam" class="headerlink" title="Adam&amp;Nadam"></a>Adam&amp;Nadam</h3><p>Adamä¸€æ–¹é¢è®¡ç®—æ¢¯åº¦å¹³æ–¹çš„åŠ æƒï¼ŒåŒæ—¶è¿˜è®¡ç®—æ¢¯åº¦çš„åŠ æƒï¼š<br><img src="/images/2018-11-13-15421205162558.jpg" width="40%" height="50%"><br>é€šå¸¸$Î²_1=0.9$ï¼Œ$Î²_2=0.99$<br>ä¹Ÿå³å†å²ä¿¡æ¯å äº†ä¸»å¯¼ã€‚</p><p>åœ¨åˆæœŸ$M_t$ä¸$G_t$ä¼šæ¯”çœŸå®å‡å€¼å’Œæ–¹å·®è¦å°ï¼ˆæƒ³è±¡$M_0=0$ï¼Œ$G_0=0$æ—¶ï¼‰ã€‚å› æ­¤å¯¹å…¶è¿›è¡Œä¿®æ­£ï¼Œå³ï¼š<br><img src="/images/2018-11-13-15421207635850.jpg" width="18%" height="50%"><br>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-11-13-15421207966341.jpg" width="26%" height="50%"></p><p>åŒç†æœ‰Nadamã€‚</p><p>Adam = Momentum + RMSprop<br>Nadam = Nesterov + RMSprop</p><h3 id="æ¢¯åº¦æˆªæ–­-gradient-clipping"><a href="#æ¢¯åº¦æˆªæ–­-gradient-clipping" class="headerlink" title="æ¢¯åº¦æˆªæ–­ gradient clipping"></a>æ¢¯åº¦æˆªæ–­ gradient clipping</h3><p>åˆ†ä¸ºæŒ‰å€¼æˆªæ–­ä¸æŒ‰æ¨¡æˆªæ–­ã€‚</p><h1 id="å‚æ•°åˆå§‹åŒ–"><a href="#å‚æ•°åˆå§‹åŒ–" class="headerlink" title="å‚æ•°åˆå§‹åŒ–"></a>å‚æ•°åˆå§‹åŒ–</h1><p>åˆå§‹å€¼é€‰å–å¾ˆå…³é”®ã€‚å‡è®¾å…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Œåˆ™åç»­æ›´æ–°å¯¼è‡´æ‰€æœ‰çš„æ¿€æ´»å€¼ç›¸åŒï¼Œä¹Ÿå³å¯¹ç§°æƒé‡ç°è±¡ã€‚</p><p>åŸåˆ™ï¼šä¸èƒ½è¿‡å¤§ï¼Œå¦åˆ™æ¿€æ´»å€¼ä¼šå˜å¾—é¥±å’Œï¼Œå¦‚sigmoidï¼›ä¸èƒ½è¿‡å°ï¼Œå¦åˆ™ç»è¿‡å¤šå±‚ä¿¡å·ä¼šé€æ¸æ¶ˆå¤±ï¼Œå¹¶ä¸”å¯¼è‡´sigmoidä¸¢å¤±éçº¿æ€§çš„èƒ½åŠ›ï¼ˆåœ¨0é™„è¿‘åŸºæœ¬è¿‘ä¼¼çº¿æ€§ï¼‰ã€‚å¦‚æœä¸€ä¸ªç¥ç»å…ƒçš„è¾“å…¥è¿æ¥å¾ˆå¤šï¼Œå®ƒçš„æ¯ä¸ªè¾“å…¥è¿æ¥ä¸Šçš„æƒé‡å°±åº”è¯¥å°ä¸€äº›ï¼Œè¿™æ˜¯ä¸ºäº†é¿å…è¾“å‡ºè¿‡å¤§ã€‚</p><h2 id="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"><a href="#Gaussianåˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="Gaussianåˆ†å¸ƒåˆå§‹åŒ–"></a>Gaussianåˆ†å¸ƒåˆå§‹åŒ–</h2><p>åŒæ—¶è€ƒè™‘è¾“å…¥è¾“å‡ºï¼Œå¯ä»¥æŒ‰ $N(0,\sqrt{\frac{2}{n_{in} + n_{out}}})$ é«˜æ–¯åˆ†å¸ƒæ¥åˆå§‹åŒ–ã€‚</p><h2 id="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"><a href="#å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–" class="headerlink" title="å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–"></a>å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–</h2><p>åœ¨$[-r,r]$åŒºé—´å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå…¶ä¸­rå¯ä»¥æŒ‰ç…§ç¥ç»å…ƒæ•°é‡è‡ªé€‚åº”è°ƒæ•´ã€‚</p><h3 id="Xavieråˆå§‹åŒ–æ–¹æ³•"><a href="#Xavieråˆå§‹åŒ–æ–¹æ³•" class="headerlink" title="Xavieråˆå§‹åŒ–æ–¹æ³•"></a>Xavieråˆå§‹åŒ–æ–¹æ³•</h3><p>è‡ªåŠ¨è®¡ç®—è¶…å‚rã€‚rçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-11-14-15421648119504.jpg" width="22%" height="50%"><br>å…¶ä¸­$n^l$ä»£è¡¨ç¬¬$l$å±‚çš„ç¥ç»å…ƒä¸ªæ•°ã€‚</p><p>ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªå¼å­ï¼ˆæ¨å¯¼è§å‚è€ƒèµ„æ–™ï¼‰ï¼šç»¼åˆè€ƒè™‘äº†â‘ è¾“å…¥è¾“å‡ºçš„æ–¹å·®è¦ä¸€è‡´ï¼›â‘¡åå‘ä¼ æ’­ä¸­è¯¯å·®ä¿¡å·çš„æ–¹å·®ä¸è¢«æ”¾å¤§æˆ–ç¼©å°ã€‚</p><h1 id="å½’ä¸€åŒ–"><a href="#å½’ä¸€åŒ–" class="headerlink" title="å½’ä¸€åŒ–"></a>å½’ä¸€åŒ–</h1><p>å°†æ•°æ®åˆ†å¸ƒå½’ä¸€åŒ–ï¼Œä½¿å¾—åˆ†å¸ƒä¿æŒç¨³å®šã€‚<br><img src="/images/2018-11-14-15421656553319.jpg" width="100%" height="50%"><br>å‡è®¾æ•°æ®æœ‰å››ç»´(N,C,H,W)ã€‚Nä»£è¡¨batchï¼›Cä»£è¡¨channelï¼›H,Wä»£è¡¨heightå’Œwidthã€‚</p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>æ²¿ç€é€šé“è¿›è¡Œå½’ä¸€åŒ–ï¼Œäº¦å³æ¯ä¸ªé€šé“éƒ½æœ‰è‡ªå·±çš„å‡å€¼å’Œæ–¹å·®ã€‚<br><img src="/images/2018-11-14-15421657694248.jpg" width="70%" height="50%"><br>å…¶ä¸­ç¼©æ”¾å¹³ç§»å˜é‡æ˜¯å¯å­¦ä¹ çš„ã€‚</p><p>ç¼ºç‚¹ï¼š<br>â‘ å¯¹batch sizeæ•æ„Ÿï¼Œbatch sizeå¤ªå°åˆ™æ–¹å·®å‡å€¼ä¸è¶³ä»¥ä»£è¡¨æ•°æ®åˆ†å¸ƒ<br>â‘¡å¯¹äºä¸ç­‰é•¿çš„è¾“å…¥å¦‚RNNæ¥è¯´ï¼Œæ¯ä¸€ä¸ªtimestepéƒ½éœ€è¦ä¿å­˜ä¸åŒçš„ç‰¹å¾ã€‚</p><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>å¯¹ä¸€ä¸ªè¾“å…¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œäº¦å³æ¯ä¸ªè¾“å…¥éƒ½æœ‰è‡ªå·±çš„æ–¹å·®ã€å‡å€¼ã€‚è¿™æ ·ä¸ä¾èµ–äºbatchå¤§å°å’Œè¾“å…¥sequenceçš„æ·±åº¦ã€‚</p><p>å¯¹RNNæ•ˆæœæ¯”è¾ƒæ˜æ˜¾ï¼Œä½†CNNä¸­ä¸å¦‚BN</p><h2 id="Instance-Normalization"><a href="#Instance-Normalization" class="headerlink" title="Instance Normalization"></a>Instance Normalization</h2><p>å¯¹HWè¿›è¡Œå½’ä¸€åŒ–</p><h2 id="Group-Normalization"><a href="#Group-Normalization" class="headerlink" title="Group Normalization"></a>Group Normalization</h2><p>å°†channelåˆ†ä¸ºå¤šä¸ªgroupï¼Œæ¯ä¸ªgroupå†…åšå½’ä¸€åŒ–</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://nndl.github.io/" target="_blank" rel="noopener">ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹</a><br><a href="https://blog.csdn.net/liuxiao214/article/details/81037416" target="_blank" rel="noopener">https://blog.csdn.net/liuxiao214/article/details/81037416</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ·±åº¦å­¦ä¹ ğŸ¤– </tag>
            
            <tag> ä¼˜åŒ–ç®—æ³• </tag>
            
            <tag> å‚æ•°åˆå§‹åŒ– </tag>
            
            <tag> Normalization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•10</title>
      <link href="/2018/11/11/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9510/"/>
      <url>/2018/11/11/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%9510/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-get-sinusoid-encoding-table"><a href="#1ï¸âƒ£-get-sinusoid-encoding-table" class="headerlink" title="1ï¸âƒ£[get_sinusoid_encoding_table]"></a>1ï¸âƒ£[get_sinusoid_encoding_table]</h3><p>Transformerç»å¯¹ä½ç½®ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sinusoid_encoding_table</span><span class="params">(n_position, d_hid, padding_idx=None)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_angle</span><span class="params">(position, hid_idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> position / np.power(<span class="number">10000</span>, <span class="number">2</span> * (hid_idx // <span class="number">2</span>) / d_hid)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_posi_angle_vec</span><span class="params">(position)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [cal_angle(position, hid_j) <span class="keyword">for</span> hid_j <span class="keyword">in</span> range(d_hid)]</span><br><span class="line"></span><br><span class="line">    sinusoid_table = np.array([get_posi_angle_vec(pos_i) <span class="keyword">for</span> pos_i <span class="keyword">in</span> range(n_position)])</span><br><span class="line"></span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.cos(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        sinusoid_table[padding_idx] = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(sinusoid_table)  <span class="comment"># n_position,embed_dim</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†11</title>
      <link href="/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8611/"/>
      <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8611/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Optimizer"><a href="#1ï¸âƒ£-Optimizer" class="headerlink" title="1ï¸âƒ£[Optimizer]"></a>1ï¸âƒ£[Optimizer]</h3><p><a href="https://zhuanlan.zhihu.com/p/32262540" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32262540</a><br><a href="https://zhuanlan.zhihu.com/p/32338983" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32338983</a></p><p>Adamç­‰è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•å¯¹äºç¨€ç–æ•°æ®å…·æœ‰ä¼˜åŠ¿ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¾ˆå¿«ï¼›ä½†ç²¾è°ƒå‚æ•°çš„SGDï¼ˆ+Momentumï¼‰å¾€å¾€èƒ½å¤Ÿå–å¾—æ›´å¥½çš„æœ€ç»ˆç»“æœã€‚</p><p>å»ºè®®ï¼š<br>å‰æœŸç”¨Adamï¼Œäº«å—Adamå¿«é€Ÿæ”¶æ•›çš„ä¼˜åŠ¿ï¼›åæœŸåˆ‡æ¢åˆ°SGDï¼Œæ…¢æ…¢å¯»æ‰¾æœ€ä¼˜è§£ã€‚<br>ä»€ä¹ˆæ—¶å€™ä»Adamåˆ‡æ¢åˆ°SGDï¼Ÿå½“SGDçš„ç›¸åº”å­¦ä¹ ç‡çš„ç§»åŠ¨å¹³å‡å€¼åŸºæœ¬ä¸å˜çš„æ—¶å€™ã€‚</p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>LongTensoré™¤ä»¥æµ®ç‚¹æ•°ï¼Œä¼šå¯¹é™¤æ•°è¿›è¡Œå–æ•´ï¼Œå†åšé™¤æ³•ã€‚<br><img src="/images/2018-11-11-15419055399325.jpg" width="30%" height="50%"></p><hr><h3 id="3ï¸âƒ£-Pytorch"><a href="#3ï¸âƒ£-Pytorch" class="headerlink" title="3ï¸âƒ£[Pytorch]"></a>3ï¸âƒ£[Pytorch]</h3><p>ä½¿ç”¨Pytorchçš„DataParallel</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda:'</span> + str(</span><br><span class="line">    config.CUDA_VISIBLE_DEVICES[<span class="number">0</span>]) <span class="keyword">if</span> config.use_cuda <span class="keyword">else</span> <span class="string">'cpu'</span>)   <span class="comment"># æŒ‡å®šç¬¬ä¸€ä¸ªè®¾å¤‡</span></span><br><span class="line"></span><br><span class="line">model = ClassifyModel(</span><br><span class="line">    vocab_size=len(vocab), max_seq_len=config.max_sent_len,</span><br><span class="line">    embed_dim=config.embed_dim, n_layers=config.n_layers,</span><br><span class="line">    n_head=config.n_head, d_k=config.d_k,</span><br><span class="line">    d_v=config.d_v,</span><br><span class="line">    d_model=config.d_model, d_inner=config.d_inner_hid,</span><br><span class="line">    n_label=config.n_label,</span><br><span class="line">    dropout=config.dropout</span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line">model = DataParallel(model, device_ids=config.CUDA_VISIBLE_DEVICES)  <span class="comment"># æ˜¾å¼å®šä¹‰device_ids</span></span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°ï¼šdevice_idsçš„èµ·å§‹ç¼–å·è¦ä¸ä¹‹å‰å®šä¹‰çš„deviceä¸­çš„â€œcuda:0â€ç›¸ä¸€è‡´ï¼Œä¸ç„¶ä¼šæŠ¥é”™ã€‚</p><p>å¦‚æœä¸æ˜¾å¼åœ¨ä»£ç ä¸­çš„DataParallelæŒ‡å®šè®¾å¤‡ï¼Œé‚£ä¹ˆéœ€è¦åœ¨å‘½ä»¤è¡Œå†…æŒ‡å®šã€‚å¦‚æœæ˜¯åœ¨å‘½ä»¤è¡Œé‡Œé¢è¿è¡Œçš„ï¼Œä¸”deviceä¸æ˜¯ä»0å¼€å§‹ï¼Œåº”å½“æ˜¾å¼è®¾ç½®GPU_idï¼Œå¦åˆ™ä¼šå‡ºé”™â€˜AssertionError: Invalid device idâ€™ï¼Œæ­£ç¡®çš„å‘½ä»¤ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=4,5Â  python -u classify_main.py --gpu_id 0,1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Optimizer </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºsparse gradient</title>
      <link href="/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8Esparse%20gradient/"/>
      <url>/2018/11/11/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8Esparse%20gradient/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ å¤©åœ¨çœ‹AllenAIåœ¨EMNLPçš„pptæ—¶ï¼Œæœ‰ä¸€é¡µå†™é“ï¼š<br><img src="/images/2018-11-11-15419037448379.jpg" width="70%" height="50%"></p><p>ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µï¼Ÿ</p><p>Embeddingæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„çŸ©é˜µï¼Œæ¯ä¸€æ¬¡å…¶å®éƒ½åªæœ‰ä¸€ä¸ªå°éƒ¨åˆ†è¿›è¡Œäº†æ›´æ–°ï¼Œå¯¹äºä¸€äº›è¯æ¥è¯´ï¼Œå‡ºç°çš„é¢‘ç‡ä¸é«˜ï¼Œæˆ–è€…è¯´ï¼Œå…¶å®å¤§éƒ¨åˆ†çš„è¯åœ¨ä¸€ä¸ªloop/epochä¸­ï¼Œè¢«æ›´æ–°çš„æ¬¡æ•°æ˜¯è¾ƒå°‘çš„ã€‚ä½†æ˜¯ï¼Œæ³¨æ„åˆ°ä¸€èˆ¬çš„optimizerç®—æ³•ï¼Œæ˜¯ä»¥matrixä¸ºå•ä½è¿›è¡Œæ›´æ–°çš„ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€æ¬¡éƒ½æ˜¯$W^{t+1}=W^{t}-\eta \frac{\partial L}{\partial{W}}$</p><p>è€ŒAdamç®—æ³•ï¼š<br><img src="/images/2018-11-11-15419038346958.jpg" width="70%" height="50%"></p><p>åŠ¨é‡å äº†ä¸»å¯¼ã€‚ä½†è¿™æ ·ï¼Œæ¯æ¬¡batchæ›´æ–°ï¼Œé‚£äº›æ²¡è¢«æ›´æ–°çš„è¯ï¼ˆä¹Ÿå³gradient=0ï¼‰çš„åŠ¨é‡ä»ç„¶ä¼šè¢«è¡°å‡ï¼Œæ‰€ä»¥è¿™æ ·å½“åˆ°è¿™ä¸ªè¯æ›´æ–°çš„æ—¶å€™ï¼Œä»–çš„åŠ¨é‡å·²ç»è¢«è¡°å‡å®Œäº†ï¼Œæ‰€ä»¥æ›´æ–°çš„gradientå°±å¾ˆå°ã€‚</p><p>è§£å†³æ–¹æ¡ˆï¼š</p><p>â‘ åœ¨PyTorchä¸­ï¼ŒEmbeddingçš„APIï¼š<br><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False, _weight=None)</code></p><p>å…¶ä¸­sparse (bool, optional) â€“ if True, gradient w.r.t. weight matrix will be a sparse tensor.</p><p>å°†sparseè®¾ä¸ºTrueå³å¯ã€‚</p><p>â‘¡é’ˆå¯¹sparseçŸ©é˜µï¼Œä½¿ç”¨ä¸åŒçš„optimizerï¼Œå¦‚torch.optim.SparseAdamï¼š</p><blockquote><p>Implements lazy version of Adam algorithm suitable for sparse tensors.<br>In this variant, only moments that show up in the gradient get updated, and only those portions of the gradient get applied to the parameters.</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> sparse gradient </tag>
            
            <tag> ä»£ç å®è·µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡5</title>
      <link href="/2018/11/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%875/"/>
      <url>/2018/11/10/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%875/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Neural-Turing-Machine"><a href="#1ï¸âƒ£-Neural-Turing-Machine" class="headerlink" title="1ï¸âƒ£[Neural Turing Machine]"></a>1ï¸âƒ£[Neural Turing Machine]</h2><p>é€šè¿‡æ¨¡ä»¿å†¯è¯ºä¾æ›¼æœºï¼Œå¼•å…¥å¤–éƒ¨å†…å­˜(externel memory)ã€‚<br><img src="/images/2018-11-10-15418626837026.jpg" width="70%" height="50%"></p><p>å’Œæ™®é€šç¥ç»ç½‘ç»œä¸€æ ·ï¼Œä¸å¤–ç•Œäº¤äº’ï¼Œè·å¾—ä¸€ä¸ªè¾“å…¥ï¼Œäº§ç”Ÿä¸€ä¸ªè¾“å‡ºã€‚ä½†ä¸åŒçš„æ˜¯ï¼Œå†…éƒ¨è¿˜æœ‰ä¸€ä¸ªmemoryè¿›è¡Œè¯»å†™ã€‚<br>å‡è®¾memoryæ˜¯ä¸€ä¸ªN Ã— Mçš„çŸ©é˜µï¼ŒNæ˜¯å†…å­˜çš„ä½ç½®æ•°é‡ã€‚</p><h3 id="è¯»å†™memory"><a href="#è¯»å†™memory" class="headerlink" title="è¯»å†™memory"></a>è¯»å†™memory</h3><p>â‘ è¯»<br><img src="/images/2018-11-10-15418627403268.jpg" width="25%" height="50%"><br>å…¶ä¸­è¯»çš„æ—¶å€™å¯¹å„å†…å­˜ä½ç½®çº¿æ€§åŠ æƒã€‚wæ˜¯å½’ä¸€åŒ–æƒé‡ã€‚</p><p>â‘¡å†™<br>$e_t$æ˜¯æ“¦é™¤å‘é‡ï¼ˆerase vectorï¼‰<br><img src="/images/2018-11-10-15418627941358.jpg" width="35%" height="50%"></p><p>$a_t$æ˜¯åŠ å’Œå‘é‡(add vector)<br><img src="/images/2018-11-10-15418628323343.jpg" width="30%" height="50%"></p><p>å…·ä½“å¦‚ä½•è·å¾—æƒé‡å°±ä¸è¯´äº†ã€‚</p><h3 id="Controller-network"><a href="#Controller-network" class="headerlink" title="Controller network"></a>Controller network</h3><p>ä¸­é—´çš„controller networkå¯ä»¥æ˜¯ä¸€ä¸ªæ™®é€šçš„feed forwardæˆ–è€…RNNã€‚</p><p>åœ¨å®é™…ä¸­NTMç”¨å¾—å¹¶ä¸å¤šã€‚</p><hr><h2 id="2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling"><a href="#2ï¸âƒ£-Efficient-Contextualized-Representation-Language-Model-Pruning-for-Sequence-Labeling" class="headerlink" title="2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]"></a>2ï¸âƒ£[Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling]</h2><p>ELMoçš„ç²¾ç®€ç‰ˆï¼Œé€šè¿‡å³æ’å³ç”¨çš„æ–¹æ³•æ¥å‹ç¼©è¯­è¨€æ¨¡å‹ï¼Œå¯¹ç‰¹å®šä»»åŠ¡å‰ªæä¸åŒçš„å±‚ï¼Œä½¿å¾—èƒ½å¤Ÿå‡å°‘inferenceçš„æ—¶é—´ã€‚<br>è¿™ç¯‡çš„ideaæŒºæœ‰åˆ›æ–°çš„ï¼Œä½†ä¼¼ä¹æœ‰äº›trivialçš„æ„Ÿè§‰ã€‚</p><p><img src="/images/2018-11-11-15418977712883.jpg" width="70%" height="50%"></p><h3 id="RNN-and-Dense-Connectivity"><a href="#RNN-and-Dense-Connectivity" class="headerlink" title="RNN and Dense Connectivity"></a>RNN and Dense Connectivity</h3><p>æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½ä¼šä¼ åˆ°æ‰€æœ‰å±‚ä½œä¸ºè¾“å…¥ï¼Œå› æ­¤å¯¹äºLå±‚çš„è¾“å…¥ï¼š<br><img src="/images/2018-11-11-15418979328482.jpg" width="35%" height="50%"></p><p>è¿™æ ·æˆ‘ä»¬å°±èƒ½å¤Ÿéšæ„åœ°å»æ‰ä»»æ„ä¸­é—´å±‚äº†ã€‚åŒæ—¶ä¸€äº›è¯­è¨€ä¿¡æ¯ä¹Ÿåˆ†æ•£åˆ°å„ä¸ªå±‚ï¼Œå³ä½¿å»æ‰æŸäº›å±‚ä¹Ÿæ²¡æœ‰å…³ç³»ã€‚</p><p>åˆ™æœ€ç»ˆçš„outputä¸ºï¼š<br><img src="/images/2018-11-11-15418991345288.jpg" width="33%" height="50%"></p><p>æœ€ç»ˆä½œprojectionåˆ°æ­£å¸¸ç»´åº¦ï¼ˆåœ¨æ¯å±‚éƒ½ä¼šè¿™ä¹ˆåšï¼Œå°†è¾“å…¥é™ç»´åˆ°æ­£å¸¸ç»´åº¦å†è¾“å…¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418992517849.jpg" width="37%" height="50%"></p><p>å†åšä¸€ä¸ªsoftmaxï¼š<br><img src="/images/2018-11-11-15418993146246.jpg" width="32%" height="50%"></p><p>ç”±äº $h^{â€»}$ ç”¨äºsoftmaxï¼Œæ‰€ä»¥å¯èƒ½å’Œtarget wordï¼Œä¹Ÿå³ä¸‹ä¸€ä¸ªè¯æ¯”è¾ƒç›¸ä¼¼ï¼Œ<strong>å› æ­¤å¯èƒ½æ²¡æœ‰å¾ˆå¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯</strong>ã€‚</p><p>æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬ä½¿ç”¨$h_t$ï¼Œä»¥åŠåå‘çš„$h_t^r$ï¼Œå†è¿‡ä¸€å±‚çº¿æ€§å±‚è·å¾—æœ€ç»ˆçš„embeddingï¼ˆå’ŒELMoæœ‰äº›ä¸åŒï¼ŒELMoæ˜¯ç›´æ¥æ‹¼èµ·æ¥ï¼‰ï¼š<br><img src="/images/2018-11-11-15418994541442.jpg" width="40%" height="50%"></p><h3 id="Layer-Selection"><a href="#Layer-Selection" class="headerlink" title="Layer Selection"></a>Layer Selection</h3><p>æˆ‘ä»¬åœ¨æ¯å±‚çš„outputéƒ½åŠ ä¸€ä¸ªæƒé‡ç³»æ•°ã€‚<br><img src="/images/2018-11-11-15418996081852.jpg" width="30%" height="50%"></p><p>æˆ‘ä»¬å¸Œæœ›åœ¨target taskä¸Šç”¨çš„æ—¶å€™ï¼Œéƒ¨åˆ†zèƒ½å¤Ÿå˜æˆ0ï¼Œè¾¾åˆ°layer selectionçš„æ•ˆæœï¼ŒåŠ å¿«inferenceçš„é€Ÿåº¦ã€‚</p><p>äº¦å³ï¼š<br><img src="/images/2018-11-11-15418996697208.jpg" width="20%" height="50%"></p><p>ä¸€ç§ç†æƒ³çš„æ–¹æ³•æ˜¯L0æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997294756.jpg" width="17%" height="50%"></p><p>ä½†ç”±äºæ²¡åŠæ³•æ±‚å¯¼ï¼Œå› æ­¤ï¼Œé‡‡ç”¨L1æ­£åˆ™åŒ–ï¼š<br><img src="/images/2018-11-11-15418997747882.jpg" width="15%" height="50%"><br>ä½†ä½¿ç”¨L1æ­£åˆ™åŒ–æœ‰ä¸€å®šçš„é£é™©ï¼Œå› ä¸ºå¦‚æœè®©æ‰€æœ‰zéƒ½è¿œç¦»1ï¼Œé‚£ä¹ˆä¼šå½±å“performanceã€‚</p><p>å¼•å…¥æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•$R_2 =\delta(|z|_0&gt;\lambda_1) |z|_1$<br>äº¦å³ï¼Œåªæœ‰åœ¨éé›¶zçš„ä¸ªæ•°å¤§äºæŸä¸ªé˜ˆå€¼æ—¶ï¼Œæ‰èƒ½æœ‰æ­£åˆ™åŒ–æ•ˆæœï¼Œä¿è¯éé›¶çš„ä¸ªæ•°ã€‚â€™it can be â€œturned-offâ€ after achieving a satisfying sparsityâ€™.</p><p>è¿›ä¸€æ­¥å¼•å…¥$R_3=\delta(|z|_0&gt;\lambda_1) |z|_1 + |z(1-z)|_1$<br>å…¶ä¸­ç¬¬äºŒé¡¹ä¸ºäº†é¼“åŠ±zå‘0æˆ–1èµ°ã€‚</p><h3 id="Layer-wise-Dropout"><a href="#Layer-wise-Dropout" class="headerlink" title="Layer-wise Dropout"></a>Layer-wise Dropout</h3><p>éšæœºåˆ é™¤éƒ¨åˆ†layerï¼Œè¿™äº›layerçš„è¾“å‡ºä¸ä¼šä¼ å…¥ä¹‹åçš„å±‚ï¼Œä½†ä»ç„¶ä¼šå‚ä¸æœ€åçš„representationè®¡ç®—ã€‚<br><img src="/images/2018-11-11-15419000928057.jpg" width="70%" height="50%"></p><p>è¿™ç§dropoutä¼šè®©perplexityæ›´é«˜ï¼Œä½†å¯¹ç”Ÿæˆæ›´å¥½çš„representationæœ‰å¸®åŠ©ã€‚</p><hr><h2 id="3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder"><a href="#3ï¸âƒ£-Constituency-Parsing-with-a-Self-Attentive-Encoder" class="headerlink" title="3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]"></a>3ï¸âƒ£[Constituency Parsing with a Self-Attentive Encoder]</h2><p>å…¶ä¸­çš„positional encodingæˆ‘æ¯”è¾ƒæ„Ÿå…´è¶£ã€‚<br>åŸç‰ˆçš„positional encodingæ˜¯ç›´æ¥å’Œembeddingç›¸åŠ çš„ã€‚<br>äº¦å³ï¼š<br><img src="/images/2018-11-11-15419002563338.jpg" width="22%" height="50%"><br>é‚£ä¹ˆåœ¨selt-attentionæ—¶ï¼Œæœ‰ï¼š<br><img src="/images/2018-11-11-15419002855901.jpg" width="45%" height="50%"><br>è¿™æ ·ä¼šæœ‰äº¤å‰é¡¹ï¼š<br><img src="/images/2018-11-11-15419003111684.jpg" width="13%" height="50%"><br>è¯¥é¡¹æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ï¼Œä¸”å¯èƒ½ä¼šå¸¦æ¥è¿‡æ‹Ÿåˆã€‚</p><p>å› æ­¤åœ¨è¿™è¾¹å°†positional encodingå’Œembeddingæ‹¼èµ·æ¥ï¼Œäº¦å³ï¼š<br><img src="/images/2018-11-11-15419003740409.jpg" width="23%" height="50%"></p><p>å¹¶ä¸”ï¼Œåœ¨è¿›å…¥multi-headæ—¶çš„çº¿æ€§å±‚ä¹Ÿåšæ”¹å˜ï¼š<br><img src="/images/2018-11-11-15419004269693.jpg" width="24%" height="50%"></p><p>è¿™æ ·åœ¨ç›¸ä¹˜çš„æ—¶å€™å°±ä¸ä¼šæœ‰äº¤å‰é¡¹äº†ã€‚</p><p>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰ä¸€å®šçš„æå‡ã€‚</p><hr><h2 id="4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks"><a href="#4ï¸âƒ£-DropBlock-A-regularization-method-for-convolutional-networks" class="headerlink" title="4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]"></a>4ï¸âƒ£[DropBlock: A regularization method for convolutional networks]</h2><p>å¤§è‡´ç¿»äº†ä¸€ä¸‹ã€‚<br>Motivation:åœ¨CNNä¸­ï¼Œdropoutå¯¹convolutional layerçš„ä½œç”¨ä¸å¤§ï¼Œä¸€èˆ¬éƒ½åªç”¨åœ¨å…¨è¿æ¥å±‚ã€‚ä½œè€…æ¨æµ‹ï¼Œå› ä¸ºæ¯ä¸ªfeature mapéƒ½æœ‰ä¸€ä¸ªæ„Ÿå—é‡èŒƒå›´ï¼Œä»…ä»…å¯¹å•ä¸ªåƒç´ è¿›è¡Œdropoutå¹¶ä¸èƒ½é™ä½feature mapå­¦ä¹ çš„ç‰¹å¾èŒƒå›´ï¼Œäº¦å³ç½‘ç»œä»å¯ä»¥é€šè¿‡è¯¥ä½ç½®çš„ç›¸é‚»ä½ç½®å…ƒç´ å»å­¦ä¹ å¯¹åº”çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¹Ÿå°±ä¸ä¼šä¿ƒä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ã€‚</p><p>å› æ­¤ä½œè€…çš„åšæ³•æ˜¯ï¼Œdropoutä¸€æ•´å—ä½ç½®ã€‚<br><img src="/images/2018-11-11-15419007355875.jpg" width="80%" height="50%"></p><hr><h2 id="5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network"><a href="#5ï¸âƒ£-Accelerating-Neural-Transformer-via-an-Average-Attention-Network" class="headerlink" title="5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]"></a>5ï¸âƒ£[Accelerating Neural Transformer via an Average Attention Network]</h2><p>æå‡ºäº†AAN(average attention network)ï¼Œå¯¹transformerç¿»è¯‘æ¨¡å‹çš„decodeéƒ¨åˆ†è¿›è¡Œæ”¹è¿›ï¼ŒåŠ é€Ÿäº†è¿‡ç¨‹ã€‚</p><p>ç”±äºTransformeråœ¨decodeé˜¶æ®µéœ€è¦ç”¨åˆ°å‰é¢æ‰€æœ‰çš„yï¼Œä¹Ÿå³è‡ªå›å½’(auto-regressive)çš„æ€§è´¨ï¼Œæ‰€ä»¥æ— æ³•å¹¶è¡Œï¼š</p><p><img src="/images/2018-11-11-15419009098650.jpg" width="50%" height="50%"></p><h3 id="è¿‡ç¨‹"><a href="#è¿‡ç¨‹" class="headerlink" title="è¿‡ç¨‹"></a>è¿‡ç¨‹</h3><p>ç»™å®šyï¼š<br><img src="/images/2018-11-11-15419010325049.jpg" width="27%" height="50%"></p><p>é¦–å…ˆå°†ä»–ä»¬åŠ èµ·æ¥ï¼Œè¿‡ä¸€å±‚å…¨è¿æ¥ï¼š<br><img src="/images/2018-11-11-15419010603010.jpg" width="27%" height="50%"><br>è¿™ä¹Ÿç›¸å½“äºå°±æ˜¯è®©æ‰€æœ‰çš„yæœ‰ç›¸åŒçš„æƒé‡ï¼Œæ­¤æ—¶gå°±æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡¨ç¤ºã€‚</p><p>æ¥ä¸‹æ¥æ·»åŠ ä¸€ä¸ªgatingï¼š<br><img src="/images/2018-11-11-15419011154221.jpg" width="27%" height="50%"><br>æ§åˆ¶äº†ä»è¿‡å»ä¿å­˜å¤šå°‘ä¿¡æ¯å’Œè·å–å¤šå°‘æ–°çš„ä¿¡æ¯ã€‚</p><p>å’ŒTransformeråŸç‰ˆè®ºæ–‡ä¸€æ ·ï¼Œæ·»åŠ ä¸€ä¸ªresidual connectionï¼š<br><img src="/images/2018-11-11-15419011595237.jpg" width="30%" height="50%"></p><p>å¦‚å›¾æ•´ä¸ªè¿‡ç¨‹ï¼š<br><img src="/images/2018-11-11-15419011840751.jpg" width="55%" height="50%"></p><p>æ€»ç»“ï¼šAAN=average layer+gating layer</p><h3 id="åŠ é€Ÿ"><a href="#åŠ é€Ÿ" class="headerlink" title="åŠ é€Ÿ"></a>åŠ é€Ÿ</h3><p>â‘ è€ƒè™‘åˆ°åŠ å’Œæ“ä½œæ˜¯åºåˆ—åŒ–çš„ï¼Œåªèƒ½ä¸€ä¸ªä¸€ä¸ªæ¥ï¼Œä¸èƒ½å¹¶è¡Œï¼Œåœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªmaskçš„trickï¼Œä½¿å¾—åœ¨è®­ç»ƒæ—¶ä¹Ÿèƒ½å¤Ÿå¹¶è¡Œï¼š<br><img src="/images/2018-11-11-15419013219526.jpg" width="60%" height="50%"></p><p>â‘¡åœ¨inferenceæ—¶çš„åŠ é€Ÿï¼š<br><img src="/images/2018-11-11-15419019335926.jpg" width="20%" height="50%"></p><p>è¿™æ ·Transformerå°±èƒ½å¤Ÿç±»ä¼¼RNNï¼Œåªè€ƒè™‘å‰ä¸€ä¸ªçš„stateï¼Œè€Œä¸æ˜¯å‰é¢æ‰€æœ‰çš„stateã€‚</p><p>æœ€ç»ˆçš„æ¨¡å‹ï¼š<br><img src="/images/2018-11-11-15419023032628.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> dropout </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> self-attention </tag>
            
            <tag> NTM </tag>
            
            <tag> ELMo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯15</title>
      <link href="/2018/11/10/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D15/"/>
      <url>/2018/11/10/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D15/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£èœ€ç›¸"><a href="#1ï¸âƒ£èœ€ç›¸" class="headerlink" title="1ï¸âƒ£èœ€ç›¸"></a>1ï¸âƒ£èœ€ç›¸</h3><p>[å”] æœç”«<br>ä¸ç›¸ç¥ å ‚ä½•å¤„å¯»ï¼Œé”¦å®˜åŸå¤–æŸæ£®æ£®ã€‚<br>æ˜ é˜¶ç¢§è‰è‡ªæ˜¥è‰²ï¼Œéš”å¶é»„é¹‚ç©ºå¥½éŸ³ã€‚<br>ä¸‰é¡¾é¢‘çƒ¦å¤©ä¸‹è®¡ï¼Œä¸¤æœå¼€æµè€è‡£å¿ƒã€‚<br><strong>å‡ºå¸ˆæœªæ·èº«å…ˆæ­»ï¼Œé•¿ä½¿è‹±é›„æ³ªæ»¡è¥Ÿ</strong>ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b93410a633bd00665efd4a</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡4</title>
      <link href="/2018/11/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%874/"/>
      <url>/2018/11/04/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%874/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention"><a href="#1ï¸âƒ£-Character-Level-Language-Modeling-with-Deeper-Self-Attention" class="headerlink" title="1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]"></a>1ï¸âƒ£[Character-Level Language Modeling with Deeper Self-Attention]</h2><p>å°†transformerç”¨äºcharacter-levelçš„è¯­è¨€æ¨¡å‹ä¸­ï¼Œé€šè¿‡æ·»åŠ å¤šä¸ªlossæ¥æé«˜å…¶è¡¨ç°ä»¥åŠåŠ å¿«æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶åŠ æ·±transformerçš„å±‚æ•°ï¼Œæå¤§æå‡è¡¨ç°ï¼Œ12å±‚çš„transformer layerèƒ½è¾¾åˆ°SOTAï¼Œè€Œ64å±‚åˆ™æœ‰æ›´å¤šçš„æå‡ã€‚</p><p>æ™®é€šRNNç”¨äºcharacter-level language modelï¼š<br>å°†å¥å­æŒ‰characterä¸ºå•ä½ç»„æˆå¤šä¸ªbatchï¼Œæ¯ä¸ªbatché¢„æµ‹æœ€åä¸€ä¸ªè¯ï¼Œç„¶åå°†è¯¥batchçš„éšçŠ¶æ€ä¼ å…¥ä¸‹ä¸€ä¸ªbatchã€‚ä¹Ÿå³â€œtruncated backpropagation through timeâ€ (TBTT)ã€‚</p><p>å¦‚æœç”¨åœ¨Transformerï¼Œå¦‚ä¸‹å›¾ï¼Œæˆ‘ä»¬åªé¢„æµ‹$t_4$ã€‚<br><img src="/images/2018-11-04-15412915431327.jpg" width="90%" height="50%"></p><p>æœ¬æ–‡çš„ä¸€å¤§è´¡çŒ®æ˜¯å¤šåŠ äº†ä¸‰ç§lossï¼Œå¹¶ä¸”æœ‰äº›lossçš„æƒå€¼ä¼šéšç€è®­ç»ƒçš„è¿‡ç¨‹è€Œé€æ¸å‡å°ï¼Œæ¯ä¸ªlosséƒ½ä¼šè‡ªå·±çš„scheduleã€‚è¿™äº›lossåŠ å¿«äº†æ‹Ÿåˆé€Ÿåº¦ï¼ŒåŒæ—¶ä¹Ÿæå‡äº†è¡¨ç°ã€‚</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><h4 id="Multiple-Positions"><a href="#Multiple-Positions" class="headerlink" title="Multiple Positions"></a>Multiple Positions</h4><p>å¯¹äºbatchå†…è€Œè¨€ï¼Œæ¯ä¸ªæ—¶é—´æ­¥téƒ½è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚<br><img src="/images/2018-11-04-15412916429104.jpg" width="90%" height="50%"></p><h4 id="Intermediate-Layer-Losses"><a href="#Intermediate-Layer-Losses" class="headerlink" title="Intermediate Layer Losses"></a>Intermediate Layer Losses</h4><p>è¦æ±‚ä¸­é—´å±‚ä¹Ÿåšå‡ºé¢„æµ‹ï¼š<br><img src="/images/2018-11-04-15412916704097.jpg" width="95%" height="50%"></p><p>åœ¨è¿™é‡Œï¼Œè¶Šåº•å±‚çš„layerå…¶lossæƒå€¼è¶Šä½ã€‚</p><h4 id="Multiple-Targets"><a href="#Multiple-Targets" class="headerlink" title="Multiple Targets"></a>Multiple Targets</h4><p>æ¯ä¸€ä¸ªpositionï¼Œä¸ä»…ä»…è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿˜è¦é¢„æµ‹ä¸‹å‡ ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å’Œé¢„æµ‹ä¸‹å‡ ä¸ªè¯çš„åˆ†ç±»å™¨æ˜¯ç‹¬ç«‹çš„ã€‚</p><p><img src="/images/2018-11-04-15412917374689.jpg" width="70%" height="50%"></p><h3 id="Positional-embedding"><a href="#Positional-embedding" class="headerlink" title="Positional embedding"></a>Positional embedding</h3><p>æ¯ä¸€å±‚çš„éƒ½æ·»åŠ ä¸€ä¸ªä¸å…±äº«çš„å¯å­¦ä¹ çš„positional embeddingã€‚</p><hr><h2 id="2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations"><a href="#2ï¸âƒ£-Self-Attention-with-Relative-Position-Representations" class="headerlink" title="2ï¸âƒ£[Self-Attention with Relative Position Representations]"></a>2ï¸âƒ£[Self-Attention with Relative Position Representations]</h2><p>æå‡ºä½¿ç”¨ç›¸å¯¹ä½ç½®æ›¿ä»£Transformerçš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¹¶åœ¨NMTä¸Šæœ‰ä¸€å®šçš„æå‡ã€‚</p><p>åˆ†è§£ï¼š<br>åœ¨åŸå…ˆçš„self-attentionä¸­ï¼Œè¾“å‡ºä¸ºï¼š<br><img src="/images/2018-11-04-15412923510664.jpg" width="25%" height="50%"></p><p>å…¶ä¸­ï¼š<br><img src="/images/2018-11-04-15412923744647.jpg" width="25%" height="50%"><br><img src="/images/2018-11-04-15412923773686.jpg" width="25%" height="50%"></p><p>ç°åœ¨æˆ‘ä»¬è€ƒè™‘æ·»åŠ ç›¸å¯¹ä½ç½®ï¼Œå…¶ä¸­ç›¸å¯¹ä½ç½®ä¿¡æ¯åœ¨å„å±‚éƒ½æ˜¯å…±äº«çš„ï¼š<br><img src="/images/2018-11-04-15412924279426.jpg" width="30%" height="50%"><br><img src="/images/2018-11-04-15412924396468.jpg" width="30%" height="50%"></p><p>$a_{ij}^K$çš„å…·ä½“å½¢å¼ï¼š<br><img src="/images/2018-11-04-15412925792994.jpg" width="40%" height="50%"><br><img src="/images/2018-11-04-15412925910424.jpg" width="55%" height="50%"><br>ä¸Šå¼ä¸ºäº†é™ä½å¤æ‚åº¦ï¼Œä¸è€ƒè™‘é•¿äºkçš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚</p><p>è€ƒè™‘åˆ°transformerçš„å¹¶è¡Œæ€§ï¼Œä¸ºäº†å¹¶è¡Œæ€§ï¼Œæˆ‘ä»¬è€ƒè™‘å¦‚ä¸‹å¼å­ï¼š<br><img src="/images/2018-11-04-15412926687951.jpg" width="50%" height="50%"><br>å…¶ä¸­ï¼Œç¬¬ä¸€é¡¹å’ŒåŸæ¥çš„Transformerä¸€è‡´ï¼›ç¬¬äºŒé¡¹ï¼Œé€šè¿‡reshapeå¯ä»¥è¾¾åˆ°å¹¶è¡Œçš„æ•ˆæœï¼Œç„¶åä¸¤é¡¹ç›´æ¥åŠ èµ·æ¥ã€‚</p><p>å®éªŒè¯æ˜ï¼Œä½¿ç”¨ç›¸å¯¹ä½ç½®æ•ˆæœæ˜¯æœ‰ä¸€å®šçš„æå‡çš„ï¼Œè€ŒåŒæ—¶ä½¿ç”¨ç»å¯¹ä½ç½®å’Œç›¸å¯¹ä½ç½®å¹¶æ²¡æœ‰æå‡ã€‚<br><img src="/images/2018-11-04-15412930642978.jpg" width="90%" height="50%"></p><hr><h2 id="3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION"><a href="#3ï¸âƒ£-WEIGHTED-TRANSFORMER-NETWORK-FOR-MACHINE-TRANSLATION" class="headerlink" title="3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]"></a>3ï¸âƒ£[WEIGHTED TRANSFORMER NETWORK FOR MACHINE TRANSLATION]</h2><p>è¿™ç¯‡è¢«ICLRæ‹’äº†ï¼Œä½†æœ‰å®¡ç¨¿äººæ‰“äº†9åˆ†çš„é«˜åˆ†ã€‚</p><p>å¯¹Transformerè¿›è¡Œæ”¹è¿›ï¼Œæ‹¥æœ‰æ›´å¥½çš„æ•ˆæœå’Œæ›´å°çš„è®¡ç®—ä»£ä»·ã€‚</p><p>ä¼ ç»Ÿçš„Transformerï¼š</p><script type="math/tex; mode=display">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V</script><script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">MultiHead(Q,K,V)=Concat_i (head_i)W^O</script><script type="math/tex; mode=display">FFN(x)=max(0,xW_1+b_1)W_2 + b_2</script><p>åœ¨æœ¬æ–‡ä¸­ï¼Œå…ˆå¯¹headè¿›è¡Œå‡ç»´å¹¶ä¹˜ä»¥æƒé‡ï¼Œè¿‡äº†FNNåï¼Œå†ä¹˜ä»¥å¦ä¸€ä¸ªæƒé‡ã€‚å…¶ä¸­æƒé‡$\alpha$ $ \kappa$ä¸ºå¯å­¦ä¹ å‚æ•°ï¼š</p><script type="math/tex; mode=display">head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)</script><script type="math/tex; mode=display">\overline{head_i}=head_i W^{O_i} \times \kappa_i</script><script type="math/tex; mode=display">BranchedAttention(Q,K,V)=\sum_{i=1}^{M} \alpha_i FFN(\overline{head}_i)</script><p>å…¶ä¸­è¦æ±‚æƒé‡ä¹‹å’Œä¸º1ã€‚å³$\sum_{i=1}^{M}\alpha_i=1$,$\sum_{i=1}^{M}\kappa_i=1$ã€‚</p><p><img src="/images/2018-11-04-15412939412047.jpg" width="90%" height="50%"></p><p>æ–‡ä¸­å¯¹$\kappa$å’Œ$\alpha$ä½œäº†è§£é‡Šã€‚</p><blockquote><p>Îº can be interpreted as a learned concatenation weight and Î± as the learned addition weight</p></blockquote><p>é€šè¿‡å®éªŒï¼Œå‘ç°è¯¥æ¨¡å‹ä¼šæœ‰æ›´å¥½çš„æ­£åˆ™åŒ–ç‰¹æ€§ã€‚åŒæ—¶æ•ˆæœä¹Ÿæœ‰ä¸€å®šæå‡ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼š<br><img src="/images/2018-11-04-15412940966579.jpg" width="80%" height="50%"></p><hr><h2 id="4ï¸âƒ£-You-May-Not-Need-Attention"><a href="#4ï¸âƒ£-You-May-Not-Need-Attention" class="headerlink" title="4ï¸âƒ£[You May Not Need Attention]"></a>4ï¸âƒ£[You May Not Need Attention]</h2><p>ç²—ç•¥åœ°è¿‡äº†ä¸€éï¼Œä¸€äº›ç»†èŠ‚æ²¡æœ‰å¼„æ˜ç™½ã€‚</p><p>æå‡ºä¸€ç§å°†encoder-decoderèåˆèµ·æ¥çš„æ¨¡å‹ï¼Œä¹Ÿå³eager translation modelï¼Œä¸éœ€è¦attentionï¼Œèƒ½å¤Ÿå®ç°å³æ—¶çš„ç¿»è¯‘ï¼Œä¹Ÿå³è¯»å…¥ä¸€ä¸ªè¯å°±èƒ½ç¿»è¯‘ä¸€ä¸ªè¯ï¼ŒåŒæ—¶ä¸éœ€è¦è®°å½•encoderçš„æ‰€æœ‰è¾“å‡ºï¼Œå› æ­¤éœ€è¦å¾ˆå°‘çš„å†…å­˜ã€‚</p><p><img src="/images/2018-11-04-15412942175720.jpg" width="50%" height="50%"></p><p>åˆ†ä¸ºä¸‰æ­¥ï¼š<br>â‘ pre-processing<br>è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿å¾—æºå¥å­å’Œç›®æ ‡å¥å­æ»¡è¶³<strong>eager feasible</strong> for every aligned pair of words $(s_i , t_j ), i â‰¤ j$ã€‚</p><p>é¦–å…ˆé€šè¿‡ç°æˆçš„å·¥å…·è¿›è¡Œå¯¹é½æ“ä½œ(alignment)ï¼Œç„¶åå¯¹äºé‚£äº›ä¸ç¬¦åˆeager feasibleçš„æœ‰å…·ä½“ç®—æ³•ï¼ˆæ²¡è®¤çœŸçœ‹ï¼‰è¿›è¡Œè¡¥paddingã€‚å¦‚å›¾<br><img src="/images/2018-11-04-15412945231042.jpg" width="60%" height="50%"></p><p>æˆ‘ä»¬è¿˜å¯ä»¥åœ¨target sentenceçš„å¼€å¤´æ·»åŠ bä¸ªpaddingï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¼€å§‹é¢„æµ‹ä¹‹å‰è·å–æ›´å¤šçš„source sentenceçš„è¯ã€‚</p><p>â‘¡æ¨¡å‹<br>ä¸¤å±‚çš„LSTMï¼Œè¾“å…¥æ˜¯ä¸Šä¸€æ¬¡çš„yå’Œå½“å‰çš„xæ‹¼æ¥èµ·æ¥ç›´æ¥ä¼ è¿›å»ã€‚</p><p>â‘¢post processing<br>åœ¨æœ€ç»ˆç»“æœä¹‹å‰ï¼Œå°†paddingå»æ‰ã€‚</p><p>åœ¨inferenceï¼ˆä¹Ÿå³beam searchï¼‰æ—¶ï¼Œè¿˜æœ‰å‡ ä¸ªæ“ä½œ/trickï¼š</p><ul><li>Padding limit</li><li>Source padding injection SPI</li></ul><p>å®éªŒè¡¨æ˜ï¼Œeager modelåœ¨é•¿çš„å¥å­è¡¨ç°è¶…è¿‡ä¼ ç»Ÿå¸¦attentionçš„NMTï¼Œè€Œé•¿å¥å­çš„å»ºæ¨¡æ­£æ˜¯attention-based çš„æ¨¡å‹çš„ä¸€å¤§æŒ‘æˆ˜ï¼›è€Œåœ¨çŸ­å¥å­ä¸Šå°±ä¸å¦‚attention-basedçš„NMTã€‚<br><img src="/images/2018-11-04-15412946442983.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> Language Modeling </tag>
            
            <tag> self-attention </tag>
            
            <tag> relative position </tag>
            
            <tag> positional encoding </tag>
            
            <tag> NMT </tag>
            
            <tag> eager translation model </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯14</title>
      <link href="/2018/11/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D14/"/>
      <url>/2018/11/04/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D14/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£é¹¤å†²å¤©"><a href="#1ï¸âƒ£é¹¤å†²å¤©" class="headerlink" title="1ï¸âƒ£é¹¤å†²å¤©"></a>1ï¸âƒ£é¹¤å†²å¤©</h3><p>[å®‹] æŸ³æ°¸<br>é»„é‡‘æ¦œä¸Šï¼Œå¶å¤±é¾™å¤´æœ›ã€‚æ˜ä»£æš‚é—è´¤ï¼Œå¦‚ä½•å‘ï¼Ÿæœªé‚é£äº‘ä¾¿ï¼Œäº‰ä¸æ£æ¸¸ç‹‚è¡ã€‚ä½•é¡»è®ºå¾—ä¸§ï¼Ÿæ‰å­è¯äººï¼Œè‡ªæ˜¯ç™½è¡£å¿ç›¸ã€‚<br>çƒŸèŠ±å··é™Œï¼Œä¾çº¦ä¸¹é‘å±›éšœã€‚å¹¸æœ‰æ„ä¸­äººï¼Œå ªå¯»è®¿ã€‚ä¸”æåçº¢å€šç¿ ï¼Œé£æµäº‹ï¼Œå¹³ç”Ÿç•…ã€‚é‘æ˜¥éƒ½ä¸€é¥·ã€‚<strong>å¿æŠŠæµ®åï¼Œæ¢äº†æµ…æ–Ÿä½å”±</strong>ï¼</p><p>æ£ï¼ˆzÃ¬ï¼‰ï¼šæ”¾çºµï¼Œéšå¿ƒæ‰€æ¬²ã€‚<br>æï¼ˆnÃ¨nï¼‰ï¼šå¦‚æ­¤ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aeff68a633bd0057f7d406</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•9</title>
      <link href="/2018/11/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%959/"/>
      <url>/2018/11/04/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%959/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-collate-fn"><a href="#1ï¸âƒ£-collate-fn" class="headerlink" title="1ï¸âƒ£[collate_fn]"></a>1ï¸âƒ£[collate_fn]</h3><p>å°†ä¸ç­‰é•¿å¥å­ç»„åˆæˆbatchã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(insts)</span>:</span></span><br><span class="line">    <span class="string">''' Pad the instance to the max seq length in batch '''</span></span><br><span class="line"></span><br><span class="line">    max_len = max(len(inst) <span class="keyword">for</span> inst <span class="keyword">in</span> insts)</span><br><span class="line"></span><br><span class="line">    batch_seq = np.array([</span><br><span class="line">        inst + [Constants.PAD] * (max_len - len(inst))</span><br><span class="line">        <span class="keyword">for</span> inst <span class="keyword">in</span> insts])</span><br><span class="line"></span><br><span class="line">    batch_pos = np.array([</span><br><span class="line">        [pos_i + <span class="number">1</span> <span class="keyword">if</span> w_i != Constants.PAD <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">         <span class="keyword">for</span> pos_i, w_i <span class="keyword">in</span> enumerate(inst)] <span class="keyword">for</span> inst <span class="keyword">in</span> batch_seq]) <span class="comment"># ä½ç½®ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line">    batch_seq = torch.LongTensor(batch_seq)</span><br><span class="line">    batch_pos = torch.LongTensor(batch_pos)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_seq, batch_pos</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>â€œè±æ–¯æ¯â€æŒ‘æˆ˜èµ›æœ‰æ„Ÿ</title>
      <link href="/2018/10/30/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E2%80%9C%E8%8E%B1%E6%96%AF%E6%9D%AF%E2%80%9D%E6%8C%91%E6%88%98%E8%B5%9B%E6%9C%89%E6%84%9F/"/>
      <url>/2018/10/30/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E2%80%9C%E8%8E%B1%E6%96%AF%E6%9D%AF%E2%80%9D%E6%8C%91%E6%88%98%E8%B5%9B%E6%9C%89%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<p>å†æ—¶ä¸‰ä¸ªæœˆçš„â€œè±æ–¯æ¯â€å…¨å›½ç¬¬ä¸€å±Šâ€œå†›äº‹æ™ºèƒ½Â·æœºå™¨é˜…è¯»â€æŒ‘æˆ˜èµ›ç»ˆäºè½ä¸‹å¸·å¹•ï¼Œå‰å‡ æ—¥ï¼ˆ10.26-10.28ï¼‰æœ‰å¹¸åœ¨å—äº¬é’æ—…å®¾é¦†å‚ä¸å†³èµ›ï¼Œä½“éªŒå¤šå¤šï¼Œæ”¶è·æ»¡æ»¡ï¼Œå¿ƒä¸­äº¦æœ‰ä¸€äº›æ„Ÿæƒ³ã€‚</p><p>ä¸€ä¸ªæ˜¯å—äº¬æ€»å¸¦ç»™æˆ‘ä¸€ç§å›å®¶çš„æ„Ÿè§‰ï¼Œå¯¹å—äº¬çš„äº‹ç‰©æ€»æœ‰äº²åˆ‡æ„Ÿã€‚ç¬¬ä¸€æ¬¡æ¥å—äº¬æ˜¯ä¸€å¹´åŠå‰ï¼Œä¹Ÿæ˜¯æ¥å‚åŠ æ¯”èµ›ã€‚å‘¨äº”æ™šä¸Šçš„å¤œæ¸¸ç§¦æ·®ï¼Œè®©æˆ‘æ„Ÿå—åˆ°è®¸ä¹…æœªæ›¾æ„Ÿå—åˆ°çš„çƒŸç«æ°”æ¯ã€‚</p><p><img src="/images/2018-10-30-511540860855_.pic_hd.jpg" width="90%" height="50%"></p><p>ç¬¬äºŒä¸ªæ˜¯æ­¤æ¬¡ä¸»åŠæ–¹æä¾›çš„é£Ÿå®¿ä»¤äººæƒŠå–œã€‚ä¸€å¼€å§‹å¬åˆ°é’æ—…å®¾é¦†ï¼Œæˆ‘å·²ç»åšå¥½äº†è‰°è‹¦å¥‹æˆ˜çš„å‡†å¤‡äº†ï¼Œç„¶è€Œé…’åº—æ˜¯æ˜Ÿçº§é…’åº—çš„ï¼Œåƒæ–¹é¢ç›´æ¥åˆ°æ¥¼ä¸‹çš„è‡ªåŠ©ã€‚å¯ä»¥çœ‹å‡ºä¸»åŠæ–¹æ­¤æ¬¡ç¡®å®ç”¨å¿ƒåœ¨ä¸¾åŠè¿™æ¬¡æ¯”èµ›ã€‚</p><p><img src="/images/2018-10-30-15408644190676.jpg" width="100%" height="50%"></p><p>ç¬¬ä¸‰ç‚¹æ˜¯å…³äºæ¯”èµ›çš„ï¼Œå…³äºæ¯”èµ›çš„æ•´ä¸ªå†ç¨‹æˆ‘è¿˜æ˜¯é¢‡æœ‰æ„Ÿè§¦ã€‚<br>æˆ‘ä»¬æ˜¯ä»¥ç¬¬9åçš„æˆç»©æŒºè¿›å†³èµ›ï¼Œå…¶å®åœ¨åæœŸæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬éƒ½æœ‰æ‰€æ‡ˆæ€ äº†ï¼Œå‡ ä¹æ²¡æœ‰èŠ±æ—¶é—´åœ¨è¿™ä¸Šé¢ï¼Œ10æœˆåˆå‘å¸ƒå†³èµ›çš„æ•°æ®é›†ï¼Œè€Œæˆ‘ä»¬åœ¨10æœˆ20æ—¥æ‰å¾—çŸ¥è¿™ä¸€äº‹æƒ…ï¼Œæ­¤æ—¶ç¦»å†³èµ›åªå‰©ä¸€å‘¨æ—¶é—´ã€‚å› æ­¤æˆ‘ä»¬ç¡®å®å‡†å¤‡ä¸è¶³ã€‚å½“ç„¶æˆ‘ä»¬ä¹Ÿæ²¡æœ‰é¢„æ–™åˆ°æˆ‘ä»¬çš„å†³èµ›æˆç»©ä¼šè¿™ä¹ˆé å‰ï¼Œå¦åˆ™æˆ‘ä»¬è‚¯å®šä¼šæ›´åŠ å……åˆ†å»å‡†å¤‡ã€‚è¿™ç¡®å®æ˜¯æˆ‘ä»¬çš„å¤±è¯¯ã€‚</p><p>æˆ‘ä»¬åœ¨æ¯”èµ›è¿‡ç¨‹ä¸­ï¼Œä¸€ç›´å°è¯•åœ¨ä½¿ç”¨ELMoï¼Œè¿™æ­£æ˜¯æˆ‘è´Ÿè´£çš„éƒ¨åˆ†ã€‚ä¸€å¼€å§‹ä½¿ç”¨å®˜æ–¹TensorFlowçš„ä»£ç ï¼Œè´¹äº†ä¹ç‰›äºŒè™ä¹‹åŠ›æˆ‘æ‰è·‘é€šä»£ç ï¼Œä½†å› ä¸ºé˜Ÿé•¿ä½¿ç”¨çš„æ˜¯pytorchï¼Œè€ŒäºŒè€…åœ¨cudaç‰ˆæœ¬ä¸Šä¸å…¼å®¹ï¼Œå› æ­¤åœ¨åˆèµ›æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ELMoã€‚è€Œåœ¨æœ€åå‡ å¤©ï¼Œæˆ‘å°è¯•ä½¿ç”¨å“ˆå·¥å¤§çš„pytorchè®­ç»ƒä»£ç ï¼Œä½†å› ä¸ºinferenceé€Ÿåº¦å®åœ¨å¤ªæ…¢ï¼Œæˆ‘ä»¬æœ€ç»ˆè¿˜æ˜¯å¼ƒç”¨äº†è¿™ä¸ªæ–¹æ¡ˆã€‚è€Œåœ¨å†³èµ›ç°åœºï¼Œæˆ‘ä»¬å‘ç°ä¹Ÿç¡®å®æ˜¯å› ä¸ºé€Ÿåº¦å’Œèµ„æºçš„åŸå› ï¼Œå¤§å®¶éƒ½æ²¡æœ‰ä½¿ç”¨ELMoï¼Œé™¤äº†ä¸€ç»„ã€‚è¯¥ç»„æ­£æ˜¯å‡­å€Ÿäº†ELMoå¼¯é“è¶…è½¦ä»ç¬¬7å‡åˆ°äº†ç¬¬ä¸€ï¼Œæ‹¿èµ°äº†20ä¸‡å¤§å¥–ã€‚è¿™ä¹Ÿæ˜¯æˆ‘ä»¬éå¸¸é—æ†¾çš„ä¸€ä¸ªåœ°æ–¹ï¼Œæˆ‘ä»¬åœ¨é‡åˆ°å›°éš¾æ—¶æ²¡æœ‰å°è¯•è§£å†³ï¼Œè€Œæ˜¯ç›´æ¥å¼ƒç”¨ï¼Œæœ€ç»ˆæ²¡æœ‰å–å¾—æ›´å¥½çš„æˆç»©ã€‚</p><p>æ­¤æ¬¡æˆ‘ä»¬çš„æˆç»©æ’åç¬¬4(ä¸‰ç­‰å¥–)ï¼Œæ˜¯æœ‰ä¸€å®šçš„è¿›æ­¥çš„ï¼Œä½†æœ‰ä¸€ç‚¹é—æ†¾çš„æ˜¯ï¼Œæˆ‘ä»¬ä»…å·®0.18ç™¾åˆ†ç‚¹ï¼Œå°±èƒ½è¶…è¿‡ç¬¬ä¸‰åæ‹¿åˆ°5ä¸‡çš„å¥–é‡‘äº†ã€‚åé¢æˆ‘ä»¬åˆ†æäº†ä¸€ä¸‹ï¼Œè¿˜æ˜¯å› ä¸ºæˆ‘ä»¬å¯¹æ¯”èµ›æ‡ˆæ€ çš„æ€åº¦ï¼Œå…¶ä»–ç»„éƒ½å¯¹æ•°æ®è¿›è¡Œäº†åˆ†æå¹¶æœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ï¼Œè€Œæˆ‘ä»¬å¹¶æ²¡æœ‰åšè¿™ä¸€æ­¥ã€‚</p><p>Anywayï¼Œç¬¬ä¸€æ¬¡ç»„é˜Ÿå‚åŠ æ¯”èµ›å°±æœ‰æ”¶è·ï¼Œå¢é•¿äº†è§è¯†ï¼Œä»äº¤æµä¸­ä¹Ÿè·å¾—äº†è®¸å¤šã€‚è¿™ä¸ªæ¯”èµ›ä¹‹åï¼Œå°±å¾—å¥½å¥½çœ‹paperäº†ã€‚ __(:Ğ·ã€âˆ )_</p><p><img src="/images/2018-10-30-521540861008_.pic_hd.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœ‰æ„Ÿ </tag>
            
            <tag> è±æ–¯æ¯ </tag>
            
            <tag> æ¯”èµ› </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯13</title>
      <link href="/2018/10/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D13/"/>
      <url>/2018/10/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D13/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"><a href="#1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–" class="headerlink" title="1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–"></a>1ï¸âƒ£è¡Œè·¯éš¾ä¸‰é¦–</h3><p>[å”] æç™½<br>ã€å…¶ä¸€ã€‘<br>é‡‘æ¨½æ¸…é…’æ–—ååƒï¼Œç‰ç›˜çç¾ç›´ä¸‡é’±ã€‚<br><strong>åœæ¯æŠ•ç®¸ä¸èƒ½é£Ÿï¼Œæ‹”å‰‘å››é¡¾å¿ƒèŒ«ç„¶</strong>ã€‚<br>æ¬²æ¸¡é»„æ²³å†°å¡å·ï¼Œå°†ç™»å¤ªè¡Œé›ªæ»¡å±±ã€‚<br>é—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚<br>è¡Œè·¯éš¾ï¼Œè¡Œè·¯éš¾ï¼Œå¤šæ­§è·¯ï¼Œä»Šå®‰åœ¨ï¼Ÿ<br><strong>é•¿é£ç ´æµªä¼šæœ‰æ—¶ï¼Œç›´æŒ‚äº‘å¸†æµæ²§æµ·</strong>ï¼</p><p><strong>æ³¨é‡Š</strong>ï¼š<br>ã€Œé—²æ¥å‚é’“ç¢§æºªä¸Šï¼Œå¿½å¤ä¹˜èˆŸæ¢¦æ—¥è¾¹ã€‚ã€å¥ï¼šæš—ç”¨å…¸æ•…ï¼šå§œå¤ªå…¬å•å°šæ›¾åœ¨æ¸­æ°´çš„ç£»æºªä¸Šé’“é±¼ï¼Œå¾—é‡å‘¨æ–‡ç‹ï¼ŒåŠ©å‘¨ç­å•†ï¼›ä¼Šå°¹æ›¾æ¢¦è§è‡ªå·±ä¹˜èˆ¹ä»æ—¥æœˆæ—è¾¹ç»è¿‡ï¼Œåè¢«å•†æ±¤è˜è¯·ï¼ŒåŠ©å•†ç­å¤ã€‚è¿™ä¸¤å¥è¡¨ç¤ºè¯—äººè‡ªå·±å¯¹ä»æ”¿ä»æœ‰æ‰€æœŸå¾…ã€‚ç¢§ï¼Œä¸€ä½œã€Œåã€ã€‚</p><hr><h3 id="2ï¸âƒ£ç™»ç§‘å"><a href="#2ï¸âƒ£ç™»ç§‘å" class="headerlink" title="2ï¸âƒ£ç™»ç§‘å"></a>2ï¸âƒ£ç™»ç§‘å</h3><p>[å”] å­ŸéƒŠ<br>æ˜”æ—¥é¾Œé¾Šä¸è¶³å¤¸ï¼Œä»Šæœæ”¾è¡æ€æ— æ¶¯ã€‚<br><strong>æ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸€æ—¥çœ‹å°½é•¿å®‰èŠ±</strong>ã€‚</p><p><strong>æ³¨é‡Š</strong>ï¼š<br>é¾Œé¾Šï¼ˆwÃ² chuÃ²ï¼‰ï¼šåŸæ„æ˜¯è‚®è„ï¼Œè¿™é‡ŒæŒ‡ä¸å¦‚æ„çš„å¤„å¢ƒã€‚ä¸è¶³å¤¸ï¼šä¸å€¼å¾—æèµ·ã€‚<br>æ”¾è¡ï¼ˆdÃ ngï¼‰ï¼šè‡ªç”±è‡ªåœ¨ï¼Œä¸å—çº¦æŸã€‚<br>æ€æ— æ¶¯ï¼šå…´è‡´é«˜æ¶¨ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57add198a633bd0057eefa8a</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡3</title>
      <link href="/2018/10/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%873/"/>
      <url>/2018/10/29/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%873/</url>
      
        <content type="html"><![CDATA[<h2 id="1ï¸âƒ£-A-Neural-Probabilistic-Language-Model"><a href="#1ï¸âƒ£-A-Neural-Probabilistic-Language-Model" class="headerlink" title="1ï¸âƒ£[A Neural Probabilistic Language Model]"></a>1ï¸âƒ£[A Neural Probabilistic Language Model]</h2><p>ç¬¬ä¸€ç¯‡ä½¿ç”¨ç¥ç»ç½‘ç»œè·å¾—è¯å‘é‡çš„paperã€‚</p><p>é€šè¿‡å¯¹language modelå»ºæ¨¡ï¼Œå°†è¯æ˜ å°„åˆ°ä½ç»´è¡¨ç¤ºï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶è®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥åŠæ¯ä¸ªè¯çš„è¯å‘é‡ã€‚</p><p><img src="/images/2018-10-29-15407808716787.jpg" width="50%" height="50%"></p><p>å°†ä¸­å¿ƒè¯çš„å‰nä¸ªæ‹¼æ¥èµ·æ¥ $x=(C(w_{t-1},C(w_{t-2}),â€¦,C(w_{t-n+1}))$<br>å°†$x$é€å…¥ç¥ç»ç½‘ç»œä¸­è·å¾—$y=b+Wx+Utanh(d+Hx)$ï¼Œæœ€ååšä¸€ä¸ªsoftmaxå³å¯ã€‚</p><hr><h2 id="2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks"><a href="#2ï¸âƒ£-Adaptive-Computation-Time-for-Recurrent-Neural-Networks" class="headerlink" title="2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]"></a>2ï¸âƒ£[Adaptive Computation Time for Recurrent Neural Networks]</h2><p>ä¸€ç§å…è®¸RNNåŠ¨æ€å †å å±‚æ•°çš„ç®—æ³•ã€‚</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>è¯æ®è¯æ˜ï¼ŒRNNçš„å †å å±‚æ•°å¤šï¼Œæ•ˆæœä¼šæœ‰æå‡ã€‚ä½†æ˜¯ï¼Œå¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œè¦æ±‚ä¸åŒçš„è®¡ç®—å¤æ‚åº¦ã€‚æˆ‘ä»¬éœ€è¦å…ˆéªŒæ¥å†³å®šç‰¹å®šä»»åŠ¡çš„è®¡ç®—å¤æ‚åº¦ã€‚å½“ç„¶æˆ‘ä»¬å¯ä»¥ç²—æš´åœ°ç›´æ¥å †å æ·±å±‚çš„ç½‘ç»œã€‚ACT(Adaptive Computation Time)èƒ½å¤ŸåŠ¨æ€å†³å®šæ¯ä¸ªè¾“å…¥tæ‰€éœ€çš„è®¡ç®—æ¬¡æ•°ã€‚</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>å°†RNNæ¯ä¸€æ­¥çš„è¾“å‡ºè¿‡ä¸€ä¸ªç½‘ç»œ+sigmoidå±‚ï¼Œè·å¾—ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå³ä»€ä¹ˆæ—¶å€™åº”å½“åœæ­¢ä¸å†ç»§ç»­å¾€ä¸Šå †å ï¼Œç›´åˆ°æ¦‚ç‡åŠ å’Œä¸º1ã€‚åŒæ—¶ä¸ºäº†å°½å¯èƒ½æŠ‘åˆ¶å±‚æ•°çš„æ— é™å¢é•¿ï¼Œåœ¨lossæ·»åŠ ä¸€é¡¹æƒ©ç½šã€‚</p><h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p>å¯¹äºæ™®é€šçš„RNNï¼š<br><img src="/images/2018-10-29-15408103221289.jpg" width="30%" height="50%"></p><p>sæ˜¯éšè—å±‚ï¼›yæ˜¯è¾“å‡ºã€‚</p><p>å¯¹äºACTçš„RNNï¼Œæœ‰ï¼š<br><img src="/images/2018-10-29-15408103823681.jpg" width="40%" height="50%"></p><p>ä¸Šæ ‡næ˜¯æŒ‡çš„tæ—¶åˆ»çš„å±‚æ•°ï¼›å…¶ä¸­ï¼š<br><img src="/images/2018-10-29-15408104201718.jpg" width="20%" height="50%"></p><p>$Î´$æ˜¯flatï¼ŒæŒ‡ç¤ºxæ˜¯ç¬¬å‡ æ¬¡è¾“å…¥ã€‚</p><p>å¼•å…¥æ–°çš„ç½‘ç»œï¼Œè¾“å…¥æ—¶éšçŠ¶æ€ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼š<br><img src="/images/2018-10-29-15408105451770.jpg" width="30%" height="50%"></p><p>é‚£ä¹ˆæ¯ä¸€å±‚çš„æ¦‚ç‡æ˜¯ï¼š<br><img src="/images/2018-10-29-15408105687677.jpg" width="35%" height="50%"></p><p>å…¶ä¸­$R(t)$æ˜¯åœ¨æ¯ä¸€å±‚æ¦‚ç‡æ±‚å’Œè¶…è¿‡1æ—¶çš„å‰©ä½™æ¦‚ç‡ï¼ˆä¸ºäº†ä¿è¯æ¦‚ç‡å’Œä¸º1ï¼Œå¯ä»¥è¯•ç€ä¸¾ä¸€ä¸ªä¾‹å­æ¥è¯æ˜ï¼‰<br><img src="/images/2018-10-29-15408106099743.jpg" width="45%" height="50%"></p><p><img src="/images/2018-10-29-15408106125837.jpg" width="25%" height="50%"></p><p>Îµæ˜¯ä¸ºäº†è§£å†³ç¬¬ä¸€æ¬¡è¾“å‡ºæ—¶å°±è¶…è¿‡1-Îµçš„æƒ…å†µï¼ŒÎµä¸€èˆ¬å–å¾ˆå°ã€‚</p><p>æœ€ç»ˆï¼ŒåŠ æƒæ±‚å’Œï¼Œä½œä¸ºæœ€ç»ˆçš„ç»“æœï¼Œä¼ å…¥ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼š<br><img src="/images/2018-10-29-15408106649319.jpg" width="45%" height="50%"></p><p>æ™®é€šRNNä¸ACTçš„RNNå¯¹æ¯”ï¼š<br><img src="/images/2018-10-29-15408106950342.jpg" width="90%" height="50%"></p><h4 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h4><p>ä¸ºäº†é˜²æ­¢æ¨¡å‹å±‚æ•°æ— é™å¢é•¿ï¼Œæ·»åŠ ä¸€é¡¹æƒ©ç½šé¡¹ä»¥æŠ‘åˆ¶ã€‚</p><p>è®°æ¯ä¸€æ­¥çš„æƒ©ç½šé¡¹ä¸ºï¼š<br><img src="/images/2018-10-29-15408107184035.jpg" width="23%" height="50%"></p><p>æ€»çš„æƒ©ç½šé¡¹åˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408107351871.jpg" width="19%" height="50%"></p><p>Loss functionåˆ™ä¸ºï¼š<br><img src="/images/2018-10-29-15408108024183.jpg" width="35%" height="50%"></p><p>å› ä¸ºN(t)æ˜¯ä¸å¯å¯¼çš„ï¼Œæˆ‘ä»¬åœ¨å®é™…è¿‡ç¨‹ä¸­åªå»æœ€å°åŒ–R(t)  ï¼ˆ<del>æˆ‘è§‰å¾—ä¸ç”šåˆç†</del>ï¼Œä¸€ç§è§£è¯»æ˜¯å¦‚æœæˆ‘ä»¬ä¸æ–­æœ€å°åŒ–R(t)ç›´åˆ°å˜æˆ0ï¼Œé‚£ä¹ˆç›¸å½“äºN(t)å°‘äº†ä¸€å±‚ï¼Œæ¥ç€R(t)å°±ä¼šå˜å¾—å¾ˆå¤§ï¼Œç„¶ååˆç»§ç»­æœ€å°åŒ–R(t)â€¦ï¼‰</p><hr><h2 id="3ï¸âƒ£-Universal-Transformers"><a href="#3ï¸âƒ£-Universal-Transformers" class="headerlink" title="3ï¸âƒ£[Universal Transformers]"></a>3ï¸âƒ£[Universal Transformers]</h2><p>æå‡ºä¸€ç§æ–°å‹é€šç”¨çš„transformerã€‚</p><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>Transformerçš„é—®é¢˜ï¼šRNNçš„å½’çº³åç½®(inductive bias)åœ¨ä¸€äº›ä»»åŠ¡ä¸Šå¾ˆé‡è¦ï¼Œä¹Ÿå³RNNçš„å¾ªç¯å­¦ä¹ çš„è¿‡ç¨‹ï¼›Transformeråœ¨ä¸€äº›é—®é¢˜ä¸Šè¡¨ç°ä¸å¥½ï¼Œå¯èƒ½æ˜¯å½’çº³åç½®çš„åŸå› ã€‚</p><blockquote><p>Notably, however, the Transformer foregoes the RNNâ€™s inductive bias towards learning iterative or recursive transformations.Our experiments indicate that this inductive bias may be crucial for several algorithmic and language understanding tasks of varying complexity: in contrast to models such as the Neural Turing Machine [13], the Neural GPU [17] or Stack RNNs [16], the Transformer does not generalize well to input lengths not encountered during training.</p></blockquote><p>å› æ­¤åœ¨Transformerå†…å¼•å…¥å½’çº³åç½®</p><h3 id="ç‰¹ç‚¹"><a href="#ç‰¹ç‚¹" class="headerlink" title="ç‰¹ç‚¹"></a>ç‰¹ç‚¹</h3><ul><li>æ¯ä¸€å±‚çš„æƒé‡æ˜¯å…±äº«çš„ï¼Œä¹Ÿå³multi-headä¸Šçš„æƒé‡ä»¥åŠtransition functionåœ¨æ¯ä¸€å±‚æ˜¯ä¸€è‡´çš„ã€‚è¿™ä¸€ç‚¹å’ŒRNNã€CNNä¸€è‡´ã€‚</li><li>åŠ¨æ€å±‚æ•°ï¼ˆACT mechanism ï¼‰ï¼šå¯¹äºæ¯ä¸ªè¯éƒ½ä¼šæœ‰ä¸åŒçš„å¾ªç¯æ¬¡æ•°ï¼›ä¹Ÿå³æœ‰äº›è¯éœ€è¦æ›´å¤šçš„refineï¼›è€Œæœ‰äº›è¯ä¸éœ€è¦ã€‚å’Œå›ºå®šå±‚æ•°çš„transformerç›¸æ¯”ï¼Œä¼šæœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚</li></ul><h3 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h3><h4 id="æ€»ä½“æ¶æ„"><a href="#æ€»ä½“æ¶æ„" class="headerlink" title="æ€»ä½“æ¶æ„"></a>æ€»ä½“æ¶æ„</h4><p><img src="/images/2018-10-29-15408125098915.jpg" width="90%" height="50%"></p><p>è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-29-15408125469899.jpg" width="45%" height="50%"></p><p><img src="/images/2018-10-29-15408125685038.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-29-15408125974795.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-29-15408126143943.jpg" width="60%" height="50%"></p><p>å’Œæ™®é€šTransformerä¸åŒçš„åœ°æ–¹åœ¨äºï¼š</p><ul><li>åŠ äº†ä¸€å±‚Transitionå±‚ï¼ŒTransitionå¯ä»¥æ˜¯depth-wise separable convolutionï¼ˆ<a href="https://www.cnblogs.com/adong7639/p/7918527.html" target="_blank" rel="noopener">æ˜¯ä»€ä¹ˆï¼Ÿ</a>ï¼‰æˆ–è€…å…¨è¿æ¥å±‚ã€‚</li><li>æ¯å±‚éƒ½æ·»åŠ äº†position embeddingï¼›ä»¥åŠtimestep embeddingï¼Œç”¨ä»¥æŒ‡ç¤ºå±‚æ•°ã€‚</li></ul><h4 id="ACT"><a href="#ACT" class="headerlink" title="ACT"></a>ACT</h4><p>ç”±äºä¸€ä¸ªå¥å­ä¸­é—´ï¼Œæœ‰äº›è¯æ¯”å…¶ä»–è¯æ›´éš¾å­¦ä¼šï¼Œéœ€è¦æ›´å¤šè®¡ç®—é‡ï¼Œä½†å †å å¤ªå¤šå±‚ä¼šå¤§å¤§å¢åŠ è®¡ç®—é‡ï¼Œä¸ºäº†èŠ‚çœè®¡ç®—é‡ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥ACTæ¥åŠ¨æ€åˆ†é…è®¡ç®—é‡ã€‚</p><p>ACTåŸæ¥ç”¨äºRNNï¼Œåœ¨Transformerä¸­ï¼Œå½“halting unitæŒ‡ç¤ºè¯tåº”å½“åœæ­¢æ—¶ï¼Œç›´æ¥è®²è¯¥è¯çš„çŠ¶æ€å¤åˆ¶åˆ°ä¸‹ä¸€ä¸ªtime stepï¼Œç›´åˆ°æ‰€æœ‰çš„è¯éƒ½åœæ­¢ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Embedding </tag>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> ACT </tag>
            
            <tag> Language Modeling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯12</title>
      <link href="/2018/10/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D12/"/>
      <url>/2018/10/21/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D12/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£æœ›æµ·æ½®"><a href="#1ï¸âƒ£æœ›æµ·æ½®" class="headerlink" title="1ï¸âƒ£æœ›æµ·æ½®"></a>1ï¸âƒ£æœ›æµ·æ½®</h3><p>[å®‹] æŸ³æ°¸<br>ä¸œå—å½¢èƒœï¼Œä¸‰å´éƒ½ä¼šï¼Œé’±å¡˜è‡ªå¤ç¹åã€‚çƒŸæŸ³ç”»æ¡¥ï¼Œé£å¸˜ç¿ å¹•ï¼Œå‚å·®åä¸‡äººå®¶ã€‚äº‘æ ‘ç»•å ¤æ²™ï¼Œæ€’æ¶›å·éœœé›ªï¼Œå¤©å ‘æ— æ¶¯ã€‚å¸‚åˆ—ç ç‘ï¼Œæˆ·ç›ˆç½—ç»®ï¼Œç«è±ªå¥¢ã€‚<br>é‡æ¹–å å·˜æ¸…å˜‰ï¼Œæœ‰ä¸‰ç§‹æ¡‚å­ï¼Œåé‡Œè·èŠ±ã€‚ç¾Œç®¡å¼„æ™´ï¼Œè±æ­Œæ³›å¤œï¼Œå¬‰å¬‰é’“åŸè²å¨ƒã€‚åƒéª‘æ‹¥é«˜ç‰™ï¼Œä¹˜é†‰å¬ç®«é¼“ï¼ŒåŸèµçƒŸéœã€‚å¼‚æ—¥å›¾å°†å¥½æ™¯ï¼Œå½’å»å‡¤æ± å¤¸ã€‚</p><p>å å·˜ï¼ˆyÇnï¼‰ï¼šå±‚å±‚å å çš„å±±å³¦ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b318228ac247005f2223db" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b318228ac247005f2223db</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•8</title>
      <link href="/2018/10/21/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%958/"/>
      <url>/2018/10/21/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%958/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-batchify"><a href="#1ï¸âƒ£-batchify" class="headerlink" title="1ï¸âƒ£[batchify]"></a>1ï¸âƒ£[batchify]</h3><p>å¿«é€Ÿå°†æ•°æ®åˆ†æˆbatchã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchify</span><span class="params">(data, bsz)</span>:</span></span><br><span class="line">    <span class="comment"># Work out how cleanly we can divide the dataset into bsz parts.</span></span><br><span class="line">    nbatch = data.size(<span class="number">0</span>) // bsz</span><br><span class="line">    <span class="comment"># Trim off any extra elements that wouldn't cleanly fit (remainders).</span></span><br><span class="line">    data = data.narrow(<span class="number">0</span>, <span class="number">0</span>, nbatch * bsz)</span><br><span class="line">    <span class="comment"># Evenly divide the data across the bsz batches.</span></span><br><span class="line">    data = data.view(bsz, <span class="number">-1</span>).t().contiguous()</span><br><span class="line">    <span class="keyword">return</span> data.to(device)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬å››ç«  åˆ†ç±»çš„çº¿æ€§æ¨¡å‹</title>
      <link href="/2018/10/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%88%86%E7%B1%BB%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2018/10/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E5%88%86%E7%B1%BB%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="åˆ¤åˆ«å‡½æ•°"><a href="#åˆ¤åˆ«å‡½æ•°" class="headerlink" title="åˆ¤åˆ«å‡½æ•°"></a>åˆ¤åˆ«å‡½æ•°</h1><p><img src="/images/2018-10-21-Xnip2018-10-21_09-26-42.jpg" alt="0"></p><hr><p><img src="/images/2018-10-21-Xnip2018-10-21_09-27-57.jpg" alt="1"></p><p>â€”-æœªå®Œâ€”-</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡2</title>
      <link href="/2018/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%872/"/>
      <url>/2018/10/20/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%872/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling"><a href="#1ï¸âƒ£-An-Empirical-Evaluation-of-Generic-Convolutional-and-Recurrent-Networks-for-Sequence-Modeling" class="headerlink" title="1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]"></a>1ï¸âƒ£[An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling]</h3><p>æœ¬æ–‡è´¡çŒ®ï¼šæå‡ºä¸€ç§æ–°çš„æ¨¡å‹<strong>TCNï¼ˆTemporal Convolutional Networksï¼‰</strong>è¿›è¡Œlanguage modelå»ºæ¨¡ã€‚</p><h4 id="Dilated-convolution"><a href="#Dilated-convolution" class="headerlink" title="Dilated convolution"></a>Dilated convolution</h4><p>æ¯ä¸€å±‚çš„æ„Ÿå—é‡éƒ½å¯ä»¥æ˜¯ä¸åŒçš„ï¼Œä¹Ÿå³ï¼ŒåŒæ ·çš„kernel sizeï¼Œé«˜å±‚çš„å¯ä»¥è·³ç€çœ‹ã€‚<br><img src="/images/2018-10-20-15400016170606.jpg" width="60%" height="50%"></p><p>æ¯å±‚çš„dé€æ¸å¢å¤§ï¼ˆä¹Ÿå³è·³çš„æ­¥æ•°ï¼‰ï¼Œä¸€èˆ¬æŒ‰æŒ‡æ•°å¢å¤§ã€‚ï¼ˆæˆ‘è§‰å¾—è¿™æ ·å¾ˆæœ‰é“ç†ï¼Œå¦‚æœæ¯ä¸€å±‚çš„déƒ½æ˜¯ä¸€æ ·çš„ï¼Œé‚£captureåˆ°çš„ä¿¡æ¯å°±ä¼šæœ‰é‡å¤ï¼Œèƒ½çœ‹åˆ°çš„è§†é‡ä¹Ÿä¸å¦‚é€æ¸å¢å¤§çš„å¤šï¼‰</p><h4 id="Residual-block"><a href="#Residual-block" class="headerlink" title="Residual block"></a>Residual block</h4><p><img src="/images/2018-10-20-15400017320092.jpg" width="70%" height="50%"></p><p>è¿™è¾¹çš„residual blockæ¯”è¾ƒå¤æ‚ï¼›ä¸€ä¸ªå€¼å¾—ä¸»æ„çš„ç»†èŠ‚æ˜¯ï¼Œå› ä¸ºæ„Ÿå—é‡çš„ä¸åŒï¼Œä¸Šå±‚çš„æ„Ÿå—é‡æ€»æ˜¯æ¯”ä¸‹å±‚çš„å¤§å¾ˆå¤šï¼Œå› æ­¤ä¸åº”è¯¥ç›´æ¥å°†ä¸‹å±‚çš„åŠ åˆ°ä¸Šå±‚ï¼Œè€Œæ˜¯å¯ä»¥ä½¿ç”¨ä¸€ä¸ª1*1çš„convolutionå¯¹ä¸‹å±‚çš„xè¿›è¡Œå·ç§¯ï¼Œè¿™å°±ç±»ä¼¼scaleå¯¹è¾“å…¥è¿›è¡Œæ”¾ç¼©ã€‚</p><hr><h3 id="2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation"><a href="#2ï¸âƒ£-Dissecting-Contextual-Word-Embeddingsï¼š-Architecture-and-Representation" class="headerlink" title="2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]"></a>2ï¸âƒ£[Dissecting Contextual Word Embeddingsï¼š Architecture and Representation]</h3><p>ä¸€ç¯‡åˆ†æçš„æ–‡ç« ã€‚ELMoä½œè€…çš„åˆä¸€ç¯‡æ–‡ç« ã€‚</p><p>å¯¹æ¯”ä¸‰ç§ä¸åŒçš„å»ºæ¨¡æ–¹å¼ï¼ˆLSTM/GCNN/Transformerï¼‰è·å¾—çš„è¯å‘é‡ï¼Œä»¥åŠåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼›ä»¥åŠä¸åŒå±‚è·å¾—çš„ä¸åŒä¿¡æ¯â€¦è·å¾—äº†ä¸åŒçš„ç»“è®ºã€‚</p><p>â‘ biLM ä¸“æ³¨äºword morphologyè¯çš„å½¢æ€ï¼›åº•å±‚çš„LMå…³æ³¨local syntaxï¼›è€Œé«˜å±‚çš„LMå…³æ³¨semantic contentï¼›</p><p>â‘¡ä¸åŒçš„ä»»åŠ¡ä¼šæœ‰ä¸åŒçš„æ­£åˆ™åŒ–sçš„å€¾å‘ã€‚</p><hr><h3 id="3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency"><a href="#3ï¸âƒ£-Transformer-XL-Language-modeling-with-longer-term-dependency" class="headerlink" title="3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]"></a>3ï¸âƒ£[Transformer-XL: Language modeling with longer-term dependency]</h3><p>åˆ©ç”¨Transformerè¿›è¡Œlanguage modelï¼Œä¸æ™®é€šçš„Transformerå»ºæ¨¡ä¸åŒçš„æ˜¯ï¼ŒTransformer-XLæ·»åŠ äº†å†å²ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡è¡¨ç°ã€‚è¿™ç¯‡è¿˜åœ¨ICLR2019å®¡ç¨¿ä¸­ã€‚</p><p>è´¡çŒ®ï¼šæœ¬æ–‡æå‡ºäº†èƒ½å¤Ÿè¿›è¡Œé•¿ç¨‹ä¾èµ–çš„åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹ Transformer-XLï¼›å¼•å…¥ç›¸å¯¹ä½ç½®çš„positional encodingã€‚</p><h4 id="ç»“æ„"><a href="#ç»“æ„" class="headerlink" title="ç»“æ„"></a>ç»“æ„</h4><p>åŸå…ˆçš„transformer language modelæ˜¯å°†å¥å­åˆ†ä¸ºä¸€ä¸ªä¸€ä¸ªsegmentã€‚segmentä¹‹é—´æ˜¯æ²¡æœ‰è”ç³»çš„ã€‚ï¼ˆä¸ºä»€ä¹ˆä¸ç›´æ¥æŒ‰åŸç‰ˆçš„Transformeré‚£æ ·æ‰€æœ‰çš„è¯éƒ½ç›¸äº’åšself-attentionï¼Ÿå› ä¸ºè€ƒè™‘åˆ°æ•ˆç‡é—®é¢˜ï¼Œå¥å­é•¿åº¦å¯èƒ½ä¼šå¾ˆé•¿ï¼‰</p><p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400023645268.jpg" width="35%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼Œæ¯æ¬¡å‘å³æ»‘åŠ¨ä¸€æ ¼ï¼š<br><img src="/images/2018-10-20-15400024115822.jpg" width="80%" height="50%"><br>è¿™æ ·æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½è¦é‡æ–°è®¡ç®—ä¸€éï¼Œå†å²ä¿¡æ¯æ²¡æœ‰åˆ©ç”¨åˆ°ã€‚æ˜¾ç„¶é€Ÿåº¦å¾ˆæ…¢ã€‚</p><p>åœ¨Transformerå¼•å…¥recurrenceï¼Œä¹Ÿå³å¼•å…¥å†å²ä¿¡æ¯ã€‚åŸºäºè¿™æ ·çš„æƒ³æ³•ï¼Œæå‡ºçš„æ–°æ¨¡å‹Transformer-XLã€‚åœ¨ç»“æ„ä¸ŠåŒæ ·åˆ†ä¸ºæ¯ä¸ªsegmentï¼Œä½†åœ¨æ¯ä¸ªé˜¶æ®µéƒ½æ¥æ”¶ä¸Šä¸€ä¸ªï¼ˆç”šè‡³ä¸ŠLä¸ªï¼‰å†å²ä¿¡æ¯ã€‚</p><p>è®­ç»ƒé˜¶æ®µï¼š<br><img src="/images/2018-10-20-15400026059113.jpg" width="80%" height="50%"></p><p>è€Œåœ¨æµ‹è¯•é˜¶æ®µï¼ŒåŒæ ·åˆ†ä¸ºsegmentï¼Œä½†å› ä¸ºæ¥æ”¶äº†å†å²ä¿¡æ¯ï¼Œä¸éœ€è¦æ¯æ¬¡æ»‘åŠ¨ä¸€æ ¼ä¹Ÿèƒ½è·å¾—å¤§é‡ä¿¡æ¯ã€‚<br><img src="/images/2018-10-20-15400027040526.jpg" width="45%" height="50%"></p><p>å…·ä½“æ¥è¯´ï¼š<br><img src="/images/2018-10-20-15400027302545.jpg" width="120%" height="50%"><br>SGä»£è¡¨stop gradientï¼Œå’Œè¯¥é˜¶æ®µçš„hidden stateè¿›è¡Œæ‹¼æ¥ã€‚</p><h4 id="RELATIVE-POSITIONAL-ENCODINGS"><a href="#RELATIVE-POSITIONAL-ENCODINGS" class="headerlink" title="RELATIVE POSITIONAL ENCODINGS"></a>RELATIVE POSITIONAL ENCODINGS</h4><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨äº†absolute positional encodingsï¼ˆä¹Ÿå³åŸç‰ˆçš„positional encodingsï¼‰é‚£ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µ</p><p><img src="/images/2018-10-20-15400027991211.jpg" width="70%" height="50%"></p><p>åœ¨åŒä¸€å±‚ä¹‹é—´çš„å‰ä¸€ä¸ªsegmentå’Œåä¸€ä¸ªsegmentä½¿ç”¨äº†åŒæ ·çš„ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¯¹äºå½“å‰segmentçš„é«˜å±‚ï¼Œå¯¹äºåŒä¸€ä¸ªä½ç½®iï¼Œæ— æ³•åŒºåˆ†è¯¥ä½ç½®ä¿¡æ¯æ˜¯æ¥è‡ªå½“å‰segmentçš„è¿˜æ˜¯ä¸Šä¸€ä¸ªsegmentçš„ï¼ˆå› ä¸ºéƒ½æ˜¯åŒæ ·çš„ç»å¯¹ä½ç½®ï¼‰ã€‚</p><p>å› æ­¤æˆ‘ä»¬å¼•å…¥ç›¸å¯¹ä½ç½®ä¿¡æ¯Rï¼Œå…¶ä¸­ç¬¬iè¡Œä»£è¡¨ç›¸å¯¹è·ç¦»içš„encodingã€‚</p><p>å…·ä½“æ¥è¯´ï¼š</p><p>é¦–å…ˆæˆ‘ä»¬åœ¨ä¼ ç»Ÿçš„è®¡ç®—$query_i$å’Œ$key_j$çš„attentionåˆ†æ•°æ—¶ï¼Œå¯ä»¥æ‹†è§£æˆï¼š</p><p><img src="/images/2018-10-20-15400030310583.jpg" width="80%" height="50%"><br>ï¼ˆå› ä¸ºquery=(embedding E +positional embedding Uï¼‰ï¼Œkeyä¹Ÿä¸€æ ·ï¼Œå°†å¼å­æ‹†å¼€å°±èƒ½è·å¾—ä¸Šè¿°å¼å­)</p><p>æˆ‘ä»¬å°†è¯¥å¼å­è¿›è¡Œä¿®æ”¹ï¼š</p><p><img src="/images/2018-10-20-15400031662378.jpg" width="80%" height="50%"></p><p>ç¬¬ä¸€ï¼Œå°†å‡ºç°äº†absolute positional embedding $U$çš„åœ°æ–¹ï¼Œç»Ÿç»Ÿæ”¹æˆ$R_{i-j}$ï¼Œä¹Ÿå³åœ¨bå’Œdé¡¹ã€‚å…¶ä¸­è¿™é‡Œçš„Rå’ŒåŸç‰ˆçš„Transformerçš„ä½ç½®è®¡ç®—å…¬å¼ç›¸åŒã€‚</p><p>ç¬¬äºŒï¼Œåœ¨cé¡¹ä¸­ï¼Œä½¿ç”¨ä¸€ä¸ª$u$æ›¿ä»£äº†$U_i W_q$ï¼Œè¿™ä¸€é¡¹åŸæœ¬çš„æ„ä¹‰åœ¨äºï¼Œ$query_i$çš„positional encodingå¯¹$key_j$çš„embeddingè¿›è¡Œattentionï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¯¥é¡¹è¡¨ç°äº†$query_i$ä½ç½®å¯¹å“ªäº›$key_j$çš„å†…å®¹æœ‰å…´è¶£ï¼Œä½œè€…è®¤ä¸ºqueryä¸ç®¡åœ¨å“ªä¸ªä½ç½®ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´queryçš„ä½ç½®ä¿¡æ¯åº”å½“æ²¡å½±å“ï¼Œæ‰€ä»¥ç»Ÿç»Ÿæ›¿æ¢æˆä¸€ä¸ªå¯å­¦ä¹ çš„$u$ã€‚åŸºäºç±»ä¼¼çš„ç†ç”±dé¡¹æ¢æˆäº†$v$ã€‚</p><p>ç¬¬ä¸‰ï¼Œå°†$W_k$ç»†åˆ†æˆäº†ä¸¤ä¸ª$W_{k,E}$å’Œ$W_{k,R}$ã€‚è¿™æ˜¯æ ¹æ®queryæ˜¯Embeddingè¿˜æ˜¯positional encodingæ¥åŒºåˆ†çš„ã€‚for producing the content-based key vectors and location-based key vectors respectively</p><p>æ¯ä¸€é¡¹ç°åœ¨éƒ½æœ‰äº†ä¸åŒçš„æ„ä¹‰ï¼š</p><blockquote><p>Under the new parameterization, each term has an intuitive meaning: term (a) represents contentbased addressing, term (b) captures a content-dependent positional bias, term (c) governs a global content bias, and (d) encodes a global positional bias.</p></blockquote><p>æœ€åæ€»ç»“ä¸€ä¸‹æ•´ä¸ªç»“æ„ï¼š</p><p><img src="/images/2018-10-20-15400040342520.jpg" width="120%" height="50%"></p><p>ä¸åŸç‰ˆTransformerä¸åŒçš„æ˜¯ï¼ŒTransformer-XLåœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†ä½ç½®ä¿¡æ¯ã€‚</p><hr><h3 id="4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling"><a href="#4ï¸âƒ£-Trellis-Networks-for-Sequence-Modeling" class="headerlink" title="4ï¸âƒ£[Trellis Networks for Sequence Modeling]"></a>4ï¸âƒ£[Trellis Networks for Sequence Modeling]</h3><p>ä¸€ç§ç»“åˆRNNå’ŒCNNçš„è¯­è¨€å»ºæ¨¡æ–¹å¼ã€‚</p><p>æœ€å°çš„å•å…ƒç»“æ„ï¼š</p><p><img src="/images/2018-10-21-15400858162232.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-21-15400860605560.jpg" width="40%" height="50%"></p><p>æ¥ä¸‹æ¥å†å¤„ç†éçº¿æ€§ï¼š<br><img src="/images/2018-10-21-15400861618655.jpg" width="30%" height="50%"></p><p>å› ä¸ºæ¯å±‚éƒ½è¦è¾“å…¥xï¼Œä¸”Wæ˜¯å…±äº«çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æå‰è®¡ç®—å¥½è¿™ä¸€é¡¹ï¼Œåé¢ç›´æ¥ç”¨å³å¯ã€‚<br><img src="/images/2018-10-21-15400861870898.jpg" width="35%" height="50%"></p><p>æœ€ç»ˆåœ¨å®ç°çš„æ—¶å€™æ˜¯ï¼š<br><img src="/images/2018-10-21-15400862184335.jpg" width="40%" height="50%"></p><p><img src="/images/2018-10-21-15400862303741.jpg" width="40%" height="50%"></p><p>æ€»ä½“æ¡†æ¶ï¼š<br><img src="/images/2018-10-21-15400874987498.jpg" width="70%" height="50%"></p><p>ä¸TCNï¼ˆtemporal convolution networkï¼‰ä¸åŒä¹‹å¤„ï¼šâ‘ filter weightä¸ä»…åœ¨time stepä¹‹é—´å…±äº«ï¼Œåœ¨ä¸åŒå±‚ä¹‹é—´ä¹Ÿå…±äº«ï¼›â‘¡åœ¨æ¯ä¸€å±‚éƒ½æ·»åŠ äº†è¾“å…¥</p><p>ä¼˜ç‚¹ï¼šå…±äº«äº†Wï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°ï¼›â€˜Weight tying can be viewed as a form of regularization that can stabilize trainingâ€™</p><p>æˆ‘ä»¬è¿˜å¯ä»¥æ‰©å±•è¯¥ç½‘ç»œï¼Œå¼•å…¥gateï¼š<br><img src="/images/2018-10-21-15400875805208.jpg" width="40%" height="50%"></p><hr><h3 id="5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation"><a href="#5ï¸âƒ£-Towards-Decoding-as-Continuous-Optimisation-in-Neural-Machine-Translation" class="headerlink" title="5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]"></a>5ï¸âƒ£[Towards Decoding as Continuous Optimisation in Neural Machine Translation]</h3><p>ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„paperã€‚ç”¨äºNMT decodeçš„inferenceé˜¶æ®µã€‚è¿™ç¯‡æœ‰ä¸€å®šçš„éš¾åº¦ï¼Œä»¥ä¸‹åªæ˜¯æˆ‘çš„ç†è§£ã€‚</p><h4 id="æ€æƒ³"><a href="#æ€æƒ³" class="headerlink" title="æ€æƒ³"></a>æ€æƒ³</h4><p>Motivationï¼š<br>NMTä¸­çš„decode inferenceé˜¶æ®µï¼Œé€šå¸¸éƒ½æ˜¯ä»å·¦åˆ°å³çš„ï¼Œè¿™æ ·æœ‰ä¸ªç¼ºç‚¹ï¼Œå°±æ˜¯æ•´ä½“çš„targetä¹‹é—´çš„ä¾èµ–æ˜¯æ²¡æœ‰è¢«å……åˆ†åˆ©ç”¨åˆ°çš„ï¼Œæ¯”å¦‚è¯´ç”Ÿæˆçš„è¯çš„å³è¾¹æ˜¯æ²¡æœ‰ç”¨åˆ°çš„ã€‚é‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆä¸ç›´æ¥å…¨éƒ¨ç”Ÿæˆå‘¢ï¼Ÿç„¶åä¸æ–­æ›´æ–°ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å°†ç¦»æ•£ï¼ˆdiscreteï¼‰çš„decodeè¿‡ç¨‹å˜æˆä¸€ä¸ªè¿ç»­çš„è¿‡ç¨‹ï¼ˆcontinuous optimizationï¼‰ã€‚</p><p>å‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½æ¨¡å‹ï¼Œç»™å®šä¸€ä¸ªå¥å­ï¼Œæˆ‘ä»¬è¦ç¿»è¯‘æˆç›®æ ‡å¥å­ï¼Œä¸”å‡è®¾æˆ‘ä»¬å·²çŸ¥è¦ç”Ÿæˆçš„å¥å­é•¿åº¦æ˜¯lï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ï¼š<br><img src="/images/2018-10-21-15400876953609.jpg" width="45%" height="50%"><br>æˆ‘ä»¬è¦æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„åºåˆ—$y$ï¼Œä½¿å¾—$-log$æœ€å°ã€‚</p><p>ç­‰ä»·äºï¼š<br><img src="/images/2018-10-21-15400877226851.jpg" width="55%" height="50%"><br>å…¶ä¸­$\widetilde{y}_i$æ˜¯one-hotã€‚å…¶å®è¿™é‡Œå°±æ˜¯å‡è®¾æœ‰è¿™ä¹ˆä¸€ä¸ªground truthï¼Œä½†å®é™…ä¸Šæ˜¯æ²¡æœ‰çš„ã€‚</p><p>æˆ‘ä»¬å°†$\widetilde{y}_i$æ˜¯one-hotè¿™ä¸ªæ¡ä»¶æ”¾å®½ä¸€äº›ï¼Œå˜æˆæ˜¯ä¸€ä¸ªæ¦‚ç‡å•çº¯å‹ï¼ˆå…¶å®å°±æ˜¯æ‰€æœ‰å…ƒç´ åŠ èµ·æ¥æ˜¯1ï¼Œä¸”éƒ½å¤§äºç­‰äº0ï¼‰ã€‚</p><p>é‚£ä¹ˆå°±å˜æˆäº†ï¼š<br><img src="/images/2018-10-21-15400879019592.jpg" width="50%" height="50%"></p><p>è¿™ä¸ªæ”¹å˜çš„æœ¬è´¨æ˜¯ï¼š<br><img src="/images/2018-10-21-15400879379023.jpg" width="50%" height="50%"></p><p>å°±æ˜¯è¯´åŸæ¥one-hotçš„$\widetilde{y}_i$ç”Ÿæˆåä¸¢åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå–äº†ä¸€ä¸ªè¯å‘é‡ï¼Œæ¥ç€è®¡ç®—ã€‚ç°åœ¨æ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ$\hat{y}_i$ä¸¢è¿›æ¥ï¼Œå°±ç›¸å½“äºå–äº†å¤šä¸ªè¯å‘é‡çš„åŠ æƒæ±‚å’Œã€‚</p><p>åœ¨åˆ©ç”¨ä¸‹è¿°çš„æ›´æ–°ç®—æ³•æ›´æ–°å®Œ$\hat{y}_i$ä¹‹åï¼Œå¯¹äºæ¯ä¸ªæ—¶é—´æ­¥tï¼Œæˆ‘ä»¬æ‰¾$\hat{y}_i$ä¸­å…ƒç´ æœ€å¤§çš„å€¼å¯¹åº”çš„è¯ä½œä¸ºç”Ÿæˆçš„è¯ã€‚</p><p>æœ‰ä¸¤ç§æ–¹æ³•Exponentiated Gradient å’Œ SGDã€‚å®é™…ä¸Šæ–¹æ³•å€’åœ¨å…¶æ¬¡äº†ï¼Œä¸»è¦æ˜¯å‰é¢æ‰€è¿°çš„continuous optimizationè¿™ç§æ€æƒ³ã€‚</p><h4 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h4><h5 id="Exponentiated-Gradient"><a href="#Exponentiated-Gradient" class="headerlink" title="Exponentiated Gradient"></a>Exponentiated Gradient</h5><p><img src="/images/2018-10-21-15400881918713.jpg" width="80%" height="50%"><br>å…·ä½“è§è®ºæ–‡</p><h5 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h5><p>å› ä¸ºæˆ‘ä»¬è¦ä¿è¯å•çº¯å½¢çš„çº¦æŸä¸å˜ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªrï¼Œç„¶ååšä¸€ä¸ªsoftmax<br><img src="/images/2018-10-21-15400882306948.jpg" width="80%" height="50%"></p><h4 id="åº”ç”¨"><a href="#åº”ç”¨" class="headerlink" title="åº”ç”¨"></a>åº”ç”¨</h4><p>è¿™ç§è¿ç»­decodeå¯ä»¥ç”¨åœ¨å“ªï¼Ÿ</p><h5 id="Bidirectional-Ensemble"><a href="#Bidirectional-Ensemble" class="headerlink" title="Bidirectional Ensemble"></a>Bidirectional Ensemble</h5><p>å¯ä»¥å¾ˆæ–¹ä¾¿åœ°è¿›è¡ŒåŒå‘çš„ç”Ÿæˆï¼š</p><p><img src="/images/2018-10-21-15400883321474.jpg" width="45%" height="50%"><br>è€Œåœ¨ä¼ ç»Ÿçš„æ–¹æ³•ä¸­æ²¡åŠæ³•ï¼ˆå¾ˆéš¾ï¼‰åšåˆ°</p><h5 id="Bilingual-Ensemble"><a href="#Bilingual-Ensemble" class="headerlink" title="Bilingual Ensemble"></a>Bilingual Ensemble</h5><p>æˆ‘ä»¬å¸Œæœ›æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€å’Œç›®æ ‡åˆ°æºè¯­è¨€éƒ½ç”Ÿæˆå¾—å¥½</p><p><img src="/images/2018-10-21-15400883583228.jpg" width="50%" height="50%"></p><h4 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h4><p>$\hat{y}_i$çš„åˆå§‹åŒ–å¾ˆé‡è¦ï¼Œä¸€ä¸å°å¿ƒå°±ä¼šé™·å…¥local minimaï¼›ç”Ÿæˆçš„é€Ÿåº¦æ…¢</p><hr><h3 id="6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation"><a href="#6ï¸âƒ£-Universal-Language-Model-Fine-tuning-for-Text-Classiï¬cation" class="headerlink" title="6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]"></a>6ï¸âƒ£[Universal Language Model Fine-tuning for Text Classiï¬cation]</h3><p>å’ŒELMoã€OpenAI GPTä¸€æ ·ï¼Œéƒ½æ˜¯é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼ˆè¿™é‡Œæ˜¯åˆ†ç±»ä»»åŠ¡ï¼‰ã€‚å¯ä»¥åœ¨éå¸¸å°çš„æ•°æ®é›†ä¸Šæœ‰å¾ˆå¥½çš„æ•ˆæœã€‚</p><p>è´¡çŒ®ï¼š</p><ol><li>è¿ç§»å­¦ä¹ æ¨¡å‹ULMFiT</li><li>æå‡ºå‡ ç§trickï¼šdiscriminative ï¬ne-tuning, slanted triangular learning rates,gradual unfreezing ï¼Œæœ€å¤§ä¿è¯çŸ¥è¯†çš„ä¿ç•™ã€‚</li></ol><h4 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h4><p><img src="/images/2018-10-21-15401043145373.jpg" width="90%" height="50%"></p><p>ä¸‰éƒ¨æ›²ï¼š</p><ol><li>é€šç”¨è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ</li><li>ç›®æ ‡ä»»åŠ¡çš„è¯­è¨€æ¨¡å‹fine-tuning</li><li>ç›®æ ‡ä»»åŠ¡çš„åˆ†ç±»fine-tuning</li></ol><h4 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h4><h5 id="Discriminative-ï¬ne-tuning"><a href="#Discriminative-ï¬ne-tuning" class="headerlink" title="Discriminative ï¬ne-tuning"></a>Discriminative ï¬ne-tuning</h5><p>Motivationï¼šä¸åŒå±‚æœ‰ä¸åŒçš„ä¿¡æ¯ï¼›åº”å½“fine-tune ä¸åŒç¨‹åº¦ï¼Œä¹Ÿå³ä½¿ç”¨ä¸åŒçš„learning rateã€‚</p><p><img src="/images/2018-10-21-15401044160803.jpg" width="35%" height="50%"></p><p>ä½œè€…å‘ç°ä¸Šä¸€å±‚çš„å­¦ä¹ ç‡æ˜¯ä¸‹ä¸€å±‚çš„2.6å€æ—¶æ•ˆæœæ¯”è¾ƒå¥½ã€‚</p><h5 id="Slanted-triangular-learning-rates-STLR"><a href="#Slanted-triangular-learning-rates-STLR" class="headerlink" title="Slanted triangular learning rates (STLR)"></a>Slanted triangular learning rates (STLR)</h5><p><img src="/images/2018-10-21-15401045153164.jpg" width="60%" height="50%"></p><p>å…·ä½“å…¬å¼ï¼š<br><img src="/images/2018-10-21-15401045316305.jpg" width="50%" height="50%"></p><h5 id="Gradual-unfreezing"><a href="#Gradual-unfreezing" class="headerlink" title="Gradual unfreezing"></a>Gradual unfreezing</h5><p>ä»é¡¶å±‚åˆ°åº•å±‚ï¼Œä¸€æ­¥ä¸€æ­¥unfreezeï¼Œä¹Ÿå³ä»ä¸Šåˆ°ä¸‹fine-tuneã€‚è¿™æ˜¯å› ä¸ºæœ€ä¸Šä¸€å±‚æœ‰æœ€å°‘çš„general knowledgeã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> TCN </tag>
            
            <tag> Transformer-XL </tag>
            
            <tag> Trellis Networks </tag>
            
            <tag> continuous decoding </tag>
            
            <tag> ULMFiT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è®ºæ–‡1</title>
      <link href="/2018/10/14/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%871/"/>
      <url>/2018/10/14/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%871/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors"><a href="#1ï¸âƒ£-Learned-in-Translation-Contextualized-Word-Vectors" class="headerlink" title="1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]"></a>1ï¸âƒ£[Learned in Translation: Contextualized Word Vectors]</h3><p>CoVeæ˜¯ç¬¬ä¸€ä¸ªå¼•å…¥åŠ¨æ€è¯å‘é‡çš„æ¨¡å‹ã€‚<br>Motivationï¼šç¿»è¯‘æ¨¡å‹èƒ½å¤Ÿä¿å­˜æœ€å¤šçš„ä¿¡æ¯ï¼Œå› ä¸ºå¦‚æœä¿å­˜ä¿¡æ¯ä¸å¤Ÿå¤šï¼Œdecoderæ¥æ”¶åˆ°çš„ä¿¡æ¯ä¸è¶³ï¼Œç¿»è¯‘æ•ˆæœå°±ä¸ä¼šå¥½ã€‚ï¼ˆä½†å®é™…ä¸Šï¼Œæˆ‘ä¸ªäººè®¤ä¸ºï¼Œdecoderçš„è¡¨ç°è¿˜å’Œlanguage modelæœ‰å…³ï¼Œå¦‚æœdecoderæ˜¯ä¸€ä¸ªå¥½çš„language modelï¼Œä¹Ÿæœ‰å¯èƒ½ç¿»è¯‘å‡ºä¸é”™çš„ç»“æœï¼‰</p><p>åšæ³•ï¼šä½¿ç”¨ä¼ ç»ŸNMTçš„encoder-decoderçš„åšæ³•ç¿»è¯‘æ¨¡å‹ï¼Œåªæ˜¯å°†(bi)LSTMæ‰€å¾—åˆ°çš„éšå±‚çŠ¶æ€è¡¨ç¤ºå–å‡ºæ¥å’Œembeddingæ‹¼æ¥èµ·æ¥ï¼Œä½œä¸ºä¸€ä¸ªè¯çš„è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">w=[GloVe(w); CoVe(w)]</script><hr><h3 id="2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks"><a href="#2ï¸âƒ£-Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]"></a>2ï¸âƒ£[Language Modeling with Gated Convolutional Networks]</h3><p>ä½¿ç”¨CNNå¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå»ºæ¨¡ï¼Œæé«˜å¹¶è¡Œæ€§ã€‚</p><p>è´¡çŒ®ï¼šä½¿ç”¨äº†CNNè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›æå‡ºäº†ç®€åŒ–ç‰ˆçš„gateæœºåˆ¶åº”ç”¨åœ¨CNNä¸­ã€‚</p><p>åšæ³•ï¼š<br><img src="/images/2018-10-14-15394870930257.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªè¾“å…¥ä¸¤ä¸ªfilterï¼Œå·ç§¯å‡ºæ¥çš„åšä¸€ä¸ªgateçš„æ“ä½œ$H_0 = AâŠ—Ïƒ(B)$ï¼Œæ§åˆ¶æµå‘ä¸‹ä¸€å±‚çš„æ•°æ®ã€‚</p><p>ä¸€ä¸ªå°ç»†èŠ‚æ˜¯ï¼Œä¸ºäº†ä¸è®©language modelçœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œæ¯ä¸€å±‚åœ¨å¼€å§‹å·ç§¯çš„æ—¶å€™ä¼šåœ¨å·¦è¾¹æ·»åŠ kernel_size-1ä¸ªpaddingã€‚</p><p>æ‰©å±•ï¼šå› ä¸ºCNNçš„å¹¶è¡Œæ€§é«˜ï¼Œå¯ä»¥ä½¿ç”¨CNNæ¥å¯¹language modelå»ºæ¨¡æ›¿ä»£ELMoï¼ŒåŒæ ·å¯ä»¥è·å¾—åŠ¨æ€è¯å‘é‡ã€‚è¿™ä¸ªæƒ³æ³•å·²ç»ç”±æå‡ºELMoçš„å›¢é˜Ÿåšå‡ºæ¥å¹¶è¿›è¡Œå¯¹æ¯”äº†ã€‚è®ºæ–‡ï¼šDissecting Contextual Word Embeddings: Architecture and Representation</p><p>ç›®å‰æ­£åœ¨<a href="https://github.com/linzehui/Gated-Convolutional-Networks" target="_blank" rel="noopener">å¤ç°</a>è¯¥è®ºæ–‡ ã€‚</p><hr><h3 id="3ï¸âƒ£-Attention-is-All-you-need"><a href="#3ï¸âƒ£-Attention-is-All-you-need" class="headerlink" title="3ï¸âƒ£[Attention is All you need]"></a>3ï¸âƒ£[Attention is All you need]</h3><p>éå¸¸ç»å…¸çš„è®ºæ–‡ã€‚æå‡ºäº†Transformerã€‚ä¸ºäº†è¯»BERTé‡æ¸©äº†ä¸€éã€‚<br><img src="/images/2018-10-14-15394876881322.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-14-15394877200390.jpg" width="70%" height="50%"></p><p><img src="/images/2018-10-14-15394877478814.jpg" width="70%" height="50%"></p><hr><h3 id="4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training"><a href="#4ï¸âƒ£-Improving-Language-Understanding-by-Generative-Pre-Training" class="headerlink" title="4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]"></a>4ï¸âƒ£[Improving Language Understanding by Generative Pre-Training]</h3><p>BERTå°±æ˜¯followè¿™ç¯‡æ–‡ç« çš„å·¥ä½œã€‚<br>ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p><p>è®­ç»ƒè¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼šâ‘ ä½¿ç”¨æœªæ ‡è®°æ•°æ®è®­ç»ƒlanguage modelï¼›â‘¡ä½¿ç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œfine-tune</p><p>Motivationï¼šELMoæ˜¯è®­ç»ƒå¥½language modelï¼Œç„¶åè·å¾—åŠ¨æ€è¯å‘é‡å†ç”¨åˆ°å…¶ä»–ä»»åŠ¡ä¸Šï¼Œè¿™æ ·å°±ä¼šå¤šäº†å¾ˆå¤šå‚æ•°ã€‚å’ŒELMoä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªTransformeræ¨¡å‹è§£å†³å¤šç§ä»»åŠ¡ï¼ˆåˆ©ç”¨è¿ç§»å­¦ä¹ ï¼‰ã€‚</p><p>è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡Œlanguage modelå»ºæ¨¡ï¼›å°è¯•åˆ©ç”¨language modelè¿›è¡Œè¿ç§»å­¦ä¹ è€Œä¸æ˜¯å¦ä¸€ç§æ€è·¯ï¼ˆELMoï¼‰åªæå–è¯å‘é‡ã€‚</p><p>â‘ æ— ç›‘ç£å­¦ä¹ language model<br><img src="/images/2018-10-14-15395044176746.jpg" width="40%" height="50%"></p><p>å…·ä½“åˆ°Transformerå°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395044608239.jpg" width="50%" height="50%"></p><p>â‘¡ç›‘ç£å­¦ä¹ ï¼ˆfine-tuneï¼‰<br>æ ¹æ®è¾“å…¥é¢„æµ‹æ ‡ç­¾<br><img src="/images/2018-10-14-15395045508824.jpg" width="35%" height="50%"></p><p>å…·ä½“å°±æ˜¯ï¼š<br><img src="/images/2018-10-14-15395045734859.jpg" width="40%" height="50%"></p><p>å°†ä¸¤ä¸ªä»»åŠ¡ä¸€èµ·è®­ç»ƒï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-10-14-15395045932795.jpg" width="30%" height="50%"></p><p>å¯¹äºä¸åŒä»»åŠ¡ï¼Œå¯¹è¾“å…¥è¿›è¡Œä¸€å®šçš„æ”¹åŠ¨ä»¥é€‚åº”Transformerç»“æ„ï¼š<br><img src="/images/2018-10-14-15395046364928.jpg" width="90%" height="50%"></p><hr><h3 id="5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#5ï¸âƒ£-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]"></a>5ï¸âƒ£[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding]</h3><p>åˆ·çˆ†å„æ¦œå•çš„ä¸€ç¯‡ç¥æ–‡ã€‚ä½¿ç”¨Transformeré¢„è®­ç»ƒä¸€ä¸ªlanguage modelè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p><p>Motivationï¼šä¹‹å‰çš„language modelåªèƒ½æ ¹æ®å‰é¢çš„è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªï¼ˆå³ä½¿ELMoæ˜¯åŒå‘çš„LSTMï¼Œä¹Ÿæ˜¯åˆ†åˆ«è®­ç»ƒä¸€ä¸ªå‰å‘å’Œä¸€ä¸ªåå‘çš„ï¼‰ï¼Œé™åˆ¶äº†åŒå‘çš„contextï¼›å› æ­¤æå‡ºäº†åŒå‘çš„language modelã€‚</p><h4 id="åšæ³•ï¼š"><a href="#åšæ³•ï¼š" class="headerlink" title="åšæ³•ï¼š"></a>åšæ³•ï¼š</h4><p>æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š<br>â‘ masked LMï¼šå› ä¸ºä½¿ç”¨äº†ä¸¤è¾¹çš„contextï¼Œè€Œlanguage modelçš„ç›®çš„æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¿™æ ·æ¨¡å‹ä¼šæå‰çœ‹åˆ°ä¸‹ä¸€ä¸ªè¯ï¼Œä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œè®­ç»ƒçš„æ—¶å€™è®²éƒ¨åˆ†è¯maskæ‰ï¼Œæœ€ç»ˆåªé¢„æµ‹è¢«maskæ‰çš„è¯ã€‚</p><p>â‘¡Next Sentence Predictionï¼šéšæœº50%ç”Ÿæˆä¸¤ä¸ªå¥å­æ˜¯æœ‰ä¸Šä¸‹å¥å…³ç³»çš„ï¼Œ50%ä¸¤ä¸ªå¥å­æ˜¯æ²¡æœ‰å…³ç³»çš„ï¼Œç„¶ååšåˆ†ç±»ï¼›å…·ä½“æ¥è¯´æ˜¯æ‹¿ç¬¬ä¸€ä¸ªè¯[CLS]ï¼ˆè¿™æ˜¯æ‰‹åŠ¨æ·»åŠ çš„ï¼‰çš„è¡¨ç¤ºï¼Œè¿‡ä¸€ä¸ªsoftmaxå±‚å¾—åˆ°ã€‚<br><img src="/images/2018-10-14-15394891973653.jpg" width="50%" height="50%"></p><p>è”åˆè®­ç»ƒè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚</p><p>æ¥ä¸‹æ¥æ˜¯é€šè¿‡å…·ä½“çš„ä»»åŠ¡è¿›è¡Œfine-tuneã€‚ä¸€ä¸ªæ¨¡å‹è§£å†³å¤šç§é—®é¢˜ï¼š<br><img src="/images/2018-10-14-15395038593955.jpg" width="80%" height="50%"></p><p>æœ¬æ–‡è´¡çŒ®ï¼šä½¿ç”¨Transformerè¿›è¡ŒåŒå‘çš„language modelå»ºæ¨¡ã€‚è®ºæ–‡æåˆ°çš„ä¸€äº›ç»†èŠ‚/trickséå¸¸å€¼å¾—è®¨è®ºï¼Œæ¯”å¦‚å¯¹token embeddingæ·»åŠ äº†è®¸å¤šä¿¡æ¯ï¼Œéå¸¸ç®€å•ç²—æš´ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper </tag>
            
            <tag> Transformer </tag>
            
            <tag> æ¯å‘¨è®ºæ–‡é˜…è¯» </tag>
            
            <tag> CoVe </tag>
            
            <tag> GCNN </tag>
            
            <tag> BERT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 18:Deep Reinforcement Learning</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2018:%20Deep%20Reinforcement%20Learning/</url>
      
        <content type="html"><![CDATA[<p>è®°å·ï¼š $a$æ˜¯actionï¼Œ$s$å³å¤–éƒ¨çŠ¶æ€stateï¼Œ$\pi_{\theta}(s)$ä¹Ÿå³ä»$s$æ˜ å°„åˆ°$a$çš„å‡½æ•°ï¼›$r$æ˜¯rewardï¼Œæ¯é‡‡å–ä¸€ä¸ªåŠ¨ä½œï¼Œä¼šæœ‰ä¸€ä¸ªrewardï¼Œåˆ™æ€»çš„rewardä¸º</p><script type="math/tex; mode=display">R_\theta = \sum_{t=1}^{T} r_t</script><p>æˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ‹Ÿåˆ$\pi$ï¼Œä¸€ä¸ªeposide $\tau$æ˜¯ä¸€ä¸ªæµç¨‹ä¸‹æ¥çš„çš„æ‰€æœ‰stateã€actionå’Œrewardçš„é›†åˆã€‚</p><script type="math/tex; mode=display">\tau = \{s_1,a_1,r_1,s_2,a_2,r_2,...,s_T,a_T,r_T \}</script><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„actorè¿è¡Œnæ¬¡ï¼Œåˆ™æ¯ä¸ª$\tau$ä¼šæœ‰ä¸€å®šçš„æ¦‚ç‡è¢«é‡‡æ ·åˆ°ï¼Œé‡‡æ ·æ¦‚ç‡è®°ä¸º$P(\tau|\theta)$ï¼Œåˆ™æˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·çš„æ–¹å¼æ¥å¯¹æœŸæœ›rewardè¿›è¡Œä¼°è®¡ï¼š</p><script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n)</script><p>é‚£ä¹ˆæˆ‘ä»¬æ¥ä¸‹æ¥çš„<strong>ç›®æ ‡</strong>å°±æ˜¯æœ€å¤§åŒ–æœŸæœ›rewardï¼Œå…¶ä¸­æœŸæœ›rewardæ˜¯ï¼š</p><script type="math/tex; mode=display">\overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta)</script><p>æˆ‘ä»¬åŒæ ·ä½¿ç”¨æ¢¯åº¦ä¸Šå‡ï¼šå…¶ä¸­ä¸$Î¸$ç›¸å…³çš„æ˜¯$P$ï¼Œåˆ™å¯ä»¥å†™æˆï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) \nabla P(\tau|\theta)= \sum_\tau R(\tau) P(\tau|\theta) \frac{\nabla P(\tau|\theta)}{P(\tau|\theta)}</script><p>ç”±äº$\dfrac {d\log \left( f\left( x\right) \right) }{dx}=\dfrac {1}{f\left( x\right) }\dfrac {df(x)}{dx}$ï¼Œåˆ™å‰å¼å¯å†™æˆï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \sum_\tau R(\tau) P(\tau|\theta) \nabla log P(\tau | \theta) â‰ˆ \frac{1}{N} \sum_{n=1}^{N} R(\tau^n) log P(\tau ^n| \theta)</script><p>å¦‚ä½•æ±‚æ¢¯åº¦ï¼Ÿ<br>ç”±äºï¼š</p><script type="math/tex; mode=display">P(\tau | \theta)=p(s_1)p(a_1|s_1,\theta)p(r_1,s_2|s_1,a_1)p(a_2|s_2,\theta)p(r_2,s_3|s_2,a_2)...\\=p(s_1)\prod_{t=1}^{T}p(a_t|s_t,\theta)p(r_t , s_{t+1}| s_t,a_t)</script><p>å®é™…ä¸Šï¼Œå…¶ä¸­ä¸æ¢¯åº¦ç›¸å…³çš„åªæœ‰ä¸­é—´é¡¹$p(a_t|s_t,\theta)$ï¼Œè¯¥é¡¹ä¹Ÿå³$Ï€$å‡½æ•°ï¼Œä»stateåˆ°actionçš„æ˜ å°„ã€‚<br>å–logå¹¶æ±‚å¯¼ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">\nabla log P(\tau | \theta)= \sum_{t=1}^{T} \nabla log p(a_t|s_t,\theta)</script><p>ä»£å›ï¼Œå› æ­¤æœ€ç»ˆ$\overline{R}_\theta$çš„æ¢¯åº¦ä¸ºï¼š</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} R(\tau^n) \nabla log p(a_{t}^n | s_t^n,\theta)</script><p>æ³¨æ„åˆ°è¯¥å¼å­å‘Šè¯‰æˆ‘ä»¬ï¼Œåº”è€ƒè™‘æ•´ä½“çš„rewardè€Œä¸åº”è¯¥åªè€ƒè™‘æ¯ä¸€æ­¥çš„rewardï¼›å¹¶ä¸”å–logçš„åŸå› å¯ä»¥ç†è§£æˆæ˜¯å¯¹actionå–å½’ä¸€åŒ–ï¼Œå› ä¸ºï¼š</p><script type="math/tex; mode=display">\frac{\nabla p(a_t^n | s_t^n,\theta)}{p(a_t^n | s_t^n,\theta)}</script><p>ä¹Ÿå°±æ˜¯è¯´å¯¹äºé‚£äº›å‡ºç°æ¬¡æ•°è¾ƒå¤šçš„actionï¼Œè¦è¡¡é‡ä»–ä»¬å¯¹rewardçš„çœŸæ­£å½±å“ï¼Œåº”å½“å¯¹ä»–ä»¬å½’ä¸€åŒ–ã€‚</p><p>ä¸ºäº†è®©é‚£äº›å‡ºç°å¯èƒ½æ€§è¾ƒä½çš„actionä¸ä¼šå› ä¸ºæ²¡è¢«sampleåˆ°è€Œåœ¨æ›´æ–°åè¢«é™ä½ä»–ä»¬çš„æ¦‚ç‡ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ªbaselineï¼Œåªæœ‰è¶…è¿‡$b$çš„rewardæ‰ä¼šå¢åŠ ä»–ä»¬å‡ºç°çš„æ¦‚ç‡ã€‚</p><script type="math/tex; mode=display">\nabla \overline{R}_\theta = \frac{1}{N} \sum_{n=1}^{N} \sum_{t=1}^{T_n} (R(\tau^n)-b) \nabla log p(a_{t}^n | s_t^n,\theta)</script>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> Deep Reinforcement Learning </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 17:Ensemble</title>
      <link href="/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2017:%20Ensemble/"/>
      <url>/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2017:%20Ensemble/</url>
      
        <content type="html"><![CDATA[<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>å¯¹äºå¤æ‚æ¨¡å‹ï¼Œå¾€å¾€varianceä¼šå¤§ï¼Œé€šè¿‡å¯¹å¤šä¸ªæ¨¡å‹çš„å¹³å‡ï¼Œèƒ½å¤Ÿå‡å°varianceï¼š<br><img src="/images/2018-10-14-15394832736339.jpg" width="50%" height="50%"></p><p>baggingçš„æ€æƒ³æ˜¯å¤šæ¬¡æœ‰æ”¾å›åœ°é‡‡æ ·Nâ€™ä¸ªç‚¹ï¼ˆé€šå¸¸Nâ€™=Nï¼‰ï¼Œç„¶åå¯¹é‡‡æ ·çš„å‡ ä¸ªæ•°æ®é›†åˆ†åˆ«è®­ç»ƒä¸€ä¸ªæ¨¡å‹<br><img src="/images/2018-10-14-15394833007835.jpg" width="50%" height="50%"></p><p>æµ‹è¯•çš„æ—¶å€™å†å¯¹å‡ ä¸ªæ¨¡å‹è¿›è¡Œå¹³å‡æˆ–æŠ•ç¥¨<br><img src="/images/2018-10-14-15394833255306.jpg" width="50%" height="50%"></p><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>åŸºæœ¬æ€æƒ³æ˜¯å¯¹å‡ ä¸ªå¼±åˆ†ç±»å™¨çº¿æ€§åŠ æƒï¼Œå¾—åˆ°å¼ºåˆ†ç±»å™¨ã€‚åˆ†ç±»å™¨æŒ‰å…ˆåé¡ºåºè®­ç»ƒï¼Œæ¯æ¬¡è®­ç»ƒå®Œï¼Œå¯¹æ–°æ¨¡å‹åˆ†ç±»é”™è¯¯çš„æ•°æ®è¿›è¡Œè°ƒé«˜æƒé‡ï¼Œè€Œæ­£ç¡®çš„æ•°æ®åˆ™é™ä½æƒé‡ã€‚</p><p>å¯ä»¥ä¿è¯ï¼šåªè¦åˆ†ç±»å™¨çš„é”™è¯¯ç‡å°äº50%ï¼Œåœ¨boostingåèƒ½å¤Ÿæœ‰100%çš„æ­£ç¡®ç‡ï¼ˆåœ¨è®­ç»ƒé›†ï¼‰ã€‚</p><p>è¯æ˜è¿‡ç¨‹ç•¥ã€‚</p><h2 id="Ensemble-Stacking"><a href="#Ensemble-Stacking" class="headerlink" title="Ensemble: Stacking"></a>Ensemble: Stacking</h2><p>åŸºæœ¬æ€æƒ³ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®è®­ç»ƒå¤šä¸ªåˆçº§åˆ†ç±»å™¨ï¼Œå°†åˆçº§åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸ºæ¬¡çº§åˆ†ç±»å™¨çš„è¾“å…¥ï¼Œè·å¾—æœ€ç»ˆçš„è¾“å‡ºã€‚æˆ‘ä»¬åº”å½“ä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒæ¬¡çº§åˆ†ç±»å™¨<br><img src="/images/2018-10-14-15394833971028.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Ensemble </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æµ…è°ˆmaskçŸ©é˜µ</title>
      <link href="/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/"/>
      <url>/2018/10/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B5%85%E8%B0%88mask%E7%9F%A9%E9%98%B5/</url>
      
        <content type="html"><![CDATA[<p>ä¸ªäººç›®å‰å¯¹maskçŸ©é˜µçš„ä¸€ç‚¹ç†è§£ã€‚</p><hr><h2 id="æ˜¯ä»€ä¹ˆ"><a href="#æ˜¯ä»€ä¹ˆ" class="headerlink" title="æ˜¯ä»€ä¹ˆ"></a>æ˜¯ä»€ä¹ˆ</h2><p>maskçŸ©é˜µæ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ä¸€ä¸ªç”±0å’Œ1ç»„æˆçš„çŸ©é˜µã€‚ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä¸­ï¼Œå¥å­çš„é•¿åº¦æ˜¯ä¸ç­‰é•¿çš„ï¼Œä½†å› ä¸ºæˆ‘ä»¬ç»å¸¸å°†å¥å­ç»„æˆmini-batchç”¨ä»¥è®­ç»ƒï¼Œå› æ­¤é‚£äº›é•¿åº¦è¾ƒçŸ­çš„å¥å­éƒ½ä¼šåœ¨å¥å°¾è¿›è¡Œå¡«å……0ï¼Œä¹Ÿå³paddingçš„æ“ä½œã€‚ä¸€ä¸ªmaskçŸ©é˜µå³ç”¨ä»¥æŒ‡ç¤ºå“ªäº›æ˜¯çœŸæ­£çš„æ•°æ®ï¼Œå“ªäº›æ˜¯paddingã€‚å¦‚ï¼š<br><img src="/images/2018-10-12-15393574958961.jpg" width="50%" height="50%"><br>å›¾ç‰‡æ¥æºï¼š<a href="https://www.cnblogs.com/neopenx/p/4806006.html" target="_blank" rel="noopener">Theanoï¼šLSTMæºç è§£æ</a></p><p>å…¶ä¸­maskçŸ©é˜µä¸­1ä»£è¡¨çœŸå®æ•°æ®ï¼›0ä»£è¡¨paddingæ•°æ®ã€‚</p><h2 id="ä¸ºä»€ä¹ˆ"><a href="#ä¸ºä»€ä¹ˆ" class="headerlink" title="ä¸ºä»€ä¹ˆ"></a>ä¸ºä»€ä¹ˆ</h2><p>ä¸ºä»€ä¹ˆè¦ä½¿ç”¨maskçŸ©é˜µï¼Ÿä½¿ç”¨maskçŸ©é˜µæ˜¯ä¸ºäº†è®©é‚£äº›è¢«maskæ‰çš„tensorä¸ä¼šè¢«æ›´æ–°ã€‚è€ƒè™‘ä¸€ä¸ªtensor Tçš„size(a,b)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œç›¸ä¹˜åï¼Œåœ¨åå‘å›ä¼ çš„æ—¶å€™åœ¨Tå¯¹åº”maskä¸º0çš„åœ°æ–¹ï¼Œ0çš„æ¢¯åº¦ä»ä¸º0ã€‚å› æ­¤ä¸ä¼šè¢«æ›´æ–°ã€‚</p><h2 id="æ€ä¹ˆåš"><a href="#æ€ä¹ˆåš" class="headerlink" title="æ€ä¹ˆåš"></a>æ€ä¹ˆåš</h2><p>æ¥ä¸‹æ¥ä»‹ç»å‡ ç§ï¼ˆå¯èƒ½ä¸å…¨ï¼‰ä½¿ç”¨maskçš„åœºæ™¯ã€‚</p><h3 id="å¯¹è¾“å…¥è¿›è¡Œmask"><a href="#å¯¹è¾“å…¥è¿›è¡Œmask" class="headerlink" title="å¯¹è¾“å…¥è¿›è¡Œmask"></a>å¯¹è¾“å…¥è¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­å¸¸è§çš„å¥å­ä¸ç­‰é•¿çš„æƒ…å†µã€‚è®¾æˆ‘ä»¬çš„è¾“å…¥çš„batch I:(batch_size,max_seqlen)ï¼Œæˆ‘ä»¬åœ¨è¿‡ä¸€å±‚Embeddingå±‚ä¹‹å‰ï¼Œ<br>åœ¨è¿‡äº†ä¸€å±‚Embeddingå±‚ï¼Œåˆ™æœ‰ E:(batch_size,max_seqlen,embed_dim)ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›Embeddingæ˜¯æ›´æ–°çš„(æ¯”å¦‚æˆ‘ä»¬çš„Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œé‚£å½“ç„¶Embeddingéœ€è¦æ›´æ–°)ï¼Œä½†æˆ‘ä»¬åˆä¸å¸Œæœ›paddingæ›´æ–°ã€‚<br>ä¸€ç§æ–¹æ³•å³ä»¤Eä¸Mç›¸ä¹˜ã€‚å…¶ä¸­Mæ˜¯maskçŸ©é˜µ(batch_size,max_seqlen,1) (1æ˜¯å› ä¸ºè¦broadcastï¼‰ï¼Œè¿™æ ·åœ¨Embeddingæ›´æ–°æ¢¯åº¦æ—¶ï¼Œå› ä¸ºmaskçŸ©é˜µçš„å…³ç³»ï¼Œpaddingä½ç½®ä¸Šçš„æ¢¯åº¦å°±æ˜¯0ã€‚<br>å½“ç„¶åœ¨Pytorchä¸­è¿˜å¯ä»¥ç›´æ¥æ˜¾å¼åœ°å†™ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p>è€Œæ­¤æ—¶åº”å½“å°†paddingæ˜¾å¼æ·»åŠ åˆ°è¯å…¸çš„ç¬¬ä¸€ä¸ªã€‚</p><h3 id="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"><a href="#å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask" class="headerlink" title="å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask"></a>å¯¹æ¨¡å‹ä¸­é—´è¿›è¡Œmask</h3><p>ä¸€ä¸ªå¾ˆç»å…¸çš„åœºæ™¯å°±æ˜¯dropoutã€‚<br>å¯¹äºå‚æ•°çŸ©é˜µW:(h,w)ï¼ŒåŒæ ·å¤§å°çš„maskçŸ©é˜µMï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ä»¤Wâ€™=W*Mï¼Œåˆ™åœ¨åå‘ä¼ æ’­æ—¶ï¼ŒMä¸­ä¸º0çš„éƒ¨åˆ†ä¸è¢«æ›´æ–°ã€‚<br>å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨PyTorchä¸­çš„åŒ…<code>nn.Dropout()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Dropout(p=<span class="number">0.2</span>)</span><br><span class="line">input = torch.randn(<span class="number">20</span>, <span class="number">16</span>)</span><br><span class="line">output = m(input)</span><br></pre></td></tr></table></figure><h3 id="å¯¹lossè¿›è¡Œmask"><a href="#å¯¹lossè¿›è¡Œmask" class="headerlink" title="å¯¹lossè¿›è¡Œmask"></a>å¯¹lossè¿›è¡Œmask</h3><p>è€ƒè™‘NLPä¸­çš„language modelï¼Œæ¯ä¸ªè¯éƒ½éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œåœ¨ä¸€ä¸ªbatchä¸­å¥å­æ€»æ˜¯æœ‰é•¿æœ‰çŸ­ï¼Œå¯¹äºä¸€ä¸ªçŸ­å¥ï¼Œæ­¤æ—¶åœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œä¼šå‡ºç°è¿™æ ·çš„åœºæ™¯ï¼š<code>&lt;pad&gt;</code>è¯è¦é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>è¯ã€‚ä¸¾ä¸ªä¾‹å­ï¼šä¸‰ä¸ªå¥å­[a,b,c,d],[e,f,g],[h,i]ï¼Œåœ¨ç»„æˆbatchåï¼Œä¼šå˜æˆ<br>Xï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>a</td><td>b</td><td>c</td><td>d</td></tr><tr><td>e</td><td>f</td><td>g</td><td><code>&lt;pad&gt;</code></td></tr><tr><td>h</td><td>i</td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table></div><p>Yï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>b</td><td>c</td><td>d</td><td><code>&lt;pad&gt;</code></td></tr><tr><td>f</td><td>g</td><td><code>&lt;eos&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr><tr><td>i</td><td><code>&lt;eos&gt;</code></td><td><code>&lt;pad&gt;</code></td><td><code>&lt;pad&gt;</code></td></tr></tbody></table></div><p>Xæ˜¯è¾“å…¥ï¼ŒYæ˜¯é¢„æµ‹ã€‚é‚£ä¹ˆä»ç¬¬ä¸‰è¡Œå¯ä»¥çœ‹å‡ºï¼Œ<code>&lt;pad&gt;</code>åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ª<code>&lt;pad&gt;</code>ã€‚è¿™æ˜¾ç„¶æ˜¯æœ‰é—®é¢˜çš„ã€‚<br>ä¸€ç§è§£å†³æ–¹æ¡ˆå°±æ˜¯ä½¿ç”¨maskçŸ©é˜µï¼Œåœ¨lossçš„è®¡ç®—æ—¶ï¼Œå°†é‚£äº›æœ¬ä¸åº”è¯¥è®¡ç®—çš„maskæ‰ï¼Œä½¿å¾—å…¶lossä¸º0ï¼Œè¿™æ ·å°±ä¸ä¼šåå‘å›ä¼ äº†ã€‚<br>å…·ä½“å®è·µï¼šåœ¨PyTorchä¸­ï¼Œä»¥CrossEntropyä¸ºä¾‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">torch</span>.<span class="title">nn</span>.<span class="title">CrossEntropyLoss</span><span class="params">(weight=None, size_average=None, ignore_index=<span class="number">-100</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">reduce=None, reduction=â€™elementwise_meanâ€™</span></span></span><br></pre></td></tr></table></figure><p>å¦‚æœ<code>reduction=None</code>åˆ™ä¼šè¿”å›ä¸€ä¸ªä¸è¾“å…¥åŒæ ·å¤§å°çš„çŸ©é˜µã€‚åœ¨ä¸maskçŸ©é˜µç›¸ä¹˜åï¼Œå†å¯¹æ–°çŸ©é˜µè¿›è¡Œmeanæ“ä½œã€‚<br>åœ¨PyTorchå®è·µä¸Šè¿˜å¯ä»¥å¯ä»¥è¿™ä¹ˆå†™ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">masked_outputs = torch.masked_select(dec_outputs, mask)</span><br><span class="line">masked_targets = torch.masked_select(targets, mask)</span><br><span class="line">loss = my_criterion(masked_outputs, masked_targets)</span><br></pre></td></tr></table></figure><p>å¦ä¸€ç§æ›´ä¸ºç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œç›´æ¥åœ¨CrossEntropyä¸­è®¾<code>ignore_index=0</code>ï¼Œè¿™æ ·ï¼Œåœ¨è®¡ç®—lossçš„æ—¶å€™ï¼Œå‘ç°target=0æ—¶ï¼Œä¼šè‡ªåŠ¨ä¸å¯¹å…¶è¿›è¡Œlossçš„è®¡ç®—ã€‚å…¶æœ¬è´¨å’ŒmaskçŸ©é˜µæ˜¯ä¸€è‡´çš„ã€‚</p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>maskçŸ©é˜µå¯ä»¥ç”¨åœ¨ä»»ä½•åœ°æ–¹ï¼Œåªè¦å¸Œæœ›ä¸ä¹‹ç›¸ä¹˜çš„tensorç›¸å¯¹åº”çš„åœ°æ–¹ä¸æ›´æ–°å°±å¯ä»¥è¿›è¡Œmaskæ“ä½œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä»£ç å®è·µ </tag>
            
            <tag> maskçŸ©é˜µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ·±åº¦ç‚¼ä¸¹tricksåˆé›†</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E7%82%BC%E4%B8%B9tricks%E5%90%88%E9%9B%86/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E7%82%BC%E4%B8%B9tricks%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>â€”-Deprecatedâ€”-</p><h2 id="è°ƒå‚æŠ€å·§"><a href="#è°ƒå‚æŠ€å·§" class="headerlink" title="è°ƒå‚æŠ€å·§"></a>è°ƒå‚æŠ€å·§</h2><h3 id="æ•°æ®å¢å¼º"><a href="#æ•°æ®å¢å¼º" class="headerlink" title="æ•°æ®å¢å¼º"></a>æ•°æ®å¢å¼º</h3><h3 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h3><h4 id="1ï¸âƒ£zero-center"><a href="#1ï¸âƒ£zero-center" class="headerlink" title="1ï¸âƒ£zero-center"></a>1ï¸âƒ£zero-center</h4><p>[9]å°†æ•°æ®ä¸­å¿ƒåŒ–</p><h3 id="åˆå§‹åŒ–"><a href="#åˆå§‹åŒ–" class="headerlink" title="åˆå§‹åŒ–"></a>åˆå§‹åŒ–</h3><h4 id="1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•"><a href="#1ï¸âƒ£Xavier-initialization-7-æ–¹æ³•" class="headerlink" title="1ï¸âƒ£Xavier initialization[7]æ–¹æ³•"></a>1ï¸âƒ£Xavier initialization[7]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºæ™®é€šæ¿€æ´»å‡½æ•°(tanh,sigmoid)ï¼šscale = np.sqrt(3/n)</p><h4 id="2ï¸âƒ£He-initialization-8-æ–¹æ³•"><a href="#2ï¸âƒ£He-initialization-8-æ–¹æ³•" class="headerlink" title="2ï¸âƒ£He initialization[8]æ–¹æ³•"></a>2ï¸âƒ£He initialization[8]æ–¹æ³•</h4><p>é€‚ç”¨[9]äºReLUï¼šscale = np.sqrt(6/n)</p><h4 id="3ï¸âƒ£Batch-normalization-10"><a href="#3ï¸âƒ£Batch-normalization-10" class="headerlink" title="3ï¸âƒ£Batch normalization[10]"></a>3ï¸âƒ£Batch normalization[10]</h4><h4 id="4ï¸âƒ£RNN-LSTM-init-hidden-state"><a href="#4ï¸âƒ£RNN-LSTM-init-hidden-state" class="headerlink" title="4ï¸âƒ£RNN/LSTM init hidden state"></a>4ï¸âƒ£RNN/LSTM init hidden state</h4><p>Hinton[3]æåˆ°å°†RNN/LSTMçš„åˆå§‹hidden stateè®¾ç½®ä¸ºå¯å­¦ä¹ çš„weight</p><h3 id="è®­ç»ƒæŠ€å·§"><a href="#è®­ç»ƒæŠ€å·§" class="headerlink" title="è®­ç»ƒæŠ€å·§"></a>è®­ç»ƒæŠ€å·§</h3><h4 id="1ï¸âƒ£Gradient-Clipping-5-6"><a href="#1ï¸âƒ£Gradient-Clipping-5-6" class="headerlink" title="1ï¸âƒ£Gradient Clipping[5,6]"></a>1ï¸âƒ£Gradient Clipping[5,6]</h4><h4 id="2ï¸âƒ£learning-rate"><a href="#2ï¸âƒ£learning-rate" class="headerlink" title="2ï¸âƒ£learning rate"></a>2ï¸âƒ£learning rate</h4><p>åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚<br>[1]Time/Drop-based/Cyclical Learning Rate</p><h4 id="3ï¸âƒ£batch-size"><a href="#3ï¸âƒ£batch-size" class="headerlink" title="3ï¸âƒ£batch size"></a>3ï¸âƒ£batch size</h4><p>[2]ä¸­è¯¦ç»†è®ºè¿°äº†å¢åŠ batch sizeè€Œä¸æ˜¯å‡å°learning rateèƒ½å¤Ÿæå‡æ¨¡å‹è¡¨ç°ã€‚ä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">How to make your model happy againâ€Šâ€”â€Špart 1</a></p><p>[2]<a href="https://arxiv.org/abs/1711.00489" target="_blank" rel="noopener">Donâ€™t Decay the Learning Rate, Increase the Batch Size</a></p><p>[3]<a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">CSC2535 2013: Advanced Machine Learning Lecture 10 Recurrent neural networks</a></p><p>[4]<a href="https://zhuanlan.zhihu.com/p/25110150" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110150</a></p><p>[5]<a href="https://arxiv.org/abs/1211.5063" target="_blank" rel="noopener">On the difficulty of training Recurrent Neural Networks</a></p><p>[6]<a href="https://arxiv.org/abs/1612.08083" target="_blank" rel="noopener">Language Modeling with Gated Convolutional Networks</a></p><p>[7]<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Understanding the difficulty of training deep feedforward neural networks</a></p><p>[8]<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></p><p>[9]<a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">çŸ¥ä¹ï¼šä½ æœ‰å“ªäº›deep learningï¼ˆrnnã€cnnï¼‰è°ƒå‚çš„ç»éªŒï¼Ÿ</a></p><p>[10]<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è°ƒå‚ </tag>
            
            <tag> tricks </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯11</title>
      <link href="/2018/10/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D11/"/>
      <url>/2018/10/07/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D11/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"><a href="#1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«" class="headerlink" title="1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«"></a>1ï¸âƒ£èµ‹å¾—å¤åŸè‰é€åˆ«</h3><p>[å”] ç™½å±…æ˜“<br>ç¦»ç¦»åŸä¸Šè‰ï¼Œä¸€å²ä¸€æ¯è£ã€‚<br><strong>é‡ç«çƒ§ä¸å°½ï¼Œæ˜¥é£å¹åˆç”Ÿ</strong>ã€‚<br>è¿œèŠ³ä¾µå¤é“ï¼Œæ™´ç¿ æ¥è’åŸã€‚<br>åˆé€ç‹å­™å»ï¼Œè‹è‹æ»¡åˆ«æƒ…ã€‚</p><p>è‹è‹ï¼ˆqÄ«ï¼‰ï¼šå½¢å®¹è‰æœ¨é•¿å¾—èŒ‚ç››çš„æ ·å­ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a5371532bc005b99da51</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬ä¸‰ç«  å›å½’çš„çº¿æ€§æ¨¡å‹</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%9B%9E%E5%BD%92%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%9B%9E%E5%BD%92%E7%9A%84%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"><a href="#çº¿æ€§åŸºå‡½æ•°æ¨¡å‹" class="headerlink" title="çº¿æ€§åŸºå‡½æ•°æ¨¡å‹"></a>çº¿æ€§åŸºå‡½æ•°æ¨¡å‹</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-51-50.jpg" alt="0"></p><p><img src="/images/2018-10-07-Xnip2018-10-07_15-53-54.jpg" alt="1"></p><h1 id="åç½®-â½…å·®åˆ†è§£"><a href="#åç½®-â½…å·®åˆ†è§£" class="headerlink" title="åç½®-â½…å·®åˆ†è§£"></a>åç½®-â½…å·®åˆ†è§£</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_15-56-30.jpg" alt="0"></p><h1 id="è´å¶æ–¯çº¿æ€§å›å½’"><a href="#è´å¶æ–¯çº¿æ€§å›å½’" class="headerlink" title="è´å¶æ–¯çº¿æ€§å›å½’"></a>è´å¶æ–¯çº¿æ€§å›å½’</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_16-13-57.jpg" alt="1"></p><h1 id="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"><a href="#è´å¶æ–¯æ¨¡å‹â½è¾ƒ" class="headerlink" title="è´å¶æ–¯æ¨¡å‹â½è¾ƒ"></a>è´å¶æ–¯æ¨¡å‹â½è¾ƒ</h1><p><img src="/images/2018-10-07-Xnip2018-10-07_23-30-33.jpg" alt="1"></p><h1 id="è¯æ®è¿‘ä¼¼"><a href="#è¯æ®è¿‘ä¼¼" class="headerlink" title="è¯æ®è¿‘ä¼¼"></a>è¯æ®è¿‘ä¼¼</h1><p><img src="/images/2018-10-09-Xnip2018-10-09_22-06-22.jpg" alt="1"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 16:SVM</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2016:%20SVM/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2016:%20SVM/</url>
      
        <content type="html"><![CDATA[<p><strong>Hinge Loss+kernel method = SVM</strong></p><h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><p>SVMä¸logistic regressionçš„åŒºåˆ«å³åœ¨äºloss functionçš„ä¸åŒï¼Œlogisticæ˜¯cross entropyï¼Œè€ŒSVMæ˜¯hinge loss<br><img src="/images/2018-10-07-15388878731499.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³å¦‚æœåˆ†ç±»é—´éš”å¤§äº1ï¼Œåˆ™ $L(m_i)=max(0,1âˆ’m_i(w))$ï¼Œåˆ™æŸå¤±ä¸º0ã€‚å› æ­¤SVMæ›´å…·é²æ£’æ€§ï¼Œå› ä¸ºå¯¹ç¦»ç¾¤ç‚¹ä¸æ•æ„Ÿã€‚</p><p>å¯¹äºlinear SVMï¼š</p><ul><li>å®šä¹‰å‡½æ•° $f(x)=\sum_i w_i x_i +b=w^T x$</li><li>å®šä¹‰æŸå¤±å‡½æ•°  $L(f)=\sum_n l(f(x^n),\hat{y}^n)+\lambda ||w||_2$ï¼Œå…¶ä¸­$l(f(x^n),\hat{y}^n)=max(0,1-\hat{y}^n f(x))$</li><li><p>æ¢¯åº¦ä¸‹é™æ±‚è§£ï¼ˆçœç•¥äº†æ­£åˆ™åŒ–ï¼‰</p><script type="math/tex; mode=display">\frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{w_i}}=  \frac{\partial{l(f(x^n),\hat{y}^n})}{\partial{f(x^n)}}  \frac{\partial{f(x^n)}}{\partial{w_i}} x_i^n</script><p>  è€Œ</p><script type="math/tex; mode=display">f(x^n)=w^T \cdot x^n</script></li></ul><script type="math/tex; mode=display">\frac{\partial{max(0,1-\hat{y}^n f(x^n)})}{\partial{f(x^n)}}=\left\{               \begin{array}{**lr**}                -\hat{y}^n & if  \hat{y}^n f(x^n)<1 \\                 0  & otherwise &                 \end{array}  \right.</script><p>å› æ­¤æœ€ç»ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388891611785.jpg" width="55%" height="50%"><br>æˆ‘ä»¬æ¥ä¸‹æ¥ç”¨$c^n(w)$æ›¿ä»£$-\delta(\hat{y}^n f(x^n)&lt;1) \hat{y}^n$</p><h3 id="Kernel-Method"><a href="#Kernel-Method" class="headerlink" title="Kernel Method"></a>Kernel Method</h3><p>ä¸€ä¸ªäº‹å®ï¼š$w$æ˜¯$x$çš„çº¿æ€§åŠ å’Œï¼Œå…¶ä¸­$Î±$ä¸ç­‰äº0å¯¹åº”çš„$x$å°±æ˜¯support vectors</p><p>è¯æ˜ï¼š<br>æˆ‘ä»¬å‰é¢è¯´è¿‡ï¼Œæ›´æ–°è¿‡ç¨‹ï¼š<br><img src="/images/2018-10-07-15388894194698.jpg" width="30%" height="50%"></p><p>å°†å…¶ç»„ç»‡æˆå‘é‡å½¢å¼ï¼š<br><img src="/images/2018-10-07-15388894627632.jpg" width="25%" height="50%"></p><p><strong>å¦‚æœæˆ‘ä»¬å°†$w$åˆå§‹åŒ–æˆ0å‘é‡</strong>ï¼Œé‚£ä¹ˆ$w$æœ€ç»ˆå°±æ˜¯$x$çš„çº¿æ€§ç»„åˆã€‚è¯æ¯•</p><p>å› ä¸º$c(w)$æ˜¯hinge lossï¼Œå› æ­¤å¤§å¤šæ•°çš„å€¼æ˜¯0ï¼Œä¼šé€ æˆ$Î±$ç¨€ç–ã€‚<br>å¦‚æœæˆ‘ä»¬å°†è®­ç»ƒæ•°æ®$x$ç»„ç»‡æˆä¸€ä¸ªçŸ©é˜µï¼Œé‚£ä¹ˆæœ‰ï¼š<br><img src="/images/2018-10-07-15388895570090.jpg" width="25%" height="50%"><br>ä¹Ÿå³ï¼š<br><img src="/images/2018-10-07-15388895870336.jpg" width="40%" height="50%"></p><p>æ‰€ä»¥å¯¹äº$f(x)$ï¼Œæœ‰ï¼š<br><img src="/images/2018-10-07-15388896378645.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Š$X^Tx$å°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®å’Œ$x$è¿›è¡Œç‚¹ç§¯çš„ç»“æœï¼Œä½†å®é™…ä¸Šçº¿æ€§å‡½æ•°å¾€å¾€è¡¨è¾¾èƒ½åŠ›ä¸å¼ºï¼Œæˆ‘ä»¬å¸Œæœ›$x$èƒ½å¤Ÿå˜æˆéçº¿æ€§çš„ã€‚å¦‚æœæˆ‘ä»¬å¼•å…¥kernelï¼Œå°†ç‚¹ç§¯æ¢æˆkernelï¼Œåˆ™ä¼šæœ‰ï¼š</p><script type="math/tex; mode=display">f(x)=\sum_n \alpha_n (x_n\cdot x)=\sum_n \alpha_n K(x_n,x)</script><p>æ‰€ä»¥æˆ‘ä»¬çš„é—®é¢˜å°±å˜æˆäº†ï¼š</p><ul><li>å®šä¹‰å‡½æ•° $f(x)=\sum_n \alpha_n K(x_n,x)$</li><li>æ‰¾åˆ°æœ€ä½³çš„Î±ï¼Œæœ€å°åŒ–loss functionï¼š$L(f)=\sum_n l(f(x^n),\hat{y}^n)=\sum_n l(\sum_{nâ€™} \alpha_{nâ€™} K(x^{n^{â€˜}},x^n),\hat{y}^n)$</li></ul><p>å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦çœŸçš„çŸ¥é“$x$çš„éçº¿æ€§çš„å…·ä½“å½¢å¼ï¼Œæˆ‘ä»¬åªéœ€è¦ä¼šç®—$K$å°±è¡Œï¼Œè¿™ç§ç»•è¿‡$x$çš„å…·ä½“å½¢å¼çš„æ–¹æ³•å°±æ˜¯<strong>kernel trick</strong>ã€‚ç›´æ¥è®¡ç®—$K$ï¼Œæ¯”å…ˆå°†$x$éçº¿æ€§è½¬åŒ–å†åšç‚¹ç§¯æ¥å¾—é«˜æ•ˆã€‚ç”šè‡³æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å¯¹$x$åšçš„éçº¿æ€§æ˜¯æ— ç©·å¤šç»´çš„ï¼Œæ˜¯æ— æ³•ç›´æ¥åšéçº¿æ€§åŒ–çš„ã€‚æ¯”å¦‚RBFæ ¸:</p><script type="math/tex; mode=display">K(x,z)=exp(-\frac{1}{2}||x-z||_2)</script><p>é€šè¿‡æ³°å‹’å±•å¼€å¯ä»¥çŸ¥é“ï¼ŒRBFæ ¸æ˜¯æ— ç©·ç»´çš„ã€‚</p><p>å¦ä¸€ä¸ªkernelçš„ä¾‹å­æ˜¯sigmoid kernelï¼š</p><script type="math/tex; mode=display">K(x,z)=tanh(x\cdot z)</script><p>å½“æˆ‘ä»¬ä½¿ç”¨sigmoid kernelæ—¶ï¼Œå°±ç›¸å½“äºä¸€å±‚hidden layerçš„ç¥ç»ç½‘ç»œï¼Œå¦‚å›¾ï¼š<br><img src="/images/2018-10-07-15388901736757.jpg" width="40%" height="50%"></p><p>ç»™å®šä¸€ä¸ªè¾“å…¥ï¼Œå…±æœ‰nä¸ªneuronï¼Œå…¶ä¸­çš„weightå°±æ˜¯æ¯ä¸ªè®­ç»ƒæ•°æ®çš„å‘é‡å€¼ï¼Œç„¶åå†å°†è¿™äº›neuronåŠ å’Œå¾—åˆ°è¾“å‡ºã€‚å½“ç„¶å¤§éƒ¨åˆ†çš„Î±çš„å€¼æ˜¯0ï¼Œå› æ­¤å®è´¨ä¸Šç¥ç»å…ƒçš„ä¸ªæ•°å’Œsupport vectorçš„ä¸ªæ•°ä¸€è‡´ã€‚</p><p>æˆ‘ä»¬å¯ä»¥ç›´æ¥è®¾è®¡kernelï¼Œè€Œä¸éœ€è¦è€ƒè™‘xçš„éçº¿æ€§å˜æ¢çš„å½¢å¼ï¼Œåªè¦kernelç¬¦åˆmercerâ€™s theoryå³å¯ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 15:Transfer Learning</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2015:%20Transfer%20Learning/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2015:%20Transfer%20Learning/</url>
      
        <content type="html"><![CDATA[<h3 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h3><p>å‡è®¾æˆ‘ä»¬æœ‰å¾ˆå¤šçš„source data $(x^s,y^s )$ï¼Œä¸ä»»åŠ¡ç›¸å…³çš„target data $(x^t,y^t )$  å¾ˆå°‘ã€‚<br>æˆ‘ä»¬åˆ©ç”¨source dataè®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åç”¨target dataæ¥fine tuneæ¨¡å‹ã€‚</p><h4 id="conservative-training"><a href="#conservative-training" class="headerlink" title="conservative training"></a>conservative training</h4><p><img src="/images/2018-10-07-15388871902739.jpg" width="50%" height="50%"></p><p>æˆ‘ä»¬å¯ä»¥ç”¨source dataè®­ç»ƒå¥½çš„æ¨¡å‹çš„weightä½œä¸ºæ–°çš„æ¨¡å‹çš„weightï¼Œç„¶åè®¾å®šä¸€äº›é™åˆ¶ï¼Œæ¯”å¦‚source dataä½œä¸ºè¾“å…¥çš„outputåº”å’Œtarget dataä½œä¸ºè¾“å…¥çš„outputå°½é‡ç›¸ä¼¼ï¼Œæˆ–è€…å‚æ•°å°½é‡ç›¸ä¼¼ç­‰ã€‚</p><h4 id="layer-transfer"><a href="#layer-transfer" class="headerlink" title="layer transfer"></a>layer transfer</h4><p>ä¹Ÿå°±æ˜¯æ–°æ¨¡å‹æœ‰å‡ å±‚æ˜¯ç›´æ¥copyæ—§æ¨¡å‹çš„ï¼Œåªè®­ç»ƒå…¶å®ƒå±‚ã€‚æ³¨æ„åˆ°ä¸åŒä»»åŠ¡æ‰€åº”copyçš„å±‚æ˜¯ä¸åŒçš„ï¼Œè¯­éŸ³ä»»åŠ¡æœ€åå‡ å±‚æ•ˆæœå¥½ï¼Œå›¾åƒè¯†åˆ«å‰é¢å‡ å±‚æ•ˆæœå¥½</p><h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p>ä¸åŒä»»åŠ¡ä¹‹é—´å…±äº«ç›¸åŒçš„ä¸­é—´å±‚ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388872452545.jpg" width="30%" height="50%"><br><img src="/images/2018-10-07-15388872627707.jpg" width="30%" height="50%"></p><p>è¿˜æœ‰ä¸€ç§progressive neural networksï¼š<br><img src="/images/2018-10-07-15388872920224.jpg" width="50%" height="50%"><br>é¦–å…ˆè®­ç»ƒå¥½ç¬¬ä¸€ä¸ªä»»åŠ¡çš„æ¨¡å‹ï¼Œç„¶ååœ¨è®­ç»ƒç¬¬äºŒä¸ªæ¨¡å‹çš„æ—¶å€™å°†ç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬äºŒä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼›è®­ç»ƒç¬¬ä¸‰ä¸ªæ¨¡å‹åˆ™å°†ç¬¬äºŒä¸ªå’Œç¬¬ä¸€ä¸ªæ¨¡å‹çš„éšå±‚åŠ å…¥åˆ°ç¬¬ä¸‰ä¸ªæ¨¡å‹çš„éšå±‚ä¸­ï¼Œä»¥æ­¤ç±»æ¨</p><h3 id="Domain-adversarial-training"><a href="#Domain-adversarial-training" class="headerlink" title="Domain-adversarial training"></a>Domain-adversarial training</h3><p>source dataæ˜¯æœ‰æ ‡ç­¾çš„ï¼Œè€Œtarget dataæ˜¯æ— æ ‡ç­¾çš„ï¼Œéƒ½å±äºåŒä¸€ä¸ªä»»åŠ¡ï¼Œä½†æ•°æ®æ˜¯mismatchçš„ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388873325090.jpg" width="50%" height="50%"></p><p>å› ä¸ºNNçš„éšå±‚å¯ä»¥ç†è§£æˆæ˜¯åœ¨æŠ½å–å›¾åƒçš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿåœ¨è®­ç»ƒNNçš„è¿‡ç¨‹ä¸­å»æ‰source dataçš„ä¸€äº›domain specificçš„ç‰¹æ€§ï¼Œè¿™æ ·å°±å¯ä»¥ç”¨åœ¨target dataä¸Šäº†ã€‚å› æ­¤æˆ‘ä»¬åœ¨feature exactoråé¢è¿æ¥ä¸¤ä¸ªæ¨¡å—ï¼š<br><img src="/images/2018-10-07-15388873772888.jpg" width="50%" height="50%"></p><p>ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›æŠ½å–çš„ç‰¹å¾èƒ½å¤Ÿä½¿å¾—åˆ†ç±»å™¨æ­£ç¡®åœ°åˆ†ç±»ï¼Œå¦ä¸€æ–¹é¢æˆ‘ä»¬å¸Œæœ›è¿™äº›ç‰¹å¾èƒ½å¤Ÿè®©domain classifierèƒ½å¤Ÿæ— æ³•è¯†åˆ«ç‰¹å¾æ˜¯ä»å“ªäº›dataæŠ½å–å¾—åˆ°çš„ï¼Œè¿™æ ·å¾—åˆ°çš„ç‰¹å¾å°±æ˜¯è¢«å»æ‰domain specificç‰¹å¾çš„ã€‚</p><p>å…·ä½“è®­ç»ƒï¼š<br><img src="/images/2018-10-07-15388874447304.jpg" width="50%" height="50%"></p><h3 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h3><p>source dataæœ‰æ ‡ç­¾ï¼Œtarget dataæ— æ ‡ç­¾ï¼Œä½†ä»»åŠ¡ä¸åŒï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388874838165.jpg" width="50%" height="50%"></p><h4 id="Representing-each-class-by-its-attributes"><a href="#Representing-each-class-by-its-attributes" class="headerlink" title="Representing each class by its attributes"></a>Representing each class by its attributes</h4><p>ä¸€ç§æ–¹æ³•æ˜¯å°†æ¯ä¸€ä¸ªç±»éƒ½ç”¨ç‰¹å¾è¡¨ç¤ºï¼Œä½†ç‰¹å¾è¦è¶³å¤Ÿä¸°å¯Œï¼š<br><img src="/images/2018-10-07-15388875088114.jpg" width="50%" height="50%"></p><p>åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å…¥æ˜¯å›¾ç‰‡ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™äº›ç‰¹å¾ï¼š<br><img src="/images/2018-10-07-15388875558853.jpg" width="40%" height="50%"><br>è¿™æ ·åœ¨å°†target dataæ”¾å…¥è®­ç»ƒå¥½çš„NNåä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªè¿™æ ·çš„attributeï¼ŒæŸ¥è¡¨å³å¯æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ç‰¹å¾å¯¹åº”çš„ç±»ã€‚</p><h4 id="Attribute-embedding"><a href="#Attribute-embedding" class="headerlink" title="Attribute embedding"></a>Attribute embedding</h4><p>å¦‚æœç‰¹å¾ç»´åº¦å¤ªé«˜ï¼Œä¹Ÿå¯ä»¥å°†ç‰¹å¾å‹ç¼©æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œè¿™æ ·åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œè¾“å‡ºåˆ™æ˜¯è¿™æ ·çš„å‘é‡ç‰¹å¾ï¼Œè¾“å…¥target dataï¼Œè¾“å‡ºå‘é‡ç‰¹å¾ï¼Œæ‰¾åˆ°æœ€è¿‘çš„ç‰¹å¾å¯¹åº”çš„ç±»å³å¯<br><img src="/images/2018-10-07-15388875888699.jpg" width="50%" height="50%"></p><h4 id="Attribute-embedding-word-embedding"><a href="#Attribute-embedding-word-embedding" class="headerlink" title="Attribute embedding + word embedding"></a>Attribute embedding + word embedding</h4><p>å¦‚æœæ²¡æœ‰attributeæ•°æ®ï¼Œåˆ©ç”¨word embeddingä¹Ÿå¯ä»¥è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚<br>åœ¨zero-shot learningä¸­ï¼Œå…‰æ˜¯è®©ç›¸åŒç±»çš„få’Œgç›¸ä¼¼æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜åº”è¯¥è®©ä¸åŒçš„få’Œgå°½é‡è¿œã€‚</p><script type="math/tex; mode=display">f^âˆ—,g^âˆ—=arg min_{(f,g)}â¡âˆ‘_nmax(0,kâˆ’f(x^n )\cdot g(y^n )+max_{(mâ‰ n)} â¡f(x^m )\cdot g(x^m ) )</script>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Transfer Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 14:Unsupervised Learning:Generation</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2014:%20Unsupervised%20Learning:%20Generation/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2014:%20Unsupervised%20Learning:%20Generation/</url>
      
        <content type="html"><![CDATA[<h3 id="Component-by-component"><a href="#Component-by-component" class="headerlink" title="Component-by-component"></a>Component-by-component</h3><p>å¯¹äºå›¾åƒæ¥è¯´ï¼Œæ¯æ¬¡ç”Ÿæˆä¸€ä¸ªpixelï¼šPixelRNN</p><h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><p>æ¶æ„ï¼š<br><img src="/images/2018-10-07-15388837191574.jpg" width="50%" height="50%"></p><p>å…¶ä¸­eæ˜¯å™ªå£°ï¼ŒÏƒæ˜¯æ–¹å·®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–reconstruction errorï¼Œä»¥åŠä¸€ä¸ªé™åˆ¶ã€‚è¯¥é™åˆ¶çš„ç›®çš„å³é˜²æ­¢Ïƒ=0ï¼Œmæ˜¯æ­£åˆ™åŒ–é¡¹ã€‚</p><p><del>ä¸­é—´çš„æ¨å¯¼ä»¥åŠä¸ºä»€ä¹ˆæ˜¯è¿™æ ·çš„æ¶æ„æˆ‘è¿˜ä¸æ˜¯å¾ˆæ‡‚ï¼Œä¹‹åå†æ›´æ–°ã€‚</del><br>å®é™…ä¸Šå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œæœ‰å‡ ä¸ªè¦ç‚¹ï¼š</p><ul><li>é¦–å…ˆæˆ‘ä»¬æ˜¯åŸºäºè¿™ä¹ˆä¸€ä¸ªå‡è®¾ï¼šä¸­é—´çš„codeåº”å½“æ˜¯æœä»æ­£æ€åˆ†å¸ƒçš„ï¼Œè€Œencoderçš„ä½œç”¨å³åœ¨äºæ‹Ÿåˆè¯¥æ­£æ€åˆ†å¸ƒçš„å‡å€¼ä¸æ–¹å·®çš„å¯¹æ•°ï¼ˆå› ä¸ºæ–¹å·®åº”å½“æ’ä¸ºæ­£ï¼Œä½†ç¥ç»ç½‘ç»œçš„è¾“å‡ºå¯èƒ½æœ‰æ­£æœ‰è´Ÿï¼‰</li><li>å¦‚æœç”Ÿæˆå‡ºæ¥çš„codeä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œä¼šæœ‰ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œä¹Ÿå°±æ˜¯ä¸Šå›¾çš„constraintï¼ˆå¯ä»¥é€šè¿‡KLæ•£åº¦æ¨å¯¼è·å¾—ï¼‰</li><li>æŒ‰ç†è¯´ï¼Œåº”å½“æ˜¯åœ¨ç”Ÿæˆäº†å‡å€¼å’Œæ–¹å·®åï¼Œå®šä¹‰å¥½è¯¥æ­£æ€åˆ†å¸ƒï¼Œç„¶åå†ä»ä¸­é‡‡æ ·ï¼Œä½†æ˜¯è¿™æ ·æ²¡åŠæ³•å›ä¼ æ›´æ–°æ¢¯åº¦ï¼Œå› æ­¤è¿™é‡Œä½¿ç”¨é‡å‚æ•°æŠ€å·§(Reparameterization Trick)ï¼Œä¹Ÿå³ä»$N(\mu,\sigma^2)$ä¸­é‡‡æ ·$Z$ï¼Œç›¸å½“äºä»$N(0,I)$ä¸­é‡‡æ ·$\varepsilon$ï¼Œç„¶åè®©$Z=\mu + \varepsilon \times \mu$</li></ul><p><img src="/images/2018-10-08-15389638077301.jpg" width="70%" height="50%"></p><p><strong>Reference</strong>:<br><a href="https://www.sohu.com/a/226209674_500659" target="_blank" rel="noopener">https://www.sohu.com/a/226209674_500659</a></p><p>VAEçš„ä¸»è¦é—®é¢˜åœ¨äºï¼Œç½‘ç»œåªè¯•å›¾å»è®°ä½è§è¿‡çš„å›¾åƒï¼Œä½†æ²¡æ³•çœŸæ­£å»ç”Ÿæˆæ²¡è§è¿‡çš„å›¾åƒã€‚</p><h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network (GAN)"></a>Generative Adversarial Network (GAN)</h3><p>GANåŒ…å«ä¸€ä¸ªdiscriminatorå’Œä¸€ä¸ªgeneratorï¼Œgeneratorè¯•å›¾ç”Ÿæˆèƒ½å¤Ÿéª—è¿‡discriminatorçš„æ ·æœ¬ï¼Œè€Œgeneratorè¯•å›¾èƒ½å¤Ÿå°†generatorç”Ÿæˆçš„æ ·æœ¬å’ŒçœŸå®çš„æ ·æœ¬åŒºåˆ†ã€‚</p><p>ä¹‹åä¼šæœ‰è¯¦ç»†çš„ä»‹ç»ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Generation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 13:Unsupervised Learning:Auto-encoder</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2013:%20Unsupervised%20Learning:%20Auto-encoder/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2013:%20Unsupervised%20Learning:%20Auto-encoder/</url>
      
        <content type="html"><![CDATA[<h3 id="Auto-encoder"><a href="#Auto-encoder" class="headerlink" title="Auto-encoder"></a>Auto-encoder</h3><p>ç”±ä¸€ä¸ªencoderå’Œä¸€ä¸ªdecoderç»„æˆï¼Œencoderè´Ÿè´£å°†è¾“å…¥è½¬æˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼ˆç»´åº¦é€šå¸¸å°äºè¾“å…¥ï¼‰ï¼Œdecoderè´Ÿè´£å°†è¿™æ®µå‘é‡è¡¨ç¤ºæ¢å¤æˆåŸæ¥çš„è¾“å…¥ã€‚é‚£ä¹ˆä¸­é—´çš„codeå°±å¯ä»¥ä½œä¸ºè¾“å…¥çš„ä¸€ä¸ªä½ç»´è¡¨ç¤ºï¼š<br><img src="/images/2018-10-07-15388832782913.jpg" width="50%" height="50%"></p><h3 id="Auto-encoder-for-CNN"><a href="#Auto-encoder-for-CNN" class="headerlink" title="Auto-encoder for CNN"></a>Auto-encoder for CNN</h3><p><img src="/images/2018-10-07-15388833149617.jpg" width="50%" height="50%"></p><h4 id="Unpooling"><a href="#Unpooling" class="headerlink" title="Unpooling"></a>Unpooling</h4><p>æœ‰ä¸¤ç§æ–¹æ³•ï¼Œä¸€ç§åœ¨poolingçš„æ—¶å€™è®°å½•æœ€å¤§å€¼çš„ä½ç½®ï¼Œåœ¨unpoolingæ—¶åœ¨ç›¸å¯¹ä½ç½®å¡«å……æœ€å¤§å€¼ï¼Œå…¶ä»–ä½ç½®å¡«å……0ï¼›å¦ä¸€ç§ä¸è®°å½•æœ€å¤§å€¼ä½ç½®ï¼Œç›´æ¥åœ¨poolingåŒºåŸŸå…¨éƒ¨å¡«å……æœ€å¤§å€¼ã€‚<br><img src="/images/2018-10-07-15388833530548.jpg" width="50%" height="50%"></p><h4 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h4><p>å…¶å®æœ¬è´¨å°±æ˜¯convolutionã€‚</p><p>è¿™æ˜¯convolution:</p><p><img src="/images/2018-10-07-15388834044149.jpg" width="10%" height="50%"></p><p>æˆ‘ä»¬æœŸå¾…çš„convolutionï¼š<br><img src="/images/2018-10-07-15388834434741.jpg" width="15%" height="50%"></p><p>å®é™…ä¸Šå°±ç­‰ä»·åœ¨ä¸¤è¾¹åšpaddingï¼Œç„¶åç›´æ¥convolutionï¼š<br><img src="/images/2018-10-07-15388834751493.jpg" width="15%" height="50%"></p><h3 id="Auto-encoderçš„ç”¨å¤„"><a href="#Auto-encoderçš„ç”¨å¤„" class="headerlink" title="Auto-encoderçš„ç”¨å¤„"></a>Auto-encoderçš„ç”¨å¤„</h3><p>å¯ä»¥é¢„è®­ç»ƒæ¯ä¸€å±‚çš„DNNï¼š<br><img src="/images/2018-10-07-15388835335550.jpg" width="50%" height="50%"></p><p>åŒç†å…¶å®ƒå±‚ä¹Ÿæ˜¯ä¸€æ ·ï¼Œæ¯æ¬¡fixä½å…¶ä»–å±‚ç„¶ååšAuto-encoderã€‚é‚£ä¹ˆåœ¨bpçš„æ—¶å€™åªéœ€è¦fine-tuneå°±è¡Œã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Auto-encoder </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 12:Unsupervised Learning:Neighbor Embedding</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2012:%20Unsupervised%20Learning:%20Neighbor%20Embedding/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2012:%20Unsupervised%20Learning:%20Neighbor%20Embedding/</url>
      
        <content type="html"><![CDATA[<h3 id="Locally-Linear-Embedding-LLE"><a href="#Locally-Linear-Embedding-LLE" class="headerlink" title="Locally Linear Embedding (LLE)"></a>Locally Linear Embedding (LLE)</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>æ€æƒ³ï¼šå‡è®¾æ¯ä¸ªç‚¹å¯ä»¥ç”±å…¶å‘¨å›´çš„ç‚¹æ¥è¡¨ç¤º<br><img src="/images/2018-10-07-15388822769215.jpg" width="25%" height="50%"></p><p>æˆ‘ä»¬éœ€è¦æ‰¾åˆ°è¿™æ ·çš„$w_{ij}$ï¼Œä½¿å¾—ï¼š</p><script type="math/tex; mode=display">âˆ‘_iâ€–x^iâˆ’âˆ‘_j w_{ij} x^j â€–_2</script><p>è¿™æ ·åœ¨é™ç»´çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä»ç„¶ä¿æŒxä¹‹é—´çš„è¿™æ ·çš„å…³ç³»:<br><img src="/images/2018-10-07-15388823792351.jpg" width="50%" height="50%"></p><h3 id="Laplacian-Eigenmaps"><a href="#Laplacian-Eigenmaps" class="headerlink" title="Laplacian Eigenmaps"></a>Laplacian Eigenmaps</h3><p>ä¸€ç§é™ç»´æ–¹æ³•<br>åŸºæœ¬æ€æƒ³ï¼šå¦‚æœ$x^1$ä¸$x^2$åœ¨é«˜ç»´ç©ºé—´ä¸­ç›¸è¿‘ï¼Œåˆ™é™ç»´åä¹Ÿåº”è¯¥æ¥è¿‘ï¼š</p><script type="math/tex; mode=display">S=1/2 âˆ‘_{i,j} w_{i,j} (z^iâˆ’z^j )^2</script><p>å…¶ä¸­ï¼š<br><img src="/images/2018-10-07-15388824984809.jpg" width="30%" height="50%"></p><p>å¦‚æœå°†zå…¨è®¾ä¸º0ï¼Œæ˜¾ç„¶Sæœ€å°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ç»™zä¸€ä¸ªé™åˆ¶ï¼šzåº”å½“å……æ»¡ç©ºé—´ï¼Œä¹Ÿå³å‡å¦‚zæ˜¯Mç»´ï¼Œé‚£ä¹ˆ$\{z^1,z^2â€¦,z^N\}$çš„ç§©åº”è¯¥ç­‰äºM</p><h3 id="T-distributed-Stochastic-Neighbor-Embedding-t-SNE"><a href="#T-distributed-Stochastic-Neighbor-Embedding-t-SNE" class="headerlink" title="T-distributed Stochastic Neighbor Embedding (t-SNE)"></a>T-distributed Stochastic Neighbor Embedding (t-SNE)</h3><p>ä¹Ÿæ˜¯ä¸€ç§é™ç»´æ–¹æ³•<br>å‰é¢æåˆ°çš„æ–¹æ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼šåŒä¸€ç±»çš„ç‚¹ç¡®å®èšåœ¨ä¸€èµ·ï¼Œä½†ä¸åŒç±»çš„ç‚¹å¹¶æ²¡æœ‰å°½é‡åˆ†å¼€<br><img src="/images/2018-10-07-15388826477983.jpg" width="50%" height="50%"></p><p>t-SNEçš„ä¸»è¦æ€æƒ³ï¼šå°†æ•°æ®ç‚¹æ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å¸Œæœ›é™ç»´å‰å’Œé™ç»´åï¼Œæ•°æ®åˆ†å¸ƒçš„æ¦‚ç‡åº”å½“å°½å¯èƒ½ä¸€è‡´ã€‚<br>t-SNEæ„å»ºä¸€ä¸ªé«˜ç»´å¯¹è±¡ä¹‹é—´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—ç›¸ä¼¼çš„å¯¹è±¡æœ‰æ›´é«˜çš„æ¦‚ç‡è¢«é€‰æ‹©ï¼Œè€Œä¸ç›¸ä¼¼çš„å¯¹è±¡æœ‰è¾ƒä½çš„æ¦‚ç‡è¢«é€‰æ‹©ã€‚t-SNEåœ¨ä½ç»´ç©ºé—´é‡Œåœ¨æ„å»ºè¿™äº›ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—è¿™ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´å°½å¯èƒ½çš„ç›¸ä¼¼ã€‚</p><p>å¦‚ä½•åšï¼Ÿ<br>åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰ï¼š</p><script type="math/tex; mode=display">P(x^j |x^i )=\frac{S(x^i,x^j )}{âˆ‘_{kâ‰ i}S(x^i,x^k )}</script><p>å…¶ä¸­Sè¡¨ç¤ºiä¸jä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</p><p>åœ¨ä½ç»´ç©ºé—´ä¸­ï¼ŒåŒæ ·æœ‰ï¼š</p><script type="math/tex; mode=display">Q(z^j |z^i )=\frac{Sâ€²(z^i,z^j )}{âˆ‘_{kâ‰ i}Sâ€²(z^i,z^k )}</script><p>ä½¿ç”¨KLæ•£åº¦å»è®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼š</p><script type="math/tex; mode=display">L=âˆ‘_i KL(P(âˆ—|x^i )||Q(âˆ—|z^i )) =âˆ‘_iâˆ‘_j P(x^j |x^i )\frac{log P(x^j |x^i )}{Q(z^j |z^i )}</script><p>t-SNEä¸­ï¼Œé«˜ç»´ç©ºé—´å’Œä½ç»´ç©ºé—´è®¡ç®—ç›¸ä¼¼åº¦çš„å…¬å¼ä¸å¤§ä¸€æ ·ï¼š</p><script type="math/tex; mode=display">S(x^i,x^j )=exp(âˆ’â€–x^iâˆ’x^j â€–_2 )</script><script type="math/tex; mode=display">Sâ€²(z^i,z^j )=\frac{1}{(1+â€–z^iâˆ’z^j â€–_2)}</script><p>ä¸¤ä¸ªå…¬å¼çš„å›¾ç¤ºï¼š<br><img src="/images/2018-10-07-15388830652023.jpg" width="70%" height="50%"></p><p>ä¹Ÿå³<strong>ä½ç»´ç©ºé—´ä¼šæ‹‰é•¿è·ç¦»ï¼Œä½¿å¾—è·ç¦»è¿œçš„ç‚¹å°½å¯èƒ½è¢«æ‹‰å¼€</strong>ã€‚</p><p>t-SNEçš„é—®é¢˜åœ¨äºï¼št-SNEæ— æ³•å¯¹æ–°çš„æ•°æ®ç‚¹è¿›è¡Œé™ç»´ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Neighbor Embedding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 11:Unsupervised Learning:Linear Dimension Reduction</title>
      <link href="/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2011:%20Unsupervised%20Learning:%20Linear%20Dimension%20Reduction/"/>
      <url>/2018/10/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2011:%20Unsupervised%20Learning:%20Linear%20Dimension%20Reduction/</url>
      
        <content type="html"><![CDATA[<h2 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h2><h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>ç®—æ³•æ­¥éª¤ï¼š<br><img src="/images/2018-10-07-15388800377875.jpg" width="70%" height="50%"></p><p>è¿­ä»£æ›´æ–°ä½¿å¾—æœ€åèšç±»ä¸­å¿ƒæ”¶æ•›ã€‚ä½†äº‹å…ˆéœ€è¦å®šå¥½æœ‰å¤šå°‘ç±»ã€‚</p><h3 id="Hierarchical-Agglomerative-Clustering-HAC"><a href="#Hierarchical-Agglomerative-Clustering-HAC" class="headerlink" title="Hierarchical Agglomerative Clustering (HAC)"></a>Hierarchical Agglomerative Clustering (HAC)</h3><p>è‡ªä¸‹è€Œä¸Šï¼Œæ¯æ¬¡é€‰ä¸¤ä¸ªæœ€è¿‘çš„èšä¸ºä¸€ç±»ï¼Œç›´åˆ°æ‰€æœ‰çš„éƒ½åˆ†æˆä¸€ç±»<br>æœ€åé€‰æ‹©ä¸€ä¸ªé˜ˆå€¼åˆ’åˆ†ï¼Œå¦‚è“è‰²ç»¿è‰²å’Œçº¢è‰²çš„çº¿<br><img src="/images/2018-10-07-15388801021791.jpg" width="50%" height="50%"></p><h2 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h2><p>æ‰¾åˆ°ä¸€ä¸ªæ˜ å°„ï¼Œä½¿å¾—xèƒ½å¤Ÿæ˜ å°„åˆ°ä½ç»´z</p><h3 id="Principle-Component-Analysis-PCA"><a href="#Principle-Component-Analysis-PCA" class="headerlink" title="Principle Component Analysis (PCA)"></a>Principle Component Analysis (PCA)</h3><p>ç›®çš„æ˜¯æ‰¾åˆ°ä¸€ä¸ªç»´åº¦ï¼Œä½¿å¾—æŠ•å½±å¾—åˆ°çš„varianceæœ€å¤§ï¼Œä¹Ÿå³æœ€å¤§ç¨‹åº¦ä¿ç•™æ•°æ®çš„å·®å¼‚æ€§ã€‚<br><img src="/images/2018-10-07-15388801830659.jpg" width="50%" height="50%"></p><p>å½¢å¼åŒ–å¯ä»¥å†™æˆï¼ˆä¸€ç»´æƒ…å½¢ï¼‰ï¼š</p><script type="math/tex; mode=display">Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2</script><p>å…¶ä¸­ï¼š</p><script type="math/tex; mode=display">â€–w^1 â€–_2=1</script><script type="math/tex; mode=display">z_1=w^1 \cdot x</script><p>$\overline{z_1}$è¡¨ç¤ºzçš„å‡å€¼</p><p>å‡å¦‚æˆ‘ä»¬è¦æŠ•å½±åˆ°å¤šç»´ï¼Œå…¶ä»–ç»´åº¦ä¹Ÿæœ‰åŒæ ·çš„ç›®æ ‡ã€‚å…¶ä¸­æ¯ä¸ªç»´åº¦ä¹‹é—´éƒ½åº”è¯¥æ˜¯ç›¸äº’æ­£äº¤çš„ã€‚<br><img src="/images/2018-10-07-15388804752506.jpg" width="20%" height="50%"></p><h4 id="å¦‚ä½•åšï¼Ÿ"><a href="#å¦‚ä½•åšï¼Ÿ" class="headerlink" title="å¦‚ä½•åšï¼Ÿ"></a>å¦‚ä½•åšï¼Ÿ</h4><p>æ‰¾åˆ°$ \frac{1}{N}âˆ‘(xâˆ’\overline{x} ) (xâˆ’\overline{x})^T$çš„å‰kä¸ªæœ€å¤§çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ï¼Œç»„åˆèµ·æ¥å³æ˜¯æˆ‘ä»¬è¦æ‰¾çš„$W$</p><h4 id="è¯æ˜"><a href="#è¯æ˜" class="headerlink" title="è¯æ˜"></a>è¯æ˜</h4><p>â€”-Warning of Mathâ€”-<br>ç›®çš„ï¼š$Var(z_1 )=\frac{1}{N} âˆ‘_{z_1}(z_1âˆ’\overline{z_1} )^2 $<br>å…¶ä¸­ $\overline{z_1} =\frac{1}{N} âˆ‘{z_1} = \frac{1}{N} âˆ‘ w^1 \cdot x=w^1\cdot \overline{x}$</p><p>æ¨å¯¼ï¼š<br><img src="/images/2018-10-07-15388811276042.jpg" width="35%" height="50%"><br>æ”¹å˜ç¬¦å· $S=Cov(x)$</p><p>åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œæœ‰ï¼š<br>$Sw^1=Î±w^1$<br>ç­‰å¼ä¸¤è¾¹å„å·¦ä¹˜$(w^1)^T$ï¼Œæœ‰ï¼š<br>$(w^1 )^T Sw^1=Î±(w^1 )^T w^1=Î±$</p><p>ä¹Ÿå³ï¼Œ$Î±$æ˜¯$S$çš„ç‰¹å¾å€¼ï¼Œé€‰æ‹©æœ€å¤§çš„ç‰¹å¾å€¼ï¼Œå°±èƒ½å¤Ÿæœ€å¤§åŒ–æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p><p>åŒç†ï¼Œæˆ‘ä»¬è¦æ‰¾$w^2$ï¼Œæœ€å¤§åŒ–$(w^2 )^T Sw^2$ï¼Œå…¶ä¸­æœ‰ï¼š<br>$(w^2 )^T w^2=1$<br>$(w^2 )^T w^1=0$ ï¼ˆä¸ç¬¬ä¸€ç»´æ­£äº¤ï¼‰</p><p>å› æ­¤åˆ©ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼š</p><script type="math/tex; mode=display">g(w^2 )= (w^2 )^T Sw^2âˆ’Î±((w^2 )^T w^2âˆ’1)âˆ’Î²((w^2 )^T w^1âˆ’0)</script><p>æœ€ç»ˆå¾—åˆ°ï¼Œw2å¯¹åº”ç¬¬äºŒå¤§çš„ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ã€‚</p><p>ä»¥æ­¤ç±»æ¨ï¼Œå…¶ä»–ç»´ä¹ŸåŒç†ã€‚<br>â€”-End of Mathâ€”-</p><h4 id="PCAçš„å…¶ä»–"><a href="#PCAçš„å…¶ä»–" class="headerlink" title="PCAçš„å…¶ä»–"></a>PCAçš„å…¶ä»–</h4><p>å®é™…ä¸Šæœ€ç»ˆå¾—åˆ°çš„zï¼Œæ¯ä¸€ç»´ä¹‹é—´çš„åæ–¹å·®éƒ½ä¸º0<br><img src="/images/2018-10-07-15388815546680.jpg" width="50%" height="50%"></p><p>è¯æ˜å¦‚ä¸‹ï¼š<br><img src="/images/2018-10-07-15388815837458.jpg" width="50%" height="50%"></p><p>PCAä¹Ÿå¯ä»¥ç”¨SVDæ¥åšï¼š<br><img src="/images/2018-10-07-15388816250075.jpg" width="60%" height="50%"></p><p>Uä¸­ä¿å­˜äº†Kä¸ªç‰¹å¾å‘é‡ã€‚</p><p>ä»å¦ä¸€ç§è§’åº¦ç†è§£PCAï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºPCAæ˜¯ä¸€ç§autoencoderï¼š<br><img src="/images/2018-10-07-15388816896369.jpg" width="50%" height="50%"></p><h4 id="PCAçš„é—®é¢˜"><a href="#PCAçš„é—®é¢˜" class="headerlink" title="PCAçš„é—®é¢˜"></a>PCAçš„é—®é¢˜</h4><p>PCAæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œå¦‚æœæœ‰æ ‡ç­¾ï¼Œåˆ™æ— æ³•æŒ‰ç…§ç±»åˆ«æ¥è¿›è¡Œæ­£ç¡®é™ç»´ï¼Œå¦‚ï¼š<br><img src="/images/2018-10-07-15388817393283.jpg" width="30%" height="50%"></p><p>ç¬¬äºŒå°±æ˜¯PCAæ˜¯çº¿æ€§å˜æ¢ï¼Œå¯¹äºä¸€äº›éœ€è¦éçº¿æ€§å˜æ¢çš„æ— èƒ½ä¸ºåŠ›<br><img src="/images/2018-10-07-15388817566149.jpg" width="28%" height="50%"></p><h3 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h3><p>å®šä¹‰ï¼šçŸ©é˜µåˆ†è§£ï¼Œå°±æ˜¯å°†ä¸€ä¸ªçŸ©é˜µDåˆ†è§£ä¸ºUå’ŒVçš„ä¹˜ç§¯ï¼Œå³å¯¹äºä¸€ä¸ªç‰¹å®šçš„è§„æ¨¡ä¸ºm*nçš„çŸ©é˜µDï¼Œä¼°è®¡å‡ºè§„æ¨¡åˆ†åˆ«ä¸ºm*kå’Œn*kçš„çŸ©é˜µUå’ŒVï¼Œä½¿å¾—$UV^T$çš„å€¼å°½å¯èƒ½é€¼è¿‘çŸ©é˜µDã€‚å¸¸ç”¨äºæ¨èç³»ç»Ÿã€‚</p><p>æ€æƒ³ï¼š<br>å‡å¦‚æœ‰ä¸€ä¸ªçŸ©é˜µï¼š<br><img src="/images/2018-10-07-15388819053983.jpg" width="60%" height="50%"></p><p>å‡è®¾æ¨ªè½´å’Œçºµè½´æ¯ä¸€ç»´éƒ½æœ‰ä¸€ä¸ªå‘é‡ä»£è¡¨è¯¥ç»´ï¼ŒçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ å°±æ˜¯æ¨ªè½´å’Œçºµè½´å¯¹åº”ç»´çš„ç‚¹ç§¯ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯å°½å¯èƒ½å‡å°ï¼š</p><script type="math/tex; mode=display">L=\sum_{(i,j)} (r^i \cdot r^j -n_{ij})^2</script><p>å…¶ä¸­$r_i$ $r_j$å°±æ˜¯å‘é‡è¡¨ç¤ºï¼Œ$n_{ij}$å°±æ˜¯çŸ©é˜µçš„å†…å®¹ã€‚</p><p>å¯ä»¥ä½¿ç”¨SVDæ±‚è§£ä¸Šå¼ï¼š<br><img src="/images/2018-10-07-15388820642382.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šï¼Œè€ƒè™‘æ¯ä¸€è¡Œæˆ–åˆ—æœ¬èº«çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬å¯¹Lossè¿›è¡Œæ‰©å±•ï¼š</p><script type="math/tex; mode=display">Minimizing \ \ L=\sum_{(i,j)} (r^i \cdot r^j +b_i+b_j-n_{ij})^2</script><p>ä½¿ç”¨SGDå¯ä»¥æ±‚è§£ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Linear Dimension Reduction </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸çš„æ¨å¯¼</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%8E%A8%E5%AF%BC/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p> è®°RNNä¸­æ¯ä¸€æ­¥çš„æŸå¤±ä¸º$E_t$ï¼Œåˆ™æŸå¤±å¯¹$h_{t-1}$çš„æƒé‡$W$çš„å¯¼æ•°æœ‰ï¼š</p><script type="math/tex; mode=display">\frac{\partial{E_t}}{\partial{W}}=\sum_{k=1}^{t}    \frac{\partial{E_t}}{\partial{y_t}} \frac{\partial{y_t}}{\partial{h_t}} \frac{\partial{h_t}}{\partial{h_k}} \frac{\partial{h_k}}{\partial{W}}</script><p>å…¶ä¸­$\frac{\partial{h_t}}{\partial{h_k}}$ä½¿ç”¨é“¾å¼æ³•åˆ™æœ‰ï¼š</p><script type="math/tex; mode=display">\frac{\partial{h_t}}{\partial{h_k}} =     \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} =    \prod_{j=k+1}^{t} W^T \times diag[f^{\prime}(h_{j-1})]</script><p>å…¶ä¸­$\frac{\partial{h_j}}{\partial{h_{j-1}}}$ æ˜¯é›…å…‹æ¯”çŸ©é˜µã€‚å¯¹å…¶å–æ¨¡(norm)ï¼Œæœ‰ï¼š</p><script type="math/tex; mode=display">\rVert \frac{\partial{h_j}}{\partial{h_{j-1}}}\rVert â‰¤ \rVert W^T \rVert \rVert diag[f^{\prime}(h_{j-1})] \rVert â‰¤ \beta_W \beta_h</script><p>å½“$f$ä¸ºsigmoidæ—¶ï¼Œ$f^{\prime}(h_{j-1})$æœ€å¤§å€¼ä¸º1ã€‚</p><p>æœ€ç»ˆæˆ‘ä»¬æœ‰ï¼š</p><script type="math/tex; mode=display">\rVert \frac{\partial{h_t}}{\partial{h_{k}}}\rVert â‰¤ \rVert \prod_{j=k+1}^{t} \frac{\partial{h_j}}{\partial{h_{j-1}}} \rVert â‰¤ (\beta_W \beta_h)^{t-k}</script><p>ä»ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“t-kè¶³å¤Ÿå¤§æ—¶ï¼Œå¦‚æœ$(\beta_W \beta_h)$å°äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å°ï¼Œç›¸åï¼Œè‹¥$(\beta_W \beta_h)$å¤§äº1åˆ™$(\beta_W \beta_h)^{t-k}$åˆ™ä¼šå˜å¾—éå¸¸å¤§ã€‚</p><p>åœ¨è®¡ç®—æœºä¸­ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå¤§æ—¶ï¼Œä¼šé€ æˆä¸Šæº¢(NaN)ï¼Œä¹Ÿå³æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œå½“æ¢¯åº¦å€¼å¾ˆå°æ—¶ï¼Œä¼šå˜æˆ0ï¼Œä¹Ÿå³æ¢¯åº¦æ¶ˆå¤±ã€‚æ³¨æ„åˆ°ï¼Œt-kçš„æŸå¤±å®é™…ä¸Šè¯„ä¼°çš„æ˜¯ä¸€ä¸ªè¾ƒè¿œçš„è¯å¯¹å½“å‰tçš„è´¡çŒ®ï¼Œæ¢¯åº¦æ¶ˆå¤±ä¹Ÿå³æ„å‘³ç€å¯¹å½“å‰çš„è´¡çŒ®æ¶ˆå¤±ã€‚</p><p>Reference:<br>CS224d: Deep Learning for NLP Lecture4</p>]]></content>
      
      
      
        <tags>
            
            <tag> æ¢¯åº¦æ¶ˆå¤± </tag>
            
            <tag> æ¢¯åº¦çˆ†ç‚¸ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†10</title>
      <link href="/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8610/"/>
      <url>/2018/10/07/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%8610/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ"><a href="#1ï¸âƒ£-æ­£æ€åˆ†å¸ƒ" class="headerlink" title="1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]"></a>1ï¸âƒ£[æ­£æ€åˆ†å¸ƒ]</h3><p>é«˜ç»´æ­£æ€åˆ†å¸ƒæ˜¯ä»ä¸€ç»´å‘å±•è€Œæ¥çš„ï¼š<br><img src="/images/2018-10-07-15388761009977.jpg" width="70%" height="50%"></p><p><a href="https://www.zhihu.com/question/36339816" target="_blank" rel="noopener">https://www.zhihu.com/question/36339816</a></p><hr><h3 id="2ï¸âƒ£-RNN"><a href="#2ï¸âƒ£-RNN" class="headerlink" title="2ï¸âƒ£[RNN]"></a>2ï¸âƒ£[RNN]</h3><p>from <a href="https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf" target="_blank" rel="noopener">https://www.cs.toronto.edu/~hinton/csc2535/notes/lec10new.pdf</a></p><p>é€šå¸¸è€Œè¨€ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†RNNçš„initial stateè®¾ä¸ºå…¨0ï¼Œä½†åœ¨Hintonçš„slideä¸­æåˆ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆå§‹çŠ¶æ€ä½œä¸ºå¯å­¦ä¹ çš„å˜é‡ï¼Œå’Œæˆ‘ä»¬åœ¨å­¦ä¹ æƒé‡çŸ©é˜µä¸€æ ·ã€‚</p><p><img src="/images/2018-10-07-15388770544817.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æ­£æ€åˆ†å¸ƒ </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬äºŒç«  æ¦‚ç‡åˆ†å¸ƒ</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<h1 id="äºŒå…ƒå˜é‡"><a href="#äºŒå…ƒå˜é‡" class="headerlink" title="äºŒå…ƒå˜é‡"></a>äºŒå…ƒå˜é‡</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-25-21.jpg" alt="äºŒå…ƒå˜é‡1"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-26-46.jpg" alt="è´å¡”åˆ†å¸ƒ"></p><h1 id="å¤šé¡¹å¼åˆ†å¸ƒ"><a href="#å¤šé¡¹å¼åˆ†å¸ƒ" class="headerlink" title="å¤šé¡¹å¼åˆ†å¸ƒ"></a>å¤šé¡¹å¼åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-31-55.jpg" alt="å¤šé¡¹å¼åˆ†å¸ƒ"></p><h1 id="é«˜æ–¯åˆ†å¸ƒ"><a href="#é«˜æ–¯åˆ†å¸ƒ" class="headerlink" title="é«˜æ–¯åˆ†å¸ƒ"></a>é«˜æ–¯åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-40-32.jpg" alt="é«˜æ–¯åˆ†å¸ƒ"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-43-09.jpg" alt="2"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-45-15.jpg" alt="3"></p><p><img src="/images/2018-09-30-Xnip2018-09-30_14-48-58.jpg" alt="4"></p><h1 id="æŒ‡æ•°æ—åˆ†å¸ƒ"><a href="#æŒ‡æ•°æ—åˆ†å¸ƒ" class="headerlink" title="æŒ‡æ•°æ—åˆ†å¸ƒ"></a>æŒ‡æ•°æ—åˆ†å¸ƒ</h1><p><img src="/images/2018-09-30-Xnip2018-09-30_14-51-25.jpg" alt="1"></p><p><img src="/images/2018-10-03-Xnip2018-10-03_10-03-54.jpg" alt="2"></p><h1 id="éå‚æ•°ä¼˜åŒ–"><a href="#éå‚æ•°ä¼˜åŒ–" class="headerlink" title="éå‚æ•°ä¼˜åŒ–"></a>éå‚æ•°ä¼˜åŒ–</h1><p><img src="/images/2018-10-03-Xnip2018-10-03_10-05-24.jpg" alt="1"></p><p><img src="/images/2018-10-03-Xnip2018-10-03_10-06-55.jpg" alt="2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 10:Semi-supervised learning</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2010:%20Semi-supervised/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%2010:%20Semi-supervised/</url>
      
        <content type="html"><![CDATA[<p>ä»€ä¹ˆæ˜¯semi-supervised learning</p><p>ç»™å®šæ•°æ®${(x^r,\hat{y}^r)}_{r=1}^{R},{(x_u)}_{u=R}^{R+U}$ï¼Œå…¶ä¸­æœªæ ‡è®°æ•°æ®è¿œè¿œå¤šäºæ ‡è®°æ•°æ® $U&gt;&gt;R$</p><p>ä¸ºä»€ä¹ˆåŠç›‘ç£å­¦ä¹ æœ‰ç”¨ï¼Ÿ<br>å› ä¸ºæœªæ ‡è®°æ•°æ®çš„åˆ†å¸ƒå¯èƒ½èƒ½å¤Ÿç»™æˆ‘ä»¬ä¸€äº›ä¿¡æ¯ã€‚</p><h3 id="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "><a href="#ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ " class="headerlink" title="ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ "></a>ç”Ÿæˆæ¨¡å‹çš„åŠç›‘ç£å­¦ä¹ </h3><p>ç»™å®šä¸¤ç±»$C_1$ã€$C_2$ï¼Œè¦æ±‚å¾—åˆ°åéªŒæ¦‚ç‡åˆ†å¸ƒ</p><script type="math/tex; mode=display">P(C_1 |x)=\frac{P(x|C_1 )P(C_1 )}{(P(x|C_1 )P(C_1 )+P(x|C_2 )P(C_2 ) )}</script><p>å…¶ä¸­è”åˆæ¦‚ç‡åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒã€‚æœªæ ‡è®°æ•°æ®æ­¤æ—¶çš„ä½œç”¨å³å¸®æˆ‘ä»¬é‡æ–°ä¼°è®¡$P(C_1),P(C_2),\mu,\Sigma$</p><p><img src="/images/2018-09-30-15382829251218.jpg" width="50%" height="50%"></p><p>å¦‚ä½•åš?<br>å…ˆåˆå§‹åŒ–$P(C_1),P(C_2),\mu,\Sigma$ï¼Œé€šå¸¸å¯ä»¥å…ˆç”¨æœ‰æ ‡è®°æ•°æ®è¿›è¡Œä¼°è®¡</p><ol><li>è®¡ç®—æ¯ä¸ªæœªæ ‡è®°æ•°æ®çš„åéªŒæ¦‚ç‡åˆ†å¸ƒ</li><li>ä»¥è¯¥æ¦‚ç‡åˆ†å¸ƒæ›´æ–°æ¨¡å‹<br>ä¸æ–­é‡å¤ç›´è‡³æ‹Ÿåˆ</li></ol><p><img src="/images/2018-09-30-15382829987091.jpg" width="70%" height="50%"></p><p>åŸå› ï¼š<br>å½“æˆ‘ä»¬åœ¨åšç›‘ç£å­¦ä¹ æ—¶ï¼Œä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ±‚è§£ï¼š</p><script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{x^r,\hat{y}^r} logP_Î¸ (x^r |\hat{y}^r )</script><p>åŠ ä¸Šäº†æœªæ ‡è®°æ•°æ®åï¼ŒåŒæ ·ä¹Ÿè¦åšæœ€å¤§ä¼¼ç„¶ï¼š</p><script type="math/tex; mode=display">logL(Î¸)=âˆ‘_{(x^r,\hat{y}^r)} logP_Î¸ (x^r |\hat{y}^r )+âˆ‘_{x^u} logP_Î¸ (x^u)</script><h3 id="Low-density-Separation"><a href="#Low-density-Separation" class="headerlink" title="Low-density Separation"></a>Low-density Separation</h3><p>å‡è®¾ä¸åŒç±»åˆ«ä¹‹é—´æœ‰ä¸€æ¡æ˜æ˜¾çš„åˆ†ç•Œçº¿ï¼Œä¹Ÿå³å­˜åœ¨ä¸€ä¸ªåŒºåŸŸï¼Œå…¶å¯†åº¦æ¯”å…¶ä»–åŒºåŸŸå°</p><h4 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h4><p>å¦‚ä½•åš?</p><ol><li>å…ˆç”¨æœ‰æ ‡ç­¾æ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹$f$ï¼›</li><li>åˆ©ç”¨æ¨¡å‹å¯¹æœªæ ‡è®°æ•°æ®è¿›è¡Œæ ‡è®°ï¼Œè¿™äº›æ ‡ç­¾ç§°ä¸ºä¼ªæ ‡ç­¾ï¼ˆpseudo-labelï¼‰</li><li>å°†éƒ¨åˆ†æœ‰ä¼ªæ ‡ç­¾çš„æ•°æ®æ”¾å…¥æœ‰æ ‡ç­¾æ•°æ®ä¸­ï¼Œé‡æ–°è®­ç»ƒ<br>é‡å¤ç›´åˆ°æ‹Ÿåˆ</li></ol><p>è¿™ç§æ–¹å¼å’Œç”Ÿæˆæ¨¡å‹çš„åŒºåˆ«ï¼šè¯¥æ–¹æ³•ä½¿ç”¨çš„æ˜¯hard labelè€Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨çš„æ˜¯soft label</p><h4 id="Entropy-based-Regularization"><a href="#Entropy-based-Regularization" class="headerlink" title="Entropy-based Regularization"></a>Entropy-based Regularization</h4><p>å°†æœªæ ‡è®°æ•°æ®å……å½“æ­£åˆ™åŒ–çš„æ•ˆæœï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹é¢„æµ‹æ ‡ç­¾çš„æ¦‚ç‡è¾ƒä¸ºé›†ä¸­ï¼Œä¹Ÿå³ç†µåº”è¯¥å°½å¯èƒ½å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœªæ ‡è®°æ•°æ®ä½¿å¾—åˆ†ç±»è¾¹ç•Œå°½å¯èƒ½åˆ’åœ¨ä½å¯†åº¦åŒºåŸŸã€‚<br><img src="/images/2018-09-30-15382837957204.jpg" width="30%" height="50%"></p><h3 id="Smoothness-Assumption"><a href="#Smoothness-Assumption" class="headerlink" title="Smoothness Assumption"></a>Smoothness Assumption</h3><p>å‡è®¾ï¼šä½äºç¨ å¯†æ•°æ®åŒºåŸŸçš„ä¸¤ä¸ªè·ç¦»å¾ˆè¿‘çš„æ ·ä¾‹çš„ç±»æ ‡ç­¾ç›¸ä¼¼ï¼Œé€šè¿‡high density pathè¿æ¥ã€‚</p><p><img src="/images/2018-09-30-15382840889274.jpg" width="40%" height="50%"><br>x1ä¸x2ä¹‹é—´è¾ƒä¸ºç¨ å¯†ï¼Œå› æ­¤x2ä¸x1æ¯”x2ä¸x3æ›´ä¸ºæ¥è¿‘ã€‚</p><p><strong>å¦‚ä½•çŸ¥é“x1ä¸x2é€šè¿‡high density pathè¿æ¥ï¼Ÿ</strong><br><img src="/images/2018-09-30-15382841851160.jpg" width="50%" height="50%"></p><p>åŸºäºå›¾çš„æ–¹æ³•ï¼š</p><ol><li>å®šä¹‰xiä¸xjä¹‹é—´çš„ç›¸ä¼¼åº¦$s(x^i,x^j)$</li><li>æ·»åŠ è¾¹ï¼Œæœ‰ä¸¤ç§é€‰æ‹©<ol><li>k nearest neighbor</li><li>e-neighborhood<br><img src="/images/2018-09-30-15382842669412.jpg" width="50%" height="50%"></li></ol></li><li>è¾¹ä¹‹é—´çš„æƒé‡é€šè¿‡ç›¸ä¼¼åº¦æ¥è¡¡é‡ã€‚å¦‚ï¼š $s(x^i,x^j )=exp(âˆ’Î³â€–x^iâˆ’x^jâ€–^2)$</li></ol><p>è¯¥æ–¹æ³•æœ¬è´¨å³åˆ©ç”¨æœ‰æ ‡ç­¾æ•°æ®å»å½±å“æœªæ ‡è®°æ•°æ®ï¼Œé€šè¿‡å›¾çš„ä¼ æ’­ã€‚ä½†ä¸€ä¸ªé—®é¢˜æ˜¯å¦‚æœæ•°æ®ä¸å¤Ÿå¤šï¼Œå°±å¯èƒ½æ²¡åŠæ³•ä¼ æ’­ã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382844101208.jpg" width="30%" height="50%"></p><p>åœ¨å»ºç«‹å¥½å›¾åï¼Œå¦‚ä½•ä½¿ç”¨?</p><ul><li>å®šä¹‰å›¾çš„å¹³æ»‘ç¨‹åº¦ï¼Œ$y$è¡¨ç¤ºæ ‡ç­¾ã€‚$S$è¶Šå°è¡¨ç¤ºè¶Šå¹³æ»‘ã€‚<script type="math/tex; mode=display">S=1/2âˆ‘_{i,j} w_{i,j} (y^iâˆ’y^j )^2=y^T Ly</script><script type="math/tex; mode=display">y=[â‹¯y^iâ‹¯y^jâ‹¯]^T</script><script type="math/tex; mode=display">L=Dâˆ’W</script></li></ul><p>Dæ˜¯é‚»æ¥çŸ©é˜µï¼Œç¬¬ijä¸ªå…ƒç´ å³xiä¸xjä¹‹é—´çš„weightï¼ŒWæ˜¯å¯¹è§’çŸ©é˜µï¼Œiiä¸ªå…ƒç´ æ˜¯Dçš„ç¬¬iè¡Œçš„åŠ å’Œï¼›Lç§°ä¸ºGraph Laplacian<br><img src="/images/2018-09-30-15382847006975.jpg" width="50%" height="50%"></p><ul><li>æˆ‘ä»¬æœ€ç»ˆåœ¨è®¡ç®—Lossçš„æ—¶å€™è¦åŠ ä¸Šè¿™é¡¹æ­£åˆ™é¡¹<script type="math/tex; mode=display">L=âˆ‘_{x^r}C(y^r,\hat{y}^r ) +Î»S</script></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> Semi-supervised learning </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 7:Tips for DL</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%207:%20Tips%20for%20DL/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%207:%20Tips%20for%20DL/</url>
      
        <content type="html"><![CDATA[<p>å¤§çº²<br><img src="/images/2018-09-30-15382757690955.jpg" width="50%" height="50%"></p><h2 id="new-activation-function"><a href="#new-activation-function" class="headerlink" title="new activation function"></a>new activation function</h2><p>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šç”±äºsigmoidä¼šå°†å€¼å‹ç¼©ï¼Œæ‰€ä»¥åœ¨åå‘ä¼ æ’­æ—¶ï¼Œè¶Šåˆ°åé¢å€¼è¶Šå°ã€‚</p><p><img src="/images/2018-09-30-15382758841507.jpg" width="30%" height="50%"><br>æ‰€ä»¥åå±‚çš„æ›´æ–°ä¼šæ¯”å‰å±‚çš„æ›´æ–°æ›´å¿«ï¼Œå¯¼è‡´å‰å±‚è¿˜æ²¡convergeï¼Œåå±‚å°±æ ¹æ®å‰å±‚çš„æ•°æ®ï¼ˆrandomï¼‰è¾¾åˆ°convergeäº†</p><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p><img src="/images/2018-09-30-15382759503401.jpg" width="30%" height="50%"><br>èƒ½å¤Ÿå¿«é€Ÿè®¡ç®—ï¼Œä¸”èƒ½å¤Ÿè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</p><p>å› ä¸ºä¼šæœ‰éƒ¨åˆ†neuronçš„å€¼æ˜¯0ï¼Œæ‰€ä»¥ç›¸å½“äºæ¯æ¬¡è®­ç»ƒä¸€ä¸ªç˜¦é•¿çš„ç¥ç»ç½‘ç»œã€‚<br><img src="/images/2018-09-30-15382760030965.jpg" width="50%" height="50%"></p><h4 id="ReLUçš„å˜ä½“"><a href="#ReLUçš„å˜ä½“" class="headerlink" title="ReLUçš„å˜ä½“"></a>ReLUçš„å˜ä½“</h4><p><img src="/images/2018-09-30-15382928024258.jpg" width="50%" height="50%"></p><h3 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h3><p>é¦–å…ˆå°†å‡ ä¸ªneuronå½’ä¸ºä¸€ç»„ï¼Œç„¶åæ¯æ¬¡å‰å‘ä¼ æ’­æ—¶å–æœ€å¤§çš„ä½œä¸ºè¾“å‡ºã€‚<br><img src="/images/2018-09-30-15382761367509.jpg" width="50%" height="50%"></p><p>å®é™…ä¸ŠReLUæ˜¯maxoutçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼š<br><img src="/images/2018-09-30-15382761741870.jpg" width="40%" height="50%"></p><p>æ›´ä¸€èˆ¬çš„ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-30-15382762237369.jpg" width="40%" height="50%"></p><p>å› ä¸ºwå’Œbçš„å˜åŒ–ï¼Œæ‰€ä»¥è¯¥activation functionå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªlearnable activation function</p><p>è¿™æ ·ä¸€ä¸ªlearnable activation functionæœ‰è¿™æ ·çš„ç‰¹ç‚¹ï¼š</p><blockquote><p>Activation function in maxout network can be any piecewise linear convex function<br>How many pieces depending on how many elements in a group</p></blockquote><p>å¦‚ï¼š<br><img src="/images/2018-09-30-15382763537888.jpg" width="60%" height="50%"></p><p>maxoutåº”å¦‚ä½•è®­ç»ƒï¼Ÿ</p><p><img src="/images/2018-09-30-15382764343880.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªæ™®é€šçš„ç˜¦é•¿networkï¼Œå¸¸è§„è®­ç»ƒå³å¯ã€‚<br><img src="/images/2018-09-30-15382764564859.jpg" width="50%" height="50%"></p><h2 id="Adaptive-learning-rate"><a href="#Adaptive-learning-rate" class="headerlink" title="Adaptive learning rate"></a>Adaptive learning rate</h2><p>åœ¨adagradä¸­:<br><img src="/images/2018-09-30-15382765516383.jpg" width="30%" height="50%"></p><p>è¶Šåˆ°åé¢learning rateè¶Šæ¥è¶Šå°ï¼Œä½†å®é™…ä¸Šåœ¨dlé‡Œé¢ï¼Œerror surfaceæ˜¯éå¸¸å¤æ‚çš„ï¼Œè¶Šæ¥è¶Šå°çš„learning rateå¯èƒ½ä¸é€‚ç”¨äºdlã€‚å¦‚ï¼š<br><img src="/images/2018-09-30-15382765821828.jpg" width="50%" height="50%"></p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p><img src="/images/2018-09-30-15382766372355.jpg" width="60%" height="50%"><br>$Ïƒ^t$æ˜¯å†å²ä¿¡æ¯ï¼Œä¹Ÿå°±æ˜¯è¯´$Ïƒ^t$å‚è€ƒäº†è¿‡å»çš„æ¢¯åº¦å’Œå½“å‰çš„æ¢¯åº¦è·å¾—ä¸€ä¸ªæ–°çš„æ”¾ç¼©å¤§å°</p><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>å¼•å…¥æƒ¯æ€§ä½œä¸ºå‚è€ƒï¼Œä¹Ÿå³å‚è€ƒäº†ä¸Šä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘ã€‚å¼•å…¥æƒ¯æ€§åï¼Œå¯èƒ½æœ‰æœºä¼šè¶Šè¿‡local minimumã€‚<br>æ™®é€šçš„gradient descent:<br><img src="/images/2018-09-30-15382769712428.jpg" width="40%" height="50%"><br>æ¯æ¬¡æœç€æ¢¯åº¦çš„åæ–¹å‘èµ°ã€‚</p><p>Momentum:<br><img src="/images/2018-09-30-15382770120104.jpg" width="40%" height="50%"></p><p>è€ƒè™‘äº†ä¸Šä¸€æ­¥èµ°çš„æ–¹å‘ã€‚</p><p>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382771516587.jpg" width="30%" height="50%"></p><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>ç»“åˆäº†RMSpropå’ŒMomentumï¼Œä¹Ÿå³ç»¼åˆè€ƒè™‘äº†å†å²ä¿¡æ¯å†³å®šå½“å‰æ­¥é•¿ï¼›è€ƒè™‘äº†ä¸Šä¸€æ­¥çš„æ–¹å‘å†³å®šå½“å‰èµ°çš„æ–¹å‘ã€‚<br>å…·ä½“ç®—æ³•ï¼š<br><img src="/images/2018-09-30-15382772986250.jpg" width="60%" height="50%"></p><h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h2><p>å°±æ˜¯åœ¨validation setçš„lossä¸å†å‡å°æ—¶åœæ­¢<br><img src="/images/2018-09-30-15382814784406.jpg" width="50%" height="50%"></p><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><h3 id="L2æ­£åˆ™åŒ–"><a href="#L2æ­£åˆ™åŒ–" class="headerlink" title="L2æ­£åˆ™åŒ–"></a>L2æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382815175056.jpg" width="50%" height="50%"><br>å…¶ä¸­<br><img src="/images/2018-09-30-15382815336088.jpg" width="30%" height="50%"><br>å› æ­¤æ›´æ–°å…¬å¼ä¸ºï¼š<br>    <img src="/images/2018-09-30-15382815641437.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³æ¯æ¬¡ä»¥$1-\eta \lambda$å¯¹wè¿›è¡Œæ”¾ç¼©ï¼Œä½¿wæ›´æ¥è¿‘0<br>æ­£åˆ™åŒ–åœ¨DLä¸­ä¹Ÿç§°ä¸ºweight decay</p><h3 id="L1æ­£åˆ™åŒ–"><a href="#L1æ­£åˆ™åŒ–" class="headerlink" title="L1æ­£åˆ™åŒ–"></a>L1æ­£åˆ™åŒ–</h3><p><img src="/images/2018-09-30-15382816962676.jpg" width="25%" height="50%"></p><p><img src="/images/2018-09-30-15382817122102.jpg" width="25%" height="50%"><br><img src="/images/2018-09-30-15382817409633.jpg" width="25%" height="50%"></p><p>åˆ™æ›´æ–°å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-30-15382817897319.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³æ¯æ¬¡ä»¥$Î·Î»sgn(w)$ ä½¿wå¾€0é ï¼ˆsgnè¡¨ç¤ºç¬¦å·å‡½æ•°ï¼‰</p><p>å¯ä»¥çœ‹å‡ºï¼ŒL1æ¯æ¬¡éƒ½åŠ å‡ç›¸åŒçš„å€¼ï¼Œè€ŒL2æŒ‰æ¯”ä¾‹è¿›è¡Œç¼©æ”¾ã€‚å› æ­¤L1æ›´ä¸ºç¨€ç–(sparse)ã€‚</p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>è®­ç»ƒçš„æ—¶å€™æ¯ä¸€å±‚é‡‡æ ·p%çš„ç¥ç»å…ƒè®¾ä¸º0ï¼Œè®©å…¶ä¸å·¥ä½œ<br><img src="/images/2018-09-30-15382819376579.jpg" width="50%" height="50%"></p><p>å®é™…ä¸Šå°±æ˜¯æ¯ä¸ªbatchæ”¹å˜äº†ç½‘ç»œç»“æ„ï¼Œä½¿å¾—ç½‘ç»œæ›´ç»†é•¿<br><img src="/images/2018-09-30-15382819772611.jpg" width="50%" height="50%"></p><p>æµ‹è¯•çš„æ—¶å€™æ‰€æœ‰çš„weightéƒ½ä¹˜ä»¥1-p%</p><p>ä»ensembleçš„è§’åº¦çœ‹å¾…dropoutï¼š<br>åœ¨è®­ç»ƒçš„æ—¶å€™è®­ç»ƒä¸€å †ä¸åŒç»“æ„çš„networkï¼Œæœ€å¤šæœ‰$2^N$ç§ç»„åˆï¼ŒNä¸ºneuronä¸ªæ•°ï¼Œå¯ä»¥ç§°ä¸ºç»ˆæçš„ensembleæ–¹æ³•äº†ã€‚è€Œåœ¨æµ‹è¯•çš„æ—¶å€™å¯¹è¿™äº›ä¸åŒçš„ç½‘ç»œè¿›è¡Œå¹³å‡ã€‚</p><p><img src="/images/2018-09-30-15382821089494.jpg" width="50%" height="50%"></p><p><img src="/images/2018-09-30-15382821379688.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Tips for DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>é‡‡æ ·æµ…æ</title>
      <link href="/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E9%87%87%E6%A0%B7%E6%B5%85%E6%9E%90/"/>
      <url>/2018/09/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/%E9%87%87%E6%A0%B7%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>æ€»ç»“åœ¨NLPä¸­çš„é‡‡æ ·æ–¹æ³•ï¼ˆæŒç»­æ›´æ–°ï¼‰ã€‚</p><h2 id="é‡‡æ ·æ–¹æ³•"><a href="#é‡‡æ ·æ–¹æ³•" class="headerlink" title="é‡‡æ ·æ–¹æ³•"></a>é‡‡æ ·æ–¹æ³•</h2><h3 id="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling"><a href="#1ï¸âƒ£é€†å˜æ¢é‡‡æ ·-Inverse-Sampling" class="headerlink" title="1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)"></a>1ï¸âƒ£é€†å˜æ¢é‡‡æ ·(Inverse Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥ä»»æ„æ¦‚ç‡åˆ†å¸ƒçš„<strong>ç´¯ç§¯åˆ†å¸ƒå‡½æ•°</strong>æ—¶ï¼Œç”¨äºä»è¯¥åˆ†å¸ƒä¸­ç”Ÿæˆéšæœºæ ·æœ¬ã€‚</p><p>â€”-ä»€ä¹ˆæ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°(CDF)â€”-<br>æ˜¯æ¦‚ç‡å¯†åº¦å‡½æ•°(PDF)çš„ç§¯åˆ†ï¼Œå®šä¹‰ï¼š</p><script type="math/tex; mode=display">F_X(x)=P(Xâ‰¤x)=\int_{-âˆ}^{x}f_X(t)dt</script><p>â€”-ENDâ€”-</p><p>æƒ³è±¡æˆ‘ä»¬çŸ¥é“é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•é‡‡æ ·ï¼Ÿæœ¬è´¨ä¸Šæˆ‘ä»¬åªèƒ½å¯¹å‡åŒ€åˆ†å¸ƒè¿›è¡Œç›´æ¥é‡‡æ ·ï¼ˆé«˜æ–¯åˆ†å¸ƒæœ‰<a href="https://www.zhihu.com/question/29971598" target="_blank" rel="noopener">ç®—æ³•</a>å¯ä»¥ç”Ÿæˆé‡‡æ ·ï¼Œä½†æ— æ³•ä¸€èˆ¬åŒ–ï¼‰ã€‚å¯¹äºè¿™ç§è¿ç»­çš„éšæœºå˜é‡ï¼Œæˆ‘ä»¬åªèƒ½é€šè¿‡é—´æ¥çš„æ–¹æ³•è¿›è¡Œé‡‡æ ·ã€‚</p><p>é€†å˜æ¢é‡‡æ ·å³æ˜¯é€šè¿‡ç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„åå‡½æ•°æ¥é‡‡æ ·ã€‚å› ä¸ºç´¯ç§¯åˆ†å¸ƒå‡½æ•°çš„å€¼åŸŸä¸º$[0,1]$ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡åœ¨$[0,1]$ä¸Šè¿›è¡Œé‡‡æ ·ï¼Œå†æ˜ å°„åˆ°åŸåˆ†å¸ƒã€‚<br>ä¾‹å­:<br><img src="/images/2018-09-30-15382714567064.jpg" width="80%" height="50%"><br>æ˜ å°„å…³ç³»å¦‚å›¾ï¼š<br><img src="/images/2018-09-30-15382715821631.jpg" width="50%" height="50%"></p><h3 id="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling"><a href="#2ï¸âƒ£é‡è¦æ€§é‡‡æ ·-Importance-Sampling" class="headerlink" title="2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)"></a>2ï¸âƒ£é‡è¦æ€§é‡‡æ ·(Importance Sampling)</h3><p>ç›®çš„ï¼šå·²çŸ¥æŸä¸ªåˆ†å¸ƒ$P$ï¼Œå¸Œæœ›èƒ½ä¼°è®¡$f(x)$çš„æœŸæœ›ã€‚äº¦å³ï¼š</p><script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)</script><p>å…¶ä¸­$x\sim p$ã€‚<br>å‡è®¾$p(x)$çš„åˆ†å¸ƒå¤æ‚æˆ–æ ·æœ¬ä¸å¥½ç”Ÿæˆï¼Œå¦ä¸€åˆ†å¸ƒ$q(x)$æ–¹ä¾¿ç”Ÿæˆæ ·æœ¬ã€‚å› æ­¤æˆ‘ä»¬å¼•å…¥$q(x)$å¯¹åŸå…ˆåˆ†å¸ƒè¿›è¡Œä¼°è®¡ã€‚</p><script type="math/tex; mode=display">E[f(x)]=\int_{x}f(x)p(x)dx=\int_{x}f(x)\frac{p(x)}{q(x)}q(x)dxâ‰ˆ\frac{1}{n}\sum_{i=1}^{n}f(x_i)\frac{p(x_i)}{q(x_i)}</script><p>å…¶ä¸­ï¼Œ$x \sim q$ã€‚$w(x)=\frac{p(x)}{q(x)}$ç§°ä¸ºImportance Weight</p><p>æ ¹æ®ä¸Šå¼ï¼Œå®é™…ä¸Šå°±æ˜¯æ¯æ¬¡é‡‡æ ·çš„åŠ æƒæ±‚å’Œã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>é€†å˜æ¢é‡‡æ ·<br><a href="https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E9%80%86%E5%8F%98%E6%8D%A2%E9%87%87%E6%A0%B7</a></p><p>é‡è¦æ€§é‡‡æ ·<br><a href="https://www.youtube.com/watch?v=S3LAOZxGcnk" target="_blank" rel="noopener">https://www.youtube.com/watch?v=S3LAOZxGcnk</a></p><p>â€”â€”æŒç»­æ›´æ–°â€”â€”</p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡‡æ · </tag>
            
            <tag> sampling </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†9</title>
      <link href="/2018/09/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%869/"/>
      <url>/2018/09/30/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%869/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>Pytorchä¸­ä¿å­˜checkpointæ˜¯ä¸€ä¸ªdictå½¢å¼ï¼Œå¯ä»¥ä¿å­˜ä»»æ„å¤šä¸ªæ¨¡å‹åˆ°ä¸€ä¸ªcheckpointä¸­ã€‚<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#save</span></span><br><span class="line">torch.save(&#123;            <span class="string">'epoch'</span>: epoch,            <span class="string">'model_state_dict'</span>: model.state_dict(),            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),            <span class="string">'loss'</span>: loss,            ...            &#125;, PATH)</span><br><span class="line"><span class="comment">#load</span></span><br><span class="line">model = TheModelClass(*args, **kwargs)optimizer = TheOptimizerClass(*args, **kwargs)</span><br><span class="line">checkpoint = torch.load(PATH)model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])epoch = checkpoint[<span class="string">'epoch'</span>]loss = checkpoint[<span class="string">'loss'</span>]</span><br><span class="line">model.eval()<span class="comment"># - or -</span>model.train()</span><br></pre></td></tr></table></figure></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>Pytorchå¯ä»¥loadéƒ¨åˆ†æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯åªloadè¿›æ¥éƒ¨åˆ†æˆ‘ä»¬éœ€è¦çš„å±‚ï¼Œè¿™åœ¨transfer learningä¸­ç”¨åˆ°ã€‚<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">torch.save(modelA.state_dict(), PATH)</span><br><span class="line">modelB = TheModelBClass(*args, **kwargs)modelB.load_state_dict(torch.load(PATH), strict=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>no title</title>
      <link href="/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%9C%89%E5%8A%9B%E9%87%8F%E7%9A%84%E6%96%87%E5%AD%97/"/>
      <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%9C%89%E5%8A%9B%E9%87%8F%E7%9A%84%E6%96%87%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<p>æ¯å½“æˆ‘é‡åˆ°è‡ªå·±ä¸æ•¢ç›´è§†çš„å›°éš¾æ—¶ï¼Œæˆ‘å°±ä¼šé—­ä¸ŠåŒçœ¼ï¼Œæƒ³è±¡è‡ªå·±æ˜¯ä¸€ä¸ª80å²çš„è€äººï¼Œä¸ºäººç”Ÿä¸­æ›¾æ”¾å¼ƒå’Œé€ƒé¿è¿‡çš„æ— æ•°å›°éš¾è€Œæ‡Šæ‚”ä¸å·²ï¼Œæˆ‘ä¼šå¯¹è‡ªå·±è¯´ï¼Œèƒ½å†å¹´è½»ä¸€æ¬¡è¯¥æœ‰å¤šå¥½ï¼Œç„¶åæˆ‘çå¼€çœ¼ç›ï¼šç °ï¼æˆ‘åˆå¹´è½»ä¸€æ¬¡äº†ï¼</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯10</title>
      <link href="/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D10/"/>
      <url>/2018/09/30/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D10/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"><a href="#1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹" class="headerlink" title="1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹"></a>1ï¸âƒ£æ¬¡åŒ—å›ºå±±ä¸‹</h3><p>[å”] ç‹æ¹¾<br>å®¢è·¯é’å±±å¤–ï¼Œè¡ŒèˆŸç»¿æ°´å‰ã€‚<br>æ½®å¹³ä¸¤å²¸é˜”ï¼Œé£æ­£ä¸€å¸†æ‚¬ã€‚<br><strong>æµ·æ—¥ç”Ÿæ®‹å¤œï¼Œæ±Ÿæ˜¥å…¥æ—§å¹´ã€‚</strong><br>ä¹¡ä¹¦ä½•å¤„è¾¾ï¼Œå½’é›æ´›é˜³è¾¹ã€‚</p><p>æ¬¡ï¼šæ—…é€”ä¸­æš‚æ—¶åœå®¿ï¼Œè¿™é‡Œæ˜¯åœæ³Šçš„æ„æ€ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b95de92e958a005fa8919e</a></p><hr><h3 id="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"><a href="#2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ" class="headerlink" title="2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ"></a>2ï¸âƒ£å°†èµ´å´å…´ç™»ä¹æ¸¸åŸ</h3><p>[å”] æœç‰§<br>æ¸…æ—¶æœ‰å‘³æ˜¯æ— èƒ½ï¼Œé—²çˆ±å­¤äº‘é™çˆ±åƒ§ã€‚<br><strong>æ¬²æŠŠä¸€éº¾æ±Ÿæµ·å»ï¼Œä¹æ¸¸åŸä¸Šæœ›æ˜­é™µã€‚</strong></p><p>æ— èƒ½ï¼šæ— æ‰€ä½œä¸ºã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b99db9165abd005a6da742" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b99db9165abd005a6da742</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PRMLç¬¬ä¸€ç«  ç»ªè®º</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/PRML%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p>è®°å½•PRMLå­¦ä¹ è¿‡ç¨‹ã€‚<br>ç¬”è®°å…±äº«é“¾æ¥ï¼š<a href="https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg" target="_blank" rel="noopener">https://1drv.ms/u/s!Apsp2510NHF6rIRjMclFB16v7B0FWg</a></p><hr><h1 id="æ¦‚ç‡è®º"><a href="#æ¦‚ç‡è®º" class="headerlink" title="æ¦‚ç‡è®º"></a>æ¦‚ç‡è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-27-21.jpg" alt="æ¦‚ç‡è®º"></p><h1 id="å†³ç­–è®º"><a href="#å†³ç­–è®º" class="headerlink" title="å†³ç­–è®º"></a>å†³ç­–è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-36-52.jpg" alt="å†³ç­–è®º"></p><h1 id="ä¿¡æ¯è®º"><a href="#ä¿¡æ¯è®º" class="headerlink" title="ä¿¡æ¯è®º"></a>ä¿¡æ¯è®º</h1><p><img src="/images/2018-09-23-Xnip2018-09-23_10-38-46.jpg" alt="ä¿¡æ¯è®º"></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> PRML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 6:Backpropagation</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%206:%20Backpropagation/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%206:%20Backpropagation/</url>
      
        <content type="html"><![CDATA[<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><p>åŸºæœ¬å…¬å¼<br><img src="/images/2018-09-23-15376684598125.jpg" width="50%" height="50%"><br><img src="/images/2018-09-23-15376684674095.jpg" width="50%" height="50%"></p><h3 id="forward-passå’Œbackward-pass"><a href="#forward-passå’Œbackward-pass" class="headerlink" title="forward passå’Œbackward pass"></a>forward passå’Œbackward pass</h3><p>å¯ä»¥å°†backpropagationåˆ†ä¸ºä¸¤æ­¥</p><h4 id="forward-pass"><a href="#forward-pass" class="headerlink" title="forward pass"></a>forward pass</h4><p>åœ¨å‰å‘ä¼ æ’­çš„æ—¶å€™æå‰è®¡ç®—/ä¿å­˜å¥½ï¼Œå› ä¸ºè¯¥æ¢¯åº¦å¾ˆç®€å•<br><img src="/images/2018-09-23-15376686358832.jpg" width="50%" height="50%"></p><p>æ¯”å¦‚zå¯¹w1çš„æ¢¯åº¦å°±æ˜¯x1ï¼Œå°±æ˜¯å’Œw1ç›¸è¿çš„é¡¹<br><img src="/images/2018-09-23-15376687025289.jpg" width="20%" height="50%"></p><h4 id="backward-pass"><a href="#backward-pass" class="headerlink" title="backward pass"></a>backward pass</h4><p>å›ä¼ çš„æ—¶å€™é€å±‚ç›¸ä¹˜ä¸‹å»ï¼Œç±»ä¼¼åŠ¨æ€è§„åˆ’ï¼Œè·å¾—äº†åä¸€å±‚çš„æ¢¯åº¦æ‰èƒ½æ±‚å‡ºå‰ä¸€å±‚çš„æ¢¯åº¦ã€‚<br><img src="/images/2018-09-23-15376687488493.jpg" width="50%" height="50%"></p><h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><p><img src="/images/2018-09-23-15376687824826.jpg" width="50%" height="50%"></p><p>å…ˆå‰å‘ï¼Œæå‰ç®—å‡ºæœ€é‚»è¿‘çš„æ¢¯åº¦ï¼Œç›´åˆ°output layerï¼Œè®¡ç®—å®Œè¯¥æ¢¯åº¦ï¼Œå†ä¸æ–­å›ä¼ é€å±‚ç›¸ä¹˜è·å¾—outputå¯¹å„å±‚çš„æ¢¯åº¦ã€‚</p><h3 id="ä»£ç å®ç°ä¾‹å­"><a href="#ä»£ç å®ç°ä¾‹å­" class="headerlink" title="ä»£ç å®ç°ä¾‹å­"></a>ä»£ç å®ç°ä¾‹å­</h3><p>reluå®ç°forward passå’Œbackward pass<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Backpropagation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 5:Classification:Logistic Regression</title>
      <link href="/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%205%20Classification:%20Logistic%20Regression/"/>
      <url>/2018/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%205%20Classification:%20Logistic%20Regression/</url>
      
        <content type="html"><![CDATA[<h3 id="logistic-regressionå¦‚ä½•åšï¼Ÿ"><a href="#logistic-regressionå¦‚ä½•åšï¼Ÿ" class="headerlink" title="logistic regressionå¦‚ä½•åšï¼Ÿ"></a>logistic regressionå¦‚ä½•åšï¼Ÿ</h3><p>step1: å®šä¹‰function set<br><img src="/images/2018-09-23-15376666391912.jpg" width="30%" height="50%"></p><p>step2: æ›´æ–°<br>ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ›´æ–°</p><script type="math/tex; mode=display">L(w,b)=f_{w,b}(x^1 )f_{w,b}(x^2 )(1âˆ’f_{w,b} (x^3 ))â‹¯f_{w,b} (x^N )</script><p>æ‰¾åˆ°wï¼Œbä½¿å¾—Læœ€å¤§</p><p>å¯¹ä¼¼ç„¶å‡½æ•°å–è´Ÿå¯¹æ•°ï¼Œåˆ™æœ‰ï¼š<br><img src="/images/2018-09-23-15376667791380.jpg" width="60%" height="50%"></p><p>å°†å¼å­çš„æ¯ä¸ªå…ƒç´ å†™æˆä¼¯åŠªåˆ©åˆ†å¸ƒå½¢å¼ï¼š<br><img src="/images/2018-09-23-15376669013511.jpg" width="60%" height="50%"></p><p>ä¸Šå¼å°±æ˜¯cross-entropyæŸå¤±å‡½æ•°ã€‚</p><p>æ±‚å¯¼è¯¥å¼å­å¯å¾—ï¼š<br><img src="/images/2018-09-23-15376669743224.jpg" width="30%" height="50%"><br>æ›´æ–°å…¬å¼ï¼š<br><img src="/images/2018-09-23-15376669980138.jpg" width="40%" height="50%"><br>å¯ä»¥çœ‹å‡ºä¸Šå¼å¾ˆç›´è§‚ï¼šå’Œç­”æ¡ˆå·®è·è¶Šå¤§ï¼Œæ›´æ–°æ­¥ä¼è¶Šå¤§ã€‚</p><p>åŒæ—¶å‘ç°ä¸Šå¼å’Œlinear regressionçš„æ›´æ–°å…¬å¼æ˜¯ä¸€è‡´çš„ã€‚</p><h3 id="ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸åƒlinear-regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸åƒlinear regressioné‚£æ ·è®¾lossä¸ºsquareï¼Ÿ</h3><p>å‡è®¾æˆ‘ä»¬ä½¿ç”¨square lossï¼Œåˆ™æ±‚å¯¼å¾—åˆ°çš„æ¢¯åº¦ï¼š<br><img src="/images/2018-09-23-15376671202521.jpg" width="50%" height="50%"><br>ä¸Šå¼å¯ä»¥çœ‹å‡ºï¼Œå½“æ¥è¿‘targetæ—¶ï¼Œæ¢¯åº¦å°ï¼›è¿œç¦»targetæ—¶ï¼Œæ¢¯åº¦ä¹Ÿå°ã€‚éš¾ä»¥è¾¾åˆ°å…¨å±€æœ€å°<br><img src="/images/2018-09-23-15376672527230.jpg" width="60%" height="50%"></p><p>ä¸‹å›¾æ˜¯cross entropyå’Œsquare errorçš„å›¾åƒç¤ºæ„ï¼š<br><img src="/images/2018-09-23-15376672892502.jpg" width="60%" height="50%"></p><p>å¦‚å›¾ï¼Œsquare losséš¾ä»¥åˆ°è¾¾å…¨å±€æœ€å°ã€‚</p><h3 id="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"><a href="#ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«" class="headerlink" title="ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«"></a>ç”Ÿæˆå¼æ¨¡å‹ä¸åˆ¤åˆ«å¼æ¨¡å‹çš„åŒºåˆ«</h3><p>ç”Ÿæˆå¼å¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œå†é€šè¿‡è´å¶æ–¯å®šç†è·å¾—åéªŒæ¦‚ç‡ï¼›è€Œåˆ¤åˆ«å¼æ¨¡å‹ç›´æ¥å¯¹åéªŒæ¦‚ç‡å»ºæ¨¡ã€‚<br><img src="/images/2018-09-23-15376674213503.jpg" width="60%" height="50%"><br>äºŒè€…æ‰€å®šä¹‰çš„function setæ˜¯ä¸€è‡´çš„ï¼Œä½†åŒä¸€ç»„æ•°æ®å¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„wå’Œbã€‚</p><p>äºŒè€…ä¼˜åŠ£å¯¹æ¯”ï¼š</p><ul><li>æ•°æ®é‡å¤šæ—¶ï¼Œä¸€èˆ¬æ¥è¯´åˆ¤åˆ«å¼æ¨¡å‹ä¼šæ›´å¥½ã€‚å› ä¸ºåˆ¤åˆ«å¼æ¨¡å‹æ²¡æœ‰å…ˆéªŒå‡è®¾ï¼Œå®Œå…¨ä¾èµ–äºæ•°æ®ã€‚ä½†å¦‚æœæ•°æ®æœ‰å™ªå£°ï¼Œå®¹æ˜“å—å½±å“ã€‚</li><li>ç”Ÿæˆå¼æ¨¡å‹æ˜¯æœ‰ä¸€å®šçš„å‡è®¾çš„ï¼Œå½“å‡è®¾é”™è¯¯ï¼Œä¼šå½±å“åˆ†ç±»æ•ˆæœã€‚</li><li>æ­£å› ä¸ºæœ‰ä¸€å®šçš„å…ˆéªŒå‡è®¾ï¼Œå½“æ•°æ®é‡å¾ˆå°‘æ—¶ï¼Œå¯èƒ½æ•ˆæœä¼šä¸é”™ï¼›å¯¹äºå™ªå£°æ›´å…·æœ‰é²æ£’æ€§ã€‚</li><li>å…ˆéªŒå¯ä»¥ä»å…¶ä»–æ•°æ®æºè·å¾—æ¥å¸®åŠ©ç‰¹å®šä»»åŠ¡ï¼Œå¦‚è¯­éŸ³è¯†åˆ«é—®é¢˜ã€‚</li></ul><h3 id="logisticçš„å±€é™"><a href="#logisticçš„å±€é™" class="headerlink" title="logisticçš„å±€é™"></a>logisticçš„å±€é™</h3><p>æœ¬è´¨ä»æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ²¡åŠæ³•åˆ†ç±»éçº¿æ€§çš„æ•°æ®ã€‚<br>å¦‚ä½•è§£å†³è¯¥é—®é¢˜?<br><strong>å°†logistic regression modelæ‹¼æ¥èµ·æ¥</strong>ï¼Œå‰é¢çš„modelå¯¹æ•°æ®è¿›è¡Œfeature transformationï¼Œç„¶åå†å¯¹æ–°çš„featureè¿›è¡Œåˆ†ç±»ã€‚<br><img src="/images/2018-09-23-15376677559470.jpg" width="70%" height="50%"></p><p>logisticä¸deep learningçš„è”ç³»ï¼š<br>å¦‚æœå°†logistic regressionçš„ä¸€ä¸ªå•å…ƒç§°ä¸ºneuronï¼Œæ‹¼èµ·æ¥å°±æ˜¯neural networkäº†ï¼ï¼ï¼</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Classification </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†8</title>
      <link href="/2018/09/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%868/"/>
      <url>/2018/09/23/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%868/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>torch.max()æœ‰ä¸¤ç§ä¸åŒå†™æ³•ã€‚<br>torch.max(input) â†’ Tensor è¿”å›å…¶ä¸­æœ€å¤§çš„å…ƒç´ <br>torch.max(input, dim, keepdim=False, out=None) â†’ (Tensor, LongTensor) è¿”å›è¯¥ç»´åº¦ä¸Šæœ€å¤§å€¼ï¼Œä»¥åŠå¯¹åº”çš„index</p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>å°†æ¨¡å‹åŒæ—¶éƒ¨ç½²åˆ°å¤šå¼ å¡ä¸Šè®­ç»ƒï¼Œæœ¬è´¨å°±æ˜¯å°†ä¸€ä¸ªbatchçš„æ•°æ®splitï¼Œé€åˆ°å„ä¸ªmodelï¼Œç„¶ååˆå¹¶ç»“æœã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£-æ±‚å¯¼"><a href="#3ï¸âƒ£-æ±‚å¯¼" class="headerlink" title="3ï¸âƒ£[æ±‚å¯¼]"></a>3ï¸âƒ£[æ±‚å¯¼]</h3><p>æ ‡é‡ã€å‘é‡ã€çŸ©é˜µä¹‹é—´çš„æ±‚å¯¼æœ‰ä¸¤ç§å¸ƒå±€ï¼Œå³åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€ã€‚åˆ†å­å¸ƒå±€å’Œåˆ†æ¯å¸ƒå±€åªå·®ä¸€ä¸ªè½¬ç½®ã€‚<br>æˆ‘çš„è®°æ³•ï¼šåœ¨æ±‚å¯¼è¿‡ç¨‹ä¸­ï¼Œå‡è®¾åˆ†æ¯ä¸ºm*nï¼Œåˆ†å­ä¸º k*nï¼Œåˆ™å¯¼æ•°çŸ©é˜µåº”è¯¥ä¸º k*m ã€‚ä¸€äº›ç‰¹æ®Šçš„å¦‚æ ‡é‡å¯¹çŸ©é˜µæ±‚å¯¼ç­‰é™¤å¤–ã€‚<br>å…·ä½“ç›´æ¥æŸ¥è¡¨ï¼š<a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a></p><p>æŒ‰ä½è®¡ç®—æ±‚å¯¼ï¼š<br>å‡è®¾ä¸€ä¸ªå‡½æ•°$f(x)$çš„è¾“å…¥æ˜¯æ ‡é‡$x$ã€‚å¯¹äºä¸€ç»„Kä¸ªæ ‡é‡$x_1,Â·Â·Â· ,x_K$ï¼Œæˆ‘ä»¬<br>å¯ä»¥é€šè¿‡$f(x)$å¾—åˆ°å¦å¤–ä¸€ç»„Kä¸ªæ ‡é‡$z_1,Â·Â·Â· ,z_K$ï¼Œ<br>$z_k = f(x_k),âˆ€k = 1,Â·Â·Â· ,K$<br>å…¶ä¸­ï¼Œ$f(x)$æ˜¯æŒ‰ä½è¿ç®—çš„ï¼Œå³$[f(x)]_i = f(x_i)$<br>å…¶å¯¼æ•°æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼š<br><img src="/images/2018-09-23-15376727095200.jpg" width="50%" height="50%"></p><p><strong>Reference</strong>ï¼š<br><a href="https://en.m.wikipedia.org/wiki/Matrix_calculus" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/Matrix_calculus</a><br><a href="https://blog.csdn.net/uncle_gy/article/details/78879131" target="_blank" rel="noopener">https://blog.csdn.net/uncle_gy/article/details/78879131</a><br><a href="https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf" target="_blank" rel="noopener">https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> æ±‚å¯¼ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•7</title>
      <link href="/2018/09/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%957/"/>
      <url>/2018/09/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%957/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£softmaxçš„numpyå®ç°"><a href="#1ï¸âƒ£softmaxçš„numpyå®ç°" class="headerlink" title="1ï¸âƒ£softmaxçš„numpyå®ç°"></a>1ï¸âƒ£softmaxçš„numpyå®ç°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x,axis=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Compute softmax values for each sets of scores in x."""</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / np.sum(np.exp(x), axis=axis)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu"><a href="#2ï¸âƒ£numpy-æ‰‹åŠ¨æ±‚å¯¼relu" class="headerlink" title="2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu"></a>2ï¸âƒ£numpy æ‰‹åŠ¨æ±‚å¯¼relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># N is batch size; D_in is input dimension;</span></span><br><span class="line"><span class="comment"># H is hidden dimension; D_out is output dimension.</span></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create random input and output data</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly initialize weights</span></span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y</span></span><br><span class="line">    h = x.dot(w1)</span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>)</span><br><span class="line">    y_pred = h_relu.dot(w2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss</span></span><br><span class="line">    loss = np.square(y_pred - y).sum()</span><br><span class="line">    print(t, loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backprop to compute gradients of w1 and w2 with respect to loss</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure><hr><h3 id="3ï¸âƒ£Pytorchå®ç°relu"><a href="#3ï¸âƒ£Pytorchå®ç°relu" class="headerlink" title="3ï¸âƒ£Pytorchå®ç°relu"></a>3ï¸âƒ£Pytorchå®ç°relu</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReLU</span><span class="params">(torch.autograd.Function)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    We can implement our own custom autograd Functions by subclassing</span></span><br><span class="line"><span class="string">    torch.autograd.Function and implementing the forward and backward passes</span></span><br><span class="line"><span class="string">    which operate on Tensors.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, input)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the forward pass we receive a Tensor containing the input and return</span></span><br><span class="line"><span class="string">        a Tensor containing the output. ctx is a context object that can be used</span></span><br><span class="line"><span class="string">        to stash information for backward computation. You can cache arbitrary</span></span><br><span class="line"><span class="string">        objects for use in the backward pass using the ctx.save_for_backward method.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        ctx.save_for_backward(input)  <span class="comment">#ä¸ºäº†ä¹‹åçš„backwardè®¡ç®—</span></span><br><span class="line">        <span class="keyword">return</span> input.clamp(min=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, grad_output)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        In the backward pass we receive a Tensor containing the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the output, and we need to compute the gradient of the loss</span></span><br><span class="line"><span class="string">        with respect to the input.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        input, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[input &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"><a href="#4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²" class="headerlink" title="4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²"></a>4ï¸âƒ£Pytorchåœ¨å¤šå¼ å¡ä¸Šéƒ¨ç½²</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = nn.DataParallel(model)</span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    input = data.to(device)</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¬è¾¾è§‚æ¯ç°åœºç­”è¾©æœ‰æ„Ÿ</title>
      <link href="/2018/09/19/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E5%90%AC%E8%BE%BE%E8%A7%82%E6%9D%AF%E7%8E%B0%E5%9C%BA%E7%AD%94%E8%BE%A9%E6%9C%89%E6%84%9F/"/>
      <url>/2018/09/19/%E8%A7%81%E9%97%BB&amp;%E6%83%B3%E6%B3%95/%E5%90%AC%E8%BE%BE%E8%A7%82%E6%9D%AF%E7%8E%B0%E5%9C%BA%E7%AD%94%E8%BE%A9%E6%9C%89%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ æ—¥ï¼ˆå‘¨æ—¥ï¼‰å»äº†è¾¾è§‚æ¯ç­”è¾©ç°åœºå¬äº†å‰10ååšäº†æŠ¥å‘Šï¼Œæœ‰äº†ä¸€äº›æ„Ÿæƒ³ï¼Œä½†ä¸€ç›´æ²¡æœ‰æŠ½å‡ºæ—¶é—´å†™ä¸€ä¸‹è‡ªå·±çš„æ„Ÿæƒ³ï¼ˆæ‡’ï¼‰ã€‚</p><p>è‡ªå·±å¤§æ¦‚èŠ±äº†åæ¥å¤©åšäº†ä¸€ä¸‹æ¯”èµ›ï¼Œå®é™…ä¸Šä¹Ÿå°±æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»çš„<a href="http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html" target="_blank" rel="noopener">æ¯”èµ›</a>ï¼Œå› ä¸ºæ²¡æœ‰æ¯”èµ›ç»éªŒçš„ç¼˜æ•…ï¼Œèµ°äº†å¾ˆå¤šå¼¯è·¯ã€‚ä¸è¿‡ä¹Ÿå­¦åˆ°äº†ä¸€äº›ä¸œè¥¿ã€‚</p><p>ç°è®°å½•å‰ååçš„ä¸€äº›idea/trickï¼š</p><ul><li>æ•°æ®å¢å¼º<ul><li>å› ä¸ºç»™çš„å¥å­é•¿åº¦å¾ˆé•¿ï¼Œå› æ­¤åœ¨åšæˆªæ–­çš„æ—¶å€™åé¢çš„å°±æ²¡æ³•è®­ç»ƒåˆ°äº†ï¼Œå¯ä»¥å°†æ–‡æœ¬å€’åºä½œä¸ºæ–°çš„æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚å¯ä»¥å……åˆ†åˆ©ç”¨åˆ°æ•°æ®</li><li>å°†æ•°æ®æ‰“ä¹±ã€éšæœºåˆ é™¤ï¼Œå®é™…ä¸Šå°±æ˜¯å¯¹ä¸€ä¸ªå¥å­çš„è¯è¿›è¡Œsampleå†ç»„åˆ</li><li>æ‰“ä¹±è¯åºä»¥å¢åŠ æ•°æ®é‡</li><li>ä½¿ç”¨pseudo labelingï¼Œä½†æœ‰çš„é˜Ÿä¼ä½¿ç”¨è¿™ä¸ªåšå‡ºæ•ˆæœäº†ï¼Œä½†æœ‰çš„æ²¡æœ‰</li></ul></li><li>ç‰¹å¾å·¥ç¨‹<ul><li>å‡è®¾å¼€å¤´ä¸­é—´ç»“å°¾çš„ä¿¡æ¯å¯¹åˆ†ç±»æœ‰å¸®åŠ©ï¼Œå› æ­¤æˆªå–è¯¥éƒ¨åˆ†ä¿¡æ¯åšè®­ç»ƒ</li><li>æ”¹è¿›baselineçš„tfidfçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºç†µçš„è¯æƒé‡è®¡ç®—</li><li>é™ç»´ï¼Œç•™ä¸‹æœ€é‡è¦çš„ç‰¹å¾ã€‚å…ˆç”¨å¡æ–¹åˆ†å¸ƒé™åˆ°20ä¸‡ï¼Œå†ç”¨SVDé™åˆ°8000</li><li>å°†word2vecå’ŒGloVeæ‹¼æ¥èµ·æ¥ä½œä¸ºdeep learningæ¨¡å‹çš„è¾“å…¥</li><li>å°†æ–‡ç« åˆ†æ®µï¼Œæ¯æ®µå–å‰20å20æ‹¼èµ·æ¥</li></ul></li><li>æ¨¡å‹èåˆ<br>  æ‰€æœ‰é˜Ÿä¼éƒ½æ— ä¸€ä¾‹å¤–ä½¿ç”¨äº†æ¨¡å‹èåˆï¼Œstackingæˆ–è€…ç®€å•çš„æŠ•ç¥¨<ul><li>DL+ML â€”&gt; lgbm model â€”&gt; voting</li><li>æ·±åº¦æ¨¡å‹+ä¼ ç»Ÿæ¨¡å‹ï¼Œåœ¨æ·±åº¦æ¨¡å‹æœ€åä¸€å±‚åŠ å…¥ä¼ ç»Ÿæ¨¡å‹çš„ä¿¡æ¯/feature</li><li>åå‘é€‰æ‹©å‰”é™¤å†—ä½™æ¨¡å‹</li></ul></li><li>DL&amp;å…¶ä»–<ul><li>HANï¼Œé€‰æ‹©10ä¸ªattention vector</li><li>å¯¹æ˜“é”™ç±»å¢åŠ æƒé‡ï¼Œé€šè¿‡æ”¹å˜æŸå¤±å‡½æ•°æ¥å¢åŠ æƒé‡</li><li>CNN, [1,2,3,4,5,6]*600</li><li>æå‡ºæ–°çš„æ¨¡å‹ï¼ˆç¬¬ä¸€åï¼‰</li></ul></li></ul><p>å…¶å®é™¤äº†ä¸€äº›trickï¼Œæˆ‘è¿˜æ˜¯æœ‰äº›å¤±æœ›çš„ï¼Œå› ä¸ºéƒ½æ˜¯ç”¨æ¨¡å‹èåˆå †å‡ºæ¥çš„ï¼Œè¿™ä¹Ÿè®©æˆ‘å¯¹æ¯”èµ›å¤±å»äº†ä¸€äº›å…´è¶£ã€‚è™½ç„¶èƒ½ç†è§£ç°åœ¨çš„æ¯”èµ›éƒ½æ˜¯è¿™æ ·çš„ï¼Œä½†æ„Ÿè§‰å®åœ¨å¤ªæš´åŠ›äº†ã€‚<br>å½“ç„¶ï¼Œå…¶ä¸­è¿˜æ˜¯æœ‰ä¸€äº›äº®ç‚¹çš„ï¼Œæœ‰ä¸€æ”¯é˜Ÿä¼ç«‹æ„å¾ˆé«˜ï¼Œä»ç†è§£ä¸šåŠ¡çš„è§’åº¦å‡ºå‘è€Œä¸æ˜¯å †æ¨¡å‹ï¼Œä¹Ÿå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼›è¿˜æœ‰ä¸€ä¸ªä½¿ç”¨äº†æœ€æ–°è®ºæ–‡ä¸­çš„ç‰¹å¾å·¥ç¨‹æ”¹è¿›æ–¹æ³•ï¼Œä»¤æˆ‘è€³ç›®ä¸€æ–°ï¼›ä»¥åŠç¬¬ä¸€ååœ¨æ¯”èµ›è¿‡ç¨‹ä¸­æå‡ºæ¥ä¸‰ä¸ªæ–°çš„æ¨¡å‹ã€‚</p><p>Anywayï¼Œæˆ‘ç›®å‰è¿˜æ˜¯å¤ªèœäº†ï¼Œè¿˜æ˜¯å®‰å¿ƒæç§‘ç ”å§ã€‚_(:Ğ·ã€âˆ )</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœ‰æ„Ÿ </tag>
            
            <tag> æ¯”èµ› </tag>
            
            <tag> è¾¾è§‚æ¯ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†7</title>
      <link href="/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%867/"/>
      <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%867/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-Pytorch"><a href="#1ï¸âƒ£-Pytorch" class="headerlink" title="1ï¸âƒ£[Pytorch]"></a>1ï¸âƒ£[Pytorch]</h3><p>åªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œå¯ç”¨.item()æ¥è·å–å…ƒç´ </p><p>tensor &lt;â€”&gt; numpy ç›¸äº’è½¬åŒ–ä¼šå…±äº«å†…éƒ¨æ•°æ®ï¼Œå› æ­¤æ”¹å˜å…¶ä¸­ä¸€ä¸ªä¼šæ”¹å˜å¦ä¸€ä¸ª</p><p>å¯ç”¨ä½¿ç”¨ .to æ¥ç§»åŠ¨åˆ°è®¾å¤‡<br><img src="/images/2018-09-16-15370671350548.jpg" alt=""></p><p>.detech()  detach it from the computation history, and to prevent future computation from being tracked. å°†å…¶ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œå˜ä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”requires_grad=False</p><p>Function è®°å½•äº†è¿™ä¸ªtensoræ˜¯æ€ä¹ˆæ¥çš„ï¼Œæ‰€æœ‰çš„tensoréƒ½æœ‰ï¼Œé™¤éæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„ï¼š<br><img src="/images/2018-09-16-15370672806253.jpg" width="65%" height="50%"></p><hr><h3 id="2ï¸âƒ£-åæ–¹å·®"><a href="#2ï¸âƒ£-åæ–¹å·®" class="headerlink" title="2ï¸âƒ£[åæ–¹å·®]"></a>2ï¸âƒ£[åæ–¹å·®]</h3><p>å…³äºåæ–¹å·®çš„ç†è§£ï¼Œxä¸yå…³äºæŸä¸ªè‡ªå˜é‡çš„å˜åŒ–ç¨‹åº¦ï¼Œå³åº¦é‡äº†xä¸yä¹‹é—´çš„è”ç³»ã€‚<br><a href="https://www.zhihu.com/question/20852004" target="_blank" rel="noopener">https://www.zhihu.com/question/20852004</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> åæ–¹å·® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 4:Classification:Probabilistic Generative Model</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%204%20Classification%20%20Probabilistic%20Generative%20Model/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%204%20Classification%20%20Probabilistic%20Generative%20Model/</url>
      
        <content type="html"><![CDATA[<h3 id="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ"></a>ä¸ºä»€ä¹ˆä¸ä½¿ç”¨regressionæ¥åˆ†ç±»ï¼Ÿ</h3><p>1ï¸âƒ£å¦‚æœä½¿ç”¨regressionçš„æ€æƒ³æ¥åˆ†ç±»ï¼Œä¼šå¯¹ç¦»è¾¹ç•Œè¾ƒè¿œçš„ç‚¹è¿›è¡Œæƒ©ç½šï¼š<br><img src="/images/2018-09-16-15370662150910.jpg" width="70%" height="50%"></p><p>2ï¸âƒ£å¦‚æœå¤šåˆ†ç±»ä½¿ç”¨regressionï¼Œå¦‚class 1, class 2, class 3ï¼›åˆ™éšå¼åœ°å‡è®¾äº†class 1 å’Œ class 2è¾ƒä¸ºæ¥è¿‘ï¼Œå¦‚æœæ²¡æœ‰è¿™ç§æ¥è¿‘å…³ç³»ï¼Œåˆ™åˆ†ç±»ä¼šä¸æ­£ç¡®ã€‚</p><h3 id="é—®é¢˜æè¿°ä¸å®šä¹‰"><a href="#é—®é¢˜æè¿°ä¸å®šä¹‰" class="headerlink" title="é—®é¢˜æè¿°ä¸å®šä¹‰"></a>é—®é¢˜æè¿°ä¸å®šä¹‰</h3><p><img src="/images/2018-09-16-15370662762802.jpg" width="70%" height="50%"></p><p>å½“På¤§äº0.5åˆ™æ˜¯C1ç±»ï¼Œåä¹‹æ˜¯C2ç±»<br>å…ˆéªŒP(C1)å’ŒP(C2)éƒ½å¥½è®¡ç®—ï¼Œè®¡ç®—C1å æ€»çš„æ¯”ä¾‹å³å¯<br>å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—çš„å°±æ˜¯p(x|C)</p><p>è¿™ä¸€æƒ³æ³•ï¼Œæœ¬è´¨æ˜¯å¾—åˆ°äº†ç”Ÿæˆå¼æ¨¡å‹ï¼š<br><img src="/images/2018-09-16-15370663099515.jpg" width="70%" height="50%"></p><h3 id="åŸç†æ¦‚è¿°"><a href="#åŸç†æ¦‚è¿°" class="headerlink" title="åŸç†æ¦‚è¿°"></a>åŸç†æ¦‚è¿°</h3><p>ç°<strong>å‡è®¾è®­ç»ƒæ•°æ®ç‚¹çš„åˆ†å¸ƒæœä»é«˜æ–¯åˆ†å¸ƒ</strong>ï¼šï¼ˆæ˜¾ç„¶å¯ä»¥è‡ªå·±è®¾ä»»ä½•åˆ†å¸ƒï¼‰<br>å³æ•°æ®ä»é«˜æ–¯åˆ†å¸ƒé‡‡æ ·å¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370663870205.jpg" width="55%" height="50%"></p><p>æ ¹æ®æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå¯ä»¥è·å¾—æ¯ä¸ªç±»åˆ«çš„Î¼å’ŒÎ£ï¼š<br><img src="/images/2018-09-16-15370664041246.jpg" width="70%" height="50%"></p><p>å¾—åˆ°äº†å‚æ•°åï¼Œå³å¯ä»£å…¥å¾—åˆ°P(C|x) ï¼š<br><img src="/images/2018-09-16-15370664355955.jpg" width="80%" height="50%"></p><p>åˆšåˆšå‡è®¾$Î£$å¯¹äºä¸åŒç±»åˆ«ä¸åŒï¼Œç°æˆ‘ä»¬<strong>ä»¤ä¸åŒç±»åˆ«å…±äº«ç›¸åŒ$Î£$</strong>ï¼š<br>ï¼ˆå› ä¸ºåæ–¹å·®ä»£è¡¨çš„æ˜¯ä¸åŒfeatureä¹‹é—´çš„è”ç³»ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯å’Œç±»åˆ«æ— å…³çš„ï¼‰</p><p>$Î£$çš„è®¡ç®—å…¬å¼æ˜¯åŠ æƒæ±‚å’Œï¼š<br><img src="/images/2018-09-16-15370665362081.jpg" width="24%" height="50%"></p><p>åœ¨ä½¿ç”¨äº†ç›¸åŒçš„åæ–¹å·®çŸ©é˜µåï¼Œè¾¹ç•Œå°±æ˜¯çº¿æ€§çš„ï¼ˆåé¢ä¼šæåˆ°ä¸ºä»€ä¹ˆæ˜¯è¿™æ ·ï¼‰ï¼š<br><img src="/images/2018-09-16-15370665553962.jpg" alt=""></p><p> æ€»ç»“ï¼š<br> ä¸‰æ­¥èµ°ï¼Œå®šä¹‰function setï¼Œè®¡ç®—Î¼å’Œåæ–¹å·®çŸ©é˜µï¼Œå¾—åˆ°best functionï¼š<br><img src="/images/2018-09-16-15370665888683.jpg" width="60%" height="50%"></p><p>æ³¨æ„åˆ°ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºï¼Œä¸åŒfeatureä¹‹é—´æ²¡æœ‰å…³ç³»ï¼Œæ¯ä¸ªfeatureç¬¦åˆç‰¹å®šçš„é«˜æ–¯åˆ†å¸ƒï¼Œåˆ™è¯¥åˆ†ç±»å™¨åˆ™æ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼š<br><img src="/images/2018-09-16-15370666092459.jpg" width="60%" height="50%"></p><h3 id="åˆ†ç±»ä¸logistics-regression"><a href="#åˆ†ç±»ä¸logistics-regression" class="headerlink" title="åˆ†ç±»ä¸logistics regression"></a>åˆ†ç±»ä¸logistics regression</h3><p>ç°æ¨å¯¼ï¼Œè¯¥åˆ†ç±»é—®é¢˜ä¸logistics regressionä¹‹é—´çš„è”ç³»ï¼š<br>å³ï¼š<br><img src="/images/2018-09-16-15370666567324.jpg" width="60%" height="50%"></p><h4 id="å‡è®¾"><a href="#å‡è®¾" class="headerlink" title="å‡è®¾"></a>å‡è®¾</h4><p>æ•°æ®æœä»é«˜æ–¯åˆ†å¸ƒï¼Œå…±äº«$Î£$</p><h4 id="æ¨å¯¼"><a href="#æ¨å¯¼" class="headerlink" title="æ¨å¯¼"></a>æ¨å¯¼</h4><p>â‘ æ€»æ¡†æ¶ï¼š<br><img src="/images/2018-09-16-15370667000974.jpg" width="50%" height="50%"></p><p>ä»¤<br><img src="/images/2018-09-16-15370667135868.jpg" width="24%" height="50%"></p><p>åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370667376312.jpg" width="50%" height="50%"></p><p>â‘¡zçš„è¿›ä¸€æ­¥æ¨å¯¼ä¸ç®€åŒ–ï¼š<br><img src="/images/2018-09-16-15370667582564.jpg" width="30%" height="50%"></p><p>å°†zå±•å¼€ï¼š<br><img src="/images/2018-09-16-15370667763267.jpg" width="50%" height="50%"></p><p>è€Œç¬¬ä¸€éƒ¨åˆ†æœ‰ï¼š<br><img src="/images/2018-09-16-15370667880942.jpg" width="50%" height="50%"></p><p>ç¬¬ä¸€éƒ¨åˆ†ç›¸é™¤ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668274551.jpg" width="50%" height="50%"></p><p>å†è¿›è¡Œå±•å¼€ï¼Œæœ‰ï¼š<br><img src="/images/2018-09-16-15370668394919.jpg" width="50%" height="50%"></p><p>æœ€ç»ˆzçš„å…¬å¼ä¸ºï¼š<br><img src="/images/2018-09-16-15370668522531.jpg" width="50%" height="50%"></p><p>ç”±äºå…±äº«åæ–¹å·®çŸ©é˜µï¼Œåˆ™å¯ä»¥æ¶ˆå»éƒ¨åˆ†ï¼Œå¾—åˆ°ï¼š<br><img src="/images/2018-09-16-15370668957564.jpg" width="50%" height="50%"></p><p>æ›¿æ¢æˆwå’Œbï¼š<br><img src="/images/2018-09-16-15370669103562.jpg" width="50%" height="50%"></p><p>â‘¢æœ€ç»ˆï¼Œå°†zå¸¦å›åˆ°åŸå¼ï¼š<br><img src="/images/2018-09-16-15370669221472.jpg" width="25%" height="50%"></p><p>æ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦å†ä¼°è®¡N1,N2,Î¼å’ŒÎ£ï¼Œç›´æ¥è®¡ç®—wå’Œbå³å¯ã€‚ä¹Ÿå› æ­¤ï¼Œåˆ†ç•Œçº¿æ˜¯çº¿æ€§çš„ã€‚</p><p>å…¨è¿‡ç¨‹ï¼š<br><img src="/images/2018-09-16-15370669594744.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Classification </tag>
            
            <tag> Probabilistic Generative Model </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 3:Gradient Descent</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%203%20Gradient%20Descent/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%203%20Gradient%20Descent/</url>
      
        <content type="html"><![CDATA[<h2 id="Gradient-Descent-tips"><a href="#Gradient-Descent-tips" class="headerlink" title="Gradient Descent tips"></a>Gradient Descent tips</h2><h3 id="tip-1ï¼šAdaptive-Learning-Rates"><a href="#tip-1ï¼šAdaptive-Learning-Rates" class="headerlink" title="tip 1ï¼šAdaptive Learning Rates"></a>tip 1ï¼šAdaptive Learning Rates</h3><h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><h5 id="åŸºæœ¬æ€æƒ³"><a href="#åŸºæœ¬æ€æƒ³" class="headerlink" title="åŸºæœ¬æ€æƒ³"></a>åŸºæœ¬æ€æƒ³</h5><p><img src="/images/2018-09-16-15370654467771.jpg" width="30%" height="50%"></p><p><img src="/images/2018-09-16-15370654502774.jpg" width="20%" height="50%"></p><p>å…¶ä¸­Ïƒæ˜¯ä¹‹å‰æ‰€æœ‰çš„æ¢¯åº¦çš„å¹³æ–¹æ ¹<br><img src="/images/2018-09-16-15370654728457.jpg" width="30%" height="50%"></p><p>åŒ–ç®€å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370654853172.jpg" width="50%" height="50%"></p><h5 id="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ"></a>ä¸ºä»€ä¹ˆè¦æ€ä¹ˆåšï¼Ÿ</h5><p>è€ƒè™‘ä¸€ä¸ªå¼€å£å‘ä¸Šçš„äºŒæ¬¡å‡½æ•°<br><img src="/images/2018-09-16-15370655091732.jpg" width="50%" height="50%"></p><p>ä¹Ÿå³ï¼Œæœ€å¥½çš„æ­¥é•¿æ˜¯ä¸€æ¬¡å¯¼é™¤ä»¥äºŒæ¬¡å¯¼ï¼Œä½†äºŒæ¬¡å¯¼è®¡ç®—é‡å¤§ï¼Œå› æ­¤ä½¿ç”¨è¿‘ä¼¼çš„æ–¹å¼ï¼š<br><strong>å¯¹ä¸€æ¬¡å¯¼ä½œå¤šæ¬¡çš„sample</strong>ã€‚<br>ä¸‹å›¾æ˜¾ç¤ºï¼Œå¦‚æœäºŒæ¬¡å¯¼å°ï¼Œé‚£ä¹ˆå¤šæ¬¡sampleè·å¾—çš„ä¸€æ¬¡å¯¼ä¹Ÿå°ï¼Œåä¹‹åˆ™å¤§ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€æ¬¡å¯¼åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥åæ˜ äºŒæ¬¡å¯¼çš„å¤§å°ï¼Œæ‰€ä»¥ç›´æ¥ç”¨ä¸€æ¬¡å¯¼è¿‘ä¼¼ï¼Œå¯ä»¥å‡å°‘è®¡ç®—é‡ã€‚</p><p><img src="/images/2018-09-16-15370655850876.jpg" width="50%" height="50%"></p><h3 id="tip-2ï¼šfeature-scaling"><a href="#tip-2ï¼šfeature-scaling" class="headerlink" title="tip 2ï¼šfeature scaling"></a>tip 2ï¼šfeature scaling</h3><p><img src="/images/2018-09-16-15370656836724.jpg" width="50%" height="50%"></p><p>èƒ½å¤Ÿæ”¹å˜lossçš„åˆ†å¸ƒï¼Œä¸Šå›¾1ä¸­w2å¯¹lossçš„å½±å“è¾ƒå¤§ï¼Œåˆ™è¾ƒé™¡å³­ï¼Œå‚æ•°æ›´æ–°å°±è¾ƒå›°éš¾ï¼Œéœ€è¦adaptive learning rateï¼›å¦‚æœè¿›è¡Œfeature scalingï¼Œèƒ½å¤Ÿæ›´å¥½è¾¾åˆ°local optimal</p><h2 id="Gradient-Descent-Theory"><a href="#Gradient-Descent-Theory" class="headerlink" title="Gradient Descent Theory"></a>Gradient Descent Theory</h2><p>å¦ä¸€ç§è§’åº¦çœ‹gradient descentï¼š</p><p>åŸºæœ¬æ€æƒ³ï¼š<br>æˆ‘ä»¬å¸Œæœ›æ¯ä¸€æ¬¡éƒ½åœ¨å½“å‰ç‚¹é™„è¿‘æ‰¾åˆ°ä¸€ä¸ªæœ€å°çš„ç‚¹ï¼Œå³åœ¨ä¸€ä¸ªèŒƒå›´å†…ï¼š<br><img src="/images/2018-09-16-15370657785697.jpg" width="40%" height="50%"></p><p>åº”è¯¥å¦‚ä½•æ‰¾åˆ°è¯¥æœ€å°ç‚¹ï¼Ÿ</p><p>æˆ‘ä»¬çŸ¥é“ï¼Œæ³°å‹’çº§æ•°çš„å½¢å¼ï¼š<br><img src="/images/2018-09-16-15370658066669.jpg" width="50%" height="50%"></p><p>å½“xæ¥è¿‘x0æ—¶ï¼Œä¼šæœ‰å¦‚ä¸‹è¿‘ä¼¼ï¼š<br><img src="/images/2018-09-16-15370658167935.jpg" width="30%" height="50%"></p><p>æ¨å¹¿åˆ°å¤šå…ƒæ³°å‹’çº§æ•°åˆ™æœ‰ï¼š<br><img src="/images/2018-09-16-15370658315314.jpg" width="60%" height="50%"></p><p>é‚£ä¹ˆï¼Œå¦‚å‰æ‰€è¿°ï¼Œxæ¥è¿‘x0ï¼Œå¯¹äºå›¾ä¸­ï¼Œå³åœ†åœˆè¶³å¤Ÿå°æ—¶ï¼š<br><img src="/images/2018-09-16-15370658494091.jpg" width="50%" height="50%"></p><p>ç®€åŒ–ç¬¦å·ï¼š<br><img src="/images/2018-09-16-15370658736683.jpg" width="12%" height="50%"></p><p><img src="/images/2018-09-16-15370658623258.jpg" width="30%" height="50%"></p><p>æ‰€ä»¥å¯ä»¥ç®€å†™æˆï¼š<br><img src="/images/2018-09-16-15370658855882.jpg" width="30%" height="50%"></p><p>ç”±äºs,u,véƒ½æ˜¯å¸¸æ•°ï¼Œåœ¨åœ†åœˆèŒƒå›´å†…å¯»æ‰¾æœ€å°å€¼å¯¹åº”çš„å‚æ•°å¯ä»¥ç®€åŒ–æˆï¼š<br><img src="/images/2018-09-16-15370658981519.jpg" width="40%" height="50%"></p><p><img src="/images/2018-09-16-15370659061025.jpg" width="30%" height="50%"></p><p>å†åº¦ç®€åŒ–ï¼Œå¯ä»¥è¡¨è¾¾æˆï¼š<br><img src="/images/2018-09-16-15370659680601.jpg" width="40%" height="50%"></p><p><img src="/images/2018-09-16-15370659747339.jpg" width="30%" height="50%"></p><p>åœ¨å›¾ä¸­å¯ä»¥ç”»ä¸ºä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯<br><img src="/images/2018-09-16-15370660126195.jpg" width="40%" height="50%"></p><p>æ˜¾ç„¶ï¼Œå½“åæ–¹å‘æ—¶ï¼Œæœ€å°ï¼š<br><img src="/images/2018-09-16-15370660243469.jpg" width="40%" height="50%"></p><p>ä¹Ÿå³ï¼š<br><img src="/images/2018-09-16-15370660628961.jpg" width="50%" height="50%"></p><p>æœ€ç»ˆå®Œæ•´çš„å¼å­ï¼š<br><img src="/images/2018-09-16-15370660794436.jpg" width="55%" height="50%"></p><p>å› æ­¤ï¼Œå½“learning rateä¸å¤Ÿå°æ—¶ï¼Œæ˜¯ä¸æ»¡è¶³æ³°å‹’çº§æ•°è¿‘ä¼¼çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> Gradient Descent </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Lecture 2:Bias and Variance</title>
      <link href="/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%202%20Bias%20and%20Variance/"/>
      <url>/2018/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86/Lecture%202%20Bias%20and%20Variance/</url>
      
        <content type="html"><![CDATA[<h3 id="å¦‚ä½•ç†è§£bias-amp-variance"><a href="#å¦‚ä½•ç†è§£bias-amp-variance" class="headerlink" title="å¦‚ä½•ç†è§£bias&amp;variance"></a>å¦‚ä½•ç†è§£bias&amp;variance</h3><p><img src="/images/2018-09-16-15370650140053.jpg" width="40%" height="50%"><br>biasæ˜¯function spaceä¸­å¿ƒç¦»optimal modelçš„å·®è·ï¼Œvarianceæ˜¯æŸæ¬¡å®éªŒæ‰€å¾—æ¨¡å‹ç¦»function spaceä¸­å¿ƒçš„è·ç¦»ã€‚</p><p>æ¯”å¦‚è¯´ï¼Œç®€å•åœ°æ¨¡å‹çš„function spaceå°ï¼Œéšæœºæ€§å°ï¼Œå› æ­¤varianceå°ï¼Œä½†ä¹Ÿå› ä¸ºfunction spaceå°ï¼Œè¡¨ç¤ºèƒ½åŠ›æœ‰é™ï¼Œå› æ­¤biaså¤§ã€‚</p><p>å¦‚å›¾ï¼š<br><img src="/images/2018-09-16-15370651353167.jpg" width="70%" height="50%"><br>è¯¥å›¾ä¸­è“è‰²åœˆä»£è¡¨æ¨¡å‹æ‰€èƒ½è¡¨è¾¾çš„èŒƒå›´ã€‚</p><h3 id="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"><a href="#å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜" class="headerlink" title="å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜"></a>å¦‚ä½•è§£å†³varianceå¤§çš„é—®é¢˜</h3><p>â‘ æ›´å¤šçš„data<br>â‘¡regularizationï¼šå¼ºè¿«functionæ›´å¹³æ»‘ï¼Œå› æ­¤å‡å°varianceï¼Œä½†å› ä¸ºè°ƒæ•´äº†function spaceï¼Œå¯èƒ½ä¼šå¢åŠ biasã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹ ğŸ¤– </tag>
            
            <tag> æå®æ¯…æœºå™¨å­¦ä¹ è¯¾ç¨‹ </tag>
            
            <tag> bias&amp;variance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯9</title>
      <link href="/2018/09/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D9/"/>
      <url>/2018/09/16/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D9/</url>
      
        <content type="html"><![CDATA[<h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€</strong>ã€‚<br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p><hr><h3 id="ç»å‘½è¯—"><a href="#ç»å‘½è¯—" class="headerlink" title="ç»å‘½è¯—"></a>ç»å‘½è¯—</h3><p>è°­å—£åŒ<br>æœ›é—¨æŠ•æ­¢æ€å¼ ä¿­ï¼Œ<br>å¿æ­»é¡»è‡¾å¾…æœæ ¹ã€‚<br><strong>æˆ‘è‡ªæ¨ªåˆ€å‘å¤©ç¬‘ï¼Œ<br>å»ç•™è‚èƒ†ä¸¤æ˜†ä»‘ï¼</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pytorch backward()æµ…æ</title>
      <link href="/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Pytorch%20backward()%E6%B5%85%E6%9E%90/"/>
      <url>/2018/09/16/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Pytorch%20backward()%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘åœ¨çœ‹pytorchæ–‡æ¡£çš„æ—¶å€™ï¼Œçœ‹åˆ°backwardå†…æœ‰ä¸€ä¸ªå‚æ•°gradientï¼Œåœ¨ç»è¿‡æŸ¥é˜…äº†ç›¸å…³èµ„æ–™å’Œè¿›è¡Œäº†å®éªŒåï¼Œå¯¹backwardæœ‰äº†æ›´æ·±çš„è®¤è¯†ã€‚</p><h2 id="backward"><a href="#backward" class="headerlink" title="backward"></a>backward</h2><p>1ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¦‚ï¼š<code>loss.backward()</code><br>åˆ™gradientä¸éœ€è¦æ‰‹åŠ¨ä¼ å…¥ï¼Œä¼šè‡ªåŠ¨æ±‚å¯¼ã€‚<br>ä¾‹å­:<br>$a=[x_1,x_2],b=\frac{x_1+x_2}{2}$<br>åˆ™bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b}{\partial x_{1}}=\frac{1}{2}ï¼Œ\dfrac {\partial b}{\partial x_{2}}=\frac{1}{2}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.Tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.mean(a)  <span class="comment">#tensor(2.5000, grad_fn=&lt;MeanBackward1&gt;)</span></span><br><span class="line">b.backward()</span><br><span class="line">a.grad   <span class="comment">#tensor([0.5000, 0.5000])</span></span><br></pre></td></tr></table></figure><p>gradientæ­¤æ—¶åªæ˜¯åœ¨ç¼©æ”¾åŸgradçš„å¤§å°ï¼Œä¹Ÿå³ä¸æŒ‡å®šgradientå’Œgradient=1æ˜¯ç­‰ä»·çš„</p><p>å½“ç„¶ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šgradientï¼Œå…¶ä¸­æŒ‡å®šgradientçš„shapeå¿…é¡»å’Œbçš„ç»´åº¦ç›¸åŒ<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gradient=torch.tensor(<span class="number">10.0</span>)</span><br><span class="line">b.backward(gradient)</span><br><span class="line">a.grad   <span class="comment">#tensor([5., 5.])</span></span><br></pre></td></tr></table></figure></p><p>2ï¸âƒ£å¦‚æœè°ƒç”¨backwardçš„æ˜¯ä¸€ä¸ªå‘é‡<br>ä¾‹å­ï¼š<br>$a=[x_1,x_2],b=[b_1,b_2]$, å…¶ä¸­ $b_1=x_1+x_2,b_2=x_1*x_2$<br>bå¯¹aæ±‚å¯¼ï¼Œæœ‰ï¼š<br>$\dfrac {\partial b_1}{\partial x_{1}}=1,\dfrac {\partial b_1}{\partial x_{2}}=1$</p><p>$\dfrac {\partial b_2}{\partial x_{1}}=x_2,\dfrac {\partial b_2}{\partial x_{2}}=x_1$</p><p>åœ¨backwardçš„æ—¶å€™åˆ™å¿…é¡»æŒ‡å®šgradientã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.FloatTensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a.requires_grad=<span class="keyword">True</span></span><br><span class="line">b=torch.zeros(<span class="number">2</span>)</span><br><span class="line">b[<span class="number">0</span>]=a[<span class="number">0</span>]+a[<span class="number">1</span>]</span><br><span class="line">b[<span class="number">1</span>]=a[<span class="number">0</span>]*a[<span class="number">1</span>]    <span class="comment"># b=tensor([5., 6.], grad_fn=&lt;CopySlices&gt;)</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">0.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment">#tensor([1., 1.])ï¼Œè¯´æ˜æ˜¯å¯¹b_1è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()  <span class="comment">#å°†æ¢¯åº¦æ¸…ç©ºï¼Œå¦åˆ™ä¼šå åŠ </span></span><br><span class="line"><span class="comment">#-------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">0.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad  <span class="comment"># tensor([3., 2.])ï¼Œè¯´æ˜å¯¹b_2è¿›è¡Œæ±‚å¯¼</span></span><br><span class="line">a.grad.zero_()</span><br><span class="line"><span class="comment"># ------------- #</span></span><br><span class="line">gradient=torch.tensor([<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line">b.backward(gradient,retain_graph=<span class="keyword">True</span>)</span><br><span class="line">a.grad   <span class="comment"># tensor([4., 3.])ï¼Œå³b_1,b_2çš„å¯¼æ•°çš„å åŠ </span></span><br><span class="line">a.grad.zero_()</span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°b.backward()æ—¶éœ€è¦retain_graphè®¾ä¸ºTrueï¼Œå¦åˆ™åœ¨è®¡ç®—å®Œåä¼šè‡ªåŠ¨é‡Šæ”¾è®¡ç®—å›¾çš„å†…å­˜ï¼Œè¿™æ ·å°±æ²¡æ³•è¿›è¡ŒäºŒæ¬¡åå‘ä¼ æ’­äº†ã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.pytorchtutorial.com/pytorch-backward/" target="_blank" rel="noopener">https://www.pytorchtutorial.com/pytorch-backward/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> backward </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯8</title>
      <link href="/2018/09/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D8/"/>
      <url>/2018/09/09/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D8/</url>
      
        <content type="html"><![CDATA[<h3 id="æœ›æœˆæ€€è¿œ"><a href="#æœ›æœˆæ€€è¿œ" class="headerlink" title="æœ›æœˆæ€€è¿œ"></a>æœ›æœˆæ€€è¿œ</h3><p>[å”] å¼ ä¹é¾„<br><strong>æµ·ä¸Šç”Ÿæ˜æœˆï¼Œå¤©æ¶¯å…±æ­¤æ—¶ã€‚</strong><br>æƒ…äººæ€¨é¥å¤œï¼Œç«Ÿå¤•èµ·ç›¸æ€ã€‚<br>ç­çƒ›æ€œå…‰æ»¡ï¼ŒæŠ«è¡£è§‰éœ²æ»‹ã€‚<br>ä¸å ªç›ˆæ‰‹èµ ï¼Œè¿˜å¯æ¢¦ä½³æœŸã€‚</p><p>é¥å¤œï¼Œé•¿å¤œã€‚</p><p><a href="http://m.xichuangzhu.com/work/57aca120a341310060e2a09f" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57aca120a341310060e2a09f</a></p><hr><h3 id="æ— é¢˜"><a href="#æ— é¢˜" class="headerlink" title="æ— é¢˜"></a>æ— é¢˜</h3><p>è¨é•‡å†°<br>äº”åä¸ƒè½½çŠ¹å¦‚æ¢¦ï¼Œä¸¾å›½æ²¦äº¡ç¼˜æ±‰åŸã€‚<br><strong>é¾™æ¸¸æµ…æ°´å‹¿è‡ªå¼ƒï¼Œç»ˆæœ‰æ‰¬çœ‰åæ°”å¤©ã€‚</strong></p><p>1951å¹´ï¼Œä¸­å›½äººæ°‘å¿—æ„¿å†›åœ¨æŠ—ç¾æ´æœæˆ˜äº‰ç¬¬ä¸‰æ¬¡æˆ˜å½¹åæ‰“è¿›äº†æ±‰åŸï¼Œè¨é•‡å†°å¾—çŸ¥æ­¤äº‹ï¼Œå›æƒ³èµ·57å¹´å‰çš„ç”²åˆæ‚²æ­Œï¼Œå½“å³ä½œè¯—ä¸€é¦–ã€‚</p><hr><h3 id="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"><a href="#ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬" class="headerlink" title="ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬"></a>ç™½é›ªæ­Œé€æ­¦åˆ¤å®˜å½’äº¬</h3><p>[å”] å²‘å‚<br>åŒ—é£å·åœ°ç™½è‰æŠ˜ï¼Œèƒ¡å¤©å…«æœˆå³é£é›ªã€‚<br><strong>å¿½å¦‚ä¸€å¤œæ˜¥é£æ¥ï¼Œåƒæ ‘ä¸‡æ ‘æ¢¨èŠ±å¼€ã€‚</strong><br>æ•£å…¥ç å¸˜æ¹¿ç½—å¹•ï¼Œç‹è£˜ä¸æš–é”¦è¡¾è–„ã€‚<br>å°†å†›è§’å¼“ä¸å¾—æ§ï¼Œéƒ½æŠ¤é“è¡£å†·éš¾ç€ã€‚<br>ç€šæµ·é˜‘å¹²ç™¾ä¸ˆå†°ï¼Œæ„äº‘æƒ¨æ·¡ä¸‡é‡Œå‡ã€‚<br>ä¸­å†›ç½®é…’é¥®å½’å®¢ï¼Œèƒ¡ç´çµç¶ä¸ç¾Œç¬›ã€‚<br>çº·çº·æš®é›ªä¸‹è¾•é—¨ï¼Œé£æ£çº¢æ——å†»ä¸ç¿»ã€‚<br><strong>è½®å°ä¸œé—¨é€å›å»ï¼Œå»æ—¶é›ªæ»¡å¤©å±±è·¯ã€‚<br>å±±å›è·¯è½¬ä¸è§å›ï¼Œé›ªä¸Šç©ºç•™é©¬è¡Œå¤„</strong>ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b903e3d342d3005ac74290</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯7</title>
      <link href="/2018/09/02/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D7/"/>
      <url>/2018/09/02/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D7/</url>
      
        <content type="html"><![CDATA[<h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„é£ã€‚çˆ½ç±å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éã€‚ç¢å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼›é‚ºæ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ã€‚å››ç¾å…·ï¼ŒäºŒéš¾å¹¶ã€‚ç©·ç‡çœ„äºä¸­å¤©ï¼Œæå¨±æ¸¸äºæš‡æ—¥ã€‚å¤©é«˜åœ°è¿¥ï¼Œè§‰å®‡å®™ä¹‹æ— ç©·ï¼›å…´å°½æ‚²æ¥ï¼Œè¯†ç›ˆè™šä¹‹æœ‰æ•°ã€‚æœ›é•¿å®‰äºæ—¥ä¸‹ï¼Œç›®å´ä¼šäºäº‘é—´ã€‚åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œã€‚å…³å±±éš¾è¶Šï¼Œè°æ‚²å¤±è·¯ä¹‹äººï¼›èæ°´ç›¸é€¢ï¼Œå°½æ˜¯ä»–ä¹¡ä¹‹å®¢ã€‚æ€€å¸é˜è€Œä¸è§ï¼Œå¥‰å®£å®¤ä»¥ä½•å¹´ï¼Ÿ</p><hr><p><strong>æ³¨é‡Šï¼š</strong><br>é¥è¥Ÿç”«ç•…ï¼Œé€¸å…´é„ï¼ˆchuÃ¡nï¼‰é£ï¼šç™»é«˜æœ›è¿œçš„èƒ¸æ€€é¡¿æ—¶èˆ’ç•…ï¼Œé£˜æ¬²è„±ä¿—çš„å…´è‡´æ²¹ç„¶è€Œç”Ÿã€‚</p><p>çˆ½ç±ï¼ˆlÃ iï¼‰å‘è€Œæ¸…é£ç”Ÿï¼Œçº¤æ­Œå‡è€Œç™½äº‘éï¼šå®´ä¼šä¸Šï¼Œæ’ç®«å“èµ·ï¼Œå¥½åƒæ¸…é£æ‹‚æ¥ï¼›æŸ”ç¾çš„æ­Œå£°ç¼­ç»•ä¸æ•£ï¼Œéæ­¢äº†ç™½äº‘é£åŠ¨ã€‚çˆ½ï¼šå½¢å®¹ç±çš„å‘éŸ³æ¸…è„†ã€‚ç±ï¼šæ’ç®«ï¼Œä¸€ç§ç”±å¤šæ ¹ç«¹ç®¡ç¼–æ’è€Œæˆçš„ç®¡ä¹å™¨ã€‚</p><p>ç¢ï¼ˆsuÄ«ï¼‰å›­ç»¿ç«¹ï¼Œæ°”å‡Œå½­æ³½ä¹‹æ¨½ï¼šä»Šæ—¥çš„å®´ä¼šï¼Œå¥½æ¯”å½“å¹´ç¢å›­ç«¹æ—çš„èšä¼šï¼Œåœ¨åº§çš„æ–‡äººé›…å£«ï¼Œè±ªçˆ½å–„é¥®çš„æ°”æ¦‚è¶…è¿‡äº†é™¶æ¸Šæ˜ã€‚ç¢å›­ï¼šè¥¿æ±‰æ¢å­ç‹åœ¨ç¢æ°´æ—ä¿®å»ºçš„ç«¹å›­ï¼Œä»–å¸¸å’Œä¸€äº›æ–‡äººåœ¨æ­¤é¥®é…’èµ‹è¯—ã€‚</p><p>é‚ºï¼ˆyÃ¨ï¼‰æ°´æœ±åï¼Œå…‰ç…§ä¸´å·ä¹‹ç¬”ï¼šè¿™æ˜¯å€Ÿè¯—äººæ›¹æ¤ã€è°¢çµè¿æ¥æ¯”æ‹Ÿå‚åŠ å®´ä¼šçš„æ–‡äººã€‚é‚ºï¼šä»Šæ²³åŒ—ä¸´æ¼³ï¼Œæ˜¯æ›¹é­å…´èµ·çš„åœ°æ–¹ã€‚æ›¹æ¤æ›¾åœ¨è¿™é‡Œä½œè¿‡ã€Šå…¬å®´è¯—ã€‹ï¼Œè¯—ä¸­æœ‰â€œæœ±åå†’ç»¿æ± â€çš„å¥å­ã€‚ä¸´å·ä¹‹ç¬”ï¼šæŒ‡è°¢çµè¿ï¼Œä»–æ›¾ä»»ä¸´å·ï¼ˆä»Šå±æ±Ÿè¥¿ï¼‰å†…å²ã€‚</p><p>å››ç¾ï¼šæŒ‡è‰¯è¾°ã€ç¾æ™¯ã€èµå¿ƒã€ä¹äº‹ã€‚</p><p>äºŒéš¾ï¼šè´¤ä¸»ã€å˜‰å®¾ã€‚</p><p>åœ°åŠ¿æè€Œå—æºŸæ·±ï¼Œå¤©æŸ±é«˜è€ŒåŒ—è¾°è¿œï¼šåœ°åŠ¿åè¿œï¼Œå—æµ·æ·±é‚ƒï¼›å¤©æŸ±é«˜è€¸ï¼ŒåŒ—ææ˜Ÿè¿œæ‚¬ã€‚</p><p>å¸é˜ï¼ˆhÅ«nï¼‰ï¼šåŸæŒ‡å¤©å¸çš„å®ˆé—¨è€…ã€‚è¿™é‡ŒæŒ‡çš‡å¸çš„å®«é—¨ã€‚</p><p>å¥‰å®£å®¤ä»¥ä½•å¹´ï¼šä»€ä¹ˆæ—¶å€™æ‰èƒ½åƒè´¾è°Šé‚£æ ·å»ä¾å¥‰å›ç‹å‘¢</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†6</title>
      <link href="/2018/09/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%866/"/>
      <url>/2018/09/02/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%866/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-dropout"><a href="#1ï¸âƒ£-dropout" class="headerlink" title="1ï¸âƒ£[dropout]"></a>1ï¸âƒ£[dropout]</h3><p>dropoutå½¢å¼:<br><img src="/images/2018-09-02-15358857481798.jpg" width="70%" height="50%"><br>RNNçš„å½¢å¼æœ‰å¤šç§ï¼š</p><ul><li><p>recurrent dropout<br>RNN: $h_t=f(W_h âŠ™ [x_t,h_{t-1}]+b_h)$<br>åŠ ä¸Šdropoutçš„RNNï¼š$h_t=f(W_h âŠ™ [x_t,d(h_{t-1})]+b_h)$ï¼Œå…¶ä¸­$d(\cdot)$ä¸ºdropoutå‡½æ•°<br>åŒç†ï¼š<br>LSTM:$c_t=f_t âŠ™c_{t-1} + i_t âŠ™ d(g_t)$<br>GRU:$h_t=(1-z_t)âŠ™c_{t-1}+z_tâŠ™d(g_t)$</p></li><li><p>å‚ç›´è¿æ¥çš„dropout<br>dropoutçš„ä½œç”¨å³æ˜¯å¦å…è®¸Lå±‚æŸä¸ªLSTMå•å…ƒçš„éšçŠ¶æ€ä¿¡æ¯æµå…¥L+1å±‚å¯¹åº”å•å…ƒã€‚<br><img src="/images/2018-09-02-15358866404870.jpg" width="50%" height="50%"></p></li></ul><p>Reference:<br><a href="https://blog.csdn.net/falianghuang/article/details/72910161" target="_blank" rel="noopener">https://blog.csdn.net/falianghuang/article/details/72910161</a></p><hr><h3 id="2ï¸âƒ£-Pytorch"><a href="#2ï¸âƒ£-Pytorch" class="headerlink" title="2ï¸âƒ£[Pytorch]"></a>2ï¸âƒ£[Pytorch]</h3><p>pack_padded_sequenceç”¨äºRNNä¸­ï¼Œå°†paddingçŸ©é˜µå‹ç¼©:<br><img src="/images/2018-09-02-15358868858836.jpg" width="60%" height="50%"><br>è¿™æ ·å°±å¯ä»¥å®ç°åœ¨RNNä¼ è¾“è¿‡ç¨‹ä¸­çŸ­å¥æå‰ç»“æŸã€‚</p><p>pad_packed_sequenceæ˜¯pack_padded_sequenceçš„é€†è¿ç®—ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> dropout </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æˆ‘æ²¡æœ‰è¯´è¯</title>
      <link href="/2018/08/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%88%91%E6%B2%A1%E6%9C%89%E8%AF%B4%E8%AF%9D/"/>
      <url>/2018/08/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%88%91%E6%B2%A1%E6%9C%89%E8%AF%B4%E8%AF%9D/</url>
      
        <content type="html"><![CDATA[<p>ã€Šæˆ‘æ²¡æœ‰è¯´è¯ã€‹</p><p>çº³ç²¹æ€å…±äº§å…šæ—¶ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å…±äº§å…šå‘˜ï¼›<br>æ¥ç€ä»–ä»¬è¿«å®³çŠ¹å¤ªäººï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯çŠ¹å¤ªäººï¼›<br>ç„¶åä»–ä»¬æ€å·¥ä¼šæˆå‘˜ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘ä¸æ˜¯å·¥ä¼šæˆå‘˜ï¼›<br>åæ¥ä»–ä»¬è¿«å®³å¤©ä¸»æ•™å¾’ï¼Œ<br>æˆ‘æ²¡æœ‰å‡ºå£°<br>â€”â€”å› ä¸ºæˆ‘æ˜¯æ–°æ•™å¾’ï¼›<br>æœ€åå½“ä»–ä»¬å¼€å§‹å¯¹ä»˜æˆ‘çš„æ—¶å€™ï¼Œ<br>å·²ç»æ²¡æœ‰äººèƒ½ç«™å‡ºæ¥ä¸ºæˆ‘å‘å£°äº†</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep Learning NLP best practicesç¬”è®°</title>
      <link href="/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Deep%20Learning%20NLP%20best%20practices%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Deep%20Learning%20NLP%20best%20practices%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>åšå®¢åœ°å€ï¼š<a href="http://ruder.io/deep-learning-nlp-best-practices/index.html" target="_blank" rel="noopener">http://ruder.io/deep-learning-nlp-best-practices/index.html</a><br>ä¸ªäººè§‰å¾—è¿™ç¯‡æ–‡ç« å†™å¾—å¾ˆå¥½ï¼Œæœ‰è®¸å¤šå®è·µå¾—åˆ°çš„ç»éªŒï¼Œé€šè¿‡è¿™ç¯‡å¯ä»¥é¿å…èµ°ä¸€äº›å¼¯è·¯ã€‚</p><h2 id="Practices"><a href="#Practices" class="headerlink" title="Practices"></a>Practices</h2><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><blockquote><p>The optimal dimensionality of word embeddings is mostly task-dependent: a smaller dimensionality works better for more syntactic tasks such as named entity recognition or part-of-speech (POS) tagging, while a larger dimensionality is more useful for more semantic tasks such as sentiment analysis.</p></blockquote><p>å¯¹äºåå‘è¯­æ³•çš„ï¼Œä½¿ç”¨ç»´åº¦ä½ä¸€äº›çš„è¯å‘é‡ï¼›è€Œå¯¹äºåå‘è¯­ä¹‰å†…å®¹çš„ï¼Œä½¿ç”¨ç»´åº¦å¤§ä¸€äº›çš„è¯å‘é‡ï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€‚</p><h3 id="LSTM-Depth"><a href="#LSTM-Depth" class="headerlink" title="LSTM Depth"></a>LSTM Depth</h3><blockquote><p>performance improvements of making the model deeper than 2 layers are minimal </p></blockquote><p>LSTMæ·±åº¦æœ€å¥½ä¸è¦è¶…è¿‡ä¸¤å±‚ã€‚</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><blockquote><p>It is often thought that Adam clearly outperforms vanilla stochastic gradient descent (SGD). However, while it converges much faster than SGD, it has been observed that SGD with learning rate annealing slightly outperforms Adam. Recent work furthermore shows that SGD with properly tuned momentum outperforms Adam .</p></blockquote><p>Adamå¯ä»¥æ›´æ—©æ‹Ÿåˆï¼Œè€ŒSGDæ•ˆæœå¯èƒ½ä¼šæ›´å¥½ä¸€äº›ã€‚</p><p>å¯ä»¥é‡‡ç”¨ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨Adamè®­ç»ƒç›´åˆ°æ‹Ÿåˆï¼Œç„¶åå°†å­¦ä¹ ç‡å‡åŠï¼Œå¹¶é‡æ–°å¯¼å…¥ä¹‹å‰è®­ç»ƒå¥½çš„æœ€å¥½çš„æ¨¡å‹ã€‚è¿™æ ·Adamèƒ½å¤Ÿå¿˜è®°ä¹‹å‰çš„ä¿¡æ¯å¹¶é‡æ–°å¼€å§‹è®­ç»ƒã€‚</p><blockquote><p>Denkowski &amp; Neubig (2017) show that Adam with 2 restarts and learning rate annealing is faster and performs better than SGD with annealing</p></blockquote><h3 id="Ensembling"><a href="#Ensembling" class="headerlink" title="Ensembling"></a>Ensembling</h3><blockquote><p>Combining multiple models into an ensemble by averaging their predictions is a proven strategy to improve model performance.</p></blockquote><p>Ensemblingå¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯éœ€è¦ä¿è¯å¤šæ ·æ€§ï¼š</p><blockquote><p>Ensembling is an important way to ensure that results are still reliable if the diversity of the evaluated models increases (Denkowski &amp; Neubig, 2017). While ensembling different checkpoints of a model has been shown to be effective (Jean et al., 2015; Sennrich et al., 2016) [51, 52], it comes at the cost of model diversity. Cyclical learning rates can help to mitigate this effect</p></blockquote><h3 id="LSTM-tricks"><a href="#LSTM-tricks" class="headerlink" title="LSTM tricks"></a>LSTM tricks</h3><ul><li><p>åœ¨initial stateä¸­æˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨å…¨0å‘é‡ï¼Œå®é™…ä¸Šå¯ä»¥å°†å…¶ä½œä¸ºå‚æ•°å­¦ä¹ ã€‚</p><blockquote><p>Instead of fixing the initial state, we can learn it like any other parameter, which can improve performance</p></blockquote></li><li><p>å°†inputå’Œoutput embeddingçš„å‚æ•°å…±äº«ï¼Œå¦‚æœæ˜¯åšlanguage modelæˆ–è€…æœºå™¨ç¿»è¯‘ä¹‹ç±»çš„ï¼Œå¯ä»¥è®©ä»–ä»¬å…±äº«ã€‚</p></li><li><p>Gradient Norm Clipping</p><blockquote><p>Rather than clipping each gradient independently, clipping the global norm of the gradient yields more significant improvements</p></blockquote></li></ul><p>è¿™ç‚¹æˆ‘æ²¡çœ‹æ‡‚ã€‚</p><h3 id="Classification-practices"><a href="#Classification-practices" class="headerlink" title="Classification practices"></a>Classification practices</h3><p>å…³äºCNN</p><blockquote><p>CNN filters:Combining filter sizes near the optimal filter size, e.g. (3,4,5) performs best (Kim, 2014; Kim et al., 2016). The optimal number of feature maps is in the range of 50-600 (Zhang &amp; Wallace, 2015) [59].</p><p>Aggregation function:1-max-pooling outperforms average-pooling and k-max pooling (Zhang &amp; Wallace, 2015).</p></blockquote><p>è¿™åœ¨æˆ‘ä¹‹å‰çš„å…³äºCNNæ–‡æœ¬åˆ†ç±»æŒ‡å—ä¸­æœ‰æ›´è¯¦å°½çš„åˆ†æã€‚</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>è¿™æ˜¯ä¸€ç¯‡å¹²è´§æ»¡æ»¡çš„åšå®¢ï¼Œå®é™…ä¸Šæˆ‘è¿˜æ˜¯æœ‰è®¸å¤šåœ°æ–¹æ²¡æœ‰è¯»æ‡‚ï¼Œè¿™é€‚åˆå¤šçœ‹å‡ éï¼Œæ…¢æ…¢ç†è§£ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æŒ‡å— </tag>
            
            <tag> è°ƒå‚ </tag>
            
            <tag> NLPğŸ¤– </tag>
            
            <tag> ç¬”è®°ğŸ“’ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†5</title>
      <link href="/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%865/"/>
      <url>/2018/08/26/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%865/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Paper]<br>Joint Embeddings of Chinese Words, Characters, and Fine-grained Subcharacter Components</p><p>åŸºæœ¬æ¡†æ¶å’ŒCBOWä¸€è‡´ï¼Œä¸»è¦è´¡çŒ®åœ¨äºé’ˆå¯¹ä¸­æ–‡è¯å‘é‡æ·»åŠ äº†åæ—ã€å­—çš„ç»„ä»¶ä½œä¸ºè®­ç»ƒä¿¡æ¯ã€‚</p><p><img src="/images/2018-08-26-15352530482345.jpg" width="50%" height="50%"></p><hr><p>2ï¸âƒ£[Paper]<br>Highway Networks</p><p>ä¸ºäº†è§£å†³ç¥ç»ç½‘ç»œæ·±åº¦è¿‡æ·±æ—¶å¯¼è‡´çš„åå‘ä¼ æ’­å›°éš¾çš„é—®é¢˜ã€‚<br>å‰å‘ä¼ æ’­çš„å…¬å¼ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H)</script><p>è€Œè®ºæ–‡æ‰€åšçš„æ”¹è¿›ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot C(x,W_C)</script><p>å…¶ä¸­$T$æ˜¯transform gateï¼Œ$C$æ˜¯carry gateã€‚æ–¹ä¾¿èµ·è§ï¼Œå¯ä»¥å°† $C=1-T$ï¼Œæœ€ç»ˆæœ‰ï¼š</p><script type="math/tex; mode=display">y=H(x,W_H) \cdot T(x,W_T)+ x \cdot (1-T(x,W_T))</script><p>å¯ä»¥çœ‹å‡ºæ€æƒ³å’ŒLSTMå¾ˆç±»ä¼¼ï¼Œéƒ½æ˜¯gateçš„æ€æƒ³ã€‚</p><hr><p>3ï¸âƒ£[è°ƒå‚æ–¹æ³•]<br>åšå®¢ï¼š<a href="https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41" target="_blank" rel="noopener">https://blog.goodaudience.com/how-to-make-your-model-happy-again-part-1-40d94a9ffb41</a></p><ul><li><strong>å­¦ä¹ ç‡</strong>ï¼š</li></ul><p>ä¸€æ¡åŸåˆ™ï¼šå½“validation losså¼€å§‹ä¸Šå‡æ—¶ï¼Œå‡å°‘å­¦ä¹ ç‡ã€‚</p><p>å¦‚ä½•å‡å°‘ï¼Ÿ</p><p><img src="/images/2018-08-26-15352871548330.jpg" width="50%" height="50%"></p><p>æˆ–è€…ï¼š</p><p><img src="/images/2018-08-26-15352873283890.jpg" width="50%" height="50%"><br>è®¾å®šä¸€å®šçš„epochä½œä¸ºä¸€ä¸ªstepsizeï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çº¿æ€§å¢åŠ å­¦ä¹ ç‡ï¼Œç„¶ååœ¨åˆ°è¾¾æœ€å¤§å€¼åå†çº¿æ€§å‡å°ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ–¹æ³•å¯ä»¥åœ¨ä¸€åŠçš„epochå†…è¾¾åˆ°ç›¸åŒçš„æ•ˆæœã€‚</p><ul><li><strong>batch size</strong>ï¼š</li></ul><p><img src="/images/2018-08-26-15352891425729.jpg" width="50%" height="50%"></p><p>ç”±äºbatch sizeå’Œå­¦ä¹ ç‡çš„å¼ºç›¸å…³æ€§ï¼Œ<a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">ç›¸å…³è®ºæ–‡</a>æå‡ºæé«˜batch sizeè€Œä¸æ˜¯é™ä½å­¦ä¹ ç‡çš„æ–¹æ³•æ¥æå‡æ¨¡å‹è¡¨ç°ã€‚</p><blockquote><p>increasing the batch size during training, instead of decaying learning rate.â€Šâ€”â€ŠL. Smith<br><a href="https://arxiv.org/pdf/1711.00489.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.00489.pdf</a></p></blockquote><p>ä¸€ä¸ªtrickï¼šä¿æŒå­¦ä¹ ç‡ä¸å˜ï¼Œæé«˜batch sizeï¼Œç›´åˆ°batch size~è®­ç»ƒé›†/10ï¼Œæ¥ä¸‹æ¥å†é‡‡ç”¨å­¦ä¹ ç‡ä¸‹é™çš„ç­–ç•¥ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Paper </tag>
            
            <tag> è°ƒå‚æ–¹æ³• </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•6</title>
      <link href="/2018/08/26/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB6/"/>
      <url>/2018/08/26/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB6/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"><a href="#1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch" class="headerlink" title="1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch"></a>1ï¸âƒ£å°†æ•°æ®æ•´ç†æˆbatch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_iter_batch</span><span class="params">(paras,labels,batch_size,shuffle=True)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param paras:</span></span><br><span class="line"><span class="string">    :param labels:</span></span><br><span class="line"><span class="string">    :param batch_size:</span></span><br><span class="line"><span class="string">    :param shuffle:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> len(paras)==len(labels)</span><br><span class="line">    paras_size=len(paras)</span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        indices=np.arange(paras_size)</span><br><span class="line">        np.random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> range(<span class="number">0</span>,paras_size-batch_size+<span class="number">1</span>,batch_size):</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            excerpt=indices[start_idx:start_idx+batch_size]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            excerpt=slice(start_idx,start_idx+batch_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> paras[excerpt],labels[excerpt]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯6</title>
      <link href="/2018/08/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D6/"/>
      <url>/2018/08/26/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D6/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£</p><h3 id="æˆä¸ºå…­ç»å¥"><a href="#æˆä¸ºå…­ç»å¥" class="headerlink" title="æˆä¸ºå…­ç»å¥"></a>æˆä¸ºå…­ç»å¥</h3><p>[å”] æœç”«<br>ã€å…¶äºŒã€‘<br>ç‹æ¨å¢éª†å½“æ—¶ä½“ï¼Œè½»è–„ä¸ºæ–‡å“‚æœªä¼‘ã€‚<br><strong>å°”æ›¹èº«ä¸åä¿±ç­ï¼Œä¸åºŸæ±Ÿæ²³ä¸‡å¤æµ</strong>ã€‚</p><p>å“‚ï¼ˆshÄ›nï¼‰ï¼šè®¥ç¬‘ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b9658c0a2b58005c95d2a7</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNNæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—</title>
      <link href="/2018/08/25/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/CNN%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8C%87%E5%8D%97/"/>
      <url>/2018/08/25/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/CNN%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘å› ä¸ºæ¯”èµ›çš„ç¼˜æ•…å¯¹æ–‡æœ¬åˆ†ç±»æœ‰ä¸€å®šçš„äº†è§£ã€‚å…¶ä¸­ä½¿ç”¨CNNæ–¹æ³•åšæƒ…æ„Ÿåˆ†æä»»åŠ¡å­˜åœ¨ç€è®¸å¤šä¼˜åŠ¿ã€‚è™½ç„¶æ¨¡å‹ç®€å•ï¼Œä½†å¦‚ä½•è®¾ç½®è¶…å‚æœ‰æ—¶å€™å¯¹ç»“æœæœ‰å¾ˆå¤§çš„å½±å“ã€‚æœ¬æ–‡è®°å½•äº†å…³äºCNNæ–‡æœ¬åˆ†ç±»çš„ä¸€äº›å­¦ä¹ å†ç¨‹å’ŒæŒ‡å—ï¼ŒåŸºæœ¬å‚è€ƒäº†è®ºæ–‡ã€‚</p><h2 id="åšæ³•"><a href="#åšæ³•" class="headerlink" title="åšæ³•"></a>åšæ³•</h2><p>åŸºæœ¬ä¸Šç›®å‰è¾ƒä¸ºæµ…å±‚çš„CNNæ–‡æœ¬åˆ†ç±»çš„åšæ³•éƒ½æ˜¯å¦‚ä¸‹å›¾ï¼š<br><img src="/images/2018-08-25-15351860103617.jpg" alt=""></p><p>å°†è¯å‘é‡å †ç§¯æˆä¸ºäºŒç»´çš„çŸ©é˜µï¼Œé€šè¿‡CNNçš„å·ç§¯å•å…ƒå¯¹çŸ©é˜µè¿›è¡Œå·ç§¯å¤„ç†ï¼ŒåŒæ—¶ä½¿ç”¨poolingï¼ˆé€šå¸¸æ˜¯1max-poolingï¼‰æ“ä½œï¼Œå°†ä¸ç­‰é•¿çš„å·ç§¯ç»“æœå˜ä¸ºç­‰é•¿ï¼Œå¯¹ä¸åŒçš„å·ç§¯å•å…ƒçš„ç»“æœè¿›è¡Œæ‹¼æ¥åç”Ÿæˆå•ä¸ªå‘é‡ï¼Œæœ€åå†é€šè¿‡çº¿æ€§å±‚è½¬åŒ–æˆç±»åˆ«æ¦‚ç‡åˆ†å¸ƒã€‚</p><p>å¦ä¸€å¼ å›¾ä¹Ÿè¯´æ˜äº†è¯¥æµç¨‹ã€‚</p><p><img src="/images/2018-08-25-15351863867337.jpg" alt=""></p><h2 id="å»ºè®®ä¸æŒ‡å¯¼"><a href="#å»ºè®®ä¸æŒ‡å¯¼" class="headerlink" title="å»ºè®®ä¸æŒ‡å¯¼"></a>å»ºè®®ä¸æŒ‡å¯¼</h2><h3 id="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"><a href="#è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“" class="headerlink" title="è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“"></a>è¶…å‚åŠå…¶å¯¹ç»“æœçš„å½±å“</h3><p>æ¥ä¸‹æ¥çš„å†…å®¹å‚è€ƒäº†è®ºæ–‡<a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p><p>CNNæ–‡æœ¬åˆ†ç±»çš„è¶…å‚ï¼š</p><ul><li>è¾“å…¥å‘é‡</li><li>å·ç§¯å¤§å°</li><li>è¾“å‡ºé€šé“ï¼ˆfeature mapsï¼‰</li><li>æ¿€æ´»å‡½æ•°</li><li>æ± åŒ–ç­–ç•¥</li><li>æ­£åˆ™åŒ–</li></ul><h4 id="è¾“å…¥å‘é‡çš„å½±å“"><a href="#è¾“å…¥å‘é‡çš„å½±å“" class="headerlink" title="è¾“å…¥å‘é‡çš„å½±å“"></a>è¾“å…¥å‘é‡çš„å½±å“</h4><p>å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨word2vecå’ŒGloVeä¸åˆ†ä¼¯ä»²ï¼Œä½†å°†word2vecå’ŒGloVeç®€å•æ‹¼æ¥åœ¨ä¸€èµ·å¹¶ä¸èƒ½å¸¦æ¥æå‡ã€‚</p><blockquote><p>unfortunately, simply concatenating these representations does necessarily seem helpful</p></blockquote><p>å½“å¥å­é•¿åº¦å¾ˆé•¿ï¼ˆdocument classificationï¼‰æ—¶ï¼Œä½¿ç”¨one-hotå¯èƒ½ä¼šæœ‰æ•ˆæœï¼Œä½†åœ¨å¥å­é•¿åº¦ä¸æ˜¯å¾ˆé•¿æ—¶ï¼Œæ•ˆæœä¸å¥½ã€‚</p><h5 id="å»ºè®®"><a href="#å»ºè®®" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>å¯¹äºæ–°ä»»åŠ¡ï¼Œå¯ä»¥word2vecæˆ–GloVeæˆ–è€…å…¶ä»–è¯å‘é‡éƒ½è¯•ä¸€ä¸‹ï¼Œå¦‚æœå¥å­é•¿ï¼Œå¯ä»¥è¯•ç€ä½¿ç”¨one-hotã€‚</p><h4 id="å·ç§¯å¤§å°"><a href="#å·ç§¯å¤§å°" class="headerlink" title="å·ç§¯å¤§å°"></a>å·ç§¯å¤§å°</h4><p>ç”±äºå·ç§¯çš„é•¿åº¦æ˜¯å›ºå®šçš„ï¼Œä¹Ÿå°±æ˜¯è¯å‘é‡çš„é•¿åº¦ï¼Œå› æ­¤åªéœ€è®¨è®ºå®½åº¦ã€‚<br>å®éªŒè¡¨æ˜ï¼Œä¸åŒçš„æ•°æ®é›†ä¼šæœ‰ä¸åŒçš„æœ€ä½³å¤§å°ï¼Œä½†ä¼¼ä¹å¯¹äºé•¿åº¦è¶Šé•¿çš„å¥å­ï¼Œæœ€ä½³å¤§å°æœ‰è¶Šå¤§çš„è¶‹åŠ¿ã€‚</p><blockquote><p>However, for datasets comprising longer sentences, such as CR (maximum sentence length is 105, whereas it ranges from 36-56 on the other sentiment datasets used here), the optimal region size may be larger.</p></blockquote><p>åŒæ—¶ï¼Œå½“å¢åŠ ä¸åŒå·ç§¯å¤§å°ä½œä¸ºç»„åˆæ—¶ï¼Œå¦‚æœç»„åˆçš„å·ç§¯æ ¸å¤§å°æ¥è¿‘äºæœ€ä½³å¤§å°ï¼ˆoptimal region sizeï¼‰ï¼Œæœ‰åŠ©äºç»“æœçš„æå‡ï¼›ç›¸åï¼Œå¦‚æœå·ç§¯æ ¸å¤§å°ç¦»æœ€ä½³å¤§å°å¾ˆè¿œæ—¶ï¼Œåè€Œä¼šäº§ç”Ÿè´Ÿé¢å½±å“ã€‚</p><h5 id="å»ºè®®-1"><a href="#å»ºè®®-1" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>é¦–å…ˆè¯•ç€æ‰¾åˆ°æœ€ä¼˜çš„å·ç§¯æ ¸å¤§å°ï¼Œç„¶ååœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ å’Œè¯¥å·ç§¯æ ¸å¤§å°ç±»ä¼¼çš„å·ç§¯æ ¸ã€‚</p><h4 id="feature-maps"><a href="#feature-maps" class="headerlink" title="feature maps"></a>feature maps</h4><p>ä¹Ÿå°±æ˜¯è¾“å‡ºé€šé“ï¼ˆout channelï¼‰ï¼Œè¡¨æ˜è¯¥å·ç§¯æ ¸å¤§å°çš„å·ç§¯æ ¸æœ‰å¤šå°‘ä¸ªã€‚</p><p>å®éªŒè¡¨æ˜ï¼Œæœ€ä½³çš„feature mapså’Œæ•°æ®é›†ç›¸å…³ï¼Œä½†ä¸€èˆ¬ä¸è¶…è¿‡600ã€‚</p><blockquote><p>it would seem that increasing the number of maps beyond 600 yields at best very marginal returns, and often hurts performance.</p></blockquote><h5 id="å»ºè®®-2"><a href="#å»ºè®®-2" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>åœ¨600å†…æœç´¢æœ€ä¼˜ï¼Œå¦‚æœåœ¨600çš„è¾¹ç¼˜è¿˜æ²¡æœ‰æ˜æ˜¾çš„æ•ˆæœä¸‹é™ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•å¤§äº600çš„feature mapsã€‚</p><h4 id="æ¿€æ´»å‡½æ•°"><a href="#æ¿€æ´»å‡½æ•°" class="headerlink" title="æ¿€æ´»å‡½æ•°"></a>æ¿€æ´»å‡½æ•°</h4><p>å®éªŒç»“æœï¼š<br><img src="/images/2018-08-25-15351889835594.jpg" alt=""></p><p>ç»“æœè¡¨æ˜ï¼Œtanhã€ReLUå’Œä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°æ•ˆæœè¾ƒå¥½ã€‚tanhçš„ä¼˜ç‚¹æ˜¯ä»¥0ä¸ºä¸­å¿ƒï¼ŒReLUèƒ½å¤ŸåŠ é€Ÿæ‹Ÿåˆï¼Œè‡³äºä¸ºä»€ä¹ˆä¸ä½¿ç”¨çš„æ•ˆæœä¼šå¥½ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹è¾ƒä¸ºç®€å•ï¼š</p><blockquote><p>This indicates that on some datasets, a linear transformation is enough to capture the<br>correlation between the word embedding and the output label.</p></blockquote><h5 id="å»ºè®®-3"><a href="#å»ºè®®-3" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>ä½¿ç”¨tanhã€ReLUæˆ–è€…å¹²è„†ä¸ä½¿ç”¨ã€‚ä½†å¦‚æœæ¨¡å‹æ›´ä¸ºå¤æ‚ï¼Œæœ‰å¤šå±‚çš„ç»“æ„ï¼Œè¿˜æ˜¯éœ€è¦ä½¿ç”¨æ¿€æ´»å‡½æ•°çš„ã€‚</p><h4 id="poolingç­–ç•¥"><a href="#poolingç­–ç•¥" class="headerlink" title="poolingç­–ç•¥"></a>poolingç­–ç•¥</h4><p>æ‰€æœ‰çš„å®éªŒéƒ½è¡¨æ˜äº†ï¼Œ1-max poolingçš„æ•ˆæœæ¯”å…¶ä»–å¥½ï¼Œå¦‚k-max poolingã€‚åœ¨poolingè¿™ä¸€æ­¥å¯ä»¥ç›´æ¥é€‰æ‹©1-max poolingã€‚</p><blockquote><p>This may be because the location of predictive contexts does not matter, and certain n-grams in the sentence can be more predictive on their own than the entire sentence considered jointly.</p></blockquote><h4 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h4><p>ä¸»è¦æ˜¯dropoutå’Œl2 norm constraintã€‚<br>dropoutå°±æ˜¯éšæœºå°†ä¸€äº›ç¥ç»å…ƒç½®ä¸º0ï¼Œl2 norm constraintæ˜¯å¯¹å‚æ•°çŸ©é˜µWè¿›è¡Œæ•´ä½“ç¼©æ”¾ï¼Œä½¿å…¶ä¸è¶…è¿‡ä¸€å®šé˜ˆå€¼ã€‚ï¼ˆä¸é€šå¸¸çš„l2 regularizationä¸åŒï¼Œæœ€æ—©å¯è¿½æº¯åˆ°Hintonçš„<a href="https://arxiv.org/pdf/1207.0580.pdf" target="_blank" rel="noopener">Improving neural networks by preventing<br>co-adaptation of feature detectors</a>ï¼‰</p><blockquote><p>the l2 norm of a weight vector is linearly scaled to a constraint c when it exceeds this threshold, so a smaller c implies stronger regularization</p></blockquote><p>å®éªŒè¡¨æ˜ï¼Œdropoutèµ·çš„ä½œç”¨å¾ˆå°ï¼Œl2 normæ²¡æœ‰æå‡ç”šè‡³è¿˜ä¼šå¯¼è‡´ä¸‹é™ã€‚å¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å‚æ•°ä¸å¤šï¼Œå› æ­¤è¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§è¾ƒä½ã€‚</p><h5 id="å»ºè®®-4"><a href="#å»ºè®®-4" class="headerlink" title="å»ºè®®"></a>å»ºè®®</h5><p>è®¾ç½®è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„l2 normï¼Œå½“feature mapså¢å¤§æ—¶ï¼Œå¯ä»¥è¯•ç€è°ƒèŠ‚è¾ƒå¤§çš„dropoutä»¥é¿å…è¿‡æ‹Ÿåˆã€‚</p><h3 id="å»ºè®®åŠç»“è®º"><a href="#å»ºè®®åŠç»“è®º" class="headerlink" title="å»ºè®®åŠç»“è®º"></a>å»ºè®®åŠç»“è®º</h3><ul><li>åˆšå¼€å§‹çš„ä½¿ç”¨ä½¿ç”¨word2vecæˆ–è€…GloVeï¼Œå¦‚æœæ•°æ®é‡å¤Ÿå¤§ï¼Œå¯ä»¥å°è¯•one-hot</li><li>çº¿æ€§æœç´¢æœ€ä½³çš„å·ç§¯æ ¸å¤§å°ï¼Œå¦‚æœå¥å­å¤Ÿé•¿ï¼Œé‚£ä¹ˆå¯ä»¥æ‰©å¤§æœç´¢èŒƒå›´ã€‚ä¸€æ—¦ç¡®å®šäº†æœ€ä½³å·ç§¯æ ¸å¤§å°ï¼Œå°è¯•åœ¨è¯¥å·ç§¯æ ¸å¤§å°çš„é™„è¿‘è¿›è¡Œç»„åˆï¼Œå¦‚æœ€ä½³å·ç§¯æ ¸å®½åº¦æ˜¯5ï¼Œé‚£ä¹ˆå°è¯•[3,4,5]æˆ–è€…[2,3,4,5]ç­‰</li><li>ä½¿ç”¨è¾ƒå°çš„dropoutå’Œè¾ƒå¤§çš„max norm constraintï¼Œç„¶ååœ¨[100,600]èŒƒå›´å†…æœç´¢feature mapsï¼Œå¦‚æœæœ€ä½³çš„feature mapsåœ¨600é™„è¿‘ï¼Œå¯ä»¥è¯•ç€é€‰æ‹©æ¯”600æ›´å¤§çš„èŒƒå›´</li><li>å°è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸tanhå’ŒReLUæ˜¯è¾ƒå¥½çš„ï¼Œä½†ä¹Ÿå¯ä»¥å°è¯•ä»€ä¹ˆéƒ½ä¸åŠ ã€‚</li><li>ä½¿ç”¨1-max poolingã€‚</li><li>å¦‚æœæ¨¡å‹å¤æ‚ï¼Œæ¯”å¦‚feature mapså¾ˆå¤§ï¼Œé‚£ä¹ˆå¯ä»¥å°è¯•æ›´ä¸ºä¸¥æ ¼çš„æ­£åˆ™åŒ–ï¼Œå¦‚æ›´å¤§çš„dropout rateå’Œè¾ƒå°çš„max norm constraintã€‚</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://www.aclweb.org/anthology/D14-1181" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></p><p><a href="https://arxiv.org/pdf/1510.03820.pdf" target="_blank" rel="noopener">A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional<br>Neural Networks for Sentence Classification</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> æƒ…æ„Ÿåˆ†æ </tag>
            
            <tag> æŒ‡å— </tag>
            
            <tag> è°ƒå‚ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­çš„inplaceçš„æ“ä½œ</title>
      <link href="/2018/08/20/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADin-place%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/08/20/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADin-place%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>æœ€è¿‘åœ¨å†™Hierarchical attention networkçš„æ—¶å€™é‡åˆ°äº†å¦‚ä¸‹çš„bugï¼š</p><blockquote><p>one of the variables needed for gradient computation has been modified by an inplace operation</p></blockquote><p>åœ¨æŸ¥é˜…äº†æ–‡æ¡£å’Œè¯·æ•™äº†å…¶ä»–äººä¹‹åï¼Œæœ€ç»ˆæ‰¾åˆ°äº†bugã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze_(<span class="number">1</span>)  <span class="comment"># take in-place opt may cause an error</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure><p>è¿™æ˜¯æˆ‘åŸæ¥çš„é€»è¾‘ï¼Œæˆ‘åœ¨æ— æ„ä¸­åšäº†inplaceæ“ä½œï¼Œå¯¼è‡´äº†bugçš„å‘ç”Ÿã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_len):</span><br><span class="line">    h_i = rnn_outputs[i]  <span class="comment"># batch,hidden*2</span></span><br><span class="line">    <span class="comment"># a_i = attn_weights[i].unsqueeze_(1)  # take in-place opt may cause an error</span></span><br><span class="line">    a_i = attn_weights[i].unsqueeze(<span class="number">1</span>)  <span class="comment"># batch,1</span></span><br><span class="line">    a_i = a_i.expand_as(h_i)  <span class="comment"># batch,hidden*2</span></span><br></pre></td></tr></table></figure><p>å®é™…ä¸Šï¼Œåœ¨å®è·µè¿‡ç¨‹ä¸­åº”å½“å°½é‡é¿å…inplaceæ“ä½œï¼Œåœ¨å®˜æ–¹æ–‡æ¡£ä¸­ä¹Ÿæåˆ°äº†ï¼ˆå­˜ç–‘ï¼‰è¿™ç‚¹ï¼Œè™½ç„¶æä¾›äº†inplaceæ“ä½œï¼Œä½†å¹¶ä¸æ¨èä½¿ç”¨ã€‚</p><p>å…·ä½“çš„åŸå› æ˜¯ï¼Œåœ¨Pytorchæ„å»ºè®¡ç®—å›¾çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®°å½•æ¯ä¸ªèŠ‚ç‚¹æ˜¯æ€ä¹ˆæ¥çš„ï¼Œä½†inplaceä¼šç ´åè¿™ç§å…³ç³»ï¼Œä½¿å¾—åœ¨å›ä¼ çš„æ—¶å€™æ²¡æ³•æ­£å¸¸æ±‚å¯¼ã€‚</p><p>ç‰¹åˆ«åœ°ï¼Œæœ‰ä¸¤ç§æƒ…å†µä¸åº”è¯¥ä½¿ç”¨inplaceæ“ä½œï¼ˆæ‘˜è‡ªçŸ¥ä¹ï¼‰ï¼š</p><ol><li>å¯¹äºrequires_grad=Trueçš„å¶å­å¼ é‡(leaf tensor)ä¸èƒ½ä½¿ç”¨inplace operation</li><li>å¯¹äºåœ¨æ±‚æ¢¯åº¦é˜¶æ®µéœ€è¦ç”¨åˆ°çš„å¼ é‡ä¸èƒ½ä½¿ç”¨inplace operation</li></ol><p>Reference:<br><a href="https://zhuanlan.zhihu.com/p/38475183" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38475183</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”</title>
      <link href="/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%84%BF%E4%B8%AD%E5%9B%BD%E9%9D%92%E5%B9%B4%E9%83%BD%E6%91%86%E8%84%B1%E5%86%B7%E6%B0%94/"/>
      <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%84%BF%E4%B8%AD%E5%9B%BD%E9%9D%92%E5%B9%B4%E9%83%BD%E6%91%86%E8%84%B1%E5%86%B7%E6%B0%94/</url>
      
        <content type="html"><![CDATA[<p>è¿‘æœŸçš„æ–°é—»å¸¸è®©äººæ„Ÿåˆ°æ„¤æ€’ä»¥è‡´ç»æœ›â€¦</p><hr><p>æ„¿ä¸­å›½é’å¹´éƒ½æ‘†è„±å†·æ°”ï¼Œåªæ˜¯å‘ä¸Šèµ°ï¼Œä¸å¿…å¬è‡ªæš´è‡ªå¼ƒè€…æµçš„è¯ã€‚èƒ½åšäº‹çš„åšäº‹ï¼Œèƒ½å‘å£°çš„å‘å£°ã€‚æœ‰ä¸€åˆ†çƒ­ï¼Œå‘ä¸€åˆ†å…‰ã€‚å°±ä»¤è¤ç«ä¸€èˆ¬ï¼Œä¹Ÿå¯ä»¥åœ¨é»‘æš—é‡Œå‘ä¸€ç‚¹å…‰ï¼Œä¸å¿…ç­‰å€™ç‚¬ç«ã€‚</p><p>â€”é²è¿…ã€Šçƒ­é£ã€‹</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•5</title>
      <link href="/2018/08/19/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB5/"/>
      <url>/2018/08/19/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB5/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"><a href="#1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤" class="headerlink" title="1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤"></a>1ï¸âƒ£sklearnæ¨¡å‹çš„ä¿å­˜ä¸æ¢å¤</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">clf = svm.SVC()</span><br><span class="line">clf.fit(X, y)  </span><br><span class="line">clf.fit(train_X,train_y)</span><br><span class="line">joblib.dump(clf, <span class="string">"train_model.m"</span>)</span><br><span class="line">clf = joblib.load(<span class="string">"train_model.m"</span>)</span><br><span class="line">clf.predit(test_X)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£Dictionaryç±»"><a href="#2ï¸âƒ£Dictionaryç±»" class="headerlink" title="2ï¸âƒ£Dictionaryç±»"></a>2ï¸âƒ£Dictionaryç±»</h3><p>åœ¨æ„é€ å­—å…¸æ—¶éœ€è¦ç”¨åˆ°<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)</span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_word</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            self.idx2word.append(word)</span><br><span class="line">            self.word2idx[word] = self.__vocab_size</span><br><span class="line">            self.__vocab_size += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__vocab_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_index</span><span class="params">(self, word)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> self.word2idx:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[word]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.word2idx[<span class="string">'&lt;UNK&gt;'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_word</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.idx2word[idx]</span><br></pre></td></tr></table></figure></p><hr><h3 id="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"><a href="#3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•"></a>3ï¸âƒ£å¯¹dictæŒ‰å…ƒç´ æ’åºçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;<span class="string">'apple'</span>:<span class="number">10</span>,<span class="string">'orange'</span>:<span class="number">20</span>,<span class="string">'banana'</span>:<span class="number">5</span>,<span class="string">'watermelon'</span>:<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line">print(sorted(d.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"></span><br><span class="line">print(sorted(d.items(),key=itemgetter(<span class="number">1</span>))) <span class="comment">#[('watermelon', 1), ('banana', 5), ('apple', 10), ('orange', 20)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"></span><br><span class="line">print(sorted(d,key=d.get))  <span class="comment">#['watermelon', 'banana', 'apple', 'orange'] æ²¡æœ‰valueäº†</span></span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"><a href="#4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•" class="headerlink" title="4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•"></a>4ï¸âƒ£åˆå¹¶dictçš„ä¸‰ç§æ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1=&#123;<span class="string">'a'</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d2=&#123;<span class="string">'b'</span>:<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d=&#123;**d1,**d2&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd=dict(d1.items()|d2.items())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#æ³•3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1.update(d2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d1</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"><a href="#5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index" class="headerlink" title="5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index"></a>5ï¸âƒ£æ‰¾åˆ°listæœ€å¤§æœ€å°å€¼çš„index</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lst = [<span class="number">40</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> min(range(len(lst)),key=lst.__getitem__)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxIndex</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> max(range(len(lst)),key=lst.__getitem__)</span><br><span class="line">    </span><br><span class="line">print(minIndex(lst))</span><br><span class="line">print(maxIndex(lst))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­çš„Embedding padding</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADEmbedding%E7%9A%84padding/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADEmbedding%E7%9A%84padding/</url>
      
        <content type="html"><![CDATA[<p>åœ¨Pytorchä¸­ï¼Œnn.Embedding()ä»£è¡¨embeddingçŸ©é˜µï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªå‚æ•°<code>padding_idx</code>æŒ‡å®šç”¨ä»¥paddingçš„ç´¢å¼•ä½ç½®ã€‚æ‰€è°“paddingï¼Œå°±æ˜¯åœ¨å°†ä¸ç­‰é•¿çš„å¥å­ç»„æˆä¸€ä¸ªbatchæ—¶ï¼Œå¯¹é‚£äº›ç©ºç¼ºçš„ä½ç½®è¡¥0ï¼Œä»¥å½¢æˆä¸€ä¸ªç»Ÿä¸€çš„çŸ©é˜µã€‚</p><p>ç”¨æ³•ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.embedding = nn.Embedding(vocab_size, embed_dim,padding_idx=<span class="number">0</span>) <span class="comment">#ä¹Ÿå¯ä»¥æ˜¯åˆ«çš„æ•°å€¼</span></span><br></pre></td></tr></table></figure></p><p>åœ¨æ˜¾å¼è®¾å®š<code>padding_idx=0</code>åï¼Œåœ¨è‡ªå®šä¹‰çš„è¯å…¸å†…ä¹Ÿåº”å½“åœ¨ç›¸åº”ä½ç½®æ·»åŠ <code>&lt;pad&gt;</code>ä½œä¸ºä¸€ä¸ªè¯ã€‚å¦‚ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dictionary</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.idx2word = []</span><br><span class="line">        self.__vocab_size = <span class="number">0</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;pad&gt;'</span>)  <span class="comment"># should add &lt;pad&gt; first</span></span><br><span class="line">        self.add_word(<span class="string">'&lt;UNK&gt;'</span>)</span><br></pre></td></tr></table></figure><p>é‚£ä¹ˆå¯¹äº<code>padding_idx</code>ï¼Œå†…éƒ¨æ˜¯å¦‚ä½•æ“ä½œçš„å‘¢ï¼Ÿ</p><p>åœ¨æŸ¥çœ‹äº†Embeddingçš„æºç åï¼Œå‘ç°è®¾ç½®äº†<code>padding_idx</code>ï¼Œç±»å†…éƒ¨ä¼šæœ‰å¦‚ä¸‹æ“ä½œï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-----Embedding __init__ å†…éƒ¨--------------</span></span><br><span class="line"><span class="keyword">if</span> _weight <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">    self.weight = Parameter(torch.Tensor(num_embeddings, embedding_dim))</span><br><span class="line">    self.reset_parameters()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#---------reset_parameters()--------</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset_parameters</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.weight.data.normal_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> self.padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        self.weight.data[self.padding_idx].fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“Embeddingæ˜¯éšæœºåˆå§‹åŒ–çš„çŸ©é˜µæ—¶ï¼Œä¼šå¯¹<code>padding_idx</code>æ‰€åœ¨çš„è¡Œè¿›è¡Œå¡«0ã€‚ä¿è¯äº†paddingè¡Œä¸ºçš„æ­£ç¡®æ€§ã€‚</p><p>é‚£ä¹ˆï¼Œè¿˜éœ€è¦ä¿è¯ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨åå‘å›ä¼ çš„æ—¶å€™ï¼Œ<code>padding_idx</code>æ˜¯ä¸ä¼šæ›´æ–°çš„.</p><p>åœ¨æŸ¥çœ‹äº†æºç åå‘ç°åœ¨Embeddingç±»å†…æœ‰å¦‚ä¸‹æ³¨é‡Šï¼š</p><blockquote><p>.. note::<br>        With :attr:<code>padding_idx</code> set, the embedding vector at<br>        :attr:<code>padding_idx</code> is initialized to all zeros. However, note that this<br>        vector can be modified afterwards, e.g., using a customized<br>        initialization method, and thus changing the vector used to pad the<br>        output. The gradient for this vector from :class:<code>~torch.nn.Embedding</code><br>        is always zero.</p></blockquote><p>å¹¶ä¸”åœ¨æŸ¥é˜…äº†å…¶ä»–èµ„æ–™åï¼Œå‘ç°è¯¥è¡Œç¡®å®ä¼šä¸æ›´æ–°ã€‚æœ‰æ„æ€çš„æ˜¯ï¼ŒæŸ¥é˜…æºç å¹¶æ²¡æœ‰æ‰¾åˆ°å¦‚ä½•ä½¿å…¶ä¸æ›´æ–°çš„æœºåˆ¶ï¼Œå› ä¸ºåœ¨F.embeddingå‡½æ•°ä¸­ï¼Œè¿”å›ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure><p>ä½†æˆ‘å¹¶ä¸èƒ½è·³è½¬åˆ°torch.embeddingä¸­ï¼Œå¤§æ¦‚æ˜¯å› ä¸ºè¿™éƒ¨åˆ†è¢«éšè—äº†å§ã€‚æˆ‘ä¹Ÿæ²¡æœ‰å†æ·±ç©¶ä¸‹å»ã€‚æˆ‘çŒœæµ‹æœ‰å¯èƒ½æ˜¯åœ¨autogradå†…éƒ¨æœ‰å¯¹è¯¥éƒ¨åˆ†è¿›è¡Œå•ç‹¬çš„å¤„ç†ï¼Œç”¨maskå±è”½è¿™éƒ¨åˆ†çš„æ›´æ–°ï¼›æˆ–è€…ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•ï¼Œå°±æ˜¯ä»»å…¶æ›´æ–°ï¼Œä½†æ¯ä¸€æ¬¡éƒ½resetï¼Œå°†ç¬¬ä¸€è¡Œæ‰‹åŠ¨è®¾ä¸ºå…¨0ã€‚</p><p><strong>é™„è®°</strong>ï¼š</p><p>å‡å¦‚è¯´æ²¡æœ‰æ˜¾å¼è®¾ç½®è¯¥è¡Œï¼Œæ˜¯å¦paddingå°±æ²¡æœ‰æ•ˆæœå‘¢ï¼Ÿ<br>æˆ‘è®¤ä¸ºæ˜¯çš„ã€‚</p><p>ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬éƒ½æ˜¯ä»¥0ä½œä¸ºpaddingçš„å¡«å……ï¼Œå¦‚ï¼š</p><div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>12</td><td>44</td><td>22</td><td>67</td><td>85</td></tr><tr><td>12</td><td>13</td><td>534</td><td>31</td><td>0</td></tr><tr><td>87</td><td>23</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div><p>æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªå¥å­ï¼Œå…¶ä¸­0ä½œä¸ºå¡«å……ã€‚ç„¶åå°†è¯¥çŸ©é˜µé€å…¥åˆ°embedding_lookupä¸­ï¼Œè·å¾—ä¸‰ç»´çš„tensorï¼Œé‚£ä¹ˆ0å¡«å……çš„éƒ¨åˆ†ï¼Œæ‰€è·å¾—çš„embeddingè¡¨ç¤ºåº”å½“æ˜¯è¦å…¨0ã€‚</p><p>å‡å¦‚ä¸æ˜¾å¼è®¾ç½®<code>padding_idx=0</code>ï¼Œå°±å¯èƒ½ä¼šå‡ºç°ä¸¤ä¸ªç»“æœï¼ˆä¸ªäººæ¨æµ‹)ï¼š</p><p>â‘ æœ¬åº”è¯¥å…¨0çš„åœ°æ–¹ï¼Œè¢«è¯å…¸ä¸­ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡è¡¨ç¤ºç»™æ›¿ä»£äº†ï¼Œå› ä¸ºå°†0ä½œä¸ºç´¢å¼•å»embeddingçŸ©é˜µè·å–åˆ°çš„è¯å‘é‡ï¼Œå°±æ˜¯ç¬¬ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼Œè€Œè¯¥è¯å¹¶ä¸å…¨0ã€‚</p><p>â‘¡è¯å…¸çš„æœ€åä¸€ä¸ªè¯è¢«å…¨0è¦†ç›–ã€‚F.embeddingä¸­æœ‰å¦‚ä¸‹ç‰‡æ®µï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> padding_idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">    <span class="keyword">if</span> padding_idx &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &lt; weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">    <span class="keyword">elif</span> padding_idx &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">assert</span> padding_idx &gt;= -weight.size(<span class="number">0</span>), <span class="string">'Padding_idx must be within num_embeddings'</span></span><br><span class="line">        padding_idx = weight.size(<span class="number">0</span>) + padding_idx</span><br><span class="line"><span class="keyword">elif</span> padding_idx <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        padding_idx = <span class="number">-1</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢ç‰‡æ®µæ˜¾ç¤ºï¼Œ<code>padding_idx</code>è¢«è®¾ç½®ä¸º-1ï¼Œä¹Ÿå°±æ˜¯æœ€åä¸€ä¸ªå•è¯ã€‚åšå®Œè¿™æ­¥ç´§æ¥ç€å°±è¿”å›ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)</span><br></pre></td></tr></table></figure><p>è¿˜æ˜¯ç”±äºtorch.embeddingæ— æ³•æŸ¥çœ‹çš„åŸå› ï¼Œæˆ‘ä¸çŸ¥é“å†…éƒ¨æ˜¯å¦‚ä½•å®ç°çš„ï¼Œä½†åº”è¯¥æ¥è¯´ï¼Œæœ€åä¸€ä¸ªè¯å°±æ˜¯è¢«è¦†ç›–äº†ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Embedding </tag>
            
            <tag> padding </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python Tricks[è½¬]</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%20Tricks%5B%E8%BD%AC%5D/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%20Tricks%5B%E8%BD%AC%5D/</url>
      
        <content type="html"><![CDATA[<p>åŸæ–‡åœ°å€:<a href="https://hackernoon.com/python-tricks-101-2836251922e0" target="_blank" rel="noopener">https://hackernoon.com/python-tricks-101-2836251922e0</a></p><p>æˆ‘è§‰å¾—è¿™ä¸ªä»‹ç»Pythonä¸€äº›tricksçš„æ–‡ç« å¾ˆå¥½ï¼Œèƒ½å¤Ÿæ›´åŠ ç†Ÿæ‚‰Pythonçš„ä¸€äº›éå¸¸æ–¹ä¾¿çš„ç”¨æ³•ã€‚<br>ä»¥ä¸‹æ˜¯æˆ‘è§‰å¾—æœ‰ç”¨çš„å‡ ä¸ªç‚¹ã€‚</p><p>1ï¸âƒ£Reverse a String/List</p><p><img src="/images/2018-08-19-15346465152976.jpg" width="70%" height="50%"></p><p><img src="/images/2018-08-19-15346467215597.jpg" width="70%" height="50%"></p><p>[::-1]è§£é‡Šï¼š<br>[:]è¡¨ç¤ºå–æ‰€æœ‰çš„å…ƒç´ ï¼Œ-1è¡¨ç¤ºæ­¥è¿›ã€‚[1:5:2]è¡¨ç¤ºçš„å°±æ˜¯ä»å…ƒç´ 1åˆ°å…ƒç´ 5ï¼Œæ¯2ä¸ªè·ç¦»å–ä¸€ä¸ªã€‚</p><hr><p>2ï¸âƒ£transpose 2d array</p><p><img src="/images/2018-08-19-15346470165919.jpg" width="70%" height="50%"></p><p>zip()ç›¸å½“äºå‹ç¼©ï¼Œzip(*)ç›¸å½“äºè§£å‹ã€‚</p><hr><p>3ï¸âƒ£Chained function call</p><p><img src="/images/2018-08-19-15346471756442.jpg" width="70%" height="50%"></p><p>éå¸¸ç®€æ´çš„å†™æ³•ã€‚</p><hr><p>4ï¸âƒ£Copy List</p><p><img src="/images/2018-08-19-15346472744350.jpg" width="50%" height="50%"></p><p>ä¹‹å‰è°ˆè¿‡çš„Pythonçš„èµ‹å€¼ã€æµ…æ‹·è´ã€æ·±æ‹·è´ã€‚</p><hr><p>5ï¸âƒ£Dictionary get</p><p><img src="/images/2018-08-19-15346473929918.jpg" width="70%" height="50%"></p><p>é¿å…äº†dictä¸å­˜åœ¨è¯¥å…ƒç´ çš„é—®é¢˜ã€‚</p><hr><p>6ï¸âƒ£âœ¨Sort Dictionary by Value</p><p><img src="/images/2018-08-19-15346475170316.jpg" width="90%" height="50%"></p><p>å…¶ä¸­ç¬¬ä¸‰ç§è¿”å›çš„æ˜¯[â€˜watermelonâ€™, â€˜bananaâ€™, â€˜appleâ€™, â€˜orangeâ€™]ï¼Œæ²¡æœ‰valueäº†ã€‚</p><hr><p>7ï¸âƒ£Forâ€¦else</p><p><img src="/images/2018-08-19-15346481408714.jpg" width="90%" height="50%"></p><p>æ³¨æ„åˆ°å¦‚æœforåœ¨ä¸­é€”breakäº†ï¼Œå°±ä¸ä¼šè¿›å…¥åˆ°elseäº†ï¼›åªæœ‰é¡ºåˆ©å¾ªç¯å®Œæ‰ä¼šè¿›å…¥åˆ°elseã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> e==<span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span><span class="comment">#ä»€ä¹ˆéƒ½æ²¡æœ‰print</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    print(e)</span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'hello'</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure><hr><p>8ï¸âƒ£Merge dictâ€™s</p><p><img src="/images/2018-08-19-15346483785515.jpg" width="90%" height="50%"></p><p>åˆå¹¶dictçš„æ–¹æ³•ã€‚</p><hr><p>9ï¸âƒ£Min and Max index in List</p><p><img src="/images/2018-08-19-15346487918895.jpg" width="80%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Python tricks </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†4</title>
      <link href="/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%864/"/>
      <url>/2018/08/19/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%864/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[æ¦‚ç‡æ ¡å‡†(Probability Calibration)]<br>ä¸€ç§å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¾“å‡ºç»“æœçš„æ ¡å‡†ï¼Œé€šè¿‡å‡ ä¸ªå®éªŒå¯ä»¥å‘ç°ï¼Œæ¦‚ç‡æ ¡å‡†èƒ½å¤Ÿä¸€å®šç¨‹åº¦æé«˜è¡¨ç°ã€‚<br>å‡ ä¸ªå‚è€ƒèµ„æ–™ï¼š<br>ç›´è§‚ç†è§£:  <a href="http://www.bubuko.com/infodetail-2133893.html" target="_blank" rel="noopener">http://www.bubuko.com/infodetail-2133893.html</a><br>SVCçš„æ¦‚ç‡æ ¡å‡†åœ¨sklearnä¸Šçš„åº”ç”¨: <a href="https://blog.csdn.net/ericcchen/article/details/79337716" target="_blank" rel="noopener">https://blog.csdn.net/ericcchen/article/details/79337716</a><br>âœ¨å®Œå…¨æ‰‹å†Œ: <a href="http://users.dsic.upv.es/~flip/papers/BFHRHandbook2010.pdf" target="_blank" rel="noopener">Calibration of Machine Learning Models</a></p><hr><p>2ï¸âƒ£[Paper]<br><a href="https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf" target="_blank" rel="noopener">Hierarchical Attention Networks for Document Classification</a></p><p>äº®ç‚¹åœ¨ä½¿ç”¨å±‚æ¬¡çš„RNNç»“æ„ï¼Œä»¥åŠä½¿ç”¨äº†attentionæ–¹æ³•ã€‚<br><img src="/images/2018-08-19-15346447273228.jpg" width="50%" height="50%"></p><p>å‚è€ƒäº†å…¶ä»–äººçš„ä»£ç è‡ªå·±ä¹Ÿè¯•ç€å®ç°äº†ä¸€ä¸ªï¼ŒGitHubåœ°å€ï¼š<a href="https://github.com/linzehui/pytorch-hierarchical-attention-network" target="_blank" rel="noopener">https://github.com/linzehui/pytorch-hierarchical-attention-network</a></p><hr><p>3ï¸âƒ£[XGBoost]<br>kaggleç¥å™¨XGBoostï¼Œä¸€ç¯‡åŸç†çš„è¯¦ç»†ä»‹ç»ï¼š<br><a href="http://www.cnblogs.com/willnote/p/6801496.html" target="_blank" rel="noopener">http://www.cnblogs.com/willnote/p/6801496.html</a><br>è™½ç„¶è¿˜æ˜¯æœ‰å¥½äº›åœ°æ–¹æ²¡ææ‡‚ï¼Œæœ‰å¿…è¦ä»å¤´å­¦èµ·ã€‚</p><hr><p>4ï¸âƒ£[Python]<br>å…³äºå‡½æ•°åˆ—è¡¨ä¸­å•æ˜Ÿå·(*)å’ŒåŒæ˜Ÿå·(**)<br>å•æ˜Ÿå·ï¼š</p><ul><li>ä»£è¡¨æ¥æ”¶ä»»æ„å¤šä¸ªéå…³é”®å­—å‚æ•°ï¼Œå°†å…¶è½¬æ¢æˆå…ƒç»„ï¼š</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one</span><span class="params">(a,*b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šä¼ å…¥å‚æ•°ï¼Œ*bæ˜¯ä¸€ä¸ªéå…³é”®å­—æ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">one(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="comment">#è¾“å‡ºï¼š(2, 3, 4, 5, 6)</span></span><br></pre></td></tr></table></figure><ul><li>å¯¹ä¸€ä¸ªæ™®é€šå˜é‡ä½¿ç”¨å•æ˜Ÿå·ï¼Œè¡¨ç¤ºå¯¹è¯¥å˜é‡æ‹†åˆ†æˆå•ä¸ªå…ƒç´ </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    print(a,b)</span><br><span class="line">l=[<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">fun(*l)  <span class="comment">#è¾“å‡º 1,2</span></span><br></pre></td></tr></table></figure><p>åŒæ˜Ÿå·ï¼š</p><ul><li>è·å¾—å­—å…¸å€¼</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">two</span><span class="params">(a=<span class="number">1</span>,**b)</span>:</span></span><br><span class="line">    <span class="string">"""aæ˜¯ä¸€ä¸ªæ™®é€šå…³é”®å­—å‚æ•°ï¼Œ**bæ˜¯ä¸€ä¸ªå…³é”®å­—åŒæ˜Ÿå·å‚æ•°"""</span></span><br><span class="line">    print(b)</span><br><span class="line">two(a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span>,d=<span class="number">4</span>,e=<span class="number">5</span>,f=<span class="number">6</span>)  <span class="comment">#è¾“å‡º&#123;'b': 2, 'c': 3, 'e': 5, 'f': 6, 'd': 4&#125;</span></span><br></pre></td></tr></table></figure><hr><p>5ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œåªè¦ä¸€ä¸ªtensorçš„requires_gradæ˜¯trueï¼Œé‚£ä¹ˆä¸¤ä¸ªtensorçš„åŠ å‡ä¹˜é™¤åçš„ç»“æœçš„requires_gradä¹Ÿä¼šæ˜¯trueã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Paper </tag>
            
            <tag> æ¦‚ç‡æ ¡å‡† </tag>
            
            <tag> Probability Calibration </tag>
            
            <tag> HAN </tag>
            
            <tag> XGBoost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯5</title>
      <link href="/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D5/"/>
      <url>/2018/08/19/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D5/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨å¤ªå¿™äº†ï¼Œæ²¡èƒŒä»€ä¹ˆè¯—è¯ï¼ŒåªèƒŒï¼ˆå¤ä¹ ï¼‰äº†éƒ¨åˆ†çš„ã€Šæ»•ç‹é˜åºã€‹ã€‚</p><p>1ï¸âƒ£</p><h3 id="æ»•ç‹é˜åº"><a href="#æ»•ç‹é˜åº" class="headerlink" title="æ»•ç‹é˜åº"></a>æ»•ç‹é˜åº</h3><p>å—Ÿä¹ï¼æ—¶è¿ä¸é½ï¼Œå‘½é€”å¤šèˆ›ã€‚å†¯å”æ˜“è€ï¼Œæå¹¿éš¾å°ã€‚å±ˆè´¾è°Šäºé•¿æ²™ï¼Œéæ— åœ£ä¸»ï¼›çªœæ¢é¸¿äºæµ·æ›²ï¼Œå²‚ä¹æ˜æ—¶ï¼Ÿæ‰€èµ–<strong>å›å­è§æœºï¼Œè¾¾äººçŸ¥å‘½</strong>ã€‚è€å½“ç›Šå£®ï¼Œå®ç§»ç™½é¦–ä¹‹å¿ƒï¼Ÿ<strong>ç©·ä¸”ç›Šåšï¼Œä¸å é’äº‘ä¹‹å¿—</strong>ã€‚é…Œè´ªæ³‰è€Œè§‰çˆ½ï¼Œå¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ã€‚<strong>åŒ—æµ·è™½èµŠï¼Œæ‰¶æ‘‡å¯æ¥ï¼›ä¸œéš…å·²é€ï¼Œæ¡‘æ¦†éæ™šã€‚</strong>å­Ÿå°é«˜æ´ï¼Œç©ºé¦€æŠ¥å›½ä¹‹æƒ…ï¼›é˜®ç±çŒ–ç‹‚ï¼Œå²‚æ•ˆç©·é€”ä¹‹å“­ï¼</p><p>å‹ƒï¼Œä¸‰å°ºå¾®å‘½ï¼Œä¸€ä»‹ä¹¦ç”Ÿã€‚æ— è·¯è¯·ç¼¨ï¼Œç­‰ç»ˆå†›ä¹‹å¼±å† ï¼›æœ‰æ€€æŠ•ç¬”ï¼Œæ…•å®—æ…¤ä¹‹é•¿é£ã€‚èˆç°ªç¬äºç™¾é¾„ï¼Œå¥‰æ™¨æ˜äºä¸‡é‡Œã€‚éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ã€‚ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼›ä»Šå…¹æ§è¢‚ï¼Œå–œæ‰˜é¾™é—¨ã€‚æ¨æ„ä¸é€¢ï¼ŒæŠšå‡Œäº‘è€Œè‡ªæƒœï¼›é”ºæœŸæ—¢é‡ï¼Œå¥æµæ°´ä»¥ä½•æƒ­ï¼Ÿ</p><hr><p><strong>æ³¨é‡Šï¼š</strong><br>å†¯å”ï¼šè¥¿æ±‰äººï¼Œæœ‰æ‰èƒ½å´ä¸€ç›´ä¸å—é‡ç”¨ã€‚æ±‰æ­¦å¸æ—¶é€‰æ±‚è´¤è‰¯ï¼Œæœ‰äººä¸¾èå†¯å”ï¼Œå¯æ˜¯ä»–å·²ä¹åå¤šå²ï¼Œéš¾å†åšå®˜äº†ã€‚æå¹¿ï¼šæ±‰æ­¦å¸æ—¶çš„åå°†ï¼Œå¤šå¹´æŠ—å‡»åŒˆå¥´ï¼Œå†›åŠŸå¾ˆå¤§ï¼Œå´ç»ˆèº«æ²¡æœ‰å°ä¾¯ã€‚</p><p>è´¾è°Šï¼šæ±‰æ–‡å¸æœ¬æƒ³ä»»è´¾è°Šä¸ºå…¬å¿ï¼Œä½†å› æœä¸­æƒè´µåå¯¹ï¼Œå°±ç–è¿œäº†è´¾è°Šï¼Œä»»ä»–ä¸ºé•¿æ²™ç‹å¤ªå‚…ã€‚æ¢é¸¿ï¼šä¸œæ±‰äººï¼Œå› ä½œè¯—è®½åˆºå›ç‹ï¼Œå¾—ç½ªäº†æ±‰ç« å¸ï¼Œè¢«è¿«é€ƒåˆ°é½é²ä¸€å¸¦èº²é¿ã€‚</p><p>é…Œï¼ˆzhuÃ³ï¼‰è´ªæ³‰è€Œè§‰çˆ½ï¼šå–ä¸‹è´ªæ³‰çš„æ°´ï¼Œä»è§‰å¾—å¿ƒå¢ƒæ¸…çˆ½ã€‚å¤ä»£ä¼ è¯´å¹¿å·æœ‰æ°´åè´ªæ³‰ï¼Œäººå–äº†è¿™é‡Œçš„æ°´å°±ä¼šå˜å¾—è´ªå©ªã€‚è¿™å¥æ˜¯è¯´æœ‰å¾·è¡Œçš„äººåœ¨æ±¡æµŠçš„ç¯å¢ƒä¸­ä¹Ÿèƒ½ä¿æŒçº¯æ­£ï¼Œä¸è¢«æ±¡æŸ“ã€‚å¤„æ¶¸è¾™ä»¥çŠ¹æ¬¢ï¼šå¤„åœ¨å¥„å¥„å¾…æ¯™çš„æ—¶å€™ï¼Œä»ç„¶ä¹è§‚å¼€æœ—ã€‚å¤„æ²³è¾™ï¼šåŸæŒ‡é²‹é±¼å¤„åœ¨å¹²æ¶¸çš„è½¦è¾™æ—¦ã€‚æ¯”å–»äººé™·å…¥å±æ€¥ä¹‹ä¸­ã€‚</p><p>å­Ÿå°ï¼šä¸œæ±‰äººï¼Œä¸ºå®˜æ¸…æ­£è´¤èƒ½ï¼Œä½†ä¸è¢«é‡ç”¨ï¼Œåæ¥å½’ç”°ã€‚é˜®ç±ï¼šä¸‰å›½é­è¯—äººï¼Œä»–æœ‰æ—¶ç‹¬è‡ªé©¾è½¦å‡ºè¡Œï¼Œåˆ°æ— è·¯å¤„ä¾¿æ¸å“­è€Œè¿”ï¼Œå€Ÿæ­¤å®£æ³„ä¸æ»¡äºç°å®çš„è‹¦é—·å¿ƒæƒ…ã€‚</p><p>ç»ˆå†›ï¼šã€Šæ±‰ä¹¦Â·ç»ˆå†›ä¼ ã€‹è®°è½½ï¼Œæ±‰æ­¦å¸æƒ³è®©å—è¶Šï¼ˆä»Šå¹¿ä¸œã€å¹¿è¥¿ä¸€å¸¦ï¼‰ç‹å½’é¡ºï¼Œæ´¾ç»ˆå†›å‰å¾€åŠè¯´ï¼Œç»ˆå†›è¯·æ±‚ç»™ä»–é•¿ç¼¨ï¼Œå¿…ç¼šä½å—è¶Šç‹ï¼Œå¸¦å›åˆ°çš‡å®«é—¨å‰ï¼ˆæ„æ€æ˜¯ä¸€å®šå®Œæˆä½¿å‘½ï¼‰ã€‚åæ¥ç”¨â€œè¯·ç¼¨â€æŒ‡æŠ•å†›æŠ¥å›½ã€‚</p><p>å®—æ‚«ï¼ˆquÃ¨ï¼‰ï¼šå—æœå®‹äººï¼Œå°‘å¹´æ—¶å¾ˆæœ‰æŠ±è´Ÿï¼Œè¯´â€œæ„¿ä¹˜é•¿é£ç ´ä¸‡é‡Œæµªâ€ã€‚</p><p>ç°ªï¼ˆzÄnï¼‰ç¬ï¼ˆhÃ¹ï¼‰ï¼šè¿™é‡Œä»£æŒ‡å®˜èŒã€‚æ™¨æ˜ï¼šæ™¨æ˜å®šçœï¼Œå‡ºè‡ª ã€Šç¤¼è®°Â·æ›²ç¤¼ä¸Šã€‹ï¼Œé‡Šä¹‰ä¸ºæ—§æ—¶ä¾å¥‰çˆ¶æ¯çš„æ—¥å¸¸ç¤¼èŠ‚ã€‚</p><p>éè°¢å®¶ä¹‹å®æ ‘ï¼Œæ¥å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè‡ªå·±å¹¶ä¸æ˜¯åƒè°¢ç„é‚£æ ·å‡ºè‰²çš„äººæ‰ï¼Œå´èƒ½åœ¨ä»Šæ—¥çš„å®´ä¼šä¸Šç»“è¯†å„ä½åå£«ã€‚è°¢å®¶ä¹‹å®æ ‘ï¼šæŒ‡è°¢ç„ã€‚ã€Šæ™‹ä¹¦Â·è°¢ç„ä¼ ã€‹è®°è½½ï¼Œæ™‹æœè°¢å®‰æ›¾é—®å­ä¾„ä»¬ï¼šä¸ºä»€ä¹ˆäººä»¬æ€»å¸Œæœ›è‡ªå·±çš„å­å¼Ÿå¥½ï¼Ÿä¾„å­è°¢ç„å›ç­”ï¼šâ€œè­¬å¦‚èŠå…°ç‰æ ‘ï¼Œæ¬²ä½¿å…¶ç”Ÿäºåº­é˜¶è€³ã€‚â€åæ¥å°±ç§°è°¢ç„ä¸ºè°¢å®¶å®æ ‘ã€‚å­Ÿæ°ä¹‹èŠ³é‚»ï¼šè¿™é‡Œå€Ÿå­Ÿå­çš„æ¯äº²ä¸ºå¯»æ‰¾é‚»å±…è€Œä¸‰æ¬¡æ¬å®¶çš„æ•…äº‹ï¼Œæ¥æŒ‡èµ´å®´çš„å˜‰å®¾ã€‚</p><p>ä»–æ—¥è¶‹åº­ï¼Œå¨é™ªé²¤å¯¹ï¼šè¿‡äº›æ—¶å€™è‡ªå·±å°†åˆ°çˆ¶äº²é‚£é‡Œé™ªä¾å’Œè†å¬æ•™è¯²ã€‚è¶‹åº­ï¼šå¿«æ­¥èµ°è¿‡åº­é™¢ï¼Œè¿™æ˜¯è¡¨ç¤ºå¯¹é•¿è¾ˆçš„æ­æ•¬ã€‚å¨ï¼šæƒ­æ„§åœ°æ‰¿å—ï¼Œè¡¨ç¤ºè‡ªè°¦ã€‚é²¤å¯¹ï¼šå­”é²¤æ˜¯å­”å­çš„å„¿å­ï¼Œé²¤å¯¹æŒ‡æ¥å—çˆ¶äº²æ•™è¯²ã€‚äº‹è§ã€Šè®ºè¯­Â·å­£æ°ã€‹ï¼šï¼ˆå­”å­ï¼‰å°ç‹¬ç«‹ï¼Œï¼ˆå­”ï¼‰é²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦è¯—ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€œæœªä¹Ÿã€‚â€â€œä¸å­¦è¯—ï¼Œæ— ä»¥è¨€ã€‚â€é²¤é€€è€Œå­¦è¯—ã€‚ä»–æ—¥ï¼Œåˆç‹¬ç«‹ï¼Œé²¤è¶‹è€Œè¿‡åº­ã€‚ï¼ˆå­ï¼‰æ›°ï¼šâ€œå­¦ç¤¼ä¹ï¼Ÿâ€å¯¹æ›°ï¼šâ€˜æœªä¹Ÿã€‚â€â€œä¸å­¦ç¤¼ï¼Œæ— ä»¥ç«‹ã€‚â€é²¤é€€è€Œå­¦ç¤¼ã€‚</p><p>æ§è¢‚ï¼ˆmÃ¨iï¼‰ï¼šä¸¾èµ·åŒè¢–ä½œæ–ï¼ŒæŒ‡è°’è§é˜å…¬ã€‚å–œæ‰˜é¾™é—¨ï¼šï¼ˆå—åˆ°é˜å…¬çš„æ¥å¾…ï¼‰ååˆ†é«˜å…´ï¼Œå¥½åƒç™»ä¸Šé¾™é—¨ä¸€æ ·ã€‚</p><p>æ¨æ„ï¼šå³èœ€äººæ¨å¾—æ„ï¼Œä»»æŒç®¡å¤©å­çŒçŠ¬çš„å®˜ï¼Œè¥¿æ±‰è¾èµ‹å®¶å¸é©¬ç›¸å¦‚æ˜¯ç”±ä»–æ¨èç»™æ±‰æ­¦å¸çš„ã€‚å‡Œäº‘ï¼šè¿™é‡ŒæŒ‡å¸é©¬ç›¸å¦‚çš„èµ‹ï¼Œã€Šå²è®°Â·å¸é©¬ç›¸å¦‚ä¼ ã€‹è¯´ï¼Œç›¸å¦‚çŒ®ã€Šå¤§äººèµ‹ã€‹ï¼Œâ€œå¤©å­å¤§æ‚¦ï¼Œé£˜é£˜æœ‰å‡Œäº‘ä¹‹æ°”ï¼Œä¼¼æ¸¸å¤©åœ°ä¹‹é—´â€ã€‚é’ŸæœŸï¼šå³é’Ÿå­æœŸã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonä¸­çš„æ‹·è´</title>
      <link href="/2018/08/18/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84%E6%8B%B7%E8%B4%9D/"/>
      <url>/2018/08/18/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E4%B8%AD%E7%9A%84%E6%8B%B7%E8%B4%9D/</url>
      
        <content type="html"><![CDATA[<p>Pythonçš„æ‹·è´å’ŒC/C++çš„å·®åˆ«å¾ˆå¤§ï¼Œå¾ˆç»å¸¸å°±å®¹æ˜“ææ··ï¼Œå› æ­¤è®°å½•ä¸€ä¸‹ã€‚</p><h3 id="èµ‹å€¼ã€æ‹·è´"><a href="#èµ‹å€¼ã€æ‹·è´" class="headerlink" title="èµ‹å€¼ã€æ‹·è´"></a>èµ‹å€¼ã€æ‹·è´</h3><ul><li>èµ‹å€¼ï¼šå®é™…ä¸Šå°±æ˜¯å¯¹è±¡çš„å¼•ç”¨ï¼Œæ²¡æœ‰å¼€è¾Ÿæ–°çš„å†…å­˜ç©ºé—´<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lst=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">l=lst</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>æµ…æ‹·è´:åˆ›å»ºäº†æ–°å¯¹è±¡ï¼Œä½†æ˜¯<strong>å†…å®¹æ˜¯å¯¹åŸå¯¹è±¡çš„å¼•ç”¨</strong>ï¼Œæœ‰ä¸‰ç§å½¢å¼</p><ol><li><p>åˆ‡ç‰‡  </p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l=lst[:]</span><br><span class="line">l=[i <span class="keyword">for</span> i <span class="keyword">in</span> lst]</span><br></pre></td></tr></table></figure></li><li><p>å·¥å‚</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l=list(lst)</span><br></pre></td></tr></table></figure></li><li><p>copy </p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.copy(lst)</span><br></pre></td></tr></table></figure></li></ol></li><li><p>æ·±æ‹·è´:copyä¸­çš„deepcopyï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„å¯¹è±¡ï¼Œä¸åŸæ¥çš„å¯¹è±¡æ— å…³</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l=copy.deepcopy(lst)</span><br></pre></td></tr></table></figure></li></ul><h3 id="ä¾‹å­"><a href="#ä¾‹å­" class="headerlink" title="ä¾‹å­"></a>ä¾‹å­</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### å¼•ç”¨https://www.cnblogs.com/huangbiquan/p/7795152.html çš„ä¾‹å­###</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> copy</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,[<span class="string">'a'</span>,<span class="string">'b'</span>]] <span class="comment">#å®šä¹‰ä¸€ä¸ªåˆ—è¡¨a</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a <span class="comment">#èµ‹å€¼</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = copy.copy(a) <span class="comment">#æµ…æ‹·è´</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = copy.deepcopy(a) <span class="comment">#æ·±æ‹·è´</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.append(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#aæ·»åŠ ä¸€ä¸ªå…ƒç´ 5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b) </span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ 5 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#cä¿æŒä¸å˜</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">4</span>].append(<span class="string">'c'</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#aä¸­çš„list(å³a[4])æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(b)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>] <span class="comment">#bè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(c)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]] <span class="comment">#cè·Ÿç€æ·»åŠ ä¸€ä¸ªå…ƒç´ c</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(d)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#dä¿æŒä¸å˜</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#è¯´æ˜å¦‚ä¸‹ï¼š</span></span><br><span class="line"><span class="comment">#1.å¤–å±‚æ·»åŠ å…ƒç´ æ—¶ï¼Œ æµ…æ‹·è´cä¸ä¼šéšåŸåˆ—è¡¨aå˜åŒ–è€Œå˜åŒ–ï¼›å†…å±‚listæ·»åŠ å…ƒç´ æ—¶ï¼Œæµ…æ‹·è´cæ‰ä¼šå˜åŒ–ã€‚</span></span><br><span class="line"><span class="comment">#2.æ— è®ºåŸåˆ—è¡¨aå¦‚ä½•å˜åŒ–ï¼Œæ·±æ‹·è´déƒ½ä¿æŒä¸å˜ã€‚</span></span><br><span class="line"><span class="comment">#3.èµ‹å€¼å¯¹è±¡éšç€åŸåˆ—è¡¨ä¸€èµ·å˜åŒ–</span></span><br></pre></td></tr></table></figure><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/huangbiquan/p/7795152.html" target="_blank" rel="noopener">https://www.cnblogs.com/huangbiquan/p/7795152.html</a><br><a href="https://www.cnblogs.com/xueli/p/4952063.html" target="_blank" rel="noopener">https://www.cnblogs.com/xueli/p/4952063.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> æ‹·è´ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¦‚ä½•å°†ELMoè¯å‘é‡ç”¨äºä¸­æ–‡</title>
      <link href="/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E5%B0%86ELMo%E8%AF%8D%E5%90%91%E9%87%8F%E7%94%A8%E4%BA%8E%E4%B8%AD%E6%96%87/"/>
      <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E5%B0%86ELMo%E8%AF%8D%E5%90%91%E9%87%8F%E7%94%A8%E4%BA%8E%E4%B8%AD%E6%96%87/</url>
      
        <content type="html"><![CDATA[<p>10.10æ›´æ–°ï¼šELMoå·²ç»ç”±å“ˆå·¥å¤§ç»„ç”¨PyTorché‡å†™äº†ï¼Œå¹¶ä¸”æä¾›äº†ä¸­æ–‡çš„é¢„è®­ç»ƒå¥½çš„language modelï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚</p><p>2019.4.7æ›´æ–°ï¼šå¹´ä»£è¿‡äºä¹…è¿œï¼Œæœ¬äººäºç»†èŠ‚æ–¹é¢æ—©å·²è®°ä¸å¤§æ¸…æ¥šäº†ã€‚é‡åˆ°bugæˆ–é—®é¢˜çƒ¦è¯·è‡ªè¡ŒæŸ¥é˜…è§£å†³ï¼Œè¯·ä¸å¿…åœ¨è¯„è®ºåŒºæé—®æˆ–é‚®ä»¶æé—®ï¼Œä¸ä¼šå†å›å¤ã€‚</p><hr><p>ELMoäºä»Šå¹´äºŒæœˆç”±AllenNLPæå‡ºï¼Œä¸word2vecæˆ–GloVeä¸åŒçš„æ˜¯å…¶åŠ¨æ€è¯å‘é‡çš„æ€æƒ³ï¼Œå…¶æœ¬è´¨å³é€šè¿‡è®­ç»ƒlanguage modelï¼Œå¯¹äºä¸€å¥è¯è¿›å…¥åˆ°language modelè·å¾—ä¸åŒçš„è¯å‘é‡ã€‚æ ¹æ®å®éªŒå¯å¾—ï¼Œä½¿ç”¨äº†Elmoè¯å‘é‡ä¹‹åï¼Œè®¸å¤šNLPä»»åŠ¡éƒ½æœ‰äº†å¤§å¹…çš„æé«˜ã€‚</p><p>è®ºæ–‡:<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">Deep contextualized word representations</a></p><p>AllenNLPä¸€å…±releaseäº†ä¸¤ä»½ELMoçš„ä»£ç ï¼Œä¸€ä»½æ˜¯Pytorchç‰ˆæœ¬çš„ï¼Œå¦ä¸€ä»½æ˜¯Tensorflowç‰ˆæœ¬çš„ã€‚Pytorchç‰ˆæœ¬çš„åªå¼€æ”¾äº†ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡çš„æ¥å£ï¼Œä½†æ²¡æœ‰ç»™å‡ºè‡ªå·±è®­ç»ƒçš„æ¥å£ï¼Œå› æ­¤æ— æ³•ä½¿ç”¨åˆ°ä¸­æ–‡è¯­æ–™ä¸­ã€‚Tensorflowç‰ˆæœ¬æœ‰æä¾›è®­ç»ƒçš„ä»£ç ï¼Œå› æ­¤æœ¬æ–‡è®°å½•å¦‚ä½•å°†ELMoç”¨äºä¸­æ–‡è¯­æ–™ä¸­ï¼Œä½†æœ¬æ–‡åªè®°å½•ä½¿ç”¨åˆ°çš„éƒ¨åˆ†ï¼Œè€Œä¸ä¼šåˆ†æå…¨éƒ¨çš„ä»£ç ã€‚</p><p>éœ€æ±‚:<br>ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è¯å‘é‡ä½œä¸ºå¥å­è¡¨ç¤ºç›´æ¥ä¼ å…¥åˆ°RNNä¸­(ä¹Ÿå°±æ˜¯ä¸ä½¿ç”¨ä»£ç ä¸­é»˜è®¤çš„å…ˆè¿‡CNN)ï¼Œåœ¨è®­ç»ƒå®Œåï¼Œå°†æ¨¡å‹ä¿å­˜ï¼Œåœ¨éœ€è¦ç”¨çš„æ—¶å€™loadè¿›æ¥ï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„å¥å­ï¼Œé¦–å…ˆå°†å…¶è½¬æ¢æˆé¢„è®­ç»ƒçš„è¯å‘é‡ï¼Œä¼ å…¥language modelä¹‹åæœ€ç»ˆå¾—åˆ°ELMoè¯å‘é‡ã€‚</p><p>å‡†å¤‡å·¥ä½œ:</p><ol><li>å°†ä¸­æ–‡è¯­æ–™åˆ†è¯</li><li>è®­ç»ƒå¥½GloVeè¯å‘é‡æˆ–è€…word2vec</li><li>ä¸‹è½½<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">bilm-tfä»£ç </a></li><li>ç”Ÿæˆè¯è¡¨ vocab_file ï¼ˆè®­ç»ƒçš„æ—¶å€™è¦ç”¨åˆ°ï¼‰</li><li>optional:é˜…è¯»Readme</li><li>optional:é€šè¯»bilm-tfçš„ä»£ç ï¼Œå¯¹ä»£ç ç»“æ„æœ‰ä¸€å®šçš„è®¤è¯†</li></ol><p>æ€è·¯:</p><ol><li>å°†é¢„è®­ç»ƒçš„è¯å‘é‡è¯»å…¥</li><li>ä¿®æ”¹bilm-tfä»£ç <ol><li>optionéƒ¨åˆ†</li><li>æ·»åŠ ç»™embedding weightèµ‹åˆå€¼</li><li>æ·»åŠ ä¿å­˜embedding weightçš„ä»£ç </li></ol></li><li>å¼€å§‹è®­ç»ƒï¼Œè·å¾—checkpointå’Œoptionæ–‡ä»¶</li><li>è¿è¡Œè„šæœ¬ï¼Œè·å¾—language modelçš„weightæ–‡ä»¶</li><li>å°†embedding weightä¿å­˜ä¸ºhdf5æ–‡ä»¶å½¢å¼</li><li>è¿è¡Œè„šæœ¬ï¼Œå°†è¯­æ–™è½¬åŒ–æˆELMo embeddingã€‚</li></ol><h3 id="è®­ç»ƒGloVeæˆ–word2vec"><a href="#è®­ç»ƒGloVeæˆ–word2vec" class="headerlink" title="è®­ç»ƒGloVeæˆ–word2vec"></a>è®­ç»ƒGloVeæˆ–word2vec</h3><p>å¯å‚è§æˆ‘ä»¥å‰çš„åšå®¢æˆ–è€…ç½‘ä¸Šçš„æ•™ç¨‹ã€‚<br>æ³¨æ„åˆ°ï¼Œå¦‚æœè¦ç”¨gensimå¯¼å…¥GloVeè®­å¥½çš„è¯å‘é‡ï¼Œéœ€è¦åœ¨å¼€å¤´æ·»åŠ num_word embedding_dimã€‚ å¦‚ï¼š<br><img src="/images/2018-08-10-15338861462682.jpg" width="70%" height="50%"></p><h3 id="è·å¾—vocabè¯è¡¨æ–‡ä»¶"><a href="#è·å¾—vocabè¯è¡¨æ–‡ä»¶" class="headerlink" title="è·å¾—vocabè¯è¡¨æ–‡ä»¶"></a>è·å¾—vocabè¯è¡¨æ–‡ä»¶</h3><p>æ³¨æ„åˆ°ï¼Œè¯è¡¨æ–‡ä»¶çš„å¼€å¤´å¿…é¡»è¦æœ‰<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œä¸”å¤§å°å†™æ•æ„Ÿã€‚å¹¶ä¸”åº”å½“æŒ‰ç…§å•è¯çš„è¯é¢‘é™åºæ’åˆ—ã€‚å¯ä»¥é€šè¿‡æ‰‹åŠ¨æ·»åŠ è¿™ä¸‰ä¸ªç‰¹æ®Šç¬¦å·ã€‚<br>å¦‚ï¼š<br><img src="/images/2018-08-11-15339757184030.jpg" width="10%" height="50%"></p><p>ä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model=gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">    fname=<span class="string">'/home/zhlin/GloVe/vectors.txt'</span>,binary=<span class="keyword">False</span></span><br><span class="line">)</span><br><span class="line">words=model.vocab</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'vocab.txt'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'&lt;S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>ï¼‰</span><br><span class="line">    f.write(<span class="string">'&lt;/S&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)</span><br><span class="line">    f.write(<span class="string">'&lt;UNK&gt;'</span>)</span><br><span class="line">    f.write(<span class="string">'\n'</span>)    <span class="comment"># bilm-tf è¦æ±‚vocabæœ‰è¿™ä¸‰ä¸ªç¬¦å·ï¼Œå¹¶ä¸”åœ¨æœ€å‰é¢</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        f.write(word)</span><br><span class="line">        f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="ä¿®æ”¹bilm-tfä»£ç "><a href="#ä¿®æ”¹bilm-tfä»£ç " class="headerlink" title="ä¿®æ”¹bilm-tfä»£ç "></a>ä¿®æ”¹bilm-tfä»£ç </h3><p>æ³¨æ„åˆ°ï¼Œåœ¨ä½¿ç”¨è¯¥ä»£ç ä¹‹å‰ï¼Œéœ€è¦å®‰è£…å¥½ç›¸åº”çš„ç¯å¢ƒã€‚</p><p><img src="/images/2018-08-10-15338879402377.jpg" width="50%" height="50%"></p><p>å¦‚æœä½¿ç”¨çš„æ˜¯condaä½œä¸ºé»˜è®¤çš„Pythonè§£é‡Šå™¨ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨condaå®‰è£…ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°ä¸€äº›è«åçš„é”™è¯¯ã€‚<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install tensorflow-gpu=1.4</span><br><span class="line">conda install h5py</span><br><span class="line">python setup.py install <span class="comment">#åº”åœ¨bilm-tfçš„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œè¯¥æŒ‡ä»¤</span></span><br></pre></td></tr></table></figure></p><p>ç„¶åå†è¿è¡Œæµ‹è¯•ä»£ç ï¼Œé€šè¿‡è¯´æ˜å®‰è£…æˆåŠŸã€‚</p><h4 id="ä¿®æ”¹train-elmo-py"><a href="#ä¿®æ”¹train-elmo-py" class="headerlink" title="ä¿®æ”¹train_elmo.py"></a>ä¿®æ”¹train_elmo.py</h4><p>binæ–‡ä»¶å¤¹ä¸‹çš„train_elmo.pyæ˜¯ç¨‹åºçš„å…¥å£ã€‚<br>ä¸»è¦ä¿®æ”¹çš„åœ°æ–¹ï¼š</p><ol><li>load_vocabçš„ç¬¬äºŒä¸ªå‚æ•°åº”è¯¥æ”¹ä¸ºNone</li><li>n_gpus CUDA_VISIBLE_DEVICES æ ¹æ®è‡ªå·±éœ€æ±‚æ”¹</li><li>n_train_tokens å¯æ”¹å¯ä¸æ”¹ï¼Œå½±å“çš„æ˜¯è¾“å‡ºä¿¡æ¯ã€‚è¦æŸ¥çœ‹è‡ªå·±è¯­æ–™çš„è¡Œæ•°ï¼Œå¯ä»¥é€šè¿‡<code>wc -l corpus.txt</code> æŸ¥çœ‹ã€‚</li><li><strong>optionçš„ä¿®æ”¹</strong>ï¼Œå°†char_cnnéƒ¨åˆ†éƒ½æ³¨é‡Šæ‰ï¼Œå…¶ä»–æ ¹æ®è‡ªå·±éœ€æ±‚ä¿®æ”¹</li></ol><p>å¦‚ï¼š<br><img src="/images/2018-08-10-15338888745894.jpg" width="70%" height="50%"></p><h4 id="ä¿®æ”¹LanguageModelç±»"><a href="#ä¿®æ”¹LanguageModelç±»" class="headerlink" title="ä¿®æ”¹LanguageModelç±»"></a>ä¿®æ”¹LanguageModelç±»</h4><p>ç”±äºæˆ‘éœ€è¦ä¼ å…¥é¢„è®­ç»ƒå¥½çš„GloVe embeddingï¼Œé‚£ä¹ˆè¿˜éœ€è¦ä¿®æ”¹embeddingéƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†åœ¨bilmæ–‡ä»¶å¤¹ä¸‹çš„training.pyï¼Œè¿›å…¥åˆ°LanguageModelç±»ä¸­_build_word_embeddingså‡½æ•°ä¸­ã€‚æ³¨æ„åˆ°ï¼Œç”±äºå‰ä¸‰ä¸ªæ˜¯<code>&lt;S&gt; &lt;/S&gt; &lt;UNK&gt;</code>ï¼Œè€Œè¿™ä¸‰ä¸ªå­—ç¬¦åœ¨GloVeé‡Œé¢æ˜¯æ²¡æœ‰çš„ï¼Œå› æ­¤è¿™ä¸‰ä¸ªå­—ç¬¦çš„embeddingåº”å½“åœ¨è®­ç»ƒçš„æ—¶å€™é€æ¸å­¦ä¹ åˆ°ï¼Œè€Œæ­£å› æ­¤ <code>embedding_weights</code>çš„<code>trainable</code>åº”å½“è®¾ä¸º<code>True</code></p><p>å¦‚:</p><p><img src="/images/2018-08-12-15340585073779.jpg" alt=""></p><h4 id="ä¿®æ”¹trainå‡½æ•°"><a href="#ä¿®æ”¹trainå‡½æ•°" class="headerlink" title="ä¿®æ”¹trainå‡½æ•°"></a>ä¿®æ”¹trainå‡½æ•°</h4><p>æ·»åŠ ä»£ç ï¼Œä½¿å¾—åœ¨trainå‡½æ•°çš„æœ€åä¿å­˜embeddingæ–‡ä»¶ã€‚<br><img src="/images/2018-08-12-15340607132103.jpg" alt=""></p><h3 id="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"><a href="#è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶" class="headerlink" title="è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶"></a>è®­ç»ƒå¹¶è·å¾—weightsæ–‡ä»¶</h3><p>è®­ç»ƒéœ€è¦è¯­æ–™æ–‡ä»¶corpus.txtï¼Œè¯è¡¨æ–‡ä»¶vocab.txtã€‚</p><h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>cdåˆ°bilm-tfæ–‡ä»¶å¤¹ä¸‹ï¼Œè¿è¡Œ<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=4</span><br><span class="line">nohup python -u bin/train_elmo.py \</span><br><span class="line">--train_prefix=<span class="string">'/home/zhlin/bilm-tf/corpus.txt'</span> \</span><br><span class="line">--vocab_file /home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try &gt;bilm_out.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>æ ¹æ®å®é™…æƒ…å†µè®¾å®šä¸åŒçš„å€¼å’Œè·¯å¾„ã€‚</p><p>è¿è¡Œæƒ…å†µï¼š<br><img src="/images/2018-08-10-15339015862848.jpg" width="50%" height="50%"></p><p>PS:è¿è¡Œè¿‡ç¨‹ä¸­å¯èƒ½ä¼šæœ‰warning:</p><blockquote><p>â€˜listâ€™ object has no attribute â€˜nameâ€™<br>WARNING:tensorflow:Error encountered when serializing lstm_output_embeddings.<br>Type is unsupported, or the types of the items donâ€™t match field type in CollectionDef.</p></blockquote><p>åº”è¯¥ä¸ç”¨æ‹…å¿ƒï¼Œè¿˜æ˜¯èƒ½å¤Ÿç»§ç»­è¿è¡Œçš„ï¼Œåé¢ä¹Ÿä¸å—å½±å“ã€‚</p><p>åœ¨ç­‰å¾…äº†ç›¸å½“é•¿çš„æ—¶é—´åï¼Œåœ¨save_diræ–‡ä»¶å¤¹å†…ç”Ÿæˆäº†å‡ ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­checkpointå’Œoptionsæ˜¯å…³é”®ï¼Œcheckpointèƒ½å¤Ÿè¿›ä¸€æ­¥ç”Ÿæˆlanguage modelçš„weightsæ–‡ä»¶ï¼Œè€Œoptionsè®°å½•language modelçš„å‚æ•°ã€‚</p><p><img src="/images/2018-08-11-15339734319058.jpg" alt=""></p><h4 id="è·å¾—language-modelçš„weights"><a href="#è·å¾—language-modelçš„weights" class="headerlink" title="è·å¾—language modelçš„weights"></a>è·å¾—language modelçš„weights</h4><p>æ¥ä¸‹æ¥è¿è¡Œbin/dump_weights.pyå°†checkpointè½¬æ¢æˆhdf5æ–‡ä»¶ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup python -u  /home/zhlin/bilm-tf/bin/dump_weights.py  \</span><br><span class="line">--save_dir /home/zhlin/bilm-tf/try  \</span><br><span class="line">--outfile /home/zhlin/bilm-tf/try/weights.hdf5 &gt;outfile.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­save_diræ˜¯checkpointå’Œoptionæ–‡ä»¶ä¿å­˜çš„åœ°å€ã€‚</p><p>æ¥ä¸‹æ¥ç­‰å¾…ç¨‹åºè¿è¡Œï¼š</p><p><img src="/images/2018-08-11-15339740970081.jpg" width="70%" height="50%"></p><p><img src="/images/2018-08-11-15339745511775.jpg" width="70%" height="50%"></p><p>æœ€ç»ˆè·å¾—äº†æƒ³è¦çš„weightså’Œoptionï¼š<br><img src="/images/2018-08-11-15339978499136.jpg" alt=""></p><h3 id="å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding"><a href="#å°†è¯­æ–™è½¬åŒ–æˆELMo-embedding" class="headerlink" title="å°†è¯­æ–™è½¬åŒ–æˆELMo embedding"></a>å°†è¯­æ–™è½¬åŒ–æˆELMo embedding</h3><p>ç”±äºæˆ‘ä»¬æœ‰äº†vocab_fileã€ä¸vocab_fileä¸€ä¸€å¯¹åº”çš„embedding h5pyæ–‡ä»¶ã€ä»¥åŠlanguage modelçš„weights.hdf5å’Œoptions.jsonã€‚<br>æ¥ä¸‹æ¥å‚è€ƒusage_token.pyå°†ä¸€å¥è¯è½¬åŒ–æˆELMo embeddingã€‚</p><p>å‚è€ƒä»£ç ï¼š<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> bilm <span class="keyword">import</span> TokenBatcher, BidirectionalLanguageModel, weight_layers, \</span><br><span class="line">    dump_token_embeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># Our small dataset.</span></span><br><span class="line">raw_context = [</span><br><span class="line">    <span class="string">'è¿™ æ˜¯ æµ‹è¯• .'</span>,</span><br><span class="line">    <span class="string">'å¥½çš„ .'</span></span><br><span class="line">]</span><br><span class="line">tokenized_context = [sentence.split() <span class="keyword">for</span> sentence <span class="keyword">in</span> raw_context]</span><br><span class="line">tokenized_question = [</span><br><span class="line">    [<span class="string">'è¿™'</span>, <span class="string">'æ˜¯'</span>, <span class="string">'ä»€ä¹ˆ'</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">vocab_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab.txt'</span></span><br><span class="line">options_file=<span class="string">'/home/zhlin/bilm-tf/try/options.json'</span></span><br><span class="line">weight_file=<span class="string">'/home/zhlin/bilm-tf/try/weights.hdf5'</span></span><br><span class="line">token_embedding_file=<span class="string">'/home/zhlin/bilm-tf/glove_embedding_vocab8.10/vocab_embedding.hdf5'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Now we can do inference.</span></span><br><span class="line"><span class="comment"># Create a TokenBatcher to map text to token ids.</span></span><br><span class="line">batcher = TokenBatcher(vocab_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input placeholders to the biLM.</span></span><br><span class="line">context_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line">question_token_ids = tf.placeholder(<span class="string">'int32'</span>, shape=(<span class="keyword">None</span>, <span class="keyword">None</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the biLM graph.</span></span><br><span class="line">bilm = BidirectionalLanguageModel(</span><br><span class="line">    options_file,</span><br><span class="line">    weight_file,</span><br><span class="line">    use_character_inputs=<span class="keyword">False</span>,</span><br><span class="line">    embedding_weight_file=token_embedding_file</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get ops to compute the LM embeddings.</span></span><br><span class="line">context_embeddings_op = bilm(context_token_ids)</span><br><span class="line">question_embeddings_op = bilm(question_token_ids)</span><br><span class="line"></span><br><span class="line">elmo_context_input = weight_layers(<span class="string">'input'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_input = weight_layers(</span><br><span class="line">        <span class="string">'input'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">elmo_context_output = weight_layers(</span><br><span class="line">    <span class="string">'output'</span>, context_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">''</span>, reuse=<span class="keyword">True</span>):</span><br><span class="line">    <span class="comment"># the reuse=True scope reuses weights from the context for the question</span></span><br><span class="line">    elmo_question_output = weight_layers(</span><br><span class="line">        <span class="string">'output'</span>, question_embeddings_op, l2_coef=<span class="number">0.0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># It is necessary to initialize variables once before running inference.</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create batches of data.</span></span><br><span class="line">    context_ids = batcher.batch_sentences(tokenized_context)</span><br><span class="line">    question_ids = batcher.batch_sentences(tokenized_question)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute ELMo representations (here for the input only, for simplicity).</span></span><br><span class="line">    elmo_context_input_, elmo_question_input_ = sess.run(</span><br><span class="line">        [elmo_context_input[<span class="string">'weighted_op'</span>], elmo_question_input[<span class="string">'weighted_op'</span>]],</span><br><span class="line">        feed_dict=&#123;context_token_ids: context_ids,</span><br><span class="line">                   question_token_ids: question_ids&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">print(elmo_context_input_,elmo_context_input_)</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥ä¿®æ”¹ä»£ç ä»¥é€‚åº”è‡ªå·±çš„éœ€æ±‚ã€‚</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">https://github.com/allenai/bilm-tf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
            <tag> ELMo </tag>
            
            <tag> è¯å‘é‡ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•4</title>
      <link href="/2018/08/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB4/"/>
      <url>/2018/08/12/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E5%88%86%E4%BA%AB4/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨æ²¡æœ‰ä»€ä¹ˆä»£ç è¦è®°å½•çš„ã€‚</p><h3 id="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"><a href="#1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­" class="headerlink" title="1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­"></a>1ï¸âƒ£sklearnä¹‹Pipelineä¾‹å­</h3><p>ç”¨æœºå™¨å­¦ä¹ è§£å†³é—®é¢˜çš„æµç¨‹ï¼š<br>(å»æ‰éƒ¨åˆ†æ•°æ®ï¼‰â€”&gt; è·å–featureï¼ˆTf-idfç­‰ï¼‰ â€”&gt; ï¼ˆfeature selectionï¼Œchi2ã€äº’ä¿¡æ¯ç­‰ï¼‰ â€”&gt; ï¼ˆç¼©æ”¾/æ­£åˆ™åŒ–ï¼‰ â€”&gt; åˆ†ç±»å™¨ â€”&gt; GridSearch/RandomizedSearchè°ƒå‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pipe=Pipeline([     <span class="comment">#å»ºç«‹pipeline</span></span><br><span class="line">    (<span class="string">'vect'</span>,TfidfVectorizer()),</span><br><span class="line">    (<span class="string">'select'</span>,SelectKBest(chi2),</span><br><span class="line">    (<span class="string">'norm'</span>,MaxAbsScaler()),   </span><br><span class="line">    (<span class="string">'svm'</span>,svm.LinearSVC())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">parameters=&#123;</span><br><span class="line">    <span class="string">'vect__ngram_range'</span>:[(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>)],</span><br><span class="line">    <span class="string">'vect__max_df'</span>:[<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>],</span><br><span class="line">    <span class="string">'vect__min_df'</span>:[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>],</span><br><span class="line">    <span class="string">'vect__norm'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__penalty'</span>:[<span class="string">'l1'</span>,<span class="string">'l2'</span>],</span><br><span class="line">    <span class="string">'svm__loss'</span>:[<span class="string">'squared_hinge'</span>],  </span><br><span class="line">    <span class="string">'svm__dual'</span>:[<span class="keyword">False</span>,<span class="keyword">True</span>],</span><br><span class="line">    <span class="string">'svm__tol'</span>:[<span class="number">1e-5</span>,<span class="number">1e-4</span>],</span><br><span class="line">    <span class="string">'svm__C'</span>:[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">1.0</span>,<span class="number">1.1</span>],</span><br><span class="line">    <span class="string">'svm__class_weight'</span>:[<span class="keyword">None</span>,<span class="string">'balanced'</span>],</span><br><span class="line">    <span class="string">'svm__max_iter'</span>:[<span class="number">1000</span>,<span class="number">5000</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search_model=GridSearchCV(pipe,parameters,error_score=<span class="number">0</span>,n_jobs=<span class="number">5</span>)</span><br><span class="line">grid_search_model.fit(train[column],train[<span class="string">'class'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> para_name <span class="keyword">in</span> sorted(parameters.keys()):</span><br><span class="line">    print(para_name,grid_search_model.best_params_[para_name])</span><br><span class="line"></span><br><span class="line">print(<span class="string">"cv_result:"</span>)</span><br><span class="line">print(grid_search_model.cv_results_)</span><br></pre></td></tr></table></figure><hr>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†3</title>
      <link href="/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%863/"/>
      <url>/2018/08/12/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%863/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Python]<br>åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç æ—¶ï¼Œå¦‚ <code>python project/folder1/a.py</code>ï¼Œå¦‚æœa.pyå¼•ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„æ¨¡å—ä½†åˆä¸åœ¨folder1å†…ï¼Œæ­¤æ—¶interpreterå°±ä¼šæŠ¥é”™ï¼Œæç¤ºæ‰¾ä¸åˆ°è¯¥æ¨¡å—ã€‚è¿™æ˜¯å› ä¸ºè§£é‡Šå™¨é»˜è®¤åªä¼šåœ¨åŒä¸€ä¸ªfolderä¸‹æŸ¥æ‰¾ã€‚è§£å†³æ–¹æ¡ˆæ˜¯åœ¨è¿è¡Œå‰æ˜¾å¼æ·»åŠ æŸ¥æ‰¾èŒƒå›´ã€‚å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONPATH=/home/zhlin/bilm-tf:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure></p><p>é‚£ä¹ˆpythonè§£é‡Šå™¨å°±ä¼šåˆ°è¯¥ç›®å½•ä¸‹å»æ‰¾ã€‚</p><hr><p>2ï¸âƒ£[åº¦é‡æ ‡å‡†]<br><img src="/images/2018-08-12-15340420442670.jpg" alt=""></p><ul><li>å‡†ç¡®ç‡(accuracy):  $ACC=\frac{TP+TN}{TP+TN+FP+FN}$<br> è¡¡é‡çš„æ˜¯åˆ†ç±»å™¨é¢„æµ‹å‡†ç¡®çš„æ¯”ä¾‹</li><li>å¬å›ç‡(recall): $Recall=\frac{TP}{TP+FN}$<br>  æ­£ä¾‹ä¸­è¢«åˆ†å¯¹çš„æ¯”ä¾‹ï¼Œè¡¡é‡äº†åˆ†ç±»å™¨å¯¹æ­£ä¾‹çš„è¯†åˆ«èƒ½åŠ›ã€‚</li><li>ç²¾ç¡®ç‡(Precision): $P=\frac{TP}{TP+FP}$<br>åº¦é‡äº†è¢«åˆ†ä¸ºæ­£ä¾‹çš„ç¤ºä¾‹ä¸­å®é™…ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ã€‚</li><li>F-Measure: $F=\frac{(\alpha^2 +1)P*R}{\alpha^2 (P+R)}$<br>  å…¶ä¸­Pæ˜¯Precision,Ræ˜¯Recallã€‚ç»¼åˆè€ƒé‡äº†ä¸¤ç§åº¦é‡ã€‚<br>  å½“$\alpha=1$æ—¶ï¼Œç§°ä¸ºF1å€¼ $F1=\frac{2PR}{P+R}$</li></ul><hr><p>3ï¸âƒ£[è°ƒå‚æŠ€å·§]<br>åœ¨googleå‘å¸ƒçš„ä¸€ä»½å…³äºtext-classificationçš„<a href="https://developers.google.com/machine-learning/guides/text-classification/" target="_blank" rel="noopener">guide</a>ä¸­ï¼Œæåˆ°äº†å‡ ä¸ªè°ƒå‚çš„trickã€‚</p><ol><li>åœ¨feature selectionæ­¥éª¤ä¸­ï¼Œå¡æ–¹æ£€éªŒchi2å’Œæ–¹å·®åˆ†æçš„Få€¼ f_classifçš„è¡¨ç°ç›¸å½“ï¼Œåœ¨å¤§çº¦é€‰æ‹©20kçš„featureæ—¶ï¼Œå‡†ç¡®ç‡è¾¾åˆ°é¡¶å³°ï¼Œå½“featureè¶Šå¤šï¼Œæ•ˆæœå¹¶æ²¡æœ‰æå‡ç”šè‡³ä¼šä¸‹é™ã€‚<br><img src="/images/2018-08-12-15340434326365.jpg" width="90%" height="50%"></li><li>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œä¼¼ä¹ä½¿ç”¨normalizationå¹¶æ²¡æœ‰å¤šå°‘ç”¨å¤„ï¼Œå»ºè®®è·³è¿‡ã€‚<blockquote><p>Normalization converts all feature/sample values to small and similar values. This simplifies gradient descent convergence in learning algorithms. From what we have seen, normalization during data preprocessing does not seem to add much value in text classification problems; we recommend skipping this step.</p></blockquote></li></ol><p>å®é™…ä¸Šæˆ‘ä¹Ÿæµ‹è¯•è¿‡ï¼Œå‘ç°ç¡®å®normalizationå¯¹äºå‡†ç¡®ç‡çš„æé«˜æ²¡ä»€ä¹ˆå¸®åŠ©ï¼Œç”šè‡³è¿˜æœ‰ä¸€ç‚¹ä¸‹é™ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> åº¦é‡æ ‡å‡† </tag>
            
            <tag> è°ƒå‚æŠ€å·§ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯4</title>
      <link href="/2018/08/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D4/"/>
      <url>/2018/08/12/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D4/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£</p><h3 id="çä¸Šç§‹å±…"><a href="#çä¸Šç§‹å±…" class="headerlink" title="çä¸Šç§‹å±…"></a>çä¸Šç§‹å±…</h3><p>[å”] é©¬æˆ´<br>çåŸé£é›¨å®šï¼Œæ™šè§é›è¡Œé¢‘ã€‚<br>è½å¶ä»–ä¹¡æ ‘ï¼Œå¯’ç¯ç‹¬å¤œäººã€‚<br>ç©ºå›­ç™½éœ²æ»´ï¼Œå­¤å£é‡åƒ§é‚»ã€‚<br><strong>å¯„å§éƒŠæ‰‰ä¹…ï¼Œä½•å¹´è‡´æ­¤èº«ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8a4080a2b58005c9108d9</a></p><hr><p>2ï¸âƒ£</p><h3 id="å”å¤šä»¤"><a href="#å”å¤šä»¤" class="headerlink" title="å”å¤šä»¤"></a>å”å¤šä»¤</h3><p>[å®‹] åˆ˜è¿‡<br>èŠ¦å¶æ»¡æ±€æ´²ï¼Œå¯’æ²™å¸¦æµ…æµã€‚äºŒåå¹´é‡è¿‡å—æ¥¼ã€‚æŸ³ä¸‹ç³»èˆ¹çŠ¹æœªç¨³ï¼Œèƒ½å‡ æ—¥ï¼Œåˆä¸­ç§‹ã€‚<br>é»„é¹¤æ–­çŸ¶å¤´ï¼Œæ•…äººä»Šåœ¨å¦ï¼Ÿæ—§æ±Ÿå±±æµ‘æ˜¯æ–°æ„ã€‚<strong>æ¬²ä¹°æ¡‚èŠ±åŒè½½é…’ï¼Œç»ˆä¸ä¼¼ã€å°‘å¹´æ¸¸ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b922e7c4c9710055904842" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b922e7c4c9710055904842</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Vimå¸¸ç”¨å¿«æ·é”®</title>
      <link href="/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Vim%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
      <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Vim%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<p>åœ¨æœåŠ¡å™¨ç»å¸¸è¦ç”¨åˆ°Vimï¼Œå› æ­¤è®°å½•å¸¸ç”¨çš„å¿«æ·é”®å¹¶ç†Ÿæ‚‰ä¹‹ã€‚</p><h3 id="é€€å‡º"><a href="#é€€å‡º" class="headerlink" title="é€€å‡º"></a>é€€å‡º</h3><p>:q é€€å‡º<br>:wq å†™å…¥å¹¶é€€å‡º<br>:q! é€€å‡ºå¹¶å¿½ç•¥æ‰€æœ‰æ›´æ”¹<br>:e! æ”¾å¼ƒä¿®æ”¹å¹¶æ‰“å¼€åŸæ¥çš„æ–‡ä»¶</p><h3 id="æ’å…¥"><a href="#æ’å…¥" class="headerlink" title="æ’å…¥"></a>æ’å…¥</h3><p>i åœ¨å½“å‰ä½ç½®å‰æ’å…¥<br>a åœ¨å½“å‰ä½ç½®åæ’å…¥</p><h3 id="æ’¤é”€"><a href="#æ’¤é”€" class="headerlink" title="æ’¤é”€"></a>æ’¤é”€</h3><p>:u æ’¤é”€<br>:U æ’¤é”€æ•´è¡Œæ“ä½œ<br>Ctrl+r é‡åš</p><h3 id="åˆ é™¤"><a href="#åˆ é™¤" class="headerlink" title="åˆ é™¤"></a>åˆ é™¤</h3><p>:md åˆ é™¤ç¬¬mè¡Œ<br>nd åˆ é™¤å½“å‰è¡Œå¼€å§‹çš„nè¡Œ(ä¸€å…±n+1è¡Œ)<br>dd åˆ é™¤å½“å‰è¡Œ<br>D åˆ é™¤å½“å‰å­—ç¬¦è‡³è¡Œå°¾<br>:m,nd åˆ é™¤ä»måˆ°nè¡Œçš„å†…å®¹ï¼Œå¦‚: <code>:100,10000d</code><br>:m,$d åˆ é™¤mè¡ŒåŠä»¥åæ‰€æœ‰çš„è¡Œ<br>:10d</p><h3 id="ç§»åŠ¨"><a href="#ç§»åŠ¨" class="headerlink" title="ç§»åŠ¨"></a>ç§»åŠ¨</h3><p>:n è·³è½¬åˆ°è¡Œå·  å¦‚ï¼Œ :100<br>gg è·³åˆ°è¡Œé¦–<br>G(shift+g)ç§»åŠ¨åˆ°æ–‡ä»¶å°¾</p><h3 id="æœç´¢"><a href="#æœç´¢" class="headerlink" title="æœç´¢"></a>æœç´¢</h3><p>/text æœç´¢textï¼Œnæœç´¢ä¸‹ä¸€ä¸ªï¼ŒNæœç´¢ä¸Šä¸€ä¸ª<br>?text åå‘æŸ¥æ‰¾<br>:set ignorecase å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>:set noignorecase ä¸å¿½ç•¥å¤§å°å†™æŸ¥æ‰¾<br>*æˆ–# å¯¹å…‰æ ‡å¤„çš„å•è¯æœç´¢</p><h3 id="å¤åˆ¶ç²˜è´´"><a href="#å¤åˆ¶ç²˜è´´" class="headerlink" title="å¤åˆ¶ç²˜è´´"></a>å¤åˆ¶ç²˜è´´</h3><p>v ä»å½“å‰ä½ç½®å¼€å§‹ï¼Œå…‰æ ‡ç»è¿‡çš„åœ°æ–¹è¢«é€‰ä¸­ï¼Œå†æŒ‰ä¸€ä¸‹vç»“æŸ</p><h3 id="ç¯å¢ƒè®¾ç½®"><a href="#ç¯å¢ƒè®¾ç½®" class="headerlink" title="ç¯å¢ƒè®¾ç½®"></a>ç¯å¢ƒè®¾ç½®</h3><p>:set nu æ˜¾ç¤ºè¡Œå·<br>:set nonu éšè—è¡Œå·<br>:set hlsearch è®¾ç½®æœç´¢ç»“æœé«˜äº®</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/wangrx/p/5907013.html" target="_blank" rel="noopener">https://www.cnblogs.com/wangrx/p/5907013.html</a><br><a href="https://www.cnblogs.com/yangjig/p/6014198.html" target="_blank" rel="noopener">https://www.cnblogs.com/yangjig/p/6014198.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æŠ€å·§ </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> å¿«æ·é”® </tag>
            
            <tag> Vim </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pycharmå¸¸ç”¨æŠ€å·§</title>
      <link href="/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Pycharm%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
      <url>/2018/08/10/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Pycharm%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<p>è®°å½•Pycharmçš„ä¸€äº›æŠ€å·§ï¼Œè®©Pycharmæ›´é¡ºæ‰‹</p><h3 id="å¿«æ·é”®"><a href="#å¿«æ·é”®" class="headerlink" title="å¿«æ·é”®"></a>å¿«æ·é”®</h3><p>0ï¸âƒ£Double Shift ä¸‡èƒ½æœç´¢<br>å¯ä»¥æœç´¢<strong>æ–‡ä»¶åã€ç±»åã€æ–¹æ³•åã€ç›®å½•å</strong>ï¼ˆåœ¨å…³é”®å­—å‰é¢åŠ / ï¼‰ï¼Œå¹¶ä¸èƒ½ç”¨æ¥æœç´¢ä»»æ„å…³é”®å­—</p><p>1ï¸âƒ£ Command+F åœ¨é¡µé¢æœç´¢</p><p>2ï¸âƒ£ Ctrl+Shift+F Find in Path åœ¨è·¯å¾„ä¸‹æœç´¢</p><p>3ï¸âƒ£âœ¨Command+E å¿«é€ŸæŸ¥æ‰¾æ–‡ä»¶<br>æ˜¾ç¤ºæœ€è¿‘æ‰“å¼€çš„æ–‡ä»¶</p><p>4ï¸âƒ£ Shift+Enter ä»»æ„ä½ç½®æ¢è¡Œ<br>æ— è®ºå…‰æ ‡åœ¨ä½•å¤„éƒ½å¯ä»¥ç›´æ¥å¦èµ·ä¸€è¡Œ</p><p>5ï¸âƒ£ Option+Enter è‡ªåŠ¨å¯¼å…¥æ¨¡å—ï¼›ä¸‡èƒ½æç¤ºé”®<br>è‡ªåŠ¨å¯¼å…¥å¦‚ä½•è®¾ç½®è§å°æŠ€å·§#0ï¸âƒ£</p><p>6ï¸âƒ£ Ctrl+F10 è¿è¡Œ<br>æˆ‘å·²ç»æ·»åŠ äº†Ctrl+Rä½œä¸ºå¦ä¸€å¯¹è¿è¡Œå¿«æ·é”®</p><p>7ï¸âƒ£ Command+Shift+ +/-  å±•å¼€/æ”¶ç¼©ä»£ç  </p><p>8ï¸âƒ£ Option+F åœ¨Dashä¸­æœç´¢</p><p>9ï¸âƒ£ Ctrl+J ä¸è·³è½¬æŸ¥çœ‹ä»£ç </p><h3 id="å°æŠ€å·§"><a href="#å°æŠ€å·§" class="headerlink" title="å°æŠ€å·§"></a>å°æŠ€å·§</h3><p>0ï¸âƒ£ Pycharmè‡ªåŠ¨å¯¼å…¥æ¨¡å—<br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a></p><p>1ï¸âƒ£ âœ¨è¿œç¨‹éƒ¨ç½²å·¥ç¨‹ å¼ºçƒˆæ¨è<br>ä¸¤æ­¥èµ°ï¼šé…ç½®æœåŠ¡å™¨æ˜ å°„+é…ç½®æœåŠ¡å™¨è§£é‡Šå™¨</p><p>2ï¸âƒ£è·³è½¬åå¦‚ä½•å›é€€<br>å¼€å¯toolbarå³å¯<br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://foofish.net/pycharm-tips.html" target="_blank" rel="noopener">https://foofish.net/pycharm-tips.html</a><br><a href="https://blog.csdn.net/lantian_123/article/details/78094148" target="_blank" rel="noopener">https://blog.csdn.net/lantian_123/article/details/78094148</a><br><a href="https://segmentfault.com/a/1190000010205945" target="_blank" rel="noopener">https://segmentfault.com/a/1190000010205945</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> æŠ€å·§ </tag>
            
            <tag> Pycharm </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> å¿«æ·é”® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ— é¢˜</title>
      <link href="/2018/08/06/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E9%A2%98/"/>
      <url>/2018/08/06/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%97%A0%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>äººè¿™è¾ˆå­ä¸€å…±ä¼šæ­»ä¸‰æ¬¡ã€‚</p><p>ç¬¬ä¸€æ¬¡æ˜¯ä½ çš„å¿ƒè„åœæ­¢è·³åŠ¨ï¼Œé‚£ä¹ˆä»ç”Ÿç‰©çš„è§’åº¦æ¥è¯´ï¼Œä½ æ­»äº†ï¼›</p><p>ç¬¬äºŒæ¬¡æ˜¯åœ¨è‘¬ç¤¼ä¸Šï¼Œè®¤è¯†ä½ çš„äººéƒ½æ¥ç¥­å¥ ï¼Œé‚£ä¹ˆä½ åœ¨ç¤¾ä¼šå…³ç³»ä¸Šçš„äº‹å®å­˜åœ¨å°±æ­»äº†ï¼›</p><p>ç¬¬ä¸‰æ¬¡æ˜¯åœ¨æœ€åä¸€ä¸ªè®°å¾—ä½ çš„äººæ­»åï¼Œé‚£ä½ å°±çœŸçš„æ­»äº†ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>äººå¯ä»¥å‘å¾®å¦‚å°˜åœŸ,ä¸å¯æ‰­æ›²å¦‚è›†è™«</title>
      <link href="/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E5%8F%AF%E4%BB%A5%E5%8D%91%E5%BE%AE%E5%A6%82%E5%B0%98%E5%9C%9F,%E4%B8%8D%E5%8F%AF%E6%89%AD%E6%9B%B2%E5%A6%82%E8%9B%86%E8%99%AB/"/>
      <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E4%BA%BA%E5%8F%AF%E4%BB%A5%E5%8D%91%E5%BE%AE%E5%A6%82%E5%B0%98%E5%9C%9F,%E4%B8%8D%E5%8F%AF%E6%89%AD%E6%9B%B2%E5%A6%82%E8%9B%86%E8%99%AB/</url>
      
        <content type="html"><![CDATA[<p>å¦‚æœå¤©æ€»ä¹Ÿä¸äº®ï¼Œé‚£å°±æ‘¸é»‘è¿‡ç”Ÿæ´»; </p><p>å¦‚æœå‘å‡ºå£°éŸ³æ˜¯å±é™©çš„ï¼Œé‚£å°±ä¿æŒæ²‰é»˜; </p><p>å¦‚æœè‡ªè§‰æ— åŠ›å‘å…‰ï¼Œé‚£å°±åˆ«å»ç…§äº®åˆ«äººã€‚ </p><p>ä½†æ˜¯â€”â€”ä¸è¦ä¹ æƒ¯äº†é»‘æš—å°±ä¸ºé»‘æš—è¾©æŠ¤; </p><p>ä¸è¦ä¸ºè‡ªå·±çš„è‹Ÿä¸”è€Œå¾—æ„æ´‹æ´‹; </p><p>ä¸è¦å˜²è®½é‚£äº›æ¯”è‡ªå·±æ›´å‹‡æ•¢ã€æ›´æœ‰çƒ­é‡çš„äººä»¬ã€‚ </p><p><strong>å¯ä»¥å‘å¾®å¦‚å°˜åœŸï¼Œä¸å¯æ‰­æ›²å¦‚è›†è™«</strong>ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ä½³å¥åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pythonæƒ¯ä¾‹[è½¬]</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E6%83%AF%E4%BE%8B/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/Python%E6%83%AF%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>fork from <a href="https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md" target="_blank" rel="noopener">https://github.com/jackfrued/Python-100-Days/blob/master/Pythonæƒ¯ä¾‹.md</a></p><h2 id="Pythonæƒ¯ä¾‹"><a href="#Pythonæƒ¯ä¾‹" class="headerlink" title="Pythonæƒ¯ä¾‹"></a>Pythonæƒ¯ä¾‹</h2><p>â€œæƒ¯ä¾‹â€è¿™ä¸ªè¯æŒ‡çš„æ˜¯â€œä¹ æƒ¯çš„åšæ³•ï¼Œå¸¸è§„çš„åŠæ³•ï¼Œä¸€è´¯çš„åšæ³•â€ï¼Œä¸è¿™ä¸ªè¯å¯¹åº”çš„è‹±æ–‡å•è¯å«â€œidiomâ€ã€‚ç”±äºPythonè·Ÿå…¶ä»–å¾ˆå¤šç¼–ç¨‹è¯­è¨€åœ¨è¯­æ³•å’Œä½¿ç”¨ä¸Šè¿˜æ˜¯æœ‰æ¯”è¾ƒæ˜¾è‘—çš„å·®åˆ«ï¼Œå› æ­¤ä½œä¸ºä¸€ä¸ªPythonå¼€å‘è€…å¦‚æœä¸èƒ½æŒæ¡è¿™äº›æƒ¯ä¾‹ï¼Œå°±æ— æ³•å†™å‡ºâ€œPythonicâ€çš„ä»£ç ã€‚ä¸‹é¢æˆ‘ä»¬æ€»ç»“äº†ä¸€äº›åœ¨Pythonå¼€å‘ä¸­çš„æƒ¯ç”¨çš„ä»£ç ã€‚</p><ol><li><p>è®©ä»£ç æ—¢å¯ä»¥è¢«å¯¼å…¥åˆå¯ä»¥è¢«æ‰§è¡Œã€‚ </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br></pre></td></tr></table></figure></li><li><p>ç”¨ä¸‹é¢çš„æ–¹å¼åˆ¤æ–­é€»è¾‘â€œçœŸâ€æˆ–â€œå‡â€ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x:</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> x:</span><br></pre></td></tr></table></figure><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name <span class="keyword">and</span> fruits <span class="keyword">and</span> owners:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'jackfrued'</span></span><br><span class="line">fruits = [<span class="string">'apple'</span>, <span class="string">'orange'</span>, <span class="string">'grape'</span>]</span><br><span class="line">owners = &#123;<span class="string">'1001'</span>: <span class="string">'éª†æ˜Š'</span>, <span class="string">'1002'</span>: <span class="string">'ç‹å¤§é”¤'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> name != <span class="string">''</span> <span class="keyword">and</span> len(fruits) &gt; <span class="number">0</span> <span class="keyword">and</span> owners != &#123;&#125;:</span><br><span class="line">    print(<span class="string">'I love fruits!'</span>)</span><br></pre></td></tr></table></figure></li><li><p>å–„äºä½¿ç”¨inè¿ç®—ç¬¦ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> x <span class="keyword">in</span> items: <span class="comment"># åŒ…å«</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> items: <span class="comment"># è¿­ä»£</span></span><br></pre></td></tr></table></figure><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'L'</span> <span class="keyword">in</span> name:</span><br><span class="line">    print(<span class="string">'The name has an L in it.'</span>)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Hao LUO'</span></span><br><span class="line"><span class="keyword">if</span> name.find(<span class="string">'L'</span>) != <span class="number">-1</span>:</span><br><span class="line">    print(<span class="string">'This name has an L in it!'</span>)</span><br></pre></td></tr></table></figure></li><li><p>ä¸ä½¿ç”¨ä¸´æ—¶å˜é‡äº¤æ¢ä¸¤ä¸ªå€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure></li><li><p><strong>ç”¨åºåˆ—æ„å»ºå­—ç¬¦ä¸²</strong>ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span>.join(chars)</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chars = [<span class="string">'j'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'k'</span>, <span class="string">'f'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>]</span><br><span class="line">name = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> char <span class="keyword">in</span> chars:</span><br><span class="line">    name += char</span><br><span class="line">print(name)  <span class="comment"># jackfrued</span></span><br></pre></td></tr></table></figure></li><li><p><strong>EAFPä¼˜äºLBYL</strong>ã€‚</p><p>EAFP - <strong>E</strong>asier to <strong>A</strong>sk <strong>F</strong>orgiveness than <strong>P</strong>ermission.</p><p>LBYL - <strong>L</strong>ook <strong>B</strong>efore <strong>Y</strong>ou <strong>L</strong>eap.</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">except</span> (KeyError, TypeError, ValueError):</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'x'</span>: <span class="string">'5'</span>&#125;</span><br><span class="line"><span class="keyword">if</span> <span class="string">'x'</span> <span class="keyword">in</span> d <span class="keyword">and</span> isinstance(d[<span class="string">'x'</span>], str) \</span><br><span class="line"><span class="keyword">and</span> d[<span class="string">'x'</span>].isdigit():</span><br><span class="line">    value = int(d[<span class="string">'x'</span>])</span><br><span class="line">    print(value)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    value = <span class="keyword">None</span></span><br></pre></td></tr></table></figure></li><li><p>ä½¿ç”¨enumerateè¿›è¡Œè¿­ä»£ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line"><span class="keyword">for</span> index, fruit <span class="keyword">in</span> enumerate(fruits):</span><br><span class="line">print(index, <span class="string">':'</span>, fruit)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fruits = [<span class="string">'orange'</span>, <span class="string">'grape'</span>, <span class="string">'pitaya'</span>, <span class="string">'blueberry'</span>]</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> fruit <span class="keyword">in</span> fruits:</span><br><span class="line">    print(index, <span class="string">':'</span>, fruit)</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>ç”¨ç”Ÿæˆå¼ç”Ÿæˆåˆ—è¡¨ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = [num * <span class="number">3</span> <span class="keyword">for</span> num <span class="keyword">in</span> data <span class="keyword">if</span> num &gt; <span class="number">10</span>]</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">7</span>, <span class="number">20</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">11</span>]</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">        result.append(i * <span class="number">3</span>)</span><br><span class="line">print(result)  <span class="comment"># [60, 45, 33]</span></span><br></pre></td></tr></table></figure></li><li><p>ç”¨zipç»„åˆé”®å’Œå€¼æ¥åˆ›å»ºå­—å…¸ã€‚</p><p><strong>å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = dict(zip(keys, values))</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure><p><strong>ä¸å¥½</strong>çš„ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keys = [<span class="string">'1001'</span>, <span class="string">'1002'</span>, <span class="string">'1003'</span>]</span><br><span class="line">values = [<span class="string">'éª†æ˜Š'</span>, <span class="string">'ç‹å¤§é”¤'</span>, <span class="string">'ç™½å…ƒèŠ³'</span>]</span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i, key <span class="keyword">in</span> enumerate(keys):</span><br><span class="line">    d[key] = values[i]</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure></li></ol><blockquote><p><strong>è¯´æ˜</strong>ï¼šè¿™ç¯‡æ–‡ç« çš„å†…å®¹æ¥è‡ªäºç½‘ç»œï¼Œæœ‰å…´è¶£çš„è¯»è€…å¯ä»¥é˜…è¯»<a href="http://safehammad.com/downloads/python-idioms-2014-01-16.pdf" target="_blank" rel="noopener">åŸæ–‡</a>ã€‚</p></blockquote><p>æ³¨ï¼š<br>è®¸å¤šåŸåˆ™æˆ‘è®¤ä¸ºéå¸¸æœ‰æ„ä¹‰ï¼Œèƒ½å¤Ÿæ‘†è„±C/C++çš„é£æ ¼ï¼ŒçœŸæ­£å†™å‡ºPythonicçš„ä»£ç ã€‚è®©æˆ‘æœ‰å¾ˆå¤§æ„Ÿè§¦çš„æ˜¯1ã€3ã€8ï¼Œèƒ½å¤Ÿå†™å‡ºéå¸¸ç®€æ´ä¼˜é›…çš„ä»£ç ã€‚åŒæ—¶6æˆ‘ä¹‹å‰ä»æ²¡æ³¨æ„è¿‡ï¼Œä¹ æƒ¯äº†C/C++é£æ ¼ä¹‹åæ€»æ˜¯ä¼šåœ¨æ‰§è¡Œä¹‹å‰è€ƒè™‘æ‰€æœ‰æƒ…å†µï¼Œä½†ç¡®å®ä¸å¤Ÿä¼˜é›…ï¼Œä»Šåå¯ä»¥å°è¯•EAFPé£æ ¼ï¼ˆ<a href="https://stackoverflow.com/questions/11360858/what-is-the-eafp-principle-in-python" target="_blank" rel="noopener">ä»€ä¹ˆæ˜¯EAFP</a>ï¼‰ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å¦‚ä½•è®­ç»ƒGloVeä¸­æ–‡è¯å‘é‡</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83GloVe%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83GloVe%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="å‡†å¤‡è¯­æ–™"><a href="#å‡†å¤‡è¯­æ–™" class="headerlink" title="å‡†å¤‡è¯­æ–™"></a>å‡†å¤‡è¯­æ–™</h3><p>å‡†å¤‡å¥½è‡ªå·±çš„è¯­æ–™ï¼Œä¿å­˜ä¸ºtxtï¼Œæ¯è¡Œä¸€ä¸ªå¥å­æˆ–ä¸€æ®µè¯ï¼Œæ³¨æ„è¦åˆ†å¥½è¯ã€‚</p><p><img src="/images/2018-08-05-15334388069130.jpg" width="60%" height="60%"></p><h3 id="å‡†å¤‡æºç "><a href="#å‡†å¤‡æºç " class="headerlink" title="å‡†å¤‡æºç "></a>å‡†å¤‡æºç </h3><p>ä»GitHubä¸‹è½½ä»£ç ï¼Œ<a href="https://github.com/stanfordnlp/GloVe" target="_blank" rel="noopener">https://github.com/stanfordnlp/GloVe</a><br>å°†è¯­æ–™corpus.txtæ”¾å…¥åˆ°Gloveçš„ä¸»æ–‡ä»¶å¤¹ä¸‹ã€‚</p><h3 id="ä¿®æ”¹bash"><a href="#ä¿®æ”¹bash" class="headerlink" title="ä¿®æ”¹bash"></a>ä¿®æ”¹bash</h3><p>æ‰“å¼€demo.shï¼Œä¿®æ”¹ç›¸åº”çš„å†…å®¹</p><ol><li>å› ä¸ºdemoé»˜è®¤æ˜¯ä¸‹è½½ç½‘ä¸Šçš„è¯­æ–™æ¥è®­ç»ƒçš„ï¼Œå› æ­¤å¦‚æœè¦è®­ç»ƒè‡ªå·±çš„è¯­æ–™ï¼Œéœ€è¦æ³¨é‡Šæ‰</li></ol><p><img src="/images/2018-08-05-15334390298383.jpg" width="70%" height="50%"></p><ol><li>ä¿®æ”¹å‚æ•°è®¾ç½®ï¼Œå°†CORPUSè®¾ç½®æˆè¯­æ–™çš„åå­—</li></ol><p><img src="/images/2018-08-05-15334391029224.jpg" width="50%" height="50%"></p><h3 id="æ‰§è¡Œbashæ–‡ä»¶"><a href="#æ‰§è¡Œbashæ–‡ä»¶" class="headerlink" title="æ‰§è¡Œbashæ–‡ä»¶"></a>æ‰§è¡Œbashæ–‡ä»¶</h3><p>è¿›å…¥åˆ°ä¸»æ–‡ä»¶å¤¹ä¸‹</p><ol><li>make</li></ol><p><img src="/images/2018-08-05-15334392348665.jpg" width="70%" height="50%"></p><ol><li>bash demo.sh</li></ol><p><img src="/images/2018-08-05-15334392595148.jpg" width="70%" height="70%"></p><p>æ³¨æ„ï¼Œå¦‚æœè®­ç»ƒæ•°æ®è¾ƒå¤§ï¼Œåˆ™è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œé‚£ä¹ˆå»ºè®®ä½¿ç”¨nohupæ¥è¿è¡Œç¨‹åº</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bash demo.sh &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>åç­‰è®­ç»ƒï¼Œæœ€åä¼šå¾—åˆ°vectors.txt ä»¥åŠå…¶ä»–çš„ç›¸åº”çš„æ–‡ä»¶ã€‚å¦‚æœè¦ç”¨gensimçš„word2vec loadè¿›æ¥ï¼Œé‚£ä¹ˆéœ€è¦åœ¨vectors.txtçš„ç¬¬ä¸€è¡ŒåŠ ä¸Švacob_size vector_sizeï¼Œç¬¬ä¸€ä¸ªæ•°æŒ‡æ˜ä¸€å…±æœ‰å¤šå°‘ä¸ªå‘é‡ï¼Œç¬¬äºŒä¸ªæ•°æŒ‡æ˜æ¯ä¸ªå‘é‡æœ‰å¤šå°‘ç»´ã€‚</p><h3 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h3><p><a href="https://www.cnblogs.com/echo-cheng/p/8561171.html" target="_blank" rel="noopener">https://www.cnblogs.com/echo-cheng/p/8561171.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GloVe </tag>
            
            <tag> æ•™ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†2</title>
      <link href="/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%862/"/>
      <url>/2018/08/05/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%862/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Pytorch]<br>é¿å…å†™å‡ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.zeros(...), requires_grad=<span class="keyword">True</span>).cuda()</span><br></pre></td></tr></table></figure><p>è€Œæ˜¯åº”è¯¥è¦ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(torch.zeros(...).cuda(), requires_grad=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187" target="_blank" rel="noopener">https://discuss.pytorch.org/t/variable-grad-is-always-none-when-extending-autograd/12187</a></p><hr><p>2ï¸âƒ£[Tf-idf]<br>æœ¬å‘¨å› ä¸ºæ¯”èµ›çš„åŸå› äº†è§£äº†ä¸€ä¸‹å„ç§æ–‡æœ¬å»ºæ¨¡çš„æ–¹æ³•ã€‚Tf-idfèƒ½å¤Ÿå–å¾—ä¸é”™çš„æˆç»©ï¼Œä½†æœ‰ä¸€å®šçš„ç¼ºé™·ã€‚</p><blockquote><p>TF-IDFç”¨äºå‘é‡ç©ºé—´æ¨¡å‹ï¼Œè¿›è¡Œæ–‡æ¡£ç›¸ä¼¼åº¦è®¡ç®—æ˜¯ç›¸å½“æœ‰æ•ˆçš„ã€‚ä½†åœ¨æ–‡æœ¬åˆ†ç±»ä¸­å•çº¯ä½¿ç”¨TF-IDFæ¥åˆ¤æ–­ä¸€ä¸ªç‰¹å¾æ˜¯å¦æœ‰åŒºåˆ†åº¦æ˜¯ä¸å¤Ÿçš„ã€‚</p><ol><li>å®ƒä»…ä»…ç»¼åˆè€ƒè™‘äº†è¯¥è¯åœ¨æ–‡æ¡£ä¸­çš„é‡è¦ç¨‹åº¦å’Œæ–‡æ¡£åŒºåˆ†åº¦ã€‚</li><li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»é—´çš„åˆ†å¸ƒã€‚ç‰¹å¾é€‰æ‹©æ‰€é€‰æ‹©çš„ç‰¹å¾åº”è¯¥åœ¨æŸç±»å‡ºç°å¤šï¼Œè€Œå…¶å®ƒç±»å‡ºç°å°‘ï¼Œå³è€ƒå¯Ÿå„ç±»çš„æ–‡æ¡£é¢‘ç‡çš„å·®å¼‚ã€‚å¦‚æœä¸€ä¸ªç‰¹å¾è¯ï¼Œåœ¨å„ä¸ªç±»é—´åˆ†å¸ƒæ¯”è¾ƒå‡åŒ€ï¼Œè¿™æ ·çš„è¯å¯¹åˆ†ç±»åŸºæœ¬æ²¡æœ‰è´¡çŒ®ï¼›ä½†æ˜¯å¦‚æœä¸€ä¸ªç‰¹å¾è¯æ¯”è¾ƒé›†ä¸­çš„åˆ†å¸ƒåœ¨æŸä¸ªç±»ä¸­ï¼Œè€Œåœ¨å…¶å®ƒç±»ä¸­å‡ ä¹ä¸å‡ºç°ï¼Œè¿™æ ·çš„è¯å´èƒ½å¤Ÿå¾ˆå¥½ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œè€ŒTF-IDFä¸èƒ½åŒºåˆ†è¿™ä¸¤ç§æƒ…å†µã€‚</li><li>å®ƒæ²¡æœ‰è€ƒè™‘ç‰¹å¾è¯åœ¨ç±»å†…éƒ¨æ–‡æ¡£ä¸­çš„åˆ†å¸ƒæƒ…å†µã€‚åœ¨ç±»å†…éƒ¨çš„æ–‡æ¡£ä¸­ï¼Œå¦‚æœç‰¹å¾è¯å‡åŒ€åˆ†å¸ƒåœ¨å…¶ä¸­ï¼Œåˆ™è¿™ä¸ªç‰¹å¾è¯èƒ½å¤Ÿå¾ˆå¥½çš„ä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ï¼Œå¦‚æœåªåœ¨å‡ ç¯‡æ–‡æ¡£ä¸­å‡ºç°ï¼Œè€Œåœ¨æ­¤ç±»çš„å…¶å®ƒæ–‡æ¡£ä¸­ä¸å‡ºç°ï¼Œæ˜¾ç„¶è¿™æ ·çš„ç‰¹å¾è¯ä¸èƒ½å¤Ÿä»£è¡¨è¿™ä¸ªç±»çš„ç‰¹å¾ã€‚</li></ol></blockquote><p>Reference:<br><a href="https://blog.csdn.net/mmc2015/article/details/46771791" target="_blank" rel="noopener">https://blog.csdn.net/mmc2015/article/details/46771791</a></p><hr><p>3ï¸âƒ£[å¡æ–¹æ£€éªŒCHI]<br>åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œç”¨äºé€‰æ‹©æœ€ç›¸å…³çš„ç‰¹å¾ã€‚</p><p>Reference:<br><a href="https://blog.csdn.net/blockheadls/article/details/49977361" target="_blank" rel="noopener">https://blog.csdn.net/blockheadls/article/details/49977361</a></p><hr><p>4ï¸âƒ£[æ–‡æœ¬åˆ†ç±»]<br>å„ç§æ–‡æœ¬åˆ†ç±»æ–¹æ³•çš„ç®€å•ä»‹ç»ã€‚</p><p>Reference:<br><a href="https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md" target="_blank" rel="noopener">https://github.com/wangjiang0624/Note/blob/master/MachineLearning/æ–‡æœ¬åˆ†ç±».md</a></p><hr><p>5ï¸âƒ£[Python]<br>collectionsçš„ä¸¤ä¸ªæœ‰ç”¨çš„ç±»</p><ol><li>named_tupleï¼šå¿«é€Ÿå»ºç«‹ä¸€ä¸ªç±»ï¼Œä½¿å¾—å¯ä»¥ä½¿ç”¨å±æ€§æ¥è®¿é—®è€Œéç´¢å¼•ï¼Œæé«˜äº†ä»£ç å¯è¯»æ€§</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line">Point = namedtuple(<span class="string">'Point'</span>,[<span class="string">'x'</span>,<span class="string">'y'</span>])</span><br><span class="line">p = Point(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">print(p.x)  <span class="comment"># 1</span></span><br><span class="line">print(p.y)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure><ol><li>Counterï¼šç»Ÿè®¡å­—ç¬¦å‡ºç°çš„æ¬¡æ•°</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">count = Counter([...]).most_commom()  <span class="comment">#ä¼šæŒ‰ç…§å‡ºç°çš„æ¬¡æ•°æ’åºï¼Œé€šå¸¸å¯ç”¨äºæ„å»ºè¯å…¸</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> count:     <span class="comment"># cæ˜¯ä¸€ä¸ªtupleï¼Œc[0]æ˜¯è¯ï¼Œc[1]æ˜¯é¢‘ç‡</span></span><br><span class="line">    <span class="keyword">if</span> c[<span class="number">1</span>]&gt;= threshold:</span><br><span class="line">        vocab.add_word(c[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>Counterç”¨æ³•ï¼š<br><a href="https://blog.csdn.net/u014755493/article/details/69812244" target="_blank" rel="noopener">https://blog.csdn.net/u014755493/article/details/69812244</a></p><hr><p>6ï¸âƒ£[nohup]<br>æœ¬å‘¨åœ¨æœåŠ¡å™¨ä¸Šè·‘ä»£ç çš„æ—¶å€™é‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨nohupæ‰§è¡Œpythonç¨‹åºæ—¶ï¼Œå‘ç°è¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ˜¾ç¤ºã€‚ä»¥ä¸ºæ˜¯ä»£ç çš„é—®é¢˜ï¼Œä½†ç»è¿‡æ’æŸ¥å¹¶éæ˜¯ä»£ç çš„é—®é¢˜ã€‚é€šè¿‡æŸ¥é˜…èµ„æ–™ï¼Œå‘ç°é—®é¢˜æ‰€åœ¨ï¼š<br>å› ä¸ºpythonè¾“å‡ºæœ‰ç¼“å†²ï¼Œå¯¼è‡´outputä¸èƒ½<strong>é©¬ä¸Š</strong>çœ‹åˆ°è¾“å‡ºã€‚å®é™…ä¸Šï¼Œåœ¨ç­‰å¾…äº†ä¸€æ®µæ—¶é—´åï¼Œè¾“å‡ºæ–‡ä»¶ç»ˆäºæ˜¾ç¤ºå‡ºæ¥äº†ã€‚</p><p>è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨pythonçš„å‚æ•° -u ä½¿å¾—pythonä¸å¯ç”¨ç¼“å†²ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://blog.csdn.net/sunlylorn/article/details/19127107" target="_blank" rel="noopener">https://blog.csdn.net/sunlylorn/article/details/19127107</a></p><hr><p>7ï¸âƒ£[hexoé…ç½®]</p><ol><li>mathjaxé…ç½®: <a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">https://www.jianshu.com/p/7ab21c7f0674</a></li><li>é…ç½®åŸŸå:<a href="https://www.zhihu.com/question/31377141" target="_blank" rel="noopener">https://www.zhihu.com/question/31377141</a></li><li>é…ç½®sitemap:<a href="http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/" target="_blank" rel="noopener">http://www.yuan-ji.me/Hexo-ä¼˜åŒ–ï¼šæäº¤sitemapåŠè§£å†³ç™¾åº¦çˆ¬è™«æŠ“å–-GitHub-Pages-é—®é¢˜/</a></li></ol><hr><p>8ï¸âƒ£[Paper]<br><a href="http://aclweb.org/anthology/D17-1025" target="_blank" rel="noopener">Learning Chinese Word Representations From Glyphs Of Characters</a></p><p>ä½¿ç”¨å›¾åƒçš„å·ç§¯æ¥ç”Ÿæˆè¯å‘é‡:<br><img src="/images/2018-08-05-15334453515509.jpg" width="60%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Paper </tag>
            
            <tag> Tf-idf </tag>
            
            <tag> æ–‡æœ¬åˆ†ç±» </tag>
            
            <tag> hexo </tag>
            
            <tag> nohup </tag>
            
            <tag> CHI </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•3</title>
      <link href="/2018/08/05/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB3/"/>
      <url>/2018/08/05/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB3/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨åªæœ‰ç®€å•çš„ä»£ç ã€‚</p><h3 id="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"><a href="#1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec" class="headerlink" title="1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec"></a>1ï¸âƒ£ä½¿ç”¨gensimè®­ç»ƒword2vec</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=utf-8</span></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line">sentences=word2vec.Text8Corpus(<span class="string">u'åˆ†è¯åçš„çˆ½è‚¤æ°´è¯„è®º.txt'</span>)   <span class="comment">#sentence:[ [ a b ],[c d]... ]</span></span><br><span class="line">model=word2vec.Word2Vec(sentences, size=<span class="number">50</span>)  <span class="comment">#size:dim </span></span><br><span class="line"></span><br><span class="line">y2=model.similarity(<span class="string">u"å¥½"</span>, <span class="string">u"è¿˜è¡Œ"</span>)  <span class="comment">#è®¡ç®—ç›¸ä¼¼åº¦</span></span><br><span class="line">print(y2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> model.most_similar(<span class="string">u"æ»‹æ¶¦"</span>):</span><br><span class="line">    <span class="keyword">print</span> i[<span class="number">0</span>],i[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment">#ä¿å­˜</span></span><br><span class="line">model.save(<span class="string">'/model/word2vec_model'</span>)</span><br><span class="line"></span><br><span class="line">new_model=gensim.models.Word2Vec.load(<span class="string">'/model/word2vec_model'</span>)</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"><a href="#2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨"></a>2ï¸âƒ£ä½¿ç”¨Counterå»ºç«‹è¯è¡¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dict</span><span class="params">(dataset,min_freq=<span class="number">5</span>)</span>:</span></span><br><span class="line">    dictionary=Dictionary() </span><br><span class="line">    count=Counter(flat(dataset)).most_common()  </span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> count:</span><br><span class="line">        <span class="keyword">if</span> c[<span class="number">1</span>]&gt;=min_freq:</span><br><span class="line">            dictionary.add_word(c[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> dictionary</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯3</title>
      <link href="/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D3/"/>
      <url>/2018/08/05/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D3/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨èƒŒçš„éƒ½æ˜¯æ¯”è¾ƒç®€å•çš„ã€‚</p><p>1ï¸âƒ£</p><h3 id="æŠŠé…’é—®æœˆ"><a href="#æŠŠé…’é—®æœˆ" class="headerlink" title="æŠŠé…’é—®æœˆ"></a>æŠŠé…’é—®æœˆ</h3><p>[å”] æç™½<br>é’å¤©æœ‰æœˆæ¥å‡ æ—¶ï¼Ÿæˆ‘ä»Šåœæ¯ä¸€é—®ä¹‹ã€‚<br>äººæ”€æ˜æœˆä¸å¯å¾—ï¼Œæœˆè¡Œå´ä¸äººç›¸éšã€‚<br>çšå¦‚é£é•œä¸´ä¸¹é˜™ï¼Œç»¿çƒŸç­å°½æ¸…è¾‰å‘ã€‚<br>ä½†è§å®µä»æµ·ä¸Šæ¥ï¼Œå®çŸ¥æ™“å‘äº‘é—´æ²¡ã€‚<br>ç™½å…”æ£è¯ç§‹å¤æ˜¥ï¼Œå«¦å¨¥å­¤æ –ä¸è°é‚»ï¼Ÿ<br><strong>ä»Šäººä¸è§å¤æ—¶æœˆï¼Œä»Šæœˆæ›¾ç»ç…§å¤äººã€‚<br>å¤äººä»Šäººè‹¥æµæ°´ï¼Œå…±çœ‹æ˜æœˆçš†å¦‚æ­¤ã€‚</strong><br><strong>å”¯æ„¿å½“æ­Œå¯¹é…’æ—¶ï¼Œæœˆå…‰é•¿ç…§é‡‘æ¨½é‡Œã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f6f4165abd0054bf8c13</a></p><hr><p>2ï¸âƒ£</p><h3 id="é‡‘ç¼•è¡£"><a href="#é‡‘ç¼•è¡£" class="headerlink" title="é‡‘ç¼•è¡£"></a>é‡‘ç¼•è¡£</h3><p>[å”] æœç§‹å¨˜<br>åŠå›è«æƒœé‡‘ç¼•è¡£ï¼ŒåŠå›æƒœå–å°‘å¹´æ—¶ã€‚<br><strong>èŠ±å¼€å ªæŠ˜ç›´é¡»æŠ˜ï¼Œè«å¾…æ— èŠ±ç©ºæŠ˜æã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92bdca633bd00665eb99e</a></p><hr><p>3ï¸âƒ£</p><h3 id="åŒ—é’è"><a href="#åŒ—é’è" class="headerlink" title="åŒ—é’è"></a>åŒ—é’è</h3><p>[å”] æå•†éš<br>æ®‹é˜³è¥¿å…¥å´¦ï¼ŒèŒ…å±‹è®¿å­¤åƒ§ã€‚<br>è½å¶äººä½•åœ¨ï¼Œå¯’äº‘è·¯å‡ å±‚ã€‚<br>ç‹¬æ•²åˆå¤œç£¬ï¼Œé—²å€šä¸€æè—¤ã€‚<br><strong>ä¸–ç•Œå¾®å°˜é‡Œï¼Œå¾å®çˆ±ä¸æ†ã€‚</strong></p><p>å´¦ï¼ˆyÄnï¼‰ï¼šå³â€œå´¦åµ«ï¼ˆzÄ«ï¼‰â€ï¼Œå±±åï¼Œåœ¨ç”˜è‚ƒã€‚å¤æ—¶å¸¸ç”¨æ¥æŒ‡å¤ªé˜³è½å±±çš„åœ°æ–¹ã€‚<br><strong>ç£¬ï¼ˆqÃ¬ngï¼‰</strong>ï¼šå¤ä»£æ‰“å‡»ä¹å™¨ï¼Œå½¢çŠ¶åƒæ›²å°ºï¼Œç”¨ç‰ã€çŸ³åˆ¶æˆï¼Œå¯æ‚¬æŒ‚ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ee240a2b58005c91c99e</a></p><hr><p>4ï¸âƒ£</p><h3 id="å¤æ—¥ç»å¥"><a href="#å¤æ—¥ç»å¥" class="headerlink" title="å¤æ—¥ç»å¥"></a>å¤æ—¥ç»å¥</h3><p>[å®‹] ææ¸…ç…§<br>ç”Ÿå½“ä½œäººæ°ï¼Œæ­»äº¦ä¸ºé¬¼é›„ã€‚<br><strong>è‡³ä»Šæ€é¡¹ç¾½ï¼Œä¸è‚¯è¿‡æ±Ÿä¸œã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b911dac4c97100558fb30e</a></p><hr><p>5ï¸âƒ£</p><h3 id="é›¨éœ–é“ƒ"><a href="#é›¨éœ–é“ƒ" class="headerlink" title="é›¨éœ–é“ƒ"></a>é›¨éœ–é“ƒ</h3><p>[å®‹] æŸ³æ°¸<br>å¯’è‰å‡„åˆ‡ï¼Œå¯¹é•¿äº­æ™šï¼Œéª¤é›¨åˆæ­‡ã€‚éƒ½é—¨å¸é¥®æ— ç»ªï¼Œç•™æ‹å¤„ï¼Œå…°èˆŸå‚¬å‘ã€‚æ‰§æ‰‹ç›¸çœ‹æ³ªçœ¼ï¼Œç«Ÿæ— è¯­å‡å™ã€‚å¿µå»å»ï¼Œåƒé‡ŒçƒŸæ³¢ï¼Œæš®éœ­æ²‰æ²‰æ¥šå¤©é˜”ã€‚<br><strong>å¤šæƒ…è‡ªå¤ä¼¤ç¦»åˆ«</strong>ï¼Œæ›´é‚£å ªã€å†·è½æ¸…ç§‹èŠ‚ã€‚ä»Šå®µé…’é†’ä½•å¤„ï¼Ÿæ¨æŸ³å²¸ï¼Œæ™“é£æ®‹æœˆã€‚æ­¤å»ç»å¹´ï¼Œåº”æ˜¯è‰¯è¾°å¥½æ™¯è™šè®¾ã€‚<strong>ä¾¿çºµæœ‰åƒç§é£æƒ…ï¼Œæ›´ä¸ä½•äººè¯´</strong>ï¼Ÿ</p><p><a href="http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ad742f5bbb500062bc7c9c</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºPytorchä¸­gradçš„ç†è§£</title>
      <link href="/2018/08/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADgrad%E7%9A%84%E7%90%86%E8%A7%A3/"/>
      <url>/2018/08/03/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8EPytorch%E4%B8%ADgrad%E7%9A%84%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>äº‹æƒ…èµ·æºäºæˆ‘å†™äº†ä¸€ä¸ªCNNç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œä½†lossä¸€ç›´æ²¡é™ï¼Œå› æ­¤æˆ‘å°è¯•<code>print(loss.grad)</code>çš„gradï¼Œå‘ç°ç¥å¥‡çš„æ˜¯loss gradæ˜¾ç¤ºä¸ºNoneï¼Œæ¥ç€å°è¯•<code>print(y_pred.grad)</code>ï¼ŒåŒæ ·æ˜¯Noneï¼Œä½†å†print losså’Œy_predçš„requires_gradå‘ç°æ˜¯æ­£å¸¸çš„Trueã€‚</p><p>åœ¨æŸ¥é˜…äº†èµ„æ–™ï¼Œä»¥åŠé—®äº†å­¦é•¿ä¹‹åå‘ç°åŸæ¥å¹¶ä¸æ˜¯bugï¼Œè€Œæ˜¯å› ä¸ºï¼ŒPytorché»˜è®¤ä¸ä¼šä¿å­˜ä¸­é—´èŠ‚ç‚¹(intermediate variable)çš„gradï¼Œæ­¤ä¸¾æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜ã€‚</p><blockquote><p>By default, gradients are only retained for leaf variables. non-leaf variablesâ€™ gradients are not retained to be inspected later. This was done by design, to save memory.</p></blockquote><p><a href="https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94" target="_blank" rel="noopener">https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94</a></p><p>å®é™…ä¸Šå¯ä»¥é€šè¿‡retain_grad()æˆ–è€…hookæ¥æŸ¥çœ‹ä¸­é—´èŠ‚ç‚¹çš„gradã€‚</p><p>æˆ‘åé¢å°è¯•printäº†å¶å­èŠ‚ç‚¹ï¼Œå¦‚ <code>print(CNN_model.fc.weight.grad)</code>ï¼Œæœ€ç»ˆè·å¾—äº†æ­£ç¡®çš„gradã€‚</p><p>psï¼šæ‰€è°“ä¸­é—´èŠ‚ç‚¹ï¼Œæ˜¯<strong>ç”±å…¶ä»–èŠ‚ç‚¹è®¡ç®—æ‰€å¾—</strong>çš„tensorï¼Œè€Œå¶å­èŠ‚ç‚¹åˆ™æ˜¯<strong>è‡ªå·±å®šä¹‰</strong>å‡ºæ¥çš„ã€‚</p><p>æœ€åæˆ‘å‘ç°ï¼ŒåŸæ¥lossä¸€ç›´æ²¡é™çš„åŸå› æ˜¯å› ä¸ºæˆ‘å®šä¹‰çš„CNNè¿‡äºå¤æ‚ï¼Œå¹¶ä¸”æ•°æ®é›†åå°ï¼Œæ— æ³•å¿«é€Ÿæ”¶æ•›å¯¼è‡´çš„ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Pytorch </tag>
            
            <tag> grad </tag>
            
            <tag> bug </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linuxå¸¸ç”¨å‘½ä»¤</title>
      <link href="/2018/08/03/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/08/03/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="å‘½ä»¤"><a href="#å‘½ä»¤" class="headerlink" title="å‘½ä»¤"></a>å‘½ä»¤</h3><p>è®°å½•è‡ªå·±å¸¸ç”¨çš„å‘½ä»¤ã€‚</p><p>1ï¸âƒ£lsï¼šæ˜¾å¼å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å’Œç›®å½•<br>    -a åŒ…æ‹¬éšè—æ–‡ä»¶<br>    -h å°†æ–‡ä»¶çš„å®¹é‡ä»¥æ˜“è¯»æ–¹å¼åˆ—å‡ºï¼ˆé…åˆ-sä½¿ç”¨ï¼‰<br>    -s ä»¥å—æ•°å½¢å¼æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶åˆ†é…çš„å°ºå¯¸<br>    -l ä»¥è¾ƒé•¿æ ¼å¼åˆ—å‡ºä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥å†™æˆ <code>ll</code><br><img src="/images/2018-08-10-15339070264416.jpg" width="70%" height="50%"></p><hr><p>2ï¸âƒ£cd åˆ°è¾¾æŒ‡å®šåœ°å€</p><hr><p>3ï¸âƒ£kill æ€æ­»ç¨‹åº<br>    -l ä¿¡æ¯ç¼–å·ã€‚<strong>å½“l=9æ—¶ï¼Œæ— æ¡ä»¶ç»ˆæ­¢ï¼Œå…¶ä»–ä¿¡å·å¯èƒ½å¿½ç•¥</strong><br>    killall -u <user_name> æ€æ­»è¯¥ç”¨æˆ·å…¨éƒ¨è¿›ç¨‹</user_name></p><p><img src="/images/2018-08-03-15332830170623.jpg" width="50%" height="50%"></p><hr><p>4ï¸âƒ£ps æŠ¥å‘Šå½“å‰ç³»ç»Ÿçš„è¿›ç¨‹çŠ¶æ€<br>    -a æ‰€æœ‰<br>    -p æŒ‡å®šç¨‹åº<br>    -u æŒ‡å®šç”¨æˆ·<br>    -x åˆ—å‡ºè¯¥ç”¨æˆ·çš„è¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯(æˆ‘çš„ç†è§£åº”è¯¥æ˜¯)<br>    å¦‚ï¼š<br><img src="/images/2018-08-10-15339036207642.jpg" width="70%" height="50%"></p><hr><p>5ï¸âƒ£htop æ¯”topæ›´ä¼˜ï¼Œäº¤äº’æ›´å¥½ï¼ŒåŒæ—¶å¯ä»¥ç›´è§‚çœ‹åˆ°èµ„æºå ç”¨æƒ…å†µ<br>åŸºæœ¬å‘½ä»¤ä¸topä¸€è‡´<br><img src="/images/2018-08-04-15333484387393.jpg" width="70%" height="50%"></p><hr><p>6ï¸âƒ£topï¼šåŠ¨æ€æŸ¥çœ‹ç³»ç»Ÿè¿è¡ŒçŠ¶æ€<br>    -u æŒ‡å®šç”¨æˆ·å<br>    -p æŒ‡å®šè¿›ç¨‹</p><p>7ï¸âƒ£nvidia-smi æŸ¥çœ‹æ˜¾å¡çŠ¶æ€<br>watch nvidia-smi å®æ—¶æŸ¥çœ‹æ˜¾å¡çŠ¶æ€ï¼Œå®šæ—¶åˆ·æ–°</p><hr><p>8ï¸âƒ£tail æ˜¾ç¤ºæŒ‡å®šæ–‡ä»¶çš„æœ«å°¾è‹¥å¹²è¡Œ<br>    -f æ˜¾ç¤ºæ–‡ä»¶æœ€æ–°è¿½åŠ çš„å†…å®¹<br>    -n æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨nè¡Œå†…å®¹<br>    -c æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨æœ€åcä¸ªå­—ç¬¦</p><p>å¦‚ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tail file æ˜¾ç¤ºæœ€å10è¡Œ</span><br><span class="line">tail -n +20 file æ˜¾ç¤ºä»ç¬¬20è¡Œè‡³æœ«å°¾</span><br><span class="line">tail -c 10 file æ˜¾ç¤ºæ–‡ä»¶fileçš„æœ€å10ä¸ªå­—ç¬¦</span><br></pre></td></tr></table></figure><pre><code>-------</code></pre><p>9ï¸âƒ£echo ç”¨äºæ‰“å°æŒ‡å®šçš„å­—ç¬¦ä¸²<br><img src="/images/2018-08-04-15333497266470.jpg" width="50%" height="50%"></p><hr><p>ğŸ”Ÿwhich ç”¨äºæŸ¥æ‰¾å¹¶æ˜¾ç¤ºç»™å®šå‘½ä»¤çš„ç»å¯¹è·¯å¾„ï¼ŒwhichæŒ‡ä»¤ä¼šåœ¨ç¯å¢ƒå˜é‡$PATHè®¾ç½®çš„ç›®å½•é‡ŒæŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚ä½¿ç”¨whichå‘½ä»¤ï¼Œå¯ä»¥çœ‹åˆ°æŸä¸ªç³»ç»Ÿå‘½ä»¤æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ‰§è¡Œçš„æ˜¯å“ªä¸ªä½ç½®çš„å‘½ä»¤ã€‚å¦‚ï¼š</p><p><img src="/images/2018-08-04-15333500837235.jpg" width="50%" height="50%"></p><hr><p>1ï¸âƒ£1ï¸âƒ£nohup å°†ç¨‹åºä»¥å¿½ç•¥æŒ‚èµ·ä¿¡å·çš„æ–¹å¼è¿è¡Œï¼Œç»å¸¸ç”¨äºåœ¨æœåŠ¡å™¨è·‘ä»£ç <br>å¦‚ï¼š<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python xxx.py &gt;output.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p><p>å³ï¼Œå°†è¾“å‡ºé‡å®šå‘åˆ°output.txt ï¼›æœ€åä¸€ä¸ª<code>&amp;</code>è¡¨ç¤ºåå°æŒ‚èµ·</p><hr><p>1ï¸âƒ£2ï¸âƒ£cp å¤åˆ¶æ–‡ä»¶   cp [æ–‡ä»¶] [ç›®æ ‡æ–‡ä»¶å¤¹]<br>    -r é€’å½’å¤åˆ¶ï¼Œç”¨äºç›®å½•çš„å¤åˆ¶</p><hr><p>1ï¸âƒ£3ï¸âƒ£mv ç§»åŠ¨æ–‡ä»¶ã€ç›®å½•æˆ–æ›´å  mv [æ–‡ä»¶/æ–‡ä»¶å¤¹] [æ–‡ä»¶å¤¹]<br>    -f å¼ºåˆ¶ï¼Œå½“ç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¦†ç›–<br>    -i ä¼šè¯¢é—®</p><hr><p>1ï¸âƒ£4ï¸âƒ£rm åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•<br>    -f å¼ºåˆ¶åˆ é™¤<br>    -r é€’å½’åˆ é™¤ï¼Œç”¨äºç›®å½•åˆ é™¤</p><hr><p>1ï¸âƒ£5ï¸âƒ£file ç”¨äºåˆ¤æ–­æ–‡ä»¶çš„åŸºæœ¬æ•°æ®<br>å¦‚ï¼š</p><p><img src="/images/2018-08-05-15334547949248.jpg" width="80%" height="50%"></p><hr><p>1ï¸âƒ£6ï¸âƒ£tar å¯¹æ–‡ä»¶æ‰“åŒ…/å‹ç¼©<br>    -t æŸ¥çœ‹æ‰“åŒ…æ–‡ä»¶çš„å†…å®¹å«æœ‰å“ªäº›æ–‡ä»¶å<br>    -x è§£å‹ç¼©<br>    -c æ–°å»ºæ‰“åŒ…æ–‡ä»¶<br>    -C æŒ‡å®šå‹ç¼©/è§£å‹ç›®å½•<br>    -v è§£å‹/å‹ç¼©è¿‡ç¨‹ä¸­å°†å¤„ç†çš„æ–‡ä»¶åæ˜¾ç¤ºå‡ºæ¥<br>å¸¸ç”¨çš„ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">å‹ç¼©ï¼štar -jcv -f filename.tar.bz2 è¦è¢«å¤„ç†çš„æ–‡ä»¶æˆ–ç›®å½•åç§°</span><br><span class="line">æŸ¥è¯¢ï¼štar -jtv -f filename.tar.bz2</span><br><span class="line">è§£å‹ï¼štar -jxv -f filename.tar.bz2 -C æ¬²è§£å‹ç¼©çš„ç›®å½•</span><br></pre></td></tr></table></figure><hr><p>1ï¸âƒ£7ï¸âƒ£wc word count ç»Ÿè®¡æ–‡ä»¶å†…å®¹ä¿¡æ¯ï¼Œå¦‚è¡Œæ•°ã€å­—ç¬¦æ•°<br>    -l æ˜¾ç¤ºæ–‡ä»¶è¡Œæ•°<br>    -c æ˜¾ç¤ºå­—èŠ‚æ•°<br>    -m æ˜¾ç¤ºå­—ç¬¦æ•°<br>    -w æ˜¾ç¤ºå­—æ•°  å­—è¢«å®šä¹‰ä¸ºç”±ç©ºç™½ã€è·³æ ¼ã€æ¢è¡Œå­—ç¬¦åˆ†éš”çš„å­—ç¬¦ä¸²<br>    -L æ˜¾ç¤ºæœ€é•¿è¡Œçš„é•¿åº¦<br>    ä¸åŠ å‚æ•°ï¼Œæ‰€æœ‰çš„éƒ½æ˜¾ç¤ºï¼Œä¾æ¬¡æ˜¯è¡Œæ•°ã€å•è¯æ•°ã€å­—èŠ‚æ•°ã€æ–‡ä»¶å</p><hr><p>1ï¸âƒ£8ï¸âƒ£df æ˜¾ç¤ºç£ç›˜ç›¸å…³ä¿¡æ¯<br>    -h ä»¥å¯è¯»æ€§è¾ƒé«˜çš„æ–¹å¼æ˜¾ç¤ºä¿¡æ¯</p><hr><p>1ï¸âƒ£9ï¸âƒ£scp æœåŠ¡å™¨ä¹‹é—´çš„æ–‡ä»¶å¤åˆ¶<br>    å¦‚:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r /test1 zhlin@123.12.1.12:/home/zhlin</span><br></pre></td></tr></table></figure><h3 id="âœ¨å¿«æ·é”®"><a href="#âœ¨å¿«æ·é”®" class="headerlink" title="âœ¨å¿«æ·é”®"></a>âœ¨å¿«æ·é”®</h3><p>Ctrl+a è·³åˆ°è¡Œé¦–<br>Ctrl+c é€€å‡ºå½“å‰è¿›ç¨‹<br>Ctrl+e è·³åˆ°é¡µå°¾<br>Ctrl+k åˆ é™¤å½“å‰å…‰æ ‡åé¢çš„æ–‡å­—<br>Ctrl+l æ¸…å±ï¼Œç­‰ä»·äºclear<br>Ctrl+r æœç´¢ä¹‹å‰æ‰“è¿‡çš„å‘½ä»¤<br>Ctrl+u åˆ é™¤å½“å‰å…‰æ ‡å‰é¢çš„æ–‡å­—<br>âœ¨Ctrl+å·¦å³é”® å•è¯ä¹‹é—´è·³è½¬ åœ¨Macä¸Šå¯ä»¥ä½¿ç”¨option+å·¦å³é”®<br>Ctrl+y è¿›è¡Œæ¢å¤åˆ é™¤<br>Ctrl+z å°†å½“å‰è¿›ç¨‹è½¬åˆ°åå°ï¼Œä½¿ç”¨fgæ¢å¤</p><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/leo_618/article/details/53003111" target="_blank" rel="noopener">https://blog.csdn.net/leo_618/article/details/53003111</a></p><p>â€”â€”â€”-æŒç»­æ›´æ–°â€”â€”â€”-</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> æŠ€å·§ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä¸€ä¸ªå…³äºyieldçš„é‡æ–°è®¤è¯†</title>
      <link href="/2018/07/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Eyield%E7%9A%84%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86/"/>
      <url>/2018/07/31/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Eyield%E7%9A%84%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<p>ä»Šå¤©é‡åˆ°äº†ä¸€ä¸ªç¥å¥‡çš„â€bugâ€ï¼Œè®©æˆ‘å¯¹yieldçš„ç†è§£æ›´æ·±ä¸€æ­¥ã€‚</p><p>è¿™æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæˆ‘æœ¬æ¥æ‰“ç®—è¯•ç€printä¸€ä¸‹lineå†…éƒ¨çš„æ ¼å¼å’Œå†…å®¹ã€‚<br><img src="/images/2018-07-31-15330184801079.jpg" width="40%" height="40%"></p><p>è¿™æ˜¯è°ƒç”¨çš„ä¸»å‡½æ•°ï¼š<br><img src="/images/2018-07-31-15330185414299.jpg" width="50%" height="50%"></p><p>ç»“æœè·‘å‡ºçš„ç»“æœæ˜¯ï¼š<br><img src="/images/2018-07-31-15330185762441.jpg" width="90%" height="90%"></p><p>ï¼Ÿï¼Ÿï¼Ÿ<br><img src="/images/2018-07-31-15330186003254.jpg" alt=""></p><p>æˆ‘å°è¯•åœ¨å‡½æ•°çš„å¼€å¤´æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330186689312.jpg" width="40%" height="50%"></p><p>ç»“æœä»ç„¶æ²¡æœ‰ä»»ä½•çš„è¾“å‡ºã€‚</p><p>æˆ‘è¯•ç€åœ¨mainå‡½æ•°æ·»åŠ printï¼š<br><img src="/images/2018-07-31-15330187249603.jpg" width="50%" height="50%"></p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-31-15330187445810.jpg" width="50%" height="50%"></p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œæ ¹æœ¬æ²¡æœ‰è¿›å…¥åˆ°get_dataset_from_txtå‡½æ•°å•Šã€‚</p><p>æˆ‘ä»¥ä¸ºæ˜¯pycharmçš„é—®é¢˜è¿˜é‡å¯äº†ä¸€éï¼Œç„¶è€Œå¹¶æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚é—®äº†å…¶ä»–äººï¼Œä»–ä»¬ä¹Ÿè§‰å¾—å¾ˆç¥å¥‡ã€‚æœ€åä¸€ä¸ªåŒå­¦çœ‹äº†ä¸€ä¸‹å‡½æ•°ï¼Œå‘ç°äº†é—®é¢˜æ‰€åœ¨ï¼š<strong>yield</strong></p><p>æˆ‘çªç„¶æƒ³èµ·æ¥ï¼Œ<strong>yieldè¿”å›çš„æ˜¯ä¸€ä¸ªgeneratorï¼Œåªæœ‰åœ¨å¯¹generatorè¿›è¡Œéå†æ—¶ï¼Œæ‰ä¼šå¼€å§‹è¿è¡Œ</strong>â€¦</p><p>äºæ˜¯ï¼Œæˆ‘è¯•ç€è¿™ä¹ˆå†™ï¼Œè¯•ç€å¯¹generatoréå†ï¼š</p><p><img src="/images/2018-07-31-15330189280379.jpg" width="50%" height="50%"></p><p>è™½ç„¶æŠ¥é”™äº†ï¼Œä½†å‡½æ•°ç»ˆäºæ˜¯è¿›å»äº†â€¦</p><p><img src="/images/2018-07-31-15330189613535.jpg" width="70%" height="50%"></p><p><strong>ç»“è®ºï¼šæœ‰yieldçš„å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªgeneratorï¼Œå½“å¯¹å…¶è¿›è¡Œéå†æ—¶ï¼Œå‡½æ•°æ‰ä¼šå¼€å§‹è¿è¡Œã€‚</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
            <tag> Python </tag>
            
            <tag> yield </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•2</title>
      <link href="/2018/07/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB2/"/>
      <url>/2018/07/29/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB2/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨ä¸»è¦çœ‹äº†<a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener">AllenNLP/ELMO</a>çš„ä»£ç ï¼Œä½†å¹¶æ²¡æœ‰æ‰¾åˆ°å¾ˆå¤šå¯å¤ç”¨çš„ä»£ç ã€‚æœ¬å‘¨ä¹Ÿæ²¡æœ‰æ¯”è¾ƒæœ‰æ„ä¹‰çš„ä»£ç ã€‚</p><hr><h3 id="1ï¸âƒ£get-time-diff"><a href="#1ï¸âƒ£get-time-diff" class="headerlink" title="1ï¸âƒ£get_time_diff"></a>1ï¸âƒ£get_time_diff</h3><p>è·å–å·²ä½¿ç”¨çš„æ—¶é—´<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line">start_time=time.time()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time_dif</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    <span class="string">"""è·å–å·²ä½¿ç”¨æ—¶é—´"""</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    time_dif = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=int(round(time_dif)))</span><br></pre></td></tr></table></figure></p><hr><h3 id="2ï¸âƒ£parserä½¿ç”¨"><a href="#2ï¸âƒ£parserä½¿ç”¨" class="headerlink" title="2ï¸âƒ£parserä½¿ç”¨"></a>2ï¸âƒ£parserä½¿ç”¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'--save_dir'</span>, help=<span class="string">'Location of checkpoint files'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--vocab_file'</span>, help=<span class="string">'Vocabulary file'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--train_prefix'</span>, help=<span class="string">'Prefix for train files'</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">    </span><br><span class="line">main(args)   <span class="comment">#ä½¿ç”¨</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨ç¢ç‰‡çŸ¥è¯†1</title>
      <link href="/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%861/"/>
      <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E6%AF%8F%E5%91%A8%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%861/</url>
      
        <content type="html"><![CDATA[<p>1ï¸âƒ£[Python]<br>assertç”¨æ³•ï¼š</p><p><code>assert expression</code><br>ç­‰ä»·äº<br><code>if not expression: raise AssertionError</code></p><hr><p>2ï¸âƒ£[Pytorch]<br>Pytorch viewï¼š<br>åˆ›å»ºä¸€ä¸ªæ–°çš„tensorï¼Œä½†ä»–ä»¬çš„<strong>dataæ˜¯å…±äº«çš„</strong>ã€‚</p><p><img src="/images/2018-07-29-15328360404485.jpg" width="50%" height="50%"></p><hr><p>3ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œembeddingçš„indexæ˜¯ä¸èƒ½requires_grad=Trueçš„ï¼Œå¦åˆ™ä¼šå‡ºé”™ã€‚<br><a href="https://github.com/pytorch/pytorch/issues/7021" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/7021</a></p><p>ä¹‹å‰çœ‹è¿‡ä¸€ä»½ä»£ç ï¼Œè®¾ç½®volatile=falseä½†æ²¡æœ‰å‡ºé”™ï¼Œæ˜¯å› ä¸ºåœ¨Pytorch0.4ä¹‹åvolatileå·²ç»è¢«å¼ƒç”¨äº†ï¼Œå› æ­¤volatile=falseä¸èµ·ä½œç”¨ï¼Œè€Œé»˜è®¤requires_grad=false</p><hr><p>4ï¸âƒ£[Pytorch]<br>åœ¨Pytorchä¸­ï¼Œ<code>nn.Linear(self.hidden_dim,self.vocab_size)</code>çš„ç»´åº¦æ˜¯vocab_size<em>hidden_dimï¼Œä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚<br>å› ä¸ºnn.Linearçš„<em>*ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºè¾“å…¥ç»´åº¦ï¼Œç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºè¾“å‡ºç»´åº¦</em></em></p><hr><p>5ï¸âƒ£[Pytorch]<br>Pytorchä¸­ï¼Œä½¿ç”¨viewä¸€èˆ¬æ¥è¯´å¿…é¡»è¦ç”¨ .contiguous()ã€‚ä¹Ÿå³ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch.view(batch_size, <span class="number">-1</span>).t().contiguous()</span><br></pre></td></tr></table></figure><p>contiguous()çš„å®˜æ–¹è§£é‡Šï¼š<br><a href="https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930" target="_blank" rel="noopener">https://discuss.pytorch.org/t/runtimeerror-input-is-not-contiguous/930</a></p><blockquote><p>It means that your tensor is not a single block of memory, but a block with holes. view can be only used with contiguous tensors, so if you need to use it here, just call .contiguous() before.</p></blockquote><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œcontiguousä¼šå°†æ•°æ®å­˜åˆ°ä¸€ä¸ªè¿ç»­çš„ç©ºé—´å†…ï¼ˆblockï¼‰ã€‚</p><hr><p>6ï¸âƒ£[Pytorch]<br>è°ƒç”¨Cross_entropyæ—¶ï¼ŒPytorchä¼šå¸®åŠ©ä½ åŠ logå’Œsoftmaxã€‚</p><p><img src="/images/2018-07-29-15328370301774.jpg" alt=""></p><hr><p>7ï¸âƒ£[Paper]<br><a href="https://arxiv.org/abs/1807.02291" target="_blank" rel="noopener">Sliced_RNN</a></p><p>å°†RNNåˆ†å—ä»¥æé«˜å¹¶è¡Œæ€§ï¼Œç”šè‡³æ¯å±‚çš„RNNéƒ½å¯ä»¥ä¸ä¸€æ ·ï¼Œè¾¾åˆ°æŠ½å–ä¸åŒç¨‹åº¦çš„æŠ½è±¡è¯­ä¹‰ä¿¡æ¯çš„ç›®çš„ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ä¸åŒä»»åŠ¡ä¸Šéƒ½æœ‰ä¸€å®šçš„æå‡ï¼Œä½†é€Ÿåº¦çš„æå‡å¾ˆå¤§ã€‚</p><p><img src="/images/2018-07-29-15328372609264.jpg" width="50%" height="50%"></p><hr><p>8ï¸âƒ£[Tf-idf]<br>è®¡ç®—è¯è¯­å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦</p><p><a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Tf-idf</a></p><p>tfæ˜¯è¯é¢‘ï¼Œidfæ˜¯é€†å‘æ–‡ä»¶é¢‘ç‡ã€‚ä¹Ÿå³å¦‚æœè¯åœ¨è¯¥å¥å‡ºç°çš„æ¬¡æ•°è¶Šå¤šï¼Œåœ¨æ‰€æœ‰æ–‡æœ¬çš„å‡ºç°æ¬¡æ•°è¶Šå°‘ï¼Œåˆ™è¯å¯¹äºå¥å­çš„é‡è¦ç¨‹åº¦è¶Šé«˜ã€‚</p><hr><p>9ï¸âƒ£[Numpy]<br>åœ¨Numpyä¸­ï¼Œä¸€ä¸ªåˆ—è¡¨è™½ç„¶æ˜¯æ¨ªç€è¡¨ç¤ºçš„ï¼Œä½†å®ƒæ˜¯åˆ—å‘é‡ã€‚æˆ‘ä¹‹å‰å±…ç„¶æ²¡æœ‰æ³¨æ„åˆ°è¿™ä¸ªé—®é¢˜ã€‚</p><p><img src="/images/2018-07-29-15328375536418.jpg" width="50%" height="50%"></p>]]></content>
      
      
      
        <tags>
            
            <tag> ç¢ç‰‡çŸ¥è¯† </tag>
            
            <tag> Python </tag>
            
            <tag> Pytorch </tag>
            
            <tag> Paper </tag>
            
            <tag> Tf-idf </tag>
            
            <tag> Numpy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Macé…ç½®å¤æ—¦æœ‰çº¿ç½‘</title>
      <link href="/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E9%85%8D%E7%BD%AE%E5%A4%8D%E6%97%A6%E6%9C%89%E7%BA%BF%E7%BD%91/"/>
      <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/Mac%E9%85%8D%E7%BD%AE%E5%A4%8D%E6%97%A6%E6%9C%89%E7%BA%BF%E7%BD%91/</url>
      
        <content type="html"><![CDATA[<h3 id="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"><a href="#é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨" class="headerlink" title="é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨"></a>é…ç½®ipã€å­ç½‘æ©ç ã€DNSã€è·¯ç”±å™¨</h3><p>æœ‰çº¿ä¼¼ä¹ä¸æ”¯æŒDHCPï¼Œå› æ­¤åªå¥½è‡ªå·±è®¾ç½®ã€‚<br>é¦–å…ˆè¿æ¥ä¸Šæœ‰çº¿ï¼Œå°†é…ç½®iPv4é€‰ä¸ºæ‰‹åŠ¨ã€‚é—®å®éªŒå®¤çš„å­¦é•¿å…·ä½“çš„ipåœ°å€ã€å­ç½‘æ©ç ã€è·¯ç”±å™¨ã€DNSæœåŠ¡å™¨ã€‚å…¶ä¸­ipåœ°å€æœ€åä¸‰ä½è¦è‡ªå·±è®¾å®šï¼Œåªè¦ä¸å’Œå…¶ä»–äººå†²çªå°±å¥½ã€‚</p><p><img src="/images/2018-07-29-15328333841584.jpg" width="50%" height="50%"></p><p><img src="/images/2018-07-29-15328335236981.jpg" width="50%" height="50%"></p><h3 id="æ‰‹åŠ¨è®¤è¯"><a href="#æ‰‹åŠ¨è®¤è¯" class="headerlink" title="æ‰‹åŠ¨è®¤è¯"></a>æ‰‹åŠ¨è®¤è¯</h3><p>åˆ°è®¤è¯å¹³å°ï¼Œä¸‹è½½Macå®¢æˆ·ç«¯ï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ª.shæ–‡ä»¶ï¼š<br><a href="http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1" target="_blank" rel="noopener">http://10.108.255.249/srun_portal_pc.php?ac_id=1&amp;&amp;phone=1</a></p><p><img src="/images/2018-07-29-15328336395029.jpg" width="30%" height="30%"></p><p>ç„¶åï¼Œæ‰“å¼€æ–‡ä»¶é…ç½®ç”¨æˆ·åå¯†ç ï¼Œæ³¨æ„åˆ°ç­‰å·åé¢è¦æœ‰åŒå¼•å·ï¼š</p><p><img src="/images/2018-07-29-15328337135244.jpg" width="50%" height="50%"></p><p>ä¿å­˜å¹¶æ”¾å…¥ç»ˆç«¯è¿è¡Œï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥ä½¿ç”¨æœ‰çº¿ç½‘äº†ã€‚</p><h3 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h3><p>ä¼¼ä¹ï¼Œæ¯æ¬¡é‡æ–°è¿æ¥éƒ½è¦è¿™æ ·é…ç½®ï¼Œæˆ‘æ²¡æœ‰è¯•è¿‡ä¸æ¸…æ¥šï¼›<br>æœ‰çº¿ç½‘å¥½åƒä¹Ÿæ²¡æœ‰æ¯”æ— çº¿ç½‘å¿«å¤šå°‘ï¼Œä½†åº”è¯¥ä¼šç¨³å®šä¸€äº›ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> ç½‘ç»œ </tag>
            
            <tag> é…ç½® </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sshå¿«é€Ÿç™»å½•é…ç½®</title>
      <link href="/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/ssh%E5%BF%AB%E9%80%9F%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/07/29/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/ssh%E5%BF%AB%E9%80%9F%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>åˆ†é…äº†æœåŠ¡å™¨ä¹‹åï¼Œæ¯æ¬¡è¦sshè¿›å…¥éƒ½å¾ˆéº»çƒ¦ï¼š<code>ssh user_name@ip_address</code> ç„¶åè¿˜è¦è¾“å…¥å¯†ç ã€‚</p><p>ç‰¹åˆ«æ˜¯å¦‚æœåˆ†é…äº†å¤šä¸ªæœåŠ¡å™¨ï¼Œé‚£æœ‰æ—¶å€™è¿˜å®¹æ˜“å¿˜è®°ipåœ°å€ã€‚å› æ­¤å¦‚æœèƒ½å¤Ÿä¸€æ¡å‘½ä»¤å°±è¿›å…¥æœåŠ¡å™¨èƒ½å¤Ÿå‡å°‘éº»çƒ¦ã€‚<br>ä¸»è¦æœ‰ä¸‰ç‚¹ï¼š</p><ol><li>åˆ›å»ºrsa key</li><li>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</li><li>è®¾ç½®alias</li></ol><h1 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h1><h2 id="åˆ›å»ºrsa-key"><a href="#åˆ›å»ºrsa-key" class="headerlink" title="åˆ›å»ºrsa key"></a>åˆ›å»ºrsa key</h2><p>åœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>å½“ç„¶å¦‚æœä»¥å‰æœ‰åˆ›å»ºè¿‡çš„å¯ä»¥ä¸ç”¨ã€‚</p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-29-Xnip2018-07-29_10-43-15.jpg" width="50%" height="50%"></p><h2 id="ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨"><a href="#ä¸Šä¼ public-keyåˆ°æœåŠ¡å™¨" class="headerlink" title="ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨"></a>ä¸Šä¼ public keyåˆ°æœåŠ¡å™¨</h2><p>ä½¿ç”¨å‘½ä»¤ï¼š<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub user@127.0.0.1</span><br></pre></td></tr></table></figure></p><p>è¾“å…¥å¯†ç å³å¯</p><p>ç»“æœï¼š</p><p><img src="/images/2018-07-29-15328324683354.jpg" width="60%" height="60%"></p><h2 id="è®¾ç½®alias"><a href="#è®¾ç½®alias" class="headerlink" title="è®¾ç½®alias"></a>è®¾ç½®alias</h2><p>å®Œæˆä»¥ä¸Šæ­¥éª¤å°±å¯ä»¥ä¸è¾“å…¥å¯†ç ç™»å½•ï¼Œä½†è¿˜æ˜¯éœ€è¦è¾“å…¥ipåœ°å€å’Œç”¨æˆ·åï¼Œä¸ºäº†æ›´ç®€åŒ–æ“ä½œï¼Œç»™å‘½ä»¤èµ·ä¸ªåˆ«åã€‚éœ€è¦é…ç½® .bash_profileæ–‡ä»¶ã€‚<br>è¾“å…¥å‘½ä»¤:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶åé¢æ·»åŠ ä»¥ä¸‹æ–‡å­—ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># alias </span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br><span class="line">alias sshÃ—Ã—Ã—=&quot;ssh user_name@ip_address&quot;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ Ã—Ã—Ã—æ˜¯ä½ è‡ªå·±èµ·çš„åå­—ï¼Œå¯ä»¥æ˜¯æœåŠ¡å™¨çš„åå­—ï¼Œuser_nameå’Œip_addressæ˜¯è‡ªå·±æœåŠ¡å™¨çš„ç”¨æˆ·åå’Œåœ°å€ã€‚ä¿å­˜æ›´æ”¹é€€å‡ºã€‚</p><p>ç„¶åè¿˜è¦ä½¿å…¶ç”Ÿæ•ˆ:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><p>è¿™æ ·ï¼Œè¾“å…¥åˆ«åï¼Œå°±å¯ä»¥ç›´æ¥ç™»å½•äº†ï¼š</p><p><img src="/images/2018-07-29-15328329815456.jpg" width="50%" height="50%"></p><h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><p><a href="https://www.jianshu.com/p/66d658c7cb9e" target="_blank" rel="noopener">https://www.jianshu.com/p/66d658c7cb9e</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> é…ç½® </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å…³äºå›°æƒ‘åº¦</title>
      <link href="/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E%E5%9B%B0%E6%83%91%E5%BA%A6/"/>
      <url>/2018/07/29/%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86/%E5%85%B3%E4%BA%8E%E5%9B%B0%E6%83%91%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>å‰å‡ å¤©åœ¨å†™æ–°æ‰‹ä»»åŠ¡<a href="https://github.com/FudanNLP/nlp-beginner" target="_blank" rel="noopener">task3</a>çš„æ—¶å€™ï¼Œå‚è€ƒäº†Pytorchå®˜æ–¹exampleçš„word language modelï¼Œå®˜æ–¹exampleåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—å›°æƒ‘åº¦æ˜¯è¿™æ ·çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">math.exp(cur_loss)</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œcur_lossè¡¨ç¤ºäº¤å‰ç†µçš„lossï¼Œå³ $-P(\hat{x})logP(x)$ï¼Œ$\hat{x}$è¡¨ç¤ºground truthã€‚</p><p>ç„¶è€Œï¼Œåœ¨æŸ¥é˜…äº†å›°æƒ‘åº¦ç›¸å…³èµ„æ–™åï¼Œæˆ‘å‘ç°ï¼Œå›°æƒ‘åº¦çš„å®šä¹‰æ˜¯è¿™æ ·çš„ï¼š</p><script type="math/tex; mode=display">\begin{aligned}PP(S)= &{P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\= &\sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>è¿™æ˜¯å¦ä¸€ç§å½¢å¼:</p><script type="math/tex; mode=display">\begin{aligned}Perplexity (W)=& 2^{H(W)} \\= & {P(w_{1}w_{2}...w_{N})}^{-\frac{1}{N}} \\= & \sqrt[N]{\frac{1}{p(w_1 w_2 ... w_N)}} \\= & \sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>å¯ä»¥çœ‹åˆ°ï¼ŒäºŒè€…æœ¬è´¨æ˜¯ä¸€æ ·çš„ã€‚</p><p><strong>é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆåœ¨ä»£ç ä¸­ä»¥eä¸ºåº•å»è®¡ç®—å›°æƒ‘åº¦ï¼Œè€Œä¸æ˜¯2å‘¢?</strong></p><p>å®é™…ä¸Šï¼Œæ˜¯å› ä¸ºåœ¨ä¸Šè¿°å…¬å¼ä¸­ï¼Œlogæ˜¯ä»¥2ä¸ºåº•çš„ï¼Œä½†åœ¨Pytorchä¸­ï¼Œlogé»˜è®¤æ˜¯ä»¥eä¸ºåº•çš„ã€‚å› æ­¤åœ¨ä»£ç ä¸­ï¼Œéœ€è¦ç”¨eä½œä¸ºæŒ‡æ•°çš„åº•æ¥è¿˜åŸæˆå›°æƒ‘åº¦çš„åŸæœ¬å½¢å¼ï¼š </p><script type="math/tex; mode=display">\begin{aligned}\sqrt[N]{\prod_{i=1}^{N}{\frac{1}{p(w_i|(w_1 w_2... w_{i-1})}} }\end{aligned}</script><p>æœ€åè¿™æ˜¯perplexityçš„æ•°å­¦æ¨å¯¼ï¼š<br><a href="https://www.zhihu.com/question/58482430" target="_blank" rel="noopener">https://www.zhihu.com/question/58482430</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> å›°æƒ‘åº¦ </tag>
            
            <tag> perplexity </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯2</title>
      <link href="/2018/07/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D2/"/>
      <url>/2018/07/29/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D2/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨çš„è¯—è¯æœ‰ä¸¤ç¯‡æ˜¯å·²ç»èƒŒè¿‡çš„ï¼Œæƒå½“æ˜¯å¤ä¹ äº†ä¸€éã€‚</p><hr><p>1ï¸âƒ£</p><h3 id="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"><a href="#ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’" class="headerlink" title="ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’"></a>ä¸‹ç»ˆå—å±±è¿‡æ–›æ–¯å±±äººå®¿ç½®é…’</h3><p>[å”] æç™½<br>æš®ä»ç¢§å±±ä¸‹ï¼Œå±±æœˆéšäººå½’ã€‚<br>å´é¡¾æ‰€æ¥å¾„ï¼Œè‹è‹æ¨ªç¿ å¾®ã€‚<br>ç›¸æºåŠç”°å®¶ï¼Œç«¥ç¨šå¼€è†æ‰‰ã€‚<br>ç»¿ç«¹å…¥å¹½å¾„ï¼Œé’èæ‹‚è¡Œè¡£ã€‚<br>æ¬¢è¨€å¾—æ‰€æ†©ï¼Œç¾é…’èŠå…±æŒ¥ã€‚<br>é•¿æ­ŒåŸæ¾é£ï¼Œæ›²å°½æ²³æ˜Ÿç¨€ã€‚<br>æˆ‘é†‰å›å¤ä¹ï¼Œé™¶ç„¶å…±å¿˜æœºã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b900307db2a20054269a2a" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b900307db2a20054269a2a</a></p><hr><p>2ï¸âƒ£</p><h3 id="é€¢å…¥äº¬ä½¿"><a href="#é€¢å…¥äº¬ä½¿" class="headerlink" title="é€¢å…¥äº¬ä½¿"></a>é€¢å…¥äº¬ä½¿</h3><p>[å”] å²‘å‚<br>æ•…å›­ä¸œæœ›è·¯æ¼«æ¼«ï¼ŒåŒè¢–é¾™é’Ÿæ³ªä¸ä¹¾ã€‚<br><strong>é©¬ä¸Šç›¸é€¢æ— çº¸ç¬”ï¼Œå‡­å›ä¼ è¯­æŠ¥å¹³å®‰ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b92218df0eea006335f923" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b92218df0eea006335f923</a></p><hr><p>3ï¸âƒ£</p><h3 id="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"><a href="#å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤" class="headerlink" title="å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤"></a>å¿µå¥´å¨‡Â·èµ¤å£æ€€å¤</h3><p>[å®‹] è‹è½¼<br>å¤§æ±Ÿä¸œå»ï¼Œæµªæ·˜å°½ã€åƒå¤é£æµäººç‰©ã€‚æ•…å’è¥¿è¾¹ï¼Œäººé“æ˜¯ã€ä¸‰å›½å‘¨éƒèµ¤å£ã€‚ä¹±çŸ³ç©¿ç©ºï¼ŒæƒŠæ¶›æ‹å²¸ï¼Œå·èµ·åƒå †é›ªã€‚æ±Ÿå±±å¦‚ç”»ï¼Œä¸€æ—¶å¤šå°‘è±ªæ°ã€‚<br>é¥æƒ³å…¬ç‘¾å½“å¹´ï¼Œå°ä¹”åˆå«äº†ï¼Œé›„å§¿è‹±å‘ã€‚ç¾½æ‰‡çº¶å·¾ï¼Œè°ˆç¬‘é—´ï¼Œæ¨¯æ©¹ç°é£çƒŸç­ã€‚æ•…å›½ç¥æ¸¸ï¼Œå¤šæƒ…åº”ç¬‘æˆ‘ï¼Œæ—©ç”Ÿåå‘ã€‚<strong>äººç”Ÿå¦‚æ¢¦ï¼Œä¸€å°Šè¿˜é…¹æ±Ÿæœˆã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8bda2df0eea006333ecd2</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä»£ç ç‰‡æ®µè®°å½•1</title>
      <link href="/2018/07/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB1/"/>
      <url>/2018/07/23/%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5%E5%88%86%E4%BA%AB1/</url>
      
        <content type="html"><![CDATA[<h3 id="1ï¸âƒ£-get-batch"><a href="#1ï¸âƒ£-get-batch" class="headerlink" title="1ï¸âƒ£ get_batch"></a>1ï¸âƒ£ get_batch</h3><p>æ³¨æ„åˆ°shuffleçš„æ ‡å‡†åšæ³•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self,data,batch_size=<span class="number">32</span>,is_shuffle)</span>:</span></span><br><span class="line">  N=len(data)  <span class="comment">#è·å¾—æ•°æ®çš„é•¿åº¦</span></span><br><span class="line">  <span class="keyword">if</span> is_shuffle <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">    r=random.Random()</span><br><span class="line">    r.seed()</span><br><span class="line">    r.shuffle(data) <span class="comment">#å¦‚æœis_shuffleä¸ºçœŸåˆ™æ‰“ä¹±</span></span><br><span class="line">  <span class="comment">#å¼€å§‹è·å¾—batchï¼Œä½¿ç”¨[ for in ]</span></span><br><span class="line">  batch=[data[k:k+batch_size] <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>,N,batch_size)]</span><br><span class="line">  <span class="keyword">if</span> N%batch_size!=<span class="number">0</span>:  <span class="comment">#å¤„ç†ä¸æ•´é™¤é—®é¢˜ï¼Œå¦‚æœæœ‰æ˜¾å¼è¦æ±‚ä¸¢æ‰åˆ™ä¸éœ€è¦å¤„ç†ï¼Œè¿™é‡Œé»˜è®¤å¤„ç†</span></span><br><span class="line">    remainder=N-N%batch_size  <span class="comment">#å‰©ä¸‹çš„éƒ¨åˆ†</span></span><br><span class="line">    batch.append(data[temp:N])</span><br><span class="line">  <span class="keyword">return</span> batch</span><br></pre></td></tr></table></figure><hr><h3 id="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"><a href="#2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥" class="headerlink" title="2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥"></a>2ï¸âƒ£ä½¿ç”¨gensimå°†GloVeè¯»å…¥</h3><p>å®é™…ä¸Šè¿™ä»½ä»£ç æœ‰ç‚¹é—®é¢˜ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå‘ç°gloveæ–‡ä»¶éœ€è¦æ”¾åœ¨gensimçš„æ–‡ä»¶å¤¹ä¸‹æ‰èƒ½è¢«è¯»åˆ°(7.20 updated,åº”è¯¥ä½¿ç”¨ç»å¯¹åœ°å€)ï¼Œå¹¶ä¸å¥½ã€‚</p><p>æ•™ç¨‹åœ°å€ï¼š<a href="https://radimrehurek.com/gensim/scripts/glove2word2vec.html" target="_blank" rel="noopener">gensim: scripts.glove2word2vec â€“ Convert glove format to word2vec</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. ä½¿ç”¨gensimè¯»å…¥word2vec</span></span><br><span class="line"></span><br><span class="line">model = gensim.models.KeyedVectors.load_word2vec_format(</span><br><span class="line">        fname=<span class="string">'GoogleNews-vectors-negative300-SLIM.bin'</span>, binary=<span class="keyword">True</span>)</span><br><span class="line">words = model.vocab  <span class="comment">#è·å¾—è¯è¡¨</span></span><br><span class="line">vector= model[word]  <span class="comment">#wordæ˜¯wordsé‡Œé¢çš„å…ƒç´ </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. ä½¿ç”¨gensimè¯»å…¥glove</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> datapath, get_tmpfile</span><br><span class="line"><span class="keyword">from</span> gensim.scripts.glove2word2vec <span class="keyword">import</span> glove2word2vec</span><br><span class="line">glove_file=datapath(<span class="string">'glove.txt'</span>)  <span class="comment">#æœ€å¥½ä½¿ç”¨ç»å¯¹åœ°å€</span></span><br><span class="line">tmp_file=get_tmpfile(<span class="string">'word2vec.txt'</span>)</span><br><span class="line">glove2word2vec(glove_file,tmp_file)</span><br><span class="line">model=KeyedVectors.load_word2vec_format(tmp_file)</span><br><span class="line"><span class="comment">#æ¥ä¸‹æ¥ä½¿ç”¨çš„æ–¹æ³•æ˜¯ä¸€æ ·çš„</span></span><br></pre></td></tr></table></figure></p><hr><h3 id="3ï¸âƒ£data-splitæ–¹æ³•"><a href="#3ï¸âƒ£data-splitæ–¹æ³•" class="headerlink" title="3ï¸âƒ£data_splitæ–¹æ³•"></a>3ï¸âƒ£data_splitæ–¹æ³•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span><span class="params">(seed=<span class="number">1</span>, proportion=<span class="number">0.7</span>)</span>:</span> </span><br><span class="line">    data = list(iter_corpus())</span><br><span class="line">    ids = list(range(len(data)))</span><br><span class="line"></span><br><span class="line">    N = int(len(ids) * proportion)  <span class="comment"># number of training data</span></span><br><span class="line"></span><br><span class="line">    rng = random.Random(seed)</span><br><span class="line">    rng.shuffle(ids)</span><br><span class="line">    test_ids = set(ids[N:])</span><br><span class="line">    train_data = []</span><br><span class="line">    test_data = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> x[<span class="number">1</span>] <span class="keyword">in</span> test_ids:  <span class="comment"># x[1]: sentence id</span></span><br><span class="line">            test_data.append(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_data.append(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_data, test_data</span><br></pre></td></tr></table></figure><hr><h3 id="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"><a href="#4ï¸âƒ£å¯¹stringé¢„å¤„ç†" class="headerlink" title="4ï¸âƒ£å¯¹stringé¢„å¤„ç†"></a>4ï¸âƒ£å¯¹stringé¢„å¤„ç†</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_str</span><span class="params">(string)</span>:</span></span><br><span class="line">    string = re.sub(<span class="string">r"[^A-Za-z0-9()!?\'\`]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'s"</span>, <span class="string">" \'s"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'m"</span>, <span class="string">" \'m"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ve"</span>, <span class="string">" \'ve"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"n\'t"</span>, <span class="string">" n\'t"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'re"</span>, <span class="string">" \'re"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'d"</span>, <span class="string">" \'d"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\'ll"</span>, <span class="string">" \'ll"</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r","</span>, <span class="string">" , "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"!"</span>, <span class="string">" ! "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\("</span>, <span class="string">" \( "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\)"</span>, <span class="string">" \) "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\?"</span>, <span class="string">" \? "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\s&#123;2,&#125;"</span>, <span class="string">" "</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"\@.*?[\s\n]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    string = re.sub(<span class="string">r"https*://.+[\s]"</span>, <span class="string">""</span>, string)</span><br><span class="line">    <span class="keyword">return</span> string.strip().lower()</span><br></pre></td></tr></table></figure><hr><h3 id="5ï¸âƒ£collate-fn-batchï¼‰"><a href="#5ï¸âƒ£collate-fn-batchï¼‰" class="headerlink" title="5ï¸âƒ£collate_fn(batchï¼‰"></a>5ï¸âƒ£collate_fn(batchï¼‰</h3><p>é‡å†™collate_fnç»„å»ºmini-batchï¼Œåœ¨NLPä¸­å¸¸ç”¨ï¼Œå¥å­çš„ä¸ç­‰é•¿æ€§<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span>  <span class="comment"># rewrite collate_fn to form a mini-batch</span></span><br><span class="line">    lengths = np.array([len(data[<span class="string">'sentence'</span>]) <span class="keyword">for</span> data <span class="keyword">in</span> batch])</span><br><span class="line">    sorted_index = np.argsort(-lengths)</span><br><span class="line">    lengths = lengths[sorted_index]  <span class="comment"># descend order</span></span><br><span class="line"></span><br><span class="line">    max_length = lengths[<span class="number">0</span>]</span><br><span class="line">    batch_size = len(batch)</span><br><span class="line">    sentence_tensor = torch.LongTensor(batch_size, int(max_length)).zero_()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> enumerate(sorted_index):</span><br><span class="line">        sentence_tensor[i][:lengths[i]] = torch.LongTensor(batch[index][<span class="string">'sentence'</span>][:max_length])</span><br><span class="line"></span><br><span class="line">    sentiments = torch.autograd.Variable(torch.LongTensor([batch[i][<span class="string">'sentiment'</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted_index]))</span><br><span class="line">    <span class="keyword">if</span> config.use_cuda:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()).cuda(), lengths)  <span class="comment">#remember to transpose</span></span><br><span class="line">        sentiments = sentiments.cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(Variable(sentence_tensor.t()),lengths)  <span class="comment"># remember to transpose</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'sentence'</span>: packed_sequences, <span class="string">'sentiment'</span>: sentiments&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## é‡å†™collate_fn(batch)ä»¥ç”¨äºdataloaderä½¿ç”¨ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š</span></span><br><span class="line"></span><br><span class="line">train_dataloader=DataLoader(train_data,batch_size=<span class="number">32</span>,shuffle=<span class="keyword">True</span>,collate_fn=collate_fn)</span><br><span class="line">â€‹</span><br><span class="line"><span class="comment">## å…¶ä¸­ï¼Œtrain_dataloaderå¯å¾ªç¯éå†â€‹â€‹ã€‚</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p><hr><h3 id="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"><a href="#6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator" class="headerlink" title="6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator"></a>6ï¸âƒ£ä½¿ç”¨yieldè·å¾—æ•°æ®çš„generator</h3><p>yieldçš„ç”¨æ³•<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span><span class="params">(txt_file)</span>:</span>     <span class="comment"># return generator</span></span><br><span class="line">    <span class="keyword">with</span> open(txt_file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">if</span> len(line.strip())==<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            sentence=list(line.strip())+[<span class="string">'&lt;eos&gt;'</span>]</span><br><span class="line">            <span class="keyword">yield</span> sentence</span><br><span class="line">            </span><br><span class="line"><span class="comment">#åœ¨ä½¿ç”¨çš„æ—¶å€™ï¼š</span></span><br><span class="line">dataset=get_dataset(txt_file)</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#å¦‚æœéœ€è¦è¿˜å¯ä»¥æ”¹æˆlistå½¢å¼</span></span><br><span class="line">dataset=list(get_dataset(txt_file))</span><br></pre></td></tr></table></figure></p><hr><h3 id="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"><a href="#7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹" class="headerlink" title="7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹"></a>7ï¸âƒ£åŠ¨æ€åˆ›å»ºRNNå®ä¾‹</h3><p>æ ¹æ®rnn_typeåŠ¨æ€åˆ›å»ºå¯¹è±¡å®ä¾‹ï¼Œä½¿ç”¨äº†getattr<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rnn in ['GRU','LSTM','RNN']</span></span><br><span class="line"></span><br><span class="line">self.rnn = getattr(nn, self.rnn_type)(self.embedding_dim, self.hidden_dim, self.num_layers, dropout=self.dropout)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> code snippets </tag>
            
            <tag> ä»£ç ç‰‡æ®µ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¯å‘¨è¯—è¯1</title>
      <link href="/2018/07/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D1/"/>
      <url>/2018/07/23/%E8%AF%97%E8%AF%8D&amp;%E5%8F%A5/%E6%AF%8F%E5%91%A8%E8%AF%97%E8%AF%8D1/</url>
      
        <content type="html"><![CDATA[<p>æœ¬å‘¨èƒŒäº†å››ç¯‡ã€‚</p><hr><p>1ï¸âƒ£</p><h3 id="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"><a href="#ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹" class="headerlink" title="ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹"></a>ä¸´æ±Ÿä»™Â·å¤œå½’ä¸´çš‹</h3><p>[å®‹] è‹è½¼<br>å¤œé¥®ä¸œå¡é†’å¤é†‰ï¼Œå½’æ¥å½·å½¿ä¸‰æ›´ã€‚å®¶ç«¥é¼»æ¯å·²é›·é¸£ï¼Œæ•²é—¨éƒ½ä¸åº”ï¼Œå€šæ–å¬æ±Ÿå£°ã€‚<br><strong>é•¿æ¨æ­¤èº«éæˆ‘æœ‰ï¼Œä½•æ—¶å¿˜å´è¥è¥ï¼Ÿ</strong>å¤œé˜‘é£é™ç¸ çº¹å¹³ï¼Œå°èˆŸä»æ­¤é€ï¼Œæ±Ÿæµ·å¯„é¦€ç”Ÿã€‚</p><p>ç¸ ï¼ˆhÃºï¼‰çº¹<br>çš‹ï¼ˆgaoï¼‰<br><a href="http://m.xichuangzhu.com/work/57ae79400a2b580063150e39" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57ae79400a2b580063150e39</a></p><hr><p>2ï¸âƒ£</p><h3 id="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"><a href="#è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦" class="headerlink" title="è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦"></a>è¶æ‹èŠ±Â·é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦</h3><p>[æ¸…] ç‹å›½ç»´<br>é˜…å°½å¤©æ¶¯ç¦»åˆ«è‹¦ã€‚ä¸é“å½’æ¥ï¼Œé›¶è½èŠ±å¦‚è®¸ã€‚èŠ±åº•ç›¸çœ‹æ— ä¸€è¯­ï¼Œç»¿çª—æ˜¥ä¸å¤©ä¿±è«ã€‚<br>å¾…æŠŠç›¸æ€ç¯ä¸‹è¯‰ã€‚ä¸€ç¼•æ–°æ¬¢ï¼Œæ—§æ¨åƒåƒç¼•ã€‚<strong>æœ€æ˜¯äººé—´ç•™ä¸ä½ï¼Œæœ±é¢œè¾é•œèŠ±è¾æ ‘ã€‚</strong></p><p><a href="http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8ef70128fe10054c91d17</a></p><hr><p>3ï¸âƒ£</p><h3 id="é€å‹äºº"><a href="#é€å‹äºº" class="headerlink" title="é€å‹äºº"></a>é€å‹äºº</h3><p>[å”] æç™½<br>é’å±±æ¨ªåŒ—éƒ­ï¼Œç™½æ°´ç»•ä¸œåŸã€‚<br>æ­¤åœ°ä¸€ä¸ºåˆ«ï¼Œå­¤è“¬ä¸‡é‡Œå¾ã€‚<br><strong>æµ®äº‘æ¸¸å­æ„ï¼Œè½æ—¥æ•…äººæƒ…ã€‚</strong><br>æŒ¥æ‰‹è‡ªå…¹å»ï¼Œè§è§ç­é©¬é¸£ã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8facfd342d3005ac6ffb4</a></p><hr><p>4ï¸âƒ£</p><h3 id="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"><a href="#é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ" class="headerlink" title="é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ"></a>é»„é¹¤æ¥¼é€å­Ÿæµ©ç„¶ä¹‹å¹¿é™µ</h3><p>[å”] æç™½<br>æ•…äººè¥¿è¾é»„é¹¤æ¥¼ï¼ŒçƒŸèŠ±ä¸‰æœˆä¸‹æ‰¬å·ã€‚<br>å­¤å¸†è¿œå½±ç¢§ç©ºå°½ï¼Œå”¯è§é•¿æ±Ÿå¤©é™…æµã€‚</p><p><a href="http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8" target="_blank" rel="noopener">http://m.xichuangzhu.com/work/57b8f306128fe10054c92fb8</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> è¯—è¯ </tag>
            
            <tag> è¯—è¯åˆ†äº« </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å®‰è£…condaé”™è¯¯</title>
      <link href="/2018/07/23/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%AE%89%E8%A3%85conda%E9%94%99%E8%AF%AF/"/>
      <url>/2018/07/23/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/%E5%AE%89%E8%A3%85conda%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<p>åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…condaçš„æ—¶å€™ï¼Œä¸€å¼€å§‹ä½¿ç”¨äº†pipå®‰è£…<br><code>pip install conda</code><br>åœ¨å®‰è£…å¥½condaä¹‹åæƒ³è¦ä½¿ç”¨condaå‘½ä»¤ï¼Œå‡ºç°ï¼š</p><p>ERROR: The install method you used for condaâ€”probably either <code>pip install conda</code> or <code>easy_install conda</code>â€”is not compatible with using conda as an application. If your intention is to install conda as a standalone application, currently supported install methods include the Anaconda installer and the miniconda installer. You can download the miniconda installer from <a href="https://conda.io/miniconda.html" target="_blank" rel="noopener">https://conda.io/miniconda.html</a>.</p><p><img src="/images/2018-07-23-15323331261104.jpg" alt=""></p><p>ç„¶ååˆ°å®˜ç½‘ä¸‹è½½.shæ–‡ä»¶å¹¶bashå®‰è£…ï¼Œä»ç„¶æ²¡æœ‰è§£å†³è¯¥é—®é¢˜ï¼›æ¥ç€å°è¯•pip uninstall condaï¼Œå‡ºç°<br><img src="/images/2018-07-23-15323337042406.jpg" alt=""></p><p>æœ€ååœ¨æŸ¥é˜…äº†ç½‘ä¸Šä¹‹åï¼Œä½¿ç”¨ <code>which conda</code>æ‰¾åˆ°condaçš„åœ°å€ï¼Œå¹¶åˆ é™¤<code>rm Ã—Ã—Ã—</code><br><img src="/images/2018-07-23-15323337894186.jpg" alt=""></p><p>æœ€åé‡æ–°bashå®‰è£…å³å¯ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> æ‚ä¸ƒæ‚å…« </tag>
            
            <tag> conda </tag>
            
            <tag> é‡åˆ°çš„é—®é¢˜ </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
