<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Paper,每周论文阅读,Curriculum Learning,style transfer," />





  <link rel="alternate" href="/atom.xml" title="Weekly Review" type="application/atom+xml" />






<meta name="description" content="本周论文：  Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction Multiple Text Style Transfer by using Word-level Conditional Generative Adversari">
<meta name="keywords" content="Paper,每周论文阅读,Curriculum Learning,style transfer">
<meta property="og:type" content="article">
<meta property="og:title" content="每周论文35">
<meta property="og:url" content="http://www.linzehui.me/2019/12/21/论文/每周论文35/index.html">
<meta property="og:site_name" content="Weekly Review">
<meta property="og:description" content="本周论文：  Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction Multiple Text Style Transfer by using Word-level Conditional Generative Adversari">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.linzehui.me/images/15769319913004.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769321731975.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769323738904.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769336548305.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769347112996.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769349339767.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769350720207.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769354278711.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769354641619.jpg">
<meta property="og:image" content="http://www.linzehui.me/images/15769354920975.jpg">
<meta property="og:updated_time" content="2019-12-27T01:14:47.208Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="每周论文35">
<meta name="twitter:description" content="本周论文：  Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction Multiple Text Style Transfer by using Word-level Conditional Generative Adversari">
<meta name="twitter:image" content="http://www.linzehui.me/images/15769319913004.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.linzehui.me/2019/12/21/论文/每周论文35/"/>





  <title>每周论文35 | Weekly Review</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Weekly Review</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/12/21/论文/每周论文35/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">每周论文35</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-21T20:27:30+08:00">
                2019-12-21
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-12-27T09:14:47+08:00">
                2019-12-27
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本周论文：</p>
<ol>
<li>Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction</li>
<li>Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training</li>
<li>Generating Diverse Translations with Sentence Codes</li>
<li>A Probabilistic Formulation of Unsupervised Text Style Transfer</li>
<li>On Variational Learning of Controllable Representations for Text without Supervision</li>
</ol>
<h2 id="Self-Attention-Enhanced-CNNs-and-Collaborative-Curriculum-Learning-for-Distantly-Supervised-Relation-Extraction"><a href="#Self-Attention-Enhanced-CNNs-and-Collaborative-Curriculum-Learning-for-Distantly-Supervised-Relation-Extraction" class="headerlink" title="[Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction]"></a>[Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction]</h2><p>Motivation：在distant relation extraction任务中由于自动标注的原因，有很多的标注错误，如：</p>
<p><img src="/images/15769319913004.jpg" width="50%" height="50%"></p>
<p>这种错误会影响模型的训练。因此在这里设计两个不同的模型，互相regularize。当二者的output出现冲突时，就认为该sample是hard的，给该sample分配一个小权重或者0。两个模型这样可以互相监督，将hard的sample排除出去/延迟训练，达到从简单到难的学习。</p>
<p>感觉这不算是Curriculum Learning啊，更像是self-paced learning。</p>
<hr>
<h2 id="Multiple-Text-Style-Transfer-by-using-Word-level-Conditional-Generative-Adversarial-Network-with-Two-Phase-Training"><a href="#Multiple-Text-Style-Transfer-by-using-Word-level-Conditional-Generative-Adversarial-Network-with-Two-Phase-Training" class="headerlink" title="[Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training]"></a>[Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training]</h2><p>使用了标准的attention encoder-decoder模型，同时还使用了adversarial discriminator，采用了back translation那一套训练方法。有一点不同的是，将y标签和decoder的hidden cat起来然后过全连接以获得output。</p>
<p><img src="/images/15769321731975.jpg" width="50%" height="50%"></p>
<p>想法：论文名字中的condition就是每个词的生成都直接condition到y的标签。而two-phase training是指先预训练reconstruction，然后再将adv引入，这个方法应该很多人都会这么做，这是为了提升稳定性。<br>其实正常的back translation（参考multiple attribute text style transfer）是不会用到adversarial的，但这里用到了，而intro又提到了adversarial的不稳定性，感觉打脸了。而且题目虽然有Multiple Text Style Transfer，但其实和multiple attribute text style transfer这篇没啥联系的感觉。</p>
<hr>
<h2 id="Generating-Diverse-Translations-with-Sentence-Codes"><a href="#Generating-Diverse-Translations-with-Sentence-Codes" class="headerlink" title="[Generating Diverse Translations with Sentence Codes]"></a>[Generating Diverse Translations with Sentence Codes]</h2><p>目的是为了在机器翻译中生成不同结构的句子，使得不同的candidate之间的diversity更强。其做法是获得一个code，其中这个code是通过constituency parsing tree的auto-encoder得到的，也即利用tree lstm将一个tree encode成一个discrete code，然后一个decoder根据该code尝试还原出原来的tree。然后将获得的code放在decoder作为前缀。也即给模型注入了syntex的信息。实验结果证明了在bleu不下降的情况下显著提升了diversity。</p>
<p><img src="/images/15769323738904.jpg" width="45%" height="50%"></p>
<hr>
<h2 id="A-Probabilistic-Formulation-of-Unsupervised-Text-Style-Transfer"><a href="#A-Probabilistic-Formulation-of-Unsupervised-Text-Style-Transfer" class="headerlink" title="[A Probabilistic Formulation of Unsupervised Text Style Transfer]"></a>[A Probabilistic Formulation of Unsupervised Text Style Transfer]</h2><p>本文从生成式概率模型的角度出发，做很少的独立性假设，这和之前的非生成式模型不一样，将non-parallel corpus作为部分可见的parallel corpus。通过优化ELBO以训练模型。同时，该模型还可以看做是过去一些模型的统一框架。</p>
<p>整体框架：<br><img src="/images/15769336548305.jpg" width="70%" height="50%"></p>
<p>将不存在的parallel corpus看做是latent，然后用模型去近似。有一点不同的是，过去都是根据已知去推测未知，这里相反，是用latent去推测observed。而这个latent有先验，是一个pretrained language model。</p>
<p>从模型角度这就是一个普通的attention encoder-decoder模型，language model也是一个recurrent的。</p>
<p>如何去学这样的模型。第一：先用reconstruction loss去pretrain，让模型有一定的能力；第二：去优化evidence lower bound（ELBO）。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>记domain1 $\mathcal{D}_{1}$的数据$X=\left\{x^{(1)}, x^{(2)}, \cdots, x^{(m)}\right\}$，domain2 $\mathcal{D}_{2}$的数据$Y=\left\{y^{(m+1)}, y^{(m+2)}, \cdots, y^{(n)}\right\}$；同时不可见的latent $\bar{X}=\left\{\bar{x}^{(m+1)}, \bar{x}^{(m+2)}, \cdots, \bar{x}^{(n)}\right\}$，$\bar{Y}=\left\{\bar{y}^{(1)}, \bar{y}^{(2)}, \cdots, \bar{y}^{(m)}\right\}$</p>
<p>模型要学的就是：<br>$p(\bar{y} | x)$ 和 $p(\bar{x} | y)$</p>
<p>显然数据不存在没法直接建模。通过一个生成式模型（也即对数据分布建模）去建模一个联合分布，也即$p(X, \bar{X}, Y, \bar{Y})$<br>该模型假设每个observed句子是由一个不可见的sentence生成的，也即上图1。具体而言，整个过程是这么假设的：首先一个latent sequence $\bar{y}^{(i)}$从一个先验$p_{\mathcal{D}_{2}}\left(\bar{y}^{(i)}\right)$采样获得；接着$x^{(i)}$是根据$p\left(x^{(i)} | \bar{y}^{(i)}\right)$采样生成。</p>
<p>联合分布可以形式化为：</p>
<script type="math/tex; mode=display">p\left(X, \bar{X}, Y, Y ; \theta_{x | \bar{y}}, \theta_{y | \bar{x}}\right)=\left(\prod_{i=1}^{m} p\left(x^{(i)} | \bar{y}^{(i)} ; \theta_{x | \bar{y}}\right) p_{\mathcal{D}_{2}}\left(\bar{y}^{(i)}\right)\right)\left(\prod_{j=m+1}^{n} p\left(y^{(j)} | \bar{x}^{(j)} ; \theta_{y | \bar{x}}\right) p_{\mathcal{D}_{1}}\left(\bar{x}^{(j)}\right)\right)</script><p>其中$p(y)$是该domain的language model的先验。</p>
<p>取log，有：</p>
<script type="math/tex; mode=display">\log p\left(X, Y ; \theta_{x | \bar{y}}, \theta_{y | \bar{x}}\right)=\log \sum_{\bar{X}} \sum_{\bar{Y}} p\left(X, \bar{X}, Y, \bar{Y} ; \theta_{x | \bar{y}}, \theta_{y | \bar{x}}\right)</script><p>没法直接解，因此转化为优化ELBO。也即：<br>$\log p\left(X, Y ; \theta_{x | \bar{y}}, \theta_{y | \bar{x}}\right)$<br>$\geq \mathcal{L}_{\mathrm{ELBO}}\left(X, Y ; \theta_{x | \bar{y}}, \theta_{y | \bar{x}}, \phi_{\bar{x} | y}, \phi_{\bar{y} | x}\right)$<br>$=\sum_{i}\left[\mathbb{E}_{q\left(\bar{y} | x^{(i)} ; \phi_{\bar{y} | x}\right)}\left[\log p\left(x^{(i)} | \bar{y} ; \theta_{x | \bar{y}}\right)\right]-D_{\mathrm{KL}}\left(q\left(\bar{y} | x^{(i)} ; \phi_{\bar{y} | x}\right) | p_{\mathcal{D}_{2}}(\bar{y})\right)\right]$<br>$+\sum_{j} \underbrace{\left[\mathbb{E}_{q\left(\bar{x} | y^{(j)} ; \phi_{\bar{x} | y}\right)}\left[\log p\left(y^{(j)} | \bar{x} ; \theta_{y | \bar{x}}\right)\right]\right.}_{\text {Reconstruction likelihood }}-\underbrace{\left.D_{K L}\left(q\left(\bar{x} | y^{(j)} ; \phi_{\bar{x} | y}\right) | p_{\mathcal{D}_{1}}(\bar{x})\right)\right]}_{\text {KL regularizer }}$</p>
<p>也即引入一个q的分布（$q\left(\bar{y} | x^{(i)} ; \phi_{\bar{y} | x}\right)$ 和 $q\left(\bar{x} | y^{(j)} ; \phi_{\bar{x} | y}\right)$）去拟合p的分布。注意这边的q，是给定observed去推测不可见的。</p>
<p>其中KL项，是作为一个regularization，使得分布能接近该domain的language model。</p>
<p>一般来说，这个方法是用在连续的latent variable，但在这里用在了discrete sequence，至于怎么用，参考Discrete generative models for sentence compression（怎么用我也还没懂）。</p>
<p>整体的结构就是这样的。在这里用了几个trick：<br>①parameter sharing。刚刚提到用q去拟合p。但实际上在style transfer中，这二者都是为了去学习一个分布变换（从domain1到domain2），也即$q\left(\bar{y} | x^{(i)} ; \phi_{\bar{y} | x}\right)$和$p\left(y | \bar{x}^{(i)} ; \theta_{y | \bar{x}}\right)$正好目标是一致的，所以在这里将二者的分布参数共享。</p>
<p>同时，还将encoder的参数绑定，也即二者的encoder是一个。（根据作者在openreview上的回复，似乎decoder也是同一个，但我的理解decoder应该是分开的，从下图中看也应该是分开的，这里有点不懂）。同时embedding的参数也绑定。因此整体的流程框架：</p>
<p><img src="/images/15769347112996.jpg" width="70%" height="50%"></p>
<p>②Approximating Gradients of ELBO<br>ELBO不是很懂。其实就是用gumbel-softmax达到梯度回传。</p>
<p>③Initialization<br>先pretrain一个能reconstruct的模型，使得模型有一定的生成能力。</p>
<h3 id="与过去的联系"><a href="#与过去的联系" class="headerlink" title="与过去的联系"></a>与过去的联系</h3><p>①与back translation的联系：从ELBO可以看出，reconstruction部分和bt一样。bt实际上可以看做一种数据增强。ELBO公式中的reconstruction部分也是这样，用一个unobserved的去生成一个observed。</p>
<p>②与language model的联系：<br>从ELBO的KL项看，KL项可以分解为：</p>
<script type="math/tex; mode=display">D_{\mathrm{KL}}\left(q(\bar{y} | x) \| p_{\mathcal{D}_{2}}(\bar{y})\right)=-H_{q}-\mathbb{E}_{q}\left[\log p_{\mathcal{D}_{2}}(\bar{y})\right]</script><p>可以看到这里利用到了pretrain language model作为一种正则方式，这和过去的一些工作类似；而这里还加了一项H，这是过去没有的。这一项的作用是防止极端的转换分布，让q的分布更平一点。啥意思，举个例子，就是如果没有这项，模型会容易陷入生成重复的句子，比如在negative到positive的时候无视source，而直接生成简单的‘i love the place’这样。这样可以更容易satisfy language model项，而有了H这项，模型就会避免这个问题。在实验中也有这部分的分析实验，发现确实是这样的。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>简单的实验结果：</p>
<p><img src="/images/15769349339767.jpg" width="90%" height="50%"></p>
<p>其中值得注意的就是BT+NLL就是少掉$H_{q}$项的模型，可以看到其ppl非常小而bleu也非常低，这是因为其一直生成重复的句子。而论文的模型则有很不错的结果，在不同任务上和UNMT差不多甚至明显优于。</p>
<p>论文同时还分析了为啥比UNMT更好。因为UNMT更倾向于更大的转换句子的内容，使得原本的意思容易丢失（但这个不是可以通过调整window来减小内容丢失吗）。同时作者定量分析得到了其模型能更好地生成更多的名词（通过POS tagging），使得保存更多的内容。</p>
<p><img src="/images/15769350720207.jpg" width="40%" height="50%"></p>
<h3 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h3><p>这篇论文感觉写得很好；同时实验也非常翔实。通过将style transfer这个问题formulate成概率问题，然后隐式地引入language model作为prior，我认为这是其主要贡献。同时还将该模型和过去的做了对比，让人对这个模型有更加深入的理解。非常推荐这篇，这篇也是今年ICLR的高分论文。<br>就我的理解而言，不考虑这个漂亮的框架，应该就是一个正常的attention encoder-decoder框架，但conditioned on pretrained language model，这样一来，就不需要像bt那样需要显式的从x到y再到x，而是只需要一步到位从unobserved到observed。当然论文中关于具体怎么实现的（直接对discrete sequence做variational inference）我还没搞懂，但整体框架还是大概明白了。</p>
<hr>
<h2 id="On-Variational-Learning-of-Controllable-Representations-for-Text-without-Supervision"><a href="#On-Variational-Learning-of-Controllable-Representations-for-Text-without-Supervision" class="headerlink" title="[On Variational Learning of Controllable Representations for Text without Supervision]"></a>[On Variational Learning of Controllable Representations for Text without Supervision]</h2><p>Motivation：主要address的问题是VAE的vacant region。（latent vacancy problem），也即被encode的latent representation的分布存在一些空洞和密度小的地方，一旦直接对该latent representation进行改动，会使得该representation移动到空洞的地方，而decoder直接对该representation进行decode会造成无法预测的行为。如图：</p>
<p><img src="/images/15769354278711.jpg" width="40%" height="50%"></p>
<p>而本文则是通过对这种posterior进行一定的限制。在encode端就进行限制，使得其分布更加紧密。具体公式没仔细看，大致是这样的：</p>
<p><img src="/images/15769354641619.jpg" width="45%" height="50%"></p>
<p>β是baseline，CP是本文提出的：<br><img src="/images/15769354920975.jpg" width="50%" height="50%"></p>
<p>可以看到cp（Constrained Posterior VAE）改进了许多，使得latent的改动能够尽可能还在分布里面。</p>
<hr>
<h3 id="本周论文小结"><a href="#本周论文小结" class="headerlink" title="[本周论文小结]"></a>[本周论文小结]</h3><p>ACL过后瞎看了几篇。还是以style transfer为主。</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    林泽辉
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://www.linzehui.me/2019/12/21/论文/每周论文35/" title="每周论文35">http://www.linzehui.me/2019/12/21/论文/每周论文35/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://www.linzehui.me" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Paper/" rel="tag"> <i class="fa fa-tag"></i> Paper</a>
          
            <a href="/tags/每周论文阅读/" rel="tag"> <i class="fa fa-tag"></i> 每周论文阅读</a>
          
            <a href="/tags/Curriculum-Learning/" rel="tag"> <i class="fa fa-tag"></i> Curriculum Learning</a>
          
            <a href="/tags/style-transfer/" rel="tag"> <i class="fa fa-tag"></i> style transfer</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/12/21/诗词&句/每周诗词41/" rel="next" title="每周诗词41">
                <i class="fa fa-chevron-left"></i> 每周诗词41
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MDA0OC8xNjU3NQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">林泽辉</p>
              <p class="site-description motion-element" itemprop="description">人一己千</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">208</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">216</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Self-Attention-Enhanced-CNNs-and-Collaborative-Curriculum-Learning-for-Distantly-Supervised-Relation-Extraction"><span class="nav-number">1.</span> <span class="nav-text">[Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction]</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-Text-Style-Transfer-by-using-Word-level-Conditional-Generative-Adversarial-Network-with-Two-Phase-Training"><span class="nav-number">2.</span> <span class="nav-text">[Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training]</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generating-Diverse-Translations-with-Sentence-Codes"><span class="nav-number">3.</span> <span class="nav-text">[Generating Diverse Translations with Sentence Codes]</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#A-Probabilistic-Formulation-of-Unsupervised-Text-Style-Transfer"><span class="nav-number">4.</span> <span class="nav-text">[A Probabilistic Formulation of Unsupervised Text Style Transfer]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型"><span class="nav-number">4.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#与过去的联系"><span class="nav-number">4.2.</span> <span class="nav-text">与过去的联系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实验结果"><span class="nav-number">4.3.</span> <span class="nav-text">实验结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#想法"><span class="nav-number">4.4.</span> <span class="nav-text">想法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#On-Variational-Learning-of-Controllable-Representations-for-Text-without-Supervision"><span class="nav-number">5.</span> <span class="nav-text">[On Variational Learning of Controllable Representations for Text without Supervision]</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#本周论文小结"><span class="nav-number">5.1.</span> <span class="nav-text">[本周论文小结]</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">林泽辉</span>

  
</div>






  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
