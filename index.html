<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="人一己千">
<meta property="og:type" content="website">
<meta property="og:title" content="Weekly Review">
<meta property="og:url" content="http://www.linzehui.me/index.html">
<meta property="og:site_name" content="Weekly Review">
<meta property="og:description" content="人一己千">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Weekly Review">
<meta name="twitter:description" content="人一己千">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.linzehui.me/"/>





  <title>Weekly Review</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Weekly Review</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/04/21/诗词&句/每周诗词22/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/21/诗词&句/每周诗词22/" itemprop="url">每周诗词22</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-21T22:56:14+08:00">
                2019-04-21
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-04-21T22:57:30+08:00">
                2019-04-21
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣九日齐安登高"><a href="#1️⃣九日齐安登高" class="headerlink" title="1️⃣九日齐安登高"></a>1️⃣九日齐安登高</h3><p>[唐] 杜牧<br>江涵秋影雁初飞，与客携壶上翠微。<br>尘世难逢开口笑，菊花须插满头归。<br>但将酩酊酬佳节，不用登临恨落晖。<br><strong>古往今来只如此，牛山何必独沾衣？</strong></p>
<p><a href="http://lib.xcz.im/work/57ba4972efa631005a799815" target="_blank" rel="noopener">http://lib.xcz.im/work/57ba4972efa631005a799815</a></p>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/04/21/论文/每周论文16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/21/论文/每周论文16/" itemprop="url">每周论文16</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-21T22:04:30+08:00">
                2019-04-21
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-04-22T16:52:53+08:00">
                2019-04-22
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本周论文：</p>
<ol>
<li>MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES</li>
<li>Fine-Grained Attention Mechanism for Neural Machine Translation</li>
<li>Competence-based Curriculum Learning for Neural Machine Translation</li>
</ol>
<h2 id="1️⃣-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES"><a href="#1️⃣-MEASURING-THE-INTRINSIC-DIMENSION-OF-OBJECTIVE-LANDSCAPES" class="headerlink" title="1️⃣[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]"></a>1️⃣[MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES]</h2><p>本文探究深度学习中的过量参数问题，通过定义intrinsic dimension，去衡量特定模型在特定数据集上所需维度。</p>
<p>在给定模型结构和loss function时，整个优化空间也随之确定，训练过程类似于在一个空间内移动使得loss尽量小。</p>
<p>给定一个有D个参数的模型，通过限制训练随机slice的参数，也即选取一个随机有d个参数的子空间训练，不断增加d，使得预定义的solution第一次出现，则称d为intrinsic dimension，可以理解为该d是解决某特定问题所需的参数量。</p>
<p>如何做？<br>$\theta^{(D)}=\theta_{0}^{(D)}+P \theta^{(d)}$<br>其中P是随机生成的$D\times d$的投影矩阵，而$\theta (d)$ 是子空间的参数；$P$是固定的而不是可训练的，且$P$可以是归一化为单位长度且正交的。</p>
<p><img src="/images/15559193313833.jpg" width="40%" height="50%"></p>
<p>（这里的投影现在还是不能理解？等之后看这方面的论文再说吧）</p>
<p>因为一些随机性以及实际效果问题，比如正则化效果在子空间无法达到在全空间的效果，因此在这里定义$d_{\mathrm{int} 90}$，也即达到baseline的90%所需要的参数量。</p>
<p>一些结果：<br><img src="/images/15559195161338.jpg" width="70%" height="50%"></p>
<p>MNIST的模型可以看到所需参数非常少；横向对比，CNN会比全连接所需的少多了，这也符合我们的直觉，也即CNN比全连接更高效。</p>
<p><img src="/images/15559195378407.jpg" width="70%" height="50%"></p>
<p>在全连接中，对于模型不同的宽度以及layer数，发现他们的dint90相差不大，说明对于特定任务，同一个模型家族所需要的参数量是类似的。</p>
<hr>
<h2 id="2️⃣-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation"><a href="#2️⃣-Fine-Grained-Attention-Mechanism-for-Neural-Machine-Translation" class="headerlink" title="2️⃣[Fine-Grained Attention Mechanism for Neural Machine Translation]"></a>2️⃣[Fine-Grained Attention Mechanism for Neural Machine Translation]</h2><p>本文提出对attention进行细化，将原来的每个词分配一个score扩展为每个词分配d维个score，并在机器翻译上有一定提升。</p>
<p><img src="/images/15559197269175.jpg" width="80%" height="50%"></p>
<p>简单地说，原来的attention机制是：<br>$e_{t^{\prime}, t}=f_{\mathrm{Att}}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}\right)$</p>
<p>其中$t^{\prime}$是decoder端的时间步，$t$则是encoder端的第$t$个词。</p>
<p>而本文的细粒度attention机制：<br>$e_{t^{\prime}, t}^{d}=f_{\mathrm{Att} \mathrm{Y} 2 \mathrm{D}}^{d}\left(\boldsymbol{z}_{t^{\prime}-1}, \boldsymbol{h}_{t}, \boldsymbol{y}_{t^{\prime}-1}\right)$</p>
<p>也即在原来的基础上做了d次操作，也即实际上在获得每一维的分数时，是能看到其他维的信息的。（如果是我自己做，我可能会将他们隔绝开来。）</p>
<p>思考：<br>将RNN作为baseline，为什么不使用transformer？当时transformer已经出了，可能是transformer上没效果？因为transformer自带多head，可能表示能力就已经足够了。</p>
<hr>
<h2 id="3️⃣-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation"><a href="#3️⃣-Competence-based-Curriculum-Learning-for-Neural-Machine-Translation" class="headerlink" title="3️⃣[Competence-based Curriculum Learning for Neural Machine Translation]"></a>3️⃣[Competence-based Curriculum Learning for Neural Machine Translation]</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>提出一种新的<strong>训练</strong>翻译模型的算法，基本思想是让模型从简单的样例开始学起，随着训练过程的进行逐渐增加难度较大的样例，该方法能够增强模型训练的稳定性，且在效果上也有提升，同时还能减少收敛所需的训练时间。</p>
<p><img src="/images/15559206435828.jpg" width="50%" height="50%"></p>
<p>论文的Motivation：如果训练数据以特定的顺序输入，也即从简单的数据开始学，等到模型有一定的能力后再去学难的数据，这样也更符合人类的直觉；同时，从机器学习的角度去看，这种方法可以避免过早陷入不好的局部最优解。</p>
<p>论文还提到了对于翻译而言，模型很难训练，需要复杂的调参，费时费力。特别是对于Transformer而言，需要精细的learning rate schedule。</p>
<p>本文提出的方法，只有一个参数，因此不需要精细的调参，同时因为只改变输入的pipeline，因此很方便地使用到已有的模型。</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>引入两个概念：<br><strong>Difficulty</strong>：代表一个训练样例的难度，可能和模型当前的状态相关。比如句子长度就是衡量样例难度的一个指标。</p>
<p><strong>Competence</strong>：范围0-1的数值，代表模型训练的进度，定义为模型状态的一个函数。更进一步，定义$c(t)$为模型在时间步t所允许使用的训练样例的比例。也即训练样例根据difficulty排列，在时间步$t$只允许top $c(t)$的数据使用。</p>
<p>根据上述两个定义，引入算法：<br><img src="/images/15559212081520.jpg" width="50%" height="50%"></p>
<p><img src="/images/15559212315953.jpg" width="100%" height="50%"></p>
<p><img src="/images/15559212598339.jpg" width="50%" height="50%"></p>
<p>那么有两个问题，如何衡量difficulty以及competence？</p>
<h4 id="Difficulty-Metrics"><a href="#Difficulty-Metrics" class="headerlink" title="Difficulty Metrics"></a>Difficulty Metrics</h4><p>①句子长度<br>长句子更难翻译，因为长句子往往包含了短句子，同时在生成目标语言时，容易出现错误传播。</p>
<script type="math/tex; mode=display">d_{\text { length }}\left(s_{i}\right) \triangleq N_{i}</script><p>②Word Rarity<br>若一个句子存在罕见词，更难翻译该句子，因为模型需要多次看见该词才能学到鲁棒的表示；同时罕见词的梯度容易有较大的方差。</p>
<p>因此我们定义相对词频：</p>
<script type="math/tex; mode=display">\hat{p}\left(w_{j}\right) \triangleq \frac{1}{N_{\text {total }}} \sum_{i=1}^{M} \sum_{k=1}^{N_{i}} \mathbb{1}_{w_{k}^{i}=w_{j}}</script><p>其中，$j=1, \ldots, \{\text {unique words in corpus}\}$，$\mathbb{1}$ 为指示函数。</p>
<p>因此最终度量方法为：<br>$d_{\text {rarity}}\left(s_{i}\right) \triangleq-\sum_{k=1}^{N_{i}} \log \hat{p}\left(w_{k}^{i}\right)$</p>
<p>这样即考虑到了长度也考虑到了词频，同时该方法有点类似language model，可以理解为language model的近似。</p>
<h4 id="Competence-Functions"><a href="#Competence-Functions" class="headerlink" title="Competence Functions"></a>Competence Functions</h4><p>我们定义competence function只与时间步$t$有关，因此只需要考虑具体的形式。<br>①linear：</p>
<script type="math/tex; mode=display">c(t) \triangleq \min \left(1, t r+c_{0}\right)</script><p>$c_{0}$是初始值。我们也可以定义T为时间步阈值，当超过该阈值，我们认为模型已经完全有能力了，则上式还可以写成：</p>
<script type="math/tex; mode=display">c_{\text { linear }}(t) \triangleq \min \left(1, t \frac{1-c_{0}}{T}+c_{0}\right)</script><p>②Root：<br>线性的一个不好的地方，当样例增加时，每个样例被sample的几率减小，因此新加进去的样例被sample到的几率也减小，因此应每次减少新加入的样例，使得模型有足够的时间去学习知识。<br>也即：</p>
<script type="math/tex; mode=display">\frac{d c(t)}{d t}=\frac{P}{c(t)}</script><p>积分后可得：</p>
<script type="math/tex; mode=display">c_{\mathrm{sqrt}}(t) \triangleq \min \left(1, \sqrt{t \frac{1-c_{0}^{2}}{T}+c_{0}^{2}}\right)</script><p>当然还可以将开n次方根</p>
<script type="math/tex; mode=display">c_{\mathrm{root}-p}(t) \triangleq \min \left(1, \sqrt[p]{t \frac{1-c_{0}^{p}}{T}+c_{0}^{p}}\right)</script><p>使得曲线更为陡峭，也即给每个样例的时间更多。</p>
<p>曲线对比：<br><img src="/images/15559218944874.jpg" width="50%" height="50%"></p>
<p>实验证明是p=2时最好。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/15559219317633.jpg" width="70%" height="50%"></p>
<p>实验有相当不错的结果，在RNN以及在Transformer上都有提升，并且是在不用learning rate schedule的情况下，并且时间更短。</p>
<p>几个实验现象：<br>①RNN的提升较少，而Transformer很多，说明RNN比Transformer更鲁棒。RNN比Transformer训练更为稳定。<br>②对于Transformer而言，若同样使用learning rate schedule，仍然有帮助，说明该方法是较为通用的。<br>③不使用lr schedule而只使用本文方法，也能达到不使用本文方法而使用lr schedule的结果，但需要更多的step。</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>为什么该方法能work？<br>符合直觉，模型从简单到难，更好训。同时从机器学习角度，如果完全正常的sample，则容易陷入局部最小或者saddle point，因此需要更长时间或者不好的泛化性能。</p>
<p>同时论文还提到了，为什么Transformer在增加batch能够有更好的收敛，这是因为一开始训练的noisy gradient太大，若增加batch能够信噪比，而本文方法在某种程度上也解决了该问题。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/04/11/诗词&句/人类永恒的愚蠢/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/11/诗词&句/人类永恒的愚蠢/" itemprop="url">无题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-11T23:02:15+08:00">
                2019-04-11
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-04-11T23:03:03+08:00">
                2019-04-11
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>人类永恒的愚蠢，是把莫名其妙的担忧，等同于智力超群。  ——美国加尔布雷斯</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/31/论文/每周论文15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/论文/每周论文15/" itemprop="url">每周论文15</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-31T22:04:30+08:00">
                2019-03-31
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-04-01T11:21:55+08:00">
                2019-04-01
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本周论文:</p>
<ol>
<li>Selective Kernel Networks</li>
<li>Attentional pooling for action recognition</li>
</ol>
<h2 id="1️⃣-Selective-Kernel-Networks"><a href="#1️⃣-Selective-Kernel-Networks" class="headerlink" title="1️⃣[Selective Kernel Networks]"></a>1️⃣[Selective Kernel Networks]</h2><p>通过对不同kernel size的feature map之间进行信息筛选获得更为鲁棒的表示，能够对不同的感受野进行整合，实现动态调整感受野。其思路还挺有意思的。</p>
<p>Introduction将该模型与视觉神经的理论结合在一起，也即，对于人类而言，在看不同尺寸不同远近的物体时，视觉皮层神经元<strong>感受野大小</strong>是会根据刺激来进行调节的，但一般而言在CNN中卷积核的大小是固定的。该模型正是从这一现象中获得灵感。</p>
<p>整个模型一共分为三个步骤：split，fuse，select</p>
<p>split生成多个不同kernel size的feature map，也即对应不同的感受野大小；fuse将不同feature map结合起来，获得一个全局的综合的向量表示；select根据不同的weight选择不同感受野的feature map。</p>
<p><img src="/images/15540416698404.jpg" width="80%" height="50%"></p>
<p>以上图为例。</p>
<h3 id="SK-Net"><a href="#SK-Net" class="headerlink" title="SK-Net"></a>SK-Net</h3><h4 id="第一步split"><a href="#第一步split" class="headerlink" title="第一步split"></a>第一步split</h4><p>给定输入$\mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}}$，通过不同的kernel size的CNN的卷积获得不同的feature map，上图是$3\times 3$与$5\times 5$的卷积核。卷积可以是传统的convolution卷积，也可以是空洞卷积（dilated convolution），或者深度卷积（depthwise convolution）。则有：<br>$\widetilde{\mathcal{F}} : \mathbf{X} \rightarrow \widetilde{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$ 与 $\widehat{\mathcal{F}} : \mathbf{X} \rightarrow \widehat{\mathbf{U}} \in \mathbb{R}^{H \times W \times C}$，其中$\widetilde{\mathcal{F}},\widehat{\mathcal{F}}$是卷积变换。</p>
<h4 id="第二步fuse"><a href="#第二步fuse" class="headerlink" title="第二步fuse"></a>第二步fuse</h4><p>直接将不同的feature map结合起来以获得全局信息，用以之后的动态调整。这里采用简单的求和以及global average pooling以获得channel-wise的信息$\mathbf{s} \in \mathbb{R}^{C}$：</p>
<script type="math/tex; mode=display">\mathbf{U}=\widetilde{\mathbf{U}}+\widehat{\mathbf{U}} \\ s_{c}=\mathcal{F}_{g p}\left(\mathbf{U}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} \mathbf{U}_{c}(i, j)</script><p>在获得$\mathbf{s}$后再通过MLP获得$\mathbf{z}$：</p>
<script type="math/tex; mode=display">\mathbf{z}=\mathcal{F}_{f c}(\mathbf{s})=\delta(\mathcal{B}(\mathbf{W} \mathbf{s}))</script><p>其中$\mathcal{B}$是batch normalization；$\delta$是Relu。</p>
<h4 id="第三步select"><a href="#第三步select" class="headerlink" title="第三步select"></a>第三步select</h4><p>使用soft attention去选择不同kernel size的feature map并结合在一起。也即：</p>
<script type="math/tex; mode=display">a_{c}=\frac{e^{\mathbf{A}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}, b_{c}=\frac{e^{\mathbf{B}_{c} \mathbf{z}}}{e^{\mathbf{A}_{c} \mathbf{z}}+e^{\mathbf{B}_{c} \mathbf{z}}}</script><p>其中$\mathbf{A}_{c}$是对应$\widetilde{\mathbf{U}}$第$c$个channel的参数，$\mathbf{B}_{c}$是对应$\widehat{\mathbf{U}}$第$c$个channel的参数。$\mathbf{A}, \mathbf{B} \in \mathbb{R}^{C \times d}$，那么$a_{c},b_{c}$就对应不同feature map的weight。</p>
<p>因此，最终的feature map $\mathbf{V}$：</p>
<script type="math/tex; mode=display">\mathbf{V}_{c}=a_{c} \cdot \tilde{\mathbf{U}}_{c}+b_{c} \cdot \widehat{\mathbf{U}}_{c}, \quad a_{c}+b_{c}=1 \\ \mathbf{V}=\left[\mathbf{V}_{1}, \mathbf{V}_{2}, \dots, \mathbf{V}_{C}\right], \mathbf{V}_{c} \in \mathbb{R}^{H \times W}</script><h3 id="对比-amp-思考"><a href="#对比-amp-思考" class="headerlink" title="对比&amp;思考"></a>对比&amp;思考</h3><h4 id="与SE-Net"><a href="#与SE-Net" class="headerlink" title="与SE-Net"></a>与SE-Net</h4><p>SE-Net是通过不同channel之间的交互，使得channel获得全局的感受野，使用的是对channel的放缩（详见上一篇论文笔记）；而SK-Net是不同的感受野之间的同一channel在通过全局信息的指导下以soft-attention的形式加权平均，这就和论文中提到的人类视觉对不同物体进行动态调整感受野的思路一致。</p>
<h4 id="与dynamic-convolution"><a href="#与dynamic-convolution" class="headerlink" title="与dynamic convolution"></a>与dynamic convolution</h4><p>在论文[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]中，研究人员提出动态感受野的convolution，通过利用当前词预测一个卷积窗口，增加了模型的灵活性，并在机器翻译上取得了很好的结果。</p>
<p>虽然目的与本篇论文一致，但思路是完全不同的。一个是通过预测；另一个是在全局信息的指导下进行加权。在我的理解看来，或许本篇论文的思路更加合理一些，第一，在有了全局信息的指导下能够更好的进行加权，而通过预测，似乎有些盲目，可能需要更多的数据才能学得更好；第二，dynamic convolution论文中也提到了，如果不使用如深度可分离卷积等轻量级卷积方法，dynamic convolution不大现实（A dynamic version of standard convolutions would be impractical for current GPUs due to their large memory requirements），而SK-Net则不会有这个问题。</p>
<h4 id="其他思考"><a href="#其他思考" class="headerlink" title="其他思考"></a>其他思考</h4><p>从另一个角度去思考，SK-Net通过人工定义好的几种不同大小的卷积，相当于在模型中引入更强的先验（inductive bias），也即假设了数据不会超过这几种大小的卷积的处理范围，这或许比不引入先验，完全靠数据去学某种特定pattern的dynamic convolution对小数据集更友好，因此可以不需要更多的数据来使得模型表现良好。类似的理解可以在CNN/RNN与Transformer的对比中看见，因为CNN/RNN引入了较强的local bias，因此对于小数据集更友好，但同时其上限或许不如Transformer高；而Transformer一开始就是全局感受野，使得需要更多数据来帮助模型学到某种特定pattern（如某种local bias），但当数据充足时，Transformer的上限更高，近期非常火的pretrained model GPT/GPT-2.0/Bert似乎也印证了这点。</p>
<hr>
<h2 id="2️⃣-Attentional-pooling-for-action-recognition"><a href="#2️⃣-Attentional-pooling-for-action-recognition" class="headerlink" title="2️⃣[Attentional pooling for action recognition]"></a>2️⃣[Attentional pooling for action recognition]</h2><p>提出一种基于attention的pooling策略，采用低秩近似的方法，使得模型能够在计算量不增加很多的情况下达到更好的效果。可以将该方法理解成对二阶pooling的低秩近似。</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="一阶pooling"><a href="#一阶pooling" class="headerlink" title="一阶pooling"></a>一阶pooling</h4><p>记$X \in R^{n \times f}$为被pooling的层，其中n为空间位置的个数，如$16\times 16$，$f$为channel个数。标准的sum/max pooling将该矩阵缩减为$R^{f \times 1}$，然后使用全连接的权重$\mathbf{w} \in R^{f \times 1}$获得一个分类的分数。这里假设的是二分类，但可以很容易推广为多分类。</p>
<p>上述操作形式化可以写成：</p>
<script type="math/tex; mode=display">\operatorname{score}_{p o o l}(X)=\mathbf{1}^{T} X \mathbf{w}, \quad \text { where } \quad X \in R^{n \times f}, \mathbf{1} \in R^{n \times 1}, \mathbf{w} \in R^{f \times 1}</script><p>其中$\mathbf{1}$为全1向量，$\mathbf{x}=\mathbf{1}^{T} X \in R^{1 \times f}$就是通过sum pooling后的feature。</p>
<h4 id="二阶pooling"><a href="#二阶pooling" class="headerlink" title="二阶pooling"></a>二阶pooling</h4><p>构建二阶feature $X^{T} X \in R^{f \times f}$，在获得二阶feature后，通常或向量化该矩阵，再送入全连接以做分类。也即我们会学习一个$f\times f$的全连接权重向量。若保持二阶feature与对应的全连接权重向量的形式为矩阵，矩阵相乘，其中的迹实际上就是这两个向量化后的矩阵所做内积获得的分数。形式化可以写成：</p>
<script type="math/tex; mode=display">\text {score}_{order2}(X)=\operatorname{Tr}\left(X^{T} X W^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W \in R^{f \times f}</script><p>这可以用迹的定义去证明：示意图<br><img src="/images/15540862875594.jpg" width="100%" height="50%"></p>
<h4 id="低秩二阶pooling"><a href="#低秩二阶pooling" class="headerlink" title="低秩二阶pooling"></a>低秩二阶pooling</h4><p>现尝试使用低秩去近似该二阶pooling，也即对$W$近似，将$W$写成两个向量的乘积，也即：</p>
<script type="math/tex; mode=display">W=\mathbf{a b}^{T} \text { where } \mathbf{a}, \mathbf{b} \in R^{f \times 1}</script><p>将上式代入二阶pooling，可获得：</p>
<script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\operatorname{Tr}\left(X^{T} X \mathbf{b a}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, \mathbf{a}, \mathbf{b} \in R^{f \times 1} \\ &=\operatorname{Tr}\left(\mathbf{a}^{T} X^{T} X \mathbf{b}\right) \\ &=\mathbf{a}^{T} X^{T} X \mathbf{b} \\ &=\mathbf{a}^{T}\left(X^{T}(X \mathbf{b})\right) \end{aligned}</script><p>第二行使用的是迹的定理：$\operatorname{Tr}(A B C)=\operatorname{Tr}(C A B)$<br>第三行使用的是标量的迹等于标量本身。<br>最后一行表明整个流程：给定一个feature map $X$，首先计算一个对所有空间位置的attentional map：$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$；然后根据该attentional map计算加权平均的feature：$\mathbf{x}=X^{T} \mathbf{h} \in R^{f \times 1}$。该feature再通过线性层获得最终的分数。</p>
<p>实际上上式还有其他理解的角度：</p>
<script type="math/tex; mode=display">\begin{aligned} \text {score}_{\text {attention}}(X) &=\left((X \mathbf{a})^{T} X\right) \mathbf{b} \\ &=(X \mathbf{a})^{T}(X \mathbf{b}) \end{aligned}</script><p>第一行表明attentional map也可以通过$X \mathbf{a} \in R^{n \times 1}$来计算，$\mathbf{b}$来做classifier。<br>第二行表明，该式子本质上是对称的，可以看成<strong>两个attentional heapmap的内积</strong>。</p>
<p>下图是整个流程：<br><img src="/images/15540869385196.jpg" width="80%" height="50%"></p>
<h4 id="Top-down-attention"><a href="#Top-down-attention" class="headerlink" title="Top-down attention"></a>Top-down attention</h4><p>现将二分类推广为多分类：</p>
<script type="math/tex; mode=display">\text {score}_{order2}(X, k)=\operatorname{Tr}\left(X^{T} X W_{k}^{T}\right), \quad \text { where } \quad X \in R^{n \times f}, W_{k} \in R^{f \times f}</script><p>也即将$W$替换成类相关的参数，仿照上面的推导，可以推出每个类都有特定的$\boldsymbol{a}_{k}$与$\boldsymbol{b}_{k}$。</p>
<p>但在这里通过固定其中一个参数为与类无关的参数，也即$\boldsymbol{b}_{k}=\boldsymbol{b}$。实际上就等价于一个是类相关的top-down attention；另一个是类无关的bottom-up attention。一个获得类特定的特征；另一个获得全局通用的特征。</p>
<p>因此最终低秩attention model为：</p>
<script type="math/tex; mode=display">\text {score}_{attention}(X, k)=\mathbf{t}_{k}^{T} \mathbf{h}, \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{a}_{k}, \mathbf{h}=X \mathbf{b}</script><h4 id="Average-pooling-Revisited"><a href="#Average-pooling-Revisited" class="headerlink" title="Average-pooling Revisited"></a>Average-pooling Revisited</h4><p>当然在给定了上述一系列的推导，我们对average-pooling重新进行形式化：</p>
<script type="math/tex; mode=display">\text {score}_{top-down}(X, k)=\mathbf{1}^{T} X \mathbf{w}_{k}=\mathbf{1}^{T} \mathbf{t}_{k} \quad \text { where } \quad \mathbf{t}_{k}=X \mathbf{w}_{k}</script><p>将$\mathbf{w}$替换成类相关的$\mathbf{w}_{k}$，实际上就是将二分类推广为多分类。但该形式赋予了average-pooling新的理解。</p>
<p>当然，我们还可以将rank-1推广为rank-k，实验证明对于大数据集使用大的秩会更好。</p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><h4 id="与Self-attentive的联系"><a href="#与Self-attentive的联系" class="headerlink" title="与Self-attentive的联系"></a>与Self-attentive的联系</h4><p>论文[A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING]就提出了利用可学习的head对feature进行attention加权平均的方法，并且将一个head推广到多个head。<br>实际上在$\mathbf{h}= {X \mathbf{b} \in R^{n \times 1}}$我们就可以看出，$\mathbf{b}$在这里扮演的角色就是self-attentive的head的角色。对于秩为1的近似，就是head为1的情况，若将秩为1推广为秩为k，也即等价于在Self-attentive中多个head的情况。</p>
<p>本文巧妙的地方在于head有两个作用，一种是top-down的head，获得的是类相关的feature；另一个是bottom-up的feature，获得的是通用的feature。并且本文通过巧妙的数学推导来获得新的解释，本来仅仅是二阶feature过一个全连接，但通过公式推导赋予了attention的解释，这点让人眼前一亮。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/31/诗词&句/每周诗词21/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/诗词&句/每周诗词21/" itemprop="url">每周诗词21</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-31T11:00:14+08:00">
                2019-03-31
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-31T11:02:39+08:00">
                2019-03-31
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣醉落魄-·-席上呈元素"><a href="#1️⃣醉落魄-·-席上呈元素" class="headerlink" title="1️⃣醉落魄 · 席上呈元素"></a>1️⃣醉落魄 · 席上呈元素</h3><p>[宋] 苏轼<br>分携如昨，人生到处萍飘泊。偶然相聚还离索。多病多愁，须信从来错。<br><strong>尊前一笑休辞却，天涯同是伤沦落</strong>。故山犹负平生约。西望峨嵋，长羡归飞鹤。</p>
<p><a href="http://lib.xcz.im/work/57c467a86be3ff0058452840" target="_blank" rel="noopener">http://lib.xcz.im/work/57c467a86be3ff0058452840</a></p>
<hr>
<h3 id="2️⃣戏为六绝句"><a href="#2️⃣戏为六绝句" class="headerlink" title="2️⃣戏为六绝句"></a>2️⃣戏为六绝句</h3><p>[唐] 杜甫<br>【其一】<br>庾信文章老更成，凌云健笔意纵横。<br>今人嗤点流传赋，不觉前贤畏后生。</p>
<p>【其三】<br>纵使卢王操翰墨，劣于汉魏近风骚。<br>龙文虎脊皆君驭，历块过都见尔曹。</p>
<p>过都历块 (guò dōu lì kuài)<br>解释：越过都市，经过山阜。意指纵横驰骋，施展才能。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/24/论文/每周论文14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/24/论文/每周论文14/" itemprop="url">每周论文14</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-24T09:57:30+08:00">
                2019-03-24
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-24T10:54:54+08:00">
                2019-03-24
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本周论文:</p>
<ol>
<li>Is Second-order Information Helpful for Large-scale Visual Recognition?</li>
<li>The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification</li>
</ol>
<h2 id="1️⃣-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition"><a href="#1️⃣-Is-Second-order-Information-Helpful-for-Large-scale-Visual-Recognition" class="headerlink" title="1️⃣[Is Second-order Information Helpful for Large-scale Visual Recognition?]"></a>1️⃣[Is Second-order Information Helpful for Large-scale Visual Recognition?]</h2><p>通过协方差的方法获得图像的二阶信息。<br>参考了<a href="https://zhuanlan.zhihu.com/p/46864160" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46864160</a></p>
<p>深度分类网络主要分为两个部分：特征提取和分类器。无论是VGG还是GoogleNet，后来的Resnet、Densenet，在连接分类器之前，一般都连接了一个Pooling层。<br>但pooling只获得了feature的一阶信息，对于细分类问题中类间差异不显著，一阶信息可能有一些不适用，因此我们可以通过一阶信息获得二阶信息，从而获取更有价值的信息。</p>
<p>本文通过获取<strong>特征协方差</strong>的方法，以达到该目的。</p>
<p>输入:$\mathbf{X} \in \mathbb{R}^{d \times N}$</p>
<p>则协方差矩阵为$\mathbf{X} \mapsto \mathbf{P}, \quad \mathbf{P}=\mathbf{X} \overline{\mathbf{I}} \mathbf{X}^{T}$，其中$\overline{\mathbf{I}}=\frac{1}{N}\left(\mathbf{I}-\frac{1}{N} \mathbf{1} \mathbf{1}^{T}\right)$, $\mathbf{I}$是单位阵，$\mathbf{1}$是全1的向量。</p>
<p>协方差矩阵是半正定矩阵，因此可写成$\mathbf{P} \mapsto(\mathbf{U}, \mathbf{\Lambda}), \quad \mathbf{P}=\mathbf{U} \mathbf{\Lambda} \mathbf{U}^{T}$，其中$\boldsymbol{\Lambda}=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{d}\right)$，$\mathbf{U}=\left[\mathbf{u}_{1}, \dots, \mathbf{u}_{d}\right]$，$\mathbf{U}$是对应的特征向量。</p>
<p>最终可获得$\mathbf{Q}$矩阵：$(\mathbf{U}, \boldsymbol{\Lambda}) \mapsto \mathbf{Q}, \mathbf{Q} \triangleq \mathbf{P}^{\alpha}=\mathbf{U F}(\mathbf{\Lambda}) \mathbf{U}^{T}$，其中$\alpha$是一个正实数，$\mathbf{F}(\boldsymbol{\Lambda})=\operatorname{diag}\left(f\left(\lambda_{1}\right), \ldots, f\left(\lambda_{d}\right)\right)$，其中$f\left(\lambda_{i}\right)=\lambda_{i}^{\alpha}$，是特征值的幂，如果要做归一化，那么可以有：</p>
<script type="math/tex; mode=display">f\left(\lambda_{i}\right)=\left\{\begin{array}{cc}{\lambda_{i}^{\alpha} / \lambda_{1}^{\alpha}} & {\text { for MPN+M }-\ell_{2}} \\ {\lambda_{i}^{\alpha} /\left(\sum_{k} \lambda_{k}^{2 \alpha}\right)^{\frac{1}{2}}} & {\text { for MPN+M-Fro }}\end{array}\right.</script><p>之所以取幂，是为了解决在协方差估计中小样本高维度的问题，以resnet为例，最后得到的feature为7X7X512，也就是49个512维的feature，这样估计出来的协方差矩阵是不靠谱的，而通过幂这个操作，可以解决这一问题。通过实验可以发现，当幂次为0.5也就是平方根操作时，效果最优。（似乎类似的有word2vec的平滑）</p>
<p>（虽然这篇有些看不大懂，但一个启发就是，可以通过协方差的方式进行特征之间的交互）</p>
<hr>
<h2 id="2️⃣-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification"><a href="#2️⃣-The-Treasure-beneath-Convolutional-Layers-Cross-convolutional-layer-Pooling-for-Image-Classification" class="headerlink" title="2️⃣[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]"></a>2️⃣[The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification]</h2><p>提出使用卷积出来后的feature经过pooling作为最后的图像特征表示而不是全连接后的特征表示。</p>
<p>Motivation：只使用最后一层fc的特征有一个缺点，就是丢失位置信息，而convolution layer包含了丰富的空间信息。在pooling完后每个local区域都能获得一个特征，并拼接起来作为最后的表示。</p>
<p><img src="/images/15533936911589.jpg" width="60%" height="50%"></p>
<p>prerequisite:<br>①首先有一个预训练好的模型<br>②有两层一样$H\times W$的convolution。论文以AlexNet作为例子</p>
<p>假设卷积后的feature map是$H × W × D$，那么可以理解成，我们将图片分为$H × W$的区域，每个区域的特征用$D$维表示。我们称每个$D$维特征一个spatial unit。当使用全连接时，这部分的空间信息就丢失了，并且无法还原。</p>
<p>本文提出，将每个区域提取出一个特征，然后拼起来组成一整张图的特征，如下图，每个长条（也即$1\times 1\times channel$）作为一个特征：</p>
<p><img src="/images/15533939765641.jpg" width="50%" height="50%"></p>
<p>如何判断区域？一种方法是首先检测出多个区域，每个区域对应一种object part，然后对于落入该区域的特征进行pooling，给定D种human-specified object parts，那么可以获得D个feature且拼在一起。</p>
<script type="math/tex; mode=display">\mathbf{P}_{k}^{t}=\sum_{i=1} \mathbf{x}_{i} I_{i, k}</script><p>具体而言，$\mathbf{x}_{i}$是特征，$I_{i, k}$是二元的indicator，表明$\mathbf{x}_{i}$是否落入该区域，每个$I$实际上定义了一个池化通道。当然，这里可以进一步将indicator从二元扩展为权重。</p>
<p>但在实现的过程中，并没有human-specified的区域。这里我们就借助下一层的卷积作为indicator。</p>
<blockquote>
<p>By doing so, D t+1 pooling channels are created for the local features extracted from the tth convolutional layer</p>
</blockquote>
<p>这也就被称为cross-convolutional-layer pooling。</p>
<p>如何做？</p>
<blockquote>
<p>the filter of a convolutional layer works as a part detector and its feature map serves a similar role as the part region indicator map.</p>
</blockquote>
<p>具体而言，有：</p>
<script type="math/tex; mode=display">\begin{array}{l}{\mathbf{P}^{t}=\left[\mathbf{P}_{1}^{t}, \mathbf{P}_{2}^{t}, \cdots, \mathbf{P}_{k}^{t}, \cdots, \mathbf{P}_{D_{t+1}}^{t}\right]} \\ {\text { where, } \mathbf{P}_{k}^{t}=\sum_{i=1}^{N_{t}} \mathbf{x}_{i}^{t} a_{i, k}^{t+1}}\end{array}</script><p>$\mathbf{P}^{t}$表示第t层convolution在卷积过后做cross-pooling后的特征集合，也即我们要获得的表示，该表示通过$D_{t+1}$次pooling后的结果拼接而成。$D_{t+1}$具体来说，就是第t+1层的卷积的channel维数。假设$\mathbf{a}_{i}^{t+1} \in \mathbb{R}^{D_{t+1}}$是第t+1层convolution的第i个空间单位（spatial unit）的feature vector，其中$a_{i, k}^{t+1}$是该向量的一个值，该值就作为pooling的权重。</p>
<p>上述有些绕口且难懂，直接看例子：<br><img src="/images/15533957004853.jpg" width="80%" height="50%"><br><img src="/images/15533957336100.jpg" width="80%" height="50%"></p>
<p>即，第t+1层convolution的channel维度为多少，则pooling后的特征个数即为多少。因为第t层与第t+1层的$H\times W$是一致的，那么可以用t+1层的每个slice去对第t层的convolution进行加权。</p>
<p>为什么这样是合理的？<br>因为第t+1层的convolution提取了$D_{t+1}$个特征，使用的是$m\times n$的kernel size，如果$x$是被$m\times n$的某个kernel提取了，那么很自然的，$x$就是对应该kernel提取出来的feature的一个spatial unit。说白了就是第t层与第t+1层的空间对应。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/23/诗词&句/每周诗词20/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/23/诗词&句/每周诗词20/" itemprop="url">每周诗词20</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-23T17:32:14+08:00">
                2019-03-23
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-23T17:35:11+08:00">
                2019-03-23
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣杂诗七首（其四）"><a href="#1️⃣杂诗七首（其四）" class="headerlink" title="1️⃣杂诗七首（其四）"></a>1️⃣杂诗七首（其四）</h3><p>[三国] 曹植<br>南国有佳人，容华若桃李。<br>朝游江北岸，夕宿潇湘沚。<br>时俗薄朱颜，谁为发皓齿？<br>俯仰岁将暮，荣耀难久恃。</p>
<p><a href="http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f" target="_blank" rel="noopener">http://lib.xcz.im/work/58ad4c78ac502e007e9f6f9f</a></p>
<hr>
<h3 id="2️⃣梦江南"><a href="#2️⃣梦江南" class="headerlink" title="2️⃣梦江南"></a>2️⃣梦江南</h3><p>[唐] 温庭筠<br>千万恨，恨极在天涯。山月不知心里事，水风空落眼前花，摇曳碧云斜。</p>
<p><a href="http://lib.xcz.im/work/57b8d0c77db2a2005425c856" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8d0c77db2a2005425c856</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/17/论文/每周论文13/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/17/论文/每周论文13/" itemprop="url">每周论文13</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-17T22:32:30+08:00">
                2019-03-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-19T15:41:14+08:00">
                2019-03-19
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1️⃣-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation"><a href="#1️⃣-Depthwise-Separable-Convolutions-for-Neural-Machine-Translation" class="headerlink" title="1️⃣[Depthwise Separable Convolutions for Neural Machine Translation]"></a>1️⃣[Depthwise Separable Convolutions for Neural Machine Translation]</h2><p>将depthwise separable convolution 深度可分离卷积 用于翻译任务，并在此基础上对depthwise separable进行更进一步的参数量优化，也即super-separable。（其实我觉得并没有啥创新性的感觉）</p>
<p><img src="/images/15528281403428.jpg" width="90%" height="50%"></p>
<p>首先介绍什么是depthwise separable convolution，实际上就是一个depthwise+pointwise。</p>
<script type="math/tex; mode=display">\operatorname{Conv}(W, y)_{(i, j)}=\sum_{k, l, m}^{K, L, M} W_{(k, l, m)} \cdot y_{(i+k, j+l, m)}</script><script type="math/tex; mode=display">\operatorname{PointwiseConv}(W, y)_{(i, j)}=\sum_{m}^{M} W_{m} \cdot y_{(i, j, m)}</script><script type="math/tex; mode=display">\text {DepthwiseConv}(W, y)_{(i, j)}=\sum_{k, l}^{K, L} W_{(k, l)} \odot y_{(i+k, j+l)}</script><script type="math/tex; mode=display">\operatorname{SepConv}\left(W_{p}, W_{d}, y\right)_{(i, j)}=\text {PointwiseConv}_{(i, j)}\left(W_{p}, \text { DepthwiseConv }_{(i, j)}\left(W_{d}, y\right)\right)</script><p>几种convolution的参数量对比：<br><img src="/images/15528283555357.jpg" width="80%" height="50%"><br>其中k是kernel size，c是channel，g是group。</p>
<p>g-Sub-separable是指将channel分为几个group，每个group进行常规的convolution操作；g-Super-separable，也即本文中提出的convolution，同样是将channel分为几个group，然后对每个group进行depthwise-separable的卷积。</p>
<hr>
<h2 id="2️⃣-Squeeze-and-Excitation-Networks"><a href="#2️⃣-Squeeze-and-Excitation-Networks" class="headerlink" title="2️⃣[Squeeze-and-Excitation Networks]"></a>2️⃣[Squeeze-and-Excitation Networks]</h2><p>提出一种新型的网络，能够通过建模channel之间的关系，使得每个channel能够获得全局的信息，进而提高模型的能力。<br><img src="/images/15528285519609.jpg" width="90%" height="50%"></p>
<p>分为两步：第一步是获得一个全局的表示，第二步是根据全局信息更新每个channel的信息。</p>
<h3 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h3><p>输入：$ \mathbf{X} \in \mathbb{R}^{H^{\prime} \times W^{\prime} \times C^{\prime}} $<br>经过特征提取后（如Convolution)：$\mathbf{U} \in \mathbb{R}^{H \times W \times C}$，也即：$\mathbf{U}=\mathbf{F}_{t r}(\mathbf{X})$<br>将$\mathbf{U}$写成：$\mathbf{U}=\left[\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{C}\right]$<br>$\mathbf{V}$ 是可学习的卷积核参数： $\mathbf{V}=\left[\mathbf{v}_{1}, \mathbf{v}_{2}, \ldots, \mathbf{v}_{C}\right]$</p>
<p>则上述卷积变换可写成：$\mathbf{u}_{c}=\mathbf{v}_{c} \ast \mathbf{X}=\sum_{s=1}^{C^{\prime}} \mathbf{v}_{c}^{s} \ast \mathbf{x}^{s}$</p>
<h3 id="Squeeze-Global-Information-Embedding"><a href="#Squeeze-Global-Information-Embedding" class="headerlink" title="Squeeze: Global Information Embedding"></a>Squeeze: Global Information Embedding</h3><p>第一步，将所有的特征进行整合得到全局的特征：</p>
<script type="math/tex; mode=display">z_{c}=\mathbf{F}_{s q}\left(\mathbf{u}_{c}\right)=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} u_{c}(i, j)</script><p>论文提取全局特征的方法直接用简单的global average pooling。那么$\mathbf{z} \in \mathbb{R}^{C}$的每一维就代表每一维的channel。</p>
<h3 id="Excitation-Adaptive-Recalibration"><a href="#Excitation-Adaptive-Recalibration" class="headerlink" title="Excitation: Adaptive Recalibration"></a>Excitation: Adaptive Recalibration</h3><p>与attention不同的是，论文希望能够同时强调不同多个channel的重要（而不是one-hot的形式），因此使用一个简单的门控制机制，采用sigmoid激活函数：（这里的想法挺有意思，相对attention的softmax似乎确实会更好的样子）</p>
<script type="math/tex; mode=display">\mathbf{s}=\mathbf{F}_{ex}(\mathbf{z}, \mathbf{W})=\sigma(g(\mathbf{z}, \mathbf{W}))=\sigma\left(\mathbf{W}_{2} \delta\left(\mathbf{W}_{1} \mathbf{z}\right)\right)</script><p>为了减少参数这里的MLP采用了bottleneck的形式。亦即：<br>${\mathbf{W}_{1} \in \mathbb{R}^{\frac{C}{r} \times C}}$ $ {\mathbf{W}_{2} \in \mathbb{R}^{C \times \frac{C}{r}}}$<br>$r$是reduction ratio。</p>
<p>贴上作者的思路：</p>
<blockquote>
<p>To make use of the information aggregated in the squeeze operation, we follow it with a second operation which aims to fully capture channel-wise dependencies. To fulfill this objective, the function must meet two criteria: first, it must be ﬂexible (in particular, it must be capable of learning a nonlinear interaction between channels) and second, it must learn a non-mutually-exclusive relationship since we would like to ensure that multiple channels are allowed to be emphasised (rather than enforcing a one-hot activation). To meet these criteria, we opt to employ a simple gating mechanism with a sigmoid activation.</p>
</blockquote>
<p>最后对每个channel进行<strong>放缩</strong>，获得新的表示：</p>
<script type="math/tex; mode=display">\widetilde{\mathbf{x}}_{c}=\mathbf{F}_{\text {scale}}\left(\mathbf{u}_{c}, s_{c}\right)=s_{c} \cdot \mathbf{u}_{c}</script><hr>
<h2 id="3️⃣-Non-local-Neural-Networks"><a href="#3️⃣-Non-local-Neural-Networks" class="headerlink" title="3️⃣[Non-local Neural Networks]"></a>3️⃣[Non-local Neural Networks]</h2><p>提出一种新的结构，与上一篇类似，希望模型的每个位置都能感知到其他位置，从而捕获长程依赖，拥有全局信息。</p>
<p><img src="/images/15528297540165.jpg" width="60%" height="50%"></p>
<h3 id="Non-local-Network"><a href="#Non-local-Network" class="headerlink" title="Non-local Network"></a>Non-local Network</h3><p>定义non-local网络：</p>
<script type="math/tex; mode=display">\mathbf{y}_{i}=\frac{1}{\mathcal{C}(\mathbf{x})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right) g\left(\mathbf{x}_{j}\right)</script><p>其中$\mathcal{C}$是归一化函数；$f$是第$i$个位置与第$j$个位置的交互函数；$g$计算第$j$个位置的表示。</p>
<h4 id="g-的具体形式"><a href="#g-的具体形式" class="headerlink" title="$g$的具体形式"></a>$g$的具体形式</h4><p>一个线性函数：$g\left(\mathbf{x}_{j}\right)=W_{g} \mathbf{x}_{j}$<br>在实现的时候是一个$1\times1$或 $1\times1\times1$的convolution。</p>
<h4 id="f-的具体形式"><a href="#f-的具体形式" class="headerlink" title="$f$的具体形式"></a>$f$的具体形式</h4><p>①Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\mathbf{x}_{i}^{T} \mathbf{x}_{j}}$<br>则归一化定义为$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$ 。</p>
<p>②Embedded Gaussian<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=e^{\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)}$<br>其中：$\theta\left(\mathbf{x}_{i}\right)=W_{\theta} \mathbf{x}_{i} $, $ \phi\left(\mathbf{x}_{j}\right)=W_{\phi} \mathbf{x}_{j}$<br>归一化：$\mathcal{C}(\mathbf{x})=\sum_{\forall j} f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)$</p>
<p>可以看到self-attention是Embedded Gaussian的一种形式。虽然有这样的关系，但作者在实验中发现softmax并不是必要的。</p>
<p>③Dot product<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\theta\left(\mathbf{x}_{i}\right)^{T} \phi\left(\mathbf{x}_{j}\right)$<br>归一化：$\mathcal{C}(\mathbf{x})=N$</p>
<p>④Concatenation<br>$f\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\operatorname{ReLU}\left(\mathbf{w}_{f}^{T}\left[\theta\left(\mathbf{x}_{i}\right), \phi\left(\mathbf{x}_{j}\right)\right]\right)$<br>$\mathcal{C}(\mathbf{x})=N$</p>
<p>有了上面的non-local的介绍，可以直接将其用于residual network。<br>$\mathbf{z}_{i}=W_{z} \mathbf{y}_{i}+\mathbf{x}_{i}$<br>$y$则是non-local network的输出。</p>
<h3 id="Non-local-block的策略-tricks"><a href="#Non-local-block的策略-tricks" class="headerlink" title="Non-local block的策略/tricks"></a>Non-local block的策略/tricks</h3><p>①设置$W_g$,$W_θ$,$W_ϕ$的channel的数目为x的channel数目的一半，这样就形成了一个bottleneck，能够减少一半的计算量。Wz再重新放大到x的channel数目，保证输入输出维度一致。</p>
<p>②在$\frac{1}{\mathcal{C}(\hat{\mathbf{x}})} \sum_{\forall j} f\left(\mathbf{x}_{i}, \hat{\mathbf{x}}_{j}\right) g\left(\hat{\mathbf{x}}_{j}\right)$使用下采样，如max-pooling，减少计算量。</p>
<hr>
<h2 id="4️⃣-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition"><a href="#4️⃣-Bilinear-CNN-Models-for-Fine-grained-Visual-Recognition" class="headerlink" title="4️⃣[Bilinear CNN Models for Fine-grained Visual Recognition]"></a>4️⃣[Bilinear CNN Models for Fine-grained Visual Recognition]</h2><p>提出一种双线性模型，由两个特征提取器组成，他们的输出做<strong>外积</strong>，最终获得图像描述特征。</p>
<p>Motivation(?不确定是不是这样)：对于细粒度物体的分类，先对局部定位，再提取特征。两个特征提取器一个是提取location，另一个提取特征。</p>
<p><img src="/images/15528310057673.jpg" width="60%" height="50%"></p>
<p>为什么用<strong>外积</strong>？</p>
<blockquote>
<p>outer product captures pairwise correlations between the feature channels</p>
</blockquote>
<p>有意思的是作者将该模型和人脑视觉处理的两个假设联系在一起(stream hypothesis)：<br>here are two main pathways, or “streams”. The ventral stream (or, “what pathway”) is involved with object identiﬁcation and recognition. The dorsal stream (or, “where pathway”) is involved with processing the object’s spatial location relative to the viewer.<br>不过看看就好，并没有什么道理。</p>
<p>对于一个分类的双线性模型而言，其一般形式是一个四元组：$\mathcal{B}=\left(f_{A}, f_{B}, \mathcal{P}, \mathcal{C}\right)$。其中$f$是特征函数，$\mathcal{P}$是pooling函数，$\mathcal{C}$是分类函数。具体而言，$f$是一个映射，${f : \mathcal{L} \times \mathcal{I} \rightarrow} {R^ {c\times D}} $。也即将一个image和一个location L 映射成feature。（We refer to locations generally which can include position and scale 其实这里不是很懂location的意思）</p>
<p>将feature a和feature b结合在一起：<br>$\text { bilinear }\left(l, \mathcal{I}, f_{A}, f_{B}\right)=f_{A}(l, \mathcal{I})^{T} f_{B}(l, \mathcal{I})$</p>
<p>pooling有好几种，可以直接加起来，或者使用max-pooling。这里使用直接加起来的方式，可以理解为，这些特征是无序(orderless)的叠加。</p>
<p>在获得输出后再做一些操作/trick能够提升表现：<br>$\begin{array}{l}{\mathbf{y} \leftarrow \operatorname{sign}(\mathbf{x}) \sqrt{|\mathbf{x}|}} \\ {\mathbf{z} \leftarrow \mathbf{y} /|\mathbf{y}|_{2}}\end{array}$</p>
<p>讨论：<br>①But do the networks specialize into roles of localization (“where”) and appearance modeling (“what”) when initialized asymmetrically and ﬁne-tuned?<br>通过可视化发现，并没有明确的功能分开。<br>Both these networks tend to activate strongly on highly speciﬁc semantic parts</p>
<p>②bilinear的好处还可以扩展成trilinear，添加更多的信息。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/17/诗词&句/每周诗词19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/17/诗词&句/每周诗词19/" itemprop="url">每周诗词19</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-17T09:26:14+08:00">
                2019-03-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-17T22:32:17+08:00">
                2019-03-17
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1️⃣送灵澈上人"><a href="#1️⃣送灵澈上人" class="headerlink" title="1️⃣送灵澈上人"></a>1️⃣送灵澈上人</h3><p>[唐] 刘长卿<br>苍苍竹林寺，杳杳钟声晚。<br>荷笠带斜阳，青山独归远。</p>
<p>荷（hè）笠：背着斗笠。</p>
<p><a href="http://lib.xcz.im/work/57b90887128fe10054c9c750" target="_blank" rel="noopener">http://lib.xcz.im/work/57b90887128fe10054c9c750</a></p>
<hr>
<h3 id="2️⃣苏幕遮-·-怀旧"><a href="#2️⃣苏幕遮-·-怀旧" class="headerlink" title="2️⃣苏幕遮 · 怀旧"></a>2️⃣苏幕遮 · 怀旧</h3><p>[宋] 范仲淹<br>碧云天，黄叶地，秋色连波，波上寒烟翠。山映斜阳天接水，芳草无情，更在斜阳外。<br>黯乡魂，追旅思。夜夜除非，好梦留人睡。明月楼高休独倚，酒入愁肠，化作相思泪。</p>
<p><a href="http://lib.xcz.im/work/57b8ee4a128fe10054c91757" target="_blank" rel="noopener">http://lib.xcz.im/work/57b8ee4a128fe10054c91757</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.linzehui.me/2019/03/10/论文/每周论文12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="林泽辉">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Weekly Review">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/10/论文/每周论文12/" itemprop="url">每周论文12</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-10T10:52:30+08:00">
                2019-03-10
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-12T21:44:42+08:00">
                2019-03-12
              </time>
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1️⃣-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS"><a href="#1️⃣-PAY-LESS-ATTENTION-WITH-LIGHTWEIGHT-AND-DYNAMIC-CONVOLUTIONS" class="headerlink" title="1️⃣[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]"></a>1️⃣[PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS]</h2><p>Facebook研究人员提出的两种基于卷积的方法尝试替代self-attention在transformer中的作用，拥有更少的参数以及更快的速度，并且能够达到很好的效果。</p>
<p><img src="/images/15521843619624.jpg" width="80%" height="80%"></p>
<h3 id="Lightweight-convolution"><a href="#Lightweight-convolution" class="headerlink" title="Lightweight convolution"></a>Lightweight convolution</h3><p>背景：depthwise convolution<br>每个channel独立进行卷积，注意到放到NLP任务上channel是指embedding的每一维。</p>
<script type="math/tex; mode=display">O_{i, c}=\text{DepthwiseConv}\left(X, W_{c, :}, i, c\right)=\sum_{j=1}^{k} W_{c, j} \cdot X_{\left(i+j-\left\lceil\frac{k+1}{2}\right]\right), c}</script><p>因此Lightweight convolution的计算方法为：</p>
<script type="math/tex; mode=display">\operatorname{LightConv}\left(X, W_{\left\lceil\frac{c H}{d}\right\rceil,:}, i, c\right)=\text { DepthwiseConv}\left(X, \text{softmax}(W_{\left\lceil\frac{c H}{d}\right\rceil,:}), i, c\right)</script><p>每一层都有固定的window size，这和self-attention不同，self-attention是所有的context都进行交互。</p>
<ul>
<li>Weight sharing 注意到这里讲每d/H个channel的参数进行绑定，进一步减少参数。</li>
<li>Softmax-normalization 对channel一维进行softmax，相当于归一化每个词的每一维的的重要性（比self-attention更精细）。实验证明，如果没有softmax没办法收敛。</li>
</ul>
<p>因此总体的架构为：<br>input—&gt;linear —&gt; GLU(gated linear unit) —&gt; lightconv/dynamicConv —&gt; linear</p>
<h3 id="Dynamic-convolution"><a href="#Dynamic-convolution" class="headerlink" title="Dynamic convolution"></a>Dynamic convolution</h3><p>与lightweight convolution相似，但加了一个动态的kernel size。</p>
<script type="math/tex; mode=display">\text { DynamicConv}( X , i , c ) = \operatorname{LightConv}\left(X, f\left(X_{i}\right)_{h,:}, i, c\right)</script><p>这里的kernel size简单使用线性映射：$f : \mathbb { R } ^ { d } \rightarrow \mathbb { R } ^ { H \times k }$<br>如：$f\left(X_{i}\right)=\sum_{c=1}^{d} W_{h, j, c}^{Q} X_{i, c}$</p>
<hr>
<h2 id="2️⃣-Joint-Embedding-of-Words-and-Labels-for-Text-Classiﬁcation"><a href="#2️⃣-Joint-Embedding-of-Words-and-Labels-for-Text-Classiﬁcation" class="headerlink" title="2️⃣[Joint Embedding of Words and Labels for Text Classiﬁcation]"></a>2️⃣[Joint Embedding of Words and Labels for Text Classiﬁcation]</h2><p>提出一种机制将label作为embedding与词一同训练，同时引入label和word的attention机制，在分类上获得效果。</p>
<p><img src="/images/15521854844061.jpg" width="40%" height="50%"></p>
<p>上图中，C是label embedding，维度为$P\times K$ ; V是句子所有词的embedding矩阵，维度为$P\times L$。<br>$\mathbf{G}$的计算公式为：</p>
<script type="math/tex; mode=display">\mathbf{G}=\left(\mathbf{C}^{\top} \mathbf{V}\right) \oslash \hat{\mathbf{G}}</script><p>$\oslash$表示element-wise相除。$\hat{\mathbf{G}}$表示l2 norm，也即：</p>
<script type="math/tex; mode=display">\hat{g}_{k l}=\left\|\boldsymbol{c}_{k}\right\|\left\|\boldsymbol{v}_{l}\right\|</script><p>因此公式的本质即在计算label与每个词的cos距离。</p>
<p>在获得了$\mathbf{G}$后，为了获得更高的的表示，如phrase，将一个一个block取出，并过线性层：</p>
<script type="math/tex; mode=display">\boldsymbol{u}_{l}=\operatorname{ReLU}\left(\mathbf{G}_{l-r : l+r} \mathbf{W}_{1}+\boldsymbol{b}_{1}\right)</script><p>接着对每个$\boldsymbol{u}_{l}$取最大值：</p>
<script type="math/tex; mode=display">m_{l}=\textbf{max-pooling}\left(\boldsymbol{u}_{l}\right)</script><p>此时的$\mathbf{m}$是一个长度为L的向量。最终对m做softmax获得一个分数的分布：</p>
<script type="math/tex; mode=display">\boldsymbol{\beta}=\operatorname{SoftMax}(\boldsymbol{m})</script><p>将该分数和每个词做加权求和，获得最终的向量表示：</p>
<script type="math/tex; mode=display">\boldsymbol{z}=\sum_{l} \beta_{l} \boldsymbol{v}_{l}</script><p>思考：将label与embedding放在一起训练这个思路不错。但整合的方式是否过于简单粗暴了<br>？特别是phrase的提取和随后的max-pooling的可解释性并不强的样子。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://ws4.sinaimg.cn/large/006tNc79gy1fthknxagbjj3069069jr8.jpg"
                alt="林泽辉" />
            
              <p class="site-author-name" itemprop="name">林泽辉</p>
              <p class="site-description motion-element" itemprop="description">人一己千</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">128</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">150</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">林泽辉</span>

  
</div>






  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
